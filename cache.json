{"2023-11-21T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2311.10899v2","updated":"2023-11-21T02:16:27Z","published":"2023-11-17T22:44:05Z","title":"Extraction and Summarization of Explicit Video Content using Multi-Modal\n  Deep Learning","summary":"  With the increase in video-sharing platforms across the internet, it is\ndifficult for humans to moderate the data for explicit content. Hence, an\nautomated pipeline to scan through video data for explicit content has become\nthe need of the hour. We propose a novel pipeline that uses multi-modal deep\nlearning to first extract the explicit segments of input videos and then\nsummarize their content using text to determine its age appropriateness and age\nrating. We also evaluate our pipeline's effectiveness in the end using standard\nmetrics.\n","authors":["Shaunak Joshi","Raghav Gaggar"],"pdf_url":"https://arxiv.org/pdf/2311.10899v2.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.09387v2","updated":"2023-11-21T18:31:57Z","published":"2023-11-15T21:30:26Z","title":"Banach-Tarski Embeddings and Transformers","summary":"  We introduce a new construction of embeddings of arbitrary recursive data\nstructures into high dimensional vectors. These embeddings provide an\ninterpretable model for the latent state vectors of transformers. We\ndemonstrate that these embeddings can be decoded to the original data structure\nwhen the embedding dimension is sufficiently large. This decoding algorithm has\na natural implementation as a transformer. We also show that these embedding\nvectors can be manipulated directly to perform computations on the underlying\ndata without decoding. As an example we present an algorithm that constructs\nthe embedded parse tree of an embedded token sequence using only vector\noperations in embedding space.\n","authors":["Joshua Maher"],"pdf_url":"https://arxiv.org/pdf/2311.09387v2.pdf","comment":"22 pages, 7 figures. v2: Fixed order of matrix multiplication in\n  section 2.4"},{"id":"http://arxiv.org/abs/2310.02168v2","updated":"2023-11-21T18:18:49Z","published":"2023-10-03T16:02:36Z","title":"Editing Personality for LLMs","summary":"  This paper introduces an innovative task focused on editing the personality\ntraits of Large Language Models (LLMs). This task seeks to adjust the models'\nresponses to opinion-related questions on specified topics since an\nindividual's personality often manifests in the form of their expressed\nopinions, thereby showcasing different personality traits. Specifically, we\nconstruct a new benchmark dataset PersonalityEdit to address this task. Drawing\non the theory in Social Psychology, we isolate three representative traits,\nnamely Neuroticism, Extraversion, and Agreeableness, as the foundation for our\nbenchmark. We then gather data using GPT-4, generating responses that not only\nalign with a specified topic but also embody the targeted personality trait. We\nconduct comprehensive experiments involving various baselines and discuss the\nrepresentation of personality behavior in LLMs. Our intriguing findings uncover\npotential challenges of the proposed task, illustrating several remaining\nissues. We anticipate that our work can provide the NLP community with\ninsights. Code and datasets will be released at\nhttps://github.com/zjunlp/EasyEdit.\n","authors":["Shengyu Mao","Ningyu Zhang","Xiaohan Wang","Mengru Wang","Yunzhi Yao","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2310.02168v2.pdf","comment":"Work in progress, add more experiments"},{"id":"http://arxiv.org/abs/2310.02129v2","updated":"2023-11-21T17:59:04Z","published":"2023-10-03T15:10:46Z","title":"Unveiling the Pitfalls of Knowledge Editing for Large Language Models","summary":"  As the cost associated with fine-tuning Large Language Models (LLMs)\ncontinues to rise, recent research efforts have pivoted towards developing\nmethodologies to edit implicit knowledge embedded within LLMs. Yet, there's\nstill a dark cloud lingering overhead -- will knowledge editing trigger\nbutterfly effect? since it is still unclear whether knowledge editing might\nintroduce side effects that pose potential risks or not. This paper pioneers\nthe investigation into the potential pitfalls associated with knowledge editing\nfor LLMs. To achieve this, we introduce new benchmark datasets and propose\ninnovative evaluation metrics. Our results underline two pivotal concerns: (1)\nKnowledge Conflict: Editing groups of facts that logically clash can magnify\nthe inherent inconsistencies in LLMs-a facet neglected by previous methods. (2)\nKnowledge Distortion: Altering parameters with the aim of editing factual\nknowledge can irrevocably warp the innate knowledge structure of LLMs.\nExperimental results vividly demonstrate that knowledge editing might\ninadvertently cast a shadow of unintended consequences on LLMs, which warrant\nattention and efforts for future works. Code is available at\nhttps://github.com/zjunlp/PitfallsKnowledgeEditing.\n","authors":["Zhoubo Li","Ningyu Zhang","Yunzhi Yao","Mengru Wang","Xi Chen","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2310.02129v2.pdf","comment":"Work in progress, add more experiments"},{"id":"http://arxiv.org/abs/2311.12735v1","updated":"2023-11-21T17:21:15Z","published":"2023-11-21T17:21:15Z","title":"LowResource at BLP-2023 Task 2: Leveraging BanglaBert for Low Resource\n  Sentiment Analysis of Bangla Language","summary":"  This paper describes the system of the LowResource Team for Task 2 of\nBLP-2023, which involves conducting sentiment analysis on a dataset composed of\npublic posts and comments from diverse social media platforms. Our primary aim\nis to utilize BanglaBert, a BERT model pre-trained on a large Bangla corpus,\nusing various strategies including fine-tuning, dropping random tokens, and\nusing several external datasets. Our final model is an ensemble of the three\nbest BanglaBert variations. Our system has achieved overall 3rd in the Test Set\namong 30 participating teams with a score of 0.718. Additionally, we discuss\nthe promising systems that didn't perform well namely task-adaptive pertaining\nand paraphrasing using BanglaT5. Training codes and external datasets which are\nused for our system are publicly available at\nhttps://github.com/Aunabil4602/bnlp-workshop-task2-2023\n","authors":["Aunabil Chakma","Masum Hasan"],"pdf_url":"https://arxiv.org/pdf/2311.12735v1.pdf","comment":"Accepted at BLP Workshop @EMNLP2023"},{"id":"http://arxiv.org/abs/2311.12727v1","updated":"2023-11-21T17:03:21Z","published":"2023-11-21T17:03:21Z","title":"Soft Random Sampling: A Theoretical and Empirical Analysis","summary":"  Soft random sampling (SRS) is a simple yet effective approach for efficient\ntraining of large-scale deep neural networks when dealing with massive data.\nSRS selects a subset uniformly at random with replacement from the full data\nset in each epoch. In this paper, we conduct a theoretical and empirical\nanalysis of SRS. First, we analyze its sampling dynamics including data\ncoverage and occupancy. Next, we investigate its convergence with non-convex\nobjective functions and give the convergence rate. Finally, we provide its\ngeneralization performance. We empirically evaluate SRS for image recognition\non CIFAR10 and automatic speech recognition on Librispeech and an in-house\npayload dataset to demonstrate its effectiveness. Compared to existing\ncoreset-based data selection methods, SRS offers a better accuracy-efficiency\ntrade-off. Especially on real-world industrial scale data sets, it is shown to\nbe a powerful training strategy with significant speedup and competitive\nperformance with almost no additional computing cost.\n","authors":["Xiaodong Cui","Ashish Mittal","Songtao Lu","Wei Zhang","George Saon","Brian Kingsbury"],"pdf_url":"https://arxiv.org/pdf/2311.12727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.10852v6","updated":"2023-11-21T16:36:43Z","published":"2022-05-22T15:30:18Z","title":"Relphormer: Relational Graph Transformer for Knowledge Graph\n  Representations","summary":"  Transformers have achieved remarkable performance in widespread fields,\nincluding natural language processing, computer vision and graph mining.\nHowever, vanilla Transformer architectures have not yielded promising\nimprovements in the Knowledge Graph (KG) representations, where the\ntranslational distance paradigm dominates this area. Note that vanilla\nTransformer architectures struggle to capture the intrinsically heterogeneous\nstructural and semantic information of knowledge graphs. To this end, we\npropose a new variant of Transformer for knowledge graph representations dubbed\nRelphormer. Specifically, we introduce Triple2Seq which can dynamically sample\ncontextualized sub-graph sequences as the input to alleviate the heterogeneity\nissue. We propose a novel structure-enhanced self-attention mechanism to encode\nthe relational information and keep the semantic information within entities\nand relations. Moreover, we utilize masked knowledge modeling for general\nknowledge graph representation learning, which can be applied to various\nKG-based tasks including knowledge graph completion, question answering, and\nrecommendation. Experimental results on six datasets show that Relphormer can\nobtain better performance compared with baselines. Code is available in\nhttps://github.com/zjunlp/Relphormer.\n","authors":["Zhen Bi","Siyuan Cheng","Jing Chen","Xiaozhuan Liang","Feiyu Xiong","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.10852v6.pdf","comment":"Neurocomputing 2023"},{"id":"http://arxiv.org/abs/2306.17103v3","updated":"2023-11-21T16:32:41Z","published":"2023-06-29T17:01:51Z","title":"LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by\n  Whispering to ChatGPT","summary":"  We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic\nlyrics transcription method achieving state-of-the-art performance on various\nlyrics transcription datasets, even in challenging genres such as rock and\nmetal. Our novel, training-free approach utilizes Whisper, a weakly supervised\nrobust speech recognition model, and GPT-4, today's most performant chat-based\nlarge language model. In the proposed method, Whisper functions as the \"ear\" by\ntranscribing the audio, while GPT-4 serves as the \"brain,\" acting as an\nannotator with a strong performance for contextualized output selection and\ncorrection. Our experiments show that LyricWhiz significantly reduces Word\nError Rate compared to existing methods in English and can effectively\ntranscribe lyrics across multiple languages. Furthermore, we use LyricWhiz to\ncreate the first publicly available, large-scale, multilingual lyrics\ntranscription dataset with a CC-BY-NC-SA copyright license, based on\nMTG-Jamendo, and offer a human-annotated subset for noise level estimation and\nevaluation. We anticipate that our proposed method and dataset will advance the\ndevelopment of multilingual lyrics transcription, a challenging and emerging\ntask.\n","authors":["Le Zhuo","Ruibin Yuan","Jiahao Pan","Yinghao Ma","Yizhi LI","Ge Zhang","Si Liu","Roger Dannenberg","Jie Fu","Chenghua Lin","Emmanouil Benetos","Wenhu Chen","Wei Xue","Yike Guo"],"pdf_url":"https://arxiv.org/pdf/2306.17103v3.pdf","comment":"9 pages, 2 figures, 5 tables, accepted by ISMIR 2023"},{"id":"http://arxiv.org/abs/2311.12707v1","updated":"2023-11-21T16:20:49Z","published":"2023-11-21T16:20:49Z","title":"Keeping Users Engaged During Repeated Administration of the Same\n  Questionnaire: Using Large Language Models to Reliably Diversify Questions","summary":"  Standardized, validated questionnaires are vital tools in HCI research and\nhealthcare, offering dependable self-report data. However, their repeated use\nin longitudinal or pre-post studies can induce respondent fatigue, impacting\ndata quality via response biases and decreased response rates. We propose\nutilizing large language models (LLMs) to generate diverse questionnaire\nversions while retaining good psychometric properties. In a longitudinal study,\nparticipants engaged with our agent system and responded daily for two weeks to\neither a standardized depression questionnaire or one of two LLM-generated\nquestionnaire variants, alongside a validated depression questionnaire.\nPsychometric testing revealed consistent covariation between the external\ncriterion and the focal measure administered across the three conditions,\ndemonstrating the reliability and validity of the LLM-generated variants.\nParticipants found the repeated administration of the standardized\nquestionnaire significantly more repetitive compared to the variants. Our\nfindings highlight the potential of LLM-generated variants to invigorate\nquestionnaires, fostering engagement and interest without compromising\nvalidity.\n","authors":["Hye Sun Yun","Mehdi Arjmand","Phillip Raymond Sherlock","Michael Paasche-Orlow","James W. Griffith","Timothy Bickmore"],"pdf_url":"https://arxiv.org/pdf/2311.12707v1.pdf","comment":"22 pages, preprint"},{"id":"http://arxiv.org/abs/2311.12699v1","updated":"2023-11-21T16:03:51Z","published":"2023-11-21T16:03:51Z","title":"Can Large Language Models Understand Content and Propagation for\n  Misinformation Detection: An Empirical Study","summary":"  Large Language Models (LLMs) have garnered significant attention for their\npowerful ability in natural language understanding and reasoning. In this\npaper, we present a comprehensive empirical study to explore the performance of\nLLMs on misinformation detection tasks. This study stands as the pioneering\ninvestigation into the understanding capabilities of multiple LLMs regarding\nboth content and propagation across social media platforms. Our empirical\nstudies on five misinformation detection datasets show that LLMs with diverse\nprompts achieve comparable performance in text-based misinformation detection\nbut exhibit notably constrained capabilities in comprehending propagation\nstructure compared to existing models in propagation-based misinformation\ndetection. Besides, we further design four instruction-tuned strategies to\nenhance LLMs for both content and propagation-based misinformation detection.\nThese strategies boost LLMs to actively learn effective features from multiple\ninstances or hard instances, and eliminate irrelevant propagation structures,\nthereby achieving better detection performance. Extensive experiments further\ndemonstrate LLMs would play a better capacity in content and propagation\nstructure under these proposed strategies and achieve promising detection\nperformance. These findings highlight the potential ability of LLMs to detect\nmisinformation.\n","authors":["Mengyang Chen","Lingwei Wei","Han Cao","Wei Zhou","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2311.12699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12689v1","updated":"2023-11-21T15:51:06Z","published":"2023-11-21T15:51:06Z","title":"Fair Text Classification with Wasserstein Independence","summary":"  Group fairness is a central research topic in text classification, where\nreaching fair treatment between sensitive groups (e.g. women vs. men) remains\nan open challenge. This paper presents a novel method for mitigating biases in\nneural text classification, agnostic to the model architecture. Considering the\ndifficulty to distinguish fair from unfair information in a text encoder, we\ntake inspiration from adversarial training to induce Wasserstein independence\nbetween representations learned to predict our target label and the ones\nlearned to predict some sensitive attribute. Our approach provides two\nsignificant advantages. Firstly, it does not require annotations of sensitive\nattributes in both testing and training data. This is more suitable for\nreal-life scenarios compared to existing methods that require annotations of\nsensitive attributes at train time. Second, our approach exhibits a comparable\nor better fairness-accuracy trade-off compared to existing methods.\n","authors":["Thibaud Leteno","Antoine Gourru","Charlotte Laclau","Rémi Emonet","Christophe Gravier"],"pdf_url":"https://arxiv.org/pdf/2311.12689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.12311v3","updated":"2023-11-21T15:40:54Z","published":"2020-12-22T19:32:52Z","title":"Influencer Videos: Unboxing the Mystique","summary":"  Influencer marketing has become a very popular tool to reach customers.\nDespite the rapid growth in influencer videos, there has been little research\non the effectiveness of their constituent features in explaining video\nengagement. We study YouTube influencers and analyze their unstructured video\ndata across text, audio and images using an \"interpretable deep learning\"\nframework that accomplishes both goals of prediction and interpretation. Our\nprediction-based approach analyzes unstructured data and finds that \"what is\nsaid\" in words (text) is more influential than \"how it is said\" in imagery\n(images) or acoustics (audio). Our novel interpretation-based approach is\nimplemented after completion of model prediction by analyzing the same source\nof unstructured data to measure importance attributed to the video features. We\neliminate several spurious relationships in two steps, identifying a subset of\nrelationships which are confirmed using theory. We uncover novel findings that\nestablish distinct associations for measures of shallow and deep engagement\nbased on the dual-system framework of human thinking. Our approach is validated\nusing simulated data, and we discuss the learnings from our findings for\ninfluencers and brands.\n","authors":["Prashant Rajaram","Puneet Manchanda"],"pdf_url":"https://arxiv.org/pdf/2012.12311v3.pdf","comment":"45 pages, Online Appendix"},{"id":"http://arxiv.org/abs/2311.12664v1","updated":"2023-11-21T15:14:54Z","published":"2023-11-21T15:14:54Z","title":"The DURel Annotation Tool: Human and Computational Measurement of\n  Semantic Proximity, Sense Clusters and Semantic Change","summary":"  We present the DURel tool that implements the annotation of semantic\nproximity between uses of words into an online, open source interface. The tool\nsupports standardized human annotation as well as computational annotation,\nbuilding on recent advances with Word-in-Context models. Annotator judgments\nare clustered with automatic graph clustering techniques and visualized for\nanalysis. This allows to measure word senses with simple and intuitive\nmicro-task judgments between use pairs, requiring minimal preparation efforts.\nThe tool offers additional functionalities to compare the agreement between\nannotators to guarantee the inter-subjectivity of the obtained judgments and to\ncalculate summary statistics giving insights into sense frequency\ndistributions, semantic variation or changes of senses over time.\n","authors":["Dominik Schlechtweg","Shafqat Mumtaz Virk","Pauline Sander","Emma Sköldberg","Lukas Theuer Linke","Tuo Zhang","Nina Tahmasebi","Jonas Kuhn","Sabine Schulte im Walde"],"pdf_url":"https://arxiv.org/pdf/2311.12664v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2311.12649v1","updated":"2023-11-21T14:49:00Z","published":"2023-11-21T14:49:00Z","title":"MathGloss: Building mathematical glossaries from text","summary":"  MathGloss is a project to create a knowledge graph (KG) for undergraduate\nmathematics from text, automatically, using modern natural language processing\n(NLP) tools and resources already available on the web. MathGloss is a linked\ndatabase of undergraduate concepts in mathematics. So far, it combines five\nresources: (i) Wikidata, a collaboratively edited, multilingual knowledge graph\nhosted by the Wikimedia Foundation, (ii) terms covered in mathematics courses\nat the University of Chicago, (iii) the syllabus of the French undergraduate\nmathematics curriculum which includes hyperlinks to the automated theorem\nprover Lean 4, (iv) MuLiMa, a multilingual dictionary of mathematics curated by\nmathematicians, and (v) the nLab, a wiki for category theory also curated by\nmathematicians. MathGloss's goal is to bring together resources for learning\nmathematics and to allow every mathematician to tailor their learning to their\nown preferences. Moreover, by organizing different resources for learning\nundergraduate mathematics alongside those for learning formal mathematics, we\nhope to make it easier for mathematicians and formal tools (theorem provers,\ncomputer algebra systems, etc) experts to \"understand\" each other and break\ndown some of the barriers to formal math.\n","authors":["Lucy Horowitz","Valeria de Paiva"],"pdf_url":"https://arxiv.org/pdf/2311.12649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.01446v3","updated":"2023-11-21T14:02:33Z","published":"2023-09-04T08:54:20Z","title":"Open Sesame! Universal Black Box Jailbreaking of Large Language Models","summary":"  Large language models (LLMs), designed to provide helpful and safe responses,\noften rely on alignment techniques to align with user intent and social\nguidelines. Unfortunately, this alignment can be exploited by malicious actors\nseeking to manipulate an LLM's outputs for unintended purposes. In this paper\nwe introduce a novel approach that employs a genetic algorithm (GA) to\nmanipulate LLMs when model architecture and parameters are inaccessible. The GA\nattack works by optimizing a universal adversarial prompt that -- when combined\nwith a user's query -- disrupts the attacked model's alignment, resulting in\nunintended and potentially harmful outputs. Our novel approach systematically\nreveals a model's limitations and vulnerabilities by uncovering instances where\nits responses deviate from expected behavior. Through extensive experiments we\ndemonstrate the efficacy of our technique, thus contributing to the ongoing\ndiscussion on responsible AI development by providing a diagnostic tool for\nevaluating and enhancing alignment of LLMs with human intent. To our knowledge\nthis is the first automated universal black box jailbreak attack.\n","authors":["Raz Lapid","Ron Langberg","Moshe Sipper"],"pdf_url":"https://arxiv.org/pdf/2309.01446v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12574v1","updated":"2023-11-21T12:40:01Z","published":"2023-11-21T12:40:01Z","title":"IMGTB: A Framework for Machine-Generated Text Detection Benchmarking","summary":"  In the era of large language models generating high quality texts, it is a\nnecessity to develop methods for detection of machine-generated text to avoid\nharmful use or simply due to annotation purposes. It is, however, also\nimportant to properly evaluate and compare such developed methods. Recently, a\nfew benchmarks have been proposed for this purpose; however, integration of\nnewest detection methods is rather challenging, since new methods appear each\nmonth and provide slightly different evaluation pipelines. In this paper, we\npresent the IMGTB framework, which simplifies the benchmarking of\nmachine-generated text detection methods by easy integration of custom (new)\nmethods and evaluation datasets. Its configurability and flexibility makes\nresearch and development of new detection methods easier, especially their\ncomparison to the existing state-of-the-art detectors. The default set of\nanalyses, metrics and visualizations offered by the tool follows the\nestablished practices of machine-generated text detection benchmarking found in\nstate-of-the-art literature.\n","authors":["Michal Spiegel","Dominik Macko"],"pdf_url":"https://arxiv.org/pdf/2311.12574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12538v1","updated":"2023-11-21T11:33:03Z","published":"2023-11-21T11:33:03Z","title":"In-Context Learning Functions with Varying Number of Minima","summary":"  Large Language Models (LLMs) have proven effective at In-Context Learning\n(ICL), an ability that allows them to create predictors from labeled examples.\nFew studies have explored the interplay between ICL and specific properties of\nfunctions it attempts to approximate. In our study, we use a formal framework\nto explore ICL and propose a new task of approximating functions with varying\nnumber of minima. We implement a method that allows for producing functions\nwith given inputs as minima. We find that increasing the number of minima\ndegrades ICL performance. At the same time, our evaluation shows that ICL\noutperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster\nthan 2NN in all settings. We validate the findings through a set of few-shot\nexperiments across various hyperparameter configurations.\n","authors":["David Oniani","Yanshan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12537v1","updated":"2023-11-21T11:32:23Z","published":"2023-11-21T11:32:23Z","title":"Oasis: Data Curation and Assessment System for Pretraining of Large\n  Language Models","summary":"  Data is one of the most critical elements in building a large language model.\nHowever, existing systems either fail to customize a corpus curation pipeline\nor neglect to leverage comprehensive corpus assessment for iterative\noptimization of the curation. To this end, we present a pretraining corpus\ncuration and assessment platform called Oasis -- a one-stop system for data\nquality improvement and quantification with user-friendly interactive\ninterfaces. Specifically, the interactive modular rule filter module can devise\ncustomized rules according to explicit feedback. The debiased neural filter\nmodule builds the quality classification dataset in a negative-centric manner\nto remove the undesired bias. The adaptive document deduplication module could\nexecute large-scale deduplication with limited memory resources. These three\nparts constitute the customized data curation module. And in the holistic data\nassessment module, a corpus can be assessed in local and global views, with\nthree evaluation means including human, GPT-4, and heuristic metrics. We\nexhibit a complete process to use Oasis for the curation and assessment of\npretraining data. In addition, an 800GB bilingual corpus curated by Oasis is\npublicly released.\n","authors":["Tong Zhou","Yubo Chen","Pengfei Cao","Kang Liu","Jun Zhao","Shengping Liu"],"pdf_url":"https://arxiv.org/pdf/2311.12537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.05140v2","updated":"2023-11-21T11:28:24Z","published":"2023-10-08T12:21:24Z","title":"Harnessing the Power of Large Language Models for Empathetic Response\n  Generation: Empirical Investigations and Improvements","summary":"  Empathetic dialogue is an indispensable part of building harmonious social\nrelationships and contributes to the development of a helpful AI. Previous\napproaches are mainly based on fine small-scale language models. With the\nadvent of ChatGPT, the application effect of large language models (LLMs) in\nthis field has attracted great attention. This work empirically investigates\nthe performance of LLMs in generating empathetic responses and proposes three\nimprovement methods of semantically similar in-context learning, two-stage\ninteractive generation, and combination with the knowledge base. Extensive\nexperiments show that LLMs can significantly benefit from our proposed methods\nand is able to achieve state-of-the-art performance in both automatic and human\nevaluations. Additionally, we explore the possibility of GPT-4 simulating human\nevaluators.\n","authors":["Yushan Qian","Wei-Nan Zhang","Ting Liu"],"pdf_url":"https://arxiv.org/pdf/2310.05140v2.pdf","comment":"the Findings of EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.12534v1","updated":"2023-11-21T11:26:26Z","published":"2023-11-21T11:26:26Z","title":"Evaluation Metrics of Language Generation Models for Synthetic Traffic\n  Generation Tasks","summary":"  Many Natural Language Generation (NLG) tasks aim to generate a single output\ntext given an input prompt. Other settings require the generation of multiple\ntexts, e.g., for Synthetic Traffic Generation (STG). This generation task is\ncrucial for training and evaluating QA systems as well as conversational\nagents, where the goal is to generate multiple questions or utterances\nresembling the linguistic variability of real users. In this paper, we show\nthat common NLG metrics, like BLEU, are not suitable for evaluating STG. We\npropose and evaluate several metrics designed to compare the generated traffic\nto the distribution of real user texts. We validate our metrics with an\nautomatic procedure to verify whether they capture different types of quality\nissues of generated data; we also run human annotations to verify the\ncorrelation with human judgements. Experiments on three tasks, i.e., Shopping\nUtterance Generation, Product Question Generation and Query Auto Completion,\ndemonstrate that our metrics are effective for evaluating STG tasks, and\nimprove the agreement with human judgement up to 20% with respect to common NLG\nmetrics. We believe these findings can pave the way towards better solutions\nfor estimating the representativeness of synthetic text data.\n","authors":["Simone Filice","Jason Ingyu Choi","Giuseppe Castellucci","Eugene Agichtein","Oleg Rokhlenko"],"pdf_url":"https://arxiv.org/pdf/2311.12534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18098v3","updated":"2023-11-21T11:01:24Z","published":"2023-05-29T14:07:52Z","title":"BigTranslate: Augmenting Large Language Models with Multilingual\n  Translation Capability over 100 Languages","summary":"  Large language models (LLMs) demonstrate promising translation performance\namong various natural languages. However, many LLMs especially the open-sourced\nones, such as BLOOM and LLaMA, are English-dominant and support only dozens of\nnatural languages, making the potential of LLMs on language translation less\nexplored. In this work, we present BigTranslate which adapts LLaMA that covers\nonly 20 languages and enhances it with multilingual translation capability on\nmore than 100 languages. BigTranslate is built upon LLaMA-13B and it is\noptimized in three steps. First, we continue training LLaMA with massive\nChinese monolingual data. Second, we continue training the model with a\nlarge-scale parallel dataset that covers 102 natural languages. Third, we\ninstruct-tune the foundation model with multilingual translation instructions,\nleading to our BigTranslate model. The preliminary experiments on multilingual\ntranslation show that BigTranslate performs comparably with ChatGPT and Google\nTranslate in many languages and even outperforms ChatGPT in 8 language pairs.\nWe release the BigTranslate model and hope it can advance the research\nprogress.\n","authors":["Wen Yang","Chong Li","Jiajun Zhang","Chengqing Zong"],"pdf_url":"https://arxiv.org/pdf/2305.18098v3.pdf","comment":"16 pages, 4 figures. Our model is available at\n  https://github.com/ZNLP/BigTranslate"},{"id":"http://arxiv.org/abs/2311.12489v1","updated":"2023-11-21T09:59:29Z","published":"2023-11-21T09:59:29Z","title":"Multilingual Word Embeddings for Low-Resource Languages using Anchors\n  and a Chain of Related Languages","summary":"  Very low-resource languages, having only a few million tokens worth of data,\nare not well-supported by multilingual NLP approaches due to poor quality\ncross-lingual word representations. Recent work showed that good cross-lingual\nperformance can be achieved if a source language is related to the low-resource\ntarget language. However, not all language pairs are related. In this paper, we\npropose to build multilingual word embeddings (MWEs) via a novel language\nchain-based approach, that incorporates intermediate related languages to\nbridge the gap between the distant source and target. We build MWEs one\nlanguage at a time by starting from the resource rich source and sequentially\nadding each language in the chain till we reach the target. We extend a\nsemi-joint bilingual approach to multiple languages in order to eliminate the\nmain weakness of previous works, i.e., independently trained monolingual\nembeddings, by anchoring the target language around the multilingual space. We\nevaluate our method on bilingual lexicon induction for 4 language families,\ninvolving 4 very low-resource (<5M tokens) and 4 moderately low-resource (<50M)\ntarget languages, showing improved performance in both categories.\nAdditionally, our analysis reveals the importance of good quality embeddings\nfor intermediate languages as well as the importance of leveraging anchor\npoints from all languages in the multilingual space.\n","authors":["Viktor Hangya","Silvia Severini","Radoslav Ralev","Alexander Fraser","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2311.12489v1.pdf","comment":"Accepted at the MRL 2023 workshop"},{"id":"http://arxiv.org/abs/2310.17940v3","updated":"2023-11-21T09:47:04Z","published":"2023-10-27T07:34:51Z","title":"Unified Segment-to-Segment Framework for Simultaneous Sequence\n  Generation","summary":"  Simultaneous sequence generation is a pivotal task for real-time scenarios,\nsuch as streaming speech recognition, simultaneous machine translation and\nsimultaneous speech translation, where the target sequence is generated while\nreceiving the source sequence. The crux of achieving high-quality generation\nwith low latency lies in identifying the optimal moments for generating,\naccomplished by learning a mapping between the source and target sequences.\nHowever, existing methods often rely on task-specific heuristics for different\nsequence types, limiting the model's capacity to adaptively learn the\nsource-target mapping and hindering the exploration of multi-task learning for\nvarious simultaneous tasks. In this paper, we propose a unified\nsegment-to-segment framework (Seg2Seg) for simultaneous sequence generation,\nwhich learns the mapping in an adaptive and unified manner. During the process\nof simultaneous generation, the model alternates between waiting for a source\nsegment and generating a target segment, making the segment serve as the\nnatural bridge between the source and target. To accomplish this, Seg2Seg\nintroduces a latent segment as the pivot between source to target and explores\nall potential source-target mappings via the proposed expectation training,\nthereby learning the optimal moments for generating. Experiments on multiple\nsimultaneous generation tasks demonstrate that Seg2Seg achieves\nstate-of-the-art performance and exhibits better generality across various\ntasks.\n","authors":["Shaolei Zhang","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2310.17940v3.pdf","comment":"Grammatical errors prevent the article from being indexed. This is\n  not a problem that can be solved by replacing a new version"},{"id":"http://arxiv.org/abs/2311.12480v1","updated":"2023-11-21T09:44:33Z","published":"2023-11-21T09:44:33Z","title":"Speaker-Adapted End-to-End Visual Speech Recognition for Continuous\n  Spanish","summary":"  Different studies have shown the importance of visual cues throughout the\nspeech perception process. In fact, the development of audiovisual approaches\nhas led to advances in the field of speech technologies. However, although\nnoticeable results have recently been achieved, visual speech recognition\nremains an open research problem. It is a task in which, by dispensing with the\nauditory sense, challenges such as visual ambiguities and the complexity of\nmodeling silence must be faced. Nonetheless, some of these challenges can be\nalleviated when the problem is approached from a speaker-dependent perspective.\nThus, this paper studies, using the Spanish LIP-RTVE database, how the\nestimation of specialized end-to-end systems for a specific person could affect\nthe quality of speech recognition. First, different adaptation strategies based\non the fine-tuning technique were proposed. Then, a pre-trained CTC/Attention\narchitecture was used as a baseline throughout our experiments. Our findings\nshowed that a two-step fine-tuning process, where the VSR system is first\nadapted to the task domain, provided significant improvements when the speaker\nadaptation was addressed. Furthermore, results comparable to the current state\nof the art were reached even when only a limited amount of data was available.\n","authors":["David Gimeno-Gómez","Carlos-D. Martínez-Hinarejos"],"pdf_url":"https://arxiv.org/pdf/2311.12480v1.pdf","comment":"Accepted in Proceedings of IberSpeech 2022 (\n  https://www.isca-speech.org/archive/iberspeech_2022/gimenogomez22_iberspeech.html\n  )"},{"id":"http://arxiv.org/abs/2311.12475v1","updated":"2023-11-21T09:37:42Z","published":"2023-11-21T09:37:42Z","title":"PhayaThaiBERT: Enhancing a Pretrained Thai Language Model with\n  Unassimilated Loanwords","summary":"  While WangchanBERTa has become the de facto standard in transformer-based\nThai language modeling, it still has shortcomings in regard to the\nunderstanding of foreign words, most notably English words, which are often\nborrowed without orthographic assimilation into Thai in many contexts. We\nidentify the lack of foreign vocabulary in WangchanBERTa's tokenizer as the\nmain source of these shortcomings. We then expand WangchanBERTa's vocabulary\nvia vocabulary transfer from XLM-R's pretrained tokenizer and pretrain a new\nmodel using the expanded tokenizer, starting from WangchanBERTa's checkpoint,\non a new dataset that is larger than the one used to train WangchanBERTa. Our\nresults show that our new pretrained model, PhayaThaiBERT, outperforms\nWangchanBERTa in many downstream tasks and datasets.\n","authors":["Panyut Sriwirote","Jalinee Thapiang","Vasan Timtong","Attapol T. Rutherford"],"pdf_url":"https://arxiv.org/pdf/2311.12475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12474v1","updated":"2023-11-21T09:36:11Z","published":"2023-11-21T09:36:11Z","title":"CSMeD: Bridging the Dataset Gap in Automated Citation Screening for\n  Systematic Literature Reviews","summary":"  Systematic literature reviews (SLRs) play an essential role in summarising,\nsynthesising and validating scientific evidence. In recent years, there has\nbeen a growing interest in using machine learning techniques to automate the\nidentification of relevant studies for SLRs. However, the lack of standardised\nevaluation datasets makes comparing the performance of such automated\nliterature screening systems difficult. In this paper, we analyse the citation\nscreening evaluation datasets, revealing that many of the available datasets\nare either too small, suffer from data leakage or have limited applicability to\nsystems treating automated literature screening as a classification task, as\nopposed to, for example, a retrieval or question-answering task. To address\nthese challenges, we introduce CSMeD, a meta-dataset consolidating nine\npublicly released collections, providing unified access to 325 SLRs from the\nfields of medicine and computer science. CSMeD serves as a comprehensive\nresource for training and evaluating the performance of automated citation\nscreening models. Additionally, we introduce CSMeD-FT, a new dataset designed\nexplicitly for evaluating the full text publication screening task. To\ndemonstrate the utility of CSMeD, we conduct experiments and establish\nbaselines on new datasets.\n","authors":["Wojciech Kusa","Oscar E. Mendoza","Matthias Samwald","Petr Knoth","Allan Hanbury"],"pdf_url":"https://arxiv.org/pdf/2311.12474v1.pdf","comment":"Accepted at NeurIPS 2023 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2311.12468v1","updated":"2023-11-21T09:28:00Z","published":"2023-11-21T09:28:00Z","title":"Analysis of Visual Features for Continuous Lipreading in Spanish","summary":"  During a conversation, our brain is responsible for combining information\nobtained from multiple senses in order to improve our ability to understand the\nmessage we are perceiving. Different studies have shown the importance of\npresenting visual information in these situations. Nevertheless, lipreading is\na complex task whose objective is to interpret speech when audio is not\navailable. By dispensing with a sense as crucial as hearing, it will be\nnecessary to be aware of the challenge that this lack presents. In this paper,\nwe propose an analysis of different speech visual features with the intention\nof identifying which of them is the best approach to capture the nature of lip\nmovements for natural Spanish and, in this way, dealing with the automatic\nvisual speech recognition task. In order to estimate our system, we present an\naudiovisual corpus compiled from a subset of the RTVE database, which has been\nused in the Albayz\\'in evaluations. We employ a traditional system based on\nHidden Markov Models with Gaussian Mixture Models. Results show that, although\nthe task is difficult, in restricted conditions we obtain recognition results\nwhich determine that using eigenlips in combination with deep features is the\nbest visual approach.\n","authors":["David Gimeno-Gómez","Carlos-D. Martínez-Hinarejos"],"pdf_url":"https://arxiv.org/pdf/2311.12468v1.pdf","comment":"Accepted in Proceedings of IberSpeech 2020 (\n  https://www.isca-speech.org/archive/iberspeech_2021/gimenogomez21_iberspeech.html\n  )"},{"id":"http://arxiv.org/abs/2310.18168v3","updated":"2023-11-21T09:19:03Z","published":"2023-10-27T14:27:43Z","title":"Personas as a Way to Model Truthfulness in Language Models","summary":"  Large Language Models (LLMs) are trained on vast amounts of text from the\ninternet, which contains both factual and misleading information about the\nworld. Can language models discern truth from falsehood in this contradicting\ndata? Expanding on the view that LLMs can model different communicative agents,\nwe present the persona hypothesis: LLMs can cluster agents into personas using\ncommon features of their generations. For instance, a truthful persona is a\ngroup of agents that are likely to produce truthful text and that share similar\nfeatures like formal writing styles and scientific references. By modeling this\npersona, LLMs can generalize truthfulness beyond the specific contexts in which\neach agent generated the training text. For example, the model can infer that\nthe agent ``Wikipedia'' will behave truthfully on topics that were only\ngenerated by ``Science'' because they both belong to the truthful persona. We\nshow evidence for the persona hypothesis via two observations: (1) we can probe\nwhether a model's answer will be truthful before it is generated; (2)\nfinetuning a model on a set of facts improves its truthfulness on unseen\ntopics. Next, using arithmetics as a synthetic environment, we show that\nlanguage models can separate true and false statements, and generalize\ntruthfulness across agents; but only if agents in the training data share a\ntruthful generative process that enables the creation of a truthful persona.\nOverall, our findings suggest that models can exploit hierarchical structures\nin the data to learn abstract concepts like truthfulness.\n","authors":["Nitish Joshi","Javier Rando","Abulhair Saparov","Najoung Kim","He He"],"pdf_url":"https://arxiv.org/pdf/2310.18168v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12457v1","updated":"2023-11-21T09:12:21Z","published":"2023-11-21T09:12:21Z","title":"LIP-RTVE: An Audiovisual Database for Continuous Spanish in the Wild","summary":"  Speech is considered as a multi-modal process where hearing and vision are\ntwo fundamentals pillars. In fact, several studies have demonstrated that the\nrobustness of Automatic Speech Recognition systems can be improved when audio\nand visual cues are combined to represent the nature of speech. In addition,\nVisual Speech Recognition, an open research problem whose purpose is to\ninterpret speech by reading the lips of the speaker, has been a focus of\ninterest in the last decades. Nevertheless, in order to estimate these systems\nin the currently Deep Learning era, large-scale databases are required. On the\nother hand, while most of these databases are dedicated to English, other\nlanguages lack sufficient resources. Thus, this paper presents a\nsemi-automatically annotated audiovisual database to deal with unconstrained\nnatural Spanish, providing 13 hours of data extracted from Spanish television.\nFurthermore, baseline results for both speaker-dependent and\nspeaker-independent scenarios are reported using Hidden Markov Models, a\ntraditional paradigm that has been widely used in the field of Speech\nTechnologies.\n","authors":["David Gimeno-Gómez","Carlos-D. Martínez-Hinarejos"],"pdf_url":"https://arxiv.org/pdf/2311.12457v1.pdf","comment":"Accepted in Proceedings of LREC 2022 (\n  https://aclanthology.org/2022.lrec-1.294 )"},{"id":"http://arxiv.org/abs/2311.12420v1","updated":"2023-11-21T08:20:39Z","published":"2023-11-21T08:20:39Z","title":"How Far Have We Gone in Vulnerability Detection Using Large Language\n  Models","summary":"  As software becomes increasingly complex and prone to vulnerabilities,\nautomated vulnerability detection is critically important, yet challenging.\nGiven the significant successes of Large Language Models (LLMs) in various\ntasks, there is growing anticipation of their efficacy in vulnerability\ndetection. However, a quantitative understanding of their potential in\nvulnerability detection is still missing. To bridge this gap, we introduce a\ncomprehensive vulnerability benchmark VulBench. This benchmark aggregates\nhigh-quality data from a wide range of CTF (Capture-the-Flag) challenges and\nreal-world applications, with annotations for each vulnerable function\ndetailing the vulnerability type and its root cause. Through our experiments\nencompassing 16 LLMs and 6 state-of-the-art (SOTA) deep learning-based models\nand static analyzers, we find that several LLMs outperform traditional deep\nlearning approaches in vulnerability detection, revealing an untapped potential\nin LLMs. This work contributes to the understanding and utilization of LLMs for\nenhanced software security.\n","authors":["Zeyu Gao","Hao Wang","Yuchen Zhou","Wenyu Zhu","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12418v1","updated":"2023-11-21T08:15:01Z","published":"2023-11-21T08:15:01Z","title":"Visual Analytics for Generative Transformer Models","summary":"  While transformer-based models have achieved state-of-the-art results in a\nvariety of classification and generation tasks, their black-box nature makes\nthem challenging for interpretability. In this work, we present a novel visual\nanalytical framework to support the analysis of transformer-based generative\nnetworks. In contrast to previous work, which has mainly focused on\nencoder-based models, our framework is one of the first dedicated to supporting\nthe analysis of transformer-based encoder-decoder models and decoder-only\nmodels for generative and classification tasks. Hence, we offer an intuitive\noverview that allows the user to explore different facets of the model through\ninteractive visualization. To demonstrate the feasibility and usefulness of our\nframework, we present three detailed case studies based on real-world NLP\nresearch problems.\n","authors":["Raymond Li","Ruixin Yang","Wen Xiao","Ahmed AbuRaed","Gabriel Murray","Giuseppe Carenini"],"pdf_url":"https://arxiv.org/pdf/2311.12418v1.pdf","comment":"6 pages (reference excluded), 7 figures"},{"id":"http://arxiv.org/abs/2311.12410v1","updated":"2023-11-21T07:56:30Z","published":"2023-11-21T07:56:30Z","title":"nach0: Multimodal Natural and Chemical Languages Foundation Model","summary":"  Large Language Models (LLMs) have substantially driven scientific progress in\nvarious domains, and many papers have demonstrated their ability to tackle\ncomplex problems with creative solutions. Our paper introduces a new foundation\nmodel, nach0, capable of solving various chemical and biological tasks:\nbiomedical question answering, named entity recognition, molecular generation,\nmolecular synthesis, attributes prediction, and others. nach0 is a multi-domain\nand multi-task encoder-decoder LLM pre-trained on unlabeled text from\nscientific literature, patents, and molecule strings to incorporate a range of\nchemical and linguistic knowledge. We employed instruction tuning, where\nspecific task-related instructions are utilized to fine-tune nach0 for the\nfinal set of tasks. To train nach0 effectively, we leverage the NeMo framework,\nenabling efficient parallel optimization of both base and large model versions.\nExtensive experiments demonstrate that our model outperforms state-of-the-art\nbaselines on single-domain and cross-domain tasks. Furthermore, it can generate\nhigh-quality outputs in molecular and textual formats, showcasing its\neffectiveness in multi-domain setups.\n","authors":["Micha Livne","Zulfat Miftahutdinov","Elena Tutubalina","Maksim Kuznetsov","Daniil Polykovskiy","Annika Brundyn","Aastha Jhunjhunwala","Anthony Costa","Alex Aliper","Alex Zhavoronkov"],"pdf_url":"https://arxiv.org/pdf/2311.12410v1.pdf","comment":"Submitted to Nature Communications"},{"id":"http://arxiv.org/abs/2310.07161v2","updated":"2023-11-21T07:54:34Z","published":"2023-10-11T03:19:22Z","title":"Psychoacoustic Challenges Of Speech Enhancement On VoIP Platforms","summary":"  Within the ambit of VoIP (Voice over Internet Protocol) telecommunications,\nthe complexities introduced by acoustic transformations merit rigorous\nanalysis. This research, rooted in the exploration of proprietary sender-side\ndenoising effects, meticulously evaluates platforms such as Google Meets and\nZoom. The study draws upon the Deep Noise Suppression (DNS) 2020 dataset,\nensuring a structured examination tailored to various denoising settings and\nreceiver interfaces. A methodological novelty is introduced via the Oaxaca\ndecomposition, traditionally an econometric tool, repurposed herein to analyze\nacoustic-phonetic perturbations within VoIP systems. To further ground the\nimplications of these transformations, psychoacoustic metrics, specifically\nPESQ and STOI, were harnessed to furnish a comprehensive understanding of\nspeech alterations. Cumulatively, the insights garnered underscore the\nintricate landscape of VoIP-influenced acoustic dynamics. In addition to the\nprimary findings, a multitude of metrics are reported, extending the research\npurview. Moreover, out-of-domain benchmarking for both time and time-frequency\ndomain speech enhancement models is included, thereby enhancing the depth and\napplicability of this inquiry. Repository:\ngithub.com/deepology/VoIP-DNS-Challenge\n","authors":["Joseph Konan","Ojas Bhargave","Shikhar Agnihotri","Shuo Han","Yunyang Zeng","Ankit Shah","Bhiksha Raj"],"pdf_url":"https://arxiv.org/pdf/2310.07161v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12405v1","updated":"2023-11-21T07:50:53Z","published":"2023-11-21T07:50:53Z","title":"IndoRobusta: Towards Robustness Against Diverse Code-Mixed Indonesian\n  Local Languages","summary":"  Significant progress has been made on Indonesian NLP. Nevertheless,\nexploration of the code-mixing phenomenon in Indonesian is limited, despite\nmany languages being frequently mixed with Indonesian in daily conversation. In\nthis work, we explore code-mixing in Indonesian with four embedded languages,\ni.e., English, Sundanese, Javanese, and Malay; and introduce IndoRobusta, a\nframework to evaluate and improve the code-mixing robustness. Our analysis\nshows that the pre-training corpus bias affects the model's ability to better\nhandle Indonesian-English code-mixing when compared to other local languages,\ndespite having higher language diversity.\n","authors":["Muhammad Farid Adilazuarda","Samuel Cahyawijaya","Genta Indra Winata","Pascale Fung","Ayu Purwarianti"],"pdf_url":"https://arxiv.org/pdf/2311.12405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12404v1","updated":"2023-11-21T07:43:50Z","published":"2023-11-21T07:43:50Z","title":"InterPrompt: Interpretable Prompting for Interrelated Interpersonal Risk\n  Factors in Reddit Posts","summary":"  Mental health professionals and clinicians have observed the upsurge of\nmental disorders due to Interpersonal Risk Factors (IRFs). To simulate the\nhuman-in-the-loop triaging scenario for early detection of mental health\ndisorders, we recognized textual indications to ascertain these IRFs : Thwarted\nBelongingness (TBe) and Perceived Burdensomeness (PBu) within personal\nnarratives. In light of this, we use N-shot learning with GPT-3 model on the\nIRF dataset, and underscored the importance of fine-tuning GPT-3 model to\nincorporate the context-specific sensitivity and the interconnectedness of\ntextual cues that represent both IRFs.\n  In this paper, we introduce an Interpretable Prompting (InterPrompt)} method\nto boost the attention mechanism by fine-tuning the GPT-3 model. This allows a\nmore sophisticated level of language modification by adjusting the pre-trained\nweights. Our model learns to detect usual patterns and underlying connections\nacross both the IRFs, which leads to better system-level explainability and\ntrustworthiness. The results of our research demonstrate that all four variants\nof GPT-3 model, when fine-tuned with InterPrompt, perform considerably better\nas compared to the baseline methods, both in terms of classification and\nexplanation generation.\n","authors":["MSVPJ Sathvik","Surjodeep Sarkar","Chandni Saxena","Sunghwan Sohn","Muskan Garg"],"pdf_url":"https://arxiv.org/pdf/2311.12404v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2311.12399v1","updated":"2023-11-21T07:22:48Z","published":"2023-11-21T07:22:48Z","title":"A Survey of Graph Meets Large Language Model: Progress and Future\n  Directions","summary":"  Graph plays a significant role in representing and analyzing complex\nrelationships in real-world applications such as citation networks, social\nnetworks, and biological data. Recently, Large Language Models (LLMs), which\nhave achieved tremendous success in various domains, have also been leveraged\nin graph-related tasks to surpass traditional Graph Neural Networks (GNNs)\nbased methods and yield state-of-the-art performance. In this survey, we first\npresent a comprehensive review and analysis of existing methods that integrate\nLLMs with graphs. First of all, we propose a new taxonomy, which organizes\nexisting methods into three categories based on the role (i.e., enhancer,\npredictor, and alignment component) played by LLMs in graph-related tasks. Then\nwe systematically survey the representative methods along the three categories\nof the taxonomy. Finally, we discuss the remaining limitations of existing\nstudies and highlight promising avenues for future research. The relevant\npapers are summarized and will be consistently updated at:\nhttps://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.\n","authors":["Yuhan Li","Zhixun Li","Peisong Wang","Jia Li","Xiangguo Sun","Hong Cheng","Jeffrey Xu Yu"],"pdf_url":"https://arxiv.org/pdf/2311.12399v1.pdf","comment":"Work in progress; 13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.10777v2","updated":"2023-11-21T07:15:57Z","published":"2023-11-16T06:01:47Z","title":"A Systematic Review of Aspect-based Sentiment Analysis (ABSA): Domains,\n  Methods, and Trends","summary":"  Aspect-based Sentiment Analysis (ABSA) is a type of fine-grained sentiment\nanalysis (SA) that identifies aspects and the associated opinions from a given\ntext. In the digital era, ABSA gained increasing popularity and applications in\nmining opinionated text data to obtain insights and support decisions. ABSA\nresearch employs linguistic, statistical, and machine-learning approaches and\nutilises resources such as labelled datasets, aspect and sentiment lexicons and\nontology. By its nature, ABSA is domain-dependent and can be sensitive to the\nimpact of misalignment between the resource and application domains. However,\nto our knowledge, this topic has not been explored by the existing ABSA\nliterature reviews. In this paper, we present a Systematic Literature Review\n(SLR) of ABSA studies with a focus on the research application domain, dataset\ndomain, and the research methods to examine their relationships and identify\ntrends over time. Our results suggest a number of potential systemic issues in\nthe ABSA research literature, including the predominance of the\n``product/service review'' dataset domain among the majority of studies that\ndid not have a specific research application domain, coupled with the\nprevalence of dataset-reliant methods such as supervised machine learning. This\nreview makes a number of unique contributions to the ABSA research field: 1) To\nour knowledge, it is the first SLR that links the research domain, dataset\ndomain, and research method through a systematic perspective; 2) it is one of\nthe largest scoped SLR on ABSA, with 519 eligible studies filtered from 4191\nsearch results without time constraint; and 3) our review methodology adopted\nan innovative automatic filtering process based on PDF-mining, which enhanced\nscreening quality and reliability. Suggestions and our review limitations are\nalso discussed.\n","authors":["Yan Cathy Hua","Paul Denny","Katerina Taskova","Jörg Wicker"],"pdf_url":"https://arxiv.org/pdf/2311.10777v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12395v1","updated":"2023-11-21T07:11:39Z","published":"2023-11-21T07:11:39Z","title":"Problems of Non-equivalent Words in Technical Translation","summary":"  Translating words which do not have equivalent in target language is not easy\nand finding proper equivalent of those words are very important to render\ncorrectly and understandably, the article defines some thoughts and ideas of\nscientists on the common problems of non-equivalent words from English to\nRussian language and includes English and Russian examples and ideas of certain\nscientist. The English language is worldwide spoken and there are 1.35 billion\nEnglish speakers and over 258 million Russian speakers according to the 2021s\nstatistics. Inevitably, these billions of speakers around the world have\nconnection and they may have deal in different criteria. In order to understand\none another they need to have a pure and fully-understood language. These pure\nlanguages understanding directly relates to translation knowledge where\nlinguists and translators need to work and research to eradicate\nmisunderstanding. Misunderstandings mostly appear in non-equivalent words\nbecause there are different local and internal words like food, garment,\ncultural and traditional words and others in every notion. Truly, most of these\nwords do not have equivalent in the target language and these words need to be\nworked and find their equivalent in the target language to fully understand the\nboth languages. However, some of these non-equivalent words are already\nprofessionally rendered to the target language but still there many other words\nto be rendered. Hence, this research paper includes different ways and rules of\nrendering non-equivalent words from source language to the target language.\n","authors":["Mohammad Ibrahim Qani"],"pdf_url":"https://arxiv.org/pdf/2311.12395v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2311.10770v2","updated":"2023-11-21T06:59:59Z","published":"2023-11-15T18:42:50Z","title":"Exponentially Faster Language Modelling","summary":"  Language models only really need to use an exponential fraction of their\nneurons for individual inferences. As proof, we present UltraFastBERT, a BERT\nvariant that uses 0.3% of its neurons during inference while performing on par\nwith similar BERT models. UltraFastBERT selectively engages just 12 out of 4095\nneurons for each layer inference. This is achieved by replacing feedforward\nnetworks with fast feedforward networks (FFFs). While no truly efficient\nimplementation currently exists to unlock the full acceleration potential of\nconditional neural execution, we provide high-level CPU code achieving 78x\nspeedup over the optimized baseline feedforward implementation, and a PyTorch\nimplementation delivering 40x speedup over the equivalent batched feedforward\ninference. We publish our training code, benchmarking setup, and model weights.\n","authors":["Peter Belcak","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2311.10770v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12375v1","updated":"2023-11-21T06:27:25Z","published":"2023-11-21T06:27:25Z","title":"The Obscure Limitation of Modular Multilingual Language Models","summary":"  We expose the limitation of modular multilingual language models (MLMs) in\nmultilingual inference scenarios with unknown languages. Existing evaluations\nof modular MLMs exclude the involvement of language identification (LID)\nmodules, which obscures the performance of real-case multilingual scenarios of\nmodular MLMs. In this work, we showcase the effect of adding LID on the\nmultilingual evaluation of modular MLMs and provide discussions for closing the\nperformance gap of caused by the pipelined approach of LID and modular MLMs.\n","authors":["Muhammad Farid Adilazuarda","Samuel Cahyawijaya","Ayu Purwarianti"],"pdf_url":"https://arxiv.org/pdf/2311.12375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12373v1","updated":"2023-11-21T06:23:38Z","published":"2023-11-21T06:23:38Z","title":"Beyond Turing: A Comparative Analysis of Approaches for Detecting\n  Machine-Generated Text","summary":"  Significant progress has been made on text generation by pre-trained language\nmodels (PLMs), yet distinguishing between human and machine-generated text\nposes an escalating challenge. This paper offers an in-depth evaluation of\nthree distinct methods used to address this task: traditional shallow learning,\nLanguage Model (LM) fine-tuning, and Multilingual Model fine-tuning. These\napproaches are rigorously tested on a wide range of machine-generated texts,\nproviding a benchmark of their competence in distinguishing between\nhuman-authored and machine-authored linguistic constructs. The results reveal\nconsiderable differences in performance across methods, thus emphasizing the\ncontinued need for advancement in this crucial area of NLP. This study offers\nvaluable insights and paves the way for future research aimed at creating\nrobust and highly discriminative models.\n","authors":["Muhammad Farid Adilazuarda","Nikolaos Nektarios Arkoulis","Oleksii Chumakov"],"pdf_url":"https://arxiv.org/pdf/2311.12373v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12355v1","updated":"2023-11-21T05:15:56Z","published":"2023-11-21T05:15:56Z","title":"Utilizing Language Models for Tour Itinerary Recommendation","summary":"  Tour itinerary recommendation involves planning a sequence of relevant\nPoint-of-Interest (POIs), which combines challenges from the fields of both\nOperations Research (OR) and Recommendation Systems (RS). As an OR problem,\nthere is the need to maximize a certain utility (e.g., popularity of POIs in\nthe tour) while adhering to some constraints (e.g., maximum time for the tour).\nAs a RS problem, it is heavily related to problem or filtering or ranking a\nsubset of POIs that are relevant to a user and recommending it as part of an\nitinerary. In this paper, we explore the use of language models for the task of\ntour itinerary recommendation and planning. This task has the unique\nrequirement of recommending personalized POIs relevant to users and planning\nthese POIs as an itinerary that satisfies various constraints. We discuss some\napproaches in this area, such as using word embedding techniques like Word2Vec\nand GloVe for learning POI embeddings and transformer-based techniques like\nBERT for generating\n  itineraries.\n","authors":["Ngai Lam Ho","Kwan Hui Lim"],"pdf_url":"https://arxiv.org/pdf/2311.12355v1.pdf","comment":"PMAI23 @IJCAI 2023 2nd International Workshop on Process Management\n  in the AI era"},{"id":"http://arxiv.org/abs/2309.17453v2","updated":"2023-11-21T05:04:49Z","published":"2023-09-29T17:59:56Z","title":"Efficient Streaming Language Models with Attention Sinks","summary":"  Deploying Large Language Models (LLMs) in streaming applications such as\nmulti-round dialogue, where long interactions are expected, is urgently needed\nbut poses two major challenges. Firstly, during the decoding stage, caching\nprevious tokens' Key and Value states (KV) consumes extensive memory. Secondly,\npopular LLMs cannot generalize to longer texts than the training sequence\nlength. Window attention, where only the most recent KVs are cached, is a\nnatural approach -- but we show that it fails when the text length surpasses\nthe cache size. We observe an interesting phenomenon, namely attention sink,\nthat keeping the KV of initial tokens will largely recover the performance of\nwindow attention. In this paper, we first demonstrate that the emergence of\nattention sink is due to the strong attention scores towards initial tokens as\na ``sink'' even if they are not semantically important. Based on the above\nanalysis, we introduce StreamingLLM, an efficient framework that enables LLMs\ntrained with a finite length attention window to generalize to infinite\nsequence lengths without any fine-tuning. We show that StreamingLLM can enable\nLlama-2, MPT, Falcon, and Pythia to perform stable and efficient language\nmodeling with up to 4 million tokens and more. In addition, we discover that\nadding a placeholder token as a dedicated attention sink during pre-training\ncan further improve streaming deployment. In streaming settings, StreamingLLM\noutperforms the sliding window recomputation baseline by up to 22.2x speedup.\nCode and datasets are provided at https://github.com/mit-han-lab/streaming-llm.\n","authors":["Guangxuan Xiao","Yuandong Tian","Beidi Chen","Song Han","Mike Lewis"],"pdf_url":"https://arxiv.org/pdf/2309.17453v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12351v1","updated":"2023-11-21T04:59:17Z","published":"2023-11-21T04:59:17Z","title":"Advancing Transformer Architecture in Long-Context Large Language\n  Models: A Comprehensive Survey","summary":"  With the bomb ignited by ChatGPT, Transformer-based Large Language Models\n(LLMs) have paved a revolutionary path toward Artificial General Intelligence\n(AGI) and have been applied in diverse areas as knowledge bases, human\ninterfaces, and dynamic agents. However, a prevailing limitation exists: many\ncurrent LLMs, constrained by resources, are primarily pre-trained on shorter\ntexts, rendering them less effective for longer-context prompts, commonly\nencountered in real-world settings. In this paper, we present a comprehensive\nsurvey focusing on the advancement of model architecture in Transformer-based\nLLMs to optimize long-context capabilities across all stages from pre-training\nto inference. We firstly delineate and analyze the problems of handling\nlong-context input and output with the current Transformer-based models. Then,\nwe mainly offer a holistic taxonomy to navigate the landscape of Transformer\nupgrades on architecture to solve these problems. Afterward, we provide the\ninvestigation on wildly used evaluation necessities tailored for long-context\nLLMs, including datasets, metrics, and baseline models, as well as some amazing\noptimization toolkits like libraries, systems, and compilers to augment LLMs'\nefficiency and efficacy across different stages. Finally, we further discuss\nthe predominant challenges and potential avenues for future research in this\ndomain. Additionally, we have established a repository where we curate relevant\nliterature with real-time updates at\nhttps://github.com/Strivin0311/long-llms-learning.\n","authors":["Yunpeng Huang","Jingwei Xu","Zixu Jiang","Junyu Lai","Zenan Li","Yuan Yao","Taolue Chen","Lijuan Yang","Zhou Xin","Xiaoxing Ma"],"pdf_url":"https://arxiv.org/pdf/2311.12351v1.pdf","comment":"35 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.12337v1","updated":"2023-11-21T04:06:08Z","published":"2023-11-21T04:06:08Z","title":"Do Smaller Language Models Answer Contextualised Questions Through\n  Memorisation Or Generalisation?","summary":"  A distinction is often drawn between a model's ability to predict a label for\nan evaluation sample that is directly memorised from highly similar training\nsamples versus an ability to predict the label via some method of\ngeneralisation. In the context of using Language Models for question-answering,\ndiscussion continues to occur as to the extent to which questions are answered\nthrough memorisation. We consider this issue for questions that would ideally\nbe answered through reasoning over an associated context. We propose a method\nof identifying evaluation samples for which it is very unlikely our model would\nhave memorised the answers. Our method is based on semantic similarity of input\ntokens and label tokens between training and evaluation samples. We show that\nour method offers advantages upon some prior approaches in that it is able to\nsurface evaluation-train pairs that have overlap in either contiguous or\ndiscontiguous sequences of tokens. We use this method to identify unmemorisable\nsubsets of our evaluation datasets. We train two Language Models in a multitask\nfashion whereby the second model differs from the first only in that it has two\nadditional datasets added to the training regime that are designed to impart\nsimple numerical reasoning strategies of a sort known to improve performance on\nsome of our evaluation datasets but not on others. We then show that there is\nperformance improvement between the two models on the unmemorisable subsets of\nthe evaluation datasets that were expected to benefit from the additional\ntraining datasets. Specifically, performance on unmemorisable subsets of two of\nour evaluation datasets, DROP and ROPES significantly improves by 9.0%, and\n25.7% respectively while other evaluation datasets have no significant change\nin performance.\n","authors":["Tim Hartill","Joshua Bensemann","Michael Witbrock","Patricia J. Riddle"],"pdf_url":"https://arxiv.org/pdf/2311.12337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12323v1","updated":"2023-11-21T03:34:20Z","published":"2023-11-21T03:34:20Z","title":"Modeling Political Orientation of Social Media Posts: An Extended\n  Analysis","summary":"  Developing machine learning models to characterize political polarization on\nonline social media presents significant challenges. These challenges mainly\nstem from various factors such as the lack of annotated data, presence of noise\nin social media datasets, and the sheer volume of data. The common research\npractice typically examines the biased structure of online user communities for\na given topic or qualitatively measuring the impacts of polarized topics on\nsocial media. However, there is limited work focusing on analyzing polarization\nat the ground-level, specifically in the social media posts themselves. Such\nexisting analysis heavily relies on annotated data, which often requires\nlaborious human labeling, offers labels only to specific problems, and lacks\nthe ability to determine the near-future bias state of a social media\nconversations. Understanding the degree of political orientation conveyed in\nsocial media posts is crucial for quantifying the bias of online user\ncommunities and investigating the spread of polarized content. In this work, we\nfirst introduce two heuristic methods that leverage on news media bias and post\ncontent to label social media posts. Next, we compare the efficacy and quality\nof heuristically labeled dataset with a randomly sampled human-annotated\ndataset. Additionally, we demonstrate that current machine learning models can\nexhibit improved performance in predicting political orientation of social\nmedia posts, employing both traditional supervised learning and few-shot\nlearning setups. We conduct experiments using the proposed heuristic methods\nand machine learning approaches to predict the political orientation of posts\ncollected from two social media forums with diverse political ideologies: Gab\nand Twitter.\n","authors":["Sadia Kamal","Brenner Little","Jade Gullic","Trevor Harms","Kristin Olofsson","Arunkumar Bagavathi"],"pdf_url":"https://arxiv.org/pdf/2311.12323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12315v1","updated":"2023-11-21T03:17:14Z","published":"2023-11-21T03:17:14Z","title":"AcademicGPT: Empowering Academic Research","summary":"  Large Language Models (LLMs) have demonstrated exceptional capabilities\nacross various natural language processing tasks. Yet, many of these advanced\nLLMs are tailored for broad, general-purpose applications. In this technical\nreport, we introduce AcademicGPT, designed specifically to empower academic\nresearch. AcademicGPT is a continual training model derived from LLaMA2-70B.\nOur training corpus mainly consists of academic papers, thesis, content from\nsome academic domain, high-quality Chinese data and others. While it may not be\nextensive in data scale, AcademicGPT marks our initial venture into a\ndomain-specific GPT tailored for research area. We evaluate AcademicGPT on\nseveral established public benchmarks such as MMLU and CEval, as well as on\nsome specialized academic benchmarks like PubMedQA, SCIEval, and our\nnewly-created ComputerScienceQA, to demonstrate its ability from general\nknowledge ability, to Chinese ability, and to academic ability. Building upon\nAcademicGPT's foundation model, we also developed several applications catered\nto the academic area, including General Academic Question Answering,\nAI-assisted Paper Reading, Paper Review, and AI-assisted Title and Abstract\nGeneration.\n","authors":["Shufa Wei","Xiaolong Xu","Xianbiao Qi","Xi Yin","Jun Xia","Jingyi Ren","Peijun Tang","Yuxiang Zhong","Yihao Chen","Xiaoqin Ren","Yuxin Liang","Liankai Huang","Kai Xie","Weikang Gui","Wei Tan","Shuanglong Sun","Yongquan Hu","Qinxian Liu","Nanjin Li","Chihao Dai","Lihua Wang","Xiaohui Liu","Lei Zhang","Yutao Xie"],"pdf_url":"https://arxiv.org/pdf/2311.12315v1.pdf","comment":"Technical Report. arXiv admin note: text overlap with\n  arXiv:2310.12081, arXiv:2310.10053 by other authors"},{"id":"http://arxiv.org/abs/2304.03898v2","updated":"2023-11-21T02:39:06Z","published":"2023-04-08T03:24:05Z","title":"The Short Text Matching Model Enhanced with Knowledge via Contrastive\n  Learning","summary":"  In recent years, short Text Matching tasks have been widely applied in the\nfields ofadvertising search and recommendation. The difficulty lies in the lack\nof semantic information and word ambiguity caused by the short length of the\ntext. Previous works have introduced complement sentences or knowledge bases to\nprovide additional feature information. However, these methods have not fully\ninteracted between the original sentence and the complement sentence, and have\nnot considered the noise issue that may arise from the introduction of external\nknowledge bases. Therefore, this paper proposes a short Text Matching model\nthat combines contrastive learning and external knowledge. The model uses a\ngenerative model to generate corresponding complement sentences and uses the\ncontrastive learning method to guide the model to obtain more semantically\nmeaningful encoding of the original sentence. In addition, to avoid noise, we\nuse keywords as the main semantics of the original sentence to retrieve\ncorresponding knowledge words in the knowledge base, and construct a knowledge\ngraph. The graph encoding model is used to integrate the knowledge base\ninformation into the model. Our designed model achieves state-of-the-art\nperformance on two publicly available Chinese Text Matching datasets,\ndemonstrating the effectiveness of our model.\n","authors":["Ruiqiang Liu","Mengmeng Cui","Hanjie Mai","Qiang Zhang","Shaohua Xu","Xiangzheng Liu","Yanlong Du"],"pdf_url":"https://arxiv.org/pdf/2304.03898v2.pdf","comment":"11 pages,2 figures"},{"id":"http://arxiv.org/abs/2311.12298v1","updated":"2023-11-21T02:35:09Z","published":"2023-11-21T02:35:09Z","title":"Noise in Relation Classification Dataset TACRED: Characterization and\n  Reduction","summary":"  The overarching objective of this paper is two-fold. First, to explore\nmodel-based approaches to characterize the primary cause of the noise. in the\nRE dataset TACRED Second, to identify the potentially noisy instances. Towards\nthe first objective, we analyze predictions and performance of state-of-the-art\n(SOTA) models to identify the root cause of noise in the dataset. Our analysis\nof TACRED shows that the majority of the noise in the dataset originates from\nthe instances labeled as no-relation which are negative examples. For the\nsecond objective, we explore two nearest-neighbor-based strategies to\nautomatically identify potentially noisy examples for elimination and\nreannotation. Our first strategy, referred to as Intrinsic Strategy (IS), is\nbased on the assumption that positive examples are clean. Thus, we have used\nfalse-negative predictions to identify noisy negative examples. Whereas, our\nsecond approach, referred to as Extrinsic Strategy, is based on using a clean\nsubset of the dataset to identify potentially noisy negative examples. Finally,\nwe retrained the SOTA models on the eliminated and reannotated dataset. Our\nempirical results based on two SOTA models trained on TACRED-E following the IS\nshow an average 4% F1-score improvement, whereas reannotation (TACRED-R) does\nnot improve the original results. However, following ES, SOTA models show the\naverage F1-score improvement of 3.8% and 4.4% when trained on respective\neliminated (TACRED-EN) and reannotated (TACRED-RN) datasets respectively. We\nfurther extended the ES for cleaning positive examples as well, which resulted\nin an average performance improvement of 5.8% and 5.6% for the eliminated\n(TACRED-ENP) and reannotated (TACRED-RNP) datasets respectively.\n","authors":["Akshay Parekh","Ashish Anand","Amit Awekar"],"pdf_url":"https://arxiv.org/pdf/2311.12298v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2311.12289v1","updated":"2023-11-21T02:02:46Z","published":"2023-11-21T02:02:46Z","title":"ATLANTIC: Structure-Aware Retrieval-Augmented Language Model for\n  Interdisciplinary Science","summary":"  Large language models record impressive performance on many natural language\nprocessing tasks. However, their knowledge capacity is limited to the\npretraining corpus. Retrieval augmentation offers an effective solution by\nretrieving context from external knowledge sources to complement the language\nmodel. However, existing retrieval augmentation techniques ignore the\nstructural relationships between these documents. Furthermore, retrieval models\nare not explored much in scientific tasks, especially in regard to the\nfaithfulness of retrieved documents. In this paper, we propose a novel\nstructure-aware retrieval augmented language model that accommodates document\nstructure during retrieval augmentation. We create a heterogeneous document\ngraph capturing multiple types of relationships (e.g., citation, co-authorship,\netc.) that connect documents from more than 15 scientific disciplines (e.g.,\nPhysics, Medicine, Chemistry, etc.). We train a graph neural network on the\ncurated document graph to act as a structural encoder for the corresponding\npassages retrieved during the model pretraining. Particularly, along with text\nembeddings of the retrieved passages, we obtain structural embeddings of the\ndocuments (passages) and fuse them together before feeding them to the language\nmodel. We evaluate our model extensively on various scientific benchmarks that\ninclude science question-answering and scientific document classification\ntasks. Experimental results demonstrate that structure-aware retrieval improves\nretrieving more coherent, faithful and contextually relevant passages, while\nshowing a comparable performance in the overall accuracy.\n","authors":["Sai Munikoti","Anurag Acharya","Sridevi Wagle","Sameera Horawalavithana"],"pdf_url":"https://arxiv.org/pdf/2311.12289v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10429v4","updated":"2023-11-21T02:01:53Z","published":"2023-05-17T17:58:13Z","title":"DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining","summary":"  The mixture proportions of pretraining data domains (e.g., Wikipedia, books,\nweb text) greatly affect language model (LM) performance. In this paper, we\npropose Domain Reweighting with Minimax Optimization (DoReMi), which first\ntrains a small proxy model using group distributionally robust optimization\n(Group DRO) over domains to produce domain weights (mixture proportions)\nwithout knowledge of downstream tasks. We then resample a dataset with these\ndomain weights and train a larger, full-sized model. In our experiments, we use\nDoReMi on a 280M-parameter proxy model to set the domain weights for training\nan 8B-parameter model (30x larger) more efficiently. On The Pile, DoReMi\nimproves perplexity across all domains, even when it downweights a domain.\nDoReMi improves average few-shot downstream accuracy by 6.5% points over a\nbaseline model trained using The Pile's default domain weights and reaches the\nbaseline accuracy with 2.6x fewer training steps. On the GLaM dataset, DoReMi,\nwhich has no knowledge of downstream tasks, even matches the performance of\nusing domain weights tuned on downstream tasks.\n","authors":["Sang Michael Xie","Hieu Pham","Xuanyi Dong","Nan Du","Hanxiao Liu","Yifeng Lu","Percy Liang","Quoc V. Le","Tengyu Ma","Adams Wei Yu"],"pdf_url":"https://arxiv.org/pdf/2305.10429v4.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.12275v1","updated":"2023-11-21T01:34:02Z","published":"2023-11-21T01:34:02Z","title":"Enabling On-Device Large Language Model Personalization with\n  Self-Supervised Data Selection and Synthesis","summary":"  After a large language model (LLM) is deployed on edge devices, it is\ndesirable for these devices to learn from user-generated conversation data to\ngenerate user-specific and personalized responses in real-time. However,\nuser-generated data usually contains sensitive and private information, and\nuploading such data to the cloud for annotation is not preferred if not\nprohibited. While it is possible to obtain annotation locally by directly\nasking users to provide preferred responses, such annotations have to be sparse\nto not affect user experience. In addition, the storage of edge devices is\nusually too limited to enable large-scale fine-tuning with full user-generated\ndata. It remains an open question how to enable on-device LLM personalization,\nconsidering sparse annotation and limited on-device storage. In this paper, we\npropose a novel framework to select and store the most representative data\nonline in a self-supervised way. Such data has a small memory footprint and\nallows infrequent requests of user annotations for further fine-tuning. To\nenhance fine-tuning quality, multiple semantically similar pairs of question\ntexts and expected responses are generated using the LLM. Our experiments show\nthat the proposed framework achieves the best user-specific content-generating\ncapability (accuracy) and fine-tuning speed (performance) compared with vanilla\nbaselines. To the best of our knowledge, this is the very first on-device LLM\npersonalization framework.\n","authors":["Ruiyang Qin","Jun Xia","Zhenge Jia","Meng Jiang","Ahmed Abbasi","Peipei Zhou","Jingtong Hu","Yiyu Shi"],"pdf_url":"https://arxiv.org/pdf/2311.12275v1.pdf","comment":"6 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2311.10813v2","updated":"2023-11-21T01:24:36Z","published":"2023-11-17T18:59:56Z","title":"A Language Agent for Autonomous Driving","summary":"  Human-level driving is an ultimate goal of autonomous driving. Conventional\napproaches formulate autonomous driving as a perception-prediction-planning\nframework, yet their systems do not capitalize on the inherent reasoning\nability and experiential knowledge of humans. In this paper, we propose a\nfundamental paradigm shift from current pipelines, exploiting Large Language\nModels (LLMs) as a cognitive agent to integrate human-like intelligence into\nautonomous driving systems. Our approach, termed Agent-Driver, transforms the\ntraditional autonomous driving pipeline by introducing a versatile tool library\naccessible via function calls, a cognitive memory of common sense and\nexperiential knowledge for decision-making, and a reasoning engine capable of\nchain-of-thought reasoning, task planning, motion planning, and\nself-reflection. Powered by LLMs, our Agent-Driver is endowed with intuitive\ncommon sense and robust reasoning capabilities, thus enabling a more nuanced,\nhuman-like approach to autonomous driving. We evaluate our approach on the\nlarge-scale nuScenes benchmark, and extensive experiments substantiate that our\nAgent-Driver significantly outperforms the state-of-the-art driving methods by\na large margin. Our approach also demonstrates superior interpretability and\nfew-shot learning ability to these methods. Code will be released.\n","authors":["Jiageng Mao","Junjie Ye","Yuxi Qian","Marco Pavone","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2311.10813v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13061v1","updated":"2023-11-21T23:50:33Z","published":"2023-11-21T23:50:33Z","title":"Attribution and Alignment: Effects of Local Context Repetition on\n  Utterance Production and Comprehension in Dialogue","summary":"  Language models are often used as the backbone of modern dialogue systems.\nThese models are pre-trained on large amounts of written fluent language.\nRepetition is typically penalised when evaluating language model generations.\nHowever, it is a key component of dialogue. Humans use local and partner\nspecific repetitions; these are preferred by human users and lead to more\nsuccessful communication in dialogue. In this study, we evaluate (a) whether\nlanguage models produce human-like levels of repetition in dialogue, and (b)\nwhat are the processing mechanisms related to lexical re-use they use during\ncomprehension. We believe that such joint analysis of model production and\ncomprehension behaviour can inform the development of cognitively inspired\ndialogue generation systems.\n","authors":["Aron Molnar","Jaap Jumelet","Mario Giulianelli","Arabella Sinclair"],"pdf_url":"https://arxiv.org/pdf/2311.13061v1.pdf","comment":"CoNLL 2023"},{"id":"http://arxiv.org/abs/2311.13053v1","updated":"2023-11-21T23:26:05Z","published":"2023-11-21T23:26:05Z","title":"Beyond Text: Unveiling Multimodal Proficiency of Large Language Models\n  with MultiAPI Benchmark","summary":"  The proliferation of Large Language Models like ChatGPT has significantly\nadvanced language understanding and generation, impacting a broad spectrum of\napplications. However, these models predominantly excel in text-based tasks,\noverlooking the complexity of real-world multimodal information. This study\nintroduces MultiAPI, a pioneering comprehensive large-scale API benchmark\ndataset aimed at expanding LLMs' proficiency in multimodal contexts. Developed\ncollaboratively through ChatGPT, MultiAPI consists of 235 diverse API calls and\n2,038 contextual prompts, offering a unique platform evaluation of\ntool-augmented LLMs handling multimodal tasks. Through comprehensive\nexperiments, our findings reveal that while LLMs demonstrate proficiency in API\ncall decision-making, they face challenges in domain identification, function\nselection, and argument generation. What's more, we surprisingly notice that\nauxiliary context can actually impair the performance. An in-depth error\nanalysis paves the way for a new paradigm to address these challenges,\nsuggesting a potential direction for future LLM research.\n","authors":["Xiao Liu","Jianfeng Lin","Jiawei Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.13053v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2211.08371v3","updated":"2023-11-21T23:04:53Z","published":"2022-11-15T18:21:46Z","title":"Pragmatics in Language Grounding: Phenomena, Tasks, and Modeling\n  Approaches","summary":"  People rely heavily on context to enrich meaning beyond what is literally\nsaid, enabling concise but effective communication. To interact successfully\nand naturally with people, user-facing artificial intelligence systems will\nrequire similar skills in pragmatics: relying on various types of context --\nfrom shared linguistic goals and conventions, to the visual and embodied world\n-- to use language effectively. We survey existing grounded settings and\npragmatic modeling approaches and analyze how the task goals, environmental\ncontexts, and communicative affordances in each work enrich linguistic meaning.\nWe present recommendations for future grounded task design to naturally elicit\npragmatic phenomena, and suggest directions that focus on a broader range of\ncommunicative contexts and affordances.\n","authors":["Daniel Fried","Nicholas Tomlin","Jennifer Hu","Roma Patel","Aida Nematzadeh"],"pdf_url":"https://arxiv.org/pdf/2211.08371v3.pdf","comment":"Findings of EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13029v1","updated":"2023-11-21T22:30:37Z","published":"2023-11-21T22:30:37Z","title":"Systematic word meta-sense extension","summary":"  The meaning of polysemous words often varies in a highly productive yet\npredictable way. Generalizing the regularity between conventional senses to\nderive novel word meaning is crucial for automated processing of non-literal\nlanguage uses such as figurative expressions. We introduce a novel task called\nsystematic word meta-sense extension (SWORME) to test and improve language\nmodels' ability to extend word meaning to denote new semantic domains (also\ncalled meta-senses) that bear regular semantic relations with existing senses.\nWe found that language models prefer incremental lexical semantic change toward\nconceptually similar meta-senses such as logical metonymy, and are much worse\nat predicting highly non-literal meaning extensions such as metaphors. We\npropose a novel analogy-based method of word meaning extension, and show that\nit effectively improves language model systematicity in making both gradual and\nradical types of meta-sense extension. We further demonstrate that learning\nsystematic meta-sense extensions benefits language models on multiple\nbenchmarks of figurative language understanding.\n","authors":["Lei Yu"],"pdf_url":"https://arxiv.org/pdf/2311.13029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.11603v3","updated":"2023-11-21T22:23:43Z","published":"2022-05-23T20:00:22Z","title":"Representation Projection Invariance Mitigates Representation Collapse","summary":"  Fine-tuning contextualized representations learned by pre-trained language\nmodels remains a prevalent practice in NLP. However, fine-tuning can lead to\nrepresentation degradation (also known as representation collapse), which may\nresult in instability, sub-optimal performance, and weak generalization.\n  In this paper, we propose Representation Projection Invariance (REPINA), a\nnovel regularization method to maintain the information content of\nrepresentation and reduce representation collapse during fine-tuning by\ndiscouraging undesirable changes in the representations. We study the empirical\nbehavior of the proposed regularization in comparison to 5 comparable baselines\nacross 13 language understanding tasks (GLUE benchmark and six additional\ndatasets). When evaluating in-domain performance, REPINA consistently\noutperforms other baselines on most tasks (10 out of 13). We also demonstrate\nits effectiveness in few-shot settings and robustness to label perturbation. As\na by-product, we extend previous studies of representation collapse and propose\nseveral metrics to quantify it. Our empirical findings show that our approach\nis significantly more effective at mitigating representation collapse.\n","authors":["Anastasia Razdaibiedina","Ashish Khetan","Zohar Karnin","Daniel Khashabi","Vishaal Kapoor","Vivek Madan"],"pdf_url":"https://arxiv.org/pdf/2205.11603v3.pdf","comment":"41 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.12986v1","updated":"2023-11-21T20:45:55Z","published":"2023-11-21T20:45:55Z","title":"Unsupervised Graph Attention Autoencoder for Attributed Networks using\n  K-means Loss","summary":"  Multimodal Sentiment Analysis (MSA) has recently become a centric research\ndirection for many real-world applications. This proliferation is due to the\nfact that opinions are central to almost all human activities and are key\ninfluencers of our behaviors. In addition, the recent deployment of Deep\nLearning-based (DL) models has proven their high efficiency for a wide range of\nWestern languages. In contrast, Arabic DL-based multimodal sentiment analysis\n(MSA) is still in its infantile stage due, mainly, to the lack of standard\ndatasets. % The contribution In this paper, our investigation is twofold.\nFirst, we design a pipeline that helps building our Arabic Multimodal dataset\nleveraging both state-of-the-art transformers and feature extraction tools\nwithin word alignment techniques. Thereafter, we validate our dataset using\nstate-of-the-art transformer-based model dealing with multimodality. Despite\nthe small size of the outcome dataset, experiments show that Arabic\nmultimodality is very promising.\n","authors":["Abdelfateh Bekkaira","Slimane Bellaouar","Slimane Oulad-Naoui"],"pdf_url":"https://arxiv.org/pdf/2311.12986v1.pdf","comment":"7 pages, 5 Figures"},{"id":"http://arxiv.org/abs/2305.14457v3","updated":"2023-11-21T20:38:22Z","published":"2023-05-23T18:28:42Z","title":"Pre-training Language Models for Comparative Reasoning","summary":"  Comparative reasoning is a process of comparing objects, concepts, or\nentities to draw conclusions, which constitutes a fundamental cognitive\nability. In this paper, we propose a novel framework to pre-train language\nmodels for enhancing their abilities of comparative reasoning over texts. While\nthere have been approaches for NLP tasks that require comparative reasoning,\nthey suffer from costly manual data labeling and limited generalizability to\ndifferent tasks. Our approach introduces a novel method of collecting scalable\ndata for text-based entity comparison, which leverages both structured and\nunstructured data. Moreover, we present a framework of pre-training language\nmodels via three novel objectives on comparative reasoning. Evaluation on\ndownstream tasks including comparative question answering, question generation,\nand summarization shows that our pre-training framework significantly improves\nthe comparative reasoning abilities of language models, especially under\nlow-resource conditions. This work also releases the first integrated benchmark\nfor comparative reasoning.\n","authors":["Mengxia Yu","Zhihan Zhang","Wenhao Yu","Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2305.14457v3.pdf","comment":"EMNLP 2023 - Camera Ready"},{"id":"http://arxiv.org/abs/2311.12983v1","updated":"2023-11-21T20:34:47Z","published":"2023-11-21T20:34:47Z","title":"GAIA: a benchmark for General AI Assistants","summary":"  We introduce GAIA, a benchmark for General AI Assistants that, if solved,\nwould represent a milestone in AI research. GAIA proposes real-world questions\nthat require a set of fundamental abilities such as reasoning, multi-modality\nhandling, web browsing, and generally tool-use proficiency. GAIA questions are\nconceptually simple for humans yet challenging for most advanced AIs: we show\nthat human respondents obtain 92\\% vs. 15\\% for GPT-4 equipped with plugins.\nThis notable performance disparity contrasts with the recent trend of LLMs\noutperforming humans on tasks requiring professional skills in e.g. law or\nchemistry. GAIA's philosophy departs from the current trend in AI benchmarks\nsuggesting to target tasks that are ever more difficult for humans. We posit\nthat the advent of Artificial General Intelligence (AGI) hinges on a system's\ncapability to exhibit similar robustness as the average human does on such\nquestions. Using GAIA's methodology, we devise 466 questions and their answer.\nWe release our questions while retaining answers to 300 of them to power a\nleader-board available at https://huggingface.co/gaia-benchmark.\n","authors":["Grégoire Mialon","Clémentine Fourrier","Craig Swift","Thomas Wolf","Yann LeCun","Thomas Scialom"],"pdf_url":"https://arxiv.org/pdf/2311.12983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.09832v3","updated":"2023-11-21T20:30:00Z","published":"2023-10-15T13:28:42Z","title":"Merging Experts into One: Improving Computational Efficiency of Mixture\n  of Experts","summary":"  Scaling the size of language models usually leads to remarkable advancements\nin NLP tasks. But it often comes with a price of growing computational cost.\nAlthough a sparse Mixture of Experts (MoE) can reduce the cost by activating a\nsmall subset of parameters (e.g., one expert) for each input, its computation\nescalates significantly if increasing the number of activated experts, limiting\nits practical utility. Can we retain the advantages of adding more experts\nwithout substantially increasing the computational costs? In this paper, we\nfirst demonstrate the superiority of selecting multiple experts and then\npropose a computation-efficient approach called \\textbf{\\texttt{Merging Experts\ninto One}} (MEO), which reduces the computation cost to that of a single\nexpert. Extensive experiments show that MEO significantly improves\ncomputational efficiency, e.g., FLOPS drops from 72.0G of vanilla MoE to 28.6G\n(MEO). Moreover, we propose a token-level attention block that further enhances\nthe efficiency and performance of token-level MEO, e.g., 83.3\\% (MEO) vs.\n82.6\\% (vanilla MoE) average score on the GLUE benchmark. Our code will be\nreleased upon acceptance. Code will be released at:\n\\url{https://github.com/Shwai-He/MEO}.\n","authors":["Shwai He","Run-Ze Fan","Liang Ding","Li Shen","Tianyi Zhou","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2310.09832v3.pdf","comment":"EMNLP 2023 Main Conference (Oral)"},{"id":"http://arxiv.org/abs/2305.11731v2","updated":"2023-11-21T19:19:10Z","published":"2023-05-19T15:05:39Z","title":"Persian Typographical Error Type Detection Using Deep Neural Networks on\n  Algorithmically-Generated Misspellings","summary":"  Spelling correction is a remarkable challenge in the field of natural\nlanguage processing. The objective of spelling correction tasks is to recognize\nand rectify spelling errors automatically. The development of applications that\ncan effectually diagnose and correct Persian spelling and grammatical errors\nhas become more important in order to improve the quality of Persian text. The\nTypographical Error Type Detection in Persian is a relatively understudied\narea. Therefore, this paper presents a compelling approach for detecting\ntypographical errors in Persian texts. Our work includes the presentation of a\npublicly available dataset called FarsTypo, which comprises 3.4 million words\narranged in chronological order and tagged with their corresponding\npart-of-speech. These words cover a wide range of topics and linguistic styles.\nWe develop an algorithm designed to apply Persian-specific errors to a scalable\nportion of these words, resulting in a parallel dataset of correct and\nincorrect words. By leveraging FarsTypo, we establish a strong foundation and\nconduct a thorough comparison of various methodologies employing different\narchitectures. Additionally, we introduce a groundbreaking Deep Sequential\nNeural Network that utilizes both word and character embeddings, along with\nbidirectional LSTM layers, for token classification aimed at detecting\ntypographical errors across 51 distinct classes. Our approach is contrasted\nwith highly advanced industrial systems that, unlike this study, have been\ndeveloped using a diverse range of resources. The outcomes of our final method\nproved to be highly competitive, achieving an accuracy of 97.62%, precision of\n98.83%, recall of 98.61%, and surpassing others in terms of speed.\n","authors":["Mohammad Dehghani","Heshaam Faili"],"pdf_url":"https://arxiv.org/pdf/2305.11731v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2311.11908v2","updated":"2023-11-21T15:17:00Z","published":"2023-11-20T16:40:29Z","title":"Continual Learning: Applications and the Road Forward","summary":"  Continual learning is a sub-field of machine learning, which aims to allow\nmachine learning models to continuously learn on new data, by accumulating\nknowledge without forgetting what was learned in the past. In this work, we\ntake a step back, and ask: \"Why should one care about continual learning in the\nfirst place?\". We set the stage by surveying recent continual learning papers\npublished at three major machine learning conferences, and show that\nmemory-constrained settings dominate the field. Then, we discuss five open\nproblems in machine learning, and even though they seem unrelated to continual\nlearning at first sight, we show that continual learning will inevitably be\npart of their solution. These problems are model-editing, personalization,\non-device learning, faster (re-)training and reinforcement learning. Finally,\nby comparing the desiderata from these unsolved problems and the current\nassumptions in continual learning, we highlight and discuss four future\ndirections for continual learning research. We hope that this work offers an\ninteresting perspective on the future of continual learning, while displaying\nits potential value and the paths we have to pursue in order to make it\nsuccessful. This work is the result of the many discussions the authors had at\nthe Dagstuhl seminar on Deep Continual Learning, in March 2023.\n","authors":["Eli Verwimp","Rahaf Aljundi","Shai Ben-David","Matthias Bethge","Andrea Cossu","Alexander Gepperth","Tyler L. Hayes","Eyke Hüllermeier","Christopher Kanan","Dhireesha Kudithipudi","Christoph H. Lampert","Martin Mundt","Razvan Pascanu","Adrian Popescu","Andreas S. Tolias","Joost van de Weijer","Bing Liu","Vincenzo Lomonaco","Tinne Tuytelaars","Gido M. van de Ven"],"pdf_url":"https://arxiv.org/pdf/2311.11908v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11808v2","updated":"2023-11-21T09:18:14Z","published":"2023-11-20T14:41:44Z","title":"Robot Hand-Eye Calibration using Structure-from-Motion","summary":"  In this paper we propose a new flexible method for hand-eye calibration. The\nvast majority of existing hand-eye calibration techniques requires a\ncalibration rig which is used in conjunction with camera pose estimation\nmethods. Instead, we combine structure-from-motion with known robot motions and\nwe show that the solution can be obtained in linear form. The latter solves for\nboth the hand-eye parameters and for the unknown scale factor inherent with\nstructure-from-motion methods. The algebraic analysis that is made possible\nwith such a linear formulation allows to investigate not only the well known\ncase of general screw motions but also such singular motions as pure\ntranslations, pure rotations, and planar motions. In essence, the robot-mounted\ncamera looks to an unknown rigid layout, tracks points over an image sequence\nand estimates the camera-to-robot relationship. Such a self calibration process\nis relevant for unmanned vehicles, robots working in remote places, and so\nforth. We conduct a large number of experiments which validate the quality of\nthe method by comparing it with existing ones.\n","authors":["Nicolas Andreff","Radu Horaud","Bernard Espiau"],"pdf_url":"https://arxiv.org/pdf/2311.11808v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11700v2","updated":"2023-11-21T07:26:16Z","published":"2023-11-20T12:08:23Z","title":"GS-SLAM: Dense Visual SLAM with 3D Gaussian Splatting","summary":"  In this paper, we introduce $\\textbf{GS-SLAM}$ that first utilizes 3D\nGaussian representation in the Simultaneous Localization and Mapping (SLAM)\nsystem. It facilitates a better balance between efficiency and accuracy.\nCompared to recent SLAM methods employing neural implicit representations, our\nmethod utilizes a real-time differentiable splatting rendering pipeline that\noffers significant speedup to map optimization and RGB-D re-rendering.\nSpecifically, we propose an adaptive expansion strategy that adds new or\ndeletes noisy 3D Gaussian in order to efficiently reconstruct new observed\nscene geometry and improve the mapping of previously observed areas. This\nstrategy is essential to extend 3D Gaussian representation to reconstruct the\nwhole scene rather than synthesize a static object in existing methods.\nMoreover, in the pose tracking process, an effective coarse-to-fine technique\nis designed to select reliable 3D Gaussian representations to optimize camera\npose, resulting in runtime reduction and robust estimation. Our method achieves\ncompetitive performance compared with existing state-of-the-art real-time\nmethods on the Replica, TUM-RGBD datasets. The source code will be released\nsoon.\n","authors":["Chi Yan","Delin Qu","Dong Wang","Dan Xu","Zhigang Wang","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2311.11700v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12685v3","updated":"2023-11-21T02:57:09Z","published":"2023-06-22T06:12:23Z","title":"Rethinking the Backward Propagation for Adversarial Transferability","summary":"  Transfer-based attacks generate adversarial examples on the surrogate model,\nwhich can mislead other black-box models without access, making it promising to\nattack real-world applications. Recently, several works have been proposed to\nboost adversarial transferability, in which the surrogate model is usually\noverlooked. In this work, we identify that non-linear layers (e.g., ReLU,\nmax-pooling, etc.) truncate the gradient during backward propagation, making\nthe gradient w.r.t. input image imprecise to the loss function. We hypothesize\nand empirically validate that such truncation undermines the transferability of\nadversarial examples. Based on these findings, we propose a novel method called\nBackward Propagation Attack (BPA) to increase the relevance between the\ngradient w.r.t. input image and loss function so as to generate adversarial\nexamples with higher transferability. Specifically, BPA adopts a non-monotonic\nfunction as the derivative of ReLU and incorporates softmax with temperature to\nsmooth the derivative of max-pooling, thereby mitigating the information loss\nduring the backward propagation of gradients. Empirical results on the ImageNet\ndataset demonstrate that not only does our method substantially boost the\nadversarial transferability, but it is also general to existing transfer-based\nattacks. Code is available at https://github.com/Trustworthy-AI-Group/RPA.\n","authors":["Xiaosen Wang","Kangheng Tong","Kun He"],"pdf_url":"https://arxiv.org/pdf/2306.12685v3.pdf","comment":"Accepted by NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.11439v2","updated":"2023-11-21T07:12:22Z","published":"2023-11-19T22:24:19Z","title":"Improved Defect Detection and Classification Method for Advanced IC\n  Nodes by Using Slicing Aided Hyper Inference with Refinement Strategy","summary":"  In semiconductor manufacturing, lithography has often been the manufacturing\nstep defining the smallest possible pattern dimensions. In recent years,\nprogress has been made towards high-NA (Numerical Aperture) EUVL\n(Extreme-Ultraviolet-Lithography) paradigm, which promises to advance pattern\nshrinking (2 nm node and beyond). However, a significant increase in stochastic\ndefects and the complexity of defect detection becomes more pronounced with\nhigh-NA. Present defect inspection techniques (both non-machine learning and\nmachine learning based), fail to achieve satisfactory performance at high-NA\ndimensions. In this work, we investigate the use of the Slicing Aided Hyper\nInference (SAHI) framework for improving upon current techniques. Using SAHI,\ninference is performed on size-increased slices of the SEM images. This leads\nto the object detector's receptive field being more effective in capturing\nsmall defect instances. First, the performance on previously investigated\nsemiconductor datasets is benchmarked across various configurations, and the\nSAHI approach is demonstrated to substantially enhance the detection of small\ndefects, by approx. 2x. Afterwards, we also demonstrated application of SAHI\nleads to flawless detection rates on a new test dataset, with scenarios not\nencountered during training, whereas previous trained models failed. Finally,\nwe formulate an extension of SAHI that does not significantly reduce\ntrue-positive predictions while eliminating false-positive predictions.\n","authors":["Vic De Ridder","Bappaditya Dey","Victor Blanco","Sandip Halder","Bartel Van Waeyenberge"],"pdf_url":"https://arxiv.org/pdf/2311.11439v2.pdf","comment":"12 pages, 9 figures, to be presented at International Conference on\n  Machine Intelligence with Applications (ICMIA), and to be published in\n  conference proceedings by AIP"},{"id":"http://arxiv.org/abs/2311.11354v2","updated":"2023-11-21T03:45:32Z","published":"2023-11-19T15:35:15Z","title":"Scale-aware competition network for palmprint recognition","summary":"  Palmprint biometrics garner heightened attention in palm-scanning payment and\nsocial security due to their distinctive attributes. However, prevailing\nmethodologies singularly prioritize texture orientation, neglecting the\nsignificant texture scale dimension. We design an innovative network for\nconcurrently extracting intra-scale and inter-scale features to redress this\nlimitation. This paper proposes a scale-aware competitive network (SAC-Net),\nwhich includes the Inner-Scale Competition Module (ISCM) and the Across-Scale\nCompetition Module (ASCM) to capture texture characteristics related to\norientation and scale. ISCM efficiently integrates learnable Gabor filters and\na self-attention mechanism to extract rich orientation data and discern\ntextures with long-range discriminative properties. Subsequently, ASCM\nleverages a competitive strategy across various scales to effectively\nencapsulate the competitive texture scale elements. By synergizing ISCM and\nASCM, our method adeptly characterizes palmprint features. Rigorous\nexperimentation across three benchmark datasets unequivocally demonstrates our\nproposed approach's exceptional recognition performance and resilience relative\nto state-of-the-art alternatives.\n","authors":["Chengrui Gao","Ziyuan Yang","Min Zhu","Andrew Beng Jin Teoh"],"pdf_url":"https://arxiv.org/pdf/2311.11354v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11306v2","updated":"2023-11-21T13:59:31Z","published":"2023-11-19T11:57:01Z","title":"UMAAF: Unveiling Aesthetics via Multifarious Attributes of Images","summary":"  With the increasing prevalence of smartphones and websites, Image Aesthetic\nAssessment (IAA) has become increasingly crucial. While the significance of\nattributes in IAA is widely recognized, many attribute-based methods lack\nconsideration for the selection and utilization of aesthetic attributes. Our\ninitial step involves the acquisition of aesthetic attributes from both intra-\nand inter-perspectives. Within the intra-perspective, we extract the direct\nvisual attributes of images, constituting the absolute attribute. In the\ninter-perspective, our focus lies in modeling the relative score relationships\nbetween images within the same sequence, forming the relative attribute. Then,\nto better utilize image attributes in aesthetic assessment, we propose the\nUnified Multi-attribute Aesthetic Assessment Framework (UMAAF) to model both\nabsolute and relative attributes of images. For absolute attributes, we\nleverage multiple absolute-attribute perception modules and an\nabsolute-attribute interacting network. The absolute-attribute perception\nmodules are first pre-trained on several absolute-attribute learning tasks and\nthen used to extract corresponding absolute attribute features. The\nabsolute-attribute interacting network adaptively learns the weight of diverse\nabsolute-attribute features, effectively integrating them with generic\naesthetic features from various absolute-attribute perspectives and generating\nthe aesthetic prediction. To model the relative attribute of images, we\nconsider the relative ranking and relative distance relationships between\nimages in a Relative-Relation Loss function, which boosts the robustness of the\nUMAAF. Furthermore, UMAAF achieves state-of-the-art performance on TAD66K and\nAVA datasets, and multiple experiments demonstrate the effectiveness of each\nmodule and the model's alignment with human preference.\n","authors":["Weijie Li","Yitian Wan","Xingjiao Wu","Junjie Xu","Cheng Jin","Liang He"],"pdf_url":"https://arxiv.org/pdf/2311.11306v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12796v1","updated":"2023-11-21T18:59:58Z","published":"2023-11-21T18:59:58Z","title":"Physics-guided Shape-from-Template: Monocular Video Perception through\n  Neural Surrogate Models","summary":"  3D reconstruction of dynamic scenes is a long-standing problem in computer\ngraphics and increasingly difficult the less information is available.\nShape-from-Template (SfT) methods aim to reconstruct a template-based geometry\nfrom RGB images or video sequences, often leveraging just a single monocular\ncamera without depth information, such as regular smartphone recordings.\nUnfortunately, existing reconstruction methods are either unphysical and noisy\nor slow in optimization. To solve this problem, we propose a novel SfT\nreconstruction algorithm for cloth using a pre-trained neural surrogate model\nthat is fast to evaluate, stable, and produces smooth reconstructions due to a\nregularizing physics simulation. Differentiable rendering of the simulated mesh\nenables pixel-wise comparisons between the reconstruction and a target video\nsequence that can be used for a gradient-based optimization procedure to\nextract not only shape information but also physical parameters such as\nstretching, shearing, or bending stiffness of the cloth. This allows to retain\na precise, stable, and smooth reconstructed geometry while reducing the runtime\nby a factor of 400-500 compared to $\\phi$-SfT, a state-of-the-art physics-based\nSfT approach.\n","authors":["David Stotko","Nils Wandel","Reinhard Klein"],"pdf_url":"https://arxiv.org/pdf/2311.12796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12793v1","updated":"2023-11-21T18:58:11Z","published":"2023-11-21T18:58:11Z","title":"ShareGPT4V: Improving Large Multi-Modal Models with Better Captions","summary":"  In the realm of large multi-modal models (LMMs), efficient modality alignment\nis crucial yet often constrained by the scarcity of high-quality image-text\ndata. To address this bottleneck, we introduce the ShareGPT4V dataset, a\npioneering large-scale resource featuring 1.2 million highly descriptive\ncaptions, which surpasses existing datasets in diversity and information\ncontent, covering world knowledge, object properties, spatial relationships,\nand aesthetic evaluations. Specifically, ShareGPT4V originates from a curated\n100K high-quality captions collected from advanced GPT4-Vision and has been\nexpanded to 1.2M with a superb caption model trained on this subset. ShareGPT4V\nfirst demonstrates its effectiveness for the Supervised Fine-Tuning (SFT)\nphase, by substituting an equivalent quantity of detailed captions in existing\nSFT datasets with a subset of our high-quality captions, significantly\nenhancing the LMMs like LLaVA-7B, LLaVA-1.5-13B, and Qwen-VL-Chat-7B on the MME\nand MMBench benchmarks, with respective gains of 222.8/22.0/22.3 and\n2.7/1.3/1.5. We further incorporate ShareGPT4V data into both the pre-training\nand SFT phases, obtaining ShareGPT4V-7B, a superior LMM based on a simple\narchitecture that has remarkable performance across a majority of the\nmulti-modal benchmarks. This project is available at\nhttps://ShareGPT4V.github.io to serve as a pivotal resource for advancing the\nLMMs community.\n","authors":["Lin Chen","Jisong Li","Xiaoyi Dong","Pan Zhang","Conghui He","Jiaqi Wang","Feng Zhao","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2311.12793v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12792v1","updated":"2023-11-21T18:58:01Z","published":"2023-11-21T18:58:01Z","title":"Intrinsic Image Decomposition via Ordinal Shading","summary":"  Intrinsic decomposition is a fundamental mid-level vision problem that plays\na crucial role in various inverse rendering and computational photography\npipelines. Generating highly accurate intrinsic decompositions is an inherently\nunder-constrained task that requires precisely estimating continuous-valued\nshading and albedo. In this work, we achieve high-resolution intrinsic\ndecomposition by breaking the problem into two parts. First, we present a dense\nordinal shading formulation using a shift- and scale-invariant loss in order to\nestimate ordinal shading cues without restricting the predictions to obey the\nintrinsic model. We then combine low- and high-resolution ordinal estimations\nusing a second network to generate a shading estimate with both global\ncoherency and local details. We encourage the model to learn an accurate\ndecomposition by computing losses on the estimated shading as well as the\nalbedo implied by the intrinsic model. We develop a straightforward method for\ngenerating dense pseudo ground truth using our model's predictions and\nmulti-illumination data, enabling generalization to in-the-wild imagery. We\npresent an exhaustive qualitative and quantitative analysis of our predicted\nintrinsic components against state-of-the-art methods. Finally, we demonstrate\nthe real-world applicability of our estimations by performing otherwise\ndifficult editing tasks such as recoloring and relighting.\n","authors":["Chris Careaga","Yağız Aksoy"],"pdf_url":"https://arxiv.org/pdf/2311.12792v1.pdf","comment":"24 pages, 23 figures, Accepted to ACM Transactions on Graphics\n  (2023). Project page: https://yaksoy.github.io/intrinsic/"},{"id":"http://arxiv.org/abs/2305.11818v2","updated":"2023-11-21T18:55:24Z","published":"2023-05-19T16:53:15Z","title":"MaGIC: Multi-modality Guided Image Completion","summary":"  Vanilla image completion approaches exhibit sensitivity to large missing\nregions, attributed to the limited availability of reference information for\nplausible generation. To mitigate this, existing methods incorporate the extra\ncue as a guidance for image completion. Despite improvements, these approaches\nare often restricted to employing a single modality (e.g., segmentation or\nsketch maps), which lacks scalability in leveraging multi-modality for more\nplausible completion. In this paper, we propose a novel, simple yet effective\nmethod for Multi-modal Guided Image Completion, dubbed MaGIC, which not only\nsupports a wide range of single modality as the guidance (e.g., text, canny\nedge, sketch, segmentation, depth, and pose), but also adapts to arbitrarily\ncustomized combination of these modalities (i.e., arbitrary multi-modality) for\nimage completion. For building MaGIC, we first introduce a modality-specific\nconditional U-Net (MCU-Net) that injects single-modal signal into a U-Net\ndenoiser for single-modal guided image completion. Then, we devise a consistent\nmodality blending (CMB) method to leverage modality signals encoded in multiple\nlearned MCU-Nets through gradient guidance in latent space. Our CMB is\ntraining-free, thereby avoids the cumbersome joint re-training of different\nmodalities, which is the secret of MaGIC to achieve exceptional flexibility in\naccommodating new modalities for completion. Experiments show the superiority\nof MaGIC over state-of-the-art methods and its generalization to various\ncompletion tasks. Our project with code and models is available at\nyeates.github.io/MaGIC-Page/.\n","authors":["Yongsheng Yu","Hao Wang","Tiejian Luo","Heng Fan","Libo Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.11818v2.pdf","comment":"23 pages, 15 figures"},{"id":"http://arxiv.org/abs/2211.13807v2","updated":"2023-11-21T18:47:51Z","published":"2022-11-24T21:41:52Z","title":"GEFF: Improving Any Clothes-Changing Person ReID Model using Gallery\n  Enrichment with Face Features","summary":"  In the Clothes-Changing Re-Identification (CC-ReID) problem, given a query\nsample of a person, the goal is to determine the correct identity based on a\nlabeled gallery in which the person appears in different clothes. Several\nmodels tackle this challenge by extracting clothes-independent features.\nHowever, the performance of these models is still lower for the\nclothes-changing setting compared to the same-clothes setting in which the\nperson appears with the same clothes in the labeled gallery. As\nclothing-related features are often dominant features in the data, we propose a\nnew process we call Gallery Enrichment, to utilize these features. In this\nprocess, we enrich the original gallery by adding to it query samples based on\ntheir face features, using an unsupervised algorithm. Additionally, we show\nthat combining ReID and face feature extraction modules alongside an enriched\ngallery results in a more accurate ReID model, even for query samples with new\noutfits that do not include faces. Moreover, we claim that existing CC-ReID\nbenchmarks do not fully represent real-world scenarios, and propose a new video\nCC-ReID dataset called 42Street, based on a theater play that includes crowded\nscenes and numerous clothes changes. When applied to multiple ReID models, our\nmethod (GEFF) achieves an average improvement of 33.5% and 6.7% in the Top-1\nclothes-changing metric on the PRCC and LTCC benchmarks. Combined with the\nlatest ReID models, our method achieves new SOTA results on the PRCC, LTCC,\nCCVID, LaST and VC-Clothes benchmarks and the proposed 42Street dataset.\n","authors":["Daniel Arkushin","Bar Cohen","Shmuel Peleg","Ohad Fried"],"pdf_url":"https://arxiv.org/pdf/2211.13807v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.12827v3","updated":"2023-11-21T18:43:43Z","published":"2023-05-22T08:39:25Z","title":"Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained\n  Models","summary":"  Task arithmetic has recently emerged as a cost-effective and scalable\napproach to edit pre-trained models directly in weight space: By adding the\nfine-tuned weights of different tasks, the model's performance can be improved\non these tasks, while negating them leads to task forgetting. Yet, our\nunderstanding of the effectiveness of task arithmetic and its underlying\nprinciples remains limited. We present a comprehensive study of task arithmetic\nin vision-language models and show that weight disentanglement is the crucial\nfactor that makes it effective. This property arises during pre-training and\nmanifests when distinct directions in weight space govern separate, localized\nregions in function space associated with the tasks. Notably, we show that\nfine-tuning models in their tangent space by linearizing them amplifies weight\ndisentanglement. This leads to substantial performance improvements across\nmultiple task arithmetic benchmarks and diverse models. Building on these\nfindings, we provide theoretical and empirical analyses of the neural tangent\nkernel (NTK) of these models and establish a compelling link between task\narithmetic and the spatial localization of the NTK eigenfunctions. Overall, our\nwork uncovers novel insights into the fundamental mechanisms of task arithmetic\nand offers a more reliable and effective approach to edit pre-trained models\nthrough the NTK linearization.\n","authors":["Guillermo Ortiz-Jimenez","Alessandro Favero","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2305.12827v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12775v1","updated":"2023-11-21T18:38:03Z","published":"2023-11-21T18:38:03Z","title":"SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh\n  Reconstruction and High-Quality Mesh Rendering","summary":"  We propose a method to allow precise and extremely fast mesh extraction from\n3D Gaussian Splatting. Gaussian Splatting has recently become very popular as\nit yields realistic rendering while being significantly faster to train than\nNeRFs. It is however challenging to extract a mesh from the millions of tiny 3D\ngaussians as these gaussians tend to be unorganized after optimization and no\nmethod has been proposed so far. Our first key contribution is a regularization\nterm that encourages the gaussians to align well with the surface of the scene.\nWe then introduce a method that exploits this alignment to extract a mesh from\nthe Gaussians using Poisson reconstruction, which is fast, scalable, and\npreserves details, in contrast to the Marching Cubes algorithm usually applied\nto extract meshes from Neural SDFs. Finally, we introduce an optional\nrefinement strategy that binds gaussians to the surface of the mesh, and\njointly optimizes these Gaussians and the mesh through Gaussian splatting\nrendering. This enables easy editing, sculpting, rigging, animating,\ncompositing and relighting of the Gaussians using traditional softwares by\nmanipulating the mesh instead of the gaussians themselves. Retrieving such an\neditable mesh for realistic rendering is done within minutes with our method,\ncompared to hours with the state-of-the-art methods on neural SDFs, while\nproviding a better rendering quality.\n","authors":["Antoine Guédon","Vincent Lepetit"],"pdf_url":"https://arxiv.org/pdf/2311.12775v1.pdf","comment":"Project Webpage: https://imagine.enpc.fr/~guedona/sugar/"},{"id":"http://arxiv.org/abs/2311.12773v1","updated":"2023-11-21T18:35:21Z","published":"2023-11-21T18:35:21Z","title":"Iris Presentation Attack: Assessing the Impact of Combining Vanadium\n  Dioxide Films with Artificial Eyes","summary":"  Iris recognition systems, operating in the near infrared spectrum (NIR), have\ndemonstrated vulnerability to presentation attacks, where an adversary uses\nartifacts such as cosmetic contact lenses, artificial eyes or printed iris\nimages in order to circumvent the system. At the same time, a number of\neffective presentation attack detection (PAD) methods have been developed.\nThese methods have demonstrated success in detecting artificial eyes (e.g.,\nfake Van Dyke eyes) as presentation attacks. In this work, we seek to alter the\noptical characteristics of artificial eyes by affixing Vanadium Dioxide (VO2)\nfilms on their surface in various spatial configurations. VO2 films can be used\nto selectively transmit NIR light and can, therefore, be used to regulate the\namount of NIR light from the object that is captured by the iris sensor. We\nstudy the impact of such images produced by the sensor on two state-of-the-art\niris PA detection methods. We observe that the addition of VO2 films on the\nsurface of artificial eyes can cause the PA detection methods to misclassify\nthem as bonafide eyes in some cases. This represents a vulnerability that must\nbe systematically analyzed and effectively addressed.\n","authors":["Darshika Jauhari","Renu Sharma","Cunjian Chen","Nelson Sepulveda","Arun Ross"],"pdf_url":"https://arxiv.org/pdf/2311.12773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.11057v3","updated":"2023-11-21T18:34:09Z","published":"2021-11-22T08:55:25Z","title":"Learning to Aggregate Multi-Scale Context for Instance Segmentation in\n  Remote Sensing Images","summary":"  The task of instance segmentation in remote sensing images, aiming at\nperforming per-pixel labeling of objects at instance level, is of great\nimportance for various civil applications. Despite previous successes, most\nexisting instance segmentation methods designed for natural images encounter\nsharp performance degradations when they are directly applied to top-view\nremote sensing images. Through careful analysis, we observe that the challenges\nmainly come from the lack of discriminative object features due to severe scale\nvariations, low contrasts, and clustered distributions. In order to address\nthese problems, a novel context aggregation network (CATNet) is proposed to\nimprove the feature extraction process. The proposed model exploits three\nlightweight plug-and-play modules, namely dense feature pyramid network\n(DenseFPN), spatial context pyramid (SCP), and hierarchical region of interest\nextractor (HRoIE), to aggregate global visual context at feature, spatial, and\ninstance domains, respectively. DenseFPN is a multi-scale feature propagation\nmodule that establishes more flexible information flows by adopting inter-level\nresidual connections, cross-level dense connections, and feature re-weighting\nstrategy. Leveraging the attention mechanism, SCP further augments the features\nby aggregating global spatial context into local regions. For each instance,\nHRoIE adaptively generates RoI features for different downstream tasks.\nExtensive evaluations of the proposed scheme on iSAID, DIOR, NWPU VHR-10, and\nHRSID datasets demonstrate that the proposed approach outperforms\nstate-of-the-arts under similar computational costs. Source code and\npre-trained models are available at https://github.com/yeliudev/CATNet.\n","authors":["Ye Liu","Huifang Li","Chao Hu","Shuang Luo","Yan Luo","Chang Wen Chen"],"pdf_url":"https://arxiv.org/pdf/2111.11057v3.pdf","comment":"Accepted to IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS), 2023"},{"id":"http://arxiv.org/abs/2311.12770v1","updated":"2023-11-21T18:30:40Z","published":"2023-11-21T18:30:40Z","title":"Swift Parameter-free Attention Network for Efficient Super-Resolution","summary":"  Single Image Super-Resolution (SISR) is a crucial task in low-level computer\nvision, aiming to reconstruct high-resolution images from low-resolution\ncounterparts. Conventional attention mechanisms have significantly improved\nSISR performance but often result in complex network structures and large\nnumber of parameters, leading to slow inference speed and large model size. To\naddress this issue, we propose the Swift Parameter-free Attention Network\n(SPAN), a highly efficient SISR model that balances parameter count, inference\nspeed, and image quality. SPAN employs a novel parameter-free attention\nmechanism, which leverages symmetric activation functions and residual\nconnections to enhance high-contribution information and suppress redundant\ninformation. Our theoretical analysis demonstrates the effectiveness of this\ndesign in achieving the attention mechanism's purpose. We evaluate SPAN on\nmultiple benchmarks, showing that it outperforms existing efficient\nsuper-resolution models in terms of both image quality and inference speed,\nachieving a significant quality-speed trade-off. This makes SPAN highly\nsuitable for real-world applications, particularly in resource-constrained\nscenarios. Notably, our model attains the best PSNR of 27.09 dB, and the test\nruntime of our team is reduced by 7.08ms in the NTIRE 2023 efficient\nsuper-resolution challenge. Our code and models are made publicly available at\n\\url{https://github.com/hongyuanyu/SPAN}.\n","authors":["Cheng Wan","Hongyuan Yu","Zhiqi Li","Yihang Chen","Yajun Zou","Yuqing Liu","Xuanwu Yin","Kunlong Zuo"],"pdf_url":"https://arxiv.org/pdf/2311.12770v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12764v1","updated":"2023-11-21T18:18:50Z","published":"2023-11-21T18:18:50Z","title":"Investigating Weight-Perturbed Deep Neural Networks With Application in\n  Iris Presentation Attack Detection","summary":"  Deep neural networks (DNNs) exhibit superior performance in various machine\nlearning tasks, e.g., image classification, speech recognition, biometric\nrecognition, object detection, etc. However, it is essential to analyze their\nsensitivity to parameter perturbations before deploying them in real-world\napplications. In this work, we assess the sensitivity of DNNs against\nperturbations to their weight and bias parameters. The sensitivity analysis\ninvolves three DNN architectures (VGG, ResNet, and DenseNet), three types of\nparameter perturbations (Gaussian noise, weight zeroing, and weight scaling),\nand two settings (entire network and layer-wise). We perform experiments in the\ncontext of iris presentation attack detection and evaluate on two publicly\navailable datasets: LivDet-Iris-2017 and LivDet-Iris-2020. Based on the\nsensitivity analysis, we propose improved models simply by perturbing\nparameters of the network without undergoing training. We further combine these\nperturbed models at the score-level and at the parameter-level to improve the\nperformance over the original model. The ensemble at the parameter-level shows\nan average improvement of 43.58% on the LivDet-Iris-2017 dataset and 9.25% on\nthe LivDet-Iris-2020 dataset. The source code is available at\n\\href{https://github.com/redwankarimsony/WeightPerturbation-MSU}{https://github.com/redwankarimsony/WeightPerturbation-MSU}.\n","authors":["Renu Sharma","Redwan Sony","Arun Ross"],"pdf_url":"https://arxiv.org/pdf/2311.12764v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12760v1","updated":"2023-11-21T18:11:26Z","published":"2023-11-21T18:11:26Z","title":"High-resolution Image-based Malware Classification using Multiple\n  Instance Learning","summary":"  This paper proposes a novel method of classifying malware into families using\nhigh-resolution greyscale images and multiple instance learning to overcome\nadversarial binary enlargement. Current methods of visualisation-based malware\nclassification largely rely on lossy transformations of inputs such as resizing\nto handle the large, variable-sized images. Through empirical analysis and\nexperimentation, it is shown that these approaches cause crucial information\nloss that can be exploited. The proposed solution divides the images into\npatches and uses embedding-based multiple instance learning with a\nconvolutional neural network and an attention aggregation function for\nclassification. The implementation is evaluated on the Microsoft Malware\nClassification dataset and achieves accuracies of up to $96.6\\%$ on\nadversarially enlarged samples compared to the baseline of $22.8\\%$. The Python\ncode is available online at https://github.com/timppeters/MIL-Malware-Images .\n","authors":["Tim Peters","Hikmat Farhat"],"pdf_url":"https://arxiv.org/pdf/2311.12760v1.pdf","comment":"14 pages, 13 figures, 2 tables"},{"id":"http://arxiv.org/abs/2211.09945v7","updated":"2023-11-21T18:03:06Z","published":"2022-11-17T23:42:10Z","title":"VeriCompress: A Tool to Streamline the Synthesis of Verified Robust\n  Compressed Neural Networks from Scratch","summary":"  AI's widespread integration has led to neural networks (NNs) deployment on\nedge and similar limited-resource platforms for safety-critical scenarios. Yet,\nNN's fragility raises concerns about reliable inference. Moreover, constrained\nplatforms demand compact networks. This study introduces VeriCompress, a tool\nthat automates the search and training of compressed models with robustness\nguarantees. These models are well-suited for safety-critical applications and\nadhere to predefined architecture and size limitations, making them deployable\non resource-restricted platforms. The method trains models 2-3 times faster\nthan the state-of-the-art approaches, surpassing relevant baseline approaches\nby average accuracy and robustness gains of 15.1 and 9.8 percentage points,\nrespectively. When deployed on a resource-restricted generic platform, these\nmodels require 5-8 times less memory and 2-4 times less inference time than\nmodels used in verified robustness literature. Our comprehensive evaluation\nacross various model architectures and datasets, including MNIST, CIFAR, SVHN,\nand a relevant pedestrian detection dataset, showcases VeriCompress's capacity\nto identify compressed verified robust models with reduced computation overhead\ncompared to current standards. This underscores its potential as a valuable\ntool for end users, such as developers of safety-critical applications on edge\nor Internet of Things platforms, empowering them to create suitable models for\nsafety-critical, resource-constrained platforms in their respective domains.\n","authors":["Sawinder Kaur","Yi Xiao","Asif Salekin"],"pdf_url":"https://arxiv.org/pdf/2211.09945v7.pdf","comment":"9 pages, 5 tables, 2 figures"},{"id":"http://arxiv.org/abs/2311.12754v1","updated":"2023-11-21T17:59:14Z","published":"2023-11-21T17:59:14Z","title":"SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction","summary":"  3D occupancy prediction is an important task for the robustness of\nvision-centric autonomous driving, which aims to predict whether each point is\noccupied in the surrounding 3D space. Existing methods usually require 3D\noccupancy labels to produce meaningful results. However, it is very laborious\nto annotate the occupancy status of each voxel. In this paper, we propose\nSelfOcc to explore a self-supervised way to learn 3D occupancy using only video\nsequences. We first transform the images into the 3D space (e.g., bird's eye\nview) to obtain 3D representation of the scene. We directly impose constraints\non the 3D representations by treating them as signed distance fields. We can\nthen render 2D images of previous and future frames as self-supervision signals\nto learn the 3D representations. We propose an MVS-embedded strategy to\ndirectly optimize the SDF-induced weights with multiple depth proposals. Our\nSelfOcc outperforms the previous best method SceneRF by 58.7% using a single\nframe as input on SemanticKITTI and is the first self-supervised work that\nproduces reasonable 3D occupancy for surround cameras on Occ3D. SelfOcc\nproduces high-quality depth and achieves state-of-the-art results on novel\ndepth synthesis, monocular depth estimation, and surround-view depth estimation\non the SemanticKITTI, KITTI-2015, and nuScenes, respectively. Code:\nhttps://github.com/huang-yh/SelfOcc.\n","authors":["Yuanhui Huang","Wenzhao Zheng","Borui Zhang","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2311.12754v1.pdf","comment":"Code is available at: https://github.com/huang-yh/SelfOcc"},{"id":"http://arxiv.org/abs/2310.02129v2","updated":"2023-11-21T17:59:04Z","published":"2023-10-03T15:10:46Z","title":"Unveiling the Pitfalls of Knowledge Editing for Large Language Models","summary":"  As the cost associated with fine-tuning Large Language Models (LLMs)\ncontinues to rise, recent research efforts have pivoted towards developing\nmethodologies to edit implicit knowledge embedded within LLMs. Yet, there's\nstill a dark cloud lingering overhead -- will knowledge editing trigger\nbutterfly effect? since it is still unclear whether knowledge editing might\nintroduce side effects that pose potential risks or not. This paper pioneers\nthe investigation into the potential pitfalls associated with knowledge editing\nfor LLMs. To achieve this, we introduce new benchmark datasets and propose\ninnovative evaluation metrics. Our results underline two pivotal concerns: (1)\nKnowledge Conflict: Editing groups of facts that logically clash can magnify\nthe inherent inconsistencies in LLMs-a facet neglected by previous methods. (2)\nKnowledge Distortion: Altering parameters with the aim of editing factual\nknowledge can irrevocably warp the innate knowledge structure of LLMs.\nExperimental results vividly demonstrate that knowledge editing might\ninadvertently cast a shadow of unintended consequences on LLMs, which warrant\nattention and efforts for future works. Code is available at\nhttps://github.com/zjunlp/PitfallsKnowledgeEditing.\n","authors":["Zhoubo Li","Ningyu Zhang","Yunzhi Yao","Mengru Wang","Xi Chen","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2310.02129v2.pdf","comment":"Work in progress, add more experiments"},{"id":"http://arxiv.org/abs/2311.12751v1","updated":"2023-11-21T17:52:30Z","published":"2023-11-21T17:52:30Z","title":"Towards Natural Language-Guided Drones: GeoText-1652 Benchmark with\n  Spatially Relation Matching","summary":"  Drone navigation through natural language commands remains a significant\nchallenge due to the lack of publicly available multi-modal datasets and the\nintricate demands of fine-grained visual-text alignment. In response to this\npressing need, we present a new human-computer interaction annotation benchmark\ncalled GeoText-1652, meticulously curated through a robust Large Language Model\n(LLM)-based data generation framework and the expertise of pre-trained vision\nmodels. This new dataset seamlessly extends the existing image dataset, \\ie,\nUniversity-1652, with spatial-aware text annotations, encompassing intricate\nimage-text-bounding box associations. Besides, we introduce a new optimization\nobjective to leverage fine-grained spatial associations, called blending\nspatial matching, for region-level spatial relation matching. Extensive\nexperiments reveal that our approach maintains an exceptional recall rate under\nvarying description complexities. This underscores the promising potential of\nour approach in elevating drone control and navigation through the seamless\nintegration of natural language commands in real-world scenarios.\n","authors":["Meng Chu","Zhedong Zheng","Wei Ji","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2311.12751v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.06185v2","updated":"2023-11-21T17:42:42Z","published":"2023-11-10T17:06:28Z","title":"An Automated Pipeline for Tumour-Infiltrating Lymphocyte Scoring in\n  Breast Cancer","summary":"  Tumour-infiltrating lymphocytes (TILs) are considered as a valuable\nprognostic markers in both triple-negative and human epidermal growth factor\nreceptor 2 (HER2) positive breast cancer. In this study, we introduce an\ninnovative deep learning pipeline based on the Efficient-UNet architecture to\npredict the TILs score for breast cancer whole-slide images (WSIs). We first\nsegment tumour and stromal regions in order to compute a tumour bulk mask. We\nthen detect TILs within the tumour-associated stroma, generating a TILs score\nby closely mirroring the pathologist's workflow. Our method exhibits\nstate-of-the-art performance in segmenting tumour/stroma areas and TILs\ndetection, as demonstrated by internal cross-validation on the TiGER Challenge\ntraining dataset and evaluation on the final leaderboards. Additionally, our\nTILs score proves competitive in predicting survival outcomes within the same\nchallenge, underscoring the clinical relevance and potential of our automated\nTILs scoring pipeline as a breast cancer prognostic tool.\n","authors":["Adam J Shephard","Mostafa Jahanifar","Ruoyu Wang","Muhammad Dawood","Simon Graham","Kastytis Sidlauskas","Syed Ali Khurram","Nasir M Rajpoot","Shan E Ahmed Raza"],"pdf_url":"https://arxiv.org/pdf/2311.06185v2.pdf","comment":"5 pages, 1 figure, 2 tables"},{"id":"http://arxiv.org/abs/2304.14408v3","updated":"2023-11-21T17:21:28Z","published":"2023-03-16T17:30:51Z","title":"Using Scalable Computer Vision to Automate High-throughput Semiconductor\n  Characterization","summary":"  High-throughput materials synthesis methods have risen in popularity due to\ntheir potential to accelerate the design and discovery of novel functional\nmaterials, such as solution-processed semiconductors. After synthesis, key\nmaterial properties must be measured and characterized to validate discovery\nand provide feedback to optimization cycles. However, with the boom in\ndevelopment of high-throughput synthesis tools that champion production rates\nup to $10^4$ samples per hour with flexible form factors, most sample\ncharacterization methods are either slow (conventional rates of $10^1$ samples\nper hour, approximately 1000x slower) or rigid (e.g., designed for\nstandard-size microplates), resulting in a bottleneck that impedes the\nmaterials-design process. To overcome this challenge, we propose a set of\nautomated material property characterization (autocharacterization) tools that\nleverage the adaptive, parallelizable, and scalable nature of computer vision\nto accelerate the throughput of characterization by 85x compared to the\nnon-automated workflow. We demonstrate a generalizable composition mapping tool\nfor high-throughput synthesized binary material systems as well as two scalable\nautocharacterization algorithms that (1) autonomously compute the band gap of\n200 unique compositions in 6 minutes and (2) autonomously compute the degree of\ndegradation in 200 unique compositions in 20 minutes, generating ultra-high\ncompositional resolution trends of band gap and stability. We demonstrate that\nthe developed band gap and degradation detection autocharacterization methods\nachieve 98.5% accuracy and 96.9% accuracy, respectively, on the\nFA$_{1-x}$MA$_{x}$PbI$_3$, $0\\leq x \\leq 1$ perovskite semiconductor system.\n","authors":["Alexander E. Siemenn","Eunice Aissi","Fang Sheng","Armi Tiihonen","Hamide Kavak","Basita Das","Tonio Buonassisi"],"pdf_url":"https://arxiv.org/pdf/2304.14408v3.pdf","comment":"Manuscript 18 pages; Supplemental 20 pages"},{"id":"http://arxiv.org/abs/2303.17646v2","updated":"2023-11-21T17:07:46Z","published":"2023-03-30T18:23:20Z","title":"XPert: Peripheral Circuit & Neural Architecture Co-search for Area and\n  Energy-efficient Xbar-based Computing","summary":"  The hardware-efficiency and accuracy of Deep Neural Networks (DNNs)\nimplemented on In-memory Computing (IMC) architectures primarily depend on the\nDNN architecture and the peripheral circuit parameters. It is therefore\nessential to holistically co-search the network and peripheral parameters to\nachieve optimal performance. To this end, we propose XPert, which co-searches\nnetwork architecture in tandem with peripheral parameters such as the type and\nprecision of analog-to-digital converters, crossbar column sharing and the\nlayer-specific input precision using an optimization-based design space\nexploration. Compared to VGG16 baselines, XPert achieves 10.24x (4.7x) lower\nEDAP, 1.72x (1.62x) higher TOPS/W,1.93x (3x) higher TOPS/mm2 at 92.46% (56.7%)\naccuracy for CIFAR10 (TinyImagenet) datasets. The code for this paper is\navailable at https://github.com/Intelligent-Computing-Lab-Yale/XPert.\n","authors":["Abhishek Moitra","Abhiroop Bhattacharjee","Youngeun Kim","Priyadarshini Panda"],"pdf_url":"https://arxiv.org/pdf/2303.17646v2.pdf","comment":"Accepted to Design and Automation Conference (DAC)"},{"id":"http://arxiv.org/abs/2311.12722v1","updated":"2023-11-21T16:51:33Z","published":"2023-11-21T16:51:33Z","title":"Attacking Motion Planners Using Adversarial Perception Errors","summary":"  Autonomous driving (AD) systems are often built and tested in a modular\nfashion, where the performance of different modules is measured using\ntask-specific metrics. These metrics should be chosen so as to capture the\ndownstream impact of each module and the performance of the system as a whole.\nFor example, high perception quality should enable prediction and planning to\nbe performed safely. Even though this is true in general, we show here that it\nis possible to construct planner inputs that score very highly on various\nperception quality metrics but still lead to planning failures. In an analogy\nto adversarial attacks on image classifiers, we call such inputs\n\\textbf{adversarial perception errors} and show they can be systematically\nconstructed using a simple boundary-attack algorithm. We demonstrate the\neffectiveness of this algorithm by finding attacks for two different black-box\nplanners in several urban and highway driving scenarios using the CARLA\nsimulator. Finally, we analyse the properties of these attacks and show that\nthey are isolated in the input space of the planner, and discuss their\nimplications for AD system deployment and testing.\n","authors":["Jonathan Sadeghi","Nicholas A. Lord","John Redford","Romain Mueller"],"pdf_url":"https://arxiv.org/pdf/2311.12722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.05088v3","updated":"2023-11-21T16:35:26Z","published":"2023-04-11T09:31:07Z","title":"WEAR: An Outdoor Sports Dataset for Wearable and Egocentric Activity\n  Recognition","summary":"  Though research has shown the complementarity of camera- and inertial-based\ndata, datasets which offer both egocentric video and inertial-based sensor data\nremain scarce. In this paper, we introduce WEAR, an outdoor sports dataset for\nboth vision- and inertial-based human activity recognition (HAR). The dataset\ncomprises data from 18 participants performing a total of 18 different workout\nactivities with untrimmed inertial (acceleration) and camera (egocentric video)\ndata recorded at 10 different outside locations. Unlike previous egocentric\ndatasets, WEAR provides a challenging prediction scenario marked by purposely\nintroduced activity variations as well as an overall small information overlap\nacross modalities. Benchmark results obtained using each modality separately\nshow that each modality interestingly offers complementary strengths and\nweaknesses in their prediction performance. Further, in light of the recent\nsuccess of temporal action localization models following the architecture\ndesign of the ActionFormer, we demonstrate their versatility by applying them\nin a plain fashion using vision, inertial and combined (vision + inertial)\nfeatures as input. Results demonstrate both the applicability of vision-based\ntemporal action localization models for inertial data and fusing both\nmodalities by means of simple concatenation, with the combined approach (vision\n+ inertial features) being able to produce the highest mean average precision\nand close-to-best F1-score. The dataset and code to reproduce experiments is\npublicly available via: https://mariusbock.github.io/wear/\n","authors":["Marius Bock","Hilde Kuehne","Kristof Van Laerhoven","Michael Moeller"],"pdf_url":"https://arxiv.org/pdf/2304.05088v3.pdf","comment":"15 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2309.12969v2","updated":"2023-11-21T16:27:11Z","published":"2023-09-22T16:07:16Z","title":"Detect Every Thing with Few Examples","summary":"  Open-set object detection aims at detecting arbitrary categories beyond those\nseen during training. Most recent advancements have adopted the open-vocabulary\nparadigm, utilizing vision-language backbones to represent categories with\nlanguage. In this paper, we introduce DE-ViT, an open-set object detector that\nemploys vision-only DINOv2 backbones and learns new categories through example\nimages instead of language. To improve general detection ability, we transform\nmulti-classification tasks into binary classification tasks while bypassing\nper-class inference, and propose a novel region propagation technique for\nlocalization. We evaluate DE-ViT on open-vocabulary, few-shot, and one-shot\nobject detection benchmark with COCO and LVIS. For COCO, DE-ViT outperforms the\nopen-vocabulary SoTA by 6.9 AP50 and achieves 50 AP50 in novel classes. DE-ViT\nsurpasses the few-shot SoTA by 15 mAP on 10-shot and 7.2 mAP on 30-shot and\none-shot SoTA by 2.8 AP50. For LVIS, DE-ViT outperforms the open-vocabulary\nSoTA by 2.2 mask AP and reaches 34.3 mask APr. Code is available at\nhttps://github.com/mlzxy/devit.\n","authors":["Xinyu Zhang","Yuting Wang","Abdeslam Boularias"],"pdf_url":"https://arxiv.org/pdf/2309.12969v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12704v1","updated":"2023-11-21T16:19:14Z","published":"2023-11-21T16:19:14Z","title":"Cascade Learning Localises Discriminant Features in Visual Scene\n  Classification","summary":"  Lack of interpretability of deep convolutional neural networks (DCNN) is a\nwell-known problem particularly in the medical domain as clinicians want\ntrustworthy automated decisions. One way to improve trust is to demonstrate the\nlocalisation of feature representations with respect to expert labeled regions\nof interest. In this work, we investigate the localisation of features learned\nvia two varied learning paradigms and demonstrate the superiority of one\nlearning approach with respect to localisation. Our analysis on medical and\nnatural datasets show that the traditional end-to-end (E2E) learning strategy\nhas a limited ability to localise discriminative features across multiple\nnetwork layers. We show that a layer-wise learning strategy, namely cascade\nlearning (CL), results in more localised features. Considering localisation\naccuracy, we not only show that CL outperforms E2E but that it is a promising\nmethod of predicting regions. On the YOLO object detection framework, our best\nresult shows that CL outperforms the E2E scheme by $2\\%$ in mAP.\n","authors":["Junwen Wang","Katayoun Farrahi"],"pdf_url":"https://arxiv.org/pdf/2311.12704v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08942v2","updated":"2023-11-21T16:14:54Z","published":"2022-11-16T14:44:27Z","title":"Differentially Private Optimizers Can Learn Adversarially Robust Models","summary":"  Machine learning models have shone in a variety of domains and attracted\nincreasing attention from both the security and the privacy communities. One\nimportant yet worrying question is: Will training models under the differential\nprivacy (DP) constraint have an unfavorable impact on their adversarial\nrobustness? While previous works have postulated that privacy comes at the cost\nof worse robustness, we give the first theoretical analysis to show that DP\nmodels can indeed be robust and accurate, even sometimes more robust than their\nnaturally-trained non-private counterparts. We observe three key factors that\ninfluence the privacy-robustness-accuracy tradeoff: (1) hyper-parameters for DP\noptimizers are critical; (2) pre-training on public data significantly\nmitigates the accuracy and robustness drop; (3) choice of DP optimizers makes a\ndifference. With these factors set properly, we achieve 90\\% natural accuracy,\n72\\% robust accuracy ($+9\\%$ than the non-private model) under $l_2(0.5)$\nattack, and 69\\% robust accuracy ($+16\\%$ than the non-private model) with\npre-trained SimCLRv2 model under $l_\\infty(4/255)$ attack on CIFAR10 with\n$\\epsilon=2$. In fact, we show both theoretically and empirically that DP\nmodels are Pareto optimal on the accuracy-robustness tradeoff. Empirically, the\nrobustness of DP models is consistently observed across various datasets and\nmodels. We believe our encouraging results are a significant step towards\ntraining models that are private as well as robust.\n","authors":["Yuan Zhang","Zhiqi Bu"],"pdf_url":"https://arxiv.org/pdf/2211.08942v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.12311v3","updated":"2023-11-21T15:40:54Z","published":"2020-12-22T19:32:52Z","title":"Influencer Videos: Unboxing the Mystique","summary":"  Influencer marketing has become a very popular tool to reach customers.\nDespite the rapid growth in influencer videos, there has been little research\non the effectiveness of their constituent features in explaining video\nengagement. We study YouTube influencers and analyze their unstructured video\ndata across text, audio and images using an \"interpretable deep learning\"\nframework that accomplishes both goals of prediction and interpretation. Our\nprediction-based approach analyzes unstructured data and finds that \"what is\nsaid\" in words (text) is more influential than \"how it is said\" in imagery\n(images) or acoustics (audio). Our novel interpretation-based approach is\nimplemented after completion of model prediction by analyzing the same source\nof unstructured data to measure importance attributed to the video features. We\neliminate several spurious relationships in two steps, identifying a subset of\nrelationships which are confirmed using theory. We uncover novel findings that\nestablish distinct associations for measures of shallow and deep engagement\nbased on the dual-system framework of human thinking. Our approach is validated\nusing simulated data, and we discuss the learnings from our findings for\ninfluencers and brands.\n","authors":["Prashant Rajaram","Puneet Manchanda"],"pdf_url":"https://arxiv.org/pdf/2012.12311v3.pdf","comment":"45 pages, Online Appendix"},{"id":"http://arxiv.org/abs/2311.12682v1","updated":"2023-11-21T15:39:21Z","published":"2023-11-21T15:39:21Z","title":"Transferring to Real-World Layouts: A Depth-aware Framework for Scene\n  Adaptation","summary":"  Scene segmentation via unsupervised domain adaptation (UDA) enables the\ntransfer of knowledge acquired from source synthetic data to real-world target\ndata, which largely reduces the need for manual pixel-level annotations in the\ntarget domain. To facilitate domain-invariant feature learning, existing\nmethods typically mix data from both the source domain and target domain by\nsimply copying and pasting the pixels. Such vanilla methods are usually\nsub-optimal since they do not take into account how well the mixed layouts\ncorrespond to real-world scenarios. Real-world scenarios are with an inherent\nlayout. We observe that semantic categories, such as sidewalks, buildings, and\nsky, display relatively consistent depth distributions, and could be clearly\ndistinguished in a depth map. Based on such observation, we propose a\ndepth-aware framework to explicitly leverage depth estimation to mix the\ncategories and facilitate the two complementary tasks, i.e., segmentation and\ndepth learning in an end-to-end manner. In particular, the framework contains a\nDepth-guided Contextual Filter (DCF) forndata augmentation and a cross-task\nencoder for contextual learning. DCF simulates the real-world layouts, while\nthe cross-task encoder further adaptively fuses the complementing features\nbetween two tasks. Besides, it is worth noting that several public datasets do\nnot provide depth annotation. Therefore, we leverage the off-the-shelf depth\nestimation network to generate the pseudo depth. Extensive experiments show\nthat our proposed methods, even with pseudo depth, achieve competitive\nperformance on two widely-used bench-marks, i.e. 77.7 mIoU on GTA to Cityscapes\nand 69.3 mIoU on Synthia to Cityscapes.\n","authors":["Mu Chen","Zhedong Zheng","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2311.12682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12679v1","updated":"2023-11-21T15:37:19Z","published":"2023-11-21T15:37:19Z","title":"BundleMoCap: Efficient, Robust and Smooth Motion Capture from Sparse\n  Multiview Videos","summary":"  Capturing smooth motions from videos using markerless techniques typically\ninvolves complex processes such as temporal constraints, multiple stages with\ndata-driven regression and optimization, and bundle solving over temporal\nwindows. These processes can be inefficient and require tuning multiple\nobjectives across stages. In contrast, BundleMoCap introduces a novel and\nefficient approach to this problem. It solves the motion capture task in a\nsingle stage, eliminating the need for temporal smoothness objectives while\nstill delivering smooth motions. BundleMoCap outperforms the state-of-the-art\nwithout increasing complexity. The key concept behind BundleMoCap is manifold\ninterpolation between latent keyframes. By relying on a local manifold\nsmoothness assumption, we can efficiently solve a bundle of frames using a\nsingle code. Additionally, the method can be implemented as a sliding window\noptimization and requires only the first frame to be properly initialized,\nreducing the overall computational burden. BundleMoCap's strength lies in its\nability to achieve high-quality motion capture results with simplicity and\nefficiency. More details can be found at https://moverseai.github.io/bundle/.\n","authors":["Georgios Albanis","Nikolaos Zioulis","Kostas Kolomvatsos"],"pdf_url":"https://arxiv.org/pdf/2311.12679v1.pdf","comment":"Published in European Conference on Visual Media Production (CVMP\n  '23)"},{"id":"http://arxiv.org/abs/2311.00187v2","updated":"2023-11-21T15:25:15Z","published":"2023-10-31T23:19:30Z","title":"Decodable and Sample Invariant Continuous Object Encoder","summary":"  We propose Hyper-Dimensional Function Encoding (HDFE). Given samples of a\ncontinuous object (e.g. a function), HDFE produces an explicit vector\nrepresentation of the given object, invariant to the sample distribution and\ndensity. Sample distribution and density invariance enables HDFE to\nconsistently encode continuous objects regardless of their sampling, and\ntherefore allows neural networks to receive continuous objects as inputs for\nmachine learning tasks, such as classification and regression. Besides, HDFE\ndoes not require any training and is proved to map the object into an organized\nembedding space, which facilitates the training of the downstream tasks. In\naddition, the encoding is decodable, which enables neural networks to regress\ncontinuous objects by regressing their encodings. Therefore, HDFE serves as an\ninterface for processing continuous objects.\n  We apply HDFE to function-to-function mapping, where vanilla HDFE achieves\ncompetitive performance as the state-of-the-art algorithm. We apply HDFE to\npoint cloud surface normal estimation, where a simple replacement from PointNet\nto HDFE leads to immediate 12% and 15% error reductions in two benchmarks. In\naddition, by integrating HDFE into the PointNet-based SOTA network, we improve\nthe SOTA baseline by 2.5% and 1.7% in the same benchmarks.\n","authors":["Dehao Yuan","Furong Huang","Cornelia Fermüller","Yiannis Aloimonos"],"pdf_url":"https://arxiv.org/pdf/2311.00187v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2004.07780v5","updated":"2023-11-21T15:22:43Z","published":"2020-04-16T17:18:49Z","title":"Shortcut Learning in Deep Neural Networks","summary":"  Deep learning has triggered the current rise of artificial intelligence and\nis the workhorse of today's machine intelligence. Numerous success stories have\nrapidly spread all over science, industry and society, but its limitations have\nonly recently come into focus. In this perspective we seek to distill how many\nof deep learning's problems can be seen as different symptoms of the same\nunderlying problem: shortcut learning. Shortcuts are decision rules that\nperform well on standard benchmarks but fail to transfer to more challenging\ntesting conditions, such as real-world scenarios. Related issues are known in\nComparative Psychology, Education and Linguistics, suggesting that shortcut\nlearning may be a common characteristic of learning systems, biological and\nartificial alike. Based on these observations, we develop a set of\nrecommendations for model interpretation and benchmarking, highlighting recent\nadvances in machine learning to improve robustness and transferability from the\nlab to real-world applications.\n","authors":["Robert Geirhos","Jörn-Henrik Jacobsen","Claudio Michaelis","Richard Zemel","Wieland Brendel","Matthias Bethge","Felix A. Wichmann"],"pdf_url":"https://arxiv.org/pdf/2004.07780v5.pdf","comment":"perspective article published at Nature Machine Intelligence\n  (https://doi.org/10.1038/s42256-020-00257-z)"},{"id":"http://arxiv.org/abs/2311.12663v1","updated":"2023-11-21T15:13:18Z","published":"2023-11-21T15:13:18Z","title":"Similar Document Template Matching Algorithm","summary":"  This study outlines a comprehensive methodology for verifying medical\ndocuments, integrating advanced techniques in template extraction, comparison,\nand fraud detection. It begins with template extraction using sophisticated\nregion-of-interest (ROI) methods, incorporating contour analysis and edge\nidentification. Pre-processing steps ensure template clarity through\nmorphological operations and adaptive thresholding. The template comparison\nalgorithm utilizes advanced feature matching with key points and descriptors,\nenhancing robustness through histogram-based analysis for accounting\nvariations. Fraud detection involves the SSIM computation and OCR for textual\ninformation extraction. The SSIM quantifies structural similarity, aiding in\npotential match identification. OCR focuses on critical areas like patient\ndetails, provider information, and billing amounts. Extracted information is\ncompared with a reference dataset, and confidence thresholding ensures reliable\nfraud detection. Adaptive parameters enhance system flexibility for dynamic\nadjustments to varying document layouts. This methodology provides a robust\napproach to medical document verification, addressing complexities in template\nextraction, comparison, fraud detection, and adaptability to diverse document\nstructures.\n","authors":["Harshitha Yenigalla","Bommareddy Revanth Srinivasa Reddy","Batta Venkata Rahul","Nannapuraju Hemanth Raju"],"pdf_url":"https://arxiv.org/pdf/2311.12663v1.pdf","comment":"8 pages,8 figures"},{"id":"http://arxiv.org/abs/2311.12660v1","updated":"2023-11-21T15:08:17Z","published":"2023-11-21T15:08:17Z","title":"Visually Guided Object Grasping","summary":"  In this paper we present a visual servoing approach to the problem of object\ngrasping and more generally, to the problem of aligning an end-effector with an\nobject. First we extend the method proposed by Espiau et al. [1] to the case of\na camera which is not mounted onto the robot being controlled and we stress the\nimportance of the real-time estimation of the image Jacobian. Second, we show\nhow to represent a grasp or more generally, an alignment between two solids in\n3-D projective space using an uncalibrated stereo rig. Such a 3-D projective\nrepresentation is view-invariant in the sense that it can be easily mapped into\nan image set-point without any knowledge about the camera parameters. Third, we\nperform an analysis of the performances of the visual servoing algorithm and of\nthe grasping precision that can be expected from this type of approach.\n","authors":["Radu Horaud","Fadi Dornaika","Bernard Espiau"],"pdf_url":"https://arxiv.org/pdf/2311.12660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12655v1","updated":"2023-11-21T14:57:24Z","published":"2023-11-21T14:57:24Z","title":"Hand-Eye Calibration","summary":"  Whenever a sensor is mounted on a robot hand it is important to know the\nrelationship between the sensor and the hand. The problem of determining this\nrelationship is referred to as hand-eye calibration, which is important in at\nleast two types of tasks: (i) map sensor centered measurements into the robot\nworkspace and (ii) allow the robot to precisely move the sensor. In the past\nsome solutions were proposed in the particular case of a camera. With almost no\nexception, all existing solutions attempt to solve the homogeneous matrix\nequation AX=XB. First we show that there are two possible formulations of the\nhand-eye calibration problem. One formulation is the classical one that we just\nmentioned. A second formulation takes the form of the following homogeneous\nmatrix equation: MY=M'YB. The advantage of the latter is that the extrinsic and\nintrinsic camera parameters need not be made explicit. Indeed, this formulation\ndirectly uses the 3 by 4 perspective matrices (M and M') associated with two\npositions of the camera. Moreover, this formulation together with the classical\none cover a wider range of camera-based sensors to be calibrated with respect\nto the robot hand. Second, we develop a common mathematical framework to solve\nfor the hand-eye calibration problem using either of the two formulations. We\npresent two methods, (i) a rotation then translation and (ii) a non-linear\nsolver for rotation and translation. Third, we perform a stability analysis\nboth for our two methods and for the classical linear method developed. In the\nlight of this comparison, the non-linear optimization method, that solves for\nrotation and translation simultaneously, seems to be the most robust one with\nrespect to noise and to measurement errors.\n","authors":["Radu Horaud","Fadi Dornaika"],"pdf_url":"https://arxiv.org/pdf/2311.12655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06504v2","updated":"2023-11-21T14:57:09Z","published":"2023-11-11T08:01:40Z","title":"SCL-VI: Self-supervised Context Learning for Visual Inspection of\n  Industrial Defects","summary":"  The unsupervised visual inspection of defects in industrial products poses a\nsignificant challenge due to substantial variations in product surfaces.\nCurrent unsupervised models struggle to strike a balance between detecting\ntexture and object defects, lacking the capacity to discern latent\nrepresentations and intricate features. In this paper, we present a novel\nself-supervised learning algorithm designed to derive an optimal encoder by\ntackling the renowned jigsaw puzzle. Our approach involves dividing the target\nimage into nine patches, tasking the encoder with predicting the relative\nposition relationships between any two patches to extract rich semantics.\nSubsequently, we introduce an affinity-augmentation method to accentuate\ndifferences between normal and abnormal latent representations. Leveraging the\nclassic support vector data description algorithm yields final detection\nresults. Experimental outcomes demonstrate that our proposed method achieves\noutstanding detection and segmentation performance on the widely used MVTec AD\ndataset, with rates of 95.8% and 96.8%, respectively, establishing a\nstate-of-the-art benchmark for both texture and object defects. Comprehensive\nexperimentation underscores the effectiveness of our approach in diverse\nindustrial applications.\n","authors":["Peng Wang","Haiming Yao","Wenyong Yu"],"pdf_url":"https://arxiv.org/pdf/2311.06504v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12651v1","updated":"2023-11-21T14:53:02Z","published":"2023-11-21T14:53:02Z","title":"Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for\n  Mobile Robots","summary":"  Precise and rapid delineation of sharp boundaries and robust semantics is\nessential for numerous downstream robotic tasks, such as robot grasping and\nmanipulation, real-time semantic mapping, and online sensor calibration\nperformed on edge computing units. Although boundary detection and semantic\nsegmentation are complementary tasks, most studies focus on lightweight models\nfor semantic segmentation but overlook the critical role of boundary detection.\nIn this work, we introduce Mobile-Seed, a lightweight, dual-task framework\ntailored for simultaneous semantic segmentation and boundary detection. Our\nframework features a two-stream encoder, an active fusion decoder (AFD) and a\ndual-task regularization approach. The encoder is divided into two pathways:\none captures category-aware semantic information, while the other discerns\nboundaries from multi-scale features. The AFD module dynamically adapts the\nfusion of semantic and boundary information by learning channel-wise\nrelationships, allowing for precise weight assignment of each channel.\nFurthermore, we introduce a regularization loss to mitigate the conflicts in\ndual-task learning and deep diversity supervision. Compared to existing\nmethods, the proposed Mobile-Seed offers a lightweight framework to\nsimultaneously improve semantic segmentation performance and accurately locate\nobject boundaries. Experiments on the Cityscapes dataset have shown that\nMobile-Seed achieves notable improvement over the state-of-the-art (SOTA)\nbaseline by 2.2 percentage points (pp) in mIoU and 4.2 pp in mF-score, while\nmaintaining an online inference speed of 23.9 frames-per-second (FPS) with\n1024x2048 resolution input on an RTX 2080 Ti GPU. Additional experiments on\nCamVid and PASCAL Context datasets confirm our method's generalizability. Code\nand additional results are publicly available at\n\\url{https://martin-liao.github.io/Mobile-Seed/}.\n","authors":["Youqi Liao","Shuhao Kang","Jianping Li","Yang Liu","Yun Liu","Zhen Dong","Bisheng Yang","Xieyuanli Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12651v1.pdf","comment":"8 pages, IEEE conference/letter underreview. Code and additional\n  results are available at: \\url{https://martin-liao.github.io/Mobile-Seed/}"},{"id":"http://arxiv.org/abs/2311.12641v1","updated":"2023-11-21T14:41:21Z","published":"2023-11-21T14:41:21Z","title":"Polyhedral Object Recognition by Indexing","summary":"  In computer vision, the indexing problem is the problem of recognizing a few\nobjects in a large database of objects while avoiding the help of the classical\nimage-feature-to-object-feature matching paradigm. In this paper we address the\nproblem of recognizing 3-D polyhedral objects from 2-D images by indexing. Both\nthe objects to be recognized and the images are represented by weighted graphs.\nThe indexing problem is therefore the problem of determining whether a graph\nextracted from the image is present or absent in a database of model graphs. We\nintroduce a novel method for performing this graph indexing process which is\nbased both on polynomial characterization of binary and weighted graphs and on\nhashing. We describe in detail this polynomial characterization and then we\nshow how it can be used in the context of polyhedral object recognition. Next\nwe describe a practical recognition-by-indexing system that includes the\norganization of the database, the representation of polyhedral objects in terms\nof 2-D characteristic views, the representation of this views in terms of\nweighted graphs, and the associated image processing. Finally, some\nexperimental results allow the evaluation of the system performance.\n","authors":["Radu Horaud","Humberto Sossa"],"pdf_url":"https://arxiv.org/pdf/2311.12641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12639v1","updated":"2023-11-21T14:39:18Z","published":"2023-11-21T14:39:18Z","title":"KNVQA: A Benchmark for evaluation knowledge-based VQA","summary":"  Within the multimodal field, large vision-language models (LVLMs) have made\nsignificant progress due to their strong perception and reasoning capabilities\nin the visual and language systems. However, LVLMs are still plagued by the two\ncritical issues of object hallucination and factual accuracy, which limit the\npracticality of LVLMs in different scenarios. Furthermore, previous evaluation\nmethods focus more on the comprehension and reasoning of language content but\nlack a comprehensive evaluation of multimodal interactions, thereby resulting\nin potential limitations. To this end, we propose a novel KNVQA-Eval, which is\ndevoted to knowledge-based VQA task evaluation to reflect the factuality of\nmultimodal LVLMs. To ensure the robustness and scalability of the evaluation,\nwe develop a new KNVQA dataset by incorporating human judgment and perception,\naiming to evaluate the accuracy of standard answers relative to AI-generated\nanswers in knowledge-based VQA. This work not only comprehensively evaluates\nthe contextual information of LVLMs using reliable human annotations, but also\nfurther analyzes the fine-grained capabilities of current methods to reveal\npotential avenues for subsequent optimization of LVLMs-based estimators. Our\nproposed VQA-Eval and corresponding dataset KNVQA will facilitate the\ndevelopment of automatic evaluation tools with the advantages of low cost,\nprivacy protection, and reproducibility. Our code will be released upon\npublication.\n","authors":["Sirui Cheng","Siyu Zhang","Jiayi Wu","Muchen Lan"],"pdf_url":"https://arxiv.org/pdf/2311.12639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10122v2","updated":"2023-11-21T14:37:30Z","published":"2023-11-16T10:59:44Z","title":"Video-LLaVA: Learning United Visual Representation by Alignment Before\n  Projection","summary":"  The Large Vision-Language Model (LVLM) has enhanced the performance of\nvarious downstream tasks in visual-language understanding. Most existing\napproaches encode images and videos into separate feature spaces, which are\nthen fed as inputs to large language models. However, due to the lack of\nunified tokenization for images and videos, namely misalignment before\nprojection, it becomes challenging for a Large Language Model (LLM) to learn\nmulti-modal interactions from several poor projection layers. In this work, we\nunify visual representation into the language feature space to advance the\nfoundational LLM towards a unified LVLM. As a result, we establish a simple but\nrobust LVLM baseline, Video-LLaVA, which learns from a mixed dataset of images\nand videos, mutually enhancing each other. Video-LLaVA achieves superior\nperformances on a broad range of 9 image benchmarks across 5 image\nquestion-answering datasets and 4 image benchmark toolkits. Additionally, our\nVideo-LLaVA also outperforms Video-ChatGPT by 5.8%, 9.9%, 18.6%, and 10.1% on\nMSRVTT, MSVD, TGIF, and ActivityNet, respectively. Notably, extensive\nexperiments demonstrate that Video-LLaVA mutually benefits images and videos\nwithin a unified visual representation, outperforming models designed\nspecifically for images or videos. We aim for this work to provide modest\ninsights into the multi-modal inputs for the LLM.\n","authors":["Bin Lin","Yang Ye","Bin Zhu","Jiaxi Cui","Munan Ning","Peng Jin","Li Yuan"],"pdf_url":"https://arxiv.org/pdf/2311.10122v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12631v1","updated":"2023-11-21T14:24:37Z","published":"2023-11-21T14:24:37Z","title":"GPT4Motion: Scripting Physical Motions in Text-to-Video Generation via\n  Blender-Oriented GPT Planning","summary":"  Recent advances in text-to-video generation have harnessed the power of\ndiffusion models to create visually compelling content conditioned on text\nprompts. However, they usually encounter high computational costs and often\nstruggle to produce videos with coherent physical motions. To tackle these\nissues, we propose GPT4Motion, a training-free framework that leverages the\nplanning capability of large language models such as GPT, the physical\nsimulation strength of Blender, and the excellent image generation ability of\ntext-to-image diffusion models to enhance the quality of video synthesis.\nSpecifically, GPT4Motion employs GPT-4 to generate a Blender script based on a\nuser textual prompt, which commands Blender's built-in physics engine to craft\nfundamental scene components that encapsulate coherent physical motions across\nframes. Then these components are inputted into Stable Diffusion to generate a\nvideo aligned with the textual prompt. Experimental results on three basic\nphysical motion scenarios, including rigid object drop and collision, cloth\ndraping and swinging, and liquid flow, demonstrate that GPT4Motion can generate\nhigh-quality videos efficiently in maintaining motion coherency and entity\nconsistency. GPT4Motion offers new insights in text-to-video research,\nenhancing its quality and broadening its horizon for future explorations.\n","authors":["Jiaxi Lv","Yi Huang","Mingfu Yan","Jiancheng Huang","Jianzhuang Liu","Yifan Liu","Yafei Wen","Xiaoxin Chen","Shifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12631v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12623v1","updated":"2023-11-21T14:16:57Z","published":"2023-11-21T14:16:57Z","title":"Bridging Generalization Gaps in High Content Imaging Through Online\n  Self-Supervised Domain Adaptation","summary":"  High Content Imaging (HCI) plays a vital role in modern drug discovery and\ndevelopment pipelines, facilitating various stages from hit identification to\ncandidate drug characterization. Applying machine learning models to these\ndatasets can prove challenging as they typically consist of multiple batches,\naffected by experimental variation, especially if different imaging equipment\nhave been used. Moreover, as new data arrive, it is preferable that they are\nanalyzed in an online fashion. To overcome this, we propose CODA, an online\nself-supervised domain adaptation approach. CODA divides the classifier's role\ninto a generic feature extractor and a task-specific model. We adapt the\nfeature extractor's weights to the new domain using cross-batch\nself-supervision while keeping the task-specific model unchanged. Our results\ndemonstrate that this strategy significantly reduces the generalization gap,\nachieving up to a 300% improvement when applied to data from different labs\nutilizing different microscopes. CODA can be applied to new, unlabeled\nout-of-domain data sources of different sizes, from a single plate to multiple\nexperimental batches.\n","authors":["Johan Fredin Haslum","Christos Matsoukas","Karl-Johan Leuchowius","Kevin Smith"],"pdf_url":"https://arxiv.org/pdf/2311.12623v1.pdf","comment":"IEEE/CVF Winter Conference on Applications of Computer Vision (WACV\n  2024)"},{"id":"http://arxiv.org/abs/2311.12621v1","updated":"2023-11-21T14:12:17Z","published":"2023-11-21T14:12:17Z","title":"Crowd management, crime detection, work monitoring using aiml","summary":"  This research endeavors to harness the potential of existing Closed-Circuit\nTelevision (CCTV) networks for a comprehensive approach to crowd management,\ncrime prevention, and workplace monitoring through the integration of\nArtificial Intelligence (AI) and Machine Learning (ML) technologies. The\nprimary objective is to develop and implement advanced algorithms capable of\nreal-time analysis of video feeds, enabling the identification and assessment\nof crowd dynamics, early detection of potential criminal activities, and\ncontinuous monitoring of workplace environments. By leveraging AI/ML, the\nproject aims to optimize surveillance capabilities, thereby enhancing public\nsafety measures and improving organizational productivity. This initiative\nunderscores the transformative impact that intelligent video analytics can have\non existing infrastructure, mitigating the need for extensive system overhauls\nwhile significantly advancing security and operational efficiency.\n","authors":["P. R. Adithya","Dheepak. S","B. Akash","Harshini. V","Sai Lakshana"],"pdf_url":"https://arxiv.org/pdf/2311.12621v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12617v1","updated":"2023-11-21T14:03:16Z","published":"2023-11-21T14:03:16Z","title":"Leveraging Unlabeled Data for 3D Medical Image Segmentation through\n  Self-Supervised Contrastive Learning","summary":"  Current 3D semi-supervised segmentation methods face significant challenges\nsuch as limited consideration of contextual information and the inability to\ngenerate reliable pseudo-labels for effective unsupervised data use. To address\nthese challenges, we introduce two distinct subnetworks designed to explore and\nexploit the discrepancies between them, ultimately correcting the erroneous\nprediction results. More specifically, we identify regions of inconsistent\npredictions and initiate a targeted verification training process. This\nprocedure strategically fine-tunes and harmonizes the predictions of the\nsubnetworks, leading to enhanced utilization of contextual information.\nFurthermore, to adaptively fine-tune the network's representational capacity\nand reduce prediction uncertainty, we employ a self-supervised contrastive\nlearning paradigm. For this, we use the network's confidence to distinguish\nbetween reliable and unreliable predictions. The model is then trained to\neffectively minimize unreliable predictions. Our experimental results for organ\nsegmentation, obtained from clinical MRI and CT scans, demonstrate the\neffectiveness of our approach when compared to state-of-the-art methods. The\ncodebase is accessible on\n\\href{https://github.com/xmindflow/SSL-contrastive}{GitHub}.\n","authors":["Sanaz Karimijafarbigloo","Reza Azad","Yury Velichko","Ulas Bagci","Dorit Merhof"],"pdf_url":"https://arxiv.org/pdf/2311.12617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.01446v3","updated":"2023-11-21T14:02:33Z","published":"2023-09-04T08:54:20Z","title":"Open Sesame! Universal Black Box Jailbreaking of Large Language Models","summary":"  Large language models (LLMs), designed to provide helpful and safe responses,\noften rely on alignment techniques to align with user intent and social\nguidelines. Unfortunately, this alignment can be exploited by malicious actors\nseeking to manipulate an LLM's outputs for unintended purposes. In this paper\nwe introduce a novel approach that employs a genetic algorithm (GA) to\nmanipulate LLMs when model architecture and parameters are inaccessible. The GA\nattack works by optimizing a universal adversarial prompt that -- when combined\nwith a user's query -- disrupts the attacked model's alignment, resulting in\nunintended and potentially harmful outputs. Our novel approach systematically\nreveals a model's limitations and vulnerabilities by uncovering instances where\nits responses deviate from expected behavior. Through extensive experiments we\ndemonstrate the efficacy of our technique, thus contributing to the ongoing\ndiscussion on responsible AI development by providing a diagnostic tool for\nevaluating and enhancing alignment of LLMs with human intent. To our knowledge\nthis is the first automated universal black box jailbreak attack.\n","authors":["Raz Lapid","Ron Langberg","Moshe Sipper"],"pdf_url":"https://arxiv.org/pdf/2309.01446v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.05858v2","updated":"2023-11-21T13:55:33Z","published":"2023-11-10T03:54:40Z","title":"Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation","summary":"  Given the inevitability of domain shifts during inference in real-world\napplications, test-time adaptation (TTA) is essential for model adaptation\nafter deployment. However, the real-world scenario of continuously changing\ntarget distributions presents challenges including catastrophic forgetting and\nerror accumulation. Existing TTA methods for non-stationary domain shifts,\nwhile effective, incur excessive computational load, making them impractical\nfor on-device settings. In this paper, we introduce a layer-wise auto-weighting\nalgorithm for continual and gradual TTA that autonomously identifies layers for\npreservation or concentrated adaptation. By leveraging the Fisher Information\nMatrix (FIM), we first design the learning weight to selectively focus on\nlayers associated with log-likelihood changes while preserving unrelated ones.\nThen, we further propose an exponential min-max scaler to make certain layers\nnearly frozen while mitigating outliers. This minimizes forgetting and error\naccumulation, leading to efficient adaptation to non-stationary target\ndistribution. Experiments on CIFAR-10C, CIFAR-100C, and ImageNet-C show our\nmethod outperforms conventional continual and gradual TTA approaches while\nsignificantly reducing computational load, highlighting the importance of\nFIM-based learning weight in adapting to continuously or gradually shifting\ntarget domains.\n","authors":["Junyoung Park","Jin Kim","Hyeongjun Kwon","Ilhoon Yoon","Kwanghoon Sohn"],"pdf_url":"https://arxiv.org/pdf/2311.05858v2.pdf","comment":"Accepted to WACV 2024"},{"id":"http://arxiv.org/abs/2311.12610v1","updated":"2023-11-21T13:52:31Z","published":"2023-11-21T13:52:31Z","title":"ChessVision -- A Dataset for Logically Coherent Multi-label\n  Classification","summary":"  Starting with early successes in computer vision tasks, deep learning based\ntechniques have since overtaken state of the art approaches in a multitude of\ndomains. However, it has been demonstrated time and again that these techniques\nfail to capture semantic context and logical constraints, instead often relying\non spurious correlations to arrive at the answer. Since application of deep\nlearning techniques to critical scenarios are dependent on adherence to domain\nspecific constraints, several attempts have been made to address this issue.\nOne limitation holding back a thorough exploration of this area, is a lack of\nsuitable datasets which feature a rich set of rules. In order to address this,\nwe present the ChessVision Dataset, consisting of 200,000+ images of annotated\nchess games in progress, requiring recreation of the game state from its\ncorresponding image. This is accompanied by a curated set of rules which\nconstrains the set of predictions to \"reasonable\" game states, and are designed\nto probe key semantic abilities like localization and enumeration. Alongside\nstandard metrics, additional metrics to measure performance with regards to\nlogical consistency is presented. We analyze several popular and state of the\nart vision models on this task, and show that, although their performance on\nstandard metrics are laudable, they produce a plethora of incoherent results,\nindicating that this dataset presents a significant challenge for future works.\n","authors":["Soumadeep Saha","Utpal Garain"],"pdf_url":"https://arxiv.org/pdf/2311.12610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12608v1","updated":"2023-11-21T13:49:28Z","published":"2023-11-21T13:49:28Z","title":"Adaptive Dense Pseudo Label Selection for Semi-supervised Oriented\n  Object Detection","summary":"  Recently, dense pseudo-label, which directly selects pseudo labels from the\noriginal output of the teacher model without any complicated post-processing\nsteps, has received considerable attention in semi-supervised object detection\n(SSOD). However, for the multi-oriented and dense objects that are common in\naerial scenes, existing dense pseudo-label selection methods are inefficient\nand impede the performance in semi-supervised oriented object detection.\nTherefore, we propose Adaptive Dense Pseudo Label Selection (ADPLS) for\nsemi-supervised oriented object detection. In ADPLS, we design a simple but\neffective adaptive mechanism to guide the selection of dense pseudo labels.\nSpecifically, we propose the mean Feature-Richness Score (mFRS) to estimate the\ndensity of potential objects and use this score to adjust the number of dense\npseudo labels. On the DOTA-v1.5 benchmark, the proposed method outperforms\nprevious methods especially when labeled data are scarce. For example, it\nachieves 49.78 mAP given only 5% of annotated data, which surpasses previous\nstate-of-the-art method given 10% of annotated data by 1.15 mAP. Our codes will\nbe available soon.\n","authors":["Tong Zhao","Qiang Fang","Shuohao Shi","Xin Xu"],"pdf_url":"https://arxiv.org/pdf/2311.12608v1.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2207.04934v2","updated":"2023-11-21T13:46:46Z","published":"2022-07-11T15:15:33Z","title":"Multi-level Geometric Optimization for Regularised Constrained Linear\n  Inverse Problems","summary":"  We present a geometric multilevel optimization approach that smoothly\nincorporates box constraints. Given a box constrained optimization problem, we\nconsider a hierarchy of models with varying discretization levels. Finer models\nare accurate but expensive to compute, while coarser models are less accurate\nbut cheaper to compute. When working at the fine level, multilevel optimisation\ncomputes the search direction based on a coarser model which speeds up updates\nat the fine level. Moreover, exploiting geometry induced by the hierarchy the\nfeasibility of the updates is preserved. In particular, our approach extends\nclassical components of multigrid methods like restriction and prolongation to\nthe Riemannian structure of our constraints.\n","authors":["Sebastian Müller","Stefania Petra","Matthias Zisler"],"pdf_url":"https://arxiv.org/pdf/2207.04934v2.pdf","comment":"25 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.12603v1","updated":"2023-11-21T13:43:16Z","published":"2023-11-21T13:43:16Z","title":"Surgical Temporal Action-aware Network with Sequence Regularization for\n  Phase Recognition","summary":"  To assist surgeons in the operating theatre, surgical phase recognition is\ncritical for developing computer-assisted surgical systems, which requires\ncomprehensive understanding of surgical videos. Although existing studies made\ngreat progress, there are still two significant limitations worthy of\nimprovement. First, due to the compromise of resource consumption, frame-wise\nvisual features are extracted by 2D networks and disregard spatial and temporal\nknowledge of surgical actions, which hinders subsequent inter-frame modeling\nfor phase prediction. Second, these works simply utilize ordinary\nclassification loss with one-hot phase labels to optimize the phase\npredictions, and cannot fully explore surgical videos under inadequate\nsupervision. To overcome these two limitations, we propose a Surgical Temporal\nAction-aware Network with sequence Regularization, named STAR-Net, to recognize\nsurgical phases more accurately from input videos. Specifically, we propose an\nefficient multi-scale surgical temporal action (MS-STA) module, which\nintegrates visual features with spatial and temporal knowledge of surgical\nactions at the cost of 2D networks. Moreover, we devise the dual-classifier\nsequence regularization (DSR) to facilitate the training of STAR-Net by the\nsequence guidance of an auxiliary classifier with a smaller capacity. Our\nSTAR-Net with MS-STA and DSR can exploit visual features of surgical actions\nwith effective regularization, thereby leading to the superior performance of\nsurgical phase recognition. Extensive experiments on a large-scale gastrectomy\nsurgery dataset and the public Cholec80 benchmark prove that our STAR-Net\nsignificantly outperforms state-of-the-arts of surgical phase recognition.\n","authors":["Zhen Chen","Yuhao Zhai","Jun Zhang","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12603v1.pdf","comment":"Accepted by 2023 IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM 2023)"},{"id":"http://arxiv.org/abs/2311.12602v1","updated":"2023-11-21T13:43:06Z","published":"2023-11-21T13:43:06Z","title":"TouchSDF: A DeepSDF Approach for 3D Shape Reconstruction using\n  Vision-Based Tactile Sensing","summary":"  Humans rely on their visual and tactile senses to develop a comprehensive 3D\nunderstanding of their physical environment. Recently, there has been a growing\ninterest in exploring and manipulating objects using data-driven approaches\nthat utilise high-resolution vision-based tactile sensors. However, 3D shape\nreconstruction using tactile sensing has lagged behind visual shape\nreconstruction because of limitations in existing techniques, including the\ninability to generalise over unseen shapes, the absence of real-world testing,\nand limited expressive capacity imposed by discrete representations. To address\nthese challenges, we propose TouchSDF, a Deep Learning approach for tactile 3D\nshape reconstruction that leverages the rich information provided by a\nvision-based tactile sensor and the expressivity of the implicit neural\nrepresentation DeepSDF. Our technique consists of two components: (1) a\nConvolutional Neural Network that maps tactile images into local meshes\nrepresenting the surface at the touch location, and (2) an implicit neural\nfunction that predicts a signed distance function to extract the desired 3D\nshape. This combination allows TouchSDF to reconstruct smooth and continuous 3D\nshapes from tactile inputs in simulation and real-world settings, opening up\nresearch avenues for robust 3D-aware representations and improved multimodal\nperception in robotics. Code and supplementary material are available at:\nhttps://touchsdf.github.io/\n","authors":["Mauro Comi","Yijiong Lin","Alex Church","Alessio Tonioni","Laurence Aitchison","Nathan F. Lepora"],"pdf_url":"https://arxiv.org/pdf/2311.12602v1.pdf","comment":"10 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.12601v1","updated":"2023-11-21T13:42:40Z","published":"2023-11-21T13:42:40Z","title":"Deep learning-based detection of morphological features associated with\n  hypoxia in H&E breast cancer whole slide images","summary":"  Hypoxia occurs when tumour cells outgrow their blood supply, leading to\nregions of low oxygen levels within the tumour. Calculating hypoxia levels can\nbe an important step in understanding the biology of tumours, their clinical\nprogression and response to treatment. This study demonstrates a novel\napplication of deep learning to evaluate hypoxia in the context of breast\ncancer histomorphology. More precisely, we show that Weakly Supervised Deep\nLearning (WSDL) models can accurately detect hypoxia associated features in\nroutine Hematoxylin and Eosin (H&E) whole slide images (WSI). We trained and\nevaluated a deep Multiple Instance Learning model on tiles from WSI H&E tissue\nfrom breast cancer primary sites (n=240) obtaining on average an AUC of 0.87 on\na left-out test set. We also showed significant differences between features of\nhypoxic and normoxic tissue regions as distinguished by the WSDL models. Such\nDL hypoxia H&E WSI detection models could potentially be extended to other\ntumour types and easily integrated into the pathology workflow without\nrequiring additional costly assays.\n","authors":["Petru Manescu","Joseph Geradts","Delmiro Fernandez-Reyes"],"pdf_url":"https://arxiv.org/pdf/2311.12601v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2311.12589v1","updated":"2023-11-21T13:26:13Z","published":"2023-11-21T13:26:13Z","title":"Improving Source-Free Target Adaptation with Vision Transformers\n  Leveraging Domain Representation Images","summary":"  Unsupervised Domain Adaptation (UDA) methods facilitate knowledge transfer\nfrom a labeled source domain to an unlabeled target domain, navigating the\nobstacle of domain shift. While Convolutional Neural Networks (CNNs) are a\nstaple in UDA, the rise of Vision Transformers (ViTs) provides new avenues for\ndomain generalization. This paper presents an innovative method to bolster ViT\nperformance in source-free target adaptation, beginning with an evaluation of\nhow key, query, and value elements affect ViT outcomes. Experiments indicate\nthat altering the key component has negligible effects on Transformer\nperformance. Leveraging this discovery, we introduce Domain Representation\nImages (DRIs), feeding embeddings through the key element. DRIs act as\ndomain-specific markers, effortlessly merging with the training regimen. To\nassess our method, we perform target adaptation tests on the Cross Instance DRI\nsource-only (SO) control. We measure the efficacy of target adaptation with and\nwithout DRIs, against existing benchmarks like SHOT-B* and adaptations via\nCDTrans. Findings demonstrate that excluding DRIs offers limited gains over\nSHOT-B*, while their inclusion in the key segment boosts average precision\npromoting superior domain generalization. This research underscores the vital\nrole of DRIs in enhancing ViT efficiency in UDA scenarios, setting a precedent\nfor further domain adaptation explorations.\n","authors":["Gauransh Sawhney","Daksh Dave","Adeel Ahmed","Jiechao Gao","Khalid Saleem"],"pdf_url":"https://arxiv.org/pdf/2311.12589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12588v1","updated":"2023-11-21T13:21:22Z","published":"2023-11-21T13:21:22Z","title":"HiPose: Hierarchical Binary Surface Encoding and Correspondence Pruning\n  for RGB-D 6DoF Object Pose Estimation","summary":"  In this work, we present a novel dense-correspondence method for 6DoF object\npose estimation from a single RGB-D image. While many existing data-driven\nmethods achieve impressive performance, they tend to be time-consuming due to\ntheir reliance on rendering-based refinement approaches. To circumvent this\nlimitation, we present HiPose, which establishes 3D-3D correspondences in a\ncoarse-to-fine manner with a hierarchical binary surface encoding. Unlike\nprevious dense-correspondence methods, we estimate the correspondence surface\nby employing point-to-surface matching and iteratively constricting the surface\nuntil it becomes a correspondence point while gradually removing outliers.\nExtensive experiments on public benchmarks LM-O, YCB-V, and T-Less demonstrate\nthat our method surpasses all refinement-free methods and is even on par with\nexpensive refinement-based approaches. Crucially, our approach is\ncomputationally efficient and enables real-time critical applications with high\naccuracy requirements. Code and models will be released.\n","authors":["Yongliang Lin","Yongzhi Su","Praveen Nathan","Sandeep Inuganti","Yan Di","Martin Sundermeyer","Fabian Manhardt","Didier Stricke","Jason Rambach","Yu Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12588v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12582v1","updated":"2023-11-21T13:00:03Z","published":"2023-11-21T13:00:03Z","title":"Echocardiogram Foundation Model -- Application 1: Estimating Ejection\n  Fraction","summary":"  Cardiovascular diseases stand as the primary global cause of mortality. Among\nthe various imaging techniques available for visualising the heart and\nevaluating its function, echocardiograms emerge as the preferred choice due to\ntheir safety and low cost. Quantifying cardiac function based on\nechocardiograms is very laborious, time-consuming and subject to high\ninteroperator variability. In this work, we introduce EchoAI, an echocardiogram\nfoundation model, that is trained using self-supervised learning (SSL) on 1.5\nmillion echocardiograms. We evaluate our approach by fine-tuning EchoAI to\nestimate the ejection fraction achieving a mean absolute percentage error of\n9.40%. This level of accuracy aligns with the performance of expert\nsonographers.\n","authors":["Adil Dahlan","Cyril Zakka","Abhinav Kumar","Laura Tang","Rohan Shad","Robyn Fong","William Hiesinger"],"pdf_url":"https://arxiv.org/pdf/2311.12582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12581v1","updated":"2023-11-21T12:56:42Z","published":"2023-11-21T12:56:42Z","title":"A Region of Interest Focused Triple UNet Architecture for Skin Lesion\n  Segmentation","summary":"  Skin lesion segmentation is of great significance for skin lesion analysis\nand subsequent treatment. It is still a challenging task due to the irregular\nand fuzzy lesion borders, and diversity of skin lesions. In this paper, we\npropose Triple-UNet to automatically segment skin lesions. It is an organic\ncombination of three UNet architectures with suitable modules. In order to\nconcatenate the first and second sub-networks more effectively, we design a\nregion of interest enhancement module (ROIE). The ROIE enhances the target\nobject region of the image by using the predicted score map of the first UNet.\nThe features learned by the first UNet and the enhanced image help the second\nUNet obtain a better score map. Finally, the results are fine-tuned by the\nthird UNet. We evaluate our algorithm on a publicly available dataset of skin\nlesion segmentation. Experiments show that Triple-UNet outperforms the\nstate-of-the-art on skin lesion segmentation.\n","authors":["Guoqing Liu","Yu Guo","Caiying Wu","Guoqing Chen","Barintag Saheya","Qiyu Jin"],"pdf_url":"https://arxiv.org/pdf/2311.12581v1.pdf","comment":"15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2212.02081v2","updated":"2023-11-21T12:43:30Z","published":"2022-12-05T07:52:08Z","title":"YolOOD: Utilizing Object Detection Concepts for Multi-Label\n  Out-of-Distribution Detection","summary":"  Out-of-distribution (OOD) detection has attracted a large amount of attention\nfrom the machine learning research community in recent years due to its\nimportance in deployed systems. Most of the previous studies focused on the\ndetection of OOD samples in the multi-class classification task. However, OOD\ndetection in the multi-label classification task, a more common real-world use\ncase, remains an underexplored domain. In this research, we propose YolOOD - a\nmethod that utilizes concepts from the object detection domain to perform OOD\ndetection in the multi-label classification task. Object detection models have\nan inherent ability to distinguish between objects of interest\n(in-distribution) and irrelevant objects (e.g., OOD objects) in images that\ncontain multiple objects belonging to different class categories. These\nabilities allow us to convert a regular object detection model into an image\nclassifier with inherent OOD detection capabilities with just minor changes. We\ncompare our approach to state-of-the-art OOD detection methods and demonstrate\nYolOOD's ability to outperform these methods on a comprehensive suite of\nin-distribution and OOD benchmark datasets.\n","authors":["Alon Zolfi","Guy Amit","Amit Baras","Satoru Koda","Ikuya Morikawa","Yuval Elovici","Asaf Shabtai"],"pdf_url":"https://arxiv.org/pdf/2212.02081v2.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.12562v1","updated":"2023-11-21T12:17:51Z","published":"2023-11-21T12:17:51Z","title":"Multi-Resolution Planar Region Extraction for Uneven Terrains","summary":"  This paper studies the problem of extracting planar regions in uneven\nterrains from unordered point cloud measurements. Such a problem is critical in\nvarious robotic applications such as robotic perceptive locomotion. While\nexisting approaches have shown promising results in effectively extracting\nplanar regions from the environment, they often suffer from issues such as low\ncomputational efficiency or loss of resolution. To address these issues, we\npropose a multi-resolution planar region extraction strategy in this paper that\nbalances the accuracy in boundaries and computational efficiency. Our method\nbegins with a pointwise classification preprocessing module, which categorizes\nall sampled points according to their local geometric properties to facilitate\nmulti-resolution segmentation. Subsequently, we arrange the categorized points\nusing an octree, followed by an in-depth analysis of nodes to finish\nmulti-resolution plane segmentation. The efficiency and robustness of the\nproposed approach are verified via synthetic and real-world experiments,\ndemonstrating our method's ability to generalize effectively across various\nuneven terrains while maintaining real-time performance, achieving frame rates\nexceeding 35 FPS.\n","authors":["Yinghan Sun","Linfang Zheng","Hua Chen","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12562v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12561v1","updated":"2023-11-21T12:15:28Z","published":"2023-11-21T12:15:28Z","title":"Convolutional Neural Networks for Neuroimaging in Parkinson's Disease:\n  Is Preprocessing Needed?","summary":"  Spatial and intensity normalization are nowadays a prerequisite for\nneuroimaging analysis. Influenced by voxel-wise and other univariate\ncomparisons, where these corrections are key, they are commonly applied to any\ntype of analysis and imaging modalities. Nuclear imaging modalities such as\nPET-FDG or FP-CIT SPECT, a common modality used in Parkinson's Disease\ndiagnosis, are especially dependent on intensity normalization. However, these\nsteps are computationally expensive and furthermore, they may introduce\ndeformations in the images, altering the information contained in them.\nConvolutional Neural Networks (CNNs), for their part, introduce position\ninvariance to pattern recognition, and have been proven to classify objects\nregardless of their orientation, size, angle, etc. Therefore, a question\narises: how well can CNNs account for spatial and intensity differences when\nanalysing nuclear brain imaging? Are spatial and intensity normalization still\nneeded? To answer this question, we have trained four different CNN models\nbased on well-established architectures, using or not different spatial and\nintensity normalization preprocessing. The results show that a sufficiently\ncomplex model such as our three-dimensional version of the ALEXNET can\neffectively account for spatial differences, achieving a diagnosis accuracy of\n94.1% with an area under the ROC curve of 0.984. The visualization of the\ndifferences via saliency maps shows that these models are correctly finding\npatterns that match those found in the literature, without the need of applying\nany complex spatial normalization procedure. However, the intensity\nnormalization -- and its type -- is revealed as very influential in the results\nand accuracy of the trained model, and therefore must be well accounted.\n","authors":["Francisco J. Martinez-Murcia","Juan M. Górriz","Javier Ramírez","Andrés Ortiz"],"pdf_url":"https://arxiv.org/pdf/2311.12561v1.pdf","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.12560v1","updated":"2023-11-21T12:12:19Z","published":"2023-11-21T12:12:19Z","title":"Benchmarking bias: Expanding clinical AI model card to incorporate bias\n  reporting of social and non-social factors","summary":"  Clinical AI model reporting cards should be expanded to incorporate a broad\nbias reporting of both social and non-social factors. Non-social factors\nconsider the role of other factors, such as disease dependent, anatomic, or\ninstrument factors on AI model bias, which are essential to ensure safe\ndeployment.\n","authors":["Carolina A. M. Heming","Mohamed Abdalla","Monish Ahluwalia","Linglin Zhang","Hari Trivedi","MinJae Woo","Benjamin Fine","Judy Wawira Gichoya","Leo Anthony Celi","Laleh Seyyed-Kalantari"],"pdf_url":"https://arxiv.org/pdf/2311.12560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12553v1","updated":"2023-11-21T12:05:56Z","published":"2023-11-21T12:05:56Z","title":"\"HoVer-UNet\": Accelerating HoVerNet with UNet-based multi-class nuclei\n  segmentation via knowledge distillation","summary":"  We present \"HoVer-UNet\", an approach to distill the knowledge of the\nmulti-branch HoVerNet framework for nuclei instance segmentation and\nclassification in histopathology. We propose a compact, streamlined single UNet\nnetwork with a Mix Vision Transformer backbone, and equip it with a custom loss\nfunction to optimally encode the distilled knowledge of HoVerNet, reducing\ncomputational requirements without compromising performances. We show that our\nmodel achieved results comparable to HoVerNet on the public PanNuke and Consep\ndatasets with a three-fold reduction in inference time. We make the code of our\nmodel publicly available at https://github.com/DIAGNijmegen/HoVer-UNet.\n","authors":["Cristian Tommasino","Cristiano Russo","Antonio Maria Rinaldi","Francesco Ciompi"],"pdf_url":"https://arxiv.org/pdf/2311.12553v1.pdf","comment":"4 pages, 2 figures, submitted to ISBI 2024"},{"id":"http://arxiv.org/abs/2304.01716v3","updated":"2023-11-21T12:05:50Z","published":"2023-04-04T11:25:44Z","title":"Decoupling Dynamic Monocular Videos for Dynamic View Synthesis","summary":"  The challenge of dynamic view synthesis from dynamic monocular videos, i.e.,\nsynthesizing novel views for free viewpoints given a monocular video of a\ndynamic scene captured by a moving camera, mainly lies in accurately modeling\nthe dynamic objects of a scene using limited 2D frames, each with a varying\ntimestamp and viewpoint. Existing methods usually require pre-processed 2D\noptical flow and depth maps by off-the-shelf methods to supervise the network,\nmaking them suffer from the inaccuracy of the pre-processed supervision and the\nambiguity when lifting the 2D information to 3D. In this paper, we tackle this\nchallenge in an unsupervised fashion. Specifically, we decouple the motion of\nthe dynamic objects into object motion and camera motion, respectively\nregularized by proposed unsupervised surface consistency and patch-based\nmulti-view constraints. The former enforces the 3D geometric surfaces of moving\nobjects to be consistent over time, while the latter regularizes their\nappearances to be consistent across different viewpoints. Such a fine-grained\nmotion formulation can alleviate the learning difficulty for the network, thus\nenabling it to produce not only novel views with higher quality but also more\naccurate scene flows and depth than existing methods requiring extra\nsupervision.\n","authors":["Meng You","Junhui Hou"],"pdf_url":"https://arxiv.org/pdf/2304.01716v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12539v1","updated":"2023-11-21T11:33:15Z","published":"2023-11-21T11:33:15Z","title":"GMISeg: General Medical Image Segmentation without Re-Training","summary":"  Although deep learning models have become the main method for medical image\nsegmentation, they often cannot be extended to unknown segmentation tasks\ninvolving new anatomical structures, image shapes, or labels. For new\nsegmentation tasks, researchers often have to retrain or fine-tune the model,\nwhich is time-consuming and poses a significant obstacle to clinical\nresearchers, who often lack the resources and professional knowledge to train\nneural networks. Therefore, we proposed a general method that can solve unknown\nmedical image segmentation tasks without requiring additional training. Given\nan example set of images and prompts for defining new segmentation tasks,\nGMISeg applies a novel low-rank fine-tuning strategy based on the proposed\napproach to the SAM (Segment Anything Model) image encoder, and works with the\nprompt encoder and mask decoder to fine-tune the labeled dataset without the\nneed for additional training. To achieve generalization of new tasks, we used\nmedical image datasets with different imaging modes for different parts. We\ntrained and generalized GMISeg on a different set of anatomical and imaging\nmodes using cardiac images on other site datasets. We have demonstrated that\nGMISeg outperforms the latest methods on unknown tasks and have conducted a\ncomprehensive analysis and summary of the important performance of the proposed\nmethod.\n","authors":["Jing Xu"],"pdf_url":"https://arxiv.org/pdf/2311.12539v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2304.06131 by other authors"},{"id":"http://arxiv.org/abs/2309.06255v2","updated":"2023-11-21T11:11:57Z","published":"2023-09-12T14:16:34Z","title":"Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation","summary":"  One primary topic of multi-modal learning is to jointly incorporate\nheterogeneous information from different modalities. However, most models often\nsuffer from unsatisfactory multi-modal cooperation, which could not jointly\nutilize all modalities well. Some methods are proposed to identify and enhance\nthe worse learnt modality, but are often hard to provide the fine-grained\nobservation of multi-modal cooperation at sample-level with theoretical\nsupport. Hence, it is essential to reasonably observe and improve the\nfine-grained cooperation between modalities, especially when facing realistic\nscenarios where the modality discrepancy could vary across different samples.\nTo this end, we introduce a fine-grained modality valuation metric to evaluate\nthe contribution of each modality at sample-level. Via modality valuation, we\nregretfully observe that the multi-modal model tends to rely on one specific\nmodality, resulting in other modalities being low-contributing. We further\nanalyze this issue and improve cooperation between modalities by enhancing the\ndiscriminative ability of low-contributing modalities in a targeted manner.\nOverall, our methods reasonably observe the fine-grained uni-modal contribution\nat sample-level and achieve considerable improvement on different multi-modal\nmodels.\n","authors":["Yake Wei","Ruoxuan Feng","Zihe Wang","Di Hu"],"pdf_url":"https://arxiv.org/pdf/2309.06255v2.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2302.10396v3","updated":"2023-11-21T10:56:24Z","published":"2023-02-21T02:07:13Z","title":"Assessing Domain Gap for Continual Domain Adaptation in Object Detection","summary":"  To ensure reliable object detection in autonomous systems, the detector must\nbe able to adapt to changes in appearance caused by environmental factors such\nas time of day, weather, and seasons. Continually adapting the detector to\nincorporate these changes is a promising solution, but it can be\ncomputationally costly. Our proposed approach is to selectively adapt the\ndetector only when necessary, using new data that does not have the same\ndistribution as the current training data. To this end, we investigate three\npopular metrics for domain gap evaluation and find that there is a correlation\nbetween the domain gap and detection accuracy. Therefore, we apply the domain\ngap as a criterion to decide when to adapt the detector. Our experiments show\nthat our approach has the potential to improve the efficiency of the detector's\noperation in real-world scenarios, where environmental conditions change in a\ncyclical manner, without sacrificing the overall performance of the detector.\nOur code is publicly available at https://github.com/dadung/DGE-CDA.\n","authors":["Anh-Dzung Doan","Bach Long Nguyen","Surabhi Gupta","Ian Reid","Markus Wagner","Tat-Jun Chin"],"pdf_url":"https://arxiv.org/pdf/2302.10396v3.pdf","comment":"Accepted to CVIU"},{"id":"http://arxiv.org/abs/2310.00582v2","updated":"2023-11-21T10:32:13Z","published":"2023-10-01T05:53:15Z","title":"Pink: Unveiling the Power of Referential Comprehension for Multi-modal\n  LLMs","summary":"  Multi-modal Large Language Models (MLLMs) have shown remarkable capabilities\nin various multi-modal tasks. Nevertheless, their performance in fine-grained\nimage understanding tasks is still limited. To address this issue, this paper\nproposes a new framework to enhance the fine-grained image understanding\nabilities of MLLMs. Specifically, we present a new method for constructing the\ninstruction tuning dataset at a low cost by leveraging annotations in existing\ndatasets. A self-consistent bootstrapping method is also introduced to extend\nexisting dense object annotations into high-quality\nreferring-expression-bounding-box pairs. These methods enable the generation of\nhigh-quality instruction data which includes a wide range of fundamental\nabilities essential for fine-grained image perception. Moreover, we argue that\nthe visual encoder should be tuned during instruction tuning to mitigate the\ngap between full image perception and fine-grained image perception.\nExperimental results demonstrate the superior performance of our method. For\ninstance, our model exhibits a 5.2% accuracy improvement over Qwen-VL on GQA\nand surpasses the accuracy of Kosmos-2 by 24.7% on RefCOCO_val. We also attain\nthe top rank on the leaderboard of MMBench. This promising performance is\nachieved by training on only publicly available data, making it easily\nreproducible. The models, datasets, and codes are publicly available at\nhttps://github.com/SY-Xuan/Pink.\n","authors":["Shiyu Xuan","Qingpei Guo","Ming Yang","Shiliang Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.00582v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05258v3","updated":"2023-11-21T10:30:07Z","published":"2022-12-10T10:19:53Z","title":"Image augmentation with conformal mappings for a convolutional neural\n  network","summary":"  For augmentation of the square-shaped image data of a convolutional neural\nnetwork (CNN), we introduce a new method, in which the original images are\nmapped onto a disk with a conformal mapping, rotated around the center of this\ndisk and mapped under such a M\\\"obius transformation that preserves the disk,\nand then mapped back onto their original square shape. This process does not\nresult the loss of information caused by removing areas from near the edges of\nthe original images unlike the typical transformations used in the data\naugmentation for a CNN. We offer here the formulas of all the mappings needed\ntogether with detailed instructions how to write a code for transforming the\nimages. The new method is also tested with simulated data and, according the\nresults, using this method to augment the training data of 10 images into 40\nimages decreases the amount of the error in the predictions by a CNN for a test\nset of 160 images in a statistically significant way (p-value=0.0360).\n","authors":["Oona Rainio","Mohamed M. S. Nasser","Matti Vuorinen","Riku Klén"],"pdf_url":"https://arxiv.org/pdf/2212.05258v3.pdf","comment":"14 pages, 3 figures"},{"id":"http://arxiv.org/abs/2305.05546v2","updated":"2023-11-21T10:02:03Z","published":"2023-05-09T15:32:50Z","title":"ColonMapper: topological mapping and localization for colonoscopy","summary":"  We propose a topological mapping and localization system able to operate on\nreal human colonoscopies, despite significant shape and illumination changes.\nThe map is a graph where each node codes a colon location by a set of real\nimages, while edges represent traversability between nodes. For close-in-time\nimages, where scene changes are minor, place recognition can be successfully\nmanaged with the recent transformers-based local feature matching algorithms.\nHowever, under long-term changes -- such as different colonoscopies of the same\npatient -- feature-based matching fails. To address this, we train on real\ncolonoscopies a deep global descriptor achieving high recall with significant\nchanges in the scene. The addition of a Bayesian filter boosts the accuracy of\nlong-term place recognition, enabling relocalization in a previously built map.\nOur experiments show that ColonMapper is able to autonomously build a map and\nlocalize against it in two important use cases: localization within the same\ncolonoscopy or within different colonoscopies of the same patient. Code will be\navailable upon acceptance.\n","authors":["Javier Morlana","Juan D. Tardós","J. M. M. Montiel"],"pdf_url":"https://arxiv.org/pdf/2305.05546v2.pdf","comment":"Under review. ICRA 2024"},{"id":"http://arxiv.org/abs/2311.12490v1","updated":"2023-11-21T10:01:08Z","published":"2023-11-21T10:01:08Z","title":"Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields","summary":"  Recent advances in Neural radiance fields (NeRF) have enabled high-fidelity\nscene reconstruction for novel view synthesis. However, NeRF requires hundreds\nof network evaluations per pixel to approximate a volume rendering integral,\nmaking it slow to train. Caching NeRFs into explicit data structures can\neffectively enhance rendering speed but at the cost of higher memory usage. To\naddress these issues, we present Hyb-NeRF, a novel neural radiance field with a\nmulti-resolution hybrid encoding that achieves efficient neural modeling and\nfast rendering, which also allows for high-quality novel view synthesis. The\nkey idea of Hyb-NeRF is to represent the scene using different encoding\nstrategies from coarse-to-fine resolution levels. Hyb-NeRF exploits\nmemory-efficiency learnable positional features at coarse resolutions and the\nfast optimization speed and local details of hash-based feature grids at fine\nresolutions. In addition, to further boost performance, we embed cone\ntracing-based features in our learnable positional encoding that eliminates\nencoding ambiguity and reduces aliasing artifacts. Extensive experiments on\nboth synthetic and real-world datasets show that Hyb-NeRF achieves faster\nrendering speed with better rending quality and even a lower memory footprint\nin comparison to previous state-of-the-art methods.\n","authors":["Yifan Wang","Yi Gong","Yuan Zeng"],"pdf_url":"https://arxiv.org/pdf/2311.12490v1.pdf","comment":"WACV2024"},{"id":"http://arxiv.org/abs/2311.12486v1","updated":"2023-11-21T09:58:39Z","published":"2023-11-21T09:58:39Z","title":"HCA-Net: Hierarchical Context Attention Network for Intervertebral Disc\n  Semantic Labeling","summary":"  Accurate and automated segmentation of intervertebral discs (IVDs) in medical\nimages is crucial for assessing spine-related disorders, such as osteoporosis,\nvertebral fractures, or IVD herniation. We present HCA-Net, a novel contextual\nattention network architecture for semantic labeling of IVDs, with a special\nfocus on exploiting prior geometric information. Our approach excels at\nprocessing features across different scales and effectively consolidating them\nto capture the intricate spatial relationships within the spinal cord. To\nachieve this, HCA-Net models IVD labeling as a pose estimation problem, aiming\nto minimize the discrepancy between each predicted IVD location and its\ncorresponding actual joint location. In addition, we introduce a skeletal loss\nterm to reinforce the model's geometric dependence on the spine. This loss\nfunction is designed to constrain the model's predictions to a range that\nmatches the general structure of the human vertebral skeleton. As a result, the\nnetwork learns to reduce the occurrence of false predictions and adaptively\nimproves the accuracy of IVD location estimation. Through extensive\nexperimental evaluation on multi-center spine datasets, our approach\nconsistently outperforms previous state-of-the-art methods on both MRI T1w and\nT2w modalities. The codebase is accessible to the public on\n\\href{https://github.com/xmindflow/HCA-Net}{GitHub}.\n","authors":["Afshin Bozorgpour","Bobby Azad","Reza Azad","Yury Velichko","Ulas Bagci","Dorit Merhof"],"pdf_url":"https://arxiv.org/pdf/2311.12486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04071v2","updated":"2023-11-21T09:58:34Z","published":"2023-11-07T15:35:56Z","title":"Energy-Calibrated VAE with Test Time Free Lunch","summary":"  In this paper, we propose a novel generative model that utilizes a\nconditional Energy-Based Model (EBM) for enhancing Variational Autoencoder\n(VAE), termed Energy-Calibrated VAE (EC-VAE). Specifically, VAEs often suffer\nfrom blurry generated samples due to the lack of a tailored training on the\nsamples generated in the generative direction. On the other hand, EBMs can\ngenerate high-quality samples but require expensive Markov Chain Monte Carlo\n(MCMC) sampling. To address these issues, we introduce a conditional EBM for\ncalibrating the generative direction of VAE during training, without requiring\nit for the generation at test time. In particular, we train EC-VAE upon both\nthe input data and the calibrated samples with adaptive weight to enhance\nefficacy while avoiding MCMC sampling at test time. Furthermore, we extend the\ncalibration idea of EC-VAE to variational learning and normalizing flows, and\napply EC-VAE to an additional application of zero-shot image restoration via\nneural transport prior and range-null theory. We evaluate the proposed method\nwith two applications, including image generation and zero-shot image\nrestoration, and the experimental results show that our method achieves the\nstate-of-the-art performance over single-step non-adversarial generation.\n","authors":["Yihong Luo","Siya Qiu","Xingjian Tao","Yujun Cai","Jing Tang"],"pdf_url":"https://arxiv.org/pdf/2311.04071v2.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2311.12480v1","updated":"2023-11-21T09:44:33Z","published":"2023-11-21T09:44:33Z","title":"Speaker-Adapted End-to-End Visual Speech Recognition for Continuous\n  Spanish","summary":"  Different studies have shown the importance of visual cues throughout the\nspeech perception process. In fact, the development of audiovisual approaches\nhas led to advances in the field of speech technologies. However, although\nnoticeable results have recently been achieved, visual speech recognition\nremains an open research problem. It is a task in which, by dispensing with the\nauditory sense, challenges such as visual ambiguities and the complexity of\nmodeling silence must be faced. Nonetheless, some of these challenges can be\nalleviated when the problem is approached from a speaker-dependent perspective.\nThus, this paper studies, using the Spanish LIP-RTVE database, how the\nestimation of specialized end-to-end systems for a specific person could affect\nthe quality of speech recognition. First, different adaptation strategies based\non the fine-tuning technique were proposed. Then, a pre-trained CTC/Attention\narchitecture was used as a baseline throughout our experiments. Our findings\nshowed that a two-step fine-tuning process, where the VSR system is first\nadapted to the task domain, provided significant improvements when the speaker\nadaptation was addressed. Furthermore, results comparable to the current state\nof the art were reached even when only a limited amount of data was available.\n","authors":["David Gimeno-Gómez","Carlos-D. Martínez-Hinarejos"],"pdf_url":"https://arxiv.org/pdf/2311.12480v1.pdf","comment":"Accepted in Proceedings of IberSpeech 2022 (\n  https://www.isca-speech.org/archive/iberspeech_2022/gimenogomez22_iberspeech.html\n  )"},{"id":"http://arxiv.org/abs/2211.15513v2","updated":"2023-11-21T09:42:12Z","published":"2022-11-25T09:41:07Z","title":"Composite Score for Anomaly Detection in Imbalanced Real-World\n  Industrial Dataset","summary":"  In recent years, the industrial sector has evolved towards its fourth\nrevolution. The quality control domain is particularly interested in advanced\nmachine learning for computer vision anomaly detection. Nevertheless, several\nchallenges have to be faced, including imbalanced datasets, the image\ncomplexity, and the zero-false-negative (ZFN) constraint to guarantee the\nhigh-quality requirement. This paper illustrates a use case for an industrial\npartner, where Printed Circuit Board Assembly (PCBA) images are first\nreconstructed with a Vector Quantized Generative Adversarial Network (VQGAN)\ntrained on normal products. Then, several multi-level metrics are extracted on\na few normal and abnormal images, highlighting anomalies through reconstruction\ndifferences. Finally, a classifer is trained to build a composite anomaly score\nthanks to the metrics extracted. This three-step approach is performed on the\npublic MVTec-AD datasets and on the partner PCBA dataset, where it achieves a\nregular accuracy of 95.69% and 87.93% under the ZFN constraint.\n","authors":["Arnaud Bougaham","Mohammed El Adoui","Isabelle Linden","Benoît Frénay"],"pdf_url":"https://arxiv.org/pdf/2211.15513v2.pdf","comment":"This version of the article has been accepted for publication, after\n  peer review and is subject to Springer Nature AM terms of use, but is not the\n  Version of Record and does not reflect post-acceptance improvements, or any\n  corrections. The Version of Record is available online at:\n  https://doi.org/10.1007/s10994-023-06415-9"},{"id":"http://arxiv.org/abs/2306.00917v2","updated":"2023-11-21T09:38:21Z","published":"2023-06-01T17:19:43Z","title":"Vocabulary-free Image Classification","summary":"  Recent advances in large vision-language models have revolutionized the image\nclassification paradigm. Despite showing impressive zero-shot capabilities, a\npre-defined set of categories, a.k.a. the vocabulary, is assumed at test time\nfor composing the textual prompts. However, such assumption can be impractical\nwhen the semantic context is unknown and evolving. We thus formalize a novel\ntask, termed as Vocabulary-free Image Classification (VIC), where we aim to\nassign to an input image a class that resides in an unconstrained\nlanguage-induced semantic space, without the prerequisite of a known\nvocabulary. VIC is a challenging task as the semantic space is extremely large,\ncontaining millions of concepts, with hard-to-discriminate fine-grained\ncategories. In this work, we first empirically verify that representing this\nsemantic space by means of an external vision-language database is the most\neffective way to obtain semantically relevant content for classifying the\nimage. We then propose Category Search from External Databases (CaSED), a\nmethod that exploits a pre-trained vision-language model and an external\nvision-language database to address VIC in a training-free manner. CaSED first\nextracts a set of candidate categories from captions retrieved from the\ndatabase based on their semantic similarity to the image, and then assigns to\nthe image the best matching candidate category according to the same\nvision-language model. Experiments on benchmark datasets validate that CaSED\noutperforms other complex vision-language frameworks, while being efficient\nwith much fewer parameters, paving the way for future research in this\ndirection.\n","authors":["Alessandro Conti","Enrico Fini","Massimiliano Mancini","Paolo Rota","Yiming Wang","Elisa Ricci"],"pdf_url":"https://arxiv.org/pdf/2306.00917v2.pdf","comment":"Accepted at NeurIPS2023, 19 pages, 8 figures, code is available at\n  https://github.com/altndrr/vic"},{"id":"http://arxiv.org/abs/2311.12476v1","updated":"2023-11-21T09:37:49Z","published":"2023-11-21T09:37:49Z","title":"MaskFlow: Object-Aware Motion Estimation","summary":"  We introduce a novel motion estimation method, MaskFlow, that is capable of\nestimating accurate motion fields, even in very challenging cases with small\nobjects, large displacements and drastic appearance changes. In addition to\nlower-level features, that are used in other Deep Neural Network (DNN)-based\nmotion estimation methods, MaskFlow draws from object-level features and\nsegmentations. These features and segmentations are used to approximate the\nobjects' translation motion field. We propose a novel and effective way of\nincorporating the incomplete translation motion field into a subsequent motion\nestimation network for refinement and completion. We also produced a new\nchallenging synthetic dataset with motion field ground truth, and also provide\nextra ground truth for the object-instance matchings and corresponding\nsegmentation masks. We demonstrate that MaskFlow outperforms state of the art\nmethods when evaluated on our new challenging dataset, whilst still producing\ncomparable results on the popular FlyingThings3D benchmark dataset.\n","authors":["Aria Ahmadi","David R. Walton","Tim Atherton","Cagatay Dikici"],"pdf_url":"https://arxiv.org/pdf/2311.12476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12468v1","updated":"2023-11-21T09:28:00Z","published":"2023-11-21T09:28:00Z","title":"Analysis of Visual Features for Continuous Lipreading in Spanish","summary":"  During a conversation, our brain is responsible for combining information\nobtained from multiple senses in order to improve our ability to understand the\nmessage we are perceiving. Different studies have shown the importance of\npresenting visual information in these situations. Nevertheless, lipreading is\na complex task whose objective is to interpret speech when audio is not\navailable. By dispensing with a sense as crucial as hearing, it will be\nnecessary to be aware of the challenge that this lack presents. In this paper,\nwe propose an analysis of different speech visual features with the intention\nof identifying which of them is the best approach to capture the nature of lip\nmovements for natural Spanish and, in this way, dealing with the automatic\nvisual speech recognition task. In order to estimate our system, we present an\naudiovisual corpus compiled from a subset of the RTVE database, which has been\nused in the Albayz\\'in evaluations. We employ a traditional system based on\nHidden Markov Models with Gaussian Mixture Models. Results show that, although\nthe task is difficult, in restricted conditions we obtain recognition results\nwhich determine that using eigenlips in combination with deep features is the\nbest visual approach.\n","authors":["David Gimeno-Gómez","Carlos-D. Martínez-Hinarejos"],"pdf_url":"https://arxiv.org/pdf/2311.12468v1.pdf","comment":"Accepted in Proceedings of IberSpeech 2020 (\n  https://www.isca-speech.org/archive/iberspeech_2021/gimenogomez21_iberspeech.html\n  )"},{"id":"http://arxiv.org/abs/2311.12467v1","updated":"2023-11-21T09:27:30Z","published":"2023-11-21T09:27:30Z","title":"GLAD: Global-Local View Alignment and Background Debiasing for\n  Unsupervised Video Domain Adaptation with Large Domain Gap","summary":"  In this work, we tackle the challenging problem of unsupervised video domain\nadaptation (UVDA) for action recognition. We specifically focus on scenarios\nwith a substantial domain gap, in contrast to existing works primarily deal\nwith small domain gaps between labeled source domains and unlabeled target\ndomains. To establish a more realistic setting, we introduce a novel UVDA\nscenario, denoted as Kinetics->BABEL, with a more considerable domain gap in\nterms of both temporal dynamics and background shifts. To tackle the temporal\nshift, i.e., action duration difference between the source and target domains,\nwe propose a global-local view alignment approach. To mitigate the background\nshift, we propose to learn temporal order sensitive representations by temporal\norder learning and background invariant representations by background\naugmentation. We empirically validate that the proposed method shows\nsignificant improvement over the existing methods on the Kinetics->BABEL\ndataset with a large domain gap. The code is available at\nhttps://github.com/KHUVLL/GLAD.\n","authors":["Hyogun Lee","Kyungho Bae","Seongjong Ha","Yumin Ko","Gyeongmoon Park","Jinwoo Choi"],"pdf_url":"https://arxiv.org/pdf/2311.12467v1.pdf","comment":"This is an accepted WACV 2024 paper"},{"id":"http://arxiv.org/abs/2309.00018v2","updated":"2023-11-21T09:22:28Z","published":"2023-08-31T07:53:02Z","title":"Unsupervised discovery of Interpretable Visual Concepts","summary":"  Providing interpretability of deep-learning models to non-experts, while\nfundamental for a responsible real-world usage, is challenging. Attribution\nmaps from xAI techniques, such as Integrated Gradients, are a typical example\nof a visualization technique containing a high level of information, but with\ndifficult interpretation. In this paper, we propose two methods, Maximum\nActivation Groups Extraction (MAGE) and Multiscale Interpretable Visualization\n(Ms-IV), to explain the model's decision, enhancing global interpretability.\nMAGE finds, for a given CNN, combinations of features which, globally, form a\nsemantic meaning, that we call concepts. We group these similar feature\npatterns by clustering in ``concepts'', that we visualize through Ms-IV. This\nlast method is inspired by Occlusion and Sensitivity analysis (incorporating\ncausality), and uses a novel metric, called Class-aware Order Correlation\n(CaOC), to globally evaluate the most important image regions according to the\nmodel's decision space. We compare our approach to xAI methods such as LIME and\nIntegrated Gradients. Experimental results evince the Ms-IV higher localization\nand faithfulness values. Finally, qualitative evaluation of combined MAGE and\nMs-IV demonstrates humans' ability to agree, based on the visualization, with\nthe decision of clusters' concepts; and, to detect, among a given set of\nnetworks, the existence of bias.\n","authors":["Caroline Mazini Rodrigues","Nicolas Boutry","Laurent Najman"],"pdf_url":"https://arxiv.org/pdf/2309.00018v2.pdf","comment":null},{"id":"http://arxiv.org/abs/1810.12813v3","updated":"2023-11-21T09:19:21Z","published":"2018-10-30T15:33:47Z","title":"Contextual Hourglass Network for Semantic Segmentation of High\n  Resolution Aerial Imagery","summary":"  Semantic segmentation for aerial imagery is a challenging and important\nproblem in remotely sensed imagery analysis. In recent years, with the success\nof deep learning, various convolutional neural network (CNN) based models have\nbeen developed. However, due to the varying sizes of the objects and imbalanced\nclass labels, it can be challenging to obtain accurate pixel-wise semantic\nsegmentation results. To address those challenges, we develop a novel semantic\nsegmentation method and call it Contextual Hourglass Network. In our method, in\norder to improve the robustness of the prediction, we design a new contextual\nhourglass module which incorporates attention mechanism on processed\nlow-resolution featuremaps to exploit the contextual semantics. We further\nexploit the stacked encoder-decoder structure by connecting multiple contextual\nhourglass modules from end to end. This architecture can effectively extract\nrich multi-scale features and add more feedback loops for better learning\ncontextual semantics through intermediate supervision. To demonstrate the\nefficacy of our semantic segmentation method, we test it on Potsdam and\nVaihingen datasets. Through the comparisons to other baseline methods, our\nmethod yields the best results on overall performance.\n","authors":["Panfeng Li","Youzuo Lin","Emily Schultz-Fellenz"],"pdf_url":"https://arxiv.org/pdf/1810.12813v3.pdf","comment":"Accepted by ICIP 2019,\n  https://cmsworkshops.com/ICIP2019/Papers/AcceptedPapers.asp"},{"id":"http://arxiv.org/abs/2301.05246v2","updated":"2023-11-21T09:18:52Z","published":"2023-01-12T19:00:27Z","title":"Online Class-Incremental Learning For Real-World Food Classification","summary":"  Food image classification is essential for monitoring health and tracking\ndietary in image-based dietary assessment methods. However, conventional\nsystems often rely on static datasets with fixed classes and uniform\ndistribution. In contrast, real-world food consumption patterns, shaped by\ncultural, economic, and personal influences, involve dynamic and evolving data.\nThus, require the classification system to cope with continuously evolving\ndata. Online Class Incremental Learning (OCIL) addresses the challenge of\nlearning continuously from a single-pass data stream while adapting to the new\nknowledge and reducing catastrophic forgetting. Experience Replay (ER) based\nOCIL methods store a small portion of previous data and have shown encouraging\nperformance. However, most existing OCIL works assume that the distribution of\nencountered data is perfectly balanced, which rarely happens in real-world\nscenarios. In this work, we explore OCIL for real-world food image\nclassification by first introducing a probabilistic framework to simulate\nrealistic food consumption scenarios. Subsequently, we present an attachable\nDynamic Model Update (DMU) module designed for existing ER methods, which\nenables the selection of relevant images for model training, addressing\nchallenges arising from data repetition and imbalanced sample occurrences\ninherent in realistic food consumption patterns within the OCIL framework. Our\nperformance evaluation demonstrates significant enhancements compared to\nestablished ER methods, showing great potential for lifelong learning in\nreal-world food image classification scenarios. The code of our method is\npublicly accessible at\n\\href{https://gitlab.com/viper-purdue/OCIL-real-world-food-image-classification}{https://gitlab.com/viper-purdue/OCIL-real-world-food-image-classification}\n","authors":["Siddeshwar Raghavan","Jiangpeng He","Fengqing Zhu"],"pdf_url":"https://arxiv.org/pdf/2301.05246v2.pdf","comment":"Accepted at IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV 2024)"},{"id":"http://arxiv.org/abs/2311.12461v1","updated":"2023-11-21T09:15:24Z","published":"2023-11-21T09:15:24Z","title":"HiFi-Syn: Hierarchical Granularity Discrimination for High-Fidelity\n  Synthesis of MR Images with Structure Preservation","summary":"  Synthesizing medical images while preserving their structural information is\ncrucial in medical research. In such scenarios, the preservation of anatomical\ncontent becomes especially important. Although recent advances have been made\nby incorporating instance-level information to guide translation, these methods\noverlook the spatial coherence of structural-level representation and the\nanatomical invariance of content during translation. To address these issues,\nwe introduce hierarchical granularity discrimination, which exploits various\nlevels of semantic information present in medical images. Our strategy utilizes\nthree levels of discrimination granularity: pixel-level discrimination using a\nBrain Memory Bank, structure-level discrimination on each brain structure with\na re-weighting strategy to focus on hard samples, and global-level\ndiscrimination to ensure anatomical consistency during translation. The image\ntranslation performance of our strategy has been evaluated on three independent\ndatasets (UK Biobank, IXI, and BraTS 2018), and it has outperformed\nstate-of-the-art algorithms. Particularly, our model excels not only in\nsynthesizing normal structures but also in handling abnormal (pathological)\nstructures, such as brain tumors, despite the variations in contrast observed\nacross different imaging modalities due to their pathological characteristics.\nThe diagnostic value of synthesized MR images containing brain tumors has been\nevaluated by radiologists. This indicates that our model may offer an\nalternative solution in scenarios where specific MR modalities of patients are\nunavailable. Extensive experiments further demonstrate the versatility of our\nmethod, providing unique insights into medical image translation.\n","authors":["Ziqi Yu","Botao Zhao","Shengjie Zhang","Xiang Chen","Jianfeng Feng","Tingying Peng","Xiao-Yong Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12457v1","updated":"2023-11-21T09:12:21Z","published":"2023-11-21T09:12:21Z","title":"LIP-RTVE: An Audiovisual Database for Continuous Spanish in the Wild","summary":"  Speech is considered as a multi-modal process where hearing and vision are\ntwo fundamentals pillars. In fact, several studies have demonstrated that the\nrobustness of Automatic Speech Recognition systems can be improved when audio\nand visual cues are combined to represent the nature of speech. In addition,\nVisual Speech Recognition, an open research problem whose purpose is to\ninterpret speech by reading the lips of the speaker, has been a focus of\ninterest in the last decades. Nevertheless, in order to estimate these systems\nin the currently Deep Learning era, large-scale databases are required. On the\nother hand, while most of these databases are dedicated to English, other\nlanguages lack sufficient resources. Thus, this paper presents a\nsemi-automatically annotated audiovisual database to deal with unconstrained\nnatural Spanish, providing 13 hours of data extracted from Spanish television.\nFurthermore, baseline results for both speaker-dependent and\nspeaker-independent scenarios are reported using Hidden Markov Models, a\ntraditional paradigm that has been widely used in the field of Speech\nTechnologies.\n","authors":["David Gimeno-Gómez","Carlos-D. Martínez-Hinarejos"],"pdf_url":"https://arxiv.org/pdf/2311.12457v1.pdf","comment":"Accepted in Proceedings of LREC 2022 (\n  https://aclanthology.org/2022.lrec-1.294 )"},{"id":"http://arxiv.org/abs/2305.18183v2","updated":"2023-11-21T09:11:38Z","published":"2023-05-29T16:20:23Z","title":"On Counterfactual Data Augmentation Under Confounding","summary":"  Counterfactual data augmentation has recently emerged as a method to mitigate\nconfounding biases in the training data. These biases, such as spurious\ncorrelations, arise due to various observed and unobserved confounding\nvariables in the data generation process. In this paper, we formally analyze\nhow confounding biases impact downstream classifiers and present a causal\nviewpoint to the solutions based on counterfactual data augmentation. We\nexplore how removing confounding biases serves as a means to learn invariant\nfeatures, ultimately aiding in generalization beyond the observed data\ndistribution. Additionally, we present a straightforward yet powerful algorithm\nfor generating counterfactual images, which effectively mitigates the influence\nof confounding effects on downstream classifiers. Through experiments on MNIST\nvariants and the CelebA datasets, we demonstrate how our simple augmentation\nmethod helps existing state-of-the-art methods achieve good results.\n","authors":["Abbavaram Gowtham Reddy","Saketh Bachu","Saloni Dash","Charchit Sharma","Amit Sharma","Vineeth N Balasubramanian"],"pdf_url":"https://arxiv.org/pdf/2305.18183v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.13788v2","updated":"2023-11-21T09:08:50Z","published":"2021-09-28T15:07:43Z","title":"PFENet++: Boosting Few-shot Semantic Segmentation with the\n  Noise-filtered Context-aware Prior Mask","summary":"  In this work, we revisit the prior mask guidance proposed in ``Prior Guided\nFeature Enrichment Network for Few-Shot Segmentation''. The prior mask serves\nas an indicator that highlights the region of interests of unseen categories,\nand it is effective in achieving better performance on different frameworks of\nrecent studies. However, the current method directly takes the maximum\nelement-to-element correspondence between the query and support features to\nindicate the probability of belonging to the target class, thus the broader\ncontextual information is seldom exploited during the prior mask generation. To\naddress this issue, first, we propose the Context-aware Prior Mask (CAPM) that\nleverages additional nearby semantic cues for better locating the objects in\nquery images. Second, since the maximum correlation value is vulnerable to\nnoisy features, we take one step further by incorporating a lightweight Noise\nSuppression Module (NSM) to screen out the unnecessary responses, yielding\nhigh-quality masks for providing the prior knowledge. Both two contributions\nare experimentally shown to have substantial practical merit, and the new model\nnamed PFENet++ significantly outperforms the baseline PFENet as well as all\nother competitors on three challenging benchmarks PASCAL-5$^i$, COCO-20$^i$ and\nFSS-1000. The new state-of-the-art performance is achieved without compromising\nthe efficiency, manifesting the potential for being a new strong baseline in\nfew-shot semantic segmentation. Our code will be available at\nhttps://github.com/luoxiaoliu/PFENet2Plus.\n","authors":["Xiaoliu Luo","Zhuotao Tian","Taiping Zhang","Bei Yu","Yuan Yan Tang","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2109.13788v2.pdf","comment":"The first two authors contribute equally and are listed in\n  alphabetical order"},{"id":"http://arxiv.org/abs/2310.08897v2","updated":"2023-11-21T08:51:03Z","published":"2023-10-13T06:58:52Z","title":"Self supervised convolutional kernel based handcrafted feature\n  harmonization: Enhanced left ventricle hypertension disease phenotyping on\n  echocardiography","summary":"  Radiomics, a medical imaging technique, extracts quantitative handcrafted\nfeatures from images to predict diseases. Harmonization in those features\nensures consistent feature extraction across various imaging devices and\nprotocols. Methods for harmonization include standardized imaging protocols,\nstatistical adjustments, and evaluating feature robustness. Myocardial diseases\nsuch as Left Ventricular Hypertrophy (LVH) and Hypertensive Heart Disease (HHD)\nare diagnosed via echocardiography, but variable imaging settings pose\nchallenges. Harmonization techniques are crucial for applying handcrafted\nfeatures in disease diagnosis in such scenario. Self-supervised learning (SSL)\nenhances data understanding within limited datasets and adapts to diverse data\nsettings. ConvNeXt-V2 integrates convolutional layers into SSL, displaying\nsuperior performance in various tasks. This study focuses on convolutional\nfilters within SSL, using them as preprocessing to convert images into feature\nmaps for handcrafted feature harmonization. Our proposed method excelled in\nharmonization evaluation and exhibited superior LVH classification performance\ncompared to existing methods.\n","authors":["Jina Lee","Youngtaek Hong","Dawun Jeong","Yeonggul Jang","Sihyeon Jeong","Taekgeun Jung","Yeonyee E. Yoon","Inki Moon","Seung-Ah Lee","Hyuk-Jae Chang"],"pdf_url":"https://arxiv.org/pdf/2310.08897v2.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2310.19641v2","updated":"2023-11-21T08:49:00Z","published":"2023-10-30T15:29:48Z","title":"DistNet2D: Leveraging long-range temporal information for efficient\n  segmentation and tracking","summary":"  Extracting long tracks and lineages from videomicroscopy requires an\nextremely low error rate, which is challenging on complex datasets of dense or\ndeforming cells. Leveraging temporal context is key to overcoming this\nchallenge. We propose DistNet2D, a new deep neural network (DNN) architecture\nfor 2D cell segmentation and tracking that leverages both mid- and long-term\ntemporal information. DistNet2D considers seven frames at the input and uses a\npost-processing procedure that exploits information from the entire video to\ncorrect segmentation errors. DistNet2D outperforms two recent methods on two\nexperimental datasets, one containing densely packed bacterial cells and the\nother containing eukaryotic cells. It is integrated into an ImageJ-based\ngraphical user interface for 2D data visualization, curation, and training.\nFinally, we demonstrate the performance of DistNet2D on correlating the size\nand shape of cells with their transport properties over large statistics, for\nboth bacterial and eukaryotic cells.\n","authors":["Jean Ollion","Martin Maliet","Caroline Giuglaris","Elise Vacher","Maxime Deforet"],"pdf_url":"https://arxiv.org/pdf/2310.19641v2.pdf","comment":"40 pages, 5 figures, 18 supp figures"},{"id":"http://arxiv.org/abs/2311.12437v1","updated":"2023-11-21T08:47:08Z","published":"2023-11-21T08:47:08Z","title":"Learning Site-specific Styles for Multi-institutional Unsupervised\n  Cross-modality Domain Adaptation","summary":"  Unsupervised cross-modality domain adaptation is a challenging task in\nmedical image analysis, and it becomes more challenging when source and target\ndomain data are collected from multiple institutions. In this paper, we present\nour solution to tackle the multi-institutional unsupervised domain adaptation\nfor the crossMoDA 2023 challenge. First, we perform unpaired image translation\nto translate the source domain images to the target domain, where we design a\ndynamic network to generate synthetic target domain images with controllable,\nsite-specific styles. Afterwards, we train a segmentation model using the\nsynthetic images and further reduce the domain gap by self-training. Our\nsolution achieved the 1st place during both the validation and testing phases\nof the challenge.\n","authors":["Han Liu","Yubo Fan","Zhoubing Xu","Benoit M. Dawant","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2311.12437v1.pdf","comment":"crossMoDA 2023 challenge 1st place solution"},{"id":"http://arxiv.org/abs/2311.12430v1","updated":"2023-11-21T08:42:44Z","published":"2023-11-21T08:42:44Z","title":"AR Visualization System for Ship Detection and Recognition Based on AI","summary":"  Augmented reality technology has been widely used in industrial design\ninteraction, exhibition guide, information retrieval and other fields. The\ncombination of artificial intelligence and augmented reality technology has\nalso become a future development trend. This project is an AR visualization\nsystem for ship detection and recognition based on AI, which mainly includes\nthree parts: artificial intelligence module, Unity development module and\nHololens2AR module. This project is based on R3Det algorithm to complete the\ndetection and recognition of ships in remote sensing images. The recognition\nrate of model detection trained on RTX 2080Ti can reach 96%. Then, the 3D model\nof the ship is obtained by ship categories and information and generated in the\nvirtual scene. At the same time, voice module and UI interaction module are\nadded. Finally, we completed the deployment of the project on Hololens2 through\nMRTK. The system realizes the fusion of computer vision and augmented reality\ntechnology, which maps the results of object detection to the AR field, and\nmakes a brave step toward the future technological trend and intelligent\napplication.\n","authors":["Ziqi Ye","Limin Huang","Yongji Wu","Min Hu"],"pdf_url":"https://arxiv.org/pdf/2311.12430v1.pdf","comment":"4 pages,7 figures,IEEE International Conference on Virtual Reality\n  and Visualization"},{"id":"http://arxiv.org/abs/2311.07784v2","updated":"2023-11-21T08:23:31Z","published":"2023-11-13T22:21:27Z","title":"A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated\n  Class Incremental Learning for Vision Tasks","summary":"  Deep learning models often suffer from forgetting previously learned\ninformation when trained on new data. This problem is exacerbated in federated\nlearning (FL), where the data is distributed and can change independently for\neach user. Many solutions are proposed to resolve this catastrophic forgetting\nin a centralized setting. However, they do not apply directly to FL because of\nits unique complexities, such as privacy concerns and resource limitations. To\novercome these challenges, this paper presents a framework for\n$\\textbf{federated class incremental learning}$ that utilizes a generative\nmodel to synthesize samples from past distributions. This data can be later\nexploited alongside the training data to mitigate catastrophic forgetting. To\npreserve privacy, the generative model is trained on the server using data-free\nmethods at the end of each task without requesting data from clients. Moreover,\nour solution does not demand the users to store old data or models, which gives\nthem the freedom to join/leave the training at any time. Additionally, we\nintroduce SuperImageNet, a new regrouping of the ImageNet dataset specifically\ntailored for federated continual learning. We demonstrate significant\nimprovements compared to existing baselines through extensive experiments on\nmultiple datasets.\n","authors":["Sara Babakniya","Zalan Fabian","Chaoyang He","Mahdi Soltanolkotabi","Salman Avestimehr"],"pdf_url":"https://arxiv.org/pdf/2311.07784v2.pdf","comment":"Accepted in NeurIPS 2023. arXiv admin note: text overlap with\n  arXiv:2307.00497"},{"id":"http://arxiv.org/abs/2311.12421v1","updated":"2023-11-21T08:21:55Z","published":"2023-11-21T08:21:55Z","title":"Two Views Are Better than One: Monocular 3D Pose Estimation with\n  Multiview Consistency","summary":"  Deducing a 3D human pose from a single 2D image or 2D keypoints is inherently\nchallenging, given the fundamental ambiguity wherein multiple 3D poses can\ncorrespond to the same 2D representation. The acquisition of 3D data, while\ninvaluable for resolving pose ambiguity, is expensive and requires an intricate\nsetup, often restricting its applicability to controlled lab environments. We\nimprove performance of monocular human pose estimation models using multiview\ndata for fine-tuning. We propose a novel loss function, multiview consistency,\nto enable adding additional training data with only 2D supervision. This loss\nenforces that the inferred 3D pose from one view aligns with the inferred 3D\npose from another view under similarity transformations. Our consistency loss\nsubstantially improves performance for fine-tuning with no available 3D data.\nOur experiments demonstrate that two views offset by 90 degrees are enough to\nobtain good performance, with only marginal improvements by adding more views.\nThus, we enable the acquisition of domain-specific data by capturing activities\nwith off-the-shelf cameras, eliminating the need for elaborate calibration\nprocedures. This research introduces new possibilities for domain adaptation in\n3D pose estimation, providing a practical and cost-effective solution to\ncustomize models for specific applications. The used dataset, featuring\nadditional views, will be made publicly available.\n","authors":["Christian Keilstrup Ingwersen","Anders Bjorholm Dahl","Janus Nørtoft Jensen","Morten Rieger Hannemose"],"pdf_url":"https://arxiv.org/pdf/2311.12421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12419v1","updated":"2023-11-21T08:16:01Z","published":"2023-11-21T08:16:01Z","title":"Board-to-Board: Evaluating Moonboard Grade Prediction Generalization","summary":"  Bouldering is a sport where athletes aim to climb up an obstacle using a set\nof defined holds called a route. Typically routes are assigned a grade to\ninform climbers of its difficulty and allow them to more easily track their\nprogression. However, the variation in individual climbers technical and\nphysical attributes and many nuances of an individual route make grading a\ndifficult and often biased task. In this work, we apply classical and\ndeep-learning modelling techniques to the 2016, 2017 and 2019 Moonboard\ndatasets, achieving state of the art grade prediction performance with 0.87 MAE\nand 1.12 RMSE. We achieve this performance on a feature-set that does not\nrequire decomposing routes into individual moves, which is a method common in\nliterature and introduces bias. We also demonstrate the generalization\ncapability of this model between editions and introduce a novel vision-based\nmethod of grade prediction. While the generalization performance of these\ntechniques is below human level performance currently, we propose these methods\nas a basis for future work. Such a tool could be implemented in pre-existing\nmobile applications and would allow climbers to better track their progress and\nassess new routes with reduced bias.\n","authors":["Daniel Petashvili","Matthew Rodda"],"pdf_url":"https://arxiv.org/pdf/2311.12419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12407v1","updated":"2023-11-21T07:54:40Z","published":"2023-11-21T07:54:40Z","title":"Learning Part Motion of Articulated Objects Using Spatially Continuous\n  Neural Implicit Representations","summary":"  Articulated objects (e.g., doors and drawers) exist everywhere in our life.\nDifferent from rigid objects, articulated objects have higher degrees of\nfreedom and are rich in geometries, semantics, and part functions. Modeling\ndifferent kinds of parts and articulations with nerual networks plays an\nessential role in articulated object understanding and manipulation, and will\nfurther benefit 3D vision and robotics communities. To model articulated\nobjects, most previous works directly encode articulated objects into feature\nrepresentations, without specific designs for parts, articulations and part\nmotions. In this paper, we introduce a novel framework that explicitly\ndisentangles the part motion of articulated objects by predicting the\ntransformation matrix of points on the part surface, using spatially continuous\nneural implicit representations to model the part motion smoothly in the space.\nMore importantly, while many methods could only model a certain kind of joint\nmotion (such as the revolution in the clockwise order), our proposed framework\nis generic to different kinds of joint motions in that transformation matrix\ncan model diverse kinds of joint motions in the space. Quantitative and\nqualitative results of experiments over diverse categories of articulated\nobjects demonstrate the effectiveness of our proposed framework.\n","authors":["Yushi Du","Ruihai Wu","Yan Shen","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2311.12407v1.pdf","comment":"10 pages, 6 figures. Accepted by BMVC 2023"},{"id":"http://arxiv.org/abs/2311.12401v1","updated":"2023-11-21T07:28:51Z","published":"2023-11-21T07:28:51Z","title":"CASR: Refining Action Segmentation via Magrinalizing Frame-levle Causal\n  Relationships","summary":"  Integrating deep learning and causal discovery has increased the\ninterpretability of Temporal Action Segmentation (TAS) tasks. However,\nframe-level causal relationships exist many complicated noises outside the\nsegment-level, making it infeasible to directly express macro action semantics.\nThus, we propose \\textit{\\textbf{Causal Abstraction Segmentation Refiner\n(CASR)}}, which can refine TAS results from various models by enhancing video\ncausality in marginalizing frame-level casual relationships. Specifically, we\ndefine the equivalent frame-level casual model and segment-level causal model,\nso that the causal adjacency matrix constructed from marginalized frame-level\ncausal relationships has the ability to represent the segmnet-level causal\nrelationships. CASR works out by reducing the difference in the causal\nadjacency matrix between we constructed and pre-segmentation results of\nbackbone models. In addition, we propose a novel evaluation metric Causal Edit\nDistance (CED) to evaluate the causal interpretability. Extensive experimental\nresults on mainstream datasets indicate that CASR significantly surpasses\nexisting various methods in action segmentation performance, as well as in\ncausal explainability and generalization. Our code will be available soon.\n","authors":["Keqing Du","Xinyu Yang","Hang Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12401v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.09112v2","updated":"2023-11-21T07:27:08Z","published":"2023-07-18T10:02:09Z","title":"NU-MCC: Multiview Compressive Coding with Neighborhood Decoder and\n  Repulsive UDF","summary":"  Remarkable progress has been made in 3D reconstruction from single-view RGB-D\ninputs. MCC is the current state-of-the-art method in this field, which\nachieves unprecedented success by combining vision Transformers with\nlarge-scale training. However, we identified two key limitations of MCC: 1) The\nTransformer decoder is inefficient in handling large number of query points; 2)\nThe 3D representation struggles to recover high-fidelity details. In this\npaper, we propose a new approach called NU-MCC that addresses these\nlimitations. NU-MCC includes two key innovations: a Neighborhood decoder and a\nRepulsive Unsigned Distance Function (Repulsive UDF). First, our Neighborhood\ndecoder introduces center points as an efficient proxy of input visual\nfeatures, allowing each query point to only attend to a small neighborhood.\nThis design not only results in much faster inference speed but also enables\nthe exploitation of finer-scale visual features for improved recovery of 3D\ntextures. Second, our Repulsive UDF is a novel alternative to the occupancy\nfield used in MCC, significantly improving the quality of 3D object\nreconstruction. Compared to standard UDFs that suffer from holes in results,\nour proposed Repulsive UDF can achieve more complete surface reconstruction.\nExperimental results demonstrate that NU-MCC is able to learn a strong 3D\nrepresentation, significantly advancing the state of the art in single-view 3D\nreconstruction. Particularly, it outperforms MCC by 9.7% in terms of the\nF1-score on the CO3D-v2 dataset with more than 5x faster running speed.\n","authors":["Stefan Lionar","Xiangyu Xu","Min Lin","Gim Hee Lee"],"pdf_url":"https://arxiv.org/pdf/2307.09112v2.pdf","comment":"NeurIPS 2023. Project page: https://numcc.github.io/ Code:\n  https://github.com/sail-sg/numcc"},{"id":"http://arxiv.org/abs/2206.14372v2","updated":"2023-11-21T07:22:04Z","published":"2022-06-29T02:36:53Z","title":"Formalizing and Evaluating Requirements of Perception Systems for\n  Automated Vehicles using Spatio-Temporal Perception Logic","summary":"  Automated vehicles (AV) heavily depend on robust perception systems. Current\nmethods for evaluating vision systems focus mainly on frame-by-frame\nperformance. Such evaluation methods appear to be inadequate in assessing the\nperformance of a perception subsystem when used within an AV. In this paper, we\npresent a logic -- referred to as Spatio-Temporal Perception Logic (STPL) --\nwhich utilizes both spatial and temporal modalities. STPL enables reasoning\nover perception data using spatial and temporal operators. One major advantage\nof STPL is that it facilitates basic sanity checks on the functional\nperformance of the perception system, even without ground-truth data in some\ncases. We identify a fragment of STPL which is efficiently monitorable offline\nin polynomial time. Finally, we present a range of specifications for AV\nperception systems to highlight the types of requirements that can be expressed\nand analyzed through offline monitoring with STPL.\n","authors":["Mohammad Hekmatnejad","Bardh Hoxha","Jyotirmoy V. Deshmukh","Yezhou Yang","Georgios Fainekos"],"pdf_url":"https://arxiv.org/pdf/2206.14372v2.pdf","comment":"32 pages, 11 figures, 6 tables, 4 algorithms, 2 appendixes"},{"id":"http://arxiv.org/abs/2304.07647v2","updated":"2023-11-21T07:21:50Z","published":"2023-04-15T22:24:05Z","title":"LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene\n  Graphs with Weak Supervision","summary":"  We propose LASER, a neuro-symbolic approach to learn semantic video\nrepresentations that capture rich spatial and temporal properties in video data\nby leveraging high-level logic specifications. In particular, we formulate the\nproblem in terms of alignment between raw videos and spatio-temporal logic\nspecifications. The alignment algorithm leverages a differentiable symbolic\nreasoner and a combination of contrastive, temporal, and semantics losses. It\neffectively and efficiently trains low-level perception models to extract\nfine-grained video representation in the form of a spatio-temporal scene graph\nthat conforms to the desired high-level specification. In doing so, we explore\na novel methodology that weakly supervises the learning of video semantic\nrepresentations through logic specifications. We evaluate our method on two\ndatasets with rich spatial and temporal specifications:\n20BN-Something-Something and MUGEN. We demonstrate that our method learns\nbetter fine-grained video semantics than existing baselines.\n","authors":["Jiani Huang","Ziyang Li","Mayur Naik","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2304.07647v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.09688v3","updated":"2023-11-21T07:20:50Z","published":"2022-08-20T14:15:35Z","title":"Learning Sub-Pixel Disparity Distribution for Light Field Depth\n  Estimation","summary":"  Light field (LF) depth estimation plays a crucial role in many LF-based\napplications. Existing LF depth estimation methods consider depth estimation as\na regression problem, where a pixel-wise L1 loss is employed to supervise the\ntraining process. However, the disparity map is only a sub-space projection\n(i.e., an expectation) of the disparity distribution, which is essential for\nmodels to learn. In this paper, we propose a simple yet effective method to\nlearn the sub-pixel disparity distribution by fully utilizing the power of deep\nnetworks, especially for LF of narrow baselines. We construct the cost volume\nat the sub-pixel level to produce a finer disparity distribution and design an\nuncertainty-aware focal loss to supervise the predicted disparity distribution\ntoward the ground truth. Extensive experimental results demonstrate the\neffectiveness of our method.Our method significantly outperforms recent\nstate-of-the-art LF depth algorithms on the HCI 4D LF Benchmark in terms of all\nfour accuracy metrics (i.e., BadPix 0.01, BadPix 0.03, BadPix 0.07, and MSE\n$\\times$100). The code and model of the proposed method are available at\n\\url{https://github.com/chaowentao/SubFocal}.\n","authors":["Wentao Chao","Xuechun Wang","Yingqian Wang","Guanghui Wang","Fuqing Duan"],"pdf_url":"https://arxiv.org/pdf/2208.09688v3.pdf","comment":"Accepted by IEEE Transactions on Computational Imaging"},{"id":"http://arxiv.org/abs/2311.12398v1","updated":"2023-11-21T07:19:47Z","published":"2023-11-21T07:19:47Z","title":"RFTrans: Leveraging Refractive Flow of Transparent Objects for Surface\n  Normal Estimation and Manipulation","summary":"  Transparent objects are widely used in our daily lives, making it important\nto teach robots to interact with them. However, it's not easy because the\nreflective and refractive effects can make RGB-D cameras fail to give accurate\ngeometry measurements. To solve this problem, this paper introduces RFTrans, an\nRGB-D-based method for surface normal estimation and manipulation of\ntransparent objects. By leveraging refractive flow as an intermediate\nrepresentation, RFTrans circumvents the drawbacks of directly predicting the\ngeometry (e.g. surface normal) from RGB images and helps bridge the sim-to-real\ngap. RFTrans integrates the RFNet, which predicts refractive flow, object mask,\nand boundaries, followed by the F2Net, which estimates surface normal from the\nrefractive flow. To make manipulation possible, a global optimization module\nwill take in the predictions, refine the raw depth, and construct the point\ncloud with normal. An analytical grasp planning algorithm, ISF, is followed to\ngenerate the grasp poses. We build a synthetic dataset with physically\nplausible ray-tracing rendering techniques to train the networks. Results show\nthat the RFTrans trained on the synthetic dataset can consistently outperform\nthe baseline ClearGrasp in both synthetic and real-world benchmarks by a large\nmargin. Finally, a real-world robot grasping task witnesses an 83% success\nrate, proving that refractive flow can help enable direct sim-to-real transfer.\nThe code, data, and supplementary materials are available at\nhttps://rftrans.robotflow.ai.\n","authors":["Tutian Tang","Jiyu Liu","Jieyi Zhang","Haoyuan Fu","Wenqiang Xu","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2311.12398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.09815v3","updated":"2023-11-21T07:19:03Z","published":"2023-07-19T08:03:53Z","title":"LDP: Language-driven Dual-Pixel Image Defocus Deblurring Network","summary":"  Recovering sharp images from dual-pixel (DP) pairs with disparity-dependent\nblur is a challenging task.~Existing blur map-based deblurring methods have\ndemonstrated promising results. In this paper, we propose, to the best of our\nknowledge, the first framework that introduces the contrastive language-image\npre-training framework (CLIP) to accurately estimate the blur map from a DP\npair unsupervisedly. To achieve this, we first carefully design text prompts to\nenable CLIP to understand blur-related geometric prior knowledge from the DP\npair. Then, we propose a format to input a stereo DP pair to CLIP without any\nfine-tuning, despite the fact that CLIP is pre-trained on monocular images.\nGiven the estimated blur map, we introduce a blur-prior attention block, a\nblur-weighting loss, and a blur-aware loss to recover the all-in-focus image.\nOur method achieves state-of-the-art performance in extensive experiments (see\nFig.~\\ref{fig:teaser}).\n","authors":["Hao Yang","Liyuan Pan","Yan Yang","Richard Hartley","Miaomiao Liu"],"pdf_url":"https://arxiv.org/pdf/2307.09815v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12397v1","updated":"2023-11-21T07:12:40Z","published":"2023-11-21T07:12:40Z","title":"Rich and Poor Texture Contrast: A Simple yet Effective Approach for\n  AI-generated Image Detection","summary":"  Recent generative models show impressive performance in generating\nphotographic images. Humans can hardly distinguish such incredibly\nrealistic-looking AI-generated images from real ones. AI-generated images may\nlead to ubiquitous disinformation dissemination. Therefore, it is of utmost\nurgency to develop a detector to identify AI-generated images. Most existing\ndetectors suffer from sharp performance drops over unseen generative models. In\nthis paper, we propose a novel AI-generated image detector capable of\nidentifying fake images created by a wide range of generative models. Our\napproach leverages the inter-pixel correlation contrast between rich and poor\ntexture regions within an image. Pixels in rich texture regions exhibit more\nsignificant fluctuations than those in poor texture regions. This discrepancy\nreflects that the entropy of rich texture regions is larger than that of poor\nones. Consequently, synthesizing realistic rich texture regions proves to be\nmore challenging for existing generative models. Based on this principle, we\ndivide an image into multiple patches and reconstruct them into two images,\ncomprising rich-texture and poor-texture patches respectively. Subsequently, we\nextract the inter-pixel correlation discrepancy feature between rich and poor\ntexture regions. This feature serves as a universal fingerprint used for\nAI-generated image forensics across different generative models. In addition,\nwe build a comprehensive AI-generated image detection benchmark, which includes\n16 kinds of prevalent generative models, to evaluate the effectiveness of\nexisting baselines and our approach. Our benchmark provides a leaderboard for\nfollow-up studies. Extensive experimental results show that our approach\noutperforms state-of-the-art baselines by a significant margin. Our project:\nhttps://fdmas.github.io/AIGCDetect/\n","authors":["Nan Zhong","Yiran Xu","Zhenxing Qian","Xinpeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12397v1.pdf","comment":"Our project: https://fdmas.github.io/AIGCDetect/"},{"id":"http://arxiv.org/abs/2311.12391v1","updated":"2023-11-21T07:02:32Z","published":"2023-11-21T07:02:32Z","title":"From Wrong To Right: A Recursive Approach Towards Vision-Language\n  Explanation","summary":"  Addressing the challenge of adapting pre-trained vision-language models for\ngenerating insightful explanations for visual reasoning tasks with limited\nannotations, we present ReVisE: a $\\textbf{Re}$cursive $\\textbf{Vis}$ual\n$\\textbf{E}$xplanation algorithm. Our method iteratively computes visual\nfeatures (conditioned on the text input), an answer, and an explanation, to\nimprove the explanation quality step by step until the answer converges. We\nfind that this multi-step approach guides the model to correct its own answers\nand outperforms single-step explanation generation. Furthermore, explanations\ngenerated by ReVisE also serve as valuable annotations for few-shot\nself-training. Our approach outperforms previous methods while utilizing merely\n5% of the human-annotated explanations across 10 metrics, demonstrating up to a\n4.2 and 1.3 increase in BLEU-1 score on the VCR and VQA-X datasets,\nunderscoring the efficacy and data-efficiency of our method.\n","authors":["Jiaxin Ge","Sanjay Subramanian","Trevor Darrell","Boyi Li"],"pdf_url":"https://arxiv.org/pdf/2311.12391v1.pdf","comment":"EMNLP 2023 Main"},{"id":"http://arxiv.org/abs/2311.12386v1","updated":"2023-11-21T06:55:21Z","published":"2023-11-21T06:55:21Z","title":"Point, Segment and Count: A Generalized Framework for Object Counting","summary":"  Class-agnostic object counting aims to count all objects in an image with\nrespect to example boxes or class names, \\emph{a.k.a} few-shot and zero-shot\ncounting. Current state-of-the-art methods highly rely on density maps to\npredict object counts, which lacks model interpretability. In this paper, we\npropose a generalized framework for both few-shot and zero-shot object counting\nbased on detection. Our framework combines the superior advantages of two\nfoundation models without compromising their zero-shot capability: (\\textbf{i})\nSAM to segment all possible objects as mask proposals, and (\\textbf{ii}) CLIP\nto classify proposals to obtain accurate object counts. However, this strategy\nmeets the obstacles of efficiency overhead and the small crowded objects that\ncannot be localized and distinguished. To address these issues, our framework,\ntermed PseCo, follows three steps: point, segment, and count. Specifically, we\nfirst propose a class-agnostic object localization to provide accurate but\nleast point prompts for SAM, which consequently not only reduces computation\ncosts but also avoids missing small objects. Furthermore, we propose a\ngeneralized object classification that leverages CLIP image/text embeddings as\nthe classifier, following a hierarchical knowledge distillation to obtain\ndiscriminative classifications among hierarchical mask proposals. Extensive\nexperimental results on FSC-147 dataset demonstrate that PseCo achieves\nstate-of-the-art performance in both few-shot/zero-shot object\ncounting/detection, with additional results on large-scale COCO and LVIS\ndatasets. The source code is available at\n\\url{https://github.com/Hzzone/PseCo}.\n","authors":["Huang Zhizhong","Dai Mingliang","Zhang Yi","Zhang Junping","Shan Hongming"],"pdf_url":"https://arxiv.org/pdf/2311.12386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11013v2","updated":"2023-11-21T06:18:25Z","published":"2023-11-18T08:48:58Z","title":"Implicit Event-RGBD Neural SLAM","summary":"  Implicit neural SLAM has achieved remarkable progress recently. Nevertheless,\nexisting methods face significant challenges in non-ideal scenarios, such as\nmotion blur or lighting variation, which often leads to issues like convergence\nfailures, localization drifts, and distorted mapping. To address these\nchallenges, we propose $\\textbf{EN-SLAM}$, the first event-RGBD implicit neural\nSLAM framework, which effectively leverages the high rate and high dynamic\nrange advantages of event data for tracking and mapping. Specifically, EN-SLAM\nproposes a differentiable CRF (Camera Response Function) rendering technique to\ngenerate distinct RGB and event camera data via a shared radiance field, which\nis optimized by learning a unified implicit representation with the captured\nevent and RGBD supervision. Moreover, based on the temporal difference property\nof events, we propose a temporal aggregating optimization strategy for the\nevent joint tracking and global bundle adjustment, capitalizing on the\nconsecutive difference constraints of events, significantly enhancing tracking\naccuracy and robustness. Finally, we construct the simulated dataset\n$\\textbf{DEV-Indoors}$ and real captured dataset $\\textbf{DEV-Reals}$\ncontaining 6 scenes, 17 sequences with practical motion blur and lighting\nchanges for evaluations. Experimental results show that our method outperforms\nthe SOTA methods in both tracking ATE and mapping ACC with a real-time $17$ FPS\nin various challenging environments. The code and dataset will be released\nsoon.\n","authors":["Delin Qu","Chi Yan","Dong Wang","Jie Yin","Dan Xu","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2311.11013v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12364v1","updated":"2023-11-21T05:55:39Z","published":"2023-11-21T05:55:39Z","title":"Semi-supervised Medical Image Segmentation via Query Distribution\n  Consistency","summary":"  Semi-supervised learning is increasingly popular in medical image\nsegmentation due to its ability to leverage large amounts of unlabeled data to\nextract additional information. However, most existing semi-supervised\nsegmentation methods focus only on extracting information from unlabeled data.\nIn this paper, we propose a novel Dual KMax UX-Net framework that leverages\nlabeled data to guide the extraction of information from unlabeled data. Our\napproach is based on a mutual learning strategy that incorporates two modules:\n3D UX-Net as our backbone meta-architecture and KMax decoder to enhance the\nsegmentation performance. Extensive experiments on the Atrial Segmentation\nChallenge dataset have shown that our method can significantly improve\nperformance by merging unlabeled data. Meanwhile, our framework outperforms\nstate-of-the-art semi-supervised learning methods on 10\\% and 20\\% labeled\nsettings. Code located at: https://github.com/Rows21/DK-UXNet.\n","authors":["Rong Wu","Dehua Li","Cong Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12364v1.pdf","comment":"Submitted to IEEE ISBI 2024"},{"id":"http://arxiv.org/abs/2310.17949v2","updated":"2023-11-21T05:55:10Z","published":"2023-10-27T07:44:25Z","title":"Instance Segmentation under Occlusions via Location-aware Copy-Paste\n  Data Augmentation","summary":"  Occlusion is a long-standing problem in computer vision, particularly in\ninstance segmentation. ACM MMSports 2023 DeepSportRadar has introduced a\ndataset that focuses on segmenting human subjects within a basketball context\nand a specialized evaluation metric for occlusion scenarios. Given the modest\nsize of the dataset and the highly deformable nature of the objects to be\nsegmented, this challenge demands the application of robust data augmentation\ntechniques and wisely-chosen deep learning architectures. Our work (ranked 1st\nin the competition) first proposes a novel data augmentation technique, capable\nof generating more training samples with wider distribution. Then, we adopt a\nnew architecture - Hybrid Task Cascade (HTC) framework with CBNetV2 as backbone\nand MaskIoU head to improve segmentation performance. Furthermore, we employ a\nStochastic Weight Averaging (SWA) training strategy to improve the model's\ngeneralization. As a result, we achieve a remarkable occlusion score (OM) of\n0.533 on the challenge dataset, securing the top-1 position on the leaderboard.\nSource code is available at this\nhttps://github.com/nguyendinhson-kaist/MMSports23-Seg-AutoID.\n","authors":["Son Nguyen","Mikel Lainsa","Hung Dao","Daeyoung Kim","Giang Nguyen"],"pdf_url":"https://arxiv.org/pdf/2310.17949v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12359v1","updated":"2023-11-21T05:27:16Z","published":"2023-11-21T05:27:16Z","title":"Post-Training Quantization with Low-precision Minifloats and Integers on\n  FPGAs","summary":"  Post-Training Quantization (PTQ) is a powerful technique for model\ncompression, reducing the precision of neural networks without additional\ntraining overhead. Recent works have investigated adopting 8-bit floating-point\nquantization (FP8) in the context of PTQ for model inference. However, the\nexploration of floating-point formats smaller than 8 bits and their comparison\nwith integer quantization remains relatively limited. In this work, we present\nminifloats, which are reduced-precision floating-point formats capable of\nfurther reducing the memory footprint, latency, and energy cost of a model\nwhile approaching full-precision model accuracy. Our work presents a novel PTQ\ndesign-space exploration, comparing minifloat and integer quantization schemes\nacross a range of 3 to 8 bits for both weights and activations. We examine the\napplicability of various PTQ techniques to minifloats, including weight\nequalization, bias correction, SmoothQuant, gradient-based learned rounding,\nand the GPTQ method. Our experiments validate the effectiveness of\nlow-precision minifloats when compared to their integer counterparts across a\nspectrum of accuracy-precision trade-offs on a set of reference deep learning\nvision workloads. Finally, we evaluate our results against an FPGA-based\nhardware cost model, showing that integer quantization often remains the\nPareto-optimal option, given its relatively smaller hardware resource\nfootprint.\n","authors":["Shivam Aggarwal","Alessandro Pappalardo","Hans Jakob Damsgaard","Giuseppe Franco","Thomas B. Preußer","Michaela Blott","Tulika Mitra"],"pdf_url":"https://arxiv.org/pdf/2311.12359v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12345v1","updated":"2023-11-21T04:38:21Z","published":"2023-11-21T04:38:21Z","title":"Stable Diffusion For Aerial Object Detection","summary":"  Aerial object detection is a challenging task, in which one major obstacle\nlies in the limitations of large-scale data collection and the long-tail\ndistribution of certain classes. Synthetic data offers a promising solution,\nespecially with recent advances in diffusion-based methods like stable\ndiffusion (SD). However, the direct application of diffusion methods to aerial\ndomains poses unique challenges: stable diffusion's optimization for rich\nground-level semantics doesn't align with the sparse nature of aerial objects,\nand the extraction of post-synthesis object coordinates remains problematic. To\naddress these challenges, we introduce a synthetic data augmentation framework\ntailored for aerial images. It encompasses sparse-to-dense region of interest\n(ROI) extraction to bridge the semantic gap, fine-tuning the diffusion model\nwith low-rank adaptation (LORA) to circumvent exhaustive retraining, and\nfinally, a Copy-Paste method to compose synthesized objects with backgrounds,\nproviding a nuanced approach to aerial object detection through synthetic data.\n","authors":["Yanan Jian","Fuxun Yu","Simranjit Singh","Dimitrios Stamoulis"],"pdf_url":"https://arxiv.org/pdf/2311.12345v1.pdf","comment":"Accepted at NeurIPS 2023 Synthetic Data Generation with Generative AI\n  workshop"},{"id":"http://arxiv.org/abs/2311.12344v1","updated":"2023-11-21T04:32:28Z","published":"2023-11-21T04:32:28Z","title":"Modality Mixer Exploiting Complementary Information for Multi-modal\n  Action Recognition","summary":"  Due to the distinctive characteristics of sensors, each modality exhibits\nunique physical properties. For this reason, in the context of multi-modal\naction recognition, it is important to consider not only the overall action\ncontent but also the complementary nature of different modalities. In this\npaper, we propose a novel network, named Modality Mixer (M-Mixer) network,\nwhich effectively leverages and incorporates the complementary information\nacross modalities with the temporal context of actions for action recognition.\nA key component of our proposed M-Mixer is the Multi-modal Contextualization\nUnit (MCU), a simple yet effective recurrent unit. Our MCU is responsible for\ntemporally encoding a sequence of one modality (e.g., RGB) with action content\nfeatures of other modalities (e.g., depth and infrared modalities). This\nprocess encourages M-Mixer network to exploit global action content and also to\nsupplement complementary information of other modalities. Furthermore, to\nextract appropriate complementary information regarding to the given modality\nsettings, we introduce a new module, named Complementary Feature Extraction\nModule (CFEM). CFEM incorporates sepearte learnable query embeddings for each\nmodality, which guide CFEM to extract complementary information and global\naction content from the other modalities. As a result, our proposed method\noutperforms state-of-the-art methods on NTU RGB+D 60, NTU RGB+D 120, and\nNW-UCLA datasets. Moreover, through comprehensive ablation studies, we further\nvalidate the effectiveness of our proposed method.\n","authors":["Sumin Lee","Sangmin Woo","Muhammad Adi Nugroho","Changick Kim"],"pdf_url":"https://arxiv.org/pdf/2311.12344v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2208.11314"},{"id":"http://arxiv.org/abs/2311.12342v1","updated":"2023-11-21T04:28:12Z","published":"2023-11-21T04:28:12Z","title":"LoCo: Locally Constrained Training-Free Layout-to-Image Synthesis","summary":"  Recent text-to-image diffusion models have reached an unprecedented level in\ngenerating high-quality images. However, their exclusive reliance on textual\nprompts often falls short in accurately conveying fine-grained spatial\ncompositions. In this paper, we propose LoCo, a training-free approach for\nlayout-to-image synthesis that excels in producing high-quality images aligned\nwith both textual prompts and spatial layouts. Our method introduces a\nLocalized Attention Constraint to refine cross-attention for individual\nobjects, ensuring their precise placement in designated regions. We further\npropose a Padding Token Constraint to leverage the semantic information\nembedded in previously neglected padding tokens, thereby preventing the\nundesired fusion of synthesized objects. LoCo seamlessly integrates into\nexisting text-to-image and layout-to-image models, significantly amplifying\ntheir performance and effectively addressing semantic failures observed in\nprior methods. Through extensive experiments, we showcase the superiority of\nour approach, surpassing existing state-of-the-art training-free\nlayout-to-image methods both qualitatively and quantitatively across multiple\nbenchmarks.\n","authors":["Peiang Zhao","Han Li","Ruiyang Jin","S. Kevin Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.12342v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2206.10996v4","updated":"2023-11-21T04:18:38Z","published":"2022-06-22T11:55:53Z","title":"ProtoCLIP: Prototypical Contrastive Language Image Pretraining","summary":"  Contrastive Language Image Pretraining (CLIP) has received widespread\nattention, since its learned representations can be transferred well to various\ndownstream tasks. During the training process of the CLIP model, the InfoNCE\nobjective aligns positive image-text pairs and separates negative ones. We show\nan underlying representation grouping effect during this process: the InfoNCE\nobjective indirectly groups semantically similar representations together via\nrandomly emerged within-modal anchors. Based on this understanding, in this\npaper, Prototypical Contrastive Language Image Pretraining (ProtoCLIP) is\nintroduced to enhance such grouping by boosting its efficiency and increasing\nits robustness against the modality gap. Specifically, ProtoCLIP sets up\nprototype-level discrimination between image and text spaces, which efficiently\ntransfers higher-level structural knowledge. Further, Prototypical Back\nTranslation (PBT) is proposed to decouple representation grouping from\nrepresentation alignment, resulting in effective learning of meaningful\nrepresentations under large modality gap. The PBT also enables us to introduce\nadditional external teachers with richer prior language knowledge. ProtoCLIP is\ntrained with an online episodic training strategy, which makes it can be scaled\nup to unlimited amounts of data. We train our ProtoCLIP on Conceptual Captions\nand achieved an +5.81% ImageNet linear probing improvement and an +2.01%\nImageNet zero-shot classification improvement. On the larger YFCC-15M dataset,\nProtoCLIP matches the performance of CLIP with 33% of training time. Codes are\navailable at https://github.com/megvii-research/protoclip.\n","authors":["Delong Chen","Zhao Wu","Fan Liu","Zaiquan Yang","Huaxi Huang","Ying Tan","Erjin Zhou"],"pdf_url":"https://arxiv.org/pdf/2206.10996v4.pdf","comment":"Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)"},{"id":"http://arxiv.org/abs/2309.04342v3","updated":"2023-11-21T04:10:20Z","published":"2023-09-08T14:12:03Z","title":"Revealing the preference for correcting separated aberrations in joint\n  optic-image design","summary":"  The joint design of the optical system and the downstream algorithm is a\nchallenging and promising task. Due to the demand for balancing the global\noptimal of imaging systems and the computational cost of physical simulation,\nexisting methods cannot achieve efficient joint design of complex systems such\nas smartphones and drones. In this work, starting from the perspective of the\noptical design, we characterize the optics with separated aberrations.\nAdditionally, to bridge the hardware and software without gradients, an image\nsimulation system is presented to reproduce the genuine imaging procedure of\nlenses with large field-of-views. As for aberration correction, we propose a\nnetwork to perceive and correct the spatially varying aberrations and validate\nits superiority over state-of-the-art methods. Comprehensive experiments reveal\nthat the preference for correcting separated aberrations in joint design is as\nfollows: longitudinal chromatic aberration, lateral chromatic aberration,\nspherical aberration, field curvature, and coma, with astigmatism coming last.\nDrawing from the preference, a 10% reduction in the total track length of the\nconsumer-level mobile phone lens module is accomplished. Moreover, this\nprocedure spares more space for manufacturing deviations, realizing\nextreme-quality enhancement of computational photography. The optimization\nparadigm provides innovative insight into the practical joint design of\nsophisticated optical systems and post-processing algorithms.\n","authors":["Jingwen Zhou","Shiqi Chen","Zheng Ren","Wenguan Zhang","Jiapu Yan","Huajun Feng","Qi Li","Yueting Chen"],"pdf_url":"https://arxiv.org/pdf/2309.04342v3.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2311.12327v1","updated":"2023-11-21T03:40:09Z","published":"2023-11-21T03:40:09Z","title":"ViLaM: A Vision-Language Model with Enhanced Visual Grounding and\n  Generalization Capability","summary":"  Vision-language models have revolutionized human-computer interaction and\nshown significant progress in multi-modal tasks. However, applying these models\nto complex visual tasks like medical image analysis remains challenging. In\nthis study, we propose ViLaM, a unified Vision-Language transformer model that\nintegrates instruction tuning predicated on a large language model. This\napproach enables us to optimally utilize the knowledge and reasoning capacities\nof large pre-trained language models for an array of tasks encompassing both\nlanguage and vision. We employ frozen pre-trained encoders to encode and align\nboth image and text features, enabling ViLaM to handle a variety of visual\ntasks following textual instructions. Besides, we've designed cycle training\nfor referring expressions to address the need for high-quality, paired\nreferring expression datasets for training large models in terms of both\nquantity and quality. We evaluated ViLaM's exceptional performance on public\ngeneral datasets and further confirmed its generalizability on medical\ndatasets. Importantly, we've observed the model's impressive zero-shot learning\nability, indicating the potential future application of ViLaM in the medical\nfield.\n","authors":["Xiaoyu Yang","Lijian Xu","Hongsheng Li","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12316v1","updated":"2023-11-21T03:25:51Z","published":"2023-11-21T03:25:51Z","title":"Overcoming Pathology Image Data Deficiency: Generating Images from\n  Pathological Transformation Process","summary":"  Histopathology serves as the gold standard for medical diagnosis but faces\napplication limitations due to the shortage of medical resources. Leveraging\ndeep learning, computer-aided diagnosis has the potential to alleviate the\npathologist scarcity and provide timely clinical analysis. However, developing\na reliable model generally necessitates substantial data for training, which is\nchallenging in pathological field. In response, we propose an adaptive\ndepth-controlled bidirectional diffusion (ADBD) network for image data\ngeneration. The domain migration approach can work with small trainset and\novercome the diffusion overfitting by source information guidance.\nSpecifically, we developed a hybrid attention strategy to blend global and\nlocal attention priorities, which guides the bidirectional diffusion and\nensures the migration success. In addition, we developed the adaptive\ndepth-controlled strategy to simulate physiological transformations, capable of\nyielding unlimited cross-domain intermediate images with corresponding soft\nlabels. ADBD is effective for overcoming pathological image data deficiency and\nsupportable for further pathology-related research.\n","authors":["Zeyu Liu","Yufang He","Yu Zhao","Yunlu Feng","Guanglei Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12316v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18639v2","updated":"2023-11-21T03:23:39Z","published":"2023-10-28T08:48:44Z","title":"Towards Plastic and Stable Exemplar-Free Incremental Learning: A\n  Dual-Learner Framework with Cumulative Parameter Averaging","summary":"  The dilemma between plasticity and stability presents a significant challenge\nin Incremental Learning (IL), especially in the exemplar-free scenario where\naccessing old-task samples is strictly prohibited during the learning of a new\ntask. A straightforward solution to this issue is learning and storing an\nindependent model for each task, known as Single Task Learning (STL). Despite\nthe linear growth in model storage with the number of tasks in STL, we\nempirically discover that averaging these model parameters can potentially\npreserve knowledge across all tasks. Inspired by this observation, we propose a\nDual-Learner framework with Cumulative Parameter Averaging (DLCPA). DLCPA\nemploys a dual-learner design: a plastic learner focused on acquiring new-task\nknowledge and a stable learner responsible for accumulating all learned\nknowledge. The knowledge from the plastic learner is transferred to the stable\nlearner via cumulative parameter averaging. Additionally, several task-specific\nclassifiers work in cooperation with the stable learner to yield the final\nprediction. Specifically, when learning a new task, these modules are updated\nin a cyclic manner: i) the plastic learner is initially optimized using a\nself-supervised loss besides the supervised loss to enhance the feature\nextraction robustness; ii) the stable learner is then updated with respect to\nthe plastic learner in a cumulative parameter averaging manner to maintain its\ntask-wise generalization; iii) the task-specific classifier is accordingly\noptimized to align with the stable learner. Experimental results on CIFAR-100\nand Tiny-ImageNet show that DLCPA outperforms several state-of-the-art\nexemplar-free baselines in both Task-IL and Class-IL settings.\n","authors":["Wenju Sun","Qingyong Li","Wen Wang","Yangli-ao Geng"],"pdf_url":"https://arxiv.org/pdf/2310.18639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12311v1","updated":"2023-11-21T03:03:22Z","published":"2023-11-21T03:03:22Z","title":"ABFL: Angular Boundary Discontinuity Free Loss for Arbitrary Oriented\n  Object Detection in Aerial Images","summary":"  Arbitrary oriented object detection (AOOD) in aerial images is a widely\nconcerned and highly challenging task, and plays an important role in many\nscenarios. The core of AOOD involves the representation, encoding, and feature\naugmentation of oriented bounding-boxes (Bboxes). Existing methods lack\nintuitive modeling of angle difference measurement in oriented Bbox\nrepresentations. Oriented Bboxes under different representations exhibit\nrotational symmetry with varying periods due to angle periodicity. The angular\nboundary discontinuity (ABD) problem at periodic boundary positions is caused\nby rotational symmetry in measuring angular differences. In addition, existing\nmethods also use additional encoding-decoding structures for oriented Bboxes.\nIn this paper, we design an angular boundary free loss (ABFL) based on the von\nMises distribution. The ABFL aims to solve the ABD problem when detecting\noriented objects. Specifically, ABFL proposes to treat angles as circular data\nrather than linear data when measuring angle differences, aiming to introduce\nangle periodicity to alleviate the ABD problem and improve the accuracy of\nangle difference measurement. In addition, ABFL provides a simple and effective\nsolution for various periodic boundary discontinuities caused by rotational\nsymmetry in AOOD tasks, as it does not require additional encoding-decoding\nstructures for oriented Bboxes. Extensive experiments on the DOTA and HRSC2016\ndatasets show that the proposed ABFL loss outperforms some state-of-the-art\nmethods focused on addressing the ABD problem.\n","authors":["Zifei Zhao","Shengyang Li"],"pdf_url":"https://arxiv.org/pdf/2311.12311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12300v1","updated":"2023-11-21T02:36:47Z","published":"2023-11-21T02:36:47Z","title":"Challenges in Video-Based Infant Action Recognition: A Critical\n  Examination of the State of the Art","summary":"  Automated human action recognition, a burgeoning field within computer\nvision, boasts diverse applications spanning surveillance, security,\nhuman-computer interaction, tele-health, and sports analysis. Precise action\nrecognition in infants serves a multitude of pivotal purposes, encompassing\nsafety monitoring, developmental milestone tracking, early intervention for\ndevelopmental delays, fostering parent-infant bonds, advancing computer-aided\ndiagnostics, and contributing to the scientific comprehension of child\ndevelopment. This paper delves into the intricacies of infant action\nrecognition, a domain that has remained relatively uncharted despite the\naccomplishments in adult action recognition. In this study, we introduce a\ngroundbreaking dataset called ``InfActPrimitive'', encompassing five\nsignificant infant milestone action categories, and we incorporate specialized\npreprocessing for infant data. We conducted an extensive comparative analysis\nemploying cutting-edge skeleton-based action recognition models using this\ndataset. Our findings reveal that, although the PoseC3D model achieves the\nhighest accuracy at approximately 71%, the remaining models struggle to\naccurately capture the dynamics of infant actions. This highlights a\nsubstantial knowledge gap between infant and adult action recognition domains\nand the urgent need for data-efficient pipeline models.\n","authors":["Elaheh Hatamimajoumerd","Pooria Daneshvar Kakhaki","Xiaofei Huang","Lingfei Luan","Somaieh Amraee","Sarah Ostadabbas"],"pdf_url":"https://arxiv.org/pdf/2311.12300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10899v2","updated":"2023-11-21T02:16:27Z","published":"2023-11-17T22:44:05Z","title":"Extraction and Summarization of Explicit Video Content using Multi-Modal\n  Deep Learning","summary":"  With the increase in video-sharing platforms across the internet, it is\ndifficult for humans to moderate the data for explicit content. Hence, an\nautomated pipeline to scan through video data for explicit content has become\nthe need of the hour. We propose a novel pipeline that uses multi-modal deep\nlearning to first extract the explicit segments of input videos and then\nsummarize their content using text to determine its age appropriateness and age\nrating. We also evaluate our pipeline's effectiveness in the end using standard\nmetrics.\n","authors":["Shaunak Joshi","Raghav Gaggar"],"pdf_url":"https://arxiv.org/pdf/2311.10899v2.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.12291v1","updated":"2023-11-21T02:14:16Z","published":"2023-11-21T02:14:16Z","title":"Instance-aware 3D Semantic Segmentation powered by Shape Generators and\n  Classifiers","summary":"  Existing 3D semantic segmentation methods rely on point-wise or voxel-wise\nfeature descriptors to output segmentation predictions. However, these\ndescriptors are often supervised at point or voxel level, leading to\nsegmentation models that can behave poorly at instance-level. In this paper, we\nproposed a novel instance-aware approach for 3D semantic segmentation. Our\nmethod combines several geometry processing tasks supervised at instance-level\nto promote the consistency of the learned feature representation. Specifically,\nour methods use shape generators and shape classifiers to perform shape\nreconstruction and classification tasks for each shape instance. This enforces\nthe feature representation to faithfully encode both structural and local shape\ninformation, with an awareness of shape instances. In the experiments, our\nmethod significantly outperform existing approaches in 3D semantic segmentation\non several public benchmarks, such as Waymo Open Dataset, SemanticKITTI and\nScanNetV2.\n","authors":["Bo Sun","Qixing Huang","Xiangru Huang"],"pdf_url":"https://arxiv.org/pdf/2311.12291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12272v1","updated":"2023-11-21T01:25:24Z","published":"2023-11-21T01:25:24Z","title":"Procedural Generation of Grain Orientations using the Wave Function\n  Collapse Algorithm","summary":"  Statistics of grain sizes and orientations in metals correlate to the\nmaterial's mechanical properties. Reproducing representative volume elements\nfor further analysis of deformation and failure in metals, like 316L stainless\nsteel, is particularly important due to their wide use in manufacturing goods\ntoday. Two approaches, initially created for video games, were considered for\nthe procedural generation of representative grain microstructures. The first is\nthe Wave Function Collapse (WFC) algorithm, and the second is constraint\npropagation and probabilistic inference through Markov Junior, a free and\nopen-source software. This study aimed to investigate these two algorithms'\neffectiveness in using reference electron backscatter diffraction (EBSD) maps\nand recreating a statistically similar one that could be used in further\nresearch. It utilized two stainless steel EBSD maps as references to test both\nalgorithms. First, the WFC algorithm was too constricting and, thus, incapable\nof producing images that resembled EBSDs. The second, MarkovJunior, was much\nmore effective in creating a Voronoi tessellation that could be used to create\nan EBSD map in Python. When comparing the results between the reference and the\ngenerated EBSD, we discovered that the orientation and volume fractions were\nextremely similar. With the study, it was concluded that MarkovJunior is an\neffective machine learning tool that can reproduce representative grain\nmicrostructures.\n","authors":["G. Magny-Fokam","D. Madisetti","J. El-Awady"],"pdf_url":"https://arxiv.org/pdf/2311.12272v1.pdf","comment":"6 pages, 18 figures"},{"id":"http://arxiv.org/abs/2311.12268v1","updated":"2023-11-21T01:18:23Z","published":"2023-11-21T01:18:23Z","title":"Boosting Audio-visual Zero-shot Learning with Large Language Models","summary":"  Audio-visual zero-shot learning aims to recognize unseen categories based on\npaired audio-visual sequences. Recent methods mainly focus on learning aligned\nand discriminative multi-modal features to boost generalization towards unseen\ncategories. However, these approaches ignore the obscure action concepts in\ncategory names and may inevitably introduce complex network structures with\ndifficult training objectives. In this paper, we propose a simple yet effective\nframework named Knowledge-aware Distribution Adaptation (KDA) to help the model\nbetter grasp the novel action contents with an external knowledge base.\nSpecifically, we first propose using large language models to generate rich\ndescriptions from category names, which leads to a better understanding of\nunseen categories. Additionally, we propose a distribution alignment loss as\nwell as a knowledge-aware adaptive margin loss to further improve the\ngeneralization ability towards unseen categories. Extensive experimental\nresults demonstrate that our proposed KDA can outperform state-of-the-art\nmethods on three popular audio-visual zero-shot learning datasets. Our code\nwill be avaliable at \\url{https://github.com/chenhaoxing/KDA}.\n","authors":["Haoxing Chen","Yaohui Li","Yan Hong","Zizheng Huang","Zhuoer Xu","Zhangxuan Gu","Jun Lan","Huijia Zhu","Weiqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12265v1","updated":"2023-11-21T01:01:08Z","published":"2023-11-21T01:01:08Z","title":"Virtual Home Staging: Inverse Rendering and Editing an Indoor Panorama\n  under Natural Illumination","summary":"  We propose a novel inverse rendering method that enables the transformation\nof existing indoor panoramas with new indoor furniture layouts under natural\nillumination. To achieve this, we captured indoor HDR panoramas along with\nreal-time outdoor hemispherical HDR photographs. Indoor and outdoor HDR images\nwere linearly calibrated with measured absolute luminance values for accurate\nscene relighting. Our method consists of three key components: (1) panoramic\nfurniture detection and removal, (2) automatic floor layout design, and (3)\nglobal rendering with scene geometry, new furniture objects, and a real-time\noutdoor photograph. We demonstrate the effectiveness of our workflow in\nrendering indoor scenes under different outdoor illumination conditions.\nAdditionally, we contribute a new calibrated HDR (Cali-HDR) dataset that\nconsists of 137 calibrated indoor panoramas and their associated outdoor\nphotographs. The source code and dataset are available:\nhttps://github.com/Gzhji/Cali-HDR-Dataset.\n","authors":["Guanzhou Ji","Azadeh O. Sawyer","Srinivasa G. Narasimhan"],"pdf_url":"https://arxiv.org/pdf/2311.12265v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11819v2","updated":"2023-11-21T20:45:51Z","published":"2023-11-20T14:55:40Z","title":"Generalized super-resolution 4D Flow MRI $\\unicode{x2013}$ using\n  ensemble learning to extend across the cardiovascular system","summary":"  4D Flow Magnetic Resonance Imaging (4D Flow MRI) is a non-invasive\nmeasurement technique capable of quantifying blood flow across the\ncardiovascular system. While practical use is limited by spatial resolution and\nimage noise, incorporation of trained super-resolution (SR) networks has\npotential to enhance image quality post-scan. However, these efforts have\npredominantly been restricted to narrowly defined cardiovascular domains, with\nlimited exploration of how SR performance extends across the cardiovascular\nsystem; a task aggravated by contrasting hemodynamic conditions apparent across\nthe cardiovasculature. The aim of our study was to explore the generalizability\nof SR 4D Flow MRI using a combination of heterogeneous training sets and\ndedicated ensemble learning. With synthetic training data generated across\nthree disparate domains (cardiac, aortic, cerebrovascular), varying\nconvolutional base and ensemble learners were evaluated as a function of domain\nand architecture, quantifying performance on both in-silico and acquired\nin-vivo data from the same three domains. Results show that both bagging and\nstacking ensembling enhance SR performance across domains, accurately\npredicting high-resolution velocities from low-resolution input data in-silico.\nLikewise, optimized networks successfully recover native resolution velocities\nfrom downsampled in-vivo data, as well as show qualitative potential in\ngenerating denoised SR-images from clinical level input data. In conclusion,\nour work presents a viable approach for generalized SR 4D Flow MRI, with\nensemble learning extending utility across various clinical areas of interest.\n","authors":["Leon Ericsson","Adam Hjalmarsson","Muhammad Usman Akbar","Edward Ferdian","Mia Bonini","Brandon Hardy","Jonas Schollenberger","Maria Aristova","Patrick Winter","Nicholas Burris","Alexander Fyrdahl","Andreas Sigfridsson","Susanne Schnell","C. Alberto Figueroa","David Nordsletten","Alistair A. Young","David Marlevi"],"pdf_url":"https://arxiv.org/pdf/2311.11819v2.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2310.08420v2","updated":"2023-11-21T23:40:09Z","published":"2023-10-12T15:39:54Z","title":"Visual Attention-Prompted Prediction and Learning","summary":"  Explanation(attention)-guided learning is a method that enhances a model's\npredictive power by incorporating human understanding during the training\nphase. While attention-guided learning has shown promising results, it often\ninvolves time-consuming and computationally expensive model retraining. To\naddress this issue, we introduce the attention-prompted prediction technique,\nwhich enables direct prediction guided by the attention prompt without the need\nfor model retraining. However, this approach presents several challenges,\nincluding: 1) How to incorporate the visual attention prompt into the model's\ndecision-making process and leverage it for future predictions even in the\nabsence of a prompt? and 2) How to handle the incomplete information from the\nvisual attention prompt? To tackle these challenges, we propose a novel\nframework called Visual Attention-Prompted Prediction and Learning, which\nseamlessly integrates visual attention prompts into the model's decision-making\nprocess and adapts to images both with and without attention prompts for\nprediction. To address the incomplete information of the visual attention\nprompt, we introduce a perturbation-based attention map modification method.\nAdditionally, we propose an optimization-based mask aggregation method with a\nnew weight learning function for adaptive perturbed annotation aggregation in\nthe attention map modification process. Our overall framework is designed to\nlearn in an attention-prompt guided multi-task manner to enhance future\npredictions even for samples without attention prompts and trained in an\nalternating manner for better convergence. Extensive experiments conducted on\ntwo datasets demonstrate the effectiveness of our proposed framework in\nenhancing predictions for samples, both with and without provided prompts.\n","authors":["Yifei Zhang","Siyi Gu","Bo Pan","Guangji Bai","Xiaofeng Yang","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.08420v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13052v1","updated":"2023-11-21T23:25:04Z","published":"2023-11-21T23:25:04Z","title":"Novel OCT mosaicking pipeline with Feature- and Pixel-based registration","summary":"  High-resolution Optical Coherence Tomography (OCT) images are crucial for\nophthalmology studies but are limited by their relatively narrow field of view\n(FoV). Image mosaicking is a technique for aligning multiple overlapping images\nto obtain a larger FoV. Current mosaicking pipelines often struggle with\nsubstantial noise and considerable displacement between the input sub-fields.\nIn this paper, we propose a versatile pipeline for stitching multi-view\nOCT/OCTA \\textit{en face} projection images. Our method combines the strengths\nof learning-based feature matching and robust pixel-based registration to align\nmultiple images effectively. Furthermore, we advance the application of a\ntrained foundational model, Segment Anything Model (SAM), to validate\nmosaicking results in an unsupervised manner. The efficacy of our pipeline is\nvalidated using an in-house dataset and a large public dataset, where our\nmethod shows superior performance in terms of both accuracy and computational\nefficiency. We also made our evaluation tool for image mosaicking and the\ncorresponding pipeline publicly available at\n\\url{https://github.com/MedICL-VU/OCT-mosaicking}.\n","authors":["Jiacheng Wang","Hao Li","Dewei Hu","Yuankai K. Tao","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2311.13052v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.16020v2","updated":"2023-11-21T23:23:08Z","published":"2023-09-27T20:54:56Z","title":"GeoCLIP: Clip-Inspired Alignment between Locations and Images for\n  Effective Worldwide Geo-localization","summary":"  Worldwide Geo-localization aims to pinpoint the precise location of images\ntaken anywhere on Earth. This task has considerable challenges due to immense\nvariation in geographic landscapes. The image-to-image retrieval-based\napproaches fail to solve this problem on a global scale as it is not feasible\nto construct a large gallery of images covering the entire world. Instead,\nexisting approaches divide the globe into discrete geographic cells,\ntransforming the problem into a classification task. However, their performance\nis limited by the predefined classes and often results in inaccurate\nlocalizations when an image's location significantly deviates from its class\ncenter. To overcome these limitations, we propose GeoCLIP, a novel\nCLIP-inspired Image-to-GPS retrieval approach that enforces alignment between\nthe image and its corresponding GPS locations. GeoCLIP's location encoder\nmodels the Earth as a continuous function by employing positional encoding\nthrough random Fourier features and constructing a hierarchical representation\nthat captures information at varying resolutions to yield a semantically rich\nhigh-dimensional feature suitable to use even beyond geo-localization. To the\nbest of our knowledge, this is the first work employing GPS encoding for\ngeo-localization. We demonstrate the efficacy of our method via extensive\nexperiments and ablations on benchmark datasets. We achieve competitive\nperformance with just 20% of training data, highlighting its effectiveness even\nin limited-data settings. Furthermore, we qualitatively demonstrate\ngeo-localization using a text query by leveraging CLIP backbone of our image\nencoder. The project webpage is available at:\nhttps://vicentevivan.github.io/GeoCLIP\n","authors":["Vicente Vivanco Cepeda","Gaurav Kumar Nayak","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2309.16020v2.pdf","comment":"Accepted at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.13045v1","updated":"2023-11-21T23:14:42Z","published":"2023-11-21T23:14:42Z","title":"Camera-Independent Single Image Depth Estimation from Defocus Blur","summary":"  Monocular depth estimation is an important step in many downstream tasks in\nmachine vision. We address the topic of estimating monocular depth from defocus\nblur which can yield more accurate results than the semantic based depth\nestimation methods. The existing monocular depth from defocus techniques are\nsensitive to the particular camera that the images are taken from. We show how\nseveral camera-related parameters affect the defocus blur using optical physics\nequations and how they make the defocus blur depend on these parameters. The\nsimple correction procedure we propose can alleviate this problem which does\nnot require any retraining of the original model. We created a synthetic\ndataset which can be used to test the camera independent performance of depth\nfrom defocus blur models. We evaluate our model on both synthetic and real\ndatasets (DDFF12 and NYU depth V2) obtained with different cameras and show\nthat our methods are significantly more robust to the changes of cameras. Code:\nhttps://github.com/sleekEagle/defocus_camind.git\n","authors":["Lahiru Wijayasingha","Homa Alemzadeh","John A. Stankovic"],"pdf_url":"https://arxiv.org/pdf/2311.13045v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13022v1","updated":"2023-11-21T22:05:00Z","published":"2023-11-21T22:05:00Z","title":"Unsupervised Multimodal Surface Registration with Geometric Deep\n  Learning","summary":"  This paper introduces GeoMorph, a novel geometric deep-learning framework\ndesigned for image registration of cortical surfaces. The registration process\nconsists of two main steps. First, independent feature extraction is performed\non each input surface using graph convolutions, generating low-dimensional\nfeature representations that capture important cortical surface\ncharacteristics. Subsequently, features are registered in a deep-discrete\nmanner to optimize the overlap of common structures across surfaces by learning\ndisplacements of a set of control points. To ensure smooth and biologically\nplausible deformations, we implement regularization through a deep conditional\nrandom field implemented with a recurrent neural network. Experimental results\ndemonstrate that GeoMorph surpasses existing deep-learning methods by achieving\nimproved alignment with smoother deformations. Furthermore, GeoMorph exhibits\ncompetitive performance compared to classical frameworks. Such versatility and\nrobustness suggest strong potential for various neuroscience applications.\n","authors":["Mohamed A. Suliman","Logan Z. J. Williams","Abdulah Fawaz","Emma C. Robinson"],"pdf_url":"https://arxiv.org/pdf/2311.13022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13018v1","updated":"2023-11-21T21:48:51Z","published":"2023-11-21T21:48:51Z","title":"Attention: Large Multimodal Model is Watching your Geo-privacy","summary":"  Geographic privacy, a crucial aspect of personal security, often goes\nunnoticed in daily activities. This paper addresses the underestimation of this\nprivacy in the context of increasing online data sharing and the advancements\nin information gathering technologies. With the surge in the use of Large\nMultimodal Models, such as GPT-4, for Open Source Intelligence (OSINT), the\npotential risks associated with geographic privacy breaches have intensified.\nThis study highlights the criticality of these developments, focusing on their\nimplications for individual privacy. The primary objective is to demonstrate\nthe capabilities of advanced AI tools, specifically a GPT-4 based model named\n\"Dr. Watson,\" in identifying and potentially compromising geographic privacy\nthrough online shared content. We developed \"Dr. Watson\" to analyze and extract\ngeographic information from publicly available data sources. The study involved\nfive experimental cases, each offering different perspectives on the tool's\napplication in extracting precise location data from partial images and social\nmedia content. The experiments revealed that \"Dr. Watson\" could successfully\nidentify specific geographic details, thereby exposing the vulnerabilities in\ncurrent geo-privacy measures. These findings underscore the ease with which\ngeographic information can be unintentionally disclosed. The paper concludes\nwith a discussion on the broader implications of these findings for individuals\nand the community at large. It emphasizes the urgency for enhanced awareness\nand protective measures against geo-privacy leakage in the era of advanced AI\nand widespread social media usage.\n","authors":["Yifan Yang","Yixian Zhang","Daoyang Li","Shuju Sun","Junhong Duan","Junzhou He","Qingyang Wu","Hao Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13018v1.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.13016v1","updated":"2023-11-21T21:44:45Z","published":"2023-11-21T21:44:45Z","title":"Image-Based Soil Organic Carbon Remote Sensing from Satellite Images\n  with Fourier Neural Operator and Structural Similarity","summary":"  Soil organic carbon (SOC) sequestration is the transfer and storage of\natmospheric carbon dioxide in soils, which plays an important role in climate\nchange mitigation. SOC concentration can be improved by proper land use, thus\nit is beneficial if SOC can be estimated at a regional or global scale. As\nmultispectral satellite data can provide SOC-related information such as\nvegetation and soil properties at a global scale, estimation of SOC through\nsatellite data has been explored as an alternative to manual soil sampling.\nAlthough existing studies show promising results, they are mainly based on\npixel-based approaches with traditional machine learning methods, and\nconvolutional neural networks (CNNs) are uncommon. To study the use of CNNs on\nSOC remote sensing, here we propose the FNO-DenseNet based on the Fourier\nneural operator (FNO). By combining the advantages of the FNO and DenseNet, the\nFNO-DenseNet outperformed the FNO in our experiments with hundreds of times\nfewer parameters. The FNO-DenseNet also outperformed a pixel-based random\nforest by 18% in the mean absolute percentage error.\n","authors":["Ken C. L. Wong","Levente Klein","Ademir Ferreira da Silva","Hongzhi Wang","Jitendra Singh","Tanveer Syeda-Mahmood"],"pdf_url":"https://arxiv.org/pdf/2311.13016v1.pdf","comment":"This paper was accepted by the 2023 IEEE International Geoscience and\n  Remote Sensing Symposium (IGARSS 2023)"},{"id":"http://arxiv.org/abs/2311.13009v1","updated":"2023-11-21T21:36:09Z","published":"2023-11-21T21:36:09Z","title":"3D Compression Using Neural Fields","summary":"  Neural Fields (NFs) have gained momentum as a tool for compressing various\ndata modalities - e.g. images and videos. This work leverages previous advances\nand proposes a novel NF-based compression algorithm for 3D data. We derive two\nversions of our approach - one tailored to watertight shapes based on Signed\nDistance Fields (SDFs) and, more generally, one for arbitrary non-watertight\nshapes using Unsigned Distance Fields (UDFs). We demonstrate that our method\nexcels at geometry compression on 3D point clouds as well as meshes. Moreover,\nwe show that, due to the NF formulation, it is straightforward to extend our\ncompression algorithm to compress both geometry and attribute (e.g. color) of\n3D data.\n","authors":["Janis Postels","Yannick Strümpler","Klara Reichard","Luc Van Gool","Federico Tombari"],"pdf_url":"https://arxiv.org/pdf/2311.13009v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.01121v2","updated":"2023-11-21T21:04:24Z","published":"2023-07-03T15:51:39Z","title":"Artifacts Mapping: Multi-Modal Semantic Mapping for Object Detection and\n  3D Localization","summary":"  Geometric navigation is nowadays a well-established field of robotics and the\nresearch focus is shifting towards higher-level scene understanding, such as\nSemantic Mapping. When a robot needs to interact with its environment, it must\nbe able to comprehend the contextual information of its surroundings. This work\nfocuses on classifying and localising objects within a map, which is under\nconstruction (SLAM) or already built. To further explore this direction, we\npropose a framework that can autonomously detect and localize predefined\nobjects in a known environment using a multi-modal sensor fusion approach\n(combining RGB and depth data from an RGB-D camera and a lidar). The framework\nconsists of three key elements: understanding the environment through RGB data,\nestimating depth through multi-modal sensor fusion, and managing artifacts\n(i.e., filtering and stabilizing measurements). The experiments show that the\nproposed framework can accurately detect 98% of the objects in the real sample\nenvironment, without post-processing, while 85% and 80% of the objects were\nmapped using the single RGBD camera or RGB + lidar setup respectively. The\ncomparison with single-sensor (camera or lidar) experiments is performed to\nshow that sensor fusion allows the robot to accurately detect near and far\nobstacles, which would have been noisy or imprecise in a purely visual or\nlaser-based approach.\n","authors":["Federico Rollo","Gennaro Raiola","Andrea Zunino","Nikolaos Tsagarakis","Arash Ajoudani"],"pdf_url":"https://arxiv.org/pdf/2307.01121v2.pdf","comment":"Accepted to the 11th European Conference on Mobile Robots (ECMR) 2023"},{"id":"http://arxiv.org/abs/2311.12993v1","updated":"2023-11-21T21:00:42Z","published":"2023-11-21T21:00:42Z","title":"AI for Agriculture: the Comparison of Semantic Segmentation Methods for\n  Crop Mapping with Sentinel-2 Imagery","summary":"  Crop mapping is one of the most common tasks in artificial intelligence for\nagriculture due to higher food demands from a growing population and increased\nawareness of climate change. In case of vineyards, the texture is very\nimportant for crop segmentation: with higher resolution satellite imagery the\ntexture is easily detected by majority of state-of-the-art algorithms. However,\nthis task becomes increasingly more difficult as the resolution of satellite\nimagery decreases and the information about the texture becomes unavailable. In\nthis paper we aim to explore the main machine learning methods that can be used\nwith freely available satellite imagery and discuss how and when they can be\napplied for vineyard segmentation problem. We assess the effectiveness of\nvarious widely-used machine learning techniques and offer guidance on selecting\nthe most suitable model for specific scenarios.\n","authors":["Irina Korotkova","Natalia Efremova"],"pdf_url":"https://arxiv.org/pdf/2311.12993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12992v1","updated":"2023-11-21T20:59:27Z","published":"2023-11-21T20:59:27Z","title":"FollowMe: a Robust Person Following Framework Based on Re-Identification\n  and Gestures","summary":"  Human-robot interaction (HRI) has become a crucial enabler in houses and\nindustries for facilitating operational flexibility. When it comes to mobile\ncollaborative robots, this flexibility can be further increased due to the\nautonomous mobility and navigation capacity of the robotic agents, expanding\ntheir workspace and consequently, the personalizable assistance they can\nprovide to the human operators. This however requires that the robot is capable\nof detecting and identifying the human counterpart in all stages of the\ncollaborative task, and in particular while following a human in crowded\nworkplaces. To respond to this need, we developed a unified perception and\nnavigation framework, which enables the robot to identify and follow a target\nperson using a combination of visual Re-Identification (Re-ID), hand gestures\ndetection, and collision-free navigation. The Re-ID module can autonomously\nlearn the features of a target person and use the acquired knowledge to\nvisually re-identify the target. The navigation stack is used to follow the\ntarget avoiding obstacles and other individuals in the environment. Experiments\nare conducted with few subjects in a laboratory setting where some unknown\ndynamic obstacles are introduced.\n","authors":["Federico Rollo","Andrea Zunino","Gennaro Raiola","Fabio Amadio","Arash Ajoudani","Nikolaos Tsagarakis"],"pdf_url":"https://arxiv.org/pdf/2311.12992v1.pdf","comment":"published in \"2023 IEEE International Conference on Advanced Robotics\n  and Its Social Impacts (ARSO)\""},{"id":"http://arxiv.org/abs/2311.12981v1","updated":"2023-11-21T20:33:17Z","published":"2023-11-21T20:33:17Z","title":"SD-NAE: Generating Natural Adversarial Examples with Stable Diffusion","summary":"  Robustly evaluating deep learning image classifiers is challenging due to\nsome limitations of standard datasets. Natural Adversarial Examples (NAEs),\narising naturally from the environment and capable of deceiving classifiers,\nare instrumental in identifying vulnerabilities in trained models. Existing\nworks collect such NAEs by filtering from a huge set of real images, a process\nthat is passive and lacks control. In this work, we propose to actively\nsynthesize NAEs with the state-of-the-art Stable Diffusion. Specifically, our\nmethod formulates a controlled optimization process, where we perturb the token\nembedding that corresponds to a specified class to synthesize NAEs. The\ngeneration is guided by the gradient of loss from the target classifier so that\nthe created image closely mimics the ground-truth class yet fools the\nclassifier. Named SD-NAE (Stable Diffusion for Natural Adversarial Examples),\nour innovative method is effective in producing valid and useful NAEs, which is\ndemonstrated through a meticulously designed experiment. Our work thereby\nprovides a valuable method for obtaining challenging evaluation data, which in\nturn can potentially advance the development of more robust deep learning\nmodels. Code is available at https://github.com/linyueqian/SD-NAE.\n","authors":["Yueqian Lin","Jingyang Zhang","Yiran Chen","Hai Li"],"pdf_url":"https://arxiv.org/pdf/2311.12981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12967v1","updated":"2023-11-21T20:12:29Z","published":"2023-11-21T20:12:29Z","title":"Robustifying Generalizable Implicit Shape Networks with a Tunable\n  Non-Parametric Model","summary":"  Feedforward generalizable models for implicit shape reconstruction from\nunoriented point cloud present multiple advantages, including high performance\nand inference speed. However, they still suffer from generalization issues,\nranging from underfitting the input point cloud, to misrepresenting samples\noutside of the training data distribution, or with toplogies unseen at\ntraining. We propose here an efficient mechanism to remedy some of these\nlimitations at test time. We combine the inter-shape data prior of the network\nwith an intra-shape regularization prior of a Nystr\\\"om Kernel Ridge\nRegression, that we further adapt by fitting its hyperprameters to the current\nshape. The resulting shape function defined in a shape specific Reproducing\nKernel Hilbert Space benefits from desirable stability and efficiency\nproperties and grants a shape adaptive expressiveness-robustness trade-off. We\ndemonstrate the improvement obtained through our method with respect to\nbaselines and the state-of-the-art using synthetic and real data.\n","authors":["Amine Ouasfi","Adnane Boukhayma"],"pdf_url":"https://arxiv.org/pdf/2311.12967v1.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.12956v1","updated":"2023-11-21T19:49:13Z","published":"2023-11-21T19:49:13Z","title":"Innovative Horizons in Aerial Imagery: LSKNet Meets DiffusionDet for\n  Advanced Object Detection","summary":"  In the realm of aerial image analysis, object detection plays a pivotal role,\nwith significant implications for areas such as remote sensing, urban planning,\nand disaster management. This study addresses the inherent challenges in this\ndomain, notably the detection of small objects, managing densely packed\nelements, and accounting for diverse orientations. We present an in-depth\nevaluation of an object detection model that integrates the Large Selective\nKernel Network (LSKNet)as its backbone with the DiffusionDet head, utilizing\nthe iSAID dataset for empirical analysis. Our approach encompasses the\nintroduction of novel methodologies and extensive ablation studies. These\nstudies critically assess various aspects such as loss functions, box\nregression techniques, and classification strategies to refine the model's\nprecision in object detection. The paper details the experimental application\nof the LSKNet backbone in synergy with the DiffusionDet heads, a combination\ntailored to meet the specific challenges in aerial image object detection. The\nfindings of this research indicate a substantial enhancement in the model's\nperformance, especially in the accuracy-time tradeoff. The proposed model\nachieves a mean average precision (MAP) of approximately 45.7%, which is a\nsignificant improvement, outperforming the RCNN model by 4.7% on the same\ndataset. This advancement underscores the effectiveness of the proposed\nmodifications and sets a new benchmark in aerial image analysis, paving the way\nfor more accurate and efficient object detection methodologies. The code is\npublicly available at https://github.com/SashaMatsun/LSKDiffDet\n","authors":["Ahmed Sharshar","Aleksandr Matsun"],"pdf_url":"https://arxiv.org/pdf/2311.12956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05705v2","updated":"2023-11-21T19:24:43Z","published":"2023-06-09T06:54:58Z","title":"On the Challenges and Perspectives of Foundation Models for Medical\n  Image Analysis","summary":"  This article discusses the opportunities, applications and future directions\nof large-scale pre-trained models, i.e., foundation models, for analyzing\nmedical images. Medical foundation models have immense potential in solving a\nwide range of downstream tasks, as they can help to accelerate the development\nof accurate and robust models, reduce the large amounts of required labeled\ndata, preserve the privacy and confidentiality of patient data. Specifically,\nwe illustrate the \"spectrum\" of medical foundation models, ranging from general\nvision models, modality-specific models, to organ/task-specific models,\nhighlighting their challenges, opportunities and applications. We also discuss\nhow foundation models can be leveraged in downstream medical tasks to enhance\nthe accuracy and efficiency of medical image analysis, leading to more precise\ndiagnosis and treatment decisions.\n","authors":["Shaoting Zhang","Dimitris Metaxas"],"pdf_url":"https://arxiv.org/pdf/2306.05705v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12919v1","updated":"2023-11-21T18:43:07Z","published":"2023-11-21T18:43:07Z","title":"SPOT! Revisiting Video-Language Models for Event Understanding","summary":"  Understanding videos is an important research topic for multimodal learning.\nLeveraging large-scale datasets of web-crawled video-text pairs as weak\nsupervision has become a pre-training paradigm for learning joint\nrepresentations and showcased remarkable potential in video understanding\ntasks. However, videos can be multi-event and multi-grained, while these\nvideo-text pairs usually contain only broad-level video captions. This raises a\nquestion: with such weak supervision, can video representation in\nvideo-language models gain the ability to distinguish even factual\ndiscrepancies in textual description and understand fine-grained events? To\naddress this, we introduce SPOT Prober, to benchmark existing video-language\nmodels's capacities of distinguishing event-level discrepancies as an indicator\nof models' event understanding ability. Our approach involves extracting events\nas tuples (<Subject, Predicate, Object, Attribute, Timestamps>) from videos and\ngenerating false event tuples by manipulating tuple components systematically.\nWe reevaluate the existing video-language models with these positive and\nnegative captions and find they fail to distinguish most of the manipulated\nevents. Based on our findings, we propose to plug in these manipulated event\ncaptions as hard negative samples and find them effective in enhancing models\nfor event understanding.\n","authors":["Gengyuan Zhang","Jinhe Bi","Jindong Gu","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2311.12919v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2311.12914v1","updated":"2023-11-21T17:55:46Z","published":"2023-11-21T17:55:46Z","title":"Attention Deficit is Ordered! Fooling Deformable Vision Transformers\n  with Collaborative Adversarial Patches","summary":"  The latest generation of transformer-based vision models have proven to be\nsuperior to Convolutional Neural Network (CNN)-based models across several\nvision tasks, largely attributed to their remarkable prowess in relation\nmodeling. Deformable vision transformers significantly reduce the quadratic\ncomplexity of modeling attention by using sparse attention structures, enabling\nthem to be used in larger scale applications such as multi-view vision systems.\nRecent work demonstrated adversarial attacks against transformers; we show that\nthese attacks do not transfer to deformable transformers due to their sparse\nattention structure. Specifically, attention in deformable transformers is\nmodeled using pointers to the most relevant other tokens. In this work, we\ncontribute for the first time adversarial attacks that manipulate the attention\nof deformable transformers, distracting them to focus on irrelevant parts of\nthe image. We also develop new collaborative attacks where a source patch\nmanipulates attention to point to a target patch that adversarially attacks the\nsystem. In our experiments, we find that only 1% patched area of the input\nfield can lead to 0% AP. We also show that the attacks provide substantial\nversatility to support different attacker scenarios because of their ability to\nredirect attention under the attacker control.\n","authors":["Quazi Mishkatul Alam","Bilel Tarchoun","Ihsen Alouani","Nael Abu-Ghazaleh"],"pdf_url":"https://arxiv.org/pdf/2311.12914v1.pdf","comment":"9 pages, 10 figures"},{"id":"http://arxiv.org/abs/2311.12912v1","updated":"2023-11-21T17:27:20Z","published":"2023-11-21T17:27:20Z","title":"Q-Seg: Quantum Annealing-based Unsupervised Image Segmentation","summary":"  In this study, we present Q-Seg, a novel unsupervised image segmentation\nmethod based on quantum annealing, tailored for existing quantum hardware. We\nformulate the pixel-wise segmentation problem, which assimilates spectral and\nspatial information of the image, as a graph-cut optimization task. Our method\nefficiently leverages the interconnected qubit topology of the D-Wave Advantage\ndevice, offering superior scalability over existing quantum approaches and\noutperforming state-of-the-art classical methods. Our empirical evaluations on\nsynthetic datasets reveal that Q-Seg offers better runtime performance against\nthe classical optimizer Gurobi. Furthermore, we evaluate our method on\nsegmentation of Earth Observation images, an area of application where the\namount of labeled data is usually very limited. In this case, Q-Seg\ndemonstrates near-optimal results in flood mapping detection with respect to\nclassical supervised state-of-the-art machine learning methods. Also, Q-Seg\nprovides enhanced segmentation for forest coverage compared to existing\nannotated masks. Thus, Q-Seg emerges as a viable alternative for real-world\napplications using available quantum hardware, particularly in scenarios where\nthe lack of labeled data and computational runtime are critical.\n","authors":["Supreeth Mysore Venkatesh","Antonio Macaluso","Marlon Nuske","Matthias Klusch","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2311.12912v1.pdf","comment":"12 pages, 9 figures, 1 table"},{"id":"http://arxiv.org/abs/2311.12908v1","updated":"2023-11-21T15:24:05Z","published":"2023-11-21T15:24:05Z","title":"Diffusion Model Alignment Using Direct Preference Optimization","summary":"  Large language models (LLMs) are fine-tuned using human comparison data with\nReinforcement Learning from Human Feedback (RLHF) methods to make them better\naligned with users' preferences. In contrast to LLMs, human preference learning\nhas not been widely explored in text-to-image diffusion models; the best\nexisting approach is to fine-tune a pretrained model using carefully curated\nhigh quality images and captions to improve visual appeal and text alignment.\nWe propose Diffusion-DPO, a method to align diffusion models to human\npreferences by directly optimizing on human comparison data. Diffusion-DPO is\nadapted from the recently developed Direct Preference Optimization (DPO), a\nsimpler alternative to RLHF which directly optimizes a policy that best\nsatisfies human preferences under a classification objective. We re-formulate\nDPO to account for a diffusion model notion of likelihood, utilizing the\nevidence lower bound to derive a differentiable objective. Using the Pick-a-Pic\ndataset of 851K crowdsourced pairwise preferences, we fine-tune the base model\nof the state-of-the-art Stable Diffusion XL (SDXL)-1.0 model with\nDiffusion-DPO. Our fine-tuned base model significantly outperforms both base\nSDXL-1.0 and the larger SDXL-1.0 model consisting of an additional refinement\nmodel in human evaluation, improving visual appeal and prompt alignment. We\nalso develop a variant that uses AI feedback and has comparable performance to\ntraining on human preferences, opening the door for scaling of diffusion model\nalignment methods.\n","authors":["Bram Wallace","Meihua Dang","Rafael Rafailov","Linqi Zhou","Aaron Lou","Senthil Purushwalkam","Stefano Ermon","Caiming Xiong","Shafiq Joty","Nikhil Naik"],"pdf_url":"https://arxiv.org/pdf/2311.12908v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2311.03488v3","updated":"2023-11-21T03:08:37Z","published":"2023-11-06T19:52:55Z","title":"Multi-Resolution Diffusion for Privacy-Sensitive Recommender Systems","summary":"  While recommender systems have become an integral component of the Web\nexperience, their heavy reliance on user data raises privacy and security\nconcerns. Substituting user data with synthetic data can address these\nconcerns, but accurately replicating these real-world datasets has been a\nnotoriously challenging problem. Recent advancements in generative AI have\ndemonstrated the impressive capabilities of diffusion models in generating\nrealistic data across various domains. In this work we introduce a Score-based\nDiffusion Recommendation Module (SDRM), which captures the intricate patterns\nof real-world datasets required for training highly accurate recommender\nsystems. SDRM allows for the generation of synthetic data that can replace\nexisting datasets to preserve user privacy, or augment existing datasets to\naddress excessive data sparsity. Our method outperforms competing baselines\nsuch as generative adversarial networks, variational autoencoders, and recently\nproposed diffusion models in synthesizing various datasets to replace or\naugment the original data by an average improvement of 4.30% in Recall@$k$ and\n4.65% in NDCG@$k$.\n","authors":["Derek Lilienthal","Paul Mello","Magdalini Eirinaki","Stas Tiomkin"],"pdf_url":"https://arxiv.org/pdf/2311.03488v3.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2205.10852v6","updated":"2023-11-21T16:36:43Z","published":"2022-05-22T15:30:18Z","title":"Relphormer: Relational Graph Transformer for Knowledge Graph\n  Representations","summary":"  Transformers have achieved remarkable performance in widespread fields,\nincluding natural language processing, computer vision and graph mining.\nHowever, vanilla Transformer architectures have not yielded promising\nimprovements in the Knowledge Graph (KG) representations, where the\ntranslational distance paradigm dominates this area. Note that vanilla\nTransformer architectures struggle to capture the intrinsically heterogeneous\nstructural and semantic information of knowledge graphs. To this end, we\npropose a new variant of Transformer for knowledge graph representations dubbed\nRelphormer. Specifically, we introduce Triple2Seq which can dynamically sample\ncontextualized sub-graph sequences as the input to alleviate the heterogeneity\nissue. We propose a novel structure-enhanced self-attention mechanism to encode\nthe relational information and keep the semantic information within entities\nand relations. Moreover, we utilize masked knowledge modeling for general\nknowledge graph representation learning, which can be applied to various\nKG-based tasks including knowledge graph completion, question answering, and\nrecommendation. Experimental results on six datasets show that Relphormer can\nobtain better performance compared with baselines. Code is available in\nhttps://github.com/zjunlp/Relphormer.\n","authors":["Zhen Bi","Siyuan Cheng","Jing Chen","Xiaozhuan Liang","Feiyu Xiong","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.10852v6.pdf","comment":"Neurocomputing 2023"},{"id":"http://arxiv.org/abs/2311.12474v1","updated":"2023-11-21T09:36:11Z","published":"2023-11-21T09:36:11Z","title":"CSMeD: Bridging the Dataset Gap in Automated Citation Screening for\n  Systematic Literature Reviews","summary":"  Systematic literature reviews (SLRs) play an essential role in summarising,\nsynthesising and validating scientific evidence. In recent years, there has\nbeen a growing interest in using machine learning techniques to automate the\nidentification of relevant studies for SLRs. However, the lack of standardised\nevaluation datasets makes comparing the performance of such automated\nliterature screening systems difficult. In this paper, we analyse the citation\nscreening evaluation datasets, revealing that many of the available datasets\nare either too small, suffer from data leakage or have limited applicability to\nsystems treating automated literature screening as a classification task, as\nopposed to, for example, a retrieval or question-answering task. To address\nthese challenges, we introduce CSMeD, a meta-dataset consolidating nine\npublicly released collections, providing unified access to 325 SLRs from the\nfields of medicine and computer science. CSMeD serves as a comprehensive\nresource for training and evaluating the performance of automated citation\nscreening models. Additionally, we introduce CSMeD-FT, a new dataset designed\nexplicitly for evaluating the full text publication screening task. To\ndemonstrate the utility of CSMeD, we conduct experiments and establish\nbaselines on new datasets.\n","authors":["Wojciech Kusa","Oscar E. Mendoza","Matthias Samwald","Petr Knoth","Allan Hanbury"],"pdf_url":"https://arxiv.org/pdf/2311.12474v1.pdf","comment":"Accepted at NeurIPS 2023 Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2311.12404v1","updated":"2023-11-21T07:43:50Z","published":"2023-11-21T07:43:50Z","title":"InterPrompt: Interpretable Prompting for Interrelated Interpersonal Risk\n  Factors in Reddit Posts","summary":"  Mental health professionals and clinicians have observed the upsurge of\nmental disorders due to Interpersonal Risk Factors (IRFs). To simulate the\nhuman-in-the-loop triaging scenario for early detection of mental health\ndisorders, we recognized textual indications to ascertain these IRFs : Thwarted\nBelongingness (TBe) and Perceived Burdensomeness (PBu) within personal\nnarratives. In light of this, we use N-shot learning with GPT-3 model on the\nIRF dataset, and underscored the importance of fine-tuning GPT-3 model to\nincorporate the context-specific sensitivity and the interconnectedness of\ntextual cues that represent both IRFs.\n  In this paper, we introduce an Interpretable Prompting (InterPrompt)} method\nto boost the attention mechanism by fine-tuning the GPT-3 model. This allows a\nmore sophisticated level of language modification by adjusting the pre-trained\nweights. Our model learns to detect usual patterns and underlying connections\nacross both the IRFs, which leads to better system-level explainability and\ntrustworthiness. The results of our research demonstrate that all four variants\nof GPT-3 model, when fine-tuned with InterPrompt, perform considerably better\nas compared to the baseline methods, both in terms of classification and\nexplanation generation.\n","authors":["MSVPJ Sathvik","Surjodeep Sarkar","Chandni Saxena","Sunghwan Sohn","Muskan Garg"],"pdf_url":"https://arxiv.org/pdf/2311.12404v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2311.12389v1","updated":"2023-11-21T07:01:05Z","published":"2023-11-21T07:01:05Z","title":"Linear-time online visibility graph transformation algorithm: for both\n  natural and horizontal visibility criteria","summary":"  Visibility graph (VG) transformation is a technique used to convert a time\nseries into a graph based on specific visibility criteria. It has attracted\nincreasing interest in the fields of time series analysis, forecasting, and\nclassification. Optimizing the VG transformation algorithm to accelerate the\nprocess is a critical aspect of VG-related research, as it enhances the\napplicability of VG transformation in latency-sensitive areas and conserves\ncomputational resources. In the real world, many time series are presented in\nthe form of data streams. Despite the proposal of the concept of VG's online\nfunctionality, previous studies have not thoroughly explored the acceleration\nof VG transformation by leveraging the characteristics of data streams. In this\npaper, we propose that an efficient online VG algorithm should adhere to two\ncriteria and develop a linear-time method, termed the LOT framework, for both\nnatural and horizontal visibility graph transformations in data stream\nscenarios. Experiments are conducted on two datasets, comparing our approach\nwith five existing methods as baselines. The results demonstrate the validity\nand promising computational efficiency of our framework.\n","authors":["Yusheng Huang","Yong Deng"],"pdf_url":"https://arxiv.org/pdf/2311.12389v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14884v2","updated":"2023-11-21T05:28:30Z","published":"2023-10-23T12:53:22Z","title":"Budgeted Embedding Table For Recommender Systems","summary":"  At the heart of contemporary recommender systems (RSs) are latent factor\nmodels that provide quality recommendation experience to users. These models\nuse embedding vectors, which are typically of a uniform and fixed size, to\nrepresent users and items. As the number of users and items continues to grow,\nthis design becomes inefficient and hard to scale. Recent lightweight embedding\nmethods have enabled different users and items to have diverse embedding sizes,\nbut are commonly subject to two major drawbacks. Firstly, they limit the\nembedding size search to optimizing a heuristic balancing the recommendation\nquality and the memory complexity, where the trade-off coefficient needs to be\nmanually tuned for every memory budget requested. The implicitly enforced\nmemory complexity term can even fail to cap the parameter usage, making the\nresultant embedding table fail to meet the memory budget strictly. Secondly,\nmost solutions, especially reinforcement learning based ones derive and\noptimize the embedding size for each each user/item on an instance-by-instance\nbasis, which impedes the search efficiency. In this paper, we propose Budgeted\nEmbedding Table (BET), a novel method that generates table-level actions (i.e.,\nembedding sizes for all users and items) that is guaranteed to meet\npre-specified memory budgets. Furthermore, by leveraging a set-based action\nformulation and engaging set representation learning, we present an innovative\naction search strategy powered by an action fitness predictor that efficiently\nevaluates each table-level action. Experiments have shown state-of-the-art\nperformance on two real-world datasets when BET is paired with three popular\nrecommender models under different memory budgets.\n","authors":["Yunke Qu","Tong Chen","Quoc Viet Hung Nguyen","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2310.14884v2.pdf","comment":"Accepted by WSDM 2024"},{"id":"http://arxiv.org/abs/2311.12355v1","updated":"2023-11-21T05:15:56Z","published":"2023-11-21T05:15:56Z","title":"Utilizing Language Models for Tour Itinerary Recommendation","summary":"  Tour itinerary recommendation involves planning a sequence of relevant\nPoint-of-Interest (POIs), which combines challenges from the fields of both\nOperations Research (OR) and Recommendation Systems (RS). As an OR problem,\nthere is the need to maximize a certain utility (e.g., popularity of POIs in\nthe tour) while adhering to some constraints (e.g., maximum time for the tour).\nAs a RS problem, it is heavily related to problem or filtering or ranking a\nsubset of POIs that are relevant to a user and recommending it as part of an\nitinerary. In this paper, we explore the use of language models for the task of\ntour itinerary recommendation and planning. This task has the unique\nrequirement of recommending personalized POIs relevant to users and planning\nthese POIs as an itinerary that satisfies various constraints. We discuss some\napproaches in this area, such as using word embedding techniques like Word2Vec\nand GloVe for learning POI embeddings and transformer-based techniques like\nBERT for generating\n  itineraries.\n","authors":["Ngai Lam Ho","Kwan Hui Lim"],"pdf_url":"https://arxiv.org/pdf/2311.12355v1.pdf","comment":"PMAI23 @IJCAI 2023 2nd International Workshop on Process Management\n  in the AI era"},{"id":"http://arxiv.org/abs/2304.07763v5","updated":"2023-11-21T05:03:06Z","published":"2023-04-16T12:30:33Z","title":"Meta-optimized Contrastive Learning for Sequential Recommendation","summary":"  Contrastive Learning (CL) performances as a rising approach to address the\nchallenge of sparse and noisy recommendation data. Although having achieved\npromising results, most existing CL methods only perform either hand-crafted\ndata or model augmentation for generating contrastive pairs to find a proper\naugmentation operation for different datasets, which makes the model hard to\ngeneralize. Additionally, since insufficient input data may lead the encoder to\nlearn collapsed embeddings, these CL methods expect a relatively large number\nof training data (e.g., large batch size or memory bank) to contrast. However,\nnot all contrastive pairs are always informative and discriminative enough for\nthe training processing. Therefore, a more general CL-based recommendation\nmodel called Meta-optimized Contrastive Learning for sequential Recommendation\n(MCLRec) is proposed in this work. By applying both data augmentation and\nlearnable model augmentation operations, this work innovates the standard CL\nframework by contrasting data and model augmented views for adaptively\ncapturing the informative features hidden in stochastic data augmentation.\nMoreover, MCLRec utilizes a meta-learning manner to guide the updating of the\nmodel augmenters, which helps to improve the quality of contrastive pairs\nwithout enlarging the amount of input data. Finally, a contrastive\nregularization term is considered to encourage the augmentation model to\ngenerate more informative augmented views and avoid too similar contrastive\npairs within the meta updating. The experimental results on commonly used\ndatasets validate the effectiveness of MCLRec.\n","authors":["Xiuyuan Qin","Huanhuan Yuan","Pengpeng Zhao","Junhua Fang","Fuzhen Zhuang","Guanfeng Liu","Victor Sheng"],"pdf_url":"https://arxiv.org/pdf/2304.07763v5.pdf","comment":"11 Pages,8 figures,SIGIR2023"},{"id":"http://arxiv.org/abs/2311.12338v1","updated":"2023-11-21T04:14:09Z","published":"2023-11-21T04:14:09Z","title":"A Survey on Large Language Models for Personalized and Explainable\n  Recommendations","summary":"  In recent years, Recommender Systems(RS) have witnessed a transformative\nshift with the advent of Large Language Models(LLMs) in the field of Natural\nLanguage Processing(NLP). These models such as OpenAI's GPT-3.5/4, Llama from\nMeta, have demonstrated unprecedented capabilities in understanding and\ngenerating human-like text. This has led to a paradigm shift in the realm of\npersonalized and explainable recommendations, as LLMs offer a versatile toolset\nfor processing vast amounts of textual data to enhance user experiences. To\nprovide a comprehensive understanding of the existing LLM-based recommendation\nsystems, this survey aims to analyze how RS can benefit from LLM-based\nmethodologies. Furthermore, we describe major challenges in Personalized\nExplanation Generating(PEG) tasks, which are cold-start problems, unfairness\nand bias problems in RS.\n","authors":["Junyi Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12329v1","updated":"2023-11-21T03:42:15Z","published":"2023-11-21T03:42:15Z","title":"Graph Neural Ordinary Differential Equations-based method for\n  Collaborative Filtering","summary":"  Graph Convolution Networks (GCNs) are widely considered state-of-the-art for\ncollaborative filtering. Although several GCN-based methods have been proposed\nand achieved state-of-the-art performance in various tasks, they can be\ncomputationally expensive and time-consuming to train if too many layers are\ncreated. However, since the linear GCN model can be interpreted as a\ndifferential equation, it is possible to transfer it to an ODE problem. This\ninspired us to address the computational limitations of GCN-based models by\ndesigning a simple and efficient NODE-based model that can skip some GCN layers\nto reach the final state, thus avoiding the need to create many layers. In this\nwork, we propose a Graph Neural Ordinary Differential Equation-based method for\nCollaborative Filtering (GODE-CF). This method estimates the final embedding by\nutilizing the information captured by one or two GCN layers. To validate our\napproach, we conducted experiments on multiple datasets. The results\ndemonstrate that our model outperforms competitive baselines, including\nGCN-based models and other state-of-the-art CF methods. Notably, our proposed\nGODE-CF model has several advantages over traditional GCN-based models. It is\nsimple, efficient, and has a fast training time, making it a practical choice\nfor real-world situations.\n","authors":["Ke Xu","Yuanjie Zhu","Weizhi Zhang","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2311.12329v1.pdf","comment":"Accepted by ICDM 2023"},{"id":"http://arxiv.org/abs/2311.12287v1","updated":"2023-11-21T02:01:01Z","published":"2023-11-21T02:01:01Z","title":"Adapting LLMs for Efficient, Personalized Information Retrieval: Methods\n  and Implications","summary":"  The advent of Large Language Models (LLMs) heralds a pivotal shift in online\nuser interactions with information. Traditional Information Retrieval (IR)\nsystems primarily relied on query-document matching, whereas LLMs excel in\ncomprehending and generating human-like text, thereby enriching the IR\nexperience significantly. While LLMs are often associated with chatbot\nfunctionalities, this paper extends the discussion to their explicit\napplication in information retrieval. We explore methodologies to optimize the\nretrieval process, select optimal models, and effectively scale and orchestrate\nLLMs, aiming for cost-efficiency and enhanced result accuracy. A notable\nchallenge, model hallucination-where the model yields inaccurate or\nmisinterpreted data-is addressed alongside other model-specific hurdles. Our\ndiscourse extends to crucial considerations including user privacy, data\noptimization, and the necessity for system clarity and interpretability.\nThrough a comprehensive examination, we unveil not only innovative strategies\nfor integrating Language Models (LLMs) with Information Retrieval (IR) systems,\nbut also the consequential considerations that underline the need for a\nbalanced approach aligned with user-centric principles.\n","authors":["Samira Ghodratnama","Mehrdad Zakershahrak"],"pdf_url":"https://arxiv.org/pdf/2311.12287v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12257v1","updated":"2023-11-21T00:37:47Z","published":"2023-11-21T00:37:47Z","title":"Equipping Pretrained Unconditional Music Transformers with Instrument\n  and Genre Controls","summary":"  The ''pretraining-and-finetuning'' paradigm has become a norm for training\ndomain-specific models in natural language processing and computer vision. In\nthis work, we aim to examine this paradigm for symbolic music generation\nthrough leveraging the largest ever symbolic music dataset sourced from the\nMuseScore forum. We first pretrain a large unconditional transformer model\nusing 1.5 million songs. We then propose a simple technique to equip this\npretrained unconditional music transformer model with instrument and genre\ncontrols by finetuning the model with additional control tokens. Our proposed\nrepresentation offers improved high-level controllability and expressiveness\nagainst two existing representations. The experimental results show that the\nproposed model can successfully generate music with user-specified instruments\nand genre. In a subjective listening test, the proposed model outperforms the\npretrained baseline model in terms of coherence, harmony, arrangement and\noverall quality.\n","authors":["Weihan Xu","Julian McAuley","Shlomo Dubnov","Hao-Wen Dong"],"pdf_url":"https://arxiv.org/pdf/2311.12257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08350v2","updated":"2023-11-21T22:09:27Z","published":"2023-11-14T17:48:27Z","title":"ChoralSynth: Synthetic Dataset of Choral Singing","summary":"  Choral singing, a widely practiced form of ensemble singing, lacks\ncomprehensive datasets in the realm of Music Information Retrieval (MIR)\nresearch, due to challenges arising from the requirement to curate multitrack\nrecordings. To address this, we devised a novel methodology, leveraging\nstate-of-the-art synthesizers to create and curate quality renditions. The\nscores were sourced from Choral Public Domain Library(CPDL). This work is done\nin collaboration with a diverse team of musicians, software engineers and\nresearchers. The resulting dataset, complete with its associated metadata, and\nmethodology is released as part of this work, opening up new avenues for\nexploration and advancement in the field of singing voice research.\n","authors":["Jyoti Narang","Viviana De La Vega","Xavier Lizarraga","Oscar Mayor","Hector Parra","Jordi Janer","Xavier Serra"],"pdf_url":"https://arxiv.org/pdf/2311.08350v2.pdf","comment":"Dataset Link: https://doi.org/10.5281/zenodo.10137883"},{"id":"http://arxiv.org/abs/2311.12955v1","updated":"2023-11-21T19:41:46Z","published":"2023-11-21T19:41:46Z","title":"Don't forget private retrieval: distributed private similarity search\n  for large language models","summary":"  While the flexible capabilities of large language models (LLMs) allow them to\nanswer a range of queries based on existing learned knowledge, information\nretrieval to augment generation is an important tool to allow LLMs to answer\nquestions on information not included in pre-training data. Such private\ninformation is increasingly being generated in a wide array of distributed\ncontexts by organizations and individuals. Performing such information\nretrieval using neural embeddings of queries and documents always leaked\ninformation about queries and database content unless both were stored locally.\nWe present Private Retrieval Augmented Generation (PRAG), an approach that uses\nmulti-party computation (MPC) to securely transmit queries to a distributed set\nof servers containing a privately constructed database to return top-k and\napproximate top-k documents. This is a first-of-its-kind approach to dense\ninformation retrieval that ensures no server observes a client's query or can\nsee the database content. The approach introduces a novel MPC friendly protocol\nfor inverted file approximate search (IVF) that allows for fast document search\nover distributed and private data in sublinear communication complexity. This\nwork presents new avenues through which data for use in LLMs can be accessed\nand used without needing to centralize or forgo privacy.\n","authors":["Guy Zyskind","Tobin South","Alex Pentland"],"pdf_url":"https://arxiv.org/pdf/2311.12955v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12894v1","updated":"2023-11-21T08:20:38Z","published":"2023-11-21T08:20:38Z","title":"Attribute-Aware Deep Hashing with Self-Consistency for Large-Scale\n  Fine-Grained Image Retrieval","summary":"  Our work focuses on tackling large-scale fine-grained image retrieval as\nranking the images depicting the concept of interests (i.e., the same\nsub-category labels) highest based on the fine-grained details in the query. It\nis desirable to alleviate the challenges of both fine-grained nature of small\ninter-class variations with large intra-class variations and explosive growth\nof fine-grained data for such a practical task. In this paper, we propose\nattribute-aware hashing networks with self-consistency for generating\nattribute-aware hash codes to not only make the retrieval process efficient,\nbut also establish explicit correspondences between hash codes and visual\nattributes. Specifically, based on the captured visual representations by\nattention, we develop an encoder-decoder structure network of a reconstruction\ntask to unsupervisedly distill high-level attribute-specific vectors from the\nappearance-specific visual representations without attribute annotations. Our\nmodels are also equipped with a feature decorrelation constraint upon these\nattribute vectors to strengthen their representative abilities. Then, driven by\npreserving original entities' similarity, the required hash codes can be\ngenerated from these attribute-specific vectors and thus become\nattribute-aware. Furthermore, to combat simplicity bias in deep hashing, we\nconsider the model design from the perspective of the self-consistency\nprinciple and propose to further enhance models' self-consistency by equipping\nan additional image reconstruction path. Comprehensive quantitative experiments\nunder diverse empirical settings on six fine-grained retrieval datasets and two\ngeneric retrieval datasets show the superiority of our models over competing\nmethods.\n","authors":["Xiu-Shen Wei","Yang Shen","Xuhao Sun","Peng Wang","Yuxin Peng"],"pdf_url":"https://arxiv.org/pdf/2311.12894v1.pdf","comment":"Accepted by IEEE TPAMI"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2311.11995v2","updated":"2023-11-21T17:29:59Z","published":"2023-11-20T18:26:01Z","title":"BrainWash: A Poisoning Attack to Forget in Continual Learning","summary":"  Continual learning has gained substantial attention within the deep learning\ncommunity, offering promising solutions to the challenging problem of\nsequential learning. Yet, a largely unexplored facet of this paradigm is its\nsusceptibility to adversarial attacks, especially with the aim of inducing\nforgetting. In this paper, we introduce \"BrainWash,\" a novel data poisoning\nmethod tailored to impose forgetting on a continual learner. By adding the\nBrainWash noise to a variety of baselines, we demonstrate how a trained\ncontinual learner can be induced to forget its previously learned tasks\ncatastrophically, even when using these continual learning baselines. An\nimportant feature of our approach is that the attacker requires no access to\nprevious tasks' data and is armed merely with the model's current parameters\nand the data belonging to the most recent task. Our extensive experiments\nhighlight the efficacy of BrainWash, showcasing degradation in performance\nacross various regularization-based continual learning methods.\n","authors":["Ali Abbasi","Parsa Nooralinejad","Hamed Pirsiavash","Soheil Kolouri"],"pdf_url":"https://arxiv.org/pdf/2311.11995v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11908v2","updated":"2023-11-21T15:17:00Z","published":"2023-11-20T16:40:29Z","title":"Continual Learning: Applications and the Road Forward","summary":"  Continual learning is a sub-field of machine learning, which aims to allow\nmachine learning models to continuously learn on new data, by accumulating\nknowledge without forgetting what was learned in the past. In this work, we\ntake a step back, and ask: \"Why should one care about continual learning in the\nfirst place?\". We set the stage by surveying recent continual learning papers\npublished at three major machine learning conferences, and show that\nmemory-constrained settings dominate the field. Then, we discuss five open\nproblems in machine learning, and even though they seem unrelated to continual\nlearning at first sight, we show that continual learning will inevitably be\npart of their solution. These problems are model-editing, personalization,\non-device learning, faster (re-)training and reinforcement learning. Finally,\nby comparing the desiderata from these unsolved problems and the current\nassumptions in continual learning, we highlight and discuss four future\ndirections for continual learning research. We hope that this work offers an\ninteresting perspective on the future of continual learning, while displaying\nits potential value and the paths we have to pursue in order to make it\nsuccessful. This work is the result of the many discussions the authors had at\nthe Dagstuhl seminar on Deep Continual Learning, in March 2023.\n","authors":["Eli Verwimp","Rahaf Aljundi","Shai Ben-David","Matthias Bethge","Andrea Cossu","Alexander Gepperth","Tyler L. Hayes","Eyke Hüllermeier","Christopher Kanan","Dhireesha Kudithipudi","Christoph H. Lampert","Martin Mundt","Razvan Pascanu","Adrian Popescu","Andreas S. Tolias","Joost van de Weijer","Bing Liu","Vincenzo Lomonaco","Tinne Tuytelaars","Gido M. van de Ven"],"pdf_url":"https://arxiv.org/pdf/2311.11908v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11446v2","updated":"2023-11-21T01:42:54Z","published":"2023-11-19T23:00:27Z","title":"Weight Norm Control","summary":"  We note that decoupled weight decay regularization is a particular case of\nweight norm control where the target norm of weights is set to 0. Any\noptimization method (e.g., Adam) which uses decoupled weight decay\nregularization (respectively, AdamW) can be viewed as a particular case of a\nmore general algorithm with weight norm control (respectively, AdamWN). We\nargue that setting the target norm of weights to 0 can be suboptimal and other\ntarget norm values can be considered. For instance, any training run where\nAdamW achieves a particular norm of weights can be challenged by AdamWN\nscheduled to achieve a comparable norm of weights. We discuss various\nimplications of introducing weight norm control instead of weight decay.\n","authors":["Ilya Loshchilov"],"pdf_url":"https://arxiv.org/pdf/2311.11446v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.13405v4","updated":"2023-11-21T08:41:31Z","published":"2022-08-29T07:36:17Z","title":"Interpreting Black-box Machine Learning Models for High Dimensional\n  Datasets","summary":"  Deep neural networks (DNNs) have been shown to outperform traditional machine\nlearning algorithms in a broad variety of application domains due to their\neffectiveness in modeling complex problems and handling high-dimensional\ndatasets. Many real-life datasets, however, are of increasingly high\ndimensionality, where a large number of features may be irrelevant for both\nsupervised and unsupervised learning tasks. The inclusion of such features\nwould not only introduce unwanted noise but also increase computational\ncomplexity. Furthermore, due to high non-linearity and dependency among a large\nnumber of features, DNN models tend to be unavoidably opaque and perceived as\nblack-box methods because of their not well-understood internal functioning.\nTheir algorithmic complexity is often simply beyond the capacities of humans to\nunderstand the interplay among myriads of hyperparameters. A well-interpretable\nmodel can identify statistically significant features and explain the way they\naffect the model's outcome. In this paper, we propose an efficient method to\nimprove the interpretability of black-box models for classification tasks in\nthe case of high-dimensional datasets. First, we train a black-box model on a\nhigh-dimensional dataset to learn the embeddings on which the classification is\nperformed. To decompose the inner working principles of the black-box model and\nto identify top-k important features, we employ different probing and\nperturbing techniques. We then approximate the behavior of the black-box model\nby means of an interpretable surrogate model on the top-k feature space.\nFinally, we derive decision rules and local explanations from the surrogate\nmodel to explain individual decisions. Our approach outperforms\nstate-of-the-art methods like TabNet and XGboost when tested on different\ndatasets with varying dimensionality between 50 and 20,000 w.r.t metrics and\nexplainability.\n","authors":["Md. Rezaul Karim","Md. Shajalal","Alex Graß","Till Döhmen","Sisay Adugna Chala","Alexander Boden","Christian Beecks","Stefan Decker"],"pdf_url":"https://arxiv.org/pdf/2208.13405v4.pdf","comment":"This paper is currently under review in a journal"},{"id":"http://arxiv.org/abs/2311.11369v2","updated":"2023-11-21T01:56:38Z","published":"2023-11-19T16:35:01Z","title":"Optimal Locally Private Nonparametric Classification with Public Data","summary":"  In this work, we investigate the problem of public data-assisted\nnon-interactive LDP (Local Differential Privacy) learning with a focus on\nnon-parametric classification. Under the posterior drift assumption, we for the\nfirst time derive the mini-max optimal convergence rate with LDP constraint.\nThen, we present a novel approach, the locally private classification tree,\nwhich attains the mini-max optimal convergence rate. Furthermore, we design a\ndata-driven pruning procedure that avoids parameter tuning and produces a fast\nconverging estimator. Comprehensive experiments conducted on synthetic and real\ndatasets show the superior performance of our proposed method. Both our\ntheoretical and experimental findings demonstrate the effectiveness of public\ndata compared to private data, which leads to practical suggestions for\nprioritizing non-private data collection.\n","authors":["Yuheng Ma","Hanfang Yang"],"pdf_url":"https://arxiv.org/pdf/2311.11369v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12796v1","updated":"2023-11-21T18:59:58Z","published":"2023-11-21T18:59:58Z","title":"Physics-guided Shape-from-Template: Monocular Video Perception through\n  Neural Surrogate Models","summary":"  3D reconstruction of dynamic scenes is a long-standing problem in computer\ngraphics and increasingly difficult the less information is available.\nShape-from-Template (SfT) methods aim to reconstruct a template-based geometry\nfrom RGB images or video sequences, often leveraging just a single monocular\ncamera without depth information, such as regular smartphone recordings.\nUnfortunately, existing reconstruction methods are either unphysical and noisy\nor slow in optimization. To solve this problem, we propose a novel SfT\nreconstruction algorithm for cloth using a pre-trained neural surrogate model\nthat is fast to evaluate, stable, and produces smooth reconstructions due to a\nregularizing physics simulation. Differentiable rendering of the simulated mesh\nenables pixel-wise comparisons between the reconstruction and a target video\nsequence that can be used for a gradient-based optimization procedure to\nextract not only shape information but also physical parameters such as\nstretching, shearing, or bending stiffness of the cloth. This allows to retain\na precise, stable, and smooth reconstructed geometry while reducing the runtime\nby a factor of 400-500 compared to $\\phi$-SfT, a state-of-the-art physics-based\nSfT approach.\n","authors":["David Stotko","Nils Wandel","Reinhard Klein"],"pdf_url":"https://arxiv.org/pdf/2311.12796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.10793v5","updated":"2023-11-21T18:51:56Z","published":"2022-02-22T10:25:59Z","title":"PyTorch Geometric Signed Directed: A Software Package on Graph Neural\n  Networks for Signed and Directed Graphs","summary":"  Networks are ubiquitous in many real-world applications (e.g., social\nnetworks encoding trust/distrust relationships, correlation networks arising\nfrom time series data). While many networks are signed or directed, or both,\nthere is a lack of unified software packages on graph neural networks (GNNs)\nspecially designed for signed and directed networks. In this paper, we present\nPyTorch Geometric Signed Directed (PyGSD), a software package which fills this\ngap. Along the way, we evaluate the implemented methods with experiments with a\nview to providing insights into which method to choose for a given task. The\ndeep learning framework consists of easy-to-use GNN models, synthetic and\nreal-world data, as well as task-specific evaluation metrics and loss functions\nfor signed and directed networks. As an extension library for PyG, our proposed\nsoftware is maintained with open-source releases, detailed documentation,\ncontinuous integration, unit tests and code coverage checks. The GitHub\nrepository of the library is\nhttps://github.com/SherylHYX/pytorch_geometric_signed_directed.\n","authors":["Yixuan He","Xitong Zhang","Junjie Huang","Benedek Rozemberczki","Mihai Cucuringu","Gesine Reinert"],"pdf_url":"https://arxiv.org/pdf/2202.10793v5.pdf","comment":"Accepted by LoG 2023. 27 pages in total"},{"id":"http://arxiv.org/abs/2311.12786v1","updated":"2023-11-21T18:51:04Z","published":"2023-11-21T18:51:04Z","title":"Mechanistically analyzing the effects of fine-tuning on procedurally\n  defined tasks","summary":"  Fine-tuning large pre-trained models has become the de facto strategy for\ndeveloping both task-specific and general-purpose machine learning systems,\nincluding developing models that are safe to deploy. Despite its clear\nimportance, there has been minimal work that explains how fine-tuning alters\nthe underlying capabilities learned by a model during pretraining: does\nfine-tuning yield entirely novel capabilities or does it just modulate existing\nones? We address this question empirically in synthetic, controlled settings\nwhere we can use mechanistic interpretability tools (e.g., network pruning and\nprobing) to understand how the model's underlying capabilities are changing. We\nperform an extensive analysis of the effects of fine-tuning in these settings,\nand show that: (i) fine-tuning rarely alters the underlying model capabilities;\n(ii) a minimal transformation, which we call a 'wrapper', is typically learned\non top of the underlying model capabilities, creating the illusion that they\nhave been modified; and (iii) further fine-tuning on a task where such hidden\ncapabilities are relevant leads to sample-efficient 'revival' of the\ncapability, i.e., the model begins reusing these capability after only a few\ngradient steps. This indicates that practitioners can unintentionally remove a\nmodel's safety wrapper merely by fine-tuning it on a, e.g., superficially\nunrelated, downstream task. We additionally perform analysis on language models\ntrained on the TinyStories dataset to support our claims in a more realistic\nsetup.\n","authors":["Samyak Jain","Robert Kirk","Ekdeep Singh Lubana","Robert P. Dick","Hidenori Tanaka","Edward Grefenstette","Tim Rocktäschel","David Scott Krueger"],"pdf_url":"https://arxiv.org/pdf/2311.12786v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01331v2","updated":"2023-11-21T18:50:49Z","published":"2023-11-02T15:41:57Z","title":"Offline Imitation from Observation via Primal Wasserstein State\n  Occupancy Matching","summary":"  In real-world scenarios, arbitrary interactions with the environment can\noften be costly, and actions of expert demonstrations are not always available.\nTo reduce the need for both, Offline Learning from Observations (LfO) is\nextensively studied, where the agent learns to solve a task with only expert\nstates and \\textit{task-agnostic} non-expert state-action pairs. The\nstate-of-the-art DIstribution Correction Estimation (DICE) methods minimize the\nstate occupancy divergence between the learner and expert policies. However,\nthey are limited to either $f$-divergences (KL and $\\chi^2$) or Wasserstein\ndistance with Rubinstein duality, the latter of which constrains the underlying\ndistance metric crucial to the performance of Wasserstein-based solutions. To\naddress this problem, we propose Primal Wasserstein DICE (PW-DICE), which\nminimizes the primal Wasserstein distance between the expert and learner state\noccupancies with a pessimistic regularizer and leverages a contrastively\nlearned distance as the underlying metric for the Wasserstein distance.\nTheoretically, we prove that our framework is a generalization of the\nstate-of-the-art, SMODICE, and unifies $f$-divergence and Wasserstein\nminimization. Empirically, we find that PW-DICE improves upon several\nstate-of-the-art methods on multiple testbeds.\n","authors":["Kai Yan","Alexander G. Schwing","Yu-xiong Wang"],"pdf_url":"https://arxiv.org/pdf/2311.01331v2.pdf","comment":"23 pages. Accepted to the Optimal Transport and Machine Learning\n  Workshop at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.12784v1","updated":"2023-11-21T18:50:38Z","published":"2023-11-21T18:50:38Z","title":"Optimality in Mean Estimation: Beyond Worst-Case, Beyond Sub-Gaussian,\n  and Beyond $1+α$ Moments","summary":"  There is growing interest in improving our algorithmic understanding of\nfundamental statistical problems such as mean estimation, driven by the goal of\nunderstanding the limits of what we can extract from valuable data. The state\nof the art results for mean estimation in $\\mathbb{R}$ are 1) the optimal\nsub-Gaussian mean estimator by [LV22], with the tight sub-Gaussian constant for\nall distributions with finite but unknown variance, and 2) the analysis of the\nmedian-of-means algorithm by [BCL13] and a lower bound by [DLLO16],\ncharacterizing the big-O optimal errors for distributions for which only a\n$1+\\alpha$ moment exists for $\\alpha \\in (0,1)$. Both results, however, are\noptimal only in the worst case. We initiate the fine-grained study of the mean\nestimation problem: Can algorithms leverage useful features of the input\ndistribution to beat the sub-Gaussian rate, without explicit knowledge of such\nfeatures?\n  We resolve this question with an unexpectedly nuanced answer: \"Yes in limited\nregimes, but in general no\". For any distribution $p$ with a finite mean, we\nconstruct a distribution $q$ whose mean is well-separated from $p$'s, yet $p$\nand $q$ are not distinguishable with high probability, and $q$ further\npreserves $p$'s moments up to constants. The main consequence is that no\nreasonable estimator can asymptotically achieve better than the sub-Gaussian\nerror rate for any distribution, matching the worst-case result of [LV22]. More\ngenerally, we introduce a new definitional framework to analyze the\nfine-grained optimality of algorithms, which we call \"neighborhood optimality\",\ninterpolating between the unattainably strong \"instance optimality\" and the\ntrivially weak \"admissibility\" definitions. Applying the new framework, we show\nthat median-of-means is neighborhood optimal, up to constant factors. It is\nopen to find a neighborhood-optimal estimator without constant factor\nslackness.\n","authors":["Trung Dang","Jasper C. H. Lee","Maoyuan Song","Paul Valiant"],"pdf_url":"https://arxiv.org/pdf/2311.12784v1.pdf","comment":"27 pages, to appear in NeurIPS 2023. Abstract shortened to fit arXiv\n  limit"},{"id":"http://arxiv.org/abs/2011.04923v5","updated":"2023-11-21T18:49:33Z","published":"2020-11-10T06:06:02Z","title":"Topological properties of basins of attraction and expressiveness of\n  width bounded neural networks","summary":"  In Radhakrishnan et al. [2020], the authors empirically show that\nautoencoders trained with usual SGD methods shape out basins of attraction\naround their training data. We consider network functions of width not\nexceeding the input dimension and prove that in this situation basins of\nattraction are bounded and their complement cannot have bounded components. Our\nconditions in these results are met in several experiments of the latter work\nand we thus address a question posed therein. We also show that under some more\nrestrictive conditions the basins of attraction are path-connected. The\ntightness of the conditions in our results is demonstrated by means of several\nexamples. Finally, the arguments used to prove the above results allow us to\nderive a root cause why scalar-valued neural network functions that fulfill our\nbounded width condition are not dense in spaces of continuous functions.\n","authors":["Hans-Peter Beise","Steve Dias Da Cruz"],"pdf_url":"https://arxiv.org/pdf/2011.04923v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12781v1","updated":"2023-11-21T18:45:52Z","published":"2023-11-21T18:45:52Z","title":"Quantifying Impairment and Disease Severity Using AI Models Trained on\n  Healthy Subjects","summary":"  Automatic assessment of impairment and disease severity is a key challenge in\ndata-driven medicine. We propose a novel framework to address this challenge,\nwhich leverages AI models trained exclusively on healthy individuals. The\nCOnfidence-Based chaRacterization of Anomalies (COBRA) score exploits the\ndecrease in confidence of these models when presented with impaired or diseased\npatients to quantify their deviation from the healthy population. We applied\nthe COBRA score to address a key limitation of current clinical evaluation of\nupper-body impairment in stroke patients. The gold-standard Fugl-Meyer\nAssessment (FMA) requires in-person administration by a trained assessor for\n30-45 minutes, which restricts monitoring frequency and precludes physicians\nfrom adapting rehabilitation protocols to the progress of each patient. The\nCOBRA score, computed automatically in under one minute, is shown to be\nstrongly correlated with the FMA on an independent test cohort for two\ndifferent data modalities: wearable sensors ($\\rho = 0.845$, 95% CI\n[0.743,0.908]) and video ($\\rho = 0.746$, 95% C.I [0.594, 0.847]). To\ndemonstrate the generalizability of the approach to other conditions, the COBRA\nscore was also applied to quantify severity of knee osteoarthritis from\nmagnetic-resonance imaging scans, again achieving significant correlation with\nan independent clinical assessment ($\\rho = 0.644$, 95% C.I [0.585,0.696]).\n","authors":["Boyang Yu","Aakash Kaku","Kangning Liu","Avinash Parnandi","Emily Fokas","Anita Venkatesan","Natasha Pandit","Rajesh Ranganath","Heidi Schambra","Carlos Fernandez-Granda"],"pdf_url":"https://arxiv.org/pdf/2311.12781v1.pdf","comment":"32 pages, 10 figures"},{"id":"http://arxiv.org/abs/2305.12827v3","updated":"2023-11-21T18:43:43Z","published":"2023-05-22T08:39:25Z","title":"Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained\n  Models","summary":"  Task arithmetic has recently emerged as a cost-effective and scalable\napproach to edit pre-trained models directly in weight space: By adding the\nfine-tuned weights of different tasks, the model's performance can be improved\non these tasks, while negating them leads to task forgetting. Yet, our\nunderstanding of the effectiveness of task arithmetic and its underlying\nprinciples remains limited. We present a comprehensive study of task arithmetic\nin vision-language models and show that weight disentanglement is the crucial\nfactor that makes it effective. This property arises during pre-training and\nmanifests when distinct directions in weight space govern separate, localized\nregions in function space associated with the tasks. Notably, we show that\nfine-tuning models in their tangent space by linearizing them amplifies weight\ndisentanglement. This leads to substantial performance improvements across\nmultiple task arithmetic benchmarks and diverse models. Building on these\nfindings, we provide theoretical and empirical analyses of the neural tangent\nkernel (NTK) of these models and establish a compelling link between task\narithmetic and the spatial localization of the NTK eigenfunctions. Overall, our\nwork uncovers novel insights into the fundamental mechanisms of task arithmetic\nand offers a more reliable and effective approach to edit pre-trained models\nthrough the NTK linearization.\n","authors":["Guillermo Ortiz-Jimenez","Alessandro Favero","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2305.12827v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09387v2","updated":"2023-11-21T18:31:57Z","published":"2023-11-15T21:30:26Z","title":"Banach-Tarski Embeddings and Transformers","summary":"  We introduce a new construction of embeddings of arbitrary recursive data\nstructures into high dimensional vectors. These embeddings provide an\ninterpretable model for the latent state vectors of transformers. We\ndemonstrate that these embeddings can be decoded to the original data structure\nwhen the embedding dimension is sufficiently large. This decoding algorithm has\na natural implementation as a transformer. We also show that these embedding\nvectors can be manipulated directly to perform computations on the underlying\ndata without decoding. As an example we present an algorithm that constructs\nthe embedded parse tree of an embedded token sequence using only vector\noperations in embedding space.\n","authors":["Joshua Maher"],"pdf_url":"https://arxiv.org/pdf/2311.09387v2.pdf","comment":"22 pages, 7 figures. v2: Fixed order of matrix multiplication in\n  section 2.4"},{"id":"http://arxiv.org/abs/2206.01255v5","updated":"2023-11-21T18:31:13Z","published":"2022-06-02T19:11:27Z","title":"Compressive Fourier collocation methods for high-dimensional diffusion\n  equations with periodic boundary conditions","summary":"  High-dimensional Partial Differential Equations (PDEs) are a popular\nmathematical modelling tool, with applications ranging from finance to\ncomputational chemistry. However, standard numerical techniques for solving\nthese PDEs are typically affected by the curse of dimensionality. In this work,\nwe tackle this challenge while focusing on stationary diffusion equations\ndefined over a high-dimensional domain with periodic boundary conditions.\nInspired by recent progress in sparse function approximation in high\ndimensions, we propose a new method called compressive Fourier collocation.\nCombining ideas from compressive sensing and spectral collocation, our method\nreplaces the use of structured collocation grids with Monte Carlo sampling and\nemploys sparse recovery techniques, such as orthogonal matching pursuit and\n$\\ell^1$ minimization, to approximate the Fourier coefficients of the PDE\nsolution. We conduct a rigorous theoretical analysis showing that the\napproximation error of the proposed method is comparable with the best $s$-term\napproximation (with respect to the Fourier basis) to the solution. Using the\nrecently introduced framework of random sampling in bounded Riesz systems, our\nanalysis shows that the compressive Fourier collocation method mitigates the\ncurse of dimensionality with respect to the number of collocation points under\nsufficient conditions on the regularity of the diffusion coefficient. We also\npresent numerical experiments that illustrate the accuracy and stability of the\nmethod for the approximation of sparse and compressible solutions.\n","authors":["Weiqi Wang","Simone Brugiapaglia"],"pdf_url":"https://arxiv.org/pdf/2206.01255v5.pdf","comment":"34 pages, 10 figures"},{"id":"http://arxiv.org/abs/2310.02168v2","updated":"2023-11-21T18:18:49Z","published":"2023-10-03T16:02:36Z","title":"Editing Personality for LLMs","summary":"  This paper introduces an innovative task focused on editing the personality\ntraits of Large Language Models (LLMs). This task seeks to adjust the models'\nresponses to opinion-related questions on specified topics since an\nindividual's personality often manifests in the form of their expressed\nopinions, thereby showcasing different personality traits. Specifically, we\nconstruct a new benchmark dataset PersonalityEdit to address this task. Drawing\non the theory in Social Psychology, we isolate three representative traits,\nnamely Neuroticism, Extraversion, and Agreeableness, as the foundation for our\nbenchmark. We then gather data using GPT-4, generating responses that not only\nalign with a specified topic but also embody the targeted personality trait. We\nconduct comprehensive experiments involving various baselines and discuss the\nrepresentation of personality behavior in LLMs. Our intriguing findings uncover\npotential challenges of the proposed task, illustrating several remaining\nissues. We anticipate that our work can provide the NLP community with\ninsights. Code and datasets will be released at\nhttps://github.com/zjunlp/EasyEdit.\n","authors":["Shengyu Mao","Ningyu Zhang","Xiaohan Wang","Mengru Wang","Yunzhi Yao","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2310.02168v2.pdf","comment":"Work in progress, add more experiments"},{"id":"http://arxiv.org/abs/2311.12760v1","updated":"2023-11-21T18:11:26Z","published":"2023-11-21T18:11:26Z","title":"High-resolution Image-based Malware Classification using Multiple\n  Instance Learning","summary":"  This paper proposes a novel method of classifying malware into families using\nhigh-resolution greyscale images and multiple instance learning to overcome\nadversarial binary enlargement. Current methods of visualisation-based malware\nclassification largely rely on lossy transformations of inputs such as resizing\nto handle the large, variable-sized images. Through empirical analysis and\nexperimentation, it is shown that these approaches cause crucial information\nloss that can be exploited. The proposed solution divides the images into\npatches and uses embedding-based multiple instance learning with a\nconvolutional neural network and an attention aggregation function for\nclassification. The implementation is evaluated on the Microsoft Malware\nClassification dataset and achieves accuracies of up to $96.6\\%$ on\nadversarially enlarged samples compared to the baseline of $22.8\\%$. The Python\ncode is available online at https://github.com/timppeters/MIL-Malware-Images .\n","authors":["Tim Peters","Hikmat Farhat"],"pdf_url":"https://arxiv.org/pdf/2311.12760v1.pdf","comment":"14 pages, 13 figures, 2 tables"},{"id":"http://arxiv.org/abs/2311.12754v1","updated":"2023-11-21T17:59:14Z","published":"2023-11-21T17:59:14Z","title":"SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction","summary":"  3D occupancy prediction is an important task for the robustness of\nvision-centric autonomous driving, which aims to predict whether each point is\noccupied in the surrounding 3D space. Existing methods usually require 3D\noccupancy labels to produce meaningful results. However, it is very laborious\nto annotate the occupancy status of each voxel. In this paper, we propose\nSelfOcc to explore a self-supervised way to learn 3D occupancy using only video\nsequences. We first transform the images into the 3D space (e.g., bird's eye\nview) to obtain 3D representation of the scene. We directly impose constraints\non the 3D representations by treating them as signed distance fields. We can\nthen render 2D images of previous and future frames as self-supervision signals\nto learn the 3D representations. We propose an MVS-embedded strategy to\ndirectly optimize the SDF-induced weights with multiple depth proposals. Our\nSelfOcc outperforms the previous best method SceneRF by 58.7% using a single\nframe as input on SemanticKITTI and is the first self-supervised work that\nproduces reasonable 3D occupancy for surround cameras on Occ3D. SelfOcc\nproduces high-quality depth and achieves state-of-the-art results on novel\ndepth synthesis, monocular depth estimation, and surround-view depth estimation\non the SemanticKITTI, KITTI-2015, and nuScenes, respectively. Code:\nhttps://github.com/huang-yh/SelfOcc.\n","authors":["Yuanhui Huang","Wenzhao Zheng","Borui Zhang","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2311.12754v1.pdf","comment":"Code is available at: https://github.com/huang-yh/SelfOcc"},{"id":"http://arxiv.org/abs/2310.02129v2","updated":"2023-11-21T17:59:04Z","published":"2023-10-03T15:10:46Z","title":"Unveiling the Pitfalls of Knowledge Editing for Large Language Models","summary":"  As the cost associated with fine-tuning Large Language Models (LLMs)\ncontinues to rise, recent research efforts have pivoted towards developing\nmethodologies to edit implicit knowledge embedded within LLMs. Yet, there's\nstill a dark cloud lingering overhead -- will knowledge editing trigger\nbutterfly effect? since it is still unclear whether knowledge editing might\nintroduce side effects that pose potential risks or not. This paper pioneers\nthe investigation into the potential pitfalls associated with knowledge editing\nfor LLMs. To achieve this, we introduce new benchmark datasets and propose\ninnovative evaluation metrics. Our results underline two pivotal concerns: (1)\nKnowledge Conflict: Editing groups of facts that logically clash can magnify\nthe inherent inconsistencies in LLMs-a facet neglected by previous methods. (2)\nKnowledge Distortion: Altering parameters with the aim of editing factual\nknowledge can irrevocably warp the innate knowledge structure of LLMs.\nExperimental results vividly demonstrate that knowledge editing might\ninadvertently cast a shadow of unintended consequences on LLMs, which warrant\nattention and efforts for future works. Code is available at\nhttps://github.com/zjunlp/PitfallsKnowledgeEditing.\n","authors":["Zhoubo Li","Ningyu Zhang","Yunzhi Yao","Mengru Wang","Xi Chen","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2310.02129v2.pdf","comment":"Work in progress, add more experiments"},{"id":"http://arxiv.org/abs/2311.12750v1","updated":"2023-11-21T17:51:30Z","published":"2023-11-21T17:51:30Z","title":"Learning to Optimise Wind Farms with Graph Transformers","summary":"  This work proposes a novel data-driven model capable of providing accurate\npredictions for the power generation of all wind turbines in wind farms of\narbitrary layout, yaw angle configurations and wind conditions. The proposed\nmodel functions by encoding a wind farm into a fully-connected graph and\nprocessing the graph representation through a graph transformer. The graph\ntransformer surrogate is shown to generalise well and is able to uncover latent\nstructural patterns within the graph representation of wind farms. It is\ndemonstrated how the resulting surrogate model can be used to optimise yaw\nangle configurations using genetic algorithms, achieving similar levels of\naccuracy to industrially-standard wind farm simulation tools while only taking\na fraction of the computational cost.\n","authors":["Siyi Li","Arnaud Robert","A. Aldo Faisal","Matthew D. Piggott"],"pdf_url":"https://arxiv.org/pdf/2311.12750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06185v2","updated":"2023-11-21T17:42:42Z","published":"2023-11-10T17:06:28Z","title":"An Automated Pipeline for Tumour-Infiltrating Lymphocyte Scoring in\n  Breast Cancer","summary":"  Tumour-infiltrating lymphocytes (TILs) are considered as a valuable\nprognostic markers in both triple-negative and human epidermal growth factor\nreceptor 2 (HER2) positive breast cancer. In this study, we introduce an\ninnovative deep learning pipeline based on the Efficient-UNet architecture to\npredict the TILs score for breast cancer whole-slide images (WSIs). We first\nsegment tumour and stromal regions in order to compute a tumour bulk mask. We\nthen detect TILs within the tumour-associated stroma, generating a TILs score\nby closely mirroring the pathologist's workflow. Our method exhibits\nstate-of-the-art performance in segmenting tumour/stroma areas and TILs\ndetection, as demonstrated by internal cross-validation on the TiGER Challenge\ntraining dataset and evaluation on the final leaderboards. Additionally, our\nTILs score proves competitive in predicting survival outcomes within the same\nchallenge, underscoring the clinical relevance and potential of our automated\nTILs scoring pipeline as a breast cancer prognostic tool.\n","authors":["Adam J Shephard","Mostafa Jahanifar","Ruoyu Wang","Muhammad Dawood","Simon Graham","Kastytis Sidlauskas","Syed Ali Khurram","Nasir M Rajpoot","Shan E Ahmed Raza"],"pdf_url":"https://arxiv.org/pdf/2311.06185v2.pdf","comment":"5 pages, 1 figure, 2 tables"},{"id":"http://arxiv.org/abs/2307.16189v6","updated":"2023-11-21T17:35:03Z","published":"2023-07-30T10:03:36Z","title":"Stable Adam Optimization for 16-bit Neural Networks Training","summary":"  In this research, we address critical concerns related to the numerical\ninstability observed in 16-bit computations of machine learning models. Such\ninstability, particularly when employing popular optimization algorithms like\nAdam, often leads to unstable training of deep neural networks. This not only\ndisrupts the learning process but also poses significant challenges in\ndeploying dependable models in real-world applications. Our investigation\nidentifies the epsilon hyperparameter as the primary source of this\ninstability. A nuanced exploration reveals that subtle adjustments to epsilon\nwithin 16-bit computations can enhance the numerical stability of Adam,\nenabling more stable training of 16-bit neural networks. We propose a novel,\ndependable approach that leverages updates from the Adam optimizer to bolster\nthe stability of the learning process. Our contributions provide deeper\ninsights into optimization challenges in low-precision computations and offer\nsolutions to ensure the stability of deep neural network training, paving the\nway for their dependable use in various applications.\n","authors":["Juyoung Yun"],"pdf_url":"https://arxiv.org/pdf/2307.16189v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12742v1","updated":"2023-11-21T17:31:10Z","published":"2023-11-21T17:31:10Z","title":"Image Transformation for IoT Time-Series Data: A Review","summary":"  In the era of the Internet of Things (IoT), where smartphones, built-in\nsystems, wireless sensors, and nearly every smart device connect through local\nnetworks or the internet, billions of smart things communicate with each other\nand generate vast amounts of time-series data. As IoT time-series data is\nhigh-dimensional and high-frequency, time-series classification or regression\nhas been a challenging issue in IoT. Recently, deep learning algorithms have\ndemonstrated superior performance results in time-series data classification in\nmany smart and intelligent IoT applications. However, it is hard to explore the\nhidden dynamic patterns and trends in time-series. Recent studies show that\ntransforming IoT data into images improves the performance of the learning\nmodel. In this paper, we present a review of these studies which use image\ntransformation/encoding techniques in IoT domain. We examine the studies\naccording to their encoding techniques, data types, and application areas.\nLastly, we emphasize the challenges and future dimensions of image\ntransformation.\n","authors":["Duygu Altunkaya","Feyza Yildirim Okay","Suat Ozdemir"],"pdf_url":"https://arxiv.org/pdf/2311.12742v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2311.12741v1","updated":"2023-11-21T17:30:57Z","published":"2023-11-21T17:30:57Z","title":"Content Augmented Graph Neural Networks","summary":"  In recent years, graph neural networks (GNNs) have become a popular tool for\nsolving various problems over graphs. In these models, the link structure of\nthe graph is typically exploited and nodes' embeddings are iteratively updated\nbased on adjacent nodes. Nodes' contents are used solely in the form of feature\nvectors, served as nodes' first-layer embeddings. However, the filters or\nconvolutions, applied during iterations/layers to these initial embeddings lead\nto their impact diminish and contribute insignificantly to the final\nembeddings. In order to address this issue, in this paper we propose augmenting\nnodes' embeddings by embeddings generating from their content, at higher GNN\nlayers. More precisely, we propose models wherein a structural embedding using\na GNN and a content embedding are computed for each node. These two are\ncombined using a combination layer to form the embedding of a node at a given\nlayer. We suggest methods such as using an auto-encoder or building a content\ngraph, to generate content embeddings. In the end, by conducting experiments\nover several real-world datasets, we demonstrate the high accuracy and\nperformance of our models.\n","authors":["Fatemeh Gholamzadeh Nasrabadi","AmirHossein Kashani","Pegah Zahedi","Mostafa Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2311.12741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03489v2","updated":"2023-11-21T17:28:17Z","published":"2023-11-06T19:58:26Z","title":"Leveraging High-Level Synthesis and Large Language Models to Generate,\n  Simulate, and Deploy a Uniform Random Number Generator Hardware Design","summary":"  We present a new high-level synthesis methodology for using large language\nmodel tools to generate hardware designs. The methodology uses exclusively\nopen-source tools excluding the large language model. As a case study, we use\nour methodology to generate a permuted congruential random number generator\ndesign with a wishbone interface. We verify the functionality and quality of\nthe random number generator design using large language model-generated\nsimulations and the Dieharder randomness test suite. We document all the large\nlanguage model chat logs, Python scripts, Verilog scripts, and simulation\nresults used in the case study. We believe that our method of hardware design\ngeneration coupled with the open source silicon 130 nm design tools will\nrevolutionize application-specific integrated circuit design. Our methodology\nsignificantly lowers the bar to entry when building domain-specific computing\naccelerators for the Internet of Things and proof of concept prototypes for\nlater fabrication in more modern process nodes.\n","authors":["James T. Meech"],"pdf_url":"https://arxiv.org/pdf/2311.03489v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12737v1","updated":"2023-11-21T17:23:05Z","published":"2023-11-21T17:23:05Z","title":"Exploring Graph Classification Techniques Under Low Data Constraints: A\n  Comprehensive Study","summary":"  This survey paper presents a brief overview of recent research on graph data\naugmentation and few-shot learning. It covers various techniques for graph data\naugmentation, including node and edge perturbation, graph coarsening, and graph\ngeneration, as well as the latest developments in few-shot learning, such as\nmeta-learning and model-agnostic meta-learning. The paper explores these areas\nin depth and delves into further sub classifications. Rule based approaches and\nlearning based approaches are surveyed under graph augmentation techniques.\nFew-Shot Learning on graphs is also studied in terms of metric learning\ntechniques and optimization-based techniques. In all, this paper provides an\nextensive array of techniques that can be employed in solving graph processing\nproblems faced in low-data scenarios.\n","authors":["Kush Kothari","Bhavya Mehta","Reshmika Nambiar","Seema Shrawne"],"pdf_url":"https://arxiv.org/pdf/2311.12737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.11774v2","updated":"2023-11-21T17:16:02Z","published":"2023-05-19T16:01:35Z","title":"Multi-Objective Optimization Using the R2 Utility","summary":"  The goal of multi-objective optimization is to identify a collection of\npoints which describe the best possible trade-offs between the multiple\nobjectives. In order to solve this vector-valued optimization problem,\npractitioners often appeal to the use of scalarization functions in order to\ntransform the multi-objective problem into a collection of single-objective\nproblems. This set of scalarized problems can then be solved using traditional\nsingle-objective optimization techniques. In this work, we formalise this\nconvention into a general mathematical framework. We show how this strategy\neffectively recasts the original multi-objective optimization problem into a\nsingle-objective optimization problem defined over sets. An appropriate class\nof objective functions for this new problem is the R2 utility function, which\nis defined as a weighted integral over the scalarized optimization problems. We\nshow that this utility function is a monotone and submodular set function,\nwhich can be optimised effectively using greedy optimization algorithms. We\nanalyse the performance of these greedy algorithms both theoretically and\nempirically. Our analysis largely focusses on Bayesian optimization, which is a\npopular probabilistic framework for black-box optimization.\n","authors":["Ben Tu","Nikolas Kantas","Robert M. Lee","Behrang Shafei"],"pdf_url":"https://arxiv.org/pdf/2305.11774v2.pdf","comment":"The code is available at: https://github.com/benmltu/scalarize"},{"id":"http://arxiv.org/abs/2311.10801v2","updated":"2023-11-21T17:11:55Z","published":"2023-11-17T09:16:59Z","title":"Reinforcement Learning with Maskable Stock Representation for Portfolio\n  Management in Customizable Stock Pools","summary":"  Portfolio management (PM) is a fundamental financial trading task, which\nexplores the optimal periodical reallocation of capitals into different stocks\nto pursue long-term profits. Reinforcement learning (RL) has recently shown its\npotential to train profitable agents for PM through interacting with financial\nmarkets. However, existing work mostly focuses on fixed stock pools, which is\ninconsistent with investors' practical demand. Specifically, the target stock\npool of different investors varies dramatically due to their discrepancy on\nmarket states and individual investors may temporally adjust stocks they desire\nto trade (e.g., adding one popular stocks), which lead to customizable stock\npools (CSPs). Existing RL methods require to retrain RL agents even with a tiny\nchange of the stock pool, which leads to high computational cost and unstable\nperformance. To tackle this challenge, we propose EarnMore, a rEinforcement\nleARNing framework with Maskable stOck REpresentation to handle PM with CSPs\nthrough one-shot training in a global stock pool (GSP). Specifically, we first\nintroduce a mechanism to mask out the representation of the stocks outside the\ntarget pool. Second, we learn meaningful stock representations through a\nself-supervised masking and reconstruction process. Third, a re-weighting\nmechanism is designed to make the portfolio concentrate on favorable stocks and\nneglect the stocks outside the target pool. Through extensive experiments on 8\nsubset stock pools of the US stock market, we demonstrate that EarnMore\nsignificantly outperforms 14 state-of-the-art baselines in terms of 6 popular\nfinancial metrics with over 40% improvement on profit.\n","authors":["Wentao Zhang","Yilei Zhao","Shuo Sun","Jie Ying","Yonggang Xie","Zitao Song","Xinrun Wang","Bo An"],"pdf_url":"https://arxiv.org/pdf/2311.10801v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.17844v2","updated":"2023-11-21T17:08:34Z","published":"2023-06-30T17:59:13Z","title":"The Clock and the Pizza: Two Stories in Mechanistic Explanation of\n  Neural Networks","summary":"  Do neural networks, trained on well-understood algorithmic tasks, reliably\nrediscover known algorithms for solving those tasks? Several recent studies, on\ntasks ranging from group arithmetic to in-context linear regression, have\nsuggested that the answer is yes. Using modular addition as a prototypical\nproblem, we show that algorithm discovery in neural networks is sometimes more\ncomplex. Small changes to model hyperparameters and initializations can induce\nthe discovery of qualitatively different algorithms from a fixed training set,\nand even parallel implementations of multiple such algorithms. Some networks\ntrained to perform modular addition implement a familiar Clock algorithm;\nothers implement a previously undescribed, less intuitive, but comprehensible\nprocedure which we term the Pizza algorithm, or a variety of even more complex\nprocedures. Our results show that even simple learning problems can admit a\nsurprising diversity of solutions, motivating the development of new tools for\ncharacterizing the behavior of neural networks across their algorithmic phase\nspace.\n","authors":["Ziqian Zhong","Ziming Liu","Max Tegmark","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2306.17844v2.pdf","comment":"Accepted by NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.12727v1","updated":"2023-11-21T17:03:21Z","published":"2023-11-21T17:03:21Z","title":"Soft Random Sampling: A Theoretical and Empirical Analysis","summary":"  Soft random sampling (SRS) is a simple yet effective approach for efficient\ntraining of large-scale deep neural networks when dealing with massive data.\nSRS selects a subset uniformly at random with replacement from the full data\nset in each epoch. In this paper, we conduct a theoretical and empirical\nanalysis of SRS. First, we analyze its sampling dynamics including data\ncoverage and occupancy. Next, we investigate its convergence with non-convex\nobjective functions and give the convergence rate. Finally, we provide its\ngeneralization performance. We empirically evaluate SRS for image recognition\non CIFAR10 and automatic speech recognition on Librispeech and an in-house\npayload dataset to demonstrate its effectiveness. Compared to existing\ncoreset-based data selection methods, SRS offers a better accuracy-efficiency\ntrade-off. Especially on real-world industrial scale data sets, it is shown to\nbe a powerful training strategy with significant speedup and competitive\nperformance with almost no additional computing cost.\n","authors":["Xiaodong Cui","Ashish Mittal","Songtao Lu","Wei Zhang","George Saon","Brian Kingsbury"],"pdf_url":"https://arxiv.org/pdf/2311.12727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12722v1","updated":"2023-11-21T16:51:33Z","published":"2023-11-21T16:51:33Z","title":"Attacking Motion Planners Using Adversarial Perception Errors","summary":"  Autonomous driving (AD) systems are often built and tested in a modular\nfashion, where the performance of different modules is measured using\ntask-specific metrics. These metrics should be chosen so as to capture the\ndownstream impact of each module and the performance of the system as a whole.\nFor example, high perception quality should enable prediction and planning to\nbe performed safely. Even though this is true in general, we show here that it\nis possible to construct planner inputs that score very highly on various\nperception quality metrics but still lead to planning failures. In an analogy\nto adversarial attacks on image classifiers, we call such inputs\n\\textbf{adversarial perception errors} and show they can be systematically\nconstructed using a simple boundary-attack algorithm. We demonstrate the\neffectiveness of this algorithm by finding attacks for two different black-box\nplanners in several urban and highway driving scenarios using the CARLA\nsimulator. Finally, we analyse the properties of these attacks and show that\nthey are isolated in the input space of the planner, and discuss their\nimplications for AD system deployment and testing.\n","authors":["Jonathan Sadeghi","Nicholas A. Lord","John Redford","Romain Mueller"],"pdf_url":"https://arxiv.org/pdf/2311.12722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12716v1","updated":"2023-11-21T16:43:13Z","published":"2023-11-21T16:43:13Z","title":"minimax: Efficient Baselines for Autocurricula in JAX","summary":"  Unsupervised environment design (UED) is a form of automatic curriculum\nlearning for training robust decision-making agents to zero-shot transfer into\nunseen environments. Such autocurricula have received much interest from the RL\ncommunity. However, UED experiments, based on CPU rollouts and GPU model\nupdates, have often required several weeks of training. This compute\nrequirement is a major obstacle to rapid innovation for the field. This work\nintroduces the minimax library for UED training on accelerated hardware. Using\nJAX to implement fully-tensorized environments and autocurriculum algorithms,\nminimax allows the entire training loop to be compiled for hardware\nacceleration. To provide a petri dish for rapid experimentation, minimax\nincludes a tensorized grid-world based on MiniGrid, in addition to reusable\nabstractions for conducting autocurricula in procedurally-generated\nenvironments. With these components, minimax provides strong UED baselines,\nincluding new parallelized variants, which achieve over 120$\\times$ speedups in\nwall time compared to previous implementations when training with equal batch\nsizes. The minimax library is available under the Apache 2.0 license at\nhttps://github.com/facebookresearch/minimax.\n","authors":["Minqi Jiang","Michael Dennis","Edward Grefenstette","Tim Rocktäschel"],"pdf_url":"https://arxiv.org/pdf/2311.12716v1.pdf","comment":"Presented at ALOE 2023"},{"id":"http://arxiv.org/abs/2311.12715v1","updated":"2023-11-21T16:42:03Z","published":"2023-11-21T16:42:03Z","title":"Attacks of fairness in Federated Learning","summary":"  Federated Learning is an important emerging distributed training paradigm\nthat keeps data private on clients. It is now well understood that by\ncontrolling only a small subset of FL clients, it is possible to introduce a\nbackdoor to a federated learning model, in the presence of certain attributes.\nIn this paper, we present a new type of attack that compromises the fairness of\nthe trained model. Fairness is understood to be the attribute-level performance\ndistribution of a trained model. It is particularly salient in domains where,\nfor example, skewed accuracy discrimination between subpopulations could have\ndisastrous consequences. We find that by employing a threat model similar to\nthat of a backdoor attack, an attacker is able to influence the aggregated\nmodel to have an unfair performance distribution between any given set of\nattributes. Furthermore, we find that this attack is possible by controlling\nonly a single client. While combating naturally induced unfairness in FL has\npreviously been discussed in depth, its artificially induced kind has been\nneglected. We show that defending against attacks on fairness should be a\ncritical consideration in any situation where unfairness in a trained model\ncould benefit a user who participated in its training.\n","authors":["Joseph Rance","Filip Svoboda"],"pdf_url":"https://arxiv.org/pdf/2311.12715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.10852v6","updated":"2023-11-21T16:36:43Z","published":"2022-05-22T15:30:18Z","title":"Relphormer: Relational Graph Transformer for Knowledge Graph\n  Representations","summary":"  Transformers have achieved remarkable performance in widespread fields,\nincluding natural language processing, computer vision and graph mining.\nHowever, vanilla Transformer architectures have not yielded promising\nimprovements in the Knowledge Graph (KG) representations, where the\ntranslational distance paradigm dominates this area. Note that vanilla\nTransformer architectures struggle to capture the intrinsically heterogeneous\nstructural and semantic information of knowledge graphs. To this end, we\npropose a new variant of Transformer for knowledge graph representations dubbed\nRelphormer. Specifically, we introduce Triple2Seq which can dynamically sample\ncontextualized sub-graph sequences as the input to alleviate the heterogeneity\nissue. We propose a novel structure-enhanced self-attention mechanism to encode\nthe relational information and keep the semantic information within entities\nand relations. Moreover, we utilize masked knowledge modeling for general\nknowledge graph representation learning, which can be applied to various\nKG-based tasks including knowledge graph completion, question answering, and\nrecommendation. Experimental results on six datasets show that Relphormer can\nobtain better performance compared with baselines. Code is available in\nhttps://github.com/zjunlp/Relphormer.\n","authors":["Zhen Bi","Siyuan Cheng","Jing Chen","Xiaozhuan Liang","Feiyu Xiong","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.10852v6.pdf","comment":"Neurocomputing 2023"},{"id":"http://arxiv.org/abs/2311.12711v1","updated":"2023-11-21T16:31:27Z","published":"2023-11-21T16:31:27Z","title":"Regression-Based Analysis of Multimodal Single-Cell Data Integration\n  Strategies","summary":"  Multimodal single-cell technologies enable the simultaneous collection of\ndiverse data types from individual cells, enhancing our understanding of\ncellular states. However, the integration of these datatypes and modeling the\ninterrelationships between modalities presents substantial computational and\nanalytical challenges in disease biomarker detection and drug discovery.\nEstablished practices rely on isolated methodologies to investigate individual\nmolecular aspects separately, often resulting in inaccurate analyses. To\naddress these obstacles, distinct Machine Learning Techniques are leveraged,\neach of its own kind to model the co-variation of DNA to RNA, and finally to\nsurface proteins in single cells during hematopoietic stem cell development,\nwhich simplifies understanding of underlying cellular mechanisms and immune\nresponses. Experiments conducted on a curated subset of a 300,000-cell time\ncourse dataset, highlights the exceptional performance of Echo State Networks,\nboasting a remarkable state-of-the-art correlation score of 0.94 and 0.895 on\nMulti-omic and CiteSeq datasets. Beyond the confines of this study, these\nfindings hold promise for advancing comprehension of cellular differentiation\nand function, leveraging the potential of Machine Learning.\n","authors":["Bhavya Mehta","Nirmit Deliwala","Madhav Chandane"],"pdf_url":"https://arxiv.org/pdf/2311.12711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.07251v2","updated":"2023-11-21T16:26:36Z","published":"2023-05-12T04:53:59Z","title":"Machine-learning-accelerated simulations to enable automatic surface\n  reconstruction","summary":"  Understanding material surfaces and interfaces is vital in applications like\ncatalysis or electronics. By combining energies from electronic structure with\nstatistical mechanics, ab initio simulations can in principle predict the\nstructure of material surfaces as a function of thermodynamic variables.\nHowever, accurate energy simulations are prohibitive when coupled to the vast\nphase space that must be statistically sampled. Here, we present a bi-faceted\ncomputational loop to predict surface phase diagrams of multi-component\nmaterials that accelerates both the energy scoring and statistical sampling\nmethods. Fast, scalable, and data-efficient machine learning interatomic\npotentials are trained on high-throughput density-functional theory\ncalculations through closed-loop active learning. Markov-chain Monte Carlo\nsampling in the semi-grand canonical ensemble is enabled by using virtual\nsurface sites. The predicted surfaces for GaN(0001), Si(111), and SrTiO3(001)\nare in agreement with past work and suggest that the proposed strategy can\nmodel complex material surfaces and discover previously unreported surface\nterminations.\n","authors":["Xiaochen Du","James K. Damewood","Jaclyn R. Lunger","Reisel Millan","Bilge Yildiz","Lin Li","Rafael Gómez-Bombarelli"],"pdf_url":"https://arxiv.org/pdf/2305.07251v2.pdf","comment":"30 pages main, 15 figures/tables, 5 pages supplementary"},{"id":"http://arxiv.org/abs/2211.08942v2","updated":"2023-11-21T16:14:54Z","published":"2022-11-16T14:44:27Z","title":"Differentially Private Optimizers Can Learn Adversarially Robust Models","summary":"  Machine learning models have shone in a variety of domains and attracted\nincreasing attention from both the security and the privacy communities. One\nimportant yet worrying question is: Will training models under the differential\nprivacy (DP) constraint have an unfavorable impact on their adversarial\nrobustness? While previous works have postulated that privacy comes at the cost\nof worse robustness, we give the first theoretical analysis to show that DP\nmodels can indeed be robust and accurate, even sometimes more robust than their\nnaturally-trained non-private counterparts. We observe three key factors that\ninfluence the privacy-robustness-accuracy tradeoff: (1) hyper-parameters for DP\noptimizers are critical; (2) pre-training on public data significantly\nmitigates the accuracy and robustness drop; (3) choice of DP optimizers makes a\ndifference. With these factors set properly, we achieve 90\\% natural accuracy,\n72\\% robust accuracy ($+9\\%$ than the non-private model) under $l_2(0.5)$\nattack, and 69\\% robust accuracy ($+16\\%$ than the non-private model) with\npre-trained SimCLRv2 model under $l_\\infty(4/255)$ attack on CIFAR10 with\n$\\epsilon=2$. In fact, we show both theoretically and empirically that DP\nmodels are Pareto optimal on the accuracy-robustness tradeoff. Empirically, the\nrobustness of DP models is consistently observed across various datasets and\nmodels. We believe our encouraging results are a significant step towards\ntraining models that are private as well as robust.\n","authors":["Yuan Zhang","Zhiqi Bu"],"pdf_url":"https://arxiv.org/pdf/2211.08942v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.02956v3","updated":"2023-11-21T15:57:17Z","published":"2022-05-05T22:56:19Z","title":"Low Dimensional Invariant Embeddings for Universal Geometric Learning","summary":"  This paper studies separating invariants: mappings on $D$ dimensional domains\nwhich are invariant to an appropriate group action, and which separate orbits.\nThe motivation for this study comes from the usefulness of separating\ninvariants in proving universality of equivariant neural network architectures.\n  We observe that in several cases the cardinality of separating invariants\nproposed in the machine learning literature is much larger than the dimension\n$D$. As a result, the theoretical universal constructions based on these\nseparating invariants is unrealistically large. Our goal in this paper is to\nresolve this issue.\n  We show that when a continuous family of semi-algebraic separating invariants\nis available, separation can be obtained by randomly selecting $2D+1 $ of these\ninvariants. We apply this methodology to obtain an efficient scheme for\ncomputing separating invariants for several classical group actions which have\nbeen studied in the invariant learning literature. Examples include matrix\nmultiplication actions on point clouds by permutations, rotations, and various\nother linear groups.\n  Often the requirement of invariant separation is relaxed and only generic\nseparation is required. In this case, we show that only $D+1$ invariants are\nrequired. More importantly, generic invariants are often significantly easier\nto compute, as we illustrate by discussing generic and full separation for\nweighted graphs. Finally we outline an approach for proving that separating\ninvariants can be constructed also when the random parameters have finite\nprecision.\n","authors":["Nadav Dym","Steven J. Gortler"],"pdf_url":"https://arxiv.org/pdf/2205.02956v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02143v2","updated":"2023-11-21T15:54:28Z","published":"2023-11-03T17:12:29Z","title":"Pairing-based graph neural network for simulating quantum materials","summary":"  We develop a pairing-based graph neural network for simulating quantum\nmany-body systems. Our architecture augments a BCS-type geminal wavefunction\nwith a generalized pair amplitude parameterized by a graph neural network.\nVariational Monte Carlo with our neural network simultaneously provides an\naccurate, flexible, and scalable method for simulating many-electron systems.\nWe apply this method to two-dimensional semiconductor electron-hole bilayers\nand obtain accurate results on a variety of interaction-induced phases,\nincluding the exciton Bose-Einstein condensate, electron-hole superconductor,\nand bilayer Wigner crystal. Our study demonstrates the potential of\nphysically-motivated neural network wavefunctions for quantum materials\nsimulations.\n","authors":["Di Luo","David D. Dai","Liang Fu"],"pdf_url":"https://arxiv.org/pdf/2311.02143v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12689v1","updated":"2023-11-21T15:51:06Z","published":"2023-11-21T15:51:06Z","title":"Fair Text Classification with Wasserstein Independence","summary":"  Group fairness is a central research topic in text classification, where\nreaching fair treatment between sensitive groups (e.g. women vs. men) remains\nan open challenge. This paper presents a novel method for mitigating biases in\nneural text classification, agnostic to the model architecture. Considering the\ndifficulty to distinguish fair from unfair information in a text encoder, we\ntake inspiration from adversarial training to induce Wasserstein independence\nbetween representations learned to predict our target label and the ones\nlearned to predict some sensitive attribute. Our approach provides two\nsignificant advantages. Firstly, it does not require annotations of sensitive\nattributes in both testing and training data. This is more suitable for\nreal-life scenarios compared to existing methods that require annotations of\nsensitive attributes at train time. Second, our approach exhibits a comparable\nor better fairness-accuracy trade-off compared to existing methods.\n","authors":["Thibaud Leteno","Antoine Gourru","Charlotte Laclau","Rémi Emonet","Christophe Gravier"],"pdf_url":"https://arxiv.org/pdf/2311.12689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12688v1","updated":"2023-11-21T15:50:37Z","published":"2023-11-21T15:50:37Z","title":"On the Out-of-Distribution Coverage of Combining Split Conformal\n  Prediction and Bayesian Deep Learning","summary":"  Bayesian deep learning and conformal prediction are two methods that have\nbeen used to convey uncertainty and increase safety in machine learning\nsystems. We focus on combining Bayesian deep learning with split conformal\nprediction and how this combination effects out-of-distribution coverage;\nparticularly in the case of multiclass image classification. We suggest that if\nthe model is generally underconfident on the calibration set, then the\nresultant conformal sets may exhibit worse out-of-distribution coverage\ncompared to simple predictive credible sets. Conversely, if the model is\noverconfident on the calibration set, the use of conformal prediction may\nimprove out-of-distribution coverage. We evaluate prediction sets as a result\nof combining split conformal methods and neural networks trained with (i)\nstochastic gradient descent, (ii) deep ensembles, and (iii) mean-field\nvariational inference. Our results suggest that combining Bayesian deep\nlearning models with split conformal prediction can, in some cases, cause\nunintended consequences such as reducing out-of-distribution coverage.\n","authors":["Paul Scemama","Ariel Kapusta"],"pdf_url":"https://arxiv.org/pdf/2311.12688v1.pdf","comment":"26 pages, 18 figures"},{"id":"http://arxiv.org/abs/2308.16113v2","updated":"2023-11-21T15:50:05Z","published":"2023-08-30T16:14:20Z","title":"survex: an R package for explaining machine learning survival models","summary":"  Due to their flexibility and superior performance, machine learning models\nfrequently complement and outperform traditional statistical survival models.\nHowever, their widespread adoption is hindered by a lack of user-friendly tools\nto explain their internal operations and prediction rationales. To tackle this\nissue, we introduce the survex R package, which provides a cohesive framework\nfor explaining any survival model by applying explainable artificial\nintelligence techniques. The capabilities of the proposed software encompass\nunderstanding and diagnosing survival models, which can lead to their\nimprovement. By revealing insights into the decision-making process, such as\nvariable effects and importances, survex enables the assessment of model\nreliability and the detection of biases. Thus, transparency and responsibility\nmay be promoted in sensitive areas, such as biomedical research and healthcare\napplications.\n","authors":["Mikołaj Spytek","Mateusz Krzyziński","Sophie Hanna Langbein","Hubert Baniecki","Marvin N. Wright","Przemysław Biecek"],"pdf_url":"https://arxiv.org/pdf/2308.16113v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12686v1","updated":"2023-11-21T15:47:06Z","published":"2023-11-21T15:47:06Z","title":"Managing ML-Based Application Non-Functional Behavior: A Multi-Model\n  Approach","summary":"  Modern applications are increasingly driven by Machine Learning (ML) models\nwhose non-deterministic behavior is affecting the entire application life cycle\nfrom design to operation. The pervasive adoption of ML is urgently calling for\napproaches that guarantee a stable non-functional behavior of ML-based\napplications over time and across model changes. To this aim, non-functional\nproperties of ML models, such as privacy, confidentiality, fairness, and\nexplainability, must be monitored, verified, and maintained. This need is even\nmore pressing when modern applications operate in the edge-cloud continuum,\nincreasing their complexity and dynamicity. Existing approaches mostly focus on\ni) implementing classifier selection solutions according to the functional\nbehavior of ML models, ii) finding new algorithmic solutions to this need, such\nas continuous re-training. In this paper, we propose a multi-model approach\nbuilt on dynamic classifier selection, where multiple ML models showing similar\nnon-functional properties are made available to the application and one model\nis selected over time according to (dynamic and unpredictable) contextual\nchanges. Our solution goes beyond the state of the art by providing an\narchitectural and methodological approach that continuously guarantees a stable\nnon-functional behavior of ML-based applications, is applicable to different ML\nmodels, and is driven by non-functional properties assessed on the models\nthemselves. It consists of a two-step process working during application\noperation, where model assessment verifies non-functional properties of ML\nmodels trained and selected at development time, and model substitution\nguarantees a continuous and stable support of non-functional properties. We\nexperimentally evaluate our solution in a real-world scenario focusing on\nnon-functional property fairness.\n","authors":["Marco Anisetti","Claudio A. Ardagna","Nicola Bena","Ernesto Damiani","Paolo G. Panero"],"pdf_url":"https://arxiv.org/pdf/2311.12686v1.pdf","comment":"13 pages, 12 figures"},{"id":"http://arxiv.org/abs/2311.12684v1","updated":"2023-11-21T15:46:11Z","published":"2023-11-21T15:46:11Z","title":"Adversarial Reweighting Guided by Wasserstein Distance for Bias\n  Mitigation","summary":"  The unequal representation of different groups in a sample population can\nlead to discrimination of minority groups when machine learning models make\nautomated decisions. To address these issues, fairness-aware machine learning\njointly optimizes two (or more) metrics aiming at predictive effectiveness and\nlow unfairness. However, the inherent under-representation of minorities in the\ndata makes the disparate treatment of subpopulations less noticeable and\ndifficult to deal with during learning. In this paper, we propose a novel\nadversarial reweighting method to address such \\emph{representation bias}. To\nbalance the data distribution between the majority and the minority groups, our\napproach deemphasizes samples from the majority group. To minimize empirical\nrisk, our method prefers samples from the majority group that are close to the\nminority group as evaluated by the Wasserstein distance. Our theoretical\nanalysis shows the effectiveness of our adversarial reweighting approach.\nExperiments demonstrate that our approach mitigates bias without sacrificing\nclassification accuracy, outperforming related state-of-the-art methods on\nimage and tabular benchmark datasets.\n","authors":["Xuan Zhao","Simone Fabbrizzi","Paula Reyero Lobo","Siamak Ghodsi","Klaus Broelemann","Steffen Staab","Gjergji Kasneci"],"pdf_url":"https://arxiv.org/pdf/2311.12684v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.12311v3","updated":"2023-11-21T15:40:54Z","published":"2020-12-22T19:32:52Z","title":"Influencer Videos: Unboxing the Mystique","summary":"  Influencer marketing has become a very popular tool to reach customers.\nDespite the rapid growth in influencer videos, there has been little research\non the effectiveness of their constituent features in explaining video\nengagement. We study YouTube influencers and analyze their unstructured video\ndata across text, audio and images using an \"interpretable deep learning\"\nframework that accomplishes both goals of prediction and interpretation. Our\nprediction-based approach analyzes unstructured data and finds that \"what is\nsaid\" in words (text) is more influential than \"how it is said\" in imagery\n(images) or acoustics (audio). Our novel interpretation-based approach is\nimplemented after completion of model prediction by analyzing the same source\nof unstructured data to measure importance attributed to the video features. We\neliminate several spurious relationships in two steps, identifying a subset of\nrelationships which are confirmed using theory. We uncover novel findings that\nestablish distinct associations for measures of shallow and deep engagement\nbased on the dual-system framework of human thinking. Our approach is validated\nusing simulated data, and we discuss the learnings from our findings for\ninfluencers and brands.\n","authors":["Prashant Rajaram","Puneet Manchanda"],"pdf_url":"https://arxiv.org/pdf/2012.12311v3.pdf","comment":"45 pages, Online Appendix"},{"id":"http://arxiv.org/abs/2311.12679v1","updated":"2023-11-21T15:37:19Z","published":"2023-11-21T15:37:19Z","title":"BundleMoCap: Efficient, Robust and Smooth Motion Capture from Sparse\n  Multiview Videos","summary":"  Capturing smooth motions from videos using markerless techniques typically\ninvolves complex processes such as temporal constraints, multiple stages with\ndata-driven regression and optimization, and bundle solving over temporal\nwindows. These processes can be inefficient and require tuning multiple\nobjectives across stages. In contrast, BundleMoCap introduces a novel and\nefficient approach to this problem. It solves the motion capture task in a\nsingle stage, eliminating the need for temporal smoothness objectives while\nstill delivering smooth motions. BundleMoCap outperforms the state-of-the-art\nwithout increasing complexity. The key concept behind BundleMoCap is manifold\ninterpolation between latent keyframes. By relying on a local manifold\nsmoothness assumption, we can efficiently solve a bundle of frames using a\nsingle code. Additionally, the method can be implemented as a sliding window\noptimization and requires only the first frame to be properly initialized,\nreducing the overall computational burden. BundleMoCap's strength lies in its\nability to achieve high-quality motion capture results with simplicity and\nefficiency. More details can be found at https://moverseai.github.io/bundle/.\n","authors":["Georgios Albanis","Nikolaos Zioulis","Kostas Kolomvatsos"],"pdf_url":"https://arxiv.org/pdf/2311.12679v1.pdf","comment":"Published in European Conference on Visual Media Production (CVMP\n  '23)"},{"id":"http://arxiv.org/abs/2311.12678v1","updated":"2023-11-21T15:36:20Z","published":"2023-11-21T15:36:20Z","title":"Interpretation of the Transformer and Improvement of the Extractor","summary":"  It has been over six years since the Transformer architecture was put\nforward. Surprisingly, the vanilla Transformer architecture is still widely\nused today. One reason is that the lack of deep understanding and comprehensive\ninterpretation of the Transformer architecture makes it more challenging to\nimprove the Transformer architecture. In this paper, we first interpret the\nTransformer architecture comprehensively in plain words based on our\nunderstanding and experiences. The interpretations are further proved and\nverified. These interpretations also cover the Extractor, a family of drop-in\nreplacements for the multi-head self-attention in the Transformer architecture.\nThen, we propose an improvement on a type of the Extractor that outperforms the\nself-attention, without introducing additional trainable parameters.\nExperimental results demonstrate that the improved Extractor performs even\nbetter, showing a way to improve the Transformer architecture.\n","authors":["Zhe Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12674v1","updated":"2023-11-21T15:31:16Z","published":"2023-11-21T15:31:16Z","title":"Contrastive Left-Right Wearable Sensors (IMUs) Consistency Matching for\n  HAR","summary":"  Machine learning algorithms are improving rapidly, but annotating training\ndata remains a bottleneck for many applications. In this paper, we show how\nreal data can be used for self-supervised learning without any transformations\nby taking advantage of the symmetry present in the activities. Our approach\ninvolves contrastive matching of two different sensors (left and right wrist or\nleg-worn IMUs) to make representations of co-occurring sensor data more similar\nand those of non-co-occurring sensor data more different. We test our approach\non the Opportunity and MM-Fit datasets. In MM-Fit we show significant\nimprovement over the baseline supervised and self-supervised method SimCLR,\nwhile for Opportunity there is significant improvement over the supervised\nbaseline and slight improvement when compared to SimCLR. Moreover, our method\nimproves supervised baselines even when using only a small amount of the data\nfor training. Future work should explore under which conditions our method is\nbeneficial for human activity recognition systems and other related\napplications.\n","authors":["Dominique Nshimyimana","Vitor Fortes Rey","Paul Lukowic"],"pdf_url":"https://arxiv.org/pdf/2311.12674v1.pdf","comment":"Accepted at ABC 2023. The 5th International Conference on Activity\n  and Behavior Computing September 7th - 9th, 2023 in Kaiserslautern, Germany\n  (Hybrid)"},{"id":"http://arxiv.org/abs/2311.12670v1","updated":"2023-11-21T15:28:44Z","published":"2023-11-21T15:28:44Z","title":"Towards a more inductive world for drug repurposing approaches","summary":"  Drug-target interaction (DTI) prediction is a challenging, albeit essential\ntask in drug repurposing. Learning on graph models have drawn special attention\nas they can significantly reduce drug repurposing costs and time commitment.\nHowever, many current approaches require high-demanding additional information\nbesides DTIs that complicates their evaluation process and usability.\nAdditionally, structural differences in the learning architecture of current\nmodels hinder their fair benchmarking. In this work, we first perform an\nin-depth evaluation of current DTI datasets and prediction models through a\nrobust benchmarking process, and show that DTI prediction methods based on\ntransductive models lack generalization and lead to inflated performance when\nevaluated as previously done in the literature, hence not being suited for drug\nrepurposing approaches. We then propose a novel biologically-driven strategy\nfor negative edge subsampling and show through in vitro validation that newly\ndiscovered interactions are indeed true. We envision this work as the\nunderpinning for future fair benchmarking and robust model design. All\ngenerated resources and tools are publicly available as a python package.\n","authors":["Jesus de la Fuente","Guillermo Serrano","Uxía Veleiro","Mikel Casals","Laura Vera","Marija Pizurica","Antonio Pineda-Lucena","Idoia Ochoa","Silve Vicent","Olivier Gevaert","Mikel Hernaez"],"pdf_url":"https://arxiv.org/pdf/2311.12670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2004.07780v5","updated":"2023-11-21T15:22:43Z","published":"2020-04-16T17:18:49Z","title":"Shortcut Learning in Deep Neural Networks","summary":"  Deep learning has triggered the current rise of artificial intelligence and\nis the workhorse of today's machine intelligence. Numerous success stories have\nrapidly spread all over science, industry and society, but its limitations have\nonly recently come into focus. In this perspective we seek to distill how many\nof deep learning's problems can be seen as different symptoms of the same\nunderlying problem: shortcut learning. Shortcuts are decision rules that\nperform well on standard benchmarks but fail to transfer to more challenging\ntesting conditions, such as real-world scenarios. Related issues are known in\nComparative Psychology, Education and Linguistics, suggesting that shortcut\nlearning may be a common characteristic of learning systems, biological and\nartificial alike. Based on these observations, we develop a set of\nrecommendations for model interpretation and benchmarking, highlighting recent\nadvances in machine learning to improve robustness and transferability from the\nlab to real-world applications.\n","authors":["Robert Geirhos","Jörn-Henrik Jacobsen","Claudio Michaelis","Richard Zemel","Wieland Brendel","Matthias Bethge","Felix A. Wichmann"],"pdf_url":"https://arxiv.org/pdf/2004.07780v5.pdf","comment":"perspective article published at Nature Machine Intelligence\n  (https://doi.org/10.1038/s42256-020-00257-z)"},{"id":"http://arxiv.org/abs/2311.12666v1","updated":"2023-11-21T15:18:29Z","published":"2023-11-21T15:18:29Z","title":"SSVEP-DAN: A Data Alignment Network for SSVEP-based Brain Computer\n  Interfaces","summary":"  Steady-state visual-evoked potential (SSVEP)-based brain-computer interfaces\n(BCIs) offer a non-invasive means of communication through high-speed speller\nsystems. However, their efficiency heavily relies on individual training data\nobtained during time-consuming calibration sessions. To address the challenge\nof data insufficiency in SSVEP-based BCIs, we present SSVEP-DAN, the first\ndedicated neural network model designed for aligning SSVEP data across\ndifferent domains, which can encompass various sessions, subjects, or devices.\nOur experimental results across multiple cross-domain scenarios demonstrate\nSSVEP-DAN's capability to transform existing source SSVEP data into\nsupplementary calibration data, significantly enhancing SSVEP decoding accuracy\nin scenarios with limited calibration data. We envision SSVEP-DAN as a catalyst\nfor practical SSVEP-based BCI applications with minimal calibration. The source\ncodes in this work are available at: https://github.com/CECNL/SSVEP-DAN.\n","authors":["Sung-Yu Chen","Chi-Min Chang","Kuan-Jung Chiang","Chun-Shu Wei"],"pdf_url":"https://arxiv.org/pdf/2311.12666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12657v1","updated":"2023-11-21T15:01:14Z","published":"2023-11-21T15:01:14Z","title":"Carbohydrate NMR chemical shift predictions using E(3) equivariant graph\n  neural networks","summary":"  Carbohydrates, vital components of biological systems, are well-known for\ntheir structural diversity. Nuclear Magnetic Resonance (NMR) spectroscopy plays\na crucial role in understanding their intricate molecular arrangements and is\nessential in assessing and verifying the molecular structure of organic\nmolecules. An important part of this process is to predict the NMR chemical\nshift from the molecular structure. This work introduces a novel approach that\nleverages E(3) equivariant graph neural networks to predict carbohydrate NMR\nspectra. Notably, our model achieves a substantial reduction in mean absolute\nerror, up to threefold, compared to traditional models that rely solely on\ntwo-dimensional molecular structure. Even with limited data, the model excels,\nhighlighting its robustness and generalization capabilities. The implications\nare far-reaching and go beyond an advanced understanding of carbohydrate\nstructures and spectral interpretation. For example, it could accelerate\nresearch in pharmaceutical applications, biochemistry, and structural biology,\noffering a faster and more reliable analysis of molecular structures.\nFurthermore, our approach is a key step towards a new data-driven era in\nspectroscopy, potentially influencing spectroscopic techniques beyond NMR.\n","authors":["Maria Bånkestad","Keven M. Dorst","Göran Widmalm","Jerk Rönnols"],"pdf_url":"https://arxiv.org/pdf/2311.12657v1.pdf","comment":"13 pages, 9 figures, 2 tables"},{"id":"http://arxiv.org/abs/2304.12023v2","updated":"2023-11-21T14:59:37Z","published":"2023-04-24T11:44:00Z","title":"Multi-channel Speech Separation Using Spatially Selective Deep\n  Non-linear Filters","summary":"  In a multi-channel separation task with multiple speakers, we aim to recover\nall individual speech signals from the mixture. In contrast to single-channel\napproaches, which rely on the different spectro-temporal characteristics of the\nspeech signals, multi-channel approaches should additionally utilize the\ndifferent spatial locations of the sources for a more powerful separation\nespecially when the number of sources increases. To enhance the spatial\nprocessing in a multi-channel source separation scenario, in this work, we\npropose a deep neural network (DNN) based spatially selective filter (SSF) that\ncan be spatially steered to extract the speaker of interest by initializing a\nrecurrent neural network layer with the target direction. We compare the\nproposed SSF with a common end-to-end direct separation (DS) approach trained\nusing utterance-wise permutation invariant training (PIT), which only\nimplicitly learns to perform spatial filtering. We show that the SSF has a\nclear advantage over a DS approach with the same underlying network\narchitecture when there are more than two speakers in the mixture, which can be\nattributed to a better use of the spatial information. Furthermore, we find\nthat the SSF generalizes much better to additional noise sources that were not\nseen during training and to scenarios with speakers positioned at a similar\nangle.\n","authors":["Kristina Tesch","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2304.12023v2.pdf","comment":"Accepted version"},{"id":"http://arxiv.org/abs/2302.04181v2","updated":"2023-11-21T14:56:21Z","published":"2023-02-08T16:40:11Z","title":"Attending to Graph Transformers","summary":"  Recently, transformer architectures for graphs emerged as an alternative to\nestablished techniques for machine learning with graphs, such as\n(message-passing) graph neural networks. So far, they have shown promising\nempirical results, e.g., on molecular prediction datasets, often attributed to\ntheir ability to circumvent graph neural networks' shortcomings, such as\nover-smoothing and over-squashing. Here, we derive a taxonomy of graph\ntransformer architectures, bringing some order to this emerging field. We\noverview their theoretical properties, survey structural and positional\nencodings, and discuss extensions for important graph classes, e.g., 3D\nmolecular graphs. Empirically, we probe how well graph transformers can recover\nvarious graph properties, how well they can deal with heterophilic graphs, and\nto what extent they prevent over-squashing. Further, we outline open challenges\nand research direction to stimulate future work. Our code is available at\nhttps://github.com/luis-mueller/probing-graph-transformers.\n","authors":["Luis Müller","Mikhail Galkin","Christopher Morris","Ladislav Rampášek"],"pdf_url":"https://arxiv.org/pdf/2302.04181v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04158v2","updated":"2023-11-21T14:55:52Z","published":"2023-11-07T17:34:56Z","title":"Computing Approximate $\\ell_p$ Sensitivities","summary":"  Recent works in dimensionality reduction for regression tasks have introduced\nthe notion of sensitivity, an estimate of the importance of a specific\ndatapoint in a dataset, offering provable guarantees on the quality of the\napproximation after removing low-sensitivity datapoints via subsampling.\nHowever, fast algorithms for approximating $\\ell_p$ sensitivities, which we\nshow is equivalent to approximate $\\ell_p$ regression, are known for only the\n$\\ell_2$ setting, in which they are termed leverage scores.\n  In this work, we provide efficient algorithms for approximating $\\ell_p$\nsensitivities and related summary statistics of a given matrix. In particular,\nfor a given $n \\times d$ matrix, we compute $\\alpha$-approximation to its\n$\\ell_1$ sensitivities at the cost of $O(n/\\alpha)$ sensitivity computations.\nFor estimating the total $\\ell_p$ sensitivity (i.e. the sum of $\\ell_p$\nsensitivities), we provide an algorithm based on importance sampling of\n$\\ell_p$ Lewis weights, which computes a constant factor approximation to the\ntotal sensitivity at the cost of roughly $O(\\sqrt{d})$ sensitivity\ncomputations. Furthermore, we estimate the maximum $\\ell_1$ sensitivity, up to\na $\\sqrt{d}$ factor, using $O(d)$ sensitivity computations. We generalize all\nthese results to $\\ell_p$ norms for $p > 1$. Lastly, we experimentally show\nthat for a wide class of matrices in real-world datasets, the total sensitivity\ncan be quickly approximated and is significantly smaller than the theoretical\nprediction, demonstrating that real-world datasets have low intrinsic effective\ndimensionality.\n","authors":["Swati Padmanabhan","David P. Woodruff","Qiuyi Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.04158v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12652v1","updated":"2023-11-21T14:53:39Z","published":"2023-11-21T14:53:39Z","title":"FedDRO: Federated Compositional Optimization for Distributionally Robust\n  Learning","summary":"  Recently, compositional optimization (CO) has gained popularity because of\nits applications in distributionally robust optimization (DRO) and many other\nmachine learning problems. Large-scale and distributed availability of data\ndemands the development of efficient federated learning (FL) algorithms for\nsolving CO problems. Developing FL algorithms for CO is particularly\nchallenging because of the compositional nature of the objective. Moreover,\ncurrent state-of-the-art methods to solve such problems rely on large batch\ngradients (depending on the solution accuracy) not feasible for most practical\nsettings. To address these challenges, in this work, we propose efficient\nFedAvg-type algorithms for solving non-convex CO in the FL setting. We first\nestablish that vanilla FedAvg is not suitable to solve distributed CO problems\nbecause of the data heterogeneity in the compositional objective at each client\nwhich leads to the amplification of bias in the local compositional gradient\nestimates. To this end, we propose a novel FL framework FedDRO that utilizes\nthe DRO problem structure to design a communication strategy that allows FedAvg\nto control the bias in the estimation of the compositional gradient. A key\nnovelty of our work is to develop solution accuracy-independent algorithms that\ndo not require large batch gradients (and function evaluations) for solving\nfederated CO problems. We establish $\\mathcal{O}(\\epsilon^{-2})$ sample and\n$\\mathcal{O}(\\epsilon^{-3/2})$ communication complexity in the FL setting while\nachieving linear speedup with the number of clients. We corroborate our\ntheoretical findings with empirical studies on large-scale DRO problems.\n","authors":["Prashant Khanduri","Chengyin Li","Rafi Ibn Sultan","Yao Qiang","Joerg Kliewer","Dongxiao Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.12652v1.pdf","comment":"38 Pages, 6 Figures"},{"id":"http://arxiv.org/abs/2310.19805v3","updated":"2023-11-21T14:50:12Z","published":"2023-10-07T00:02:05Z","title":"Sample Efficient Reward Augmentation in offline-to-online Reinforcement\n  Learning","summary":"  Offline-to-online RL can make full use of pre-collected offline datasets to\ninitialize policies, resulting in higher sample efficiency and better\nperformance compared to only using online algorithms alone for policy training.\nHowever, direct fine-tuning of the pre-trained policy tends to result in\nsub-optimal performance. A primary reason is that conservative offline RL\nmethods diminish the agent's capability of exploration, thereby impacting\nonline fine-tuning performance. To encourage agent's exploration during online\nfine-tuning and enhance the overall online fine-tuning performance, we propose\na generalized reward augmentation method called Sample Efficient Reward\nAugmentation (SERA). Specifically, SERA encourages agent to explore by\ncomputing Q conditioned entropy as intrinsic reward. The advantage of SERA is\nthat it can extensively utilize offline pre-trained Q to encourage agent\nuniformly coverage of state space while considering the imbalance between the\ndistributions of high-value and low-value states. Additionally, SERA can be\neffortlessly plugged into various RL algorithms to improve online fine-tuning\nand ensure sustained asymptotic improvement. Moreover, extensive experimental\nresults demonstrate that when conducting offline-to-online problems, SERA\nconsistently and effectively enhances the performance of various offline\nalgorithms.\n","authors":["Ziqi Zhang","Xiao Xiong","Zifeng Zhuang","Jinxin Liu","Donglin Wang"],"pdf_url":"https://arxiv.org/pdf/2310.19805v3.pdf","comment":"23 pages, 11 Figures, and 6 Tables"},{"id":"http://arxiv.org/abs/2311.12644v1","updated":"2023-11-21T14:44:51Z","published":"2023-11-21T14:44:51Z","title":"Careful Selection and Thoughtful Discarding: Graph Explicit Pooling\n  Utilizing Discarded Nodes","summary":"  Graph pooling has been increasingly recognized as crucial for Graph Neural\nNetworks (GNNs) to facilitate hierarchical graph representation learning.\nExisting graph pooling methods commonly consist of two stages: selecting\ntop-ranked nodes and discarding the remaining to construct coarsened graph\nrepresentations. However, this paper highlights two key issues with these\nmethods: 1) The process of selecting nodes to discard frequently employs\nadditional Graph Convolutional Networks or Multilayer Perceptrons, lacking a\nthorough evaluation of each node's impact on the final graph representation and\nsubsequent prediction tasks. 2) Current graph pooling methods tend to directly\ndiscard the noise segment (dropped) of the graph without accounting for the\nlatent information contained within these elements. To address the first issue,\nwe introduce a novel Graph Explicit Pooling (GrePool) method, which selects\nnodes by explicitly leveraging the relationships between the nodes and final\nrepresentation vectors crucial for classification. The second issue is\naddressed using an extended version of GrePool (i.e., GrePool+), which applies\na uniform loss on the discarded nodes. This addition is designed to augment the\ntraining process and improve classification accuracy. Furthermore, we conduct\ncomprehensive experiments across 12 widely used datasets to validate our\nproposed method's effectiveness, including the Open Graph Benchmark datasets.\nOur experimental results uniformly demonstrate that GrePool outperforms 14\nbaseline methods for most datasets. Likewise, implementing GrePool+ enhances\nGrePool's performance without incurring additional computational costs.\n","authors":["Chuang Liu","Wenhang Yu","Kuang Gao","Xueqi Ma","Yibing Zhan","Jia Wu","Bo Du","Wenbin Hu"],"pdf_url":"https://arxiv.org/pdf/2311.12644v1.pdf","comment":"14 pages, 7 figures, 4 tables. Submitting to Science China\n  Information Sciences"},{"id":"http://arxiv.org/abs/2311.12630v1","updated":"2023-11-21T14:24:21Z","published":"2023-11-21T14:24:21Z","title":"Hierarchical Joint Graph Learning and Multivariate Time Series\n  Forecasting","summary":"  Multivariate time series is prevalent in many scientific and industrial\ndomains. Modeling multivariate signals is challenging due to their long-range\ntemporal dependencies and intricate interactions--both direct and indirect. To\nconfront these complexities, we introduce a method of representing multivariate\nsignals as nodes in a graph with edges indicating interdependency between them.\nSpecifically, we leverage graph neural networks (GNN) and attention mechanisms\nto efficiently learn the underlying relationships within the time series data.\nMoreover, we suggest employing hierarchical signal decompositions running over\nthe graphs to capture multiple spatial dependencies. The effectiveness of our\nproposed model is evaluated across various real-world benchmark datasets\ndesigned for long-term forecasting tasks. The results consistently showcase the\nsuperiority of our model, achieving an average 23\\% reduction in mean squared\nerror (MSE) compared to existing models.\n","authors":["Juhyeon Kim","Hyungeun Lee","Seungwon Yu","Ung Hwang","Wooyul Jung","Miseon Park","Kijung Yoon"],"pdf_url":"https://arxiv.org/pdf/2311.12630v1.pdf","comment":"Temporal Graph Learning Workshop @ NeurIPS 2023, New Orleans, United\n  States"},{"id":"http://arxiv.org/abs/2311.12624v1","updated":"2023-11-21T14:18:28Z","published":"2023-11-21T14:18:28Z","title":"Bridging Algorithmic Information Theory and Machine Learning: A New\n  Approach to Kernel Learning","summary":"  Machine Learning (ML) and Algorithmic Information Theory (AIT) look at\nComplexity from different points of view. We explore the interface between AIT\nand Kernel Methods (that are prevalent in ML) by adopting an AIT perspective on\nthe problem of learning kernels from data, in kernel ridge regression, through\nthe method of Sparse Kernel Flows. In particular, by looking at the differences\nand commonalities between Minimal Description Length (MDL) and Regularization\nin Machine Learning (RML), we prove that the method of Sparse Kernel Flows is\nthe natural approach to adopt to learn kernels from data. This paper shows that\nit is not necessary to use the statistical route to derive Sparse Kernel Flows\nand that one can directly work with code-lengths and complexities that are\nconcepts that show up in AIT.\n","authors":["Boumediene Hamzi","Marcus Hutter","Houman Owhadi"],"pdf_url":"https://arxiv.org/pdf/2311.12624v1.pdf","comment":"An earlier version of this paper appeared at\n  https://www.researchgate.net/publication/371875631_A_note_on_learning_kernels_from_data_from_an_Algorithmic_Information_Theoretic_point_of_view.\n  arXiv admin note: text overlap with arXiv:2111.13037, arXiv:2007.05074"},{"id":"http://arxiv.org/abs/2306.03163v2","updated":"2023-11-21T14:10:03Z","published":"2023-06-05T18:17:37Z","title":"How Can We Train Deep Learning Models Across Clouds and Continents? An\n  Experimental Study","summary":"  Training deep learning models in the cloud or on dedicated hardware is\nexpensive. A more cost-efficient option are hyperscale clouds offering spot\ninstances, a cheap but ephemeral alternative to on-demand resources. As spot\ninstance availability can change depending on the time of day, continent, and\ncloud provider, it could be more cost-efficient to distribute resources over\nthe world. Still, it has not been investigated whether geo-distributed,\ndata-parallel spot deep learning training could be a more cost-efficient\nalternative to centralized training.\n  This paper aims to answer the question: Can deep learning models be\ncost-efficiently trained on a global market of spot VMs spanning different data\ncenters and cloud providers? To provide guidance, we extensively evaluate the\ncost and throughput implications of training in different zones, continents,\nand clouds for representative CV, NLP and ASR models. To expand the current\ntraining options further, we compare the scalability potential for hybrid-cloud\nscenarios by adding cloud resources to on-premise hardware to improve training\nthroughput. Finally, we show how leveraging spot instance pricing enables a new\ncost-efficient way to train models with multiple cheap VMs, trumping both more\ncentralized and powerful hardware and even on-demand cloud offerings at\ncompetitive prices.\n","authors":["Alexander Isenko","Ruben Mayer","Hans-Arno Jacobsen"],"pdf_url":"https://arxiv.org/pdf/2306.03163v2.pdf","comment":"Currently in review. Artifacts and Code:\n  https://github.com/cirquit/hivemind-multi-cloud"},{"id":"http://arxiv.org/abs/2211.07931v3","updated":"2023-11-21T13:59:55Z","published":"2022-11-15T06:30:57Z","title":"Personalized Federated Learning with Multi-branch Architecture","summary":"  Federated learning (FL) is a decentralized machine learning technique that\nenables multiple clients to collaboratively train models without requiring\nclients to reveal their raw data to each other. Although traditional FL trains\na single global model with average performance among clients, statistical data\nheterogeneity across clients has resulted in the development of personalized FL\n(PFL), which trains personalized models with good performance on each client's\ndata. A key challenge with PFL is how to facilitate clients with similar data\nto collaborate more in a situation where each client has data from complex\ndistribution and cannot determine one another's distribution. In this paper, we\npropose a new PFL method (pFedMB) using multi-branch architecture, which\nachieves personalization by splitting each layer of a neural network into\nmultiple branches and assigning client-specific weights to each branch. We also\ndesign an aggregation method to improve the communication efficiency and the\nmodel performance, with which each branch is globally updated with weighted\naveraging by client-specific weights assigned to the branch. pFedMB is simple\nbut effective in facilitating each client to share knowledge with similar\nclients by adjusting the weights assigned to each branch. We experimentally\nshow that pFedMB performs better than the state-of-the-art PFL methods using\nthe CIFAR10 and CIFAR100 datasets.\n","authors":["Junki Mori","Tomoyuki Yoshiyama","Furukawa Ryo","Isamu Teranishi"],"pdf_url":"https://arxiv.org/pdf/2211.07931v3.pdf","comment":"Published at IJCNN 2023"},{"id":"http://arxiv.org/abs/2311.12615v1","updated":"2023-11-21T13:59:00Z","published":"2023-11-21T13:59:00Z","title":"Koopman Learning with Episodic Memory","summary":"  Koopman operator theory, a data-driven dynamical systems framework, has found\nsignificant success in learning models from complex, real-world data sets,\nenabling state-of-the-art prediction and control. The greater interpretability\nand lower computational costs of these models, compared to traditional machine\nlearning methodologies, make Koopman learning an especially appealing approach.\nDespite this, little work has been performed on endowing Koopman learning with\nthe ability to learn from its own mistakes. To address this, we equip Koopman\nmethods - developed for predicting non-stationary time-series - with an\nepisodic memory mechanism, enabling global recall of (or attention to) periods\nin time where similar dynamics previously occurred. We find that a basic\nimplementation of Koopman learning with episodic memory leads to significant\nimprovements in prediction on synthetic and real-world data. Our framework has\nconsiderable potential for expansion, allowing for future advances, and opens\nexciting new directions for Koopman learning.\n","authors":["William T. Redman","Dean Huang","Maria Fonoberova","Igor Mezić"],"pdf_url":"https://arxiv.org/pdf/2311.12615v1.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2310.10837v3","updated":"2023-11-21T13:58:00Z","published":"2023-10-16T21:23:16Z","title":"Approximating Two-Layer Feedforward Networks for Efficient Transformers","summary":"  How to reduce compute and memory requirements of neural networks (NNs)\nwithout sacrificing performance? Many recent works use sparse Mixtures of\nExperts (MoEs) to build resource-efficient large language models (LMs). Here we\nintroduce several novel perspectives on MoEs, presenting a general framework\nthat unifies various methods to approximate two-layer NNs (e.g., feedforward\nblocks of Transformers), including product-key memories (PKMs). Leveraging\ninsights from this framework, we propose methods to improve both MoEs and PKMs.\nUnlike prior work that compares MoEs with dense baselines under the\ncompute-equal condition, our evaluation condition is parameter-equal, which is\ncrucial to properly evaluate LMs. We show that our MoEs are competitive with\nthe dense Transformer-XL on both the WikiText-103 and enwiki8 datasets at two\ndifferent scales, while being much more resource efficient. This demonstrates\nthat MoEs are relevant not only to extremely large LMs but also to any-scale\nresource-efficient LMs. Our code is public.\n","authors":["Róbert Csordás","Kazuki Irie","Jürgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2310.10837v3.pdf","comment":"Accepted to EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2311.12613v1","updated":"2023-11-21T13:56:44Z","published":"2023-11-21T13:56:44Z","title":"Decentralised Q-Learning for Multi-Agent Markov Decision Processes with\n  a Satisfiability Criterion","summary":"  In this paper, we propose a reinforcement learning algorithm to solve a\nmulti-agent Markov decision process (MMDP). The goal, inspired by Blackwell's\nApproachability Theorem, is to lower the time average cost of each agent to\nbelow a pre-specified agent-specific bound. For the MMDP, we assume the state\ndynamics to be controlled by the joint actions of agents, but the per-stage\ncosts to only depend on the individual agent's actions. We combine the\nQ-learning algorithm for a weighted combination of the costs of each agent,\nobtained by a gossip algorithm with the Metropolis-Hastings or Multiplicative\nWeights formalisms to modulate the averaging matrix of the gossip. We use\nmultiple timescales in our algorithm and prove that under mild conditions, it\napproximately achieves the desired bounds for each of the agents. We also\ndemonstrate the empirical performance of this algorithm in the more general\nsetting of MMDPs having jointly controlled per-stage costs.\n","authors":["Keshav P. Keval","Vivek S. Borkar"],"pdf_url":"https://arxiv.org/pdf/2311.12613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.05858v2","updated":"2023-11-21T13:55:33Z","published":"2023-11-10T03:54:40Z","title":"Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation","summary":"  Given the inevitability of domain shifts during inference in real-world\napplications, test-time adaptation (TTA) is essential for model adaptation\nafter deployment. However, the real-world scenario of continuously changing\ntarget distributions presents challenges including catastrophic forgetting and\nerror accumulation. Existing TTA methods for non-stationary domain shifts,\nwhile effective, incur excessive computational load, making them impractical\nfor on-device settings. In this paper, we introduce a layer-wise auto-weighting\nalgorithm for continual and gradual TTA that autonomously identifies layers for\npreservation or concentrated adaptation. By leveraging the Fisher Information\nMatrix (FIM), we first design the learning weight to selectively focus on\nlayers associated with log-likelihood changes while preserving unrelated ones.\nThen, we further propose an exponential min-max scaler to make certain layers\nnearly frozen while mitigating outliers. This minimizes forgetting and error\naccumulation, leading to efficient adaptation to non-stationary target\ndistribution. Experiments on CIFAR-10C, CIFAR-100C, and ImageNet-C show our\nmethod outperforms conventional continual and gradual TTA approaches while\nsignificantly reducing computational load, highlighting the importance of\nFIM-based learning weight in adapting to continuously or gradually shifting\ntarget domains.\n","authors":["Junyoung Park","Jin Kim","Hyeongjun Kwon","Ilhoon Yoon","Kwanghoon Sohn"],"pdf_url":"https://arxiv.org/pdf/2311.05858v2.pdf","comment":"Accepted to WACV 2024"},{"id":"http://arxiv.org/abs/2308.07121v2","updated":"2023-11-21T13:55:04Z","published":"2023-08-14T13:06:10Z","title":"Active Bird2Vec: Towards End-to-End Bird Sound Monitoring with\n  Transformers","summary":"  We propose a shift towards end-to-end learning in bird sound monitoring by\ncombining self-supervised (SSL) and deep active learning (DAL). Leveraging\ntransformer models, we aim to bypass traditional spectrogram conversions,\nenabling direct raw audio processing. ActiveBird2Vec is set to generate\nhigh-quality bird sound representations through SSL, potentially accelerating\nthe assessment of environmental changes and decision-making processes for wind\nfarms. Additionally, we seek to utilize the wide variety of bird vocalizations\nthrough DAL, reducing the reliance on extensively labeled datasets by human\nexperts. We plan to curate a comprehensive set of tasks through Huggingface\nDatasets, enhancing future comparability and reproducibility of bioacoustic\nresearch. A comparative analysis between various transformer models will be\nconducted to evaluate their proficiency in bird sound recognition tasks. We aim\nto accelerate the progression of avian bioacoustic research and contribute to\nmore effective conservation strategies.\n","authors":["Lukas Rauch","Raphael Schwinger","Moritz Wirth","Bernhard Sick","Sven Tomforde","Christoph Scholz"],"pdf_url":"https://arxiv.org/pdf/2308.07121v2.pdf","comment":"Accepted @AI4S ECAI2023. This is the author's version of the work"},{"id":"http://arxiv.org/abs/2311.12612v1","updated":"2023-11-21T13:54:08Z","published":"2023-11-21T13:54:08Z","title":"A New Type Of Upper And Lower Bounds On Right-Tail Probabilities Of\n  Continuous Random Variables","summary":"  In this paper, I present a completely new type of upper and lower bounds on\nthe right-tail probabilities of continuous random variables with unbounded\nsupport and with semi-bounded support from the left. The presented upper and\nlower right-tail bounds depend only on the probability density function (PDF),\nits first derivative, and two parameters that are used for tightening the\nbounds. These tail bounds hold under certain conditions that depend on the PDF,\nits first and second derivatives, and the two parameters. The new tail bounds\nare shown to be tight for a wide range of continuous random variables via\nnumerical examples.\n","authors":["Nikola Zlatanov"],"pdf_url":"https://arxiv.org/pdf/2311.12612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.07955v2","updated":"2023-11-21T13:53:36Z","published":"2023-04-17T02:50:18Z","title":"Heterogeneous Domain Adaptation with Positive and Unlabeled Data","summary":"  Heterogeneous unsupervised domain adaptation (HUDA) is the most challenging\ndomain adaptation setting where the feature spaces of source and target domains\nare heterogeneous, and the target domain has only unlabeled data. Existing HUDA\nmethods assume that both positive and negative examples are available in the\nsource domain, which may not be satisfied in some real applications. This paper\naddresses a new challenging setting called positive and unlabeled heterogeneous\nunsupervised domain adaptation (PU-HUDA), a HUDA setting where the source\ndomain only has positives. PU-HUDA can also be viewed as an extension of PU\nlearning where the positive and unlabeled examples are sampled from different\ndomains. A naive combination of existing HUDA and PU learning methods is\nineffective in PU-HUDA due to the gap in label distribution between the source\nand target domains. To overcome this issue, we propose a novel method,\npredictive adversarial domain adaptation (PADA), which can predict likely\npositive examples from the unlabeled target data and simultaneously align the\nfeature spaces to reduce the distribution divergence between the whole source\ndata and the likely positive target data. PADA achieves this by a unified\nadversarial training framework for learning a classifier to predict positive\nexamples and a feature transformer to transform the target feature space to\nthat of the source. Specifically, they are both trained to fool a common\ndiscriminator that determines whether the likely positive examples are from the\ntarget or source domain. We experimentally show that PADA outperforms several\nbaseline methods, such as the naive combination of HUDA and PU learning.\n","authors":["Junki Mori","Ryo Furukawa","Isamu Teranishi","Jun Sakuma"],"pdf_url":"https://arxiv.org/pdf/2304.07955v2.pdf","comment":"Accepted by IEEE Big Data 2023 as a regular paper"},{"id":"http://arxiv.org/abs/2311.12602v1","updated":"2023-11-21T13:43:06Z","published":"2023-11-21T13:43:06Z","title":"TouchSDF: A DeepSDF Approach for 3D Shape Reconstruction using\n  Vision-Based Tactile Sensing","summary":"  Humans rely on their visual and tactile senses to develop a comprehensive 3D\nunderstanding of their physical environment. Recently, there has been a growing\ninterest in exploring and manipulating objects using data-driven approaches\nthat utilise high-resolution vision-based tactile sensors. However, 3D shape\nreconstruction using tactile sensing has lagged behind visual shape\nreconstruction because of limitations in existing techniques, including the\ninability to generalise over unseen shapes, the absence of real-world testing,\nand limited expressive capacity imposed by discrete representations. To address\nthese challenges, we propose TouchSDF, a Deep Learning approach for tactile 3D\nshape reconstruction that leverages the rich information provided by a\nvision-based tactile sensor and the expressivity of the implicit neural\nrepresentation DeepSDF. Our technique consists of two components: (1) a\nConvolutional Neural Network that maps tactile images into local meshes\nrepresenting the surface at the touch location, and (2) an implicit neural\nfunction that predicts a signed distance function to extract the desired 3D\nshape. This combination allows TouchSDF to reconstruct smooth and continuous 3D\nshapes from tactile inputs in simulation and real-world settings, opening up\nresearch avenues for robust 3D-aware representations and improved multimodal\nperception in robotics. Code and supplementary material are available at:\nhttps://touchsdf.github.io/\n","authors":["Mauro Comi","Yijiong Lin","Alex Church","Alessio Tonioni","Laurence Aitchison","Nathan F. Lepora"],"pdf_url":"https://arxiv.org/pdf/2311.12602v1.pdf","comment":"10 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.12601v1","updated":"2023-11-21T13:42:40Z","published":"2023-11-21T13:42:40Z","title":"Deep learning-based detection of morphological features associated with\n  hypoxia in H&E breast cancer whole slide images","summary":"  Hypoxia occurs when tumour cells outgrow their blood supply, leading to\nregions of low oxygen levels within the tumour. Calculating hypoxia levels can\nbe an important step in understanding the biology of tumours, their clinical\nprogression and response to treatment. This study demonstrates a novel\napplication of deep learning to evaluate hypoxia in the context of breast\ncancer histomorphology. More precisely, we show that Weakly Supervised Deep\nLearning (WSDL) models can accurately detect hypoxia associated features in\nroutine Hematoxylin and Eosin (H&E) whole slide images (WSI). We trained and\nevaluated a deep Multiple Instance Learning model on tiles from WSI H&E tissue\nfrom breast cancer primary sites (n=240) obtaining on average an AUC of 0.87 on\na left-out test set. We also showed significant differences between features of\nhypoxic and normoxic tissue regions as distinguished by the WSDL models. Such\nDL hypoxia H&E WSI detection models could potentially be extended to other\ntumour types and easily integrated into the pathology workflow without\nrequiring additional costly assays.\n","authors":["Petru Manescu","Joseph Geradts","Delmiro Fernandez-Reyes"],"pdf_url":"https://arxiv.org/pdf/2311.12601v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2310.17355v2","updated":"2023-11-21T13:27:01Z","published":"2023-10-26T12:44:33Z","title":"Exploring the Trie of Rules: a fast data structure for the\n  representation of association rules","summary":"  Association rule mining techniques can generate a large volume of sequential\ndata when implemented on transactional databases. Extracting insights from a\nlarge set of association rules has been found to be a challenging process. When\nexamining a ruleset, the fundamental question is how to summarise and represent\nmeaningful mined knowledge efficiently. Many algorithms and strategies have\nbeen developed to address issue of knowledge extraction; however, the\neffectiveness of this process can be limited by the data structures. A better\ndata structure can sufficiently affect the speed of the knowledge extraction\nprocess. This paper proposes a novel data structure, called the Trie of rules,\nfor storing a ruleset that is generated by association rule mining. The\nresulting data structure is a prefix-tree graph structure made of pre-mined\nrules. This graph stores the rules as paths within the prefix-tree in a way\nthat similar rules overlay each other. Each node in the tree represents a rule\nwhere a consequent is this node, and an antecedent is a path from this node to\nthe root of the tree. The evaluation showed that the proposed representation\ntechnique is promising. It compresses a ruleset with almost no data loss and\nbenefits in terms of time for basic operations such as searching for a specific\nrule and sorting, which is the base for many knowledge discovery methods.\nMoreover, our method demonstrated a significant improvement in traversing time,\nachieving an 8-fold increase compared to traditional data structures.\n","authors":["Mikhail Kudriavtsev","Marija Bezbradica","Andrew McCarren"],"pdf_url":"https://arxiv.org/pdf/2310.17355v2.pdf","comment":"12 pages, 13 figures, preprint of journal article"},{"id":"http://arxiv.org/abs/2311.12590v1","updated":"2023-11-21T13:26:33Z","published":"2023-11-21T13:26:33Z","title":"ChronoPscychosis: Temporal Segmentation and Its Impact on Schizophrenia\n  Classification Using Motor Activity Data","summary":"  Schizophrenia is a complicated mental illness characterized by a broad\nspectrum of symptoms affecting cognition, behavior, and emotion. The task of\nidentifying reliable biomarkers to classify Schizophrenia accurately continues\nto be a challenge in the field of psychiatry. We investigate the temporal\npatterns within the motor activity data as a potential key to enhancing the\ncategorization of individuals with Schizophrenia, using the dataset having\nmotor activity recordings of 22 Schizophrenia patients and 32 control subjects.\nThe dataset contains per-minute motor activity measurements collected for an\naverage of 12.7 days in a row for each participant. We dissect each day into\nsegments (Twelve, Eight, six, four, three, and two parts) and evaluate their\nimpact on classification. We employ sixteen statistical features within these\ntemporal segments and train them on Seven machine learning models to get deeper\ninsights. LightGBM model outperforms the other six models. Our results indicate\nthat the temporal segmentation significantly improves the classification, with\nAUC-ROC = 0.93, F1 score = 0.84( LightGBM- without any segmentation) and\nAUC-ROC = 0.98, F1 score = 0.93( LightGBM- with segmentation). Distinguishing\nbetween diurnal and nocturnal segments amplifies the differences between\nSchizophrenia patients and controls. However, further subdivisions into smaller\ntime segments do not affect the AUC- ROC significantly. Morning, afternoon,\nevening, and night partitioning gives similar classification performance to\nday-night partitioning. These findings are valuable as they indicate that\nextensive temporal classification beyond distinguishing between day and night\ndoes not yield substantial results, offering an efficient approach for further\nclassification, early diagnosis, and monitoring of Schizophrenia.\n","authors":["Pradnya Rajendra Jadhav","Raviprasad Aduri"],"pdf_url":"https://arxiv.org/pdf/2311.12590v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12589v1","updated":"2023-11-21T13:26:13Z","published":"2023-11-21T13:26:13Z","title":"Improving Source-Free Target Adaptation with Vision Transformers\n  Leveraging Domain Representation Images","summary":"  Unsupervised Domain Adaptation (UDA) methods facilitate knowledge transfer\nfrom a labeled source domain to an unlabeled target domain, navigating the\nobstacle of domain shift. While Convolutional Neural Networks (CNNs) are a\nstaple in UDA, the rise of Vision Transformers (ViTs) provides new avenues for\ndomain generalization. This paper presents an innovative method to bolster ViT\nperformance in source-free target adaptation, beginning with an evaluation of\nhow key, query, and value elements affect ViT outcomes. Experiments indicate\nthat altering the key component has negligible effects on Transformer\nperformance. Leveraging this discovery, we introduce Domain Representation\nImages (DRIs), feeding embeddings through the key element. DRIs act as\ndomain-specific markers, effortlessly merging with the training regimen. To\nassess our method, we perform target adaptation tests on the Cross Instance DRI\nsource-only (SO) control. We measure the efficacy of target adaptation with and\nwithout DRIs, against existing benchmarks like SHOT-B* and adaptations via\nCDTrans. Findings demonstrate that excluding DRIs offers limited gains over\nSHOT-B*, while their inclusion in the key segment boosts average precision\npromoting superior domain generalization. This research underscores the vital\nrole of DRIs in enhancing ViT efficiency in UDA scenarios, setting a precedent\nfor further domain adaptation explorations.\n","authors":["Gauransh Sawhney","Daksh Dave","Adeel Ahmed","Jiechao Gao","Khalid Saleem"],"pdf_url":"https://arxiv.org/pdf/2311.12589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.09355v5","updated":"2023-11-21T13:12:21Z","published":"2023-04-19T00:33:59Z","title":"To Compress or Not to Compress- Self-Supervised Learning and Information\n  Theory: A Review","summary":"  Deep neural networks excel in supervised learning tasks but are constrained\nby the need for extensive labeled data. Self-supervised learning emerges as a\npromising alternative, allowing models to learn without explicit labels.\nInformation theory, and notably the information bottleneck principle, has been\npivotal in shaping deep neural networks. This principle focuses on optimizing\nthe trade-off between compression and preserving relevant information,\nproviding a foundation for efficient network design in supervised contexts.\nHowever, its precise role and adaptation in self-supervised learning remain\nunclear. In this work, we scrutinize various self-supervised learning\napproaches from an information-theoretic perspective, introducing a unified\nframework that encapsulates the \\textit{self-supervised information-theoretic\nlearning problem}. We weave together existing research into a cohesive\nnarrative, delve into contemporary self-supervised methodologies, and spotlight\npotential research avenues and inherent challenges. Additionally, we discuss\nthe empirical evaluation of information-theoretic quantities and their\nestimation methods. Overall, this paper furnishes an exhaustive review of the\nintersection of information theory, self-supervised learning, and deep neural\nnetworks.\n","authors":["Ravid Shwartz-Ziv","Yann LeCun"],"pdf_url":"https://arxiv.org/pdf/2304.09355v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.11494v2","updated":"2023-11-21T13:11:36Z","published":"2023-07-21T10:56:36Z","title":"Predict, Refine, Synthesize: Self-Guiding Diffusion Models for\n  Probabilistic Time Series Forecasting","summary":"  Diffusion models have achieved state-of-the-art performance in generative\nmodeling tasks across various domains. Prior works on time series diffusion\nmodels have primarily focused on developing conditional models tailored to\nspecific forecasting or imputation tasks. In this work, we explore the\npotential of task-agnostic, unconditional diffusion models for several time\nseries applications. We propose TSDiff, an unconditionally-trained diffusion\nmodel for time series. Our proposed self-guidance mechanism enables\nconditioning TSDiff for downstream tasks during inference, without requiring\nauxiliary networks or altering the training procedure. We demonstrate the\neffectiveness of our method on three different time series tasks: forecasting,\nrefinement, and synthetic data generation. First, we show that TSDiff is\ncompetitive with several task-specific conditional forecasting methods\n(predict). Second, we leverage the learned implicit probability density of\nTSDiff to iteratively refine the predictions of base forecasters with reduced\ncomputational overhead over reverse diffusion (refine). Notably, the generative\nperformance of the model remains intact -- downstream forecasters trained on\nsynthetic samples from TSDiff outperform forecasters that are trained on\nsamples from other state-of-the-art generative time series models, occasionally\neven outperforming models trained on real data (synthesize).\n","authors":["Marcel Kollovieh","Abdul Fatir Ansari","Michael Bohlke-Schneider","Jasper Zschiegner","Hao Wang","Yuyang Wang"],"pdf_url":"https://arxiv.org/pdf/2307.11494v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12579v1","updated":"2023-11-21T12:50:24Z","published":"2023-11-21T12:50:24Z","title":"Machine-Guided Discovery of a Real-World Rogue Wave Model","summary":"  Big data and large-scale machine learning have had a profound impact on\nscience and engineering, particularly in fields focused on forecasting and\nprediction. Yet, it is still not clear how we can use the superior pattern\nmatching abilities of machine learning models for scientific discovery. This is\nbecause the goals of machine learning and science are generally not aligned. In\naddition to being accurate, scientific theories must also be causally\nconsistent with the underlying physical process and allow for human analysis,\nreasoning, and manipulation to advance the field. In this paper, we present a\ncase study on discovering a new symbolic model for oceanic rogue waves from\ndata using causal analysis, deep learning, parsimony-guided model selection,\nand symbolic regression. We train an artificial neural network on causal\nfeatures from an extensive dataset of observations from wave buoys, while\nselecting for predictive performance and causal invariance. We apply symbolic\nregression to distill this black-box model into a mathematical equation that\nretains the neural network's predictive capabilities, while allowing for\ninterpretation in the context of existing wave theory. The resulting model\nreproduces known behavior, generates well-calibrated probabilities, and\nachieves better predictive scores on unseen data than current theory. This\nshowcases how machine learning can facilitate inductive scientific discovery,\nand paves the way for more accurate rogue wave forecasting.\n","authors":["Dion Häfner","Johannes Gemmrich","Markus Jochum"],"pdf_url":"https://arxiv.org/pdf/2311.12579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02081v2","updated":"2023-11-21T12:43:30Z","published":"2022-12-05T07:52:08Z","title":"YolOOD: Utilizing Object Detection Concepts for Multi-Label\n  Out-of-Distribution Detection","summary":"  Out-of-distribution (OOD) detection has attracted a large amount of attention\nfrom the machine learning research community in recent years due to its\nimportance in deployed systems. Most of the previous studies focused on the\ndetection of OOD samples in the multi-class classification task. However, OOD\ndetection in the multi-label classification task, a more common real-world use\ncase, remains an underexplored domain. In this research, we propose YolOOD - a\nmethod that utilizes concepts from the object detection domain to perform OOD\ndetection in the multi-label classification task. Object detection models have\nan inherent ability to distinguish between objects of interest\n(in-distribution) and irrelevant objects (e.g., OOD objects) in images that\ncontain multiple objects belonging to different class categories. These\nabilities allow us to convert a regular object detection model into an image\nclassifier with inherent OOD detection capabilities with just minor changes. We\ncompare our approach to state-of-the-art OOD detection methods and demonstrate\nYolOOD's ability to outperform these methods on a comprehensive suite of\nin-distribution and OOD benchmark datasets.\n","authors":["Alon Zolfi","Guy Amit","Amit Baras","Satoru Koda","Ikuya Morikawa","Yuval Elovici","Asaf Shabtai"],"pdf_url":"https://arxiv.org/pdf/2212.02081v2.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.12573v1","updated":"2023-11-21T12:38:05Z","published":"2023-11-21T12:38:05Z","title":"Moderating Model Marketplaces: Platform Governance Puzzles for AI\n  Intermediaries","summary":"  The AI development community is increasingly making use of hosting\nintermediaries such as Hugging Face provide easy access to user-uploaded models\nand training data. These model marketplaces lower technical deployment barriers\nfor hundreds of thousands of users, yet can be used in numerous potentially\nharmful and illegal ways. In this article, we explain ways in which AI systems,\nwhich can both `contain' content and be open-ended tools, present one of the\ntrickiest platform governance challenges seen to date. We provide case studies\nof several incidents across three illustrative platforms -- Hugging Face,\nGitHub and Civitai -- to examine how model marketplaces moderate models.\nBuilding on this analysis, we outline important (and yet nevertheless limited)\npractices that industry has been developing to respond to moderation demands:\nlicensing, access and use restrictions, automated content moderation, and open\npolicy development. While the policy challenge at hand is a considerable one,\nwe conclude with some ideas as to how platforms could better mobilize resources\nto act as a careful, fair, and proportionate regulatory access point.\n","authors":["Robert Gorwa","Michael Veale"],"pdf_url":"https://arxiv.org/pdf/2311.12573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08051v3","updated":"2023-11-21T12:36:49Z","published":"2023-10-12T05:52:54Z","title":"LGL-BCI: A Lightweight Geometric Learning Framework for Motor\n  Imagery-Based Brain-Computer Interfaces","summary":"  Brain-Computer Interfaces (BCIs) are a groundbreaking technology for\ninteracting with external devices using brain signals. Despite advancements,\nelectroencephalogram (EEG)-based Motor Imagery (MI) tasks face challenges like\namplitude and phase variability, and complex spatial correlations, with a need\nfor smaller model size and faster inference. This study introduces the LGL-BCI\nframework, employing a Geometric Deep Learning Framework for EEG processing in\nnon-Euclidean metric spaces, particularly the Symmetric Positive Definite (SPD)\nManifold space. LGL-BCI offers robust EEG data representation and captures\nspatial correlations. We propose an EEG channel selection solution via a\nfeature decomposition algorithm to reduce SPD matrix dimensionality, with a\nlossless transformation boosting inference speed. Extensive experiments show\nLGL-BCI's superior accuracy and efficiency compared to current solutions,\nhighlighting geometric deep learning's potential in MI-BCI applications. The\nefficiency, assessed on two public EEG datasets and two real-world EEG devices,\nsignificantly outperforms the state-of-the-art solution in accuracy ($82.54\\%$\nversus $62.22\\%$) with fewer parameters (64.9M compared to 183.7M).\n","authors":["Jianchao Lu","Yuzhe Tian","Yang Zhang","Jiaqi Ge","Quan Z. Sheng","Xi Zheng"],"pdf_url":"https://arxiv.org/pdf/2310.08051v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12570v1","updated":"2023-11-21T12:34:00Z","published":"2023-11-21T12:34:00Z","title":"BEND: Benchmarking DNA Language Models on biologically meaningful tasks","summary":"  The genome sequence contains the blueprint for governing cellular processes.\nWhile the availability of genomes has vastly increased over the last decades,\nexperimental annotation of the various functional, non-coding and regulatory\nelements encoded in the DNA sequence remains both expensive and challenging.\nThis has sparked interest in unsupervised language modeling of genomic DNA, a\nparadigm that has seen great success for protein sequence data. Although\nvarious DNA language models have been proposed, evaluation tasks often differ\nbetween individual works, and might not fully recapitulate the fundamental\nchallenges of genome annotation, including the length, scale and sparsity of\nthe data. In this study, we introduce BEND, a Benchmark for DNA language\nmodels, featuring a collection of realistic and biologically meaningful\ndownstream tasks defined on the human genome. We find that embeddings from\ncurrent DNA LMs can approach performance of expert methods on some tasks, but\nonly capture limited information about long-range features. BEND is available\nat https://github.com/frederikkemarin/BEND.\n","authors":["Frederikke Isa Marin","Felix Teufel","Marc Horrender","Dennis Madsen","Dennis Pultz","Ole Winther","Wouter Boomsma"],"pdf_url":"https://arxiv.org/pdf/2311.12570v1.pdf","comment":"10 pages, 1 figure, 3 tables, code available at\n  https://github.com/frederikkemarin/BEND"},{"id":"http://arxiv.org/abs/2311.12569v1","updated":"2023-11-21T12:32:38Z","published":"2023-11-21T12:32:38Z","title":"Differentiable Sampling of Categorical Distributions Using the\n  CatLog-Derivative Trick","summary":"  Categorical random variables can faithfully represent the discrete and\nuncertain aspects of data as part of a discrete latent variable model. Learning\nin such models necessitates taking gradients with respect to the parameters of\nthe categorical probability distributions, which is often intractable due to\ntheir combinatorial nature. A popular technique to estimate these otherwise\nintractable gradients is the Log-Derivative trick. This trick forms the basis\nof the well-known REINFORCE gradient estimator and its many extensions. While\nthe Log-Derivative trick allows us to differentiate through samples drawn from\ncategorical distributions, it does not take into account the discrete nature of\nthe distribution itself. Our first contribution addresses this shortcoming by\nintroducing the CatLog-Derivative trick - a variation of the Log-Derivative\ntrick tailored towards categorical distributions. Secondly, we use the\nCatLog-Derivative trick to introduce IndeCateR, a novel and unbiased gradient\nestimator for the important case of products of independent categorical\ndistributions with provably lower variance than REINFORCE. Thirdly, we\nempirically show that IndeCateR can be efficiently implemented and that its\ngradient estimates have significantly lower bias and variance for the same\nnumber of samples compared to the state of the art.\n","authors":["Lennert De Smet","Emanuele Sansone","Pedro Zuidberg Dos Martires"],"pdf_url":"https://arxiv.org/pdf/2311.12569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12566v1","updated":"2023-11-21T12:26:14Z","published":"2023-11-21T12:26:14Z","title":"Variational Elliptical Processes","summary":"  We present elliptical processes, a family of non-parametric probabilistic\nmodels that subsume Gaussian processes and Student's t processes. This\ngeneralization includes a range of new heavy-tailed behaviors while retaining\ncomputational tractability. Elliptical processes are based on a representation\nof elliptical distributions as a continuous mixture of Gaussian distributions.\nWe parameterize this mixture distribution as a spline normalizing flow, which\nwe train using variational inference. The proposed form of the variational\nposterior enables a sparse variational elliptical process applicable to\nlarge-scale problems. We highlight advantages compared to Gaussian processes\nthrough regression and classification experiments. Elliptical processes can\nsupersede Gaussian processes in several settings, including cases where the\nlikelihood is non-Gaussian or when accurate tail modeling is essential.\n","authors":["Maria Bånkestad","Jens Sjölund","Jalil Taghia","Thomas B. Schöon"],"pdf_url":"https://arxiv.org/pdf/2311.12566v1.pdf","comment":"14 pages, 15 figures, appendix 9 pages"},{"id":"http://arxiv.org/abs/2311.12564v1","updated":"2023-11-21T12:23:58Z","published":"2023-11-21T12:23:58Z","title":"Summary of the DISPLACE Challenge 2023 -- DIarization of SPeaker and\n  LAnguage in Conversational Environments","summary":"  In multi-lingual societies, where multiple languages are spoken in a small\ngeographic vicinity, informal conversations often involve mix of languages.\nExisting speech technologies may be inefficient in extracting information from\nsuch conversations, where the speech data is rich in diversity with multiple\nlanguages and speakers. The DISPLACE (DIarization of SPeaker and LAnguage in\nConversational Environments) challenge constitutes an open-call for evaluating\nand bench-marking the speaker and language diarization technologies on this\nchallenging condition. The challenge entailed two tracks: Track-1 focused on\nspeaker diarization (SD) in multilingual situations while, Track-2 addressed\nthe language diarization (LD) in a multi-speaker scenario. Both the tracks were\nevaluated using the same underlying audio data. To facilitate this evaluation,\na real-world dataset featuring multilingual, multi-speaker conversational\nfar-field speech was recorded and distributed. Furthermore, a baseline system\nwas made available for both SD and LD task which mimicked the state-of-art in\nthese tasks. The challenge garnered a total of $42$ world-wide registrations\nand received a total of $19$ combined submissions for Track-1 and Track-2. This\npaper describes the challenge, details of the datasets, tasks, and the baseline\nsystem. Additionally, the paper provides a concise overview of the submitted\nsystems in both tracks, with an emphasis given to the top performing systems.\nThe paper also presents insights and future perspectives for SD and LD tasks,\nfocusing on the key challenges that the systems need to overcome before\nwide-spread commercial deployment on such conversations.\n","authors":["Shikha Baghel","Shreyas Ramoji","Somil Jain","Pratik Roy Chowdhuri","Prachi Singh","Deepu Vijayasenan","Sriram Ganapathy"],"pdf_url":"https://arxiv.org/pdf/2311.12564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.09076v2","updated":"2023-11-21T12:23:27Z","published":"2021-10-18T07:55:39Z","title":"An actor-critic algorithm with policy gradients to solve the job shop\n  scheduling problem using deep double recurrent agents","summary":"  There is a growing interest in integrating machine learning techniques and\noptimization to solve challenging optimization problems. In this work, we\npropose a deep reinforcement learning methodology for the job shop scheduling\nproblem (JSSP). The aim is to build up a greedy-like heuristic able to learn on\nsome distribution of JSSP instances, different in the number of jobs and\nmachines. The need for fast scheduling methods is well known, and it arises in\nmany areas, from transportation to healthcare. We model the JSSP as a Markov\nDecision Process and then we exploit the efficacy of reinforcement learning to\nsolve the problem. We adopt an actor-critic scheme, where the action taken by\nthe agent is influenced by policy considerations on the state-value function.\nThe procedures are adapted to take into account the challenging nature of JSSP,\nwhere the state and the action space change not only for every instance but\nalso after each decision. To tackle the variability in the number of jobs and\noperations in the input, we modeled the agent using two incident LSTM models, a\nspecial type of deep neural network. Experiments show the algorithm reaches\ngood solutions in a short time, proving that is possible to generate new greedy\nheuristics just from learning-based methodologies. Benchmarks have been\ngenerated in comparison with the commercial solver CPLEX. As expected, the\nmodel can generalize, to some extent, to larger problems or instances\noriginated by a different distribution from the one used in training.\n","authors":["Marta Monaci","Valerio Agasucci","Giorgio Grani"],"pdf_url":"https://arxiv.org/pdf/2110.09076v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13193v2","updated":"2023-11-21T12:17:40Z","published":"2022-10-24T13:10:06Z","title":"Langevin dynamics based algorithm e-TH$\\varepsilon$O POULA for\n  stochastic optimization problems with discontinuous stochastic gradient","summary":"  We introduce a new Langevin dynamics based algorithm, called\ne-TH$\\varepsilon$O POULA, to solve optimization problems with discontinuous\nstochastic gradients which naturally appear in real-world applications such as\nquantile estimation, vector quantization, CVaR minimization, and regularized\noptimization problems involving ReLU neural networks. We demonstrate both\ntheoretically and numerically the applicability of the e-TH$\\varepsilon$O POULA\nalgorithm. More precisely, under the conditions that the stochastic gradient is\nlocally Lipschitz in average and satisfies a certain convexity at infinity\ncondition, we establish non-asymptotic error bounds for e-TH$\\varepsilon$O\nPOULA in Wasserstein distances and provide a non-asymptotic estimate for the\nexpected excess risk, which can be controlled to be arbitrarily small. Three\nkey applications in finance and insurance are provided, namely, multi-period\nportfolio optimization, transfer learning in multi-period portfolio\noptimization, and insurance claim prediction, which involve neural networks\nwith (Leaky)-ReLU activation functions. Numerical experiments conducted using\nreal-world datasets illustrate the superior empirical performance of\ne-TH$\\varepsilon$O POULA compared to SGLD, TUSLA, ADAM, and AMSGrad in terms of\nmodel accuracy.\n","authors":["Dong-Young Lim","Ariel Neufeld","Sotirios Sabanis","Ying Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.13193v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12561v1","updated":"2023-11-21T12:15:28Z","published":"2023-11-21T12:15:28Z","title":"Convolutional Neural Networks for Neuroimaging in Parkinson's Disease:\n  Is Preprocessing Needed?","summary":"  Spatial and intensity normalization are nowadays a prerequisite for\nneuroimaging analysis. Influenced by voxel-wise and other univariate\ncomparisons, where these corrections are key, they are commonly applied to any\ntype of analysis and imaging modalities. Nuclear imaging modalities such as\nPET-FDG or FP-CIT SPECT, a common modality used in Parkinson's Disease\ndiagnosis, are especially dependent on intensity normalization. However, these\nsteps are computationally expensive and furthermore, they may introduce\ndeformations in the images, altering the information contained in them.\nConvolutional Neural Networks (CNNs), for their part, introduce position\ninvariance to pattern recognition, and have been proven to classify objects\nregardless of their orientation, size, angle, etc. Therefore, a question\narises: how well can CNNs account for spatial and intensity differences when\nanalysing nuclear brain imaging? Are spatial and intensity normalization still\nneeded? To answer this question, we have trained four different CNN models\nbased on well-established architectures, using or not different spatial and\nintensity normalization preprocessing. The results show that a sufficiently\ncomplex model such as our three-dimensional version of the ALEXNET can\neffectively account for spatial differences, achieving a diagnosis accuracy of\n94.1% with an area under the ROC curve of 0.984. The visualization of the\ndifferences via saliency maps shows that these models are correctly finding\npatterns that match those found in the literature, without the need of applying\nany complex spatial normalization procedure. However, the intensity\nnormalization -- and its type -- is revealed as very influential in the results\nand accuracy of the trained model, and therefore must be well accounted.\n","authors":["Francisco J. Martinez-Murcia","Juan M. Górriz","Javier Ramírez","Andrés Ortiz"],"pdf_url":"https://arxiv.org/pdf/2311.12561v1.pdf","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.12550v1","updated":"2023-11-21T11:59:16Z","published":"2023-11-21T11:59:16Z","title":"Explainable Anomaly Detection using Masked Latent Generative Modeling","summary":"  We present a novel time series anomaly detection method that achieves\nexcellent detection accuracy while offering a superior level of explainability.\nOur proposed method, TimeVQVAE-AD, leverages masked generative modeling adapted\nfrom the cutting-edge time series generation method known as TimeVQVAE. The\nprior model is trained on the discrete latent space of a time-frequency domain.\nNotably, the dimensional semantics of the time-frequency domain are preserved\nin the latent space, enabling us to compute anomaly scores across different\nfrequency bands, which provides a better insight into the detected anomalies.\nAdditionally, the generative nature of the prior model allows for sampling\nlikely normal states for detected anomalies, enhancing the explainability of\nthe detected anomalies through counterfactuals. Our experimental evaluation on\nthe UCR Time Series Anomaly archive demonstrates that TimeVQVAE-AD\nsignificantly surpasses the existing methods in terms of detection accuracy and\nexplainability.\n","authors":["Daesoo Lee","Sara Malacarne","Erlend Aune"],"pdf_url":"https://arxiv.org/pdf/2311.12550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12538v1","updated":"2023-11-21T11:33:03Z","published":"2023-11-21T11:33:03Z","title":"In-Context Learning Functions with Varying Number of Minima","summary":"  Large Language Models (LLMs) have proven effective at In-Context Learning\n(ICL), an ability that allows them to create predictors from labeled examples.\nFew studies have explored the interplay between ICL and specific properties of\nfunctions it attempts to approximate. In our study, we use a formal framework\nto explore ICL and propose a new task of approximating functions with varying\nnumber of minima. We implement a method that allows for producing functions\nwith given inputs as minima. We find that increasing the number of minima\ndegrades ICL performance. At the same time, our evaluation shows that ICL\noutperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster\nthan 2NN in all settings. We validate the findings through a set of few-shot\nexperiments across various hyperparameter configurations.\n","authors":["David Oniani","Yanshan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11899v3","updated":"2023-11-21T11:24:29Z","published":"2023-01-27T18:23:10Z","title":"Is TinyML Sustainable? Assessing the Environmental Impacts of Machine\n  Learning on Microcontrollers","summary":"  The sustained growth of carbon emissions and global waste elicits significant\nsustainability concerns for our environment's future. The growing Internet of\nThings (IoT) has the potential to exacerbate this issue. However, an emerging\narea known as Tiny Machine Learning (TinyML) has the opportunity to help\naddress these environmental challenges through sustainable computing practices.\nTinyML, the deployment of machine learning (ML) algorithms onto low-cost,\nlow-power microcontroller systems, enables on-device sensor analytics that\nunlocks numerous always-on ML applications. This article discusses both the\npotential of these TinyML applications to address critical sustainability\nchallenges, as well as the environmental footprint of this emerging technology.\nThrough a complete life cycle analysis (LCA), we find that TinyML systems\npresent opportunities to offset their carbon emissions by enabling applications\nthat reduce the emissions of other sectors. Nevertheless, when globally scaled,\nthe carbon footprint of TinyML systems is not negligible, necessitating that\ndesigners factor in environmental impact when formulating new devices. Finally,\nwe outline research directions to enable further sustainable contributions of\nTinyML.\n","authors":["Shvetank Prakash","Matthew Stewart","Colby Banbury","Mark Mazumder","Pete Warden","Brian Plancher","Vijay Janapa Reddi"],"pdf_url":"https://arxiv.org/pdf/2301.11899v3.pdf","comment":"Communications of the ACM (CACM) November 2023 Issue"},{"id":"http://arxiv.org/abs/2311.12530v1","updated":"2023-11-21T11:21:53Z","published":"2023-11-21T11:21:53Z","title":"An efficient likelihood-free Bayesian inference method based on\n  sequential neural posterior estimation","summary":"  Sequential neural posterior estimation (SNPE) techniques have been recently\nproposed for dealing with simulation-based models with intractable likelihoods.\nUnlike approximate Bayesian computation, SNPE techniques learn the posterior\nfrom sequential simulation using neural network-based conditional density\nestimators. This paper reclaims SNPE-B proposed by Lueckmann et al. (2017),\nwhich suffers from inefficiency and slow inference due to inefficient\nutilization of simulated data and high variance of parameter updates. To\naddress these issues, we firstly introduce a concentrated loss function based\non an adaptive calibration kernel that reweights the simulated data\nappropriately to improve the data efficiency. Moreover, we provide a\ntheoretical analysis of the variance of associated Monte Carlo estimators.\nBased on this analysis, we then propose several variance reduction techniques\nto further accelerate the process of learning. Numerical experiments\ndemonstrate that our method outperforms the original method together with other\nexisting competitors on certain tasks.\n","authors":["Yifei Xiong","Xiliang Yang","Sanguo Zhang","Zhijian He"],"pdf_url":"https://arxiv.org/pdf/2311.12530v1.pdf","comment":"29 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.12528v1","updated":"2023-11-21T11:15:14Z","published":"2023-11-21T11:15:14Z","title":"Inverse Problems with Learned Forward Operators","summary":"  Solving inverse problems requires knowledge of the forward operator, but\naccurate models can be computationally expensive and hence cheaper variants are\ndesired that do not compromise reconstruction quality. This chapter reviews\nreconstruction methods in inverse problems with learned forward operators that\nfollow two different paradigms. The first one is completely agnostic to the\nforward operator and learns its restriction to the subspace spanned by the\ntraining data. The framework of regularisation by projection is then used to\nfind a reconstruction. The second one uses a simplified model of the physics of\nthe measurement process and only relies on the training data to learn a model\ncorrection. We present the theory of these two approaches and compare them\nnumerically. A common theme emerges: both methods require, or at least benefit\nfrom, training data not only for the forward operator, but also for its\nadjoint.\n","authors":["Simon Arridge","Andreas Hauptmann","Yury Korolev"],"pdf_url":"https://arxiv.org/pdf/2311.12528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12526v1","updated":"2023-11-21T11:12:03Z","published":"2023-11-21T11:12:03Z","title":"Neural Network Pruning by Gradient Descent","summary":"  The rapid increase in the parameters of deep learning models has led to\nsignificant costs, challenging computational efficiency and model\ninterpretability. In this paper, we introduce a novel and straightforward\nneural network pruning framework that incorporates the Gumbel-Softmax\ntechnique. This framework enables the simultaneous optimization of a network's\nweights and topology in an end-to-end process using stochastic gradient\ndescent. Empirical results demonstrate its exceptional compression capability,\nmaintaining high accuracy on the MNIST dataset with only 0.15\\% of the original\nnetwork parameters. Moreover, our framework enhances neural network\ninterpretability, not only by allowing easy extraction of feature importance\ndirectly from the pruned network but also by enabling visualization of feature\nsymmetry and the pathways of information propagation from features to outcomes.\nAlthough the pruning strategy is learned through deep learning, it is\nsurprisingly intuitive and understandable, focusing on selecting key\nrepresentative features and exploiting data patterns to achieve extreme sparse\npruning. We believe our method opens a promising new avenue for deep learning\npruning and the creation of interpretable machine learning systems.\n","authors":["Zhang Zhang","Ruyi Tao","Jiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12526v1.pdf","comment":"21 pages, 5 figures"},{"id":"http://arxiv.org/abs/2309.06255v2","updated":"2023-11-21T11:11:57Z","published":"2023-09-12T14:16:34Z","title":"Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation","summary":"  One primary topic of multi-modal learning is to jointly incorporate\nheterogeneous information from different modalities. However, most models often\nsuffer from unsatisfactory multi-modal cooperation, which could not jointly\nutilize all modalities well. Some methods are proposed to identify and enhance\nthe worse learnt modality, but are often hard to provide the fine-grained\nobservation of multi-modal cooperation at sample-level with theoretical\nsupport. Hence, it is essential to reasonably observe and improve the\nfine-grained cooperation between modalities, especially when facing realistic\nscenarios where the modality discrepancy could vary across different samples.\nTo this end, we introduce a fine-grained modality valuation metric to evaluate\nthe contribution of each modality at sample-level. Via modality valuation, we\nregretfully observe that the multi-modal model tends to rely on one specific\nmodality, resulting in other modalities being low-contributing. We further\nanalyze this issue and improve cooperation between modalities by enhancing the\ndiscriminative ability of low-contributing modalities in a targeted manner.\nOverall, our methods reasonably observe the fine-grained uni-modal contribution\nat sample-level and achieve considerable improvement on different multi-modal\nmodels.\n","authors":["Yake Wei","Ruoxuan Feng","Zihe Wang","Di Hu"],"pdf_url":"https://arxiv.org/pdf/2309.06255v2.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2311.12524v1","updated":"2023-11-21T11:09:57Z","published":"2023-11-21T11:09:57Z","title":"ALPHA: AnomaLous Physiological Health Assessment Using Large Language\n  Models","summary":"  This study concentrates on evaluating the efficacy of Large Language Models\n(LLMs) in healthcare, with a specific focus on their application in personal\nanomalous health monitoring. Our research primarily investigates the\ncapabilities of LLMs in interpreting and analyzing physiological data obtained\nfrom FDA-approved devices. We conducted an extensive analysis using anomalous\nphysiological data gathered in a simulated low-air-pressure plateau\nenvironment. This allowed us to assess the precision and reliability of LLMs in\nunderstanding and evaluating users' health status with notable specificity. Our\nfindings reveal that LLMs exhibit exceptional performance in determining\nmedical indicators, including a Mean Absolute Error (MAE) of less than 1 beat\nper minute for heart rate and less than 1% for oxygen saturation (SpO2).\nFurthermore, the Mean Absolute Percentage Error (MAPE) for these evaluations\nremained below 1%, with the overall accuracy of health assessments surpassing\n85%. In image analysis tasks, such as interpreting photoplethysmography (PPG)\ndata, our specially adapted GPT models demonstrated remarkable proficiency,\nachieving less than 1 bpm error in cycle count and 7.28 MAE for heart rate\nestimation. This study highlights LLMs' dual role as health data analysis tools\nand pivotal elements in advanced AI health assistants, offering personalized\nhealth insights and recommendations within the future health assistant\nframework.\n","authors":["Jiankai Tang","Kegang Wang","Hongming Hu","Xiyuxing Zhang","Peiyu Wang","Xin Liu","Yuntao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12524v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.05587v2","updated":"2023-11-21T10:38:16Z","published":"2023-11-09T18:47:33Z","title":"Bayesian Methods for Media Mix Modelling with shape and funnel effects","summary":"  In recent years, significant progress in generative AI has highlighted the\nimportant role of physics-inspired models that utilize advanced mathematical\nconcepts based on fundamental physics principles to enhance artificial\nintelligence capabilities. Among these models, those based on diffusion\nequations have greatly improved image quality. This study aims to explore the\npotential uses of Maxwell-Boltzmann equation, which forms the basis of the\nkinetic theory of gases, and the Michaelis-Menten model in Marketing Mix\nModelling (MMM) applications. We propose incorporating these equations into\nHierarchical Bayesian models to analyse consumer behaviour in the context of\nadvertising. These equation sets excel in accurately describing the random\ndynamics in complex systems like social interactions and consumer-advertising\ninteractions.\n","authors":["Javier Marin"],"pdf_url":"https://arxiv.org/pdf/2311.05587v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12501v1","updated":"2023-11-21T10:20:34Z","published":"2023-11-21T10:20:34Z","title":"Fair Polylog-Approximate Low-Cost Hierarchical Clustering","summary":"  Research in fair machine learning, and particularly clustering, has been\ncrucial in recent years given the many ethical controversies that modern\nintelligent systems have posed. Ahmadian et al. [2020] established the study of\nfairness in \\textit{hierarchical} clustering, a stronger, more structured\nvariant of its well-known flat counterpart, though their proposed algorithm\nthat optimizes for Dasgupta's [2016] famous cost function was highly\ntheoretical. Knittel et al. [2023] then proposed the first practical fair\napproximation for cost, however they were unable to break the\npolynomial-approximate barrier they posed as a hurdle of interest. We break\nthis barrier, proposing the first truly polylogarithmic-approximate low-cost\nfair hierarchical clustering, thus greatly bridging the gap between the best\nfair and vanilla hierarchical clustering approximations.\n","authors":["Marina Knittel","Max Springer","John Dickerson","MohammadTaghi Hajiaghayi"],"pdf_url":"https://arxiv.org/pdf/2311.12501v1.pdf","comment":"Accepted to NeurIPS '23 (16 pages, 5 figures)"},{"id":"http://arxiv.org/abs/2311.12495v1","updated":"2023-11-21T10:11:19Z","published":"2023-11-21T10:11:19Z","title":"Multi-Objective Reinforcement Learning based on Decomposition: A\n  taxonomy and framework","summary":"  Multi-objective reinforcement learning (MORL) extends traditional RL by\nseeking policies making different compromises among conflicting objectives. The\nrecent surge of interest in MORL has led to diverse studies and solving\nmethods, often drawing from existing knowledge in multi-objective optimization\nbased on decomposition (MOO/D). Yet, a clear categorization based on both RL\nand MOO/D is lacking in the existing literature. Consequently, MORL researchers\nface difficulties when trying to classify contributions within a broader\ncontext due to the absence of a standardized taxonomy. To tackle such an issue,\nthis paper introduces Multi-Objective Reinforcement Learning based on\nDecomposition (MORL/D), a novel methodology bridging RL and MOO literature. A\ncomprehensive taxonomy for MORL/D is presented, providing a structured\nfoundation for categorizing existing and potential MORL works. The introduced\ntaxonomy is then used to scrutinize MORL research, enhancing clarity and\nconciseness through well-defined categorization. Moreover, a flexible framework\nderived from the taxonomy is introduced. This framework accommodates diverse\ninstantiations using tools from both RL and MOO/D. Implementation across\nvarious configurations demonstrates its versatility, assessed against benchmark\nproblems. Results indicate MORL/D instantiations achieve comparable performance\nwith significantly greater versatility than current state-of-the-art\napproaches. By presenting the taxonomy and framework, this paper offers a\ncomprehensive perspective and a unified vocabulary for MORL. This not only\nfacilitates the identification of algorithmic contributions but also lays the\ngroundwork for novel research avenues in MORL, contributing to the continued\nadvancement of this field.\n","authors":["Florian Felten","El-Ghazali Talbi","Grégoire Danoy"],"pdf_url":"https://arxiv.org/pdf/2311.12495v1.pdf","comment":"Under review at JAIR"},{"id":"http://arxiv.org/abs/2311.12491v1","updated":"2023-11-21T10:05:32Z","published":"2023-11-21T10:05:32Z","title":"Heuristics for Detecting CoinJoin Transactions on the Bitcoin Blockchain","summary":"  This research delves into the intricacies of Bitcoin, a decentralized\npeer-to-peer network, and its associated blockchain, which records all\ntransactions since its inception. While this ensures integrity and\ntransparency, the transparent nature of Bitcoin potentially compromises users'\nprivacy rights. To address this concern, users have adopted CoinJoin, a method\nthat amalgamates multiple transaction intents into a single, larger transaction\nto bolster transactional privacy. This process complicates individual\ntransaction tracing and disrupts many established blockchain analysis\nheuristics. Despite its significance, limited research has been conducted on\nidentifying CoinJoin transactions. Particularly noteworthy are varied CoinJoin\nimplementations such as JoinMarket, Wasabi, and Whirlpool, each presenting\ndistinct challenges due to their unique transaction structures. This study\ndelves deeply into the open-source implementations of these protocols, aiming\nto develop refined heuristics for identifying their transactions on the\nblockchain. Our exhaustive analysis covers transactions up to block 760,000,\noffering a comprehensive insight into CoinJoin transactions and their\nimplications for Bitcoin blockchain analysis.\n","authors":["Hugo Schnoering","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2311.12491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.05879v2","updated":"2023-11-21T10:04:37Z","published":"2021-08-12T17:53:47Z","title":"Feature Engineering with Regularity Structures","summary":"  We investigate the use of models from the theory of regularity structures as\nfeatures in machine learning tasks. A model is a polynomial function of a\nspace-time signal designed to well-approximate solutions to partial\ndifferential equations (PDEs), even in low regularity regimes. Models can be\nseen as natural multi-dimensional generalisations of signatures of paths; our\nwork therefore aims to extend the recent use of signatures in data science\nbeyond the context of time-ordered data. We provide a flexible definition of a\nmodel feature vector associated to a space-time signal, along with two\nalgorithms which illustrate ways in which these features can be combined with\nlinear regression. We apply these algorithms in several numerical experiments\ndesigned to learn solutions to PDEs with a given forcing and boundary data. Our\nexperiments include semi-linear parabolic and wave equations with forcing, and\nBurgers' equation with no forcing. We find an advantage in favour of our\nalgorithms when compared to several alternative methods. Additionally, in the\nexperiment with Burgers' equation, we find non-trivial predictive power when\nnoise is added to the observations.\n","authors":["Ilya Chevyrev","Andris Gerasimovics","Hendrik Weber"],"pdf_url":"https://arxiv.org/pdf/2108.05879v2.pdf","comment":"33 pages, 7 figures, 7 tables. Improved presentation of model feature\n  vector (Section 2) and experiments (Section 3). Added new experiment in 2D\n  spatial domain (Section 3.1.2). To appear in Journal of Scientific Computing"},{"id":"http://arxiv.org/abs/2311.12490v1","updated":"2023-11-21T10:01:08Z","published":"2023-11-21T10:01:08Z","title":"Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields","summary":"  Recent advances in Neural radiance fields (NeRF) have enabled high-fidelity\nscene reconstruction for novel view synthesis. However, NeRF requires hundreds\nof network evaluations per pixel to approximate a volume rendering integral,\nmaking it slow to train. Caching NeRFs into explicit data structures can\neffectively enhance rendering speed but at the cost of higher memory usage. To\naddress these issues, we present Hyb-NeRF, a novel neural radiance field with a\nmulti-resolution hybrid encoding that achieves efficient neural modeling and\nfast rendering, which also allows for high-quality novel view synthesis. The\nkey idea of Hyb-NeRF is to represent the scene using different encoding\nstrategies from coarse-to-fine resolution levels. Hyb-NeRF exploits\nmemory-efficiency learnable positional features at coarse resolutions and the\nfast optimization speed and local details of hash-based feature grids at fine\nresolutions. In addition, to further boost performance, we embed cone\ntracing-based features in our learnable positional encoding that eliminates\nencoding ambiguity and reduces aliasing artifacts. Extensive experiments on\nboth synthetic and real-world datasets show that Hyb-NeRF achieves faster\nrendering speed with better rending quality and even a lower memory footprint\nin comparison to previous state-of-the-art methods.\n","authors":["Yifan Wang","Yi Gong","Yuan Zeng"],"pdf_url":"https://arxiv.org/pdf/2311.12490v1.pdf","comment":"WACV2024"},{"id":"http://arxiv.org/abs/2205.02645v3","updated":"2023-11-21T09:48:28Z","published":"2022-05-05T13:44:24Z","title":"PyDaddy: A Python package for discovering stochastic dynamical equations\n  from timeseries data","summary":"  Stochastic differential equations (SDEs) are an important framework to model\ndynamics with randomness, as is common in most biological systems. The inverse\nproblem of integrating these models with empirical data remains a major\nchallenge. Here, we present a software package, PyDaDDy (Python Library for\nData Driven Dynamics) that takes time series data as an input and outputs an\ninterpretable SDE. We achieve this by combining traditional approaches from\nstochastic calculus literature with state-of-the-art equation discovery\ntechniques. We validate our approach on synthetic datasets, and demonstrate the\ngenerality and applicability of the method on two real-world datasets of vastly\ndifferent spatiotemporal scales: (i) collective movement of fish school where\nstochasticity plays a crucial role, and (ii) confined migration of a single\ncell, primarily following a relaxed oscillation. We make the method available\nas an easy-to-use, open-source Python package, PyDaddy (Python Library for Data\nDriven Dynamics).\n","authors":["Arshed Nabeel","Ashwin Karichannavar","Shuaib Palathingal","Jitesh Jhawar","David B. Brückner","Danny Raj M.","Vishwesha Guttal"],"pdf_url":"https://arxiv.org/pdf/2205.02645v3.pdf","comment":"15 pages (+ 9 page appendix), 6 figures (+ 8 appendix figures)"},{"id":"http://arxiv.org/abs/2211.15513v2","updated":"2023-11-21T09:42:12Z","published":"2022-11-25T09:41:07Z","title":"Composite Score for Anomaly Detection in Imbalanced Real-World\n  Industrial Dataset","summary":"  In recent years, the industrial sector has evolved towards its fourth\nrevolution. The quality control domain is particularly interested in advanced\nmachine learning for computer vision anomaly detection. Nevertheless, several\nchallenges have to be faced, including imbalanced datasets, the image\ncomplexity, and the zero-false-negative (ZFN) constraint to guarantee the\nhigh-quality requirement. This paper illustrates a use case for an industrial\npartner, where Printed Circuit Board Assembly (PCBA) images are first\nreconstructed with a Vector Quantized Generative Adversarial Network (VQGAN)\ntrained on normal products. Then, several multi-level metrics are extracted on\na few normal and abnormal images, highlighting anomalies through reconstruction\ndifferences. Finally, a classifer is trained to build a composite anomaly score\nthanks to the metrics extracted. This three-step approach is performed on the\npublic MVTec-AD datasets and on the partner PCBA dataset, where it achieves a\nregular accuracy of 95.69% and 87.93% under the ZFN constraint.\n","authors":["Arnaud Bougaham","Mohammed El Adoui","Isabelle Linden","Benoît Frénay"],"pdf_url":"https://arxiv.org/pdf/2211.15513v2.pdf","comment":"This version of the article has been accepted for publication, after\n  peer review and is subject to Springer Nature AM terms of use, but is not the\n  Version of Record and does not reflect post-acceptance improvements, or any\n  corrections. The Version of Record is available online at:\n  https://doi.org/10.1007/s10994-023-06415-9"},{"id":"http://arxiv.org/abs/2311.12476v1","updated":"2023-11-21T09:37:49Z","published":"2023-11-21T09:37:49Z","title":"MaskFlow: Object-Aware Motion Estimation","summary":"  We introduce a novel motion estimation method, MaskFlow, that is capable of\nestimating accurate motion fields, even in very challenging cases with small\nobjects, large displacements and drastic appearance changes. In addition to\nlower-level features, that are used in other Deep Neural Network (DNN)-based\nmotion estimation methods, MaskFlow draws from object-level features and\nsegmentations. These features and segmentations are used to approximate the\nobjects' translation motion field. We propose a novel and effective way of\nincorporating the incomplete translation motion field into a subsequent motion\nestimation network for refinement and completion. We also produced a new\nchallenging synthetic dataset with motion field ground truth, and also provide\nextra ground truth for the object-instance matchings and corresponding\nsegmentation masks. We demonstrate that MaskFlow outperforms state of the art\nmethods when evaluated on our new challenging dataset, whilst still producing\ncomparable results on the popular FlyingThings3D benchmark dataset.\n","authors":["Aria Ahmadi","David R. Walton","Tim Atherton","Cagatay Dikici"],"pdf_url":"https://arxiv.org/pdf/2311.12476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.00018v2","updated":"2023-11-21T09:22:28Z","published":"2023-08-31T07:53:02Z","title":"Unsupervised discovery of Interpretable Visual Concepts","summary":"  Providing interpretability of deep-learning models to non-experts, while\nfundamental for a responsible real-world usage, is challenging. Attribution\nmaps from xAI techniques, such as Integrated Gradients, are a typical example\nof a visualization technique containing a high level of information, but with\ndifficult interpretation. In this paper, we propose two methods, Maximum\nActivation Groups Extraction (MAGE) and Multiscale Interpretable Visualization\n(Ms-IV), to explain the model's decision, enhancing global interpretability.\nMAGE finds, for a given CNN, combinations of features which, globally, form a\nsemantic meaning, that we call concepts. We group these similar feature\npatterns by clustering in ``concepts'', that we visualize through Ms-IV. This\nlast method is inspired by Occlusion and Sensitivity analysis (incorporating\ncausality), and uses a novel metric, called Class-aware Order Correlation\n(CaOC), to globally evaluate the most important image regions according to the\nmodel's decision space. We compare our approach to xAI methods such as LIME and\nIntegrated Gradients. Experimental results evince the Ms-IV higher localization\nand faithfulness values. Finally, qualitative evaluation of combined MAGE and\nMs-IV demonstrates humans' ability to agree, based on the visualization, with\nthe decision of clusters' concepts; and, to detect, among a given set of\nnetworks, the existence of bias.\n","authors":["Caroline Mazini Rodrigues","Nicolas Boutry","Laurent Najman"],"pdf_url":"https://arxiv.org/pdf/2309.00018v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06617v3","updated":"2023-11-21T09:20:33Z","published":"2022-11-12T09:41:02Z","title":"Empirical Risk Minimization with Relative Entropy Regularization","summary":"  The empirical risk minimization (ERM) problem with relative entropy\nregularization (ERM-RER) is investigated under the assumption that the\nreference measure is a {\\sigma}-finite measure, and not necessarily a\nprobability measure. Under this assumption, which leads to a generalization of\nthe ERM-RER problem allowing a larger degree of flexibility for incorporating\nprior knowledge, numerous relevant properties are stated. Among these\nproperties, the solution to this problem, if it exists, is shown to be a unique\nprobability measure, often mutually absolutely continuous with the reference\nmeasure. Such a solution exhibits a probably-approximately-correct guarantee\nfor the ERM problem independently of whether the latter possesses a solution.\nFor a fixed dataset, the empirical risk is shown to be a sub-Gaussian random\nvariable when the models are sampled from the solution to the ERM-RER problem.\nThe generalization capabilities of the solution to the ERM-RER problem (the\nGibbs algorithm) are studied via the sensitivity of the expected empirical risk\nto deviations from such a solution towards alternative probability measures.\nFinally, an interesting connection between sensitivity, generalization error,\nand lautum information is established\n","authors":["Samir M. Perlaza","Gaetan Bisson","Iñaki Esnaola","Alain Jean-Marie","Stefano Rini"],"pdf_url":"https://arxiv.org/pdf/2211.06617v3.pdf","comment":"Submitted to the the Transactions on Information Theory on June 12,\n  2023. Also available as: Research Report, INRIA, No. RR-9454, Centre Inria\n  d'Universit\\'e C\\^ote d'Azur, Sophia Antipolis, France, Feb., 2022 This\n  version contains the revision for Transactions on Information Theory on\n  November 21, 2023"},{"id":"http://arxiv.org/abs/2310.20567v2","updated":"2023-11-21T09:19:06Z","published":"2023-10-31T15:56:17Z","title":"One-shot backpropagation for multi-step prediction in physics-based\n  system identification -- EXTENDED VERSION","summary":"  The aim of this paper is to present a novel physics-based framework for the\nidentification of dynamical systems, in which the physical and structural\ninsights are reflected directly into a backpropagation-based learning\nalgorithm. The main result is a method to compute in closed form the gradient\nof a multi-step loss function, while enforcing physical properties and\nconstraints. The derived algorithm has been exploited to identify the unknown\ninertia matrix of a space debris, and the results show the reliability of the\nmethod in capturing the physical adherence of the estimated parameters.\n","authors":["Cesare Donati","Martina Mammarella","Fabrizio Dabbene","Carlo Novara","Constantino Lagoa"],"pdf_url":"https://arxiv.org/pdf/2310.20567v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18168v3","updated":"2023-11-21T09:19:03Z","published":"2023-10-27T14:27:43Z","title":"Personas as a Way to Model Truthfulness in Language Models","summary":"  Large Language Models (LLMs) are trained on vast amounts of text from the\ninternet, which contains both factual and misleading information about the\nworld. Can language models discern truth from falsehood in this contradicting\ndata? Expanding on the view that LLMs can model different communicative agents,\nwe present the persona hypothesis: LLMs can cluster agents into personas using\ncommon features of their generations. For instance, a truthful persona is a\ngroup of agents that are likely to produce truthful text and that share similar\nfeatures like formal writing styles and scientific references. By modeling this\npersona, LLMs can generalize truthfulness beyond the specific contexts in which\neach agent generated the training text. For example, the model can infer that\nthe agent ``Wikipedia'' will behave truthfully on topics that were only\ngenerated by ``Science'' because they both belong to the truthful persona. We\nshow evidence for the persona hypothesis via two observations: (1) we can probe\nwhether a model's answer will be truthful before it is generated; (2)\nfinetuning a model on a set of facts improves its truthfulness on unseen\ntopics. Next, using arithmetics as a synthetic environment, we show that\nlanguage models can separate true and false statements, and generalize\ntruthfulness across agents; but only if agents in the training data share a\ntruthful generative process that enables the creation of a truthful persona.\nOverall, our findings suggest that models can exploit hierarchical structures\nin the data to learn abstract concepts like truthfulness.\n","authors":["Nitish Joshi","Javier Rando","Abulhair Saparov","Najoung Kim","He He"],"pdf_url":"https://arxiv.org/pdf/2310.18168v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18183v2","updated":"2023-11-21T09:11:38Z","published":"2023-05-29T16:20:23Z","title":"On Counterfactual Data Augmentation Under Confounding","summary":"  Counterfactual data augmentation has recently emerged as a method to mitigate\nconfounding biases in the training data. These biases, such as spurious\ncorrelations, arise due to various observed and unobserved confounding\nvariables in the data generation process. In this paper, we formally analyze\nhow confounding biases impact downstream classifiers and present a causal\nviewpoint to the solutions based on counterfactual data augmentation. We\nexplore how removing confounding biases serves as a means to learn invariant\nfeatures, ultimately aiding in generalization beyond the observed data\ndistribution. Additionally, we present a straightforward yet powerful algorithm\nfor generating counterfactual images, which effectively mitigates the influence\nof confounding effects on downstream classifiers. Through experiments on MNIST\nvariants and the CelebA datasets, we demonstrate how our simple augmentation\nmethod helps existing state-of-the-art methods achieve good results.\n","authors":["Abbavaram Gowtham Reddy","Saketh Bachu","Saloni Dash","Charchit Sharma","Amit Sharma","Vineeth N Balasubramanian"],"pdf_url":"https://arxiv.org/pdf/2305.18183v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01959v2","updated":"2023-11-21T09:01:17Z","published":"2023-10-03T11:10:21Z","title":"Beyond Labeling Oracles: What does it mean to steal ML models?","summary":"  Model extraction attacks are designed to steal trained models with only query\naccess, as is often provided through APIs that ML-as-a-Service providers offer.\nML models are expensive to train, in part because data is hard to obtain, and a\nprimary incentive for model extraction is to acquire a model while incurring\nless cost than training from scratch. Literature on model extraction commonly\nclaims or presumes that the attacker is able to save on both data acquisition\nand labeling costs. We show that the attacker often does not. This is because\ncurrent attacks implicitly rely on the adversary being able to sample from the\nvictim model's data distribution. We thoroughly evaluate factors influencing\nthe success of model extraction. We discover that prior knowledge of the\nattacker, i.e. access to in-distribution data, dominates other factors like the\nattack policy the adversary follows to choose which queries to make to the\nvictim model API. Thus, an adversary looking to develop an equally capable\nmodel with a fixed budget has little practical incentive to perform model\nextraction, since for the attack to work they need to collect in-distribution\ndata, saving only on the cost of labeling. With low labeling costs in the\ncurrent market, the usefulness of such attacks is questionable. Ultimately, we\ndemonstrate that the effect of prior knowledge needs to be explicitly decoupled\nfrom the attack policy. To this end, we propose a benchmark to evaluate attack\npolicy directly.\n","authors":["Avital Shafran","Ilia Shumailov","Murat A. Erdogdu","Nicolas Papernot"],"pdf_url":"https://arxiv.org/pdf/2310.01959v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12439v1","updated":"2023-11-21T08:51:58Z","published":"2023-11-21T08:51:58Z","title":"Harnessing FPGA Technology for Enhanced Biomedical Computation","summary":"  This research delves into sophisticated neural network frameworks like\nConvolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long\nShort-Term Memory Networks (LSTMs), and Deep Belief Networks (DBNs) for\nimproved analysis of ECG signals via Field Programmable Gate Arrays (FPGAs).\nThe MIT-BIH Arrhythmia Database serves as the foundation for training and\nevaluating our models, with added Gaussian noise to heighten the algorithms'\nresilience. The developed architectures incorporate various layers for specific\nprocessing and categorization functions, employing strategies such as the\nEarlyStopping callback and Dropout layer to prevent overfitting. Additionally,\nthis paper details the creation of a tailored Tensor Compute Unit (TCU)\naccelerator for the PYNQ Z1 platform. It provides a thorough methodology for\nimplementing FPGA-based machine learning, encompassing the configuration of the\nTensil toolchain in Docker, selection of architectures, PS-PL configuration,\nand the compilation and deployment of models. By evaluating performance\nindicators like latency and throughput, we showcase the efficacy of FPGAs in\nadvanced biomedical computing. This study ultimately serves as a comprehensive\nguide to optimizing neural network operations on FPGAs across various fields.\n","authors":["Nisanur Alici","Kayode Inadagbo","Murat Isik"],"pdf_url":"https://arxiv.org/pdf/2311.12439v1.pdf","comment":"Submitted to IEEE Transactions on Biomedical Circuits and Systems.\n  arXiv admin note: substantial text overlap with arXiv:2307.07914"},{"id":"http://arxiv.org/abs/2310.08897v2","updated":"2023-11-21T08:51:03Z","published":"2023-10-13T06:58:52Z","title":"Self supervised convolutional kernel based handcrafted feature\n  harmonization: Enhanced left ventricle hypertension disease phenotyping on\n  echocardiography","summary":"  Radiomics, a medical imaging technique, extracts quantitative handcrafted\nfeatures from images to predict diseases. Harmonization in those features\nensures consistent feature extraction across various imaging devices and\nprotocols. Methods for harmonization include standardized imaging protocols,\nstatistical adjustments, and evaluating feature robustness. Myocardial diseases\nsuch as Left Ventricular Hypertrophy (LVH) and Hypertensive Heart Disease (HHD)\nare diagnosed via echocardiography, but variable imaging settings pose\nchallenges. Harmonization techniques are crucial for applying handcrafted\nfeatures in disease diagnosis in such scenario. Self-supervised learning (SSL)\nenhances data understanding within limited datasets and adapts to diverse data\nsettings. ConvNeXt-V2 integrates convolutional layers into SSL, displaying\nsuperior performance in various tasks. This study focuses on convolutional\nfilters within SSL, using them as preprocessing to convert images into feature\nmaps for handcrafted feature harmonization. Our proposed method excelled in\nharmonization evaluation and exhibited superior LVH classification performance\ncompared to existing methods.\n","authors":["Jina Lee","Youngtaek Hong","Dawun Jeong","Yeonggul Jang","Sihyeon Jeong","Taekgeun Jung","Yeonyee E. Yoon","Inki Moon","Seung-Ah Lee","Hyuk-Jae Chang"],"pdf_url":"https://arxiv.org/pdf/2310.08897v2.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.12436v1","updated":"2023-11-21T08:45:09Z","published":"2023-11-21T08:45:09Z","title":"Classifier Calibration with ROC-Regularized Isotonic Regression","summary":"  Calibration of machine learning classifiers is necessary to obtain reliable\nand interpretable predictions, bridging the gap between model confidence and\nactual probabilities. One prominent technique, isotonic regression (IR), aims\nat calibrating binary classifiers by minimizing the cross entropy on a\ncalibration set via monotone transformations. IR acts as an adaptive binning\nprocedure, which allows achieving a calibration error of zero, but leaves open\nthe issue of the effect on performance. In this paper, we first prove that IR\npreserves the convex hull of the ROC curve -- an essential performance metric\nfor binary classifiers. This ensures that a classifier is calibrated while\ncontrolling for overfitting of the calibration set. We then present a novel\ngeneralization of isotonic regression to accommodate classifiers with K\nclasses. Our method constructs a multidimensional adaptive binning scheme on\nthe probability simplex, again achieving a multi-class calibration error equal\nto zero. We regularize this algorithm by imposing a form of monotony that\npreserves the K-dimensional ROC surface of the classifier. We show empirically\nthat this general monotony criterion is effective in striking a balance between\nreducing cross entropy loss and avoiding overfitting of the calibration set.\n","authors":["Eugene Berta","Francis Bach","Michael Jordan"],"pdf_url":"https://arxiv.org/pdf/2311.12436v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12435v1","updated":"2023-11-21T08:44:38Z","published":"2023-11-21T08:44:38Z","title":"Fair Enough? A map of the current limitations of the requirements to\n  have \"fair'' algorithms","summary":"  In the recent years, the raise in the usage and efficiency of Artificial\nIntelligence and, more in general, of Automated Decision-Making systems has\nbrought with it an increasing and welcome awareness of the risks associated\nwith such systems. One of such risks is that of perpetuating or even amplifying\nbias and unjust disparities present in the data from which many of these\nsystems learn to adjust and optimise their decisions. This awareness has on one\nside encouraged several scientific communities to come up with more and more\nappropriate ways and methods to assess, quantify, and possibly mitigate such\nbiases and disparities. On the other hand, it has prompted more and more layers\nof society, including policy makers, to call for ``fair'' algorithms. We\nbelieve that while a lot of excellent and multidisciplinary research is\ncurrently being conducted, what is still fundamentally missing is the awareness\nthat having ``fair'' algorithms is per s\\'e a nearly meaningless requirement,\nthat needs to be complemented with a lot of additional societal choices to\nbecome actionable. Namely, there is a hiatus between what the society is\ndemanding from Automated Decision-Making systems, and what this demand actually\nmeans in real-world scenarios. In this work, we outline the key features of\nsuch a hiatus, and pinpoint a list of fundamental ambiguities and attention\npoints that we as a society must address in order to give a concrete meaning to\nthe increasing demand of fairness in Automated Decision-Making systems.\n","authors":["Alessandro Castelnovo","Nicole Inverardi","Gabriele Nanino","Ilaria Giuseppina Penco","Daniele Regoli"],"pdf_url":"https://arxiv.org/pdf/2311.12435v1.pdf","comment":"20 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2311.12424v1","updated":"2023-11-21T08:32:38Z","published":"2023-11-21T08:32:38Z","title":"Looped Transformers are Better at Learning Learning Algorithms","summary":"  Transformers have demonstrated effectiveness in \\emph{in-context solving}\ndata-fitting problems from various (latent) models, as reported by Garg et al.\nHowever, the absence of an inherent iterative structure in the transformer\narchitecture presents a challenge in emulating the iterative algorithms, which\nare commonly employed in traditional machine learning methods. To address this,\nwe propose the utilization of \\emph{looped} transformer architecture and its\nassociated training methodology, with the aim of incorporating iterative\ncharacteristics into the transformer architectures. Experimental results\nsuggest that the looped transformer achieves performance comparable to the\nstandard transformer in solving various data-fitting problems, while utilizing\nless than 10\\% of the parameter count.\n","authors":["Liu Yang","Kangwook Lee","Robert Nowak","Dimitris Papailiopoulos"],"pdf_url":"https://arxiv.org/pdf/2311.12424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.05077v4","updated":"2023-11-21T08:29:16Z","published":"2022-06-10T13:18:26Z","title":"Tensor Train for Global Optimization Problems in Robotics","summary":"  The convergence of many numerical optimization techniques is highly dependent\non the initial guess given to the solver. To address this issue, we propose a\nnovel approach that utilizes tensor methods to initialize existing optimization\nsolvers near global optima. Our method does not require access to a database of\ngood solutions. We first transform the cost function, which depends on both\ntask parameters and optimization variables, into a probability density\nfunction. Unlike existing approaches, the joint probability distribution of the\ntask parameters and optimization variables is approximated using the Tensor\nTrain model, which enables efficient conditioning and sampling. We treat the\ntask parameters as random variables, and for a given task, we generate samples\nfor decision variables from the conditional distribution to initialize the\noptimization solver. Our method can produce multiple solutions (when they\nexist) faster than existing methods. We first evaluate the approach on\nbenchmark functions for numerical optimization that are hard to solve using\ngradient-based optimization solvers with a naive initialization. The results\nshow that the proposed method can generate samples close to global optima and\nfrom multiple modes. We then demonstrate the generality and relevance of our\nframework to robotics by applying it to inverse kinematics with obstacles and\nmotion planning problems with a 7-DoF manipulator.\n","authors":["Suhan Shetty","Teguh Lembono","Tobias Loew","Sylvain Calinon"],"pdf_url":"https://arxiv.org/pdf/2206.05077v4.pdf","comment":"25 pages, 21 figures"},{"id":"http://arxiv.org/abs/2311.07784v2","updated":"2023-11-21T08:23:31Z","published":"2023-11-13T22:21:27Z","title":"A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated\n  Class Incremental Learning for Vision Tasks","summary":"  Deep learning models often suffer from forgetting previously learned\ninformation when trained on new data. This problem is exacerbated in federated\nlearning (FL), where the data is distributed and can change independently for\neach user. Many solutions are proposed to resolve this catastrophic forgetting\nin a centralized setting. However, they do not apply directly to FL because of\nits unique complexities, such as privacy concerns and resource limitations. To\novercome these challenges, this paper presents a framework for\n$\\textbf{federated class incremental learning}$ that utilizes a generative\nmodel to synthesize samples from past distributions. This data can be later\nexploited alongside the training data to mitigate catastrophic forgetting. To\npreserve privacy, the generative model is trained on the server using data-free\nmethods at the end of each task without requesting data from clients. Moreover,\nour solution does not demand the users to store old data or models, which gives\nthem the freedom to join/leave the training at any time. Additionally, we\nintroduce SuperImageNet, a new regrouping of the ImageNet dataset specifically\ntailored for federated continual learning. We demonstrate significant\nimprovements compared to existing baselines through extensive experiments on\nmultiple datasets.\n","authors":["Sara Babakniya","Zalan Fabian","Chaoyang He","Mahdi Soltanolkotabi","Salman Avestimehr"],"pdf_url":"https://arxiv.org/pdf/2311.07784v2.pdf","comment":"Accepted in NeurIPS 2023. arXiv admin note: text overlap with\n  arXiv:2307.00497"},{"id":"http://arxiv.org/abs/2008.12690v2","updated":"2023-11-21T08:18:01Z","published":"2020-08-28T14:46:56Z","title":"ROOT-SGD: Sharp Nonasymptotics and Asymptotic Efficiency in a Single\n  Algorithm","summary":"  We study the problem of solving strongly convex and smooth unconstrained\noptimization problems using stochastic first-order algorithms. We devise a\nnovel algorithm, referred to as \\emph{Recursive One-Over-T SGD} (\\ROOTSGD),\nbased on an easily implementable, recursive averaging of past stochastic\ngradients. We prove that it simultaneously achieves state-of-the-art\nperformance in both a finite-sample, nonasymptotic sense and an asymptotic\nsense. On the nonasymptotic side, we prove risk bounds on the last iterate of\n\\ROOTSGD with leading-order terms that match the optimal statistical risk with\na unity pre-factor, along with a higher-order term that scales at the sharp\nrate of $O(n^{-3/2})$ under the Lipschitz condition on the Hessian matrix. On\nthe asymptotic side, we show that when a mild, one-point Hessian continuity\ncondition is imposed, the rescaled last iterate of (multi-epoch) \\ROOTSGD\nconverges asymptotically to a Gaussian limit with the Cram\\'{e}r-Rao optimal\nasymptotic covariance, for a broad range of step-size choices.\n","authors":["Chris Junchi Li","Wenlong Mou","Martin J. Wainwright","Michael I. Jordan"],"pdf_url":"https://arxiv.org/pdf/2008.12690v2.pdf","comment":"Camera Ready, COLT 2022"},{"id":"http://arxiv.org/abs/2311.12419v1","updated":"2023-11-21T08:16:01Z","published":"2023-11-21T08:16:01Z","title":"Board-to-Board: Evaluating Moonboard Grade Prediction Generalization","summary":"  Bouldering is a sport where athletes aim to climb up an obstacle using a set\nof defined holds called a route. Typically routes are assigned a grade to\ninform climbers of its difficulty and allow them to more easily track their\nprogression. However, the variation in individual climbers technical and\nphysical attributes and many nuances of an individual route make grading a\ndifficult and often biased task. In this work, we apply classical and\ndeep-learning modelling techniques to the 2016, 2017 and 2019 Moonboard\ndatasets, achieving state of the art grade prediction performance with 0.87 MAE\nand 1.12 RMSE. We achieve this performance on a feature-set that does not\nrequire decomposing routes into individual moves, which is a method common in\nliterature and introduces bias. We also demonstrate the generalization\ncapability of this model between editions and introduce a novel vision-based\nmethod of grade prediction. While the generalization performance of these\ntechniques is below human level performance currently, we propose these methods\nas a basis for future work. Such a tool could be implemented in pre-existing\nmobile applications and would allow climbers to better track their progress and\nassess new routes with reduced bias.\n","authors":["Daniel Petashvili","Matthew Rodda"],"pdf_url":"https://arxiv.org/pdf/2311.12419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12410v1","updated":"2023-11-21T07:56:30Z","published":"2023-11-21T07:56:30Z","title":"nach0: Multimodal Natural and Chemical Languages Foundation Model","summary":"  Large Language Models (LLMs) have substantially driven scientific progress in\nvarious domains, and many papers have demonstrated their ability to tackle\ncomplex problems with creative solutions. Our paper introduces a new foundation\nmodel, nach0, capable of solving various chemical and biological tasks:\nbiomedical question answering, named entity recognition, molecular generation,\nmolecular synthesis, attributes prediction, and others. nach0 is a multi-domain\nand multi-task encoder-decoder LLM pre-trained on unlabeled text from\nscientific literature, patents, and molecule strings to incorporate a range of\nchemical and linguistic knowledge. We employed instruction tuning, where\nspecific task-related instructions are utilized to fine-tune nach0 for the\nfinal set of tasks. To train nach0 effectively, we leverage the NeMo framework,\nenabling efficient parallel optimization of both base and large model versions.\nExtensive experiments demonstrate that our model outperforms state-of-the-art\nbaselines on single-domain and cross-domain tasks. Furthermore, it can generate\nhigh-quality outputs in molecular and textual formats, showcasing its\neffectiveness in multi-domain setups.\n","authors":["Micha Livne","Zulfat Miftahutdinov","Elena Tutubalina","Maksim Kuznetsov","Daniil Polykovskiy","Annika Brundyn","Aastha Jhunjhunwala","Anthony Costa","Alex Aliper","Alex Zhavoronkov"],"pdf_url":"https://arxiv.org/pdf/2311.12410v1.pdf","comment":"Submitted to Nature Communications"},{"id":"http://arxiv.org/abs/2202.06054v4","updated":"2023-11-21T07:47:04Z","published":"2022-02-12T12:42:36Z","title":"Towards Data-Algorithm Dependent Generalization: a Case Study on\n  Overparameterized Linear Regression","summary":"  One of the major open problems in machine learning is to characterize\ngeneralization in the overparameterized regime, where most traditional\ngeneralization bounds become inconsistent even for overparameterized linear\nregression. In many scenarios, this failure can be attributed to obscuring the\ncrucial interplay between the training algorithm and the underlying data\ndistribution. This paper demonstrate that the generalization behavior of\noverparameterized model should be analyzed in a both data-relevant and\nalgorithm-relevant manner. To make a formal characterization, We introduce a\nnotion called data-algorithm compatibility, which considers the generalization\nbehavior of the entire data-dependent training trajectory, instead of\ntraditional last-iterate analysis. We validate our claim by studying the\nsetting of solving overparameterized linear regression with gradient descent.\nSpecifically, we perform a data-dependent trajectory analysis and derive a\nsufficient condition for compatibility in such a setting. Our theoretical\nresults demonstrate that if we take early stopping iterates into consideration,\ngeneralization can hold with significantly weaker restrictions on the problem\ninstance than the previous last-iterate analysis.\n","authors":["Jing Xu","Jiaye Teng","Yang Yuan","Andrew Chi-Chih Yao"],"pdf_url":"https://arxiv.org/pdf/2202.06054v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.09299v3","updated":"2023-11-21T07:34:26Z","published":"2023-10-07T09:09:19Z","title":"Digital Twin Assisted Deep Reinforcement Learning for Online Admission\n  Control in Sliced Network","summary":"  The proliferation of diverse wireless services in 5G and beyond has led to\nthe emergence of network slicing technologies. Among these, admission control\nplays a crucial role in achieving service-oriented optimization goals through\nthe selective acceptance of service requests. Although deep reinforcement\nlearning (DRL) forms the foundation in many admission control approaches thanks\nto its effectiveness and flexibility, initial instability with excessive\nconvergence delay of DRL models hinders their deployment in real-world\nnetworks. We propose a digital twin (DT) accelerated DRL solution to address\nthis issue. Specifically, we first formulate the admission decision-making\nprocess as a semi-Markov decision process, which is subsequently simplified\ninto an equivalent discrete-time Markov decision process to facilitate the\nimplementation of DRL methods. A neural network-based DT is established with a\ncustomized output layer for queuing systems, trained through supervised\nlearning, and then employed to assist the training phase of the DRL model.\nExtensive simulations show that the DT-accelerated DRL improves resource\nutilization by over 40% compared to the directly trained state-of-the-art\ndueling deep Q-learning model. This improvement is achieved while preserving\nthe model's capability to optimize the long-term rewards of the admission\nprocess.\n","authors":["Zhenyu Tao","Wei Xu","Xiaohu You"],"pdf_url":"https://arxiv.org/pdf/2310.09299v3.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.12399v1","updated":"2023-11-21T07:22:48Z","published":"2023-11-21T07:22:48Z","title":"A Survey of Graph Meets Large Language Model: Progress and Future\n  Directions","summary":"  Graph plays a significant role in representing and analyzing complex\nrelationships in real-world applications such as citation networks, social\nnetworks, and biological data. Recently, Large Language Models (LLMs), which\nhave achieved tremendous success in various domains, have also been leveraged\nin graph-related tasks to surpass traditional Graph Neural Networks (GNNs)\nbased methods and yield state-of-the-art performance. In this survey, we first\npresent a comprehensive review and analysis of existing methods that integrate\nLLMs with graphs. First of all, we propose a new taxonomy, which organizes\nexisting methods into three categories based on the role (i.e., enhancer,\npredictor, and alignment component) played by LLMs in graph-related tasks. Then\nwe systematically survey the representative methods along the three categories\nof the taxonomy. Finally, we discuss the remaining limitations of existing\nstudies and highlight promising avenues for future research. The relevant\npapers are summarized and will be consistently updated at:\nhttps://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.\n","authors":["Yuhan Li","Zhixun Li","Peisong Wang","Jia Li","Xiangguo Sun","Hong Cheng","Jeffrey Xu Yu"],"pdf_url":"https://arxiv.org/pdf/2311.12399v1.pdf","comment":"Work in progress; 13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2304.07647v2","updated":"2023-11-21T07:21:50Z","published":"2023-04-15T22:24:05Z","title":"LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene\n  Graphs with Weak Supervision","summary":"  We propose LASER, a neuro-symbolic approach to learn semantic video\nrepresentations that capture rich spatial and temporal properties in video data\nby leveraging high-level logic specifications. In particular, we formulate the\nproblem in terms of alignment between raw videos and spatio-temporal logic\nspecifications. The alignment algorithm leverages a differentiable symbolic\nreasoner and a combination of contrastive, temporal, and semantics losses. It\neffectively and efficiently trains low-level perception models to extract\nfine-grained video representation in the form of a spatio-temporal scene graph\nthat conforms to the desired high-level specification. In doing so, we explore\na novel methodology that weakly supervises the learning of video semantic\nrepresentations through logic specifications. We evaluate our method on two\ndatasets with rich spatial and temporal specifications:\n20BN-Something-Something and MUGEN. We demonstrate that our method learns\nbetter fine-grained video semantics than existing baselines.\n","authors":["Jiani Huang","Ziyang Li","Mayur Naik","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2304.07647v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.04589v3","updated":"2023-11-21T07:16:51Z","published":"2022-08-09T08:07:21Z","title":"Long-term Causal Effects Estimation via Latent Surrogates Representation\n  Learning","summary":"  Estimating long-term causal effects based on short-term surrogates is a\nsignificant but challenging problem in many real-world applications, e.g.,\nmarketing and medicine. Despite its success in certain domains, most existing\nmethods estimate causal effects in an idealistic and simplistic way - ignoring\nthe causal structure among short-term outcomes and treating all of them as\nsurrogates. However, such methods cannot be well applied to real-world\nscenarios, in which the partially observed surrogates are mixed with their\nproxies among short-term outcomes. To this end, we develop our flexible method,\nLaser, to estimate long-term causal effects in the more realistic situation\nthat the surrogates are observed or have observed proxies.Given the\nindistinguishability between the surrogates and proxies, we utilize\nidentifiable variational auto-encoder (iVAE) to recover the whole valid\nsurrogates on all the surrogates candidates without the need of distinguishing\nthe observed surrogates or the proxies of latent surrogates. With the help of\nthe recovered surrogates, we further devise an unbiased estimation of long-term\ncausal effects. Extensive experimental results on the real-world and\nsemi-synthetic datasets demonstrate the effectiveness of our proposed method.\n","authors":["Ruichu Cai","Weilin Chen","Zeqin Yang","Shu Wan","Chen Zheng","Xiaoqing Yang","Jiecheng Guo"],"pdf_url":"https://arxiv.org/pdf/2208.04589v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10777v2","updated":"2023-11-21T07:15:57Z","published":"2023-11-16T06:01:47Z","title":"A Systematic Review of Aspect-based Sentiment Analysis (ABSA): Domains,\n  Methods, and Trends","summary":"  Aspect-based Sentiment Analysis (ABSA) is a type of fine-grained sentiment\nanalysis (SA) that identifies aspects and the associated opinions from a given\ntext. In the digital era, ABSA gained increasing popularity and applications in\nmining opinionated text data to obtain insights and support decisions. ABSA\nresearch employs linguistic, statistical, and machine-learning approaches and\nutilises resources such as labelled datasets, aspect and sentiment lexicons and\nontology. By its nature, ABSA is domain-dependent and can be sensitive to the\nimpact of misalignment between the resource and application domains. However,\nto our knowledge, this topic has not been explored by the existing ABSA\nliterature reviews. In this paper, we present a Systematic Literature Review\n(SLR) of ABSA studies with a focus on the research application domain, dataset\ndomain, and the research methods to examine their relationships and identify\ntrends over time. Our results suggest a number of potential systemic issues in\nthe ABSA research literature, including the predominance of the\n``product/service review'' dataset domain among the majority of studies that\ndid not have a specific research application domain, coupled with the\nprevalence of dataset-reliant methods such as supervised machine learning. This\nreview makes a number of unique contributions to the ABSA research field: 1) To\nour knowledge, it is the first SLR that links the research domain, dataset\ndomain, and research method through a systematic perspective; 2) it is one of\nthe largest scoped SLR on ABSA, with 519 eligible studies filtered from 4191\nsearch results without time constraint; and 3) our review methodology adopted\nan innovative automatic filtering process based on PDF-mining, which enhanced\nscreening quality and reliability. Suggestions and our review limitations are\nalso discussed.\n","authors":["Yan Cathy Hua","Paul Denny","Katerina Taskova","Jörg Wicker"],"pdf_url":"https://arxiv.org/pdf/2311.10777v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10770v2","updated":"2023-11-21T06:59:59Z","published":"2023-11-15T18:42:50Z","title":"Exponentially Faster Language Modelling","summary":"  Language models only really need to use an exponential fraction of their\nneurons for individual inferences. As proof, we present UltraFastBERT, a BERT\nvariant that uses 0.3% of its neurons during inference while performing on par\nwith similar BERT models. UltraFastBERT selectively engages just 12 out of 4095\nneurons for each layer inference. This is achieved by replacing feedforward\nnetworks with fast feedforward networks (FFFs). While no truly efficient\nimplementation currently exists to unlock the full acceleration potential of\nconditional neural execution, we provide high-level CPU code achieving 78x\nspeedup over the optimized baseline feedforward implementation, and a PyTorch\nimplementation delivering 40x speedup over the equivalent batched feedforward\ninference. We publish our training code, benchmarking setup, and model weights.\n","authors":["Peter Belcak","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2311.10770v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12379v1","updated":"2023-11-21T06:41:41Z","published":"2023-11-21T06:41:41Z","title":"Infinite forecast combinations based on Dirichlet process","summary":"  Forecast combination integrates information from various sources by\nconsolidating multiple forecast results from the target time series. Instead of\nthe need to select a single optimal forecasting model, this paper introduces a\ndeep learning ensemble forecasting model based on the Dirichlet process.\nInitially, the learning rate is sampled with three basis distributions as\nhyperparameters to convert the infinite mixture into a finite one. All\ncheckpoints are collected to establish a deep learning sub-model pool, and\nweight adjustment and diversity strategies are developed during the combination\nprocess. The main advantage of this method is its ability to generate the\nrequired base learners through a single training process, utilizing the\ndecaying strategy to tackle the challenge posed by the stochastic nature of\ngradient descent in determining the optimal learning rate. To ensure the\nmethod's generalizability and competitiveness, this paper conducts an empirical\nanalysis using the weekly dataset from the M4 competition and explores\nsensitivity to the number of models to be combined. The results demonstrate\nthat the ensemble model proposed offers substantial improvements in prediction\naccuracy and stability compared to a single benchmark model.\n","authors":["Yinuo Ren","Feng Li","Yanfei Kang"],"pdf_url":"https://arxiv.org/pdf/2311.12379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10863v2","updated":"2023-11-21T06:15:56Z","published":"2023-11-17T20:51:24Z","title":"Verified Compositional Neuro-Symbolic Control for Stochastic Systems\n  with Temporal Logic Tasks","summary":"  Several methods have been proposed recently to learn neural network (NN)\ncontrollers for autonomous agents, with unknown and stochastic dynamics, tasked\nwith complex missions captured by Linear Temporal Logic (LTL). Due to the\nsample-inefficiency of the majority of these works, compositional learning\nmethods have been proposed decomposing the LTL specification into smaller\nsub-tasks. Then, separate controllers are learned and composed to satisfy the\noriginal task. A key challenge within these approaches is that they often lack\nsafety guarantees or the provided guarantees are impractical. This paper aims\nto address this challenge. Particularly, we consider autonomous systems with\nunknown and stochastic dynamics and LTL-encoded tasks. We assume that the\nsystem is equipped with a finite set of base skills modeled by trained NN\nfeedback controllers. Our goal is to check if there exists a temporal\ncomposition of the trained NN controllers - and if so, to compute it - that\nwill yield a composite system behavior that satisfies the assigned LTL task\nwith probability one. We propose a new approach that relies on a novel\nintegration of automata theory and data-driven reachability analysis tools for\nNN-controlled stochastic systems. The resulting neuro-symbolic controller\nallows the agent to generate safe behaviors for unseen complex temporal logic\ntasks in a zero-shot fashion by leveraging its base skills. We show correctness\nof the proposed method and we provide conditions under which it is complete. To\nthe best of our knowledge, this is the first work that designs verified\ntemporal compositions of NN controllers for unknown and stochastic systems.\nFinally, we provide extensive numerical simulations and hardware experiments on\nrobot navigation tasks to demonstrate the proposed method.\n","authors":["Jun Wang","Kaiyuan Tan","Zihe Sun","Yiannis Kantaros"],"pdf_url":"https://arxiv.org/pdf/2311.10863v2.pdf","comment":"The paper was withdrawn as it did not include the correct author\n  list, credit was given to the wrong author"},{"id":"http://arxiv.org/abs/2311.01038v2","updated":"2023-11-21T05:48:06Z","published":"2023-11-02T07:09:59Z","title":"Better with Less: A Data-Active Perspective on Pre-Training Graph Neural\n  Networks","summary":"  Pre-training on graph neural networks (GNNs) aims to learn transferable\nknowledge for downstream tasks with unlabeled data, and it has recently become\nan active research area. The success of graph pre-training models is often\nattributed to the massive amount of input data. In this paper, however, we\nidentify the curse of big data phenomenon in graph pre-training: more training\ndata do not necessarily lead to better downstream performance. Motivated by\nthis observation, we propose a better-with-less framework for graph\npre-training: fewer, but carefully chosen data are fed into a GNN model to\nenhance pre-training. The proposed pre-training pipeline is called the\ndata-active graph pre-training (APT) framework, and is composed of a graph\nselector and a pre-training model. The graph selector chooses the most\nrepresentative and instructive data points based on the inherent properties of\ngraphs as well as predictive uncertainty. The proposed predictive uncertainty,\nas feedback from the pre-training model, measures the confidence level of the\nmodel in the data. When fed with the chosen data, on the other hand, the\npre-training model grasps an initial understanding of the new, unseen data, and\nat the same time attempts to remember the knowledge learned from previous data.\nTherefore, the integration and interaction between these two components form a\nunified framework (APT), in which graph pre-training is performed in a\nprogressive and iterative way. Experiment results show that the proposed APT is\nable to obtain an efficient pre-training model with fewer training data and\nbetter downstream performance.\n","authors":["Jiarong Xu","Renhong Huang","Xin Jiang","Yuxuan Cao","Carl Yang","Chunping Wang","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2311.01038v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12359v1","updated":"2023-11-21T05:27:16Z","published":"2023-11-21T05:27:16Z","title":"Post-Training Quantization with Low-precision Minifloats and Integers on\n  FPGAs","summary":"  Post-Training Quantization (PTQ) is a powerful technique for model\ncompression, reducing the precision of neural networks without additional\ntraining overhead. Recent works have investigated adopting 8-bit floating-point\nquantization (FP8) in the context of PTQ for model inference. However, the\nexploration of floating-point formats smaller than 8 bits and their comparison\nwith integer quantization remains relatively limited. In this work, we present\nminifloats, which are reduced-precision floating-point formats capable of\nfurther reducing the memory footprint, latency, and energy cost of a model\nwhile approaching full-precision model accuracy. Our work presents a novel PTQ\ndesign-space exploration, comparing minifloat and integer quantization schemes\nacross a range of 3 to 8 bits for both weights and activations. We examine the\napplicability of various PTQ techniques to minifloats, including weight\nequalization, bias correction, SmoothQuant, gradient-based learned rounding,\nand the GPTQ method. Our experiments validate the effectiveness of\nlow-precision minifloats when compared to their integer counterparts across a\nspectrum of accuracy-precision trade-offs on a set of reference deep learning\nvision workloads. Finally, we evaluate our results against an FPGA-based\nhardware cost model, showing that integer quantization often remains the\nPareto-optimal option, given its relatively smaller hardware resource\nfootprint.\n","authors":["Shivam Aggarwal","Alessandro Pappalardo","Hans Jakob Damsgaard","Giuseppe Franco","Thomas B. Preußer","Michaela Blott","Tulika Mitra"],"pdf_url":"https://arxiv.org/pdf/2311.12359v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12358v1","updated":"2023-11-21T05:26:33Z","published":"2023-11-21T05:26:33Z","title":"Federated Learning via Consensus Mechanism on Heterogeneous Data: A New\n  Perspective on Convergence","summary":"  Federated learning (FL) on heterogeneous data (non-IID data) has recently\nreceived great attention. Most existing methods focus on studying the\nconvergence guarantees for the global objective. While these methods can\nguarantee the decrease of the global objective in each communication round,\nthey fail to ensure risk decrease for each client. In this paper, to address\nthe problem,we propose FedCOME, which introduces a consensus mechanism to\nenforce decreased risk for each client after each training round. In\nparticular, we allow a slight adjustment to a client's gradient on the server\nside, which generates an acute angle between the corrected gradient and the\noriginal ones of other clients. We theoretically show that the consensus\nmechanism can guarantee the convergence of the global objective. To generalize\nthe consensus mechanism to the partial participation FL scenario, we devise a\nnovel client sampling strategy to select the most representative clients for\nthe global data distribution. Training on these selected clients with the\nconsensus mechanism could empirically lead to risk decrease for clients that\nare not selected. Finally, we conduct extensive experiments on four benchmark\ndatasets to show the superiority of FedCOME against other state-of-the-art\nmethods in terms of effectiveness, efficiency and fairness. For\nreproducibility, we make our source code publicly available at:\n\\url{https://github.com/fedcome/fedcome}.\n","authors":["Shu Zheng","Tiandi Ye","Xiang Li","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2311.12358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12356v1","updated":"2023-11-21T05:22:39Z","published":"2023-11-21T05:22:39Z","title":"Random Linear Projections Loss for Hyperplane-Based Optimization in\n  Regression Neural Networks","summary":"  Despite their popularity across a wide range of domains, regression neural\nnetworks are prone to overfitting complex datasets. In this work, we propose a\nloss function termed Random Linear Projections (RLP) loss, which is empirically\nshown to mitigate overfitting. With RLP loss, the distance between sets of\nhyperplanes connecting fixed-size subsets of the neural network's\nfeature-prediction pairs and feature-label pairs is minimized. The intuition\nbehind this loss derives from the notion that if two functions share the same\nhyperplanes connecting all subsets of feature-label pairs, then these functions\nmust necessarily be equivalent. Our empirical studies, conducted across\nbenchmark datasets and representative synthetic examples, demonstrate the\nimprovements of the proposed RLP loss over mean squared error (MSE).\nSpecifically, neural networks trained with the RLP loss achieve better\nperformance while requiring fewer data samples and are more robust to additive\nnoise. We provide theoretical analysis supporting our empirical findings.\n","authors":["Shyam Venkatasubramanian","Ahmed Aloui","Vahid Tarokh"],"pdf_url":"https://arxiv.org/pdf/2311.12356v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12355v1","updated":"2023-11-21T05:15:56Z","published":"2023-11-21T05:15:56Z","title":"Utilizing Language Models for Tour Itinerary Recommendation","summary":"  Tour itinerary recommendation involves planning a sequence of relevant\nPoint-of-Interest (POIs), which combines challenges from the fields of both\nOperations Research (OR) and Recommendation Systems (RS). As an OR problem,\nthere is the need to maximize a certain utility (e.g., popularity of POIs in\nthe tour) while adhering to some constraints (e.g., maximum time for the tour).\nAs a RS problem, it is heavily related to problem or filtering or ranking a\nsubset of POIs that are relevant to a user and recommending it as part of an\nitinerary. In this paper, we explore the use of language models for the task of\ntour itinerary recommendation and planning. This task has the unique\nrequirement of recommending personalized POIs relevant to users and planning\nthese POIs as an itinerary that satisfies various constraints. We discuss some\napproaches in this area, such as using word embedding techniques like Word2Vec\nand GloVe for learning POI embeddings and transformer-based techniques like\nBERT for generating\n  itineraries.\n","authors":["Ngai Lam Ho","Kwan Hui Lim"],"pdf_url":"https://arxiv.org/pdf/2311.12355v1.pdf","comment":"PMAI23 @IJCAI 2023 2nd International Workshop on Process Management\n  in the AI era"},{"id":"http://arxiv.org/abs/2204.09157v2","updated":"2023-11-21T05:06:33Z","published":"2022-04-19T23:19:05Z","title":"Multifidelity Deep Operator Networks For Data-Driven and\n  Physics-Informed Problems","summary":"  Operator learning for complex nonlinear systems is increasingly common in\nmodeling multi-physics and multi-scale systems. However, training such\nhigh-dimensional operators requires a large amount of expensive, high-fidelity\ndata, either from experiments or simulations. In this work, we present a\ncomposite Deep Operator Network (DeepONet) for learning using two datasets with\ndifferent levels of fidelity to accurately learn complex operators when\nsufficient high-fidelity data is not available. Additionally, we demonstrate\nthat the presence of low-fidelity data can improve the predictions of\nphysics-informed learning with DeepONets. We demonstrate the new multi-fidelity\ntraining in diverse examples, including modeling of the ice-sheet dynamics of\nthe Humboldt glacier, Greenland, using two different fidelity models and also\nusing the same physical model at two different resolutions.\n","authors":["Amanda A. Howard","Mauro Perego","George E. Karniadakis","Panos Stinis"],"pdf_url":"https://arxiv.org/pdf/2204.09157v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12351v1","updated":"2023-11-21T04:59:17Z","published":"2023-11-21T04:59:17Z","title":"Advancing Transformer Architecture in Long-Context Large Language\n  Models: A Comprehensive Survey","summary":"  With the bomb ignited by ChatGPT, Transformer-based Large Language Models\n(LLMs) have paved a revolutionary path toward Artificial General Intelligence\n(AGI) and have been applied in diverse areas as knowledge bases, human\ninterfaces, and dynamic agents. However, a prevailing limitation exists: many\ncurrent LLMs, constrained by resources, are primarily pre-trained on shorter\ntexts, rendering them less effective for longer-context prompts, commonly\nencountered in real-world settings. In this paper, we present a comprehensive\nsurvey focusing on the advancement of model architecture in Transformer-based\nLLMs to optimize long-context capabilities across all stages from pre-training\nto inference. We firstly delineate and analyze the problems of handling\nlong-context input and output with the current Transformer-based models. Then,\nwe mainly offer a holistic taxonomy to navigate the landscape of Transformer\nupgrades on architecture to solve these problems. Afterward, we provide the\ninvestigation on wildly used evaluation necessities tailored for long-context\nLLMs, including datasets, metrics, and baseline models, as well as some amazing\noptimization toolkits like libraries, systems, and compilers to augment LLMs'\nefficiency and efficacy across different stages. Finally, we further discuss\nthe predominant challenges and potential avenues for future research in this\ndomain. Additionally, we have established a repository where we curate relevant\nliterature with real-time updates at\nhttps://github.com/Strivin0311/long-llms-learning.\n","authors":["Yunpeng Huang","Jingwei Xu","Zixu Jiang","Junyu Lai","Zenan Li","Yuan Yao","Taolue Chen","Lijuan Yang","Zhou Xin","Xiaoxing Ma"],"pdf_url":"https://arxiv.org/pdf/2311.12351v1.pdf","comment":"35 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.06483v2","updated":"2023-11-21T04:53:27Z","published":"2023-11-11T05:43:54Z","title":"Stacked networks improve physics-informed training: applications to\n  neural networks and deep operator networks","summary":"  Physics-informed neural networks and operator networks have shown promise for\neffectively solving equations modeling physical systems. However, these\nnetworks can be difficult or impossible to train accurately for some systems of\nequations. We present a novel multifidelity framework for stacking\nphysics-informed neural networks and operator networks that facilitates\ntraining. We successively build a chain of networks, where the output at one\nstep can act as a low-fidelity input for training the next step, gradually\nincreasing the expressivity of the learned model. The equations imposed at each\nstep of the iterative process can be the same or different (akin to simulated\nannealing). The iterative (stacking) nature of the proposed method allows us to\nprogressively learn features of a solution that are hard to learn directly.\nThrough benchmark problems including a nonlinear pendulum, the wave equation,\nand the viscous Burgers equation, we show how stacking can be used to improve\nthe accuracy and reduce the required size of physics-informed neural networks\nand operator networks.\n","authors":["Amanda A Howard","Sarah H Murphy","Shady E Ahmed","Panos Stinis"],"pdf_url":"https://arxiv.org/pdf/2311.06483v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12345v1","updated":"2023-11-21T04:38:21Z","published":"2023-11-21T04:38:21Z","title":"Stable Diffusion For Aerial Object Detection","summary":"  Aerial object detection is a challenging task, in which one major obstacle\nlies in the limitations of large-scale data collection and the long-tail\ndistribution of certain classes. Synthetic data offers a promising solution,\nespecially with recent advances in diffusion-based methods like stable\ndiffusion (SD). However, the direct application of diffusion methods to aerial\ndomains poses unique challenges: stable diffusion's optimization for rich\nground-level semantics doesn't align with the sparse nature of aerial objects,\nand the extraction of post-synthesis object coordinates remains problematic. To\naddress these challenges, we introduce a synthetic data augmentation framework\ntailored for aerial images. It encompasses sparse-to-dense region of interest\n(ROI) extraction to bridge the semantic gap, fine-tuning the diffusion model\nwith low-rank adaptation (LORA) to circumvent exhaustive retraining, and\nfinally, a Copy-Paste method to compose synthesized objects with backgrounds,\nproviding a nuanced approach to aerial object detection through synthetic data.\n","authors":["Yanan Jian","Fuxun Yu","Simranjit Singh","Dimitrios Stamoulis"],"pdf_url":"https://arxiv.org/pdf/2311.12345v1.pdf","comment":"Accepted at NeurIPS 2023 Synthetic Data Generation with Generative AI\n  workshop"},{"id":"http://arxiv.org/abs/2304.14922v2","updated":"2023-11-21T04:25:31Z","published":"2023-04-24T05:21:10Z","title":"Supervised and Unsupervised Deep Learning Approaches for EEG Seizure\n  Prediction","summary":"  Epilepsy affects more than 50 million people worldwide, making it one of the\nworld's most prevalent neurological diseases. The main symptom of epilepsy is\nseizures, which occur abruptly and can cause serious injury or death. The\nability to predict the occurrence of an epileptic seizure could alleviate many\nrisks and stresses people with epilepsy face. We formulate the problem of\ndetecting preictal (or pre-seizure) with reference to normal EEG as a precursor\nto incoming seizure. To this end, we developed several supervised deep learning\napproaches model to identify preictal EEG from normal EEG. We further develop\nnovel unsupervised deep learning approaches to train the models on only normal\nEEG, and detecting pre-seizure EEG as an anomalous event. These deep learning\nmodels were trained and evaluated on two large EEG seizure datasets in a\nperson-specific manner. We found that both supervised and unsupervised\napproaches are feasible; however, their performance varies depending on the\npatient, approach and architecture. This new line of research has the potential\nto develop therapeutic interventions and save human lives.\n","authors":["Zakary Georgis-Yap","Milos R. Popovic","Shehroz S. Khan"],"pdf_url":"https://arxiv.org/pdf/2304.14922v2.pdf","comment":"16 figures, 9 tables"},{"id":"http://arxiv.org/abs/2307.01452v2","updated":"2023-11-21T03:43:15Z","published":"2023-07-04T03:00:43Z","title":"Causal Reinforcement Learning: A Survey","summary":"  Reinforcement learning is an essential paradigm for solving sequential\ndecision problems under uncertainty. Despite many remarkable achievements in\nrecent decades, applying reinforcement learning methods in the real world\nremains challenging. One of the main obstacles is that reinforcement learning\nagents lack a fundamental understanding of the world and must therefore learn\nfrom scratch through numerous trial-and-error interactions. They may also face\nchallenges in providing explanations for their decisions and generalizing the\nacquired knowledge. Causality, however, offers a notable advantage as it can\nformalize knowledge in a systematic manner and leverage invariance for\neffective knowledge transfer. This has led to the emergence of causal\nreinforcement learning, a subfield of reinforcement learning that seeks to\nenhance existing algorithms by incorporating causal relationships into the\nlearning process. In this survey, we comprehensively review the literature on\ncausal reinforcement learning. We first introduce the basic concepts of\ncausality and reinforcement learning, and then explain how causality can\naddress core challenges in non-causal reinforcement learning. We categorize and\nsystematically review existing causal reinforcement learning approaches based\non their target problems and methodologies. Finally, we outline open issues and\nfuture directions in this emerging field.\n","authors":["Zhihong Deng","Jing Jiang","Guodong Long","Chengqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2307.01452v2.pdf","comment":"52 pages, 10 figures"},{"id":"http://arxiv.org/abs/2311.12329v1","updated":"2023-11-21T03:42:15Z","published":"2023-11-21T03:42:15Z","title":"Graph Neural Ordinary Differential Equations-based method for\n  Collaborative Filtering","summary":"  Graph Convolution Networks (GCNs) are widely considered state-of-the-art for\ncollaborative filtering. Although several GCN-based methods have been proposed\nand achieved state-of-the-art performance in various tasks, they can be\ncomputationally expensive and time-consuming to train if too many layers are\ncreated. However, since the linear GCN model can be interpreted as a\ndifferential equation, it is possible to transfer it to an ODE problem. This\ninspired us to address the computational limitations of GCN-based models by\ndesigning a simple and efficient NODE-based model that can skip some GCN layers\nto reach the final state, thus avoiding the need to create many layers. In this\nwork, we propose a Graph Neural Ordinary Differential Equation-based method for\nCollaborative Filtering (GODE-CF). This method estimates the final embedding by\nutilizing the information captured by one or two GCN layers. To validate our\napproach, we conducted experiments on multiple datasets. The results\ndemonstrate that our model outperforms competitive baselines, including\nGCN-based models and other state-of-the-art CF methods. Notably, our proposed\nGODE-CF model has several advantages over traditional GCN-based models. It is\nsimple, efficient, and has a fast training time, making it a practical choice\nfor real-world situations.\n","authors":["Ke Xu","Yuanjie Zhu","Weizhi Zhang","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2311.12329v1.pdf","comment":"Accepted by ICDM 2023"},{"id":"http://arxiv.org/abs/2311.12323v1","updated":"2023-11-21T03:34:20Z","published":"2023-11-21T03:34:20Z","title":"Modeling Political Orientation of Social Media Posts: An Extended\n  Analysis","summary":"  Developing machine learning models to characterize political polarization on\nonline social media presents significant challenges. These challenges mainly\nstem from various factors such as the lack of annotated data, presence of noise\nin social media datasets, and the sheer volume of data. The common research\npractice typically examines the biased structure of online user communities for\na given topic or qualitatively measuring the impacts of polarized topics on\nsocial media. However, there is limited work focusing on analyzing polarization\nat the ground-level, specifically in the social media posts themselves. Such\nexisting analysis heavily relies on annotated data, which often requires\nlaborious human labeling, offers labels only to specific problems, and lacks\nthe ability to determine the near-future bias state of a social media\nconversations. Understanding the degree of political orientation conveyed in\nsocial media posts is crucial for quantifying the bias of online user\ncommunities and investigating the spread of polarized content. In this work, we\nfirst introduce two heuristic methods that leverage on news media bias and post\ncontent to label social media posts. Next, we compare the efficacy and quality\nof heuristically labeled dataset with a randomly sampled human-annotated\ndataset. Additionally, we demonstrate that current machine learning models can\nexhibit improved performance in predicting political orientation of social\nmedia posts, employing both traditional supervised learning and few-shot\nlearning setups. We conduct experiments using the proposed heuristic methods\nand machine learning approaches to predict the political orientation of posts\ncollected from two social media forums with diverse political ideologies: Gab\nand Twitter.\n","authors":["Sadia Kamal","Brenner Little","Jade Gullic","Trevor Harms","Kristin Olofsson","Arunkumar Bagavathi"],"pdf_url":"https://arxiv.org/pdf/2311.12323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.13108v2","updated":"2023-11-21T03:25:56Z","published":"2023-09-22T18:00:01Z","title":"Data is often loadable in short depth: Quantum circuits from tensor\n  networks for finance, images, fluids, and proteins","summary":"  Though there has been substantial progress in developing quantum algorithms\nto study classical datasets, the cost of simply loading classical data is an\nobstacle to quantum advantage. When the amplitude encoding is used, loading an\narbitrary classical vector requires up to exponential circuit depths with\nrespect to the number of qubits. Here, we address this \"input problem\" with two\ncontributions. First, we introduce a circuit compilation method based on tensor\nnetwork (TN) theory. Our method -- AMLET (Automatic Multi-layer Loader\nExploiting TNs) -- proceeds via careful construction of a specific TN topology\nand can be tailored to arbitrary circuit depths. Second, we perform numerical\nexperiments on real-world classical data from four distinct areas: finance,\nimages, fluid mechanics, and proteins. To the best of our knowledge, this is\nthe broadest numerical analysis to date of loading classical data into a\nquantum computer. Consistent with other recent work in this area, the required\ncircuit depths are often several orders of magnitude lower than the\nexponentially-scaling general loading algorithm would require. Besides\nintroducing a more efficient loading algorithm, this work demonstrates that\nmany classical datasets are loadable in depths that are much shorter than\npreviously expected, which has positive implications for speeding up classical\nworkloads on quantum computers.\n","authors":["Raghav Jumade","Nicolas PD Sawaya"],"pdf_url":"https://arxiv.org/pdf/2309.13108v2.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.03488v3","updated":"2023-11-21T03:08:37Z","published":"2023-11-06T19:52:55Z","title":"Multi-Resolution Diffusion for Privacy-Sensitive Recommender Systems","summary":"  While recommender systems have become an integral component of the Web\nexperience, their heavy reliance on user data raises privacy and security\nconcerns. Substituting user data with synthetic data can address these\nconcerns, but accurately replicating these real-world datasets has been a\nnotoriously challenging problem. Recent advancements in generative AI have\ndemonstrated the impressive capabilities of diffusion models in generating\nrealistic data across various domains. In this work we introduce a Score-based\nDiffusion Recommendation Module (SDRM), which captures the intricate patterns\nof real-world datasets required for training highly accurate recommender\nsystems. SDRM allows for the generation of synthetic data that can replace\nexisting datasets to preserve user privacy, or augment existing datasets to\naddress excessive data sparsity. Our method outperforms competing baselines\nsuch as generative adversarial networks, variational autoencoders, and recently\nproposed diffusion models in synthesizing various datasets to replace or\naugment the original data by an average improvement of 4.30% in Recall@$k$ and\n4.65% in NDCG@$k$.\n","authors":["Derek Lilienthal","Paul Mello","Magdalini Eirinaki","Stas Tiomkin"],"pdf_url":"https://arxiv.org/pdf/2311.03488v3.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.12310v1","updated":"2023-11-21T03:02:33Z","published":"2023-11-21T03:02:33Z","title":"IEKM: A Model Incorporating External Keyword Matrices","summary":"  A customer service platform system with a core text semantic similarity (STS)\ntask faces two urgent challenges: Firstly, one platform system needs to adapt\nto different domains of customers, i.e., different domains adaptation (DDA).\nSecondly, it is difficult for the model of the platform system to distinguish\nsentence pairs that are literally close but semantically different, i.e., hard\nnegative samples. In this paper, we propose an incorporation external keywords\nmatrices model (IEKM) to address these challenges. The model uses external\ntools or dictionaries to construct external matrices and fuses them to the\nself-attention layers of the Transformer structure through gating units, thus\nenabling flexible corrections to the model results. We evaluate the method on\nmultiple datasets and the results show that our method has improved performance\non all datasets. To demonstrate that our method can effectively solve all the\nabove challenges, we conduct a flexible correction experiment, which results in\nan increase in the F1 value from 56.61 to 73.53. Our code will be publicly\navailable.\n","authors":["Cheng Luo","Qin Li","Zhao Yan","Mengliang Rao","Yunbo Cao"],"pdf_url":"https://arxiv.org/pdf/2311.12310v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12309v1","updated":"2023-11-21T03:02:30Z","published":"2023-11-21T03:02:30Z","title":"Power grid operational risk assessment using graph neural network\n  surrogates","summary":"  We investigate the utility of graph neural networks (GNNs) as proxies of\npower grid operational decision-making algorithms (optimal power flow (OPF) and\nsecurity-constrained unit commitment (SCUC)) to enable rigorous quantification\nof the operational risk. To conduct principled risk analysis, numerous Monte\nCarlo (MC) samples are drawn from the (foretasted) probability distributions of\nspatio-temporally correlated stochastic grid variables. The corresponding OPF\nand SCUC solutions, which are needed to quantify the risk, are generated using\ntraditional OPF and SCUC solvers to generate data for training GNN model(s).\nThe GNN model performance is evaluated in terms of the accuracy of predicting\nquantities of interests (QoIs) derived from the decision variables in OPF and\nSCUC. Specifically, we focus on thermal power generation and load shedding at\nsystem and individual zone level. We also perform reliability and risk\nquantification based on GNN predictions and compare with that obtained from\nOPF/SCUC solutions. Our results demonstrate that GNNs are capable of providing\nfast and accurate prediction of QoIs and thus can be good surrogate models for\nOPF and SCUC. The excellent accuracy of GNN-based reliability and risk\nassessment further suggests that GNN surrogate has the potential to be applied\nin real-time and hours-ahead risk quantification.\n","authors":["Yadong Zhang","Pranav M Karve","Sankaran Mahadevan"],"pdf_url":"https://arxiv.org/pdf/2311.12309v1.pdf","comment":"Manuscript submitted to IEEE PES GM 2024"},{"id":"http://arxiv.org/abs/2311.12304v1","updated":"2023-11-21T02:46:14Z","published":"2023-11-21T02:46:14Z","title":"Discovering Effective Policies for Land-Use Planning","summary":"  How areas of land are allocated for different uses, such as forests, urban,\nand agriculture, has a large effect on carbon balance, and therefore climate\nchange. Based on available historical data on changes in land use and a\nsimulation of carbon emissions/absorption, a surrogate model can be learned\nthat makes it possible to evaluate the different options available to\ndecision-makers efficiently. An evolutionary search process can then be used to\ndiscover effective land-use policies for specific locations. Such a system was\nbuilt on the Project Resilience platform and evaluated with the Land-Use\nHarmonization dataset and the BLUE simulator. It generates Pareto fronts that\ntrade off carbon impact and amount of change customized to different locations,\nthus providing a potentially useful tool for land-use planning.\n","authors":["Risto Miikkulainen","Olivier Francon","Daniel Young","Elliot Meyerson","Babak Hodjat"],"pdf_url":"https://arxiv.org/pdf/2311.12304v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12303v1","updated":"2023-11-21T02:45:53Z","published":"2023-11-21T02:45:53Z","title":"Detecting subtle macroscopic changes in a finite temperature classical\n  scalar field with machine learning","summary":"  The ability to detect macroscopic changes is important for probing the\nbehaviors of experimental many-body systems from the classical to the quantum\nrealm. Although abrupt changes near phase boundaries can easily be detected,\nsubtle macroscopic changes are much more difficult to detect as the changes can\nbe obscured by noise. In this study, as a toy model for detecting subtle\nmacroscopic changes in many-body systems, we try to differentiate scalar field\nsamples at varying temperatures. We compare different methods for making such\ndifferentiations, from physics method, statistics method, to AI method. Our\nfinding suggests that the AI method outperforms both the statistical method and\nthe physics method in its sensitivity. Our result provides a proof-of-concept\nthat AI can potentially detect macroscopic changes in many-body systems that\nelude physical measures.\n","authors":["Jiming Yang","Yutong Zheng","Jiahong Zhou","Huiyu Li","Jun Yin"],"pdf_url":"https://arxiv.org/pdf/2311.12303v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2310.13230v2","updated":"2023-11-21T02:28:21Z","published":"2023-10-20T02:40:05Z","title":"Absolute Policy Optimization","summary":"  In recent years, trust region on-policy reinforcement learning has achieved\nimpressive results in addressing complex control tasks and gaming scenarios.\nHowever, contemporary state-of-the-art algorithms within this category\nprimarily emphasize improvement in expected performance, lacking the ability to\ncontrol over the worst-case performance outcomes. To address this limitation,\nwe introduce a novel objective function; by optimizing which, it will lead to\nguaranteed monotonic improvement in the lower bound of near-total performance\nsamples (absolute performance). Considering this groundbreaking theoretical\nadvancement, we then refine this theoretically grounded algorithm through a\nseries of approximations, resulting in a practical solution called Absolute\nPolicy Optimization (APO). Our experiments demonstrate the effectiveness of our\napproach across challenging continuous control benchmark tasks and extend its\napplicability to mastering Atari games. Our findings reveal that APO\nsignificantly outperforms state-of-the-art policy gradient algorithms,\nresulting in substantial improvements in both expected performance and\nworst-case performance.\n","authors":["Weiye Zhao","Feihan Li","Yifan Sun","Rui Chen","Tianhao Wei","Changliu Liu"],"pdf_url":"https://arxiv.org/pdf/2310.13230v2.pdf","comment":"I submitted this article to Journal of Machine Learning Research. The\n  manuscript will go under a major revision and I don't want the reviewer know\n  who I am. I will re-upload after JMLR review released"},{"id":"http://arxiv.org/abs/2311.12292v1","updated":"2023-11-21T02:24:52Z","published":"2023-11-21T02:24:52Z","title":"Mapping \"Brain Coral\" Regions on Mars using Deep Learning","summary":"  One of the main objectives of the Mars Exploration Program is to search for\nevidence of past or current life on the planet. To achieve this, Mars\nexploration has been focusing on regions that may have liquid or frozen water.\nA set of critical areas may have seen cycles of ice thawing in the relatively\nrecent past in response to periodic changes in the obliquity of Mars. In this\nwork, we use convolutional neural networks to detect surface regions containing\n\"Brain Coral\" terrain, a landform on Mars whose similarity in morphology and\nscale to sorted stone circles on Earth suggests that it may have formed as a\nconsequence of freeze/thaw cycles. We use large images (~100-1000 megapixels)\nfrom the Mars Reconnaissance Orbiter to search for these landforms at\nresolutions close to a few tens of centimeters per pixel (~25--50 cm). Over\n52,000 images (~28 TB) were searched (~5% of the Martian surface) where we\nfound detections in over 200 images. To expedite the processing we leverage a\nclassifier network (prior to segmentation) in the Fourier domain that can take\nadvantage of JPEG compression by leveraging blocks of coefficients from a\ndiscrete cosine transform in lieu of decoding the entire image at the full\nspatial resolution. The hybrid pipeline approach maintains ~93% accuracy while\ncutting down on ~95% of the total processing time compared to running the\nsegmentation network at the full resolution on every image. The timely\nprocessing of big data sets helps inform mission operations, geologic surveys\nto prioritize candidate landing sites, avoid hazardous areas, or map the\nspatial extent of certain terrain. The segmentation masks and source code are\navailable on Github for the community to explore and build upon.\n","authors":["Kyle A. Pearson","Eldar Noe","Daniel Zhao","Alphan Altinok","Alex Morgan"],"pdf_url":"https://arxiv.org/pdf/2311.12292v1.pdf","comment":"Submitted for publication, seeking comments from the community. Code\n  available: https://github.com/pearsonkyle/Mars-Brain-Coral-Network"},{"id":"http://arxiv.org/abs/2311.10899v2","updated":"2023-11-21T02:16:27Z","published":"2023-11-17T22:44:05Z","title":"Extraction and Summarization of Explicit Video Content using Multi-Modal\n  Deep Learning","summary":"  With the increase in video-sharing platforms across the internet, it is\ndifficult for humans to moderate the data for explicit content. Hence, an\nautomated pipeline to scan through video data for explicit content has become\nthe need of the hour. We propose a novel pipeline that uses multi-modal deep\nlearning to first extract the explicit segments of input videos and then\nsummarize their content using text to determine its age appropriateness and age\nrating. We also evaluate our pipeline's effectiveness in the end using standard\nmetrics.\n","authors":["Shaunak Joshi","Raghav Gaggar"],"pdf_url":"https://arxiv.org/pdf/2311.10899v2.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2304.07927v2","updated":"2023-11-21T02:15:33Z","published":"2023-04-17T00:38:01Z","title":"A Randomized Approach for Tight Privacy Accounting","summary":"  Bounding privacy leakage over compositions, i.e., privacy accounting, is a\nkey challenge in differential privacy (DP). The privacy parameter ($\\eps$ or\n$\\delta$) is often easy to estimate but hard to bound. In this paper, we\npropose a new differential privacy paradigm called estimate-verify-release\n(EVR), which addresses the challenges of providing a strict upper bound for\nprivacy parameter in DP compositions by converting an estimate of privacy\nparameter into a formal guarantee. The EVR paradigm first estimates the privacy\nparameter of a mechanism, then verifies whether it meets this guarantee, and\nfinally releases the query output based on the verification result. The core\ncomponent of the EVR is privacy verification. We develop a randomized privacy\nverifier using Monte Carlo (MC) technique. Furthermore, we propose an MC-based\nDP accountant that outperforms existing DP accounting techniques in terms of\naccuracy and efficiency. Our empirical evaluation shows the newly proposed EVR\nparadigm improves the utility-privacy tradeoff for privacy-preserving machine\nlearning.\n","authors":["Jiachen T. Wang","Saeed Mahloujifar","Tong Wu","Ruoxi Jia","Prateek Mittal"],"pdf_url":"https://arxiv.org/pdf/2304.07927v2.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.12290v1","updated":"2023-11-21T02:06:52Z","published":"2023-11-21T02:06:52Z","title":"A Supervised Contrastive Learning Pretrain-Finetune Approach for Time\n  Series","summary":"  Foundation models have recently gained attention within the field of machine\nlearning thanks to its efficiency in broad data processing. While researchers\nhad attempted to extend this success to time series models, the main challenge\nis effectively extracting representations and transferring knowledge from\npretraining datasets to the target finetuning dataset. To tackle this issue, we\nintroduce a novel pretraining procedure that leverages supervised contrastive\nlearning to distinguish features within each pretraining dataset. This\npretraining phase enables a probabilistic similarity metric, which assesses the\nlikelihood of a univariate sample being closely related to one of the\npretraining datasets. Subsequently, using this similarity metric as a guide, we\npropose a fine-tuning procedure designed to enhance the accurate prediction of\nthe target data by aligning it more closely with the learned dynamics of the\npretraining datasets. Our experiments have shown promising results which\ndemonstrate the efficacy of our approach.\n","authors":["Trang H. Tran","Lam M. Nguyen","Kyongmin Yeo","Nam Nguyen","Roman Vaculin"],"pdf_url":"https://arxiv.org/pdf/2311.12290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10429v4","updated":"2023-11-21T02:01:53Z","published":"2023-05-17T17:58:13Z","title":"DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining","summary":"  The mixture proportions of pretraining data domains (e.g., Wikipedia, books,\nweb text) greatly affect language model (LM) performance. In this paper, we\npropose Domain Reweighting with Minimax Optimization (DoReMi), which first\ntrains a small proxy model using group distributionally robust optimization\n(Group DRO) over domains to produce domain weights (mixture proportions)\nwithout knowledge of downstream tasks. We then resample a dataset with these\ndomain weights and train a larger, full-sized model. In our experiments, we use\nDoReMi on a 280M-parameter proxy model to set the domain weights for training\nan 8B-parameter model (30x larger) more efficiently. On The Pile, DoReMi\nimproves perplexity across all domains, even when it downweights a domain.\nDoReMi improves average few-shot downstream accuracy by 6.5% points over a\nbaseline model trained using The Pile's default domain weights and reaches the\nbaseline accuracy with 2.6x fewer training steps. On the GLaM dataset, DoReMi,\nwhich has no knowledge of downstream tasks, even matches the performance of\nusing domain weights tuned on downstream tasks.\n","authors":["Sang Michael Xie","Hieu Pham","Xuanyi Dong","Nan Du","Hanxiao Liu","Yifeng Lu","Percy Liang","Quoc V. Le","Tengyu Ma","Adams Wei Yu"],"pdf_url":"https://arxiv.org/pdf/2305.10429v4.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.12282v1","updated":"2023-11-21T01:52:15Z","published":"2023-11-21T01:52:15Z","title":"Orthogonally weighted $\\ell_{2,1}$ regularization for rank-aware joint\n  sparse recovery: algorithm and analysis","summary":"  We propose and analyze an efficient algorithm for solving the joint sparse\nrecovery problem using a new regularization-based method, named orthogonally\nweighted $\\ell_{2,1}$ ($\\mathit{ow}\\ell_{2,1}$), which is specifically designed\nto take into account the rank of the solution matrix. This method has\napplications in feature extraction, matrix column selection, and dictionary\nlearning, and it is distinct from commonly used $\\ell_{2,1}$ regularization and\nother existing regularization-based approaches because it can exploit the full\nrank of the row-sparse solution matrix, a key feature in many applications. We\nprovide a proof of the method's rank-awareness, establish the existence of\nsolutions to the proposed optimization problem, and develop an efficient\nalgorithm for solving it, whose convergence is analyzed. We also present\nnumerical experiments to illustrate the theory and demonstrate the\neffectiveness of our method on real-life problems.\n","authors":["Armenak Petrosyan","Konstantin Pieper","Hoang Tran"],"pdf_url":"https://arxiv.org/pdf/2311.12282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12279v1","updated":"2023-11-21T01:46:56Z","published":"2023-11-21T01:46:56Z","title":"Probabilistic Forecast Reconciliation with Kullback-Leibler Divergence\n  Regularization","summary":"  As the popularity of hierarchical point forecast reconciliation methods\nincreases, there is a growing interest in probabilistic forecast\nreconciliation. Many studies have utilized machine learning or deep learning\ntechniques to implement probabilistic forecasting reconciliation and have made\nnotable progress. However, these methods treat the reconciliation step as a\nfixed and hard post-processing step, leading to a trade-off between accuracy\nand coherency. In this paper, we propose a new approach for probabilistic\nforecast reconciliation. Unlike existing approaches, our proposed approach\nfuses the prediction step and reconciliation step into a deep learning\nframework, making the reconciliation step more flexible and soft by introducing\nthe Kullback-Leibler divergence regularization term into the loss function. The\napproach is evaluated using three hierarchical time series datasets, which\nshows the advantages of our approach over other probabilistic forecast\nreconciliation methods.\n","authors":["Guanyu Zhang","Feng Li","Yanfei Kang"],"pdf_url":"https://arxiv.org/pdf/2311.12279v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12267v1","updated":"2023-11-21T01:09:11Z","published":"2023-11-21T01:09:11Z","title":"Learning Causal Representations from General Environments:\n  Identifiability and Intrinsic Ambiguity","summary":"  This paper studies causal representation learning, the task of recovering\nhigh-level latent variables and their causal relationships from low-level data\nthat we observe, assuming access to observations generated from multiple\nenvironments. While existing works are able to prove full identifiability of\nthe underlying data generating process, they typically assume access to\nsingle-node, hard interventions which is rather unrealistic in practice. The\nmain contribution of this paper is characterize a notion of identifiability\nwhich is provably the best one can achieve when hard interventions are not\navailable. First, for linear causal models, we provide identifiability\nguarantee for data observed from general environments without assuming any\nsimilarities between them. While the causal graph is shown to be fully\nrecovered, the latent variables are only identified up to an effect-domination\nambiguity (EDA). We then propose an algorithm, LiNGCReL which is guaranteed to\nrecover the ground-truth model up to EDA, and we demonstrate its effectiveness\nvia numerical experiments. Moving on to general non-parametric causal models,\nwe prove the same idenfifiability guarantee assuming access to groups of soft\ninterventions. Finally, we provide counterparts of our identifiability results,\nindicating that EDA is basically inevitable in our setting.\n","authors":["Jikai Jin","Vasilis Syrgkanis"],"pdf_url":"https://arxiv.org/pdf/2311.12267v1.pdf","comment":"43 pages"},{"id":"http://arxiv.org/abs/2311.12264v1","updated":"2023-11-21T00:59:27Z","published":"2023-11-21T00:59:27Z","title":"Resilient Control of Networked Microgrids using Vertical Federated\n  Reinforcement Learning: Designs and Real-Time Test-Bed Validations","summary":"  Improving system-level resiliency of networked microgrids is an important\naspect with increased population of inverter-based resources (IBRs). This paper\n(1) presents resilient control design in presence of adversarial cyber-events,\nand proposes a novel federated reinforcement learning (Fed-RL) approach to\ntackle (a) model complexities, unknown dynamical behaviors of IBR devices, (b)\nprivacy issues regarding data sharing in multi-party-owned networked grids, and\n(2) transfers learned controls from simulation to hardware-in-the-loop\ntest-bed, thereby bridging the gap between simulation and real world. With\nthese multi-prong objectives, first, we formulate a reinforcement learning (RL)\ntraining setup generating episodic trajectories with adversaries (attack\nsignal) injected at the primary controllers of the grid forming (GFM) inverters\nwhere RL agents (or controllers) are being trained to mitigate the injected\nattacks. For networked microgrids, the horizontal Fed-RL method involving\ndistinct independent environments is not appropriate, leading us to develop\nvertical variant Federated Soft Actor-Critic (FedSAC) algorithm to grasp the\ninterconnected dynamics of networked microgrid. Next, utilizing OpenAI Gym\ninterface, we built a custom simulation set-up in GridLAB-D/HELICS\nco-simulation platform, named Resilient RL Co-simulation (ResRLCoSIM), to train\nthe RL agents with IEEE 123-bus benchmark test systems comprising 3\ninterconnected microgrids. Finally, the learned policies in simulation world\nare transferred to the real-time hardware-in-the-loop test-bed set-up developed\nusing high-fidelity Hypersim platform. Experiments show that the\nsimulator-trained RL controllers produce convincing results with the real-time\ntest-bed set-up, validating the minimization of sim-to-real gap.\n","authors":["Sayak Mukherjee","Ramij R. Hossain","Sheik M. Mohiuddin","Yuan Liu","Wei Du","Veronica Adetola","Rohit A. Jinsiwale","Qiuhua Huang","Tianzhixi Yin","Ankit Singhal"],"pdf_url":"https://arxiv.org/pdf/2311.12264v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.05067v2","updated":"2023-11-21T00:46:47Z","published":"2023-11-09T00:05:17Z","title":"Accelerating Exploration with Unlabeled Prior Data","summary":"  Learning to solve tasks from a sparse reward signal is a major challenge for\nstandard reinforcement learning (RL) algorithms. However, in the real world,\nagents rarely need to solve sparse reward tasks entirely from scratch. More\noften, we might possess prior experience to draw on that provides considerable\nguidance about which actions and outcomes are possible in the world, which we\ncan use to explore more effectively for new tasks. In this work, we study how\nprior data without reward labels may be used to guide and accelerate\nexploration for an agent solving a new sparse reward task. We propose a simple\napproach that learns a reward model from online experience, labels the\nunlabeled prior data with optimistic rewards, and then uses it concurrently\nalongside the online data for downstream policy and critic optimization. This\ngeneral formula leads to rapid exploration in several challenging sparse-reward\ndomains where tabula rasa exploration is insufficient, including the AntMaze\ndomain, Adroit hand manipulation domain, and a visual simulated robotic\nmanipulation domain. Our results highlight the ease of incorporating unlabeled\nprior data into existing online RL algorithms, and the (perhaps surprising)\neffectiveness of doing so.\n","authors":["Qiyang Li","Jason Zhang","Dibya Ghosh","Amy Zhang","Sergey Levine"],"pdf_url":"https://arxiv.org/pdf/2311.05067v2.pdf","comment":"25 pages, 16 figures, 37th Conference on Neural Information\n  Processing Systems (NeurIPS 2023)"},{"id":"http://arxiv.org/abs/2311.12261v1","updated":"2023-11-21T00:45:13Z","published":"2023-11-21T00:45:13Z","title":"Beyond Simulated Drivers: Evaluating the Impact of Real-World\n  Car-Following in Mixed Traffic Control","summary":"  Human-driven vehicles can amplify naturally occurring perturbations in\ntraffic, leading to congestion and consequently increased fuel consumption,\nhigher collision risks, and reduced capacity utilization. While previous\nresearch has highlighted that a fraction of Robot Vehicles (RVs) can mitigate\nthese issues, they often rely on simulations with simplistic, model-based\nHuman-driven Vehicles (HVs) during car-following scenarios. Diverging from this\ntrend, in this study, we analyze real-world human driving trajectories,\nextracting a wide range of acceleration behaviors during car-following. We then\nincorporate these behaviors in simulation where RVs from prior studies are\nemployed to mitigate congestion, and evaluate their safety, efficiency, and\nstability. Further, we also introduce a reinforcement learning based RV that\nutilizes a congestion stage classifier neural network to optimize either\n\"safety+stability\" or \"efficiency\" in the presence of the diverse human driving\nbehaviors. We evaluate the proposed RVs in two different mixed traffic control\nenvironments at various densities, configurations, and penetration rates and\ncompare with the existing RVs.\n","authors":["Bibek Poudel","Weizi Li"],"pdf_url":"https://arxiv.org/pdf/2311.12261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12255v1","updated":"2023-11-21T00:34:53Z","published":"2023-11-21T00:34:53Z","title":"Exploring Time Granularity on Temporal Graphs for Dynamic Link\n  Prediction in Real-world Networks","summary":"  Dynamic Graph Neural Networks (DGNNs) have emerged as the predominant\napproach for processing dynamic graph-structured data. However, the influence\nof temporal information on model performance and robustness remains\ninsufficiently explored, particularly regarding how models address prediction\ntasks with different time granularities. In this paper, we explore the impact\nof time granularity when training DGNNs on dynamic graphs through extensive\nexperiments. We examine graphs derived from various domains and compare three\ndifferent DGNNs to the baseline model across four varied time granularities. We\nmainly consider the interplay between time granularities, model architectures,\nand negative sampling strategies to obtain general conclusions. Our results\nreveal that a sophisticated memory mechanism and proper time granularity are\ncrucial for a DGNN to deliver competitive and robust performance in the dynamic\nlink prediction task. We also discuss drawbacks in considered models and\ndatasets and propose promising directions for future research on the time\ngranularity of temporal graphs.\n","authors":["Xiangjian Jiang","Yanyi Pu"],"pdf_url":"https://arxiv.org/pdf/2311.12255v1.pdf","comment":"Presented at the Temporal Graph Learning Workshop @ NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.12253v1","updated":"2023-11-21T00:21:15Z","published":"2023-11-21T00:21:15Z","title":"The limitation of neural nets for approximation and optimization","summary":"  We are interested in assessing the use of neural networks as surrogate models\nto approximate and minimize objective functions in optimization problems. While\nneural networks are widely used for machine learning tasks such as\nclassification and regression, their application in solving optimization\nproblems has been limited. Our study begins by determining the best activation\nfunction for approximating the objective functions of popular nonlinear\noptimization test problems, and the evidence provided shows that~SiLU has the\nbest performance. We then analyze the accuracy of function value, gradient, and\nHessian approximations for such objective functions obtained through\ninterpolation/regression models and neural networks. When compared to\ninterpolation/regression models, neural networks can deliver competitive zero-\nand first-order approximations (at a high training cost) but underperform on\nsecond-order approximation. However, it is shown that combining a neural net\nactivation function with the natural basis for quadratic\ninterpolation/regression can waive the necessity of including cross terms in\nthe natural basis, leading to models with fewer parameters to determine.\nLastly, we provide evidence that the performance of a state-of-the-art\nderivative-free optimization algorithm can hardly be improved when the gradient\nof an objective function is approximated using any of the surrogate models\nconsidered, including neural networks.\n","authors":["Tommaso Giovannelli","Oumaima Sohab","Luis Nunes Vicente"],"pdf_url":"https://arxiv.org/pdf/2311.12253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13059v1","updated":"2023-11-21T23:46:44Z","published":"2023-11-21T23:46:44Z","title":"A note on estimating the dimension from a random geometric graph","summary":"  Let $G_n$ be a random geometric graph with vertex set $[n]$ based on $n$\ni.i.d.\\ random vectors $X_1,\\ldots,X_n$ drawn from an unknown density $f$ on\n$\\R^d$. An edge $(i,j)$ is present when $\\|X_i -X_j\\| \\le r_n$, for a given\nthreshold $r_n$ possibly depending upon $n$, where $\\| \\cdot \\|$ denotes\nEuclidean distance. We study the problem of estimating the dimension $d$ of the\nunderlying space when we have access to the adjacency matrix of the graph but\ndo not know $r_n$ or the vectors $X_i$. The main result of the paper is that\nthere exists an estimator of $d$ that converges to $d$ in probability as $n \\to\n\\infty$ for all densities with $\\int f^5 < \\infty$ whenever $n^{3/2} r_n^d \\to\n\\infty$ and $r_n = o(1)$. The conditions allow very sparse graphs since when\n$n^{3/2} r_n^d \\to 0$, the graph contains isolated edges only, with high\nprobability. We also show that, without any condition on the density, a\nconsistent estimator of $d$ exists when $n r_n^d \\to \\infty$ and $r_n = o(1)$.\n","authors":["Caelan Atamanchuk","Luc Devroye","Gabor Lugosi"],"pdf_url":"https://arxiv.org/pdf/2311.13059v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.17301v2","updated":"2023-11-21T23:42:55Z","published":"2023-06-29T20:58:48Z","title":"Why Shallow Networks Struggle with Approximating and Learning High\n  Frequency: A Numerical Study","summary":"  In this work, a comprehensive numerical study involving analysis and\nexperiments shows why a two-layer neural network has difficulties handling high\nfrequencies in approximation and learning when machine precision and\ncomputation cost are important factors in real practice. In particular, the\nfollowing basic computational issues are investigated: (1) the minimal\nnumerical error one can achieve given a finite machine precision, (2) the\ncomputation cost to achieve a given accuracy, and (3) stability with respect to\nperturbations. The key to the study is the conditioning of the representation\nand its learning dynamics. Explicit answers to the above questions with\nnumerical verifications are presented.\n","authors":["Shijun Zhang","Hongkai Zhao","Yimin Zhong","Haomin Zhou"],"pdf_url":"https://arxiv.org/pdf/2306.17301v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13052v1","updated":"2023-11-21T23:25:04Z","published":"2023-11-21T23:25:04Z","title":"Novel OCT mosaicking pipeline with Feature- and Pixel-based registration","summary":"  High-resolution Optical Coherence Tomography (OCT) images are crucial for\nophthalmology studies but are limited by their relatively narrow field of view\n(FoV). Image mosaicking is a technique for aligning multiple overlapping images\nto obtain a larger FoV. Current mosaicking pipelines often struggle with\nsubstantial noise and considerable displacement between the input sub-fields.\nIn this paper, we propose a versatile pipeline for stitching multi-view\nOCT/OCTA \\textit{en face} projection images. Our method combines the strengths\nof learning-based feature matching and robust pixel-based registration to align\nmultiple images effectively. Furthermore, we advance the application of a\ntrained foundational model, Segment Anything Model (SAM), to validate\nmosaicking results in an unsupervised manner. The efficacy of our pipeline is\nvalidated using an in-house dataset and a large public dataset, where our\nmethod shows superior performance in terms of both accuracy and computational\nefficiency. We also made our evaluation tool for image mosaicking and the\ncorresponding pipeline publicly available at\n\\url{https://github.com/MedICL-VU/OCT-mosaicking}.\n","authors":["Jiacheng Wang","Hao Li","Dewei Hu","Yuankai K. Tao","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2311.13052v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.16020v2","updated":"2023-11-21T23:23:08Z","published":"2023-09-27T20:54:56Z","title":"GeoCLIP: Clip-Inspired Alignment between Locations and Images for\n  Effective Worldwide Geo-localization","summary":"  Worldwide Geo-localization aims to pinpoint the precise location of images\ntaken anywhere on Earth. This task has considerable challenges due to immense\nvariation in geographic landscapes. The image-to-image retrieval-based\napproaches fail to solve this problem on a global scale as it is not feasible\nto construct a large gallery of images covering the entire world. Instead,\nexisting approaches divide the globe into discrete geographic cells,\ntransforming the problem into a classification task. However, their performance\nis limited by the predefined classes and often results in inaccurate\nlocalizations when an image's location significantly deviates from its class\ncenter. To overcome these limitations, we propose GeoCLIP, a novel\nCLIP-inspired Image-to-GPS retrieval approach that enforces alignment between\nthe image and its corresponding GPS locations. GeoCLIP's location encoder\nmodels the Earth as a continuous function by employing positional encoding\nthrough random Fourier features and constructing a hierarchical representation\nthat captures information at varying resolutions to yield a semantically rich\nhigh-dimensional feature suitable to use even beyond geo-localization. To the\nbest of our knowledge, this is the first work employing GPS encoding for\ngeo-localization. We demonstrate the efficacy of our method via extensive\nexperiments and ablations on benchmark datasets. We achieve competitive\nperformance with just 20% of training data, highlighting its effectiveness even\nin limited-data settings. Furthermore, we qualitatively demonstrate\ngeo-localization using a text query by leveraging CLIP backbone of our image\nencoder. The project webpage is available at:\nhttps://vicentevivan.github.io/GeoCLIP\n","authors":["Vicente Vivanco Cepeda","Gaurav Kumar Nayak","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2309.16020v2.pdf","comment":"Accepted at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.13050v1","updated":"2023-11-21T23:22:11Z","published":"2023-11-21T23:22:11Z","title":"Multi-fidelity Bayesian Optimization in Engineering Design","summary":"  Resided at the intersection of multi-fidelity optimization (MFO) and Bayesian\noptimization (BO), MF BO has found a niche in solving expensive engineering\ndesign optimization problems, thanks to its advantages in incorporating\nphysical and mathematical understandings of the problems, saving resources,\naddressing exploitation-exploration trade-off, considering uncertainty, and\nprocessing parallel computing. The increasing number of works dedicated to MF\nBO suggests the need for a comprehensive review of this advanced optimization\ntechnique. In this paper, we survey recent developments of two essential\ningredients of MF BO: Gaussian process (GP) based MF surrogates and acquisition\nfunctions. We first categorize the existing MF modeling methods and MFO\nstrategies to locate MF BO in a large family of surrogate-based optimization\nand MFO algorithms. We then exploit the common properties shared between the\nmethods from each ingredient of MF BO to describe important GP-based MF\nsurrogate models and review various acquisition functions. By doing so, we\nexpect to provide a structured understanding of MF BO. Finally, we attempt to\nreveal important aspects that require further research for applications of MF\nBO in solving intricate yet important design optimization problems, including\nconstrained optimization, high-dimensional optimization, optimization under\nuncertainty, and multi-objective optimization.\n","authors":["Bach Do","Ruda Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.13050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13046v1","updated":"2023-11-21T23:14:47Z","published":"2023-11-21T23:14:47Z","title":"Do we listen to what we are told? An empirical study on human behaviour\n  during the COVID-19 pandemic: neural networks vs. regression analysis","summary":"  In this work, we contribute the first visual open-source empirical study on\nhuman behaviour during the COVID-19 pandemic, in order to investigate how\ncompliant a general population is to mask-wearing-related public-health policy.\nObject-detection-based convolutional neural networks, regression analysis and\nmultilayer perceptrons are combined to analyse visual data of the Viennese\npublic during 2020. We find that mask-wearing-related government regulations\nand public-transport announcements encouraged correct mask-wearing-behaviours\nduring the COVID-19 pandemic. Importantly, changes in announcement and\nregulation contents led to heterogeneous effects on people's behaviour.\nComparing the predictive power of regression analysis and neural networks, we\ndemonstrate that the latter produces more accurate predictions of population\nreactions during the COVID-19 pandemic. Our use of regression modelling also\nallows us to unearth possible causal pathways underlying societal behaviour.\nSince our findings highlight the importance of appropriate communication\ncontents, our results will facilitate more effective non-pharmaceutical\ninterventions to be developed in future. Adding to the literature, we\ndemonstrate that regression modelling and neural networks are not mutually\nexclusive but instead complement each other.\n","authors":["Yuxi Heluo","Kexin Wang","Charles W. Robson"],"pdf_url":"https://arxiv.org/pdf/2311.13046v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.13933v2","updated":"2023-11-21T23:06:51Z","published":"2022-08-30T00:08:37Z","title":"Using Taylor-Approximated Gradients to Improve the Frank-Wolfe Method\n  for Empirical Risk Minimization","summary":"  The Frank-Wolfe method has become increasingly useful in statistical and\nmachine learning applications, due to the structure-inducing properties of the\niterates, and especially in settings where linear minimization over the\nfeasible set is more computationally efficient than projection. In the setting\nof Empirical Risk Minimization -- one of the fundamental optimization problems\nin statistical and machine learning -- the computational effectiveness of\nFrank-Wolfe methods typically grows linearly in the number of data observations\n$n$. This is in stark contrast to the case for typical stochastic projection\nmethods. In order to reduce this dependence on $n$, we look to second-order\nsmoothness of typical smooth loss functions (least squares loss and logistic\nloss, for example) and we propose amending the Frank-Wolfe method with Taylor\nseries-approximated gradients, including variants for both deterministic and\nstochastic settings. Compared with current state-of-the-art methods in the\nregime where the optimality tolerance $\\varepsilon$ is sufficiently small, our\nmethods are able to simultaneously reduce the dependence on large $n$ while\nobtaining optimal convergence rates of Frank-Wolfe methods, in both the convex\nand non-convex settings. We also propose a novel adaptive step-size approach\nfor which we have computational guarantees. Last of all, we present\ncomputational experiments which show that our methods exhibit very significant\nspeed-ups over existing methods on real-world datasets for both convex and\nnon-convex binary classification problems.\n","authors":["Zikai Xiong","Robert M. Freund"],"pdf_url":"https://arxiv.org/pdf/2208.13933v2.pdf","comment":"30 pages, 2 figures"},{"id":"http://arxiv.org/abs/2311.10242v2","updated":"2023-11-21T23:01:29Z","published":"2023-11-17T00:08:19Z","title":"Advancements in Generative AI: A Comprehensive Review of GANs, GPT,\n  Autoencoders, Diffusion Model, and Transformers","summary":"  The launch of ChatGPT has garnered global attention, marking a significant\nmilestone in the field of Generative Artificial Intelligence. While Generative\nAI has been in effect for the past decade, the introduction of ChatGPT has\nignited a new wave of research and innovation in the AI domain. This surge in\ninterest has led to the development and release of numerous cutting-edge tools,\nsuch as Bard, Stable Diffusion, DALL-E, Make-A-Video, Runway ML, and Jukebox,\namong others. These tools exhibit remarkable capabilities, encompassing tasks\nranging from text generation and music composition, image creation, video\nproduction, code generation, and even scientific work. They are built upon\nvarious state-of-the-art models, including Stable Diffusion, transformer models\nlike GPT-3 (recent GPT-4), variational autoencoders, and generative adversarial\nnetworks. This advancement in Generative AI presents a wealth of exciting\nopportunities and, simultaneously, unprecedented challenges. Throughout this\npaper, we have explored these state-of-the-art models, the diverse array of\ntasks they can accomplish, the challenges they pose, and the promising future\nof Generative Artificial Intelligence.\n","authors":["Staphord Bengesi","Hoda El-Sayed","Md Kamruzzaman Sarker","Yao Houkpati","John Irungu","Timothy Oladunni"],"pdf_url":"https://arxiv.org/pdf/2311.10242v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13038v1","updated":"2023-11-21T22:56:13Z","published":"2023-11-21T22:56:13Z","title":"Synaptic Sampling of Neural Networks","summary":"  Probabilistic artificial neural networks offer intriguing prospects for\nenabling the uncertainty of artificial intelligence methods to be described\nexplicitly in their function; however, the development of techniques that\nquantify uncertainty by well-understood methods such as Monte Carlo sampling\nhas been limited by the high costs of stochastic sampling on deterministic\ncomputing hardware. Emerging computing systems that are amenable to\nhardware-level probabilistic computing, such as those that leverage stochastic\ndevices, may make probabilistic neural networks more feasible in the\nnot-too-distant future. This paper describes the scANN technique --\n\\textit{sampling (by coinflips) artificial neural networks} -- which enables\nneural networks to be sampled directly by treating the weights as Bernoulli\ncoin flips. This method is natively well suited for probabilistic computing\ntechniques that focus on tunable stochastic devices, nearly matches fully\ndeterministic performance while also describing the uncertainty of correct and\nincorrect neural network outputs.\n","authors":["James B. Aimone","William Severa","J. Darby Smith"],"pdf_url":"https://arxiv.org/pdf/2311.13038v1.pdf","comment":"9 pages, accepted to 2023 IEEE International Conference on Rebooting\n  Computing"},{"id":"http://arxiv.org/abs/2311.13036v1","updated":"2023-11-21T22:53:20Z","published":"2023-11-21T22:53:20Z","title":"Favour: FAst Variance Operator for Uncertainty Rating","summary":"  Bayesian Neural Networks (BNN) have emerged as a crucial approach for\ninterpreting ML predictions. By sampling from the posterior distribution, data\nscientists may estimate the uncertainty of an inference. Unfortunately many\ninference samples are often needed, the overhead of which greatly hinder BNN's\nwide adoption. To mitigate this, previous work proposed propagating the first\nand second moments of the posterior directly through the network. However, on\nits own this method is even slower than sampling, so the propagated variance\nneeds to be approximated such as assuming independence between neural nodes.\nThe resulting trade-off between quality and inference time did not match even\nplain Monte Carlo sampling.\n  Our contribution is a more principled variance propagation framework based on\n\"spiked covariance matrices\", which smoothly interpolates between quality and\ninference time. This is made possible by a new fast algorithm for updating a\ndiagonal-plus-low-rank matrix approximation under various operations. We tested\nour algorithm against sampling based MC Dropout and Variational Inference on a\nnumber of downstream uncertainty themed tasks, such as calibration and\nout-of-distribution testing. We find that Favour is as fast as performing 2-3\ninference samples, while matching the performance of 10-100 samples.\n  In summary, this work enables the use of BNN in the realm of performance\ncritical tasks where they have previously been out of reach.\n","authors":["Thomas D. Ahle","Sahar Karimi","Peter Tak Peter Tang"],"pdf_url":"https://arxiv.org/pdf/2311.13036v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.08549v3","updated":"2023-11-21T22:49:27Z","published":"2023-09-15T17:12:19Z","title":"HINT: Healthy Influential-Noise based Training to Defend against Data\n  Poisoning Attacks","summary":"  While numerous defense methods have been proposed to prohibit potential\npoisoning attacks from untrusted data sources, most research works only defend\nagainst specific attacks, which leaves many avenues for an adversary to\nexploit. In this work, we propose an efficient and robust training approach to\ndefend against data poisoning attacks based on influence functions, named\nHealthy Influential-Noise based Training. Using influence functions, we craft\nhealthy noise that helps to harden the classification model against poisoning\nattacks without significantly affecting the generalization ability on test\ndata. In addition, our method can perform effectively when only a subset of the\ntraining data is modified, instead of the current method of adding noise to all\nexamples that has been used in several previous works. We conduct comprehensive\nevaluations over two image datasets with state-of-the-art poisoning attacks\nunder different realistic attack scenarios. Our empirical results show that\nHINT can efficiently protect deep learning models against the effect of both\nuntargeted and targeted poisoning attacks.\n","authors":["Minh-Hao Van","Alycia N. Carey","Xintao Wu"],"pdf_url":"https://arxiv.org/pdf/2309.08549v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.11280v2","updated":"2023-11-21T22:35:18Z","published":"2023-07-21T00:49:07Z","title":"Epsilon*: Privacy Metric for Machine Learning Models","summary":"  We introduce Epsilon*, a new privacy metric for measuring the privacy risk of\na single model instance prior to, during, or after deployment of privacy\nmitigation strategies. The metric requires only black-box access to model\npredictions, does not require training data re-sampling or model re-training,\nand can be used to measure the privacy risk of models not trained with\ndifferential privacy. Epsilon* is a function of true positive and false\npositive rates in a hypothesis test used by an adversary in a membership\ninference attack. We distinguish between quantifying the privacy loss of a\ntrained model instance, which we refer to as empirical privacy, and quantifying\nthe privacy loss of the training mechanism which produces this model instance.\nExisting approaches in the privacy auditing literature provide lower bounds for\nthe latter, while our metric provides an empirical lower bound for the former\nby relying on an (${\\epsilon}$, ${\\delta}$)-type of quantification of the\nprivacy of the trained model instance. We establish a relationship between\nthese lower bounds and show how to implement Epsilon* to avoid numerical and\nnoise amplification instability. We further show in experiments on benchmark\npublic data sets that Epsilon* is sensitive to privacy risk mitigation by\ntraining with differential privacy (DP), where the value of Epsilon* is reduced\nby up to 800% compared to the Epsilon* values of non-DP trained baseline\nmodels. This metric allows privacy auditors to be independent of model owners,\nand enables visualizing the privacy-utility landscape to make informed\ndecisions regarding the trade-offs between model privacy and utility.\n","authors":["Diana M. Negoescu","Humberto Gonzalez","Saad Eddin Al Orjany","Jilei Yang","Yuliia Lut","Rahul Tandra","Xiaowen Zhang","Xinyi Zheng","Zach Douglas","Vidita Nolkha","Parvez Ahammad","Gennady Samorodnitsky"],"pdf_url":"https://arxiv.org/pdf/2307.11280v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13028v1","updated":"2023-11-21T22:29:25Z","published":"2023-11-21T22:29:25Z","title":"DMLR: Data-centric Machine Learning Research -- Past, Present and Future","summary":"  Drawing from discussions at the inaugural DMLR workshop at ICML 2023 and\nmeetings prior, in this report we outline the relevance of community engagement\nand infrastructure development for the creation of next-generation public\ndatasets that will advance machine learning science. We chart a path forward as\na collective effort to sustain the creation and maintenance of these datasets\nand methods towards positive scientific, societal and business impact.\n","authors":["Luis Oala","Manil Maskey","Lilith Bat-Leah","Alicia Parrish","Nezihe Merve Gürel","Tzu-Sheng Kuo","Yang Liu","Rotem Dror","Danilo Brajovic","Xiaozhe Yao","Max Bartolo","William A Gaviria Rojas","Ryan Hileman","Rainier Aliment","Michael W. Mahoney","Meg Risdal","Matthew Lease","Wojciech Samek","Debojyoti Dutta","Curtis G Northcutt","Cody Coleman","Braden Hancock","Bernard Koch","Girmaw Abebe Tadesse","Bojan Karlaš","Ahmed Alaa","Adji Bousso Dieng","Natasha Noy","Vijay Janapa Reddi","James Zou","Praveen Paritosh","Mihaela van der Schaar","Kurt Bollacker","Lora Aroyo","Ce Zhang","Joaquin Vanschoren","Isabelle Guyon","Peter Mattson"],"pdf_url":"https://arxiv.org/pdf/2311.13028v1.pdf","comment":"This editorial report accompanies the inaugural Data-centric Machine\n  Learning Research (DMLR) Workshop that took place at ICML 2023\n  https://dmlr.ai/"},{"id":"http://arxiv.org/abs/2310.15290v2","updated":"2023-11-21T22:19:09Z","published":"2023-10-23T18:56:01Z","title":"Reliable Generation of EHR Time Series via Diffusion Models","summary":"  Electronic Health Records (EHRs) are rich sources of patient-level data,\nincluding laboratory tests, medications, and diagnoses, offering valuable\nresources for medical data analysis. However, concerns about privacy often\nrestrict access to EHRs, hindering downstream analysis. Researchers have\nexplored various methods for generating privacy-preserving EHR data. In this\nstudy, we introduce a new method for generating diverse and realistic synthetic\nEHR time series data using Denoising Diffusion Probabilistic Models (DDPM). We\nconducted experiments on six datasets, comparing our proposed method with eight\nexisting methods. Our results demonstrate that our approach significantly\noutperforms all existing methods in terms of data utility while requiring less\ntraining effort. Our approach also enhances downstream medical data analysis by\nproviding diverse and realistic synthetic EHR data.\n","authors":["Muhang Tian","Bernie Chen","Allan Guo","Shiyi Jiang","Anru R. Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.15290v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.01897v2","updated":"2023-11-21T22:08:41Z","published":"2023-09-05T02:15:08Z","title":"Inferring Actual Treatment Pathways from Patient Records","summary":"  Treatment pathways are step-by-step plans outlining the recommended medical\ncare for specific diseases; they get revised when different treatments are\nfound to improve patient outcomes. Examining health records is an important\npart of this revision process, but inferring patients' actual treatments from\nhealth data is challenging due to complex event-coding schemes and the absence\nof pathway-related annotations. This study aims to infer the actual treatment\nsteps for a particular patient group from administrative health records (AHR) -\na common form of tabular healthcare data - and address several technique- and\nmethodology-based gaps in treatment pathway-inference research. We introduce\nDefrag, a method for examining AHRs to infer the real-world treatment steps for\na particular patient group. Defrag learns the semantic and temporal meaning of\nhealthcare event sequences, allowing it to reliably infer treatment steps from\ncomplex healthcare data. To our knowledge, Defrag is the first\npathway-inference method to utilise a neural network (NN), an approach made\npossible by a novel, self-supervised learning objective. We also developed a\ntesting and validation framework for pathway inference, which we use to\ncharacterise and evaluate Defrag's pathway inference ability and compare\nagainst baselines. We demonstrate Defrag's effectiveness by identifying\nbest-practice pathway fragments for breast cancer, lung cancer, and melanoma in\npublic healthcare records. Additionally, we use synthetic data experiments to\ndemonstrate the characteristics of the Defrag method, and to compare Defrag to\nseveral baselines where it significantly outperforms non-NN-based methods.\nDefrag significantly outperforms several existing pathway-inference methods and\noffers an innovative and effective approach for inferring treatment pathways\nfrom AHRs. Open-source code is provided to encourage further research in this\narea.\n","authors":["Adrian Wilkins-Caruana","Madhushi Bandara","Katarzyna Musial","Daniel Catchpoole","Paul J. Kennedy"],"pdf_url":"https://arxiv.org/pdf/2309.01897v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03357v2","updated":"2023-11-21T22:05:37Z","published":"2023-07-07T02:40:09Z","title":"Stability and Generalization of Stochastic Compositional Gradient\n  Descent Algorithms","summary":"  Many machine learning tasks can be formulated as a stochastic compositional\noptimization (SCO) problem such as reinforcement learning, AUC maximization,\nand meta-learning, where the objective function involves a nested composition\nassociated with an expectation. While a significant amount of studies has been\ndevoted to studying the convergence behavior of SCO algorithms, there is little\nwork on understanding their generalization, i.e., how these learning algorithms\nbuilt from training examples would behave on future test examples. In this\npaper, we provide the stability and generalization analysis of stochastic\ncompositional gradient descent algorithms through the lens of algorithmic\nstability in the framework of statistical learning theory. Firstly, we\nintroduce a stability concept called compositional uniform stability and\nestablish its quantitative relation with generalization for SCO problems. Then,\nwe establish the compositional uniform stability results for two popular\nstochastic compositional gradient descent algorithms, namely SCGD and SCSC.\nFinally, we derive dimension-independent excess risk bounds for SCGD and SCSC\nby trade-offing their stability results and optimization errors. To the best of\nour knowledge, these are the first-ever-known results on stability and\ngeneralization analysis of stochastic compositional gradient descent\nalgorithms.\n","authors":["Ming Yang","Xiyuan Wei","Tianbao Yang","Yiming Ying"],"pdf_url":"https://arxiv.org/pdf/2307.03357v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13022v1","updated":"2023-11-21T22:05:00Z","published":"2023-11-21T22:05:00Z","title":"Unsupervised Multimodal Surface Registration with Geometric Deep\n  Learning","summary":"  This paper introduces GeoMorph, a novel geometric deep-learning framework\ndesigned for image registration of cortical surfaces. The registration process\nconsists of two main steps. First, independent feature extraction is performed\non each input surface using graph convolutions, generating low-dimensional\nfeature representations that capture important cortical surface\ncharacteristics. Subsequently, features are registered in a deep-discrete\nmanner to optimize the overlap of common structures across surfaces by learning\ndisplacements of a set of control points. To ensure smooth and biologically\nplausible deformations, we implement regularization through a deep conditional\nrandom field implemented with a recurrent neural network. Experimental results\ndemonstrate that GeoMorph surpasses existing deep-learning methods by achieving\nimproved alignment with smoother deformations. Furthermore, GeoMorph exhibits\ncompetitive performance compared to classical frameworks. Such versatility and\nrobustness suggest strong potential for various neuroscience applications.\n","authors":["Mohamed A. Suliman","Logan Z. J. Williams","Abdulah Fawaz","Emma C. Robinson"],"pdf_url":"https://arxiv.org/pdf/2311.13022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13015v1","updated":"2023-11-21T21:44:28Z","published":"2023-11-21T21:44:28Z","title":"Fast and Interpretable Mortality Risk Scores for Critical Care Patients","summary":"  Prediction of mortality in intensive care unit (ICU) patients is an important\ntask in critical care medicine. Prior work in creating mortality risk models\nfalls into two major categories: domain-expert-created scoring systems, and\nblack box machine learning (ML) models. Both of these have disadvantages: black\nbox models are unacceptable for use in hospitals, whereas manual creation of\nmodels (including hand-tuning of logistic regression parameters) relies on\nhumans to perform high-dimensional constrained optimization, which leads to a\nloss in performance. In this work, we bridge the gap between accurate black box\nmodels and hand-tuned interpretable models. We build on modern interpretable ML\ntechniques to design accurate and interpretable mortality risk scores. We\nleverage the largest existing public ICU monitoring datasets, namely the MIMIC\nIII and eICU datasets. By evaluating risk across medical centers, we are able\nto study generalization across domains. In order to customize our risk score\nmodels, we develop a new algorithm, GroupFasterRisk, which has several\nimportant benefits: (1) it uses hard sparsity constraint, allowing users to\ndirectly control the number of features; (2) it incorporates group sparsity to\nallow more cohesive models; (3) it allows for monotonicity correction on models\nfor including domain knowledge; (4) it produces many equally-good models at\nonce, which allows domain experts to choose among them. GroupFasterRisk creates\nits risk scores within hours, even on the large datasets we study here.\nGroupFasterRisk's risk scores perform better than risk scores currently used in\nhospitals, and have similar prediction performance to black box ML models\n(despite being much sparser). Because GroupFasterRisk produces a variety of\nrisk scores and handles constraints, it allows design flexibility, which is the\nkey enabler of practical and trustworthy model creation.\n","authors":["Chloe Qinyu Zhu","Muhang Tian","Lesia Semenova","Jiachang Liu","Jack Xu","Joseph Scarpa","Cynthia Rudin"],"pdf_url":"https://arxiv.org/pdf/2311.13015v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10747v2","updated":"2023-11-21T21:40:21Z","published":"2023-10-31T18:21:24Z","title":"Safety-aware Causal Representation for Trustworthy Reinforcement\n  Learning in Autonomous Driving","summary":"  In the domain of autonomous driving, the Learning from Demonstration (LfD)\nparadigm has exhibited notable efficacy in addressing sequential\ndecision-making problems. However, consistently achieving safety in varying\ntraffic contexts, especially in safety-critical scenarios, poses a significant\nchallenge due to the long-tailed and unforeseen scenarios absent from offline\ndatasets. In this paper, we introduce the saFety-aware strUctured Scenario\nrepresentatION (FUSION), a pioneering methodology conceived to facilitate the\nlearning of an adaptive end-to-end driving policy by leveraging structured\nscenario information. FUSION capitalizes on the causal relationships between\ndecomposed reward, cost, state, and action space, constructing a framework for\nstructured sequential reasoning under dynamic traffic environments. We conduct\nrigorous evaluations in two typical real-world settings of distribution shift\nin autonomous vehicles, demonstrating the good balance between safety cost and\nutility reward of FUSION compared to contemporary state-of-the-art safety-aware\nLfD baselines. Empirical evidence under diverse driving scenarios attests that\nFUSION significantly enhances the safety and generalizability of autonomous\ndriving agents, even in the face of challenging and unseen environments.\nFurthermore, our ablation studies reveal noticeable improvements in the\nintegration of causal representation into the safe offline RL problem.\n","authors":["Haohong Lin","Wenhao Ding","Zuxin Liu","Yaru Niu","Jiacheng Zhu","Yuming Niu","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.10747v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01012v2","updated":"2023-11-21T21:31:47Z","published":"2023-10-02T09:03:59Z","title":"Efficient Algorithms for the CCA Family: Unconstrained Objectives with\n  Unbiased Gradients","summary":"  The Canonical Correlation Analysis (CCA) family of methods is foundational in\nmulti-view learning. Regularised linear CCA methods can be seen to generalise\nPartial Least Squares (PLS) and be unified with a Generalized Eigenvalue\nProblem (GEP) framework. However, classical algorithms for these linear methods\nare computationally infeasible for large-scale data. Extensions to Deep CCA\nshow great promise, but current training procedures are slow and complicated.\nFirst we propose a novel unconstrained objective that characterizes the top\nsubspace of GEPs. Our core contribution is a family of fast algorithms for\nstochastic PLS, stochastic CCA, and Deep CCA, simply obtained by applying\nstochastic gradient descent (SGD) to the corresponding CCA objectives. These\nmethods show far faster convergence and recover higher correlations than the\nprevious state-of-the-art on all standard CCA and Deep CCA benchmarks. This\nspeed allows us to perform a first-of-its-kind PLS analysis of an extremely\nlarge biomedical dataset from the UK Biobank, with over 33,000 individuals and\n500,000 variants. Finally, we not only match the performance of `CCA-family'\nSelf-Supervised Learning (SSL) methods on CIFAR-10 and CIFAR-100 with minimal\nhyper-parameter tuning, but also establish the first solid theoretical links to\nclassical CCA, laying the groundwork for future insights.\n","authors":["James Chapman","Lennie Wells","Ana Lawry Aguila"],"pdf_url":"https://arxiv.org/pdf/2310.01012v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12999v1","updated":"2023-11-21T21:19:59Z","published":"2023-11-21T21:19:59Z","title":"CovarNav: Machine Unlearning via Model Inversion and Covariance\n  Navigation","summary":"  The rapid progress of AI, combined with its unprecedented public adoption and\nthe propensity of large neural networks to memorize training data, has given\nrise to significant data privacy concerns. To address these concerns, machine\nunlearning has emerged as an essential technique to selectively remove the\ninfluence of specific training data points on trained models. In this paper, we\napproach the machine unlearning problem through the lens of continual learning.\nGiven a trained model and a subset of training data designated to be forgotten\n(i.e., the \"forget set\"), we introduce a three-step process, named CovarNav, to\nfacilitate this forgetting. Firstly, we derive a proxy for the model's training\ndata using a model inversion attack. Secondly, we mislabel the forget set by\nselecting the most probable class that deviates from the actual ground truth.\nLastly, we deploy a gradient projection method to minimize the cross-entropy\nloss on the modified forget set (i.e., learn incorrect labels for this set)\nwhile preventing forgetting of the inverted samples. We rigorously evaluate\nCovarNav on the CIFAR-10 and Vggface2 datasets, comparing our results with\nrecent benchmarks in the field and demonstrating the efficacy of our proposed\napproach.\n","authors":["Ali Abbasi","Chayne Thrash","Elaheh Akbari","Daniel Zhang","Soheil Kolouri"],"pdf_url":"https://arxiv.org/pdf/2311.12999v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12997v1","updated":"2023-11-21T21:16:54Z","published":"2023-11-21T21:16:54Z","title":"How Capable Can a Transformer Become? A Study on Synthetic,\n  Interpretable Tasks","summary":"  Transformers trained on huge text corpora exhibit a remarkable set of\ncapabilities, e.g., performing simple logical operations. Given the inherent\ncompositional nature of language, one can expect the model to learn to compose\nthese capabilities, potentially yielding a combinatorial explosion of what\noperations it can perform on an input. Motivated by the above, we aim to assess\nin this paper \"how capable can a transformer become?\". Specifically, we train\nautoregressive Transformer models on a data-generating process that involves\ncompositions of a set of well-defined monolithic capabilities. Through a series\nof extensive and systematic experiments on this data-generating process, we\nshow that: (1) autoregressive Transformers can learn compositional structures\nfrom the training data and generalize to exponentially or even combinatorially\nmany functions; (2) composing functions by generating intermediate outputs is\nmore effective at generalizing to unseen compositions, compared to generating\nno intermediate outputs; (3) the training data has a significant impact on the\nmodel's ability to compose unseen combinations of functions; and (4) the\nattention layers in the latter half of the model are critical to\ncompositionality.\n","authors":["Rahul Ramesh","Mikail Khona","Robert P. Dick","Hidenori Tanaka","Ekdeep Singh Lubana"],"pdf_url":"https://arxiv.org/pdf/2311.12997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11819v2","updated":"2023-11-21T20:45:51Z","published":"2023-11-20T14:55:40Z","title":"Generalized super-resolution 4D Flow MRI $\\unicode{x2013}$ using\n  ensemble learning to extend across the cardiovascular system","summary":"  4D Flow Magnetic Resonance Imaging (4D Flow MRI) is a non-invasive\nmeasurement technique capable of quantifying blood flow across the\ncardiovascular system. While practical use is limited by spatial resolution and\nimage noise, incorporation of trained super-resolution (SR) networks has\npotential to enhance image quality post-scan. However, these efforts have\npredominantly been restricted to narrowly defined cardiovascular domains, with\nlimited exploration of how SR performance extends across the cardiovascular\nsystem; a task aggravated by contrasting hemodynamic conditions apparent across\nthe cardiovasculature. The aim of our study was to explore the generalizability\nof SR 4D Flow MRI using a combination of heterogeneous training sets and\ndedicated ensemble learning. With synthetic training data generated across\nthree disparate domains (cardiac, aortic, cerebrovascular), varying\nconvolutional base and ensemble learners were evaluated as a function of domain\nand architecture, quantifying performance on both in-silico and acquired\nin-vivo data from the same three domains. Results show that both bagging and\nstacking ensembling enhance SR performance across domains, accurately\npredicting high-resolution velocities from low-resolution input data in-silico.\nLikewise, optimized networks successfully recover native resolution velocities\nfrom downsampled in-vivo data, as well as show qualitative potential in\ngenerating denoised SR-images from clinical level input data. In conclusion,\nour work presents a viable approach for generalized SR 4D Flow MRI, with\nensemble learning extending utility across various clinical areas of interest.\n","authors":["Leon Ericsson","Adam Hjalmarsson","Muhammad Usman Akbar","Edward Ferdian","Mia Bonini","Brandon Hardy","Jonas Schollenberger","Maria Aristova","Patrick Winter","Nicholas Burris","Alexander Fyrdahl","Andreas Sigfridsson","Susanne Schnell","C. Alberto Figueroa","David Nordsletten","Alistair A. Young","David Marlevi"],"pdf_url":"https://arxiv.org/pdf/2311.11819v2.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.11381v3","updated":"2023-11-21T20:17:40Z","published":"2023-02-22T13:55:08Z","title":"Optimal Convergence Rate for Exact Policy Mirror Descent in Discounted\n  Markov Decision Processes","summary":"  Policy Mirror Descent (PMD) is a general family of algorithms that covers a\nwide range of novel and fundamental methods in reinforcement learning.\nMotivated by the instability of policy iteration (PI) with inexact policy\nevaluation, PMD algorithmically regularises the policy improvement step of PI.\nWith exact policy evaluation, PI is known to converge linearly with a rate\ngiven by the discount factor $\\gamma$ of a Markov Decision Process. In this\nwork, we bridge the gap between PI and PMD with exact policy evaluation and\nshow that the dimension-free $\\gamma$-rate of PI can be achieved by the general\nfamily of unregularised PMD algorithms under an adaptive step-size. We show\nthat both the rate and step-size are unimprovable for PMD: we provide matching\nlower bounds that demonstrate that the $\\gamma$-rate is optimal for PMD methods\nas well as PI, and that the adaptive step-size is necessary for PMD to achieve\nit. Our work is the first to relate PMD to rate-optimality and step-size\nnecessity. Our study of the convergence of PMD avoids the use of the\nperformance difference lemma, which leads to a direct analysis of independent\ninterest. We also extend the analysis to the inexact setting and establish the\nfirst dimension-optimal sample complexity for unregularised PMD under a\ngenerative model, improving upon the best-known result.\n","authors":["Emmeran Johnson","Ciara Pike-Burke","Patrick Rebeschini"],"pdf_url":"https://arxiv.org/pdf/2302.11381v3.pdf","comment":"Accepted at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.00474v2","updated":"2023-11-21T20:16:57Z","published":"2023-11-01T12:17:05Z","title":"Diffusion models for probabilistic programming","summary":"  We propose Diffusion Model Variational Inference (DMVI), a novel method for\nautomated approximate inference in probabilistic programming languages (PPLs).\nDMVI utilizes diffusion models as variational approximations to the true\nposterior distribution by deriving a novel bound to the marginal likelihood\nobjective used in Bayesian modelling. DMVI is easy to implement, allows\nhassle-free inference in PPLs without the drawbacks of, e.g., variational\ninference using normalizing flows, and does not make any constraints on the\nunderlying neural network model. We evaluate DMVI on a set of common Bayesian\nmodels and show that its posterior inferences are in general more accurate than\nthose of contemporary methods used in PPLs while having a similar computational\ncost and requiring less manual tuning.\n","authors":["Simon Dirmeier","Fernando Perez-Cruz"],"pdf_url":"https://arxiv.org/pdf/2311.00474v2.pdf","comment":"* Fix mathematical typos * Add conference info"},{"id":"http://arxiv.org/abs/2311.12970v1","updated":"2023-11-21T20:16:02Z","published":"2023-11-21T20:16:02Z","title":"Clustered Policy Decision Ranking","summary":"  Policies trained via reinforcement learning (RL) are often very complex even\nfor simple tasks. In an episode with n time steps, a policy will make n\ndecisions on actions to take, many of which may appear non-intuitive to the\nobserver. Moreover, it is not clear which of these decisions directly\ncontribute towards achieving the reward and how significant their contribution\nis. Given a trained policy, we propose a black-box method based on statistical\ncovariance estimation that clusters the states of the environment and ranks\neach cluster according to the importance of decisions made in its states. We\ncompare our measure against a previous statistical fault localization based\nranking procedure.\n","authors":["Mark Levin","Hana Chockler"],"pdf_url":"https://arxiv.org/pdf/2311.12970v1.pdf","comment":"4 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:2111.08415"},{"id":"http://arxiv.org/abs/2311.12956v1","updated":"2023-11-21T19:49:13Z","published":"2023-11-21T19:49:13Z","title":"Innovative Horizons in Aerial Imagery: LSKNet Meets DiffusionDet for\n  Advanced Object Detection","summary":"  In the realm of aerial image analysis, object detection plays a pivotal role,\nwith significant implications for areas such as remote sensing, urban planning,\nand disaster management. This study addresses the inherent challenges in this\ndomain, notably the detection of small objects, managing densely packed\nelements, and accounting for diverse orientations. We present an in-depth\nevaluation of an object detection model that integrates the Large Selective\nKernel Network (LSKNet)as its backbone with the DiffusionDet head, utilizing\nthe iSAID dataset for empirical analysis. Our approach encompasses the\nintroduction of novel methodologies and extensive ablation studies. These\nstudies critically assess various aspects such as loss functions, box\nregression techniques, and classification strategies to refine the model's\nprecision in object detection. The paper details the experimental application\nof the LSKNet backbone in synergy with the DiffusionDet heads, a combination\ntailored to meet the specific challenges in aerial image object detection. The\nfindings of this research indicate a substantial enhancement in the model's\nperformance, especially in the accuracy-time tradeoff. The proposed model\nachieves a mean average precision (MAP) of approximately 45.7%, which is a\nsignificant improvement, outperforming the RCNN model by 4.7% on the same\ndataset. This advancement underscores the effectiveness of the proposed\nmodifications and sets a new benchmark in aerial image analysis, paving the way\nfor more accurate and efficient object detection methodologies. The code is\npublicly available at https://github.com/SashaMatsun/LSKDiffDet\n","authors":["Ahmed Sharshar","Aleksandr Matsun"],"pdf_url":"https://arxiv.org/pdf/2311.12956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.13536v2","updated":"2023-11-21T19:36:07Z","published":"2023-05-22T23:19:45Z","title":"Subspace-Configurable Networks","summary":"  While the deployment of deep learning models on edge devices is increasing,\nthese models often lack robustness when faced with dynamic changes in sensed\ndata. This can be attributed to sensor drift, or variations in the data\ncompared to what was used during offline training due to factors such as\nspecific sensor placement or naturally changing sensing conditions. Hence,\nachieving the desired robustness necessitates the utilization of either an\ninvariant architecture or specialized training approaches, like data\naugmentation. Alternatively, input transformations can be treated as a domain\nshift problem, and solved by post-deployment model adaptation. In this paper,\nwe train a parameterized subspace of configurable networks, where an optimal\nnetwork for a particular parameter setting is part of this subspace. The\nobtained subspace is low-dimensional and has a surprisingly simple structure\neven for complex, non-invertible transformations of the input, leading to an\nexceptionally high efficiency of subspace-configurable networks (SCNs) when\nlimited storage and computing resources are at stake. We evaluate SCNs on a\nwide range of standard datasets, architectures, and transformations, and\ndemonstrate their power on resource-constrained IoT devices, where they can\ntake up to 2.4 times less RAM and be 7.6 times faster at inference time than a\nmodel that achieves the same test set accuracy, yet is trained with data\naugmentations to cover the desired range of input transformations.\n","authors":["Olga Saukh","Dong Wang","Xiaoxi He","Lothar Thiele"],"pdf_url":"https://arxiv.org/pdf/2305.13536v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05326v3","updated":"2023-11-21T19:33:57Z","published":"2023-01-20T23:17:48Z","title":"Scalable Real-Time Recurrent Learning Using Columnar-Constructive\n  Networks","summary":"  Constructing states from sequences of observations is an important component\nof reinforcement learning agents. One solution for state construction is to use\nrecurrent neural networks. Back-propagation through time (BPTT), and real-time\nrecurrent learning (RTRL) are two popular gradient-based methods for recurrent\nlearning. BPTT requires complete trajectories of observations before it can\ncompute the gradients and is unsuitable for online updates. RTRL can do online\nupdates but scales poorly to large networks. In this paper, we propose two\nconstraints that make RTRL scalable. We show that by either decomposing the\nnetwork into independent modules or learning the network in stages, we can make\nRTRL scale linearly with the number of parameters. Unlike prior scalable\ngradient estimation algorithms, such as UORO and Truncated-BPTT, our algorithms\ndo not add noise or bias to the gradient estimate. Instead, they trade off the\nfunctional capacity of the network for computationally efficient learning. We\ndemonstrate the effectiveness of our approach over Truncated-BPTT on a\nprediction benchmark inspired by animal learning and by doing policy evaluation\nof pre-trained policies for Atari 2600 games.\n","authors":["Khurram Javed","Haseeb Shah","Rich Sutton","Martha White"],"pdf_url":"https://arxiv.org/pdf/2302.05326v3.pdf","comment":"Scalable recurrent learning, online learning, real-time recurrent\n  learning, cascade correlation networks, agent-state construction, columnar\n  networks, constructive networks"},{"id":"http://arxiv.org/abs/2310.13458v3","updated":"2023-11-21T19:33:52Z","published":"2023-10-20T12:42:06Z","title":"Correspondence learning between morphologically different robots via\n  task demonstrations","summary":"  We observe a large variety of robots in terms of their bodies, sensors, and\nactuators. Given the commonalities in the skill sets, teaching each skill to\neach different robot independently is inefficient and not scalable when the\nlarge variety in the robotic landscape is considered. If we can learn the\ncorrespondences between the sensorimotor spaces of different robots, we can\nexpect a skill that is learned in one robot can be more directly and easily\ntransferred to other robots. In this paper, we propose a method to learn\ncorrespondences among two or more robots that may have different morphologies.\nTo be specific, besides robots with similar morphologies with different degrees\nof freedom, we show that a fixed-based manipulator robot with joint control and\na differential drive mobile robot can be addressed within the proposed\nframework. To set up the correspondence among the robots considered, an initial\nbase task is demonstrated to the robots to achieve the same goal. Then, a\ncommon latent representation is learned along with the individual robot\npolicies for achieving the goal. After the initial learning stage, the\nobservation of a new task execution by one robot becomes sufficient to generate\na latent space representation pertaining to the other robots to achieve the\nsame task. We verified our system in a set of experiments where the\ncorrespondence between robots is learned (1) when the robots need to follow the\nsame paths to achieve the same task, (2) when the robots need to follow\ndifferent trajectories to achieve the same task, and (3) when complexities of\nthe required sensorimotor trajectories are different for the robots. We also\nprovide a proof-of-the-concept realization of correspondence learning between a\nreal manipulator robot and a simulated mobile robot.\n","authors":["Hakan Aktas","Yukie Nagai","Minoru Asada","Erhan Oztop","Emre Ugur"],"pdf_url":"https://arxiv.org/pdf/2310.13458v3.pdf","comment":"8 pages, 12 figures, Submitted to IEEE Robotics Automation Letters\n  (RA-L)"},{"id":"http://arxiv.org/abs/2311.12944v1","updated":"2023-11-21T19:17:39Z","published":"2023-11-21T19:17:39Z","title":"DroneOptiNet: A Framework for Optimal Drone-based Load Redistribution\n  Mechanism for 5G and Beyond Solar Small Cell Networks","summary":"  The power requirements posed by the fifth-generation and beyond cellular\nnetworks are an important constraint in network deployment and require\nenergy-efficient solutions. In this work, we propose a novel user load transfer\napproach using airborne base stations (BS), mounted on drones, for reliable and\nsecure power redistribution across the micro-grid network comprising green\nsmall cell BSs. Depending on the user density and the availability of an aerial\nBS, the energy requirement of a cell with an energy deficit is accommodated by\nmigrating the aerial BS from a high-energy to a low-energy cell. The proposed\nhybrid drone-based framework integrates long short-term memory with unique cost\nfunctions using an evolutionary neural network for drones and BSs, and\nefficiently manages energy and load redistribution. The proposed algorithm\nreduces power outages at BSs and maintains consistent throughput stability,\nthereby demonstrating its capability to boost the reliability and robustness of\nwireless communication systems.\n","authors":["Daksh Dave","Vinay Chamola","Sandeep Joshi","Sherali Zeadally"],"pdf_url":"https://arxiv.org/pdf/2311.12944v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01588v2","updated":"2023-11-21T19:16:51Z","published":"2023-11-02T20:40:21Z","title":"Domain Adaptive Graph Neural Networks for Constraining Cosmological\n  Parameters Across Multiple Data Sets","summary":"  Deep learning models have been shown to outperform methods that rely on\nsummary statistics, like the power spectrum, in extracting information from\ncomplex cosmological data sets. However, due to differences in the subgrid\nphysics implementation and numerical approximations across different simulation\nsuites, models trained on data from one cosmological simulation show a drop in\nperformance when tested on another. Similarly, models trained on any of the\nsimulations would also likely experience a drop in performance when applied to\nobservational data. Training on data from two different suites of the CAMELS\nhydrodynamic cosmological simulations, we examine the generalization\ncapabilities of Domain Adaptive Graph Neural Networks (DA-GNNs). By utilizing\nGNNs, we capitalize on their capacity to capture structured scale-free\ncosmological information from galaxy distributions. Moreover, by including\nunsupervised domain adaptation via Maximum Mean Discrepancy (MMD), we enable\nour models to extract domain-invariant features. We demonstrate that DA-GNN\nachieves higher accuracy and robustness on cross-dataset tasks (up to $28\\%$\nbetter relative error and up to almost an order of magnitude better $\\chi^2$).\nUsing data visualizations, we show the effects of domain adaptation on proper\nlatent space data alignment. This shows that DA-GNNs are a promising method for\nextracting domain-independent cosmological information, a vital step toward\nrobust deep learning for real cosmic survey data.\n","authors":["Andrea Roncoli","Aleksandra Ćiprijanović","Maggie Voetberg","Francisco Villaescusa-Navarro","Brian Nord"],"pdf_url":"https://arxiv.org/pdf/2311.01588v2.pdf","comment":"Accepted in Machine Learning and the Physical Sciences Workshop at\n  NeurIPS 2023; 9 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2311.12943v1","updated":"2023-11-21T19:15:17Z","published":"2023-11-21T19:15:17Z","title":"InteRACT: Transformer Models for Human Intent Prediction Conditioned on\n  Robot Actions","summary":"  In collaborative human-robot manipulation, a robot must predict human intents\nand adapt its actions accordingly to smoothly execute tasks. However, the\nhuman's intent in turn depends on actions the robot takes, creating a\nchicken-or-egg problem. Prior methods ignore such inter-dependency and instead\ntrain marginal intent prediction models independent of robot actions. This is\nbecause training conditional models is hard given a lack of paired human-robot\ninteraction datasets.\n  Can we instead leverage large-scale human-human interaction data that is more\neasily accessible? Our key insight is to exploit a correspondence between human\nand robot actions that enables transfer learning from human-human to\nhuman-robot data. We propose a novel architecture, InteRACT, that pre-trains a\nconditional intent prediction model on large human-human datasets and\nfine-tunes on a small human-robot dataset. We evaluate on a set of real-world\ncollaborative human-robot manipulation tasks and show that our conditional\nmodel improves over various marginal baselines. We also introduce new\ntechniques to tele-operate a 7-DoF robot arm and collect a diverse range of\nhuman-robot collaborative manipulation data, which we open-source.\n","authors":["Kushal Kedia","Atiksh Bhardwaj","Prithwish Dan","Sanjiban Choudhury"],"pdf_url":"https://arxiv.org/pdf/2311.12943v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.13390v3","updated":"2023-11-21T19:11:34Z","published":"2023-07-25T10:21:26Z","title":"Counterfactual Explanation via Search in Gaussian Mixture Distributed\n  Latent Space","summary":"  Counterfactual Explanations (CEs) are an important tool in Algorithmic\nRecourse for addressing two questions: 1. What are the crucial factors that led\nto an automated prediction/decision? 2. How can these factors be changed to\nachieve a more favorable outcome from a user's perspective? Thus, guiding the\nuser's interaction with AI systems by proposing easy-to-understand explanations\nand easy-to-attain feasible changes is essential for the trustworthy adoption\nand long-term acceptance of AI systems. In the literature, various methods have\nbeen proposed to generate CEs, and different quality measures have been\nsuggested to evaluate these methods. However, the generation of CEs is usually\ncomputationally expensive, and the resulting suggestions are unrealistic and\nthus non-actionable. In this paper, we introduce a new method to generate CEs\nfor a pre-trained binary classifier by first shaping the latent space of an\nautoencoder to be a mixture of Gaussian distributions. CEs are then generated\nin latent space by linear interpolation between the query sample and the\ncentroid of the target class. We show that our method maintains the\ncharacteristics of the input sample during the counterfactual search. In\nvarious experiments, we show that the proposed method is competitive based on\ndifferent quality measures on image and tabular datasets -- efficiently returns\nresults that are closer to the original data manifold compared to three\nstate-of-the-art methods, which are essential for realistic high-dimensional\nmachine learning applications.\n","authors":["Xuan Zhao","Klaus Broelemann","Gjergji Kasneci"],"pdf_url":"https://arxiv.org/pdf/2307.13390v3.pdf","comment":"XAI workshop of IJCAI 2023"},{"id":"http://arxiv.org/abs/2311.12929v1","updated":"2023-11-21T19:00:03Z","published":"2023-11-21T19:00:03Z","title":"Hierarchical Learning for Quantum ML: Novel Training Technique for\n  Large-Scale Variational Quantum Circuits","summary":"  We present hierarchical learning, a novel variational architecture for\nefficient training of large-scale variational quantum circuits. We test and\nbenchmark our technique for distribution loading with quantum circuit born\nmachines (QCBMs). With QCBMs, probability distributions are loaded into the\nsquared amplitudes of computational basis vectors represented by bitstrings.\nOur key insight is to take advantage of the fact that the most significant\n(qu)bits have a greater effect on the final distribution and can be learned\nfirst. One can think of it as a generalization of layerwise learning, where\nsome parameters of the variational circuit are learned first to prevent the\nphenomena of barren plateaus. We briefly review adjoint methods for computing\nthe gradient, in particular for loss functions that are not expectation values\nof observables. We first compare the role of connectivity in the variational\nansatz for the task of loading a Gaussian distribution on nine qubits, finding\nthat 2D connectivity greatly outperforms qubits arranged on a line. Based on\nour observations, we then implement this strategy on large-scale numerical\nexperiments with GPUs, training a QCBM to reproduce a 3-dimensional\nmultivariate Gaussian distribution on 27 qubits up to $\\sim4\\%$ total variation\ndistance. Though barren plateau arguments do not strictly apply here due to the\nobjective function not being tied to an observable, this is to our knowledge\nthe first practical demonstration of variational learning on large numbers of\nqubits. We also demonstrate hierarchical learning as a resource-efficient way\nto load distributions for existing quantum hardware (IBM's 7 and 27 qubit\ndevices) in tandem with Fire Opal optimizations.\n","authors":["Hrant Gharibyan","Vincent Su","Hayk Tepanyan"],"pdf_url":"https://arxiv.org/pdf/2311.12929v1.pdf","comment":"22 pages, 15 figures"},{"id":"http://arxiv.org/abs/2311.12918v1","updated":"2023-11-21T18:28:35Z","published":"2023-11-21T18:28:35Z","title":"Deep Learning-Based Real-Time Quality Control of Standard Video\n  Compression for Live Streaming","summary":"  Ensuring high-quality video content for wireless users has become\nincreasingly vital. Nevertheless, maintaining a consistent level of video\nquality faces challenges due to the fluctuating encoded bitrate, primarily\ncaused by dynamic video content, especially in live streaming scenarios. Video\ncompression is typically employed to eliminate unnecessary redundancies within\nand between video frames, thereby reducing the required bandwidth for video\ntransmission. The encoded bitrate and the quality of the compressed video\ndepend on encoder parameters, specifically, the quantization parameter (QP).\nPoor choices of encoder parameters can result in reduced bandwidth efficiency\nand high likelihood of non-conformance. Non-conformance refers to the violation\nof the peak signal-to-noise ratio (PSNR) constraint for an encoded video\nsegment. To address these issues, a real-time deep learning-based H.264\ncontroller is proposed. This controller dynamically estimates the optimal\nencoder parameters based on the content of a video chunk with minimal delay.\nThe objective is to maintain video quality in terms of PSNR above a specified\nthreshold while minimizing the average bitrate of the compressed video.\nExperimental results, conducted on both QCIF dataset and a diverse range of\nrandom videos from public datasets, validate the effectiveness of this\napproach. Notably, it achieves improvements of up to 2.5 times in average\nbandwidth usage compared to the state-of-the-art adaptive bitrate video\nstreaming, with a negligible non-conformance probability below $10^{-2}$.\n","authors":["Matin Mortaheb","Mohammad A. Amir Khojastepour","Srimat T. Chakradhar","Sennur Ulukus"],"pdf_url":"https://arxiv.org/pdf/2311.12918v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2310.06857"},{"id":"http://arxiv.org/abs/2311.12917v1","updated":"2023-11-21T18:25:23Z","published":"2023-11-21T18:25:23Z","title":"Orchard: building large cancer phylogenies using stochastic\n  combinatorial search","summary":"  Phylogenies depicting the evolutionary history of genetically heterogeneous\nsubpopulations of cells from the same cancer i.e., cancer phylogenies, provide\nuseful insights about cancer development and inform treatment. Cancer\nphylogenies can be reconstructed using data obtained from bulk DNA sequencing\nof multiple tissue samples from the same cancer. We introduce Orchard, a fast\nalgorithm that reconstructs cancer phylogenies using point mutations detected\nin bulk DNA sequencing data. Orchard constructs cancer phylogenies\nprogressively, one point mutation at a time, ultimately sampling complete\nphylogenies from a posterior distribution implied by the bulk DNA data. Orchard\nreconstructs more plausible phylogenies than state-of-the-art cancer phylogeny\nreconstruction methods on 90 simulated cancers and 14 B-progenitor acute\nlymphoblastic leukemias (B-ALLs). These results demonstrate that Orchard\naccurately reconstructs cancer phylogenies with up to 300 mutations. We then\nintroduce a simple graph based clustering algorithm that uses a reconstructed\nphylogeny to infer unique groups of mutations i.e., mutation clusters, that\ncharacterize the genetic differences between cancer cell populations, and show\nthat this approach is competitive with state-of-the-art mutation clustering\nmethods.\n","authors":["E. Kulman","R. Kuang","Q. Morris"],"pdf_url":"https://arxiv.org/pdf/2311.12917v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12915v1","updated":"2023-11-21T17:57:12Z","published":"2023-11-21T17:57:12Z","title":"Neural-Integrated Meshfree (NIM) Method: A differentiable\n  programming-based hybrid solver for computational mechanics","summary":"  We present the neural-integrated meshfree (NIM) method, a differentiable\nprogramming-based hybrid meshfree approach within the field of computational\nmechanics. NIM seamlessly integrates traditional physics-based meshfree\ndiscretization techniques with deep learning architectures. It employs a hybrid\napproximation scheme, NeuroPU, to effectively represent the solution by\ncombining continuous DNN representations with partition of unity (PU) basis\nfunctions associated with the underlying spatial discretization. This\nneural-numerical hybridization not only enhances the solution representation\nthrough functional space decomposition but also reduces both the size of DNN\nmodel and the need for spatial gradient computations based on automatic\ndifferentiation, leading to a significant improvement in training efficiency.\nUnder the NIM framework, we propose two truly meshfree solvers: the strong\nform-based NIM (S-NIM) and the local variational form-based NIM (V-NIM). In the\nS-NIM solver, the strong-form governing equation is directly considered in the\nloss function, while the V-NIM solver employs a local Petrov-Galerkin approach\nthat allows the construction of variational residuals based on arbitrary\noverlapping subdomains. This ensures both the satisfaction of underlying\nphysics and the preservation of meshfree property. We perform extensive\nnumerical experiments on both stationary and transient benchmark problems to\nassess the effectiveness of the proposed NIM methods in terms of accuracy,\nscalability, generalizability, and convergence properties. Moreover,\ncomparative analysis with other physics-informed machine learning methods\ndemonstrates that NIM, especially V-NIM, significantly enhances both accuracy\nand efficiency in end-to-end predictive capabilities.\n","authors":["Honghui Du","QiZhi He"],"pdf_url":"https://arxiv.org/pdf/2311.12915v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12909v1","updated":"2023-11-21T16:42:26Z","published":"2023-11-21T16:42:26Z","title":"Non-Sequential Ensemble Kalman Filtering using Distributed Arrays","summary":"  This work introduces a new, distributed implementation of the Ensemble Kalman\nFilter (EnKF) that allows for non-sequential assimilation of large datasets in\nhigh-dimensional problems. The traditional EnKF algorithm is computationally\nintensive and exhibits difficulties in applications requiring interaction with\nthe background covariance matrix, prompting the use of methods like sequential\nassimilation which can introduce unwanted consequences, such as dependency on\nobservation ordering. Our implementation leverages recent advancements in\ndistributed computing to enable the construction and use of the full model\nerror covariance matrix in distributed memory, allowing for single-batch\nassimilation of all observations and eliminating order dependencies.\nComparative performance assessments, involving both synthetic and real-world\npaleoclimatic reconstruction applications, indicate that the new,\nnon-sequential implementation outperforms the traditional, sequential one.\n","authors":["Cédric Travelletti","Jörg Franke","David Ginsbourger","Stefan Brönnimann"],"pdf_url":"https://arxiv.org/pdf/2311.12909v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2311.12751v1","updated":"2023-11-21T17:52:30Z","published":"2023-11-21T17:52:30Z","title":"Towards Natural Language-Guided Drones: GeoText-1652 Benchmark with\n  Spatially Relation Matching","summary":"  Drone navigation through natural language commands remains a significant\nchallenge due to the lack of publicly available multi-modal datasets and the\nintricate demands of fine-grained visual-text alignment. In response to this\npressing need, we present a new human-computer interaction annotation benchmark\ncalled GeoText-1652, meticulously curated through a robust Large Language Model\n(LLM)-based data generation framework and the expertise of pre-trained vision\nmodels. This new dataset seamlessly extends the existing image dataset, \\ie,\nUniversity-1652, with spatial-aware text annotations, encompassing intricate\nimage-text-bounding box associations. Besides, we introduce a new optimization\nobjective to leverage fine-grained spatial associations, called blending\nspatial matching, for region-level spatial relation matching. Extensive\nexperiments reveal that our approach maintains an exceptional recall rate under\nvarying description complexities. This underscores the promising potential of\nour approach in elevating drone control and navigation through the seamless\nintegration of natural language commands in real-world scenarios.\n","authors":["Meng Chu","Zhedong Zheng","Wei Ji","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2311.12751v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2309.06255v2","updated":"2023-11-21T11:11:57Z","published":"2023-09-12T14:16:34Z","title":"Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation","summary":"  One primary topic of multi-modal learning is to jointly incorporate\nheterogeneous information from different modalities. However, most models often\nsuffer from unsatisfactory multi-modal cooperation, which could not jointly\nutilize all modalities well. Some methods are proposed to identify and enhance\nthe worse learnt modality, but are often hard to provide the fine-grained\nobservation of multi-modal cooperation at sample-level with theoretical\nsupport. Hence, it is essential to reasonably observe and improve the\nfine-grained cooperation between modalities, especially when facing realistic\nscenarios where the modality discrepancy could vary across different samples.\nTo this end, we introduce a fine-grained modality valuation metric to evaluate\nthe contribution of each modality at sample-level. Via modality valuation, we\nregretfully observe that the multi-modal model tends to rely on one specific\nmodality, resulting in other modalities being low-contributing. We further\nanalyze this issue and improve cooperation between modalities by enhancing the\ndiscriminative ability of low-contributing modalities in a targeted manner.\nOverall, our methods reasonably observe the fine-grained uni-modal contribution\nat sample-level and achieve considerable improvement on different multi-modal\nmodels.\n","authors":["Yake Wei","Ruoxuan Feng","Zihe Wang","Di Hu"],"pdf_url":"https://arxiv.org/pdf/2309.06255v2.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2311.12454v1","updated":"2023-11-21T09:07:11Z","published":"2023-11-21T09:07:11Z","title":"HierSpeech++: Bridging the Gap between Semantic and Acoustic\n  Representation of Speech by Hierarchical Variational Inference for Zero-shot\n  Speech Synthesis","summary":"  Large language models (LLM)-based speech synthesis has been widely adopted in\nzero-shot speech synthesis. However, they require a large-scale data and\npossess the same limitations as previous autoregressive speech models,\nincluding slow inference speed and lack of robustness. This paper proposes\nHierSpeech++, a fast and strong zero-shot speech synthesizer for text-to-speech\n(TTS) and voice conversion (VC). We verified that hierarchical speech synthesis\nframeworks could significantly improve the robustness and expressiveness of the\nsynthetic speech. Furthermore, we significantly improve the naturalness and\nspeaker similarity of synthetic speech even in zero-shot speech synthesis\nscenarios. For text-to-speech, we adopt the text-to-vec framework, which\ngenerates a self-supervised speech representation and an F0 representation\nbased on text representations and prosody prompts. Then, HierSpeech++ generates\nspeech from the generated vector, F0, and voice prompt. We further introduce a\nhigh-efficient speech super-resolution framework from 16 kHz to 48 kHz. The\nexperimental results demonstrated that the hierarchical variational autoencoder\ncould be a strong zero-shot speech synthesizer given that it outperforms\nLLM-based and diffusion-based models. Moreover, we achieved the first\nhuman-level quality zero-shot speech synthesis. Audio samples and source code\nare available at https://github.com/sh-lee-prml/HierSpeechpp.\n","authors":["Sang-Hoon Lee","Ha-Yeong Choi","Seung-Bin Kim","Seong-Whan Lee"],"pdf_url":"https://arxiv.org/pdf/2311.12454v1.pdf","comment":"16 pages, 9 figures, 12 tables"},{"id":"http://arxiv.org/abs/2311.12401v1","updated":"2023-11-21T07:28:51Z","published":"2023-11-21T07:28:51Z","title":"CASR: Refining Action Segmentation via Magrinalizing Frame-levle Causal\n  Relationships","summary":"  Integrating deep learning and causal discovery has increased the\ninterpretability of Temporal Action Segmentation (TAS) tasks. However,\nframe-level causal relationships exist many complicated noises outside the\nsegment-level, making it infeasible to directly express macro action semantics.\nThus, we propose \\textit{\\textbf{Causal Abstraction Segmentation Refiner\n(CASR)}}, which can refine TAS results from various models by enhancing video\ncausality in marginalizing frame-level casual relationships. Specifically, we\ndefine the equivalent frame-level casual model and segment-level causal model,\nso that the causal adjacency matrix constructed from marginalized frame-level\ncausal relationships has the ability to represent the segmnet-level causal\nrelationships. CASR works out by reducing the difference in the causal\nadjacency matrix between we constructed and pre-segmentation results of\nbackbone models. In addition, we propose a novel evaluation metric Causal Edit\nDistance (CED) to evaluate the causal interpretability. Extensive experimental\nresults on mainstream datasets indicate that CASR significantly surpasses\nexisting various methods in action segmentation performance, as well as in\ncausal explainability and generalization. Our code will be available soon.\n","authors":["Keqing Du","Xinyu Yang","Hang Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12401v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12257v1","updated":"2023-11-21T00:37:47Z","published":"2023-11-21T00:37:47Z","title":"Equipping Pretrained Unconditional Music Transformers with Instrument\n  and Genre Controls","summary":"  The ''pretraining-and-finetuning'' paradigm has become a norm for training\ndomain-specific models in natural language processing and computer vision. In\nthis work, we aim to examine this paradigm for symbolic music generation\nthrough leveraging the largest ever symbolic music dataset sourced from the\nMuseScore forum. We first pretrain a large unconditional transformer model\nusing 1.5 million songs. We then propose a simple technique to equip this\npretrained unconditional music transformer model with instrument and genre\ncontrols by finetuning the model with additional control tokens. Our proposed\nrepresentation offers improved high-level controllability and expressiveness\nagainst two existing representations. The experimental results show that the\nproposed model can successfully generate music with user-specified instruments\nand genre. In a subjective listening test, the proposed model outperforms the\npretrained baseline model in terms of coherence, harmony, arrangement and\noverall quality.\n","authors":["Weihan Xu","Julian McAuley","Shlomo Dubnov","Hao-Wen Dong"],"pdf_url":"https://arxiv.org/pdf/2311.12257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10256v2","updated":"2023-11-21T23:52:32Z","published":"2023-11-17T00:56:55Z","title":"Exploring User Perceptions of Virtual Reality Scene Design in Metaverse\n  Learning Environments","summary":"  Metaverse learning environments allow for a seamless and intuitive transition\nbetween activities compared to Virtual Reality (VR) learning environments, due\nto their interconnected design. The design of VR scenes is important for\ncreating effective learning experiences in the Metaverse. However, there is\nlimited research on the impact of different design elements on user's learning\nexperiences in VR scenes. To address this, a study was conducted with 16\nparticipants who interacted with two VR scenes, each with varying design\nelements such as style, color, texture, object, and background, while watching\na short tutorial. Participant rankings of the scenes for learning were obtained\nusing a seven-point Likert scale, and the Mann-Whitney U test was used to\nvalidate differences in preference between the scenes. The results showed a\nsignificant difference in preference between the scenes. Further analysis using\nthe NASA TLX questionnaire was conducted to examine the impact of this\ndifference on cognitive load, and participant feedback was also considered. The\nstudy emphasizes the importance of careful VR scene design to improve the\nuser's learning experience.\n","authors":["Rahatara Ferdousi","Mohammed Faisal","Fedwa Laamarti","Chunsheng Yang","Abdulmotaleb El Saddik"],"pdf_url":"https://arxiv.org/pdf/2311.10256v2.pdf","comment":"6 pages,3 figures, accepted to present at IEEE 42nd International\n  Conference on Consumer Electronics"},{"id":"http://arxiv.org/abs/2311.12894v1","updated":"2023-11-21T08:20:38Z","published":"2023-11-21T08:20:38Z","title":"Attribute-Aware Deep Hashing with Self-Consistency for Large-Scale\n  Fine-Grained Image Retrieval","summary":"  Our work focuses on tackling large-scale fine-grained image retrieval as\nranking the images depicting the concept of interests (i.e., the same\nsub-category labels) highest based on the fine-grained details in the query. It\nis desirable to alleviate the challenges of both fine-grained nature of small\ninter-class variations with large intra-class variations and explosive growth\nof fine-grained data for such a practical task. In this paper, we propose\nattribute-aware hashing networks with self-consistency for generating\nattribute-aware hash codes to not only make the retrieval process efficient,\nbut also establish explicit correspondences between hash codes and visual\nattributes. Specifically, based on the captured visual representations by\nattention, we develop an encoder-decoder structure network of a reconstruction\ntask to unsupervisedly distill high-level attribute-specific vectors from the\nappearance-specific visual representations without attribute annotations. Our\nmodels are also equipped with a feature decorrelation constraint upon these\nattribute vectors to strengthen their representative abilities. Then, driven by\npreserving original entities' similarity, the required hash codes can be\ngenerated from these attribute-specific vectors and thus become\nattribute-aware. Furthermore, to combat simplicity bias in deep hashing, we\nconsider the model design from the perspective of the self-consistency\nprinciple and propose to further enhance models' self-consistency by equipping\nan additional image reconstruction path. Comprehensive quantitative experiments\nunder diverse empirical settings on six fine-grained retrieval datasets and two\ngeneric retrieval datasets show the superiority of our models over competing\nmethods.\n","authors":["Xiu-Shen Wei","Yang Shen","Xuhao Sun","Peng Wang","Yuxin Peng"],"pdf_url":"https://arxiv.org/pdf/2311.12894v1.pdf","comment":"Accepted by IEEE TPAMI"}]},"2023-11-22T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2311.12538v2","updated":"2023-11-22T08:44:34Z","published":"2023-11-21T11:33:03Z","title":"In-Context Learning Functions with Varying Number of Minima","summary":"  Large Language Models (LLMs) have proven effective at In-Context Learning\n(ICL), an ability that allows them to create predictors from labeled examples.\nFew studies have explored the interplay between ICL and specific properties of\nfunctions it attempts to approximate. In our study, we use a formal framework\nto explore ICL and propose a new task of approximating functions with varying\nnumber of minima. We implement a method that allows for producing functions\nwith given inputs as minima. We find that increasing the number of minima\ndegrades ICL performance. At the same time, our evaluation shows that ICL\noutperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster\nthan 2NN in all settings. We validate the findings through a set of few-shot\nexperiments across various hyperparameter configurations.\n","authors":["David Oniani","Yanshan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12538v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.09886v4","updated":"2023-11-22T06:44:16Z","published":"2023-10-15T16:51:11Z","title":"Lifelong Sequence Generation with Dynamic Module Expansion and\n  Adaptation","summary":"  Lifelong sequence generation (LSG), a problem in continual learning, aims to\ncontinually train a model on a sequence of generation tasks to learn constantly\nemerging new generation patterns while avoiding the forgetting of previous\nknowledge. Existing LSG methods mainly focus on maintaining old knowledge while\npaying little attention to knowledge transfer across tasks. In contrast, humans\ncan better learn new tasks by leveraging previously acquired knowledge from\nsimilar tasks. Inspired by the learning paradigm of humans, we propose Dynamic\nModule Expansion and Adaptation (DMEA), which enables the model to dynamically\ndetermine the architecture for acquiring new knowledge based on task\ncorrelation and select the most similar previous tasks to facilitate adaptation\nto new tasks. In addition, as the learning process can easily be biased towards\nthe current task which might cause more severe forgetting of previously learned\nknowledge, we propose dynamic gradient scaling to balance the learning of the\ncurrent task and replayed tasks. With extensive experiments, we demonstrate\nthat DMEA can consistently outperform existing methods in different LSG\nsettings.\n","authors":["Chengwei Qin","Chen Chen","Shafiq Joty"],"pdf_url":"https://arxiv.org/pdf/2310.09886v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13581v1","updated":"2023-11-22T18:37:27Z","published":"2023-11-22T18:37:27Z","title":"PaSS: Parallel Speculative Sampling","summary":"  Scaling the size of language models to tens of billions of parameters has led\nto impressive performance on a wide range of tasks. At generation, these models\nare used auto-regressively, requiring a forward pass for each generated token,\nand thus reading the full set of parameters from memory. This memory access\nforms the primary bottleneck for generation and it worsens as the model size\nincreases. Moreover, executing a forward pass for multiple tokens in parallel\noften takes nearly the same time as it does for just one token. These two\nobservations lead to the development of speculative sampling, where a second\nsmaller model is used to draft a few tokens, that are then validated or\nrejected using a single forward pass of the large model. Unfortunately, this\nmethod requires two models that share the same tokenizer and thus limits its\nadoption. As an alternative, we propose to use parallel decoding as a way to\ndraft multiple tokens from a single model with no computational cost, nor the\nneed for a second model. Our approach only requires an additional input token\nthat marks the words that will be generated simultaneously. We show promising\nperformance (up to $30\\%$ speed-up) while requiring only as few as $O(d_{emb})$\nadditional parameters.\n","authors":["Giovanni Monea","Armand Joulin","Edouard Grave"],"pdf_url":"https://arxiv.org/pdf/2311.13581v1.pdf","comment":"Accepted at the 3rd workshop on Efficient Natural Language and Speech\n  Processing (ENLSP, NeurIPS 2023)"},{"id":"http://arxiv.org/abs/2311.13565v1","updated":"2023-11-22T18:22:56Z","published":"2023-11-22T18:22:56Z","title":"Drilling Down into the Discourse Structure with LLMs for Long Document\n  Question Answering","summary":"  We address the task of evidence retrieval for long document question\nanswering, which involves locating relevant paragraphs within a document to\nanswer a question. We aim to assess the applicability of large language models\n(LLMs) in the task of zero-shot long document evidence retrieval, owing to\ntheir unprecedented performance across various NLP tasks. However, currently\nthe LLMs can consume limited context lengths as input, thus providing document\nchunks as inputs might overlook the global context while missing out on\ncapturing the inter-segment dependencies. Moreover, directly feeding the large\ninput sets can incur significant computational costs, particularly when\nprocessing the entire document (and potentially incurring monetary expenses\nwith enterprise APIs like OpenAI's GPT variants). To address these challenges,\nwe propose a suite of techniques that exploit the discourse structure commonly\nfound in documents. By utilizing this structure, we create a condensed\nrepresentation of the document, enabling a more comprehensive understanding and\nanalysis of relationships between different parts. We retain $99.6\\%$ of the\nbest zero-shot approach's performance, while processing only $26\\%$ of the\ntotal tokens used by the best approach in the information seeking evidence\nretrieval setup. We also show how our approach can be combined with\n\\textit{self-ask} reasoning agent to achieve best zero-shot performance in\ncomplex multi-hop question answering, just $\\approx 4\\%$ short of zero-shot\nperformance using gold evidence.\n","authors":["Inderjeet Nair","Shwetha Somasundaram","Apoorv Saxena","Koustava Goswami"],"pdf_url":"https://arxiv.org/pdf/2311.13565v1.pdf","comment":"Accepted to the Findings of EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13534v1","updated":"2023-11-22T17:14:54Z","published":"2023-11-22T17:14:54Z","title":"LM-Cocktail: Resilient Tuning of Language Models via Model Merging","summary":"  The pre-trained language models are continually fine-tuned to better support\ndownstream applications. However, this operation may result in significant\nperformance degeneration on general tasks beyond the targeted domain. To\novercome this problem, we propose a novel method which enables the fine-tuned\nmodel to stay resilient in general perspectives. Our method is conducted in the\nform of model merging (namely LM-Cocktail), where the fine-tuned language model\nis merged with the pre-trained base model or the peer models from other domains\nthrough weighted average. Despite simplicity, LM-Cocktail is surprisingly\neffective: the resulted model is able to achieve a strong empirical performance\nin the whole scope of general tasks while preserving a superior capacity in its\ntargeted domain. We conduct comprehensive experiments with LLama and BGE model\non popular benchmarks, including FLAN, MMLU, MTEB, whose results validate the\nefficacy of our proposed method. The code and checkpoints are available at\nhttps://github.com/FlagOpen/FlagEmbedding.\n","authors":["Shitao Xiao","Zheng Liu","Peitian Zhang","Xingrun Xing"],"pdf_url":"https://arxiv.org/pdf/2311.13534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.12261v4","updated":"2023-11-22T16:59:55Z","published":"2022-07-06T13:56:48Z","title":"GraphCFC: A Directed Graph Based Cross-Modal Feature Complementation\n  Approach for Multimodal Conversational Emotion Recognition","summary":"  Emotion Recognition in Conversation (ERC) plays a significant part in\nHuman-Computer Interaction (HCI) systems since it can provide empathetic\nservices. Multimodal ERC can mitigate the drawbacks of uni-modal approaches.\nRecently, Graph Neural Networks (GNNs) have been widely used in a variety of\nfields due to their superior performance in relation modeling. In multimodal\nERC, GNNs are capable of extracting both long-distance contextual information\nand inter-modal interactive information. Unfortunately, since existing methods\nsuch as MMGCN directly fuse multiple modalities, redundant information may be\ngenerated and diverse information may be lost. In this work, we present a\ndirected Graph based Cross-modal Feature Complementation (GraphCFC) module that\ncan efficiently model contextual and interactive information. GraphCFC\nalleviates the problem of heterogeneity gap in multimodal fusion by utilizing\nmultiple subspace extractors and Pair-wise Cross-modal Complementary (PairCC)\nstrategy. We extract various types of edges from the constructed graph for\nencoding, thus enabling GNNs to extract crucial contextual and interactive\ninformation more accurately when performing message passing. Furthermore, we\ndesign a GNN structure called GAT-MLP, which can provide a new unified network\nframework for multimodal learning. The experimental results on two benchmark\ndatasets show that our GraphCFC outperforms the state-of-the-art (SOTA)\napproaches.\n","authors":["Jiang Li","Xiaoping Wang","Guoqing Lv","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2207.12261v4.pdf","comment":"Accepted by IEEE Transactions on Multimedia (TMM)"},{"id":"http://arxiv.org/abs/2311.13495v1","updated":"2023-11-22T16:12:42Z","published":"2023-11-22T16:12:42Z","title":"Current Topological and Machine Learning Applications for Bias Detection\n  in Text","summary":"  Institutional bias can impact patient outcomes, educational attainment, and\nlegal system navigation. Written records often reflect bias, and once bias is\nidentified; it is possible to refer individuals for training to reduce bias.\nMany machine learning tools exist to explore text data and create predictive\nmodels that can search written records to identify real-time bias. However, few\nprevious studies investigate large language model embeddings and geometric\nmodels of biased text data to understand geometry's impact on bias modeling\naccuracy. To overcome this issue, this study utilizes the RedditBias database\nto analyze textual biases. Four transformer models, including BERT and RoBERTa\nvariants, were explored. Post-embedding, t-SNE allowed two-dimensional\nvisualization of data. KNN classifiers differentiated bias types, with lower\nk-values proving more effective. Findings suggest BERT, particularly mini BERT,\nexcels in bias classification, while multilingual models lag. The\nrecommendation emphasizes refining monolingual models and exploring\ndomain-specific biases.\n","authors":["Colleen Farrelly","Yashbir Singh","Quincy A. Hathaway","Gunnar Carlsson","Ashok Choudhary","Rahul Paul","Gianfranco Doretto","Yassine Himeur","Shadi Atalls","Wathiq Mansoor"],"pdf_url":"https://arxiv.org/pdf/2311.13495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19680v3","updated":"2023-11-22T16:12:39Z","published":"2023-10-30T16:00:13Z","title":"Integrating Pre-trained Language Model into Neural Machine Translation","summary":"  Neural Machine Translation (NMT) has become a significant technology in\nnatural language processing through extensive research and development.\nHowever, the deficiency of high-quality bilingual language pair data still\nposes a major challenge to improving NMT performance. Recent studies have been\nexploring the use of contextual information from pre-trained language model\n(PLM) to address this problem. Yet, the issue of incompatibility between PLM\nand NMT model remains unresolved. This study proposes PLM-integrated NMT\n(PiNMT) model to overcome the identified problems. PiNMT model consists of\nthree critical components, PLM Multi Layer Converter, Embedding Fusion, and\nCosine Alignment, each playing a vital role in providing effective PLM\ninformation to NMT. Furthermore, two training strategies, Separate Learning\nRates and Dual Step Training, are also introduced in this paper. By\nimplementing the proposed PiNMT model and training strategy, we achieve\nstate-of-the-art performance on the IWSLT'14 En$\\leftrightarrow$De dataset.\nThis study's outcomes are noteworthy as they demonstrate a novel approach for\nefficiently integrating PLM with NMT to overcome incompatibility and enhance\nperformance.\n","authors":["Soon-Jae Hwang","Chang-Sung Jeong"],"pdf_url":"https://arxiv.org/pdf/2310.19680v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.00449v2","updated":"2023-11-22T15:43:23Z","published":"2023-07-02T01:25:47Z","title":"A Dual-Stream Recurrence-Attention Network With Global-Local Awareness\n  for Emotion Recognition in Textual Dialog","summary":"  In real-world dialog systems, the ability to understand the user's emotions\nand interact anthropomorphically is of great significance. Emotion Recognition\nin Conversation (ERC) is one of the key ways to accomplish this goal and has\nattracted growing attention. How to model the context in a conversation is a\ncentral aspect and a major challenge of ERC tasks. Most existing approaches\nstruggle to adequately incorporate both global and local contextual\ninformation, and their network structures are overly sophisticated. For this\nreason, we propose a simple and effective Dual-stream Recurrence-Attention\nNetwork (DualRAN), which is based on Recurrent Neural Network (RNN) and\nMulti-head ATtention network (MAT). DualRAN eschews the complex components of\ncurrent methods and focuses on combining recurrence-based methods with\nattention-based ones. DualRAN is a dual-stream structure mainly consisting of\nlocal- and global-aware modules, modeling a conversation simultaneously from\ndistinct perspectives. In addition, we develop two single-stream network\nvariants for DualRAN, i.e., SingleRANv1 and SingleRANv2. According to the\nexperimental findings, DualRAN boosts the weighted F1 scores by 1.43% and 0.64%\non the IEMOCAP and MELD datasets, respectively, in comparison to the strongest\nbaseline. On two other datasets (i.e., EmoryNLP and DailyDialog), our method\nalso attains competitive results.\n","authors":["Jiang Li","Xiaoping Wang","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2307.00449v2.pdf","comment":"Accepted by Engineering Applications of Artificial Intelligence\n  (EAAI)"},{"id":"http://arxiv.org/abs/2311.13475v1","updated":"2023-11-22T15:42:51Z","published":"2023-11-22T15:42:51Z","title":"Machine Translation to Control Formality Features in the Target Language","summary":"  Formality plays a significant role in language communication, especially in\nlow-resource languages such as Hindi, Japanese and Korean. These languages\nutilise formal and informal expressions to convey messages based on social\ncontexts and relationships. When a language translation technique is used to\ntranslate from a source language that does not pertain the formality (e.g.\nEnglish) to a target language that does, there is a missing information on\nformality that could be a challenge in producing an accurate outcome. This\nresearch explores how this issue should be resolved when machine learning\nmethods are used to translate from English to languages with formality, using\nHindi as the example data. This was done by training a bilingual model in a\nformality-controlled setting and comparing its performance with a pre-trained\nmultilingual model in a similar setting. Since there are not a lot of training\ndata with ground truth, automated annotation techniques were employed to\nincrease the data size. The primary modeling approach involved leveraging\ntransformer models, which have demonstrated effectiveness in various natural\nlanguage processing tasks. We evaluate the official formality accuracy(ACC) by\ncomparing the predicted masked tokens with the ground truth. This metric\nprovides a quantitative measure of how well the translations align with the\ndesired outputs. Our study showcases a versatile translation strategy that\nconsiders the nuances of formality in the target language, catering to diverse\nlanguage communication needs and scenarios.\n","authors":["Harshita Tyagi","Prashasta Jung","Hyowon Lee"],"pdf_url":"https://arxiv.org/pdf/2311.13475v1.pdf","comment":"9 pages, based on DCU MCM Practicum 2022/2023"},{"id":"http://arxiv.org/abs/2311.13472v1","updated":"2023-11-22T15:40:57Z","published":"2023-11-22T15:40:57Z","title":"Complexity-Guided Curriculum Learning for Text Graphs","summary":"  Curriculum learning provides a systematic approach to training. It refines\ntraining progressively, tailors training to task requirements, and improves\ngeneralization through exposure to diverse examples. We present a curriculum\nlearning approach that builds on existing knowledge about text and graph\ncomplexity formalisms for training with text graph data. The core part of our\napproach is a novel data scheduler, which employs \"spaced repetition\" and\ncomplexity formalisms to guide the training process. We demonstrate the\neffectiveness of the proposed approach on several text graph tasks and graph\nneural network architectures. The proposed model gains more and uses less data;\nconsistently prefers text over graph complexity indices throughout training,\nwhile the best curricula derived from text and graph complexity indices are\nequally effective; and it learns transferable curricula across GNN models and\ndatasets. In addition, we find that both node-level (local) and graph-level\n(global) graph complexity indices, as well as shallow and traditional text\ncomplexity indices play a crucial role in effective curriculum learning.\n","authors":["Nidhi Vakil","Hadi Amiri"],"pdf_url":"https://arxiv.org/pdf/2311.13472v1.pdf","comment":"Long Paper Accepted at EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13455v1","updated":"2023-11-22T15:22:04Z","published":"2023-11-22T15:22:04Z","title":"Generation of Explanations for Logic Reasoning","summary":"  This thesis delves into a fortiori arguments in deductive reasoning,\nunderscoring their relevance in various domains such as law, philosophy, and\nartificial intelligence. The research is centred on employing GPT-3.5-turbo to\nautomate the analysis of these arguments, with a focus on understanding\nintricate reasoning processes, generating clear and coherent explanations, and\ncreating novel arguments. The methodology encompasses a series of tasks\nincluding detailed reasoning, interpretation, and the augmentation of a\nfortiori arguments. It involves meticulously identifying these arguments in\ndiverse contexts, differentiating comparative elements, and categorizing them\nbased on their logical structure.\n  Extensive experiments reveals the challenges encountered by GPT-3.5-turbo in\naccurately detecting and classifying a fortiori arguments. Nevertheless, the\nmodel demonstrates a performance that rivals specialized models, particularly\nin extracting key components and interpreting underlying properties. The\nintegration of external information into the model's processing significantly\nelevates the quality of the generated explanations. Additionally, the model\nexhibits a noteworthy capability in augmenting arguments, thus contributing to\nthe enrichment of the data set.\n  Despite facing certain limitations, this thesis makes significant\ncontributions to the fields of artificial intelligence and logical reasoning.\nIt introduces novel methodologies, establishes a rigorous evaluation framework,\nand provides deep insights that set the stage for future advancements in\nautomated logical reasoning. The findings and methodologies presented herein\nnot only underscore the potential of AI in complex reasoning tasks but also\nhighlight areas for future research and development.\n","authors":["Yanyi Pu"],"pdf_url":"https://arxiv.org/pdf/2311.13455v1.pdf","comment":"78 Pages, 16 Figures, Thesis Presentation is available at\n  https://drive.google.com/file/d/1wLIBsjfLvO11PjCS6qx4Y9UgRBUfq3wQ/view?usp=sharing"},{"id":"http://arxiv.org/abs/2311.13350v1","updated":"2023-11-22T12:39:28Z","published":"2023-11-22T12:39:28Z","title":"Fact-based Court Judgment Prediction","summary":"  This extended abstract extends the research presented in \"ILDC for CJPE:\nIndian Legal Documents Corpus for Court Judgment Prediction and Explanation\"\n\\cite{malik-etal-2021-ildc}, focusing on fact-based judgment prediction within\nthe context of Indian legal documents. We introduce two distinct problem\nvariations: one based solely on facts, and another combining facts with rulings\nfrom lower courts (RLC). Our research aims to enhance early-phase case outcome\nprediction, offering significant benefits to legal professionals and the\ngeneral public. The results, however, indicated a performance decline compared\nto the original ILDC for CJPE study, even after implementing various weightage\nschemes in our DELSumm algorithm. Additionally, using only facts for legal\njudgment prediction with different transformer models yielded results inferior\nto the state-of-the-art outcomes reported in the \"ILDC for CJPE\" study.\n","authors":["Shubham Kumar Nigam","Aniket Deroy"],"pdf_url":"https://arxiv.org/pdf/2311.13350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13314v1","updated":"2023-11-22T11:08:38Z","published":"2023-11-22T11:08:38Z","title":"Mitigating Large Language Model Hallucinations via Autonomous Knowledge\n  Graph-based Retrofitting","summary":"  Incorporating factual knowledge in knowledge graph is regarded as a promising\napproach for mitigating the hallucination of large language models (LLMs).\nExisting methods usually only use the user's input to query the knowledge\ngraph, thus failing to address the factual hallucination generated by LLMs\nduring its reasoning process. To address this problem, this paper proposes\nKnowledge Graph-based Retrofitting (KGR), a new framework that incorporates\nLLMs with KGs to mitigate factual hallucination during the reasoning process by\nretrofitting the initial draft responses of LLMs based on the factual knowledge\nstored in KGs. Specifically, KGR leverages LLMs to extract, select, validate,\nand retrofit factual statements within the model-generated responses, which\nenables an autonomous knowledge verifying and refining procedure without any\nadditional manual efforts. Experiments show that KGR can significantly improve\nthe performance of LLMs on factual QA benchmarks especially when involving\ncomplex reasoning processes, which demonstrates the necessity and effectiveness\nof KGR in mitigating hallucination and enhancing the reliability of LLMs.\n","authors":["Xinyan Guan","Yanjiang Liu","Hongyu Lin","Yaojie Lu","Ben He","Xianpei Han","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2311.13314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13307v1","updated":"2023-11-22T10:55:36Z","published":"2023-11-22T10:55:36Z","title":"Rethinking Radiology Report Generation via Causal Reasoning and\n  Counterfactual Augmentation","summary":"  Radiology Report Generation (RRG) draws attention as an interaction between\nvision and language fields. Previous works inherited the ideology of\nvision-to-language generation tasks,aiming to generate paragraphs with high\nconsistency as reports. However, one unique characteristic of RRG, the\nindependence between diseases, was neglected, leading to the injection of the\nspurious confounder, i.e., the disease co-occurrence. Unfortunately, this\nconfounder confuses the process of report generation worse because of the\nbiased RRG data distribution. In this paper, to rethink this issue thoroughly,\nwe reason about its causes and effects from a novel perspective of statistics\nand causality, where the Joint Vision Coupling and the Conditional Sentence\nCoherence Coupling are two aspects prone to implicitly decrease the accuracy of\nreports. Then, a counterfactual augmentation strategy that contains the\nCounterfactual Sample Synthesis and the Counterfactual Report Reconstruction\nsub-methods is proposed to break these two aspects of spurious effects.\nExperimental results and further analyses on two widely used datasets justify\nour reasoning and proposed methods.\n","authors":["Xiao Song","Jiafan Liu","Yun Li","Wenbin Lei","Ruxin Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13307v1.pdf","comment":"10 pages,5 figures"},{"id":"http://arxiv.org/abs/2305.14264v2","updated":"2023-11-22T10:22:18Z","published":"2023-05-23T17:16:04Z","title":"Active Learning Principles for In-Context Learning with Large Language\n  Models","summary":"  The remarkable advancements in large language models (LLMs) have\nsignificantly enhanced the performance in few-shot learning settings. By using\nonly a small number of labeled examples, referred to as demonstrations, LLMs\ncan effectively grasp the task at hand through in-context learning. However,\nthe process of selecting appropriate demonstrations has received limited\nattention in prior work. This paper addresses the issue of identifying the most\ninformative demonstrations for few-shot learning by approaching it as a\npool-based Active Learning (AL) problem over a single iteration. Our objective\nis to investigate how AL algorithms can serve as effective demonstration\nselection methods for in-context learning. We compare various standard AL\nalgorithms based on uncertainty, diversity, and similarity, and consistently\nobserve that the latter outperforms all other methods, including random\nsampling. Notably, uncertainty sampling, despite its success in conventional\nsupervised learning scenarios, performs poorly in this context. Our extensive\nexperimentation involving a diverse range of GPT and OPT models across $24$\nclassification and multi-choice tasks, coupled with thorough analysis,\nunambiguously demonstrates that in-context example selection through AL\nprioritizes high-quality examples that exhibit low uncertainty and bear\nsimilarity to the test examples.\n","authors":["Katerina Margatina","Timo Schick","Nikolaos Aletras","Jane Dwivedi-Yu"],"pdf_url":"https://arxiv.org/pdf/2305.14264v2.pdf","comment":"To appear at Findings of EMNLP (Camera Ready version)"},{"id":"http://arxiv.org/abs/2311.13281v1","updated":"2023-11-22T10:04:29Z","published":"2023-11-22T10:04:29Z","title":"Intention and Context Elicitation with Large Language Models in the\n  Legal Aid Intake Process","summary":"  Large Language Models (LLMs) and chatbots show significant promise in\nstreamlining the legal intake process. This advancement can greatly reduce the\nworkload and costs for legal aid organizations, improving availability while\nmaking legal assistance more accessible to a broader audience. However, a key\nchallenge with current LLMs is their tendency to overconfidently deliver an\nimmediate 'best guess' to a client's question based on the output distribution\nlearned over the training data. This approach often overlooks the client's\nactual intentions or the specifics of their legal situation. As a result,\nclients may not realize the importance of providing essential additional\ncontext or expressing their underlying intentions, which are crucial for their\nlegal cases. Traditionally, logic based decision trees have been used to\nautomate intake for specific access to justice issues, such as immigration and\neviction. But those solutions lack scalability. We demonstrate a\nproof-of-concept using LLMs to elicit and infer clients' underlying intentions\nand specific legal circumstances through free-form, language-based\ninteractions. We also propose future research directions to use supervised\nfine-tuning or offline reinforcement learning to automatically incorporate\nintention and context elicitation in chatbots without explicit prompting.\n","authors":["Nick Goodson","Rongfei Lu"],"pdf_url":"https://arxiv.org/pdf/2311.13281v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13274v1","updated":"2023-11-22T09:51:53Z","published":"2023-11-22T09:51:53Z","title":"Enhancing Summarization Performance through Transformer-Based Prompt\n  Engineering in Automated Medical Reporting","summary":"  Customized medical prompts enable Large Language Models (LLM) to effectively\naddress medical dialogue summarization. The process of medical reporting is\noften time-consuming for healthcare professionals. Implementing medical\ndialogue summarization techniques presents a viable solution to alleviate this\ntime constraint by generating automated medical reports. The effectiveness of\nLLMs in this process is significantly influenced by the formulation of the\nprompt, which plays a crucial role in determining the quality and relevance of\nthe generated reports. In this research, we used a combination of two distinct\nprompting strategies, known as shot prompting and pattern prompting to enhance\nthe performance of automated medical reporting. The evaluation of the automated\nmedical reports is carried out using the ROUGE score and a human evaluation\nwith the help of an expert panel. The two-shot prompting approach in\ncombination with scope and domain context outperforms other methods and\nachieves the highest score when compared to the human reference set by a\ngeneral practitioner. However, the automated reports are approximately twice as\nlong as the human references, due to the addition of both redundant and\nrelevant statements that are added to the report.\n","authors":["Daphne van Zandvoort","Laura Wiersema","Tom Huibers","Sandra van Dulmen","Sjaak Brinkkemper"],"pdf_url":"https://arxiv.org/pdf/2311.13274v1.pdf","comment":"12 pages, 4 figures, submitted to Healthinf 2024, author roles:\n  research conducted and written by Daphne van Zandvoort and Laura Wiersema,\n  research suggested and used software created by Tom Huibers, data provided\n  and feedback provided by Sandra van Dulmen, supervision and feedback provided\n  by Sjaak Brinkkemper"},{"id":"http://arxiv.org/abs/2311.13273v1","updated":"2023-11-22T09:51:43Z","published":"2023-11-22T09:51:43Z","title":"Comparative Experimentation of Accuracy Metrics in Automated Medical\n  Reporting: The Case of Otitis Consultations","summary":"  Generative Artificial Intelligence (AI) can be used to automatically generate\nmedical reports based on transcripts of medical consultations. The aim is to\nreduce the administrative burden that healthcare professionals face. The\naccuracy of the generated reports needs to be established to ensure their\ncorrectness and usefulness. There are several metrics for measuring the\naccuracy of AI generated reports, but little work has been done towards the\napplication of these metrics in medical reporting. A comparative\nexperimentation of 10 accuracy metrics has been performed on AI generated\nmedical reports against their corresponding General Practitioner's (GP) medical\nreports concerning Otitis consultations. The number of missing, incorrect, and\nadditional statements of the generated reports have been correlated with the\nmetric scores. In addition, we introduce and define a Composite Accuracy Score\nwhich produces a single score for comparing the metrics within the field of\nautomated medical reporting. Findings show that based on the correlation study\nand the Composite Accuracy Score, the ROUGE-L and Word Mover's Distance metrics\nare the preferred metrics, which is not in line with previous work. These\nfindings help determine the accuracy of an AI generated medical report, which\naids the development of systems that generate medical reports for GPs to reduce\nthe administrative burden.\n","authors":["Wouter Faber","Renske Eline Bootsma","Tom Huibers","Sandra van Dulmen","Sjaak Brinkkemper"],"pdf_url":"https://arxiv.org/pdf/2311.13273v1.pdf","comment":"10 pages, 1 figure, submitted to HEALTHINF 2024, Author\n  contributions: Wouter Faber and Renske Eline Bootsma performed research and\n  wrote paper, Tom Huibers provided needed software and research inspiration,\n  Sandra van Dulmen provided the data and feedback on paper, Sjaak Brinkkemper\n  supervised the project and provided continuous feedback"},{"id":"http://arxiv.org/abs/2311.13258v1","updated":"2023-11-22T09:23:34Z","published":"2023-11-22T09:23:34Z","title":"ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided\n  Code-Vision Representation","summary":"  State-of-the-art vision-language models (VLMs) still have limited performance\nin structural knowledge extraction, such as relations between objects. In this\nwork, we present ViStruct, a training framework to learn VLMs for effective\nvisual structural knowledge extraction. Two novel designs are incorporated.\nFirst, we propose to leverage the inherent structure of programming language to\ndepict visual structural information. This approach enables explicit and\nconsistent representation of visual structural information of multiple\ngranularities, such as concepts, relations, and events, in a well-organized\nstructured format. Second, we introduce curriculum-based learning for VLMs to\nprogressively comprehend visual structures, from fundamental visual concepts to\nintricate event structures. Our intuition is that lower-level knowledge may\ncontribute to complex visual structure understanding. Furthermore, we compile\nand release a collection of datasets tailored for visual structural knowledge\nextraction. We adopt a weakly-supervised approach to directly generate visual\nevent structures from captions for ViStruct training, capitalizing on abundant\nimage-caption pairs from the web. In experiments, we evaluate ViStruct on\nvisual structure prediction tasks, demonstrating its effectiveness in improving\nthe understanding of visual structures. The code is public at\n\\url{https://github.com/Yangyi-Chen/vi-struct}.\n","authors":["Yangyi Chen","Xingyao Wang","Manling Li","Derek Hoiem","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2311.13258v1.pdf","comment":"Accepted to EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.00321v2","updated":"2023-11-22T09:08:03Z","published":"2023-11-01T06:09:54Z","title":"HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning","summary":"  With the proliferation of social media, accurate detection of hate speech has\nbecome critical to ensure safety online. To combat nuanced forms of hate\nspeech, it is important to identify and thoroughly explain hate speech to help\nusers understand its harmful effects. Recent benchmarks have attempted to\ntackle this issue by training generative models on free-text annotations of\nimplications in hateful text. However, we find significant reasoning gaps in\nthe existing annotations schemes, which may hinder the supervision of detection\nmodels. In this paper, we introduce a hate speech detection framework, HARE,\nwhich harnesses the reasoning capabilities of large language models (LLMs) to\nfill these gaps in explanations of hate speech, thus enabling effective\nsupervision of detection models. Experiments on SBIC and Implicit Hate\nbenchmarks show that our method, using model-generated data, consistently\noutperforms baselines, using existing free-text human annotations. Analysis\ndemonstrates that our method enhances the explanation quality of trained models\nand improves generalization to unseen datasets. Our code is available at\nhttps://github.com/joonkeekim/hare-hate-speech.git.\n","authors":["Yongjin Yang","Joonkee Kim","Yujin Kim","Namgyu Ho","James Thorne","Se-young Yun"],"pdf_url":"https://arxiv.org/pdf/2311.00321v2.pdf","comment":"Findings of EMNLP 2023; The first three authors contribute equally"},{"id":"http://arxiv.org/abs/2311.13246v1","updated":"2023-11-22T09:04:57Z","published":"2023-11-22T09:04:57Z","title":"Automatic Instruction Optimization for Open-source LLM Instruction\n  Tuning","summary":"  Instruction tuning is crucial for enabling Language Learning Models (LLMs) in\nresponding to human instructions. The quality of instruction pairs used for\ntuning greatly affects the performance of LLMs. However, the manual creation of\nhigh-quality instruction datasets is costly, leading to the adoption of\nautomatic generation of instruction pairs by LLMs as a popular alternative in\nthe training of open-source LLMs. To ensure the high quality of LLM-generated\ninstruction datasets, several approaches have been proposed. Nevertheless,\nexisting methods either compromise dataset integrity by filtering a large\nproportion of samples, or are unsuitable for industrial applications. In this\npaper, instead of discarding low-quality samples, we propose CoachLM, a novel\napproach to enhance the quality of instruction datasets through automatic\nrevisions on samples in the dataset. CoachLM is trained from the samples\nrevised by human experts and significantly increases the proportion of\nhigh-quality samples in the dataset from 17.7% to 78.9%. The effectiveness of\nCoachLM is further assessed on various real-world instruction test sets. The\nresults show that CoachLM improves the instruction-following capabilities of\nthe instruction-tuned LLM by an average of 29.9%, which even surpasses larger\nLLMs with nearly twice the number of parameters. Furthermore, CoachLM is\nsuccessfully deployed in a data management system for LLMs at Huawei, resulting\nin an efficiency improvement of up to 20% in the cleaning of 40k real-world\ninstruction pairs. We release the training data and code of CoachLM\n(https://github.com/lunyiliu/CoachLM).\n","authors":["Yilun Liu","Shimin Tao","Xiaofeng Zhao","Ming Zhu","Wenbing Ma","Junhao Zhu","Chang Su","Yutai Hou","Miao Zhang","Min Zhang","Hongxia Ma","Li Zhang","Hao Yang","Yanfei Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.13246v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13240v1","updated":"2023-11-22T08:57:55Z","published":"2023-11-22T08:57:55Z","title":"On the Calibration of Large Language Models and Alignment","summary":"  As large language models attract increasing attention and find widespread\napplication, concurrent challenges of reliability also arise at the same time.\nConfidence calibration, an effective analysis method for gauging the\nreliability of deep models, serves as a crucial tool for assessing and\nimproving their reliability. However, such investigation has been comparatively\nunderexplored. In this work, we conduct a systematic examination of the\ncalibration of aligned language models throughout the entire construction\nprocess, including pretraining and alignment training. At each stage, we\ninvestigate how different training settings, such as parameter scales and\ntraining data, affect model calibration. To thoroughly assess model\ncalibration, we evaluate models on three most concerned aspects: generation,\nfactuality and understanding. Our work sheds light on whether popular LLMs are\nwell-calibrated and how the training process influences model calibration.\n","authors":["Chiwei Zhu","Benfeng Xu","Quan Wang","Yongdong Zhang","Zhendong Mao"],"pdf_url":"https://arxiv.org/pdf/2311.13240v1.pdf","comment":"to be published in findings of EMNLP-2023"},{"id":"http://arxiv.org/abs/2311.13230v1","updated":"2023-11-22T08:39:17Z","published":"2023-11-22T08:39:17Z","title":"Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus","summary":"  Large Language Models (LLMs) have gained significant popularity for their\nimpressive performance across diverse fields. However, LLMs are prone to\nhallucinate untruthful or nonsensical outputs that fail to meet user\nexpectations in many real-world applications. Existing works for detecting\nhallucinations in LLMs either rely on external knowledge for reference\nretrieval or require sampling multiple responses from the LLM for consistency\nverification, making these methods costly and inefficient. In this paper, we\npropose a novel reference-free, uncertainty-based method for detecting\nhallucinations in LLMs. Our approach imitates human focus in factuality\nchecking from three aspects: 1) focus on the most informative and important\nkeywords in the given text; 2) focus on the unreliable tokens in historical\ncontext which may lead to a cascade of hallucinations; and 3) focus on the\ntoken properties such as token type and token frequency. Experimental results\non relevant datasets demonstrate the effectiveness of our proposed method,\nwhich achieves state-of-the-art performance across all the evaluation metrics\nand eliminates the need for additional information.\n","authors":["Tianhang Zhang","Lin Qiu","Qipeng Guo","Cheng Deng","Yue Zhang","Zheng Zhang","Chenghu Zhou","Xinbing Wang","Luoyi Fu"],"pdf_url":"https://arxiv.org/pdf/2311.13230v1.pdf","comment":"Accepted by EMNLP 2023 (main conference)"},{"id":"http://arxiv.org/abs/2310.00603v2","updated":"2023-11-22T08:00:10Z","published":"2023-10-01T07:31:04Z","title":"Faithful Explanations of Black-box NLP Models Using LLM-generated\n  Counterfactuals","summary":"  Causal explanations of the predictions of NLP systems are essential to ensure\nsafety and establish trust. Yet, existing methods often fall short of\nexplaining model predictions effectively or efficiently and are often\nmodel-specific. In this paper, we address model-agnostic explanations,\nproposing two approaches for counterfactual (CF) approximation. The first\napproach is CF generation, where a large language model (LLM) is prompted to\nchange a specific text concept while keeping confounding concepts unchanged.\nWhile this approach is demonstrated to be very effective, applying LLM at\ninference-time is costly. We hence present a second approach based on matching,\nand propose a method that is guided by an LLM at training-time and learns a\ndedicated embedding space. This space is faithful to a given causal graph and\neffectively serves to identify matches that approximate CFs. After showing\ntheoretically that approximating CFs is required in order to construct faithful\nexplanations, we benchmark our approaches and explain several models, including\nLLMs with billions of parameters. Our empirical results demonstrate the\nexcellent performance of CF generation models as model-agnostic explainers.\nMoreover, our matching approach, which requires far less test-time resources,\nalso provides effective explanations, surpassing many baselines. We also find\nthat Top-K techniques universally improve every tested method. Finally, we\nshowcase the potential of LLMs in constructing new benchmarks for model\nexplanation and subsequently validate our conclusions. Our work illuminates new\npathways for efficient and accurate approaches to interpreting NLP systems.\n","authors":["Yair Gat","Nitay Calderon","Amir Feder","Alexander Chapanin","Amit Sharma","Roi Reichart"],"pdf_url":"https://arxiv.org/pdf/2310.00603v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03214v2","updated":"2023-11-22T07:28:19Z","published":"2023-10-05T00:04:12Z","title":"FreshLLMs: Refreshing Large Language Models with Search Engine\n  Augmentation","summary":"  Most large language models (LLMs) are trained once and never updated; thus,\nthey lack the ability to dynamically adapt to our ever-changing world. In this\nwork, we perform a detailed study of the factuality of LLM-generated text in\nthe context of answering questions that test current world knowledge.\nSpecifically, we introduce FreshQA, a novel dynamic QA benchmark encompassing a\ndiverse range of question and answer types, including questions that require\nfast-changing world knowledge as well as questions with false premises that\nneed to be debunked. We benchmark a diverse array of both closed and\nopen-source LLMs under a two-mode evaluation procedure that allows us to\nmeasure both correctness and hallucination. Through human evaluations involving\nmore than 50K judgments, we shed light on limitations of these models and\ndemonstrate significant room for improvement: for instance, all models\n(regardless of model size) struggle on questions that involve fast-changing\nknowledge and false premises. Motivated by these results, we present\nFreshPrompt, a simple few-shot prompting method that substantially boosts the\nperformance of an LLM on FreshQA by incorporating relevant and up-to-date\ninformation retrieved from a search engine into the prompt. Our experiments\nshow that FreshPrompt outperforms both competing search engine-augmented\nprompting methods such as Self-Ask (Press et al., 2022) as well as commercial\nsystems such as Perplexity.AI. Further analysis of FreshPrompt reveals that\nboth the number of retrieved evidences and their order play a key role in\ninfluencing the correctness of LLM-generated answers. Additionally, instructing\nthe LLM to generate concise and direct answers helps reduce hallucination\ncompared to encouraging more verbose answers. To facilitate future work, we\nrelease FreshQA at github.com/freshllms/freshqa and commit to updating it at\nregular intervals.\n","authors":["Tu Vu","Mohit Iyyer","Xuezhi Wang","Noah Constant","Jerry Wei","Jason Wei","Chris Tar","Yun-Hsuan Sung","Denny Zhou","Quoc Le","Thang Luong"],"pdf_url":"https://arxiv.org/pdf/2310.03214v2.pdf","comment":"Preprint, 26 pages, 10 figures, 5 tables; Added FreshEval"},{"id":"http://arxiv.org/abs/2311.13184v1","updated":"2023-11-22T06:23:18Z","published":"2023-11-22T06:23:18Z","title":"AS-LLM: When Algorithm Selection Meets Large Language Model","summary":"  Algorithm selection aims to identify the most suitable algorithm for solving\na specific problem before execution, which has become a critical process of the\nAutoML. Current mainstream algorithm selection techniques rely heavily on\nfeature representations of various problems and employ the performance of each\nalgorithm as supervised information. However, there is a significant research\ngap concerning the consideration of algorithm features. This gap is primarily\nattributed to the inherent complexity of algorithms, making it particularly\nchallenging to find a universally effective feature extraction method that is\napplicable across a diverse range of algorithms. Unfortunately, neglecting this\naspect undoubtedly impacts the accuracy of algorithm selection and indirectly\nnecessitates an increased volume of problem data for training purposes. This\npaper takes a significant stride towards addressing this gap by proposing an\napproach that integrates algorithm representation into the algorithm selection\nprocess. Specifically, our proposed model employs distinct modules to extract\nrepresentations of both problems and algorithms, where the algorithm\nrepresentation leverages the capabilities of pre-trained LLMs in the realm of\ncode comprehension. Following the extraction of embedding vectors for both\nalgorithms and problems, the most suitable algorithm is determined through\ncalculations of matching degrees. Our experiments not only validate the\neffectiveness of the proposed model but also showcase the performance of\ndifferent embedded pre-trained LLMs, which suggests that the proposed algorithm\nselection framework holds the potential to serve as a baseline task for\nevaluating the code representation capabilities of LLMs.\n","authors":["Xingyu Wu","Yan Zhong","Jibin Wu","Kay Chen Tan"],"pdf_url":"https://arxiv.org/pdf/2311.13184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13171v1","updated":"2023-11-22T05:28:59Z","published":"2023-11-22T05:28:59Z","title":"ComPEFT: Compression for Communicating Parameter Efficient Updates via\n  Sparsification and Quantization","summary":"  Parameter-efficient fine-tuning (PEFT) techniques make it possible to\nefficiently adapt a language model to create \"expert\" models that specialize to\nnew tasks or domains. Recent techniques in model merging and compositional\ngeneralization leverage these expert models by dynamically composing modules to\nimprove zero/few-shot generalization. Despite the efficiency of PEFT methods,\nthe size of expert models can make it onerous to retrieve expert models per\nquery over high-latency networks like the Internet or serve multiple experts on\na single GPU. To address these issues, we present ComPEFT, a novel method for\ncompressing fine-tuning residuals (task vectors) of PEFT based models. ComPEFT\nemploys sparsification and ternary quantization to reduce the size of the PEFT\nmodule without performing any additional retraining while preserving or\nenhancing model performance. In extensive evaluation across T5, T0, and\nLLaMA-based models with 200M - 65B parameters, ComPEFT achieves compression\nratios of 8x - 50x. In particular, we show that ComPEFT improves with scale -\nstronger models exhibit higher compressibility and better performance. For\nexample, we show that ComPEFT applied to LLaMA outperforms QLoRA by 4.16% on\nMMLU with a storage size reduction of up to 26x. In addition, we show that the\ncompressed experts produced by ComPEFT maintain few-shot compositional\ngeneralization capabilities, facilitate efficient communication and\ncomputation, and exhibit enhanced performance when merged. Lastly, we provide\nan analysis of different method components, compare it with other PEFT methods,\nand test ComPEFT's efficacy for compressing the residual of full-finetuning.\nOur code is available at https://github.com/prateeky2806/compeft.\n","authors":["Prateek Yadav","Leshem Choshen","Colin Raffel","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2311.13171v1.pdf","comment":"25 Pages, 6 Figures, 16 Tables"},{"id":"http://arxiv.org/abs/2311.13133v1","updated":"2023-11-22T03:37:01Z","published":"2023-11-22T03:37:01Z","title":"LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms","summary":"  Large Language Models are traditionally finetuned on large instruction\ndatasets. However recent studies suggest that small, high-quality datasets can\nsuffice for general purpose instruction following. This lack of consensus\nsurrounding finetuning best practices is in part due to rapidly diverging\napproaches to LLM evaluation. In this study, we ask whether a small amount of\ndiverse finetuning samples can improve performance on both traditional\nperplexity-based NLP benchmarks, and on open-ended, model-based evaluation. We\nfinetune open-source MPT-7B and MPT-30B models on instruction finetuning\ndatasets of various sizes ranging from 1k to 60k samples. We find that subsets\nof 1k-6k instruction finetuning samples are sufficient to achieve good\nperformance on both (1) traditional NLP benchmarks and (2) model-based\nevaluation. Finally, we show that mixing textbook-style and open-ended QA\nfinetuning datasets optimizes performance on both evaluation paradigms.\n","authors":["Aditi Jha","Sam Havens","Jeremey Dohmann","Alex Trott","Jacob Portes"],"pdf_url":"https://arxiv.org/pdf/2311.13133v1.pdf","comment":"36 pages, 12 figures, NeurIPS 2023 Workshop on Instruction Tuning and\n  Instruction Following"},{"id":"http://arxiv.org/abs/2311.13126v1","updated":"2023-11-22T03:28:34Z","published":"2023-11-22T03:28:34Z","title":"Towards Better Parameter-Efficient Fine-Tuning for Large Language\n  Models: A Position Paper","summary":"  This paper delves into the pressing need in Parameter-Efficient Fine-Tuning\n(PEFT) for Large Language Models (LLMs). While LLMs possess remarkable\ncapabilities, their extensive parameter requirements and associated\ncomputational demands hinder their practicality and scalability for real-world\napplications. Our position paper highlights current states and the necessity of\nfurther studying into the topic, and recognizes significant challenges and open\nissues that must be addressed to fully harness the powerful abilities of LLMs.\nThese challenges encompass novel efficient PEFT architectures, PEFT for\ndifferent learning settings, PEFT combined with model compression techniques,\nand the exploration of PEFT for multi-modal LLMs. By presenting this position\npaper, we aim to stimulate further research and foster discussions surrounding\nmore efficient and accessible PEFT for LLMs.\n","authors":["Chengyu Wang","Junbing Yan","Wei Zhang","Jun Huang"],"pdf_url":"https://arxiv.org/pdf/2311.13126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13118v1","updated":"2023-11-22T02:45:01Z","published":"2023-11-22T02:45:01Z","title":"Combatting Human Trafficking in the Cyberspace: A Natural Language\n  Processing-Based Methodology to Analyze the Language in Online Advertisements","summary":"  This project tackles the pressing issue of human trafficking in online C2C\nmarketplaces through advanced Natural Language Processing (NLP) techniques. We\nintroduce a novel methodology for generating pseudo-labeled datasets with\nminimal supervision, serving as a rich resource for training state-of-the-art\nNLP models. Focusing on tasks like Human Trafficking Risk Prediction (HTRP) and\nOrganized Activity Detection (OAD), we employ cutting-edge Transformer models\nfor analysis. A key contribution is the implementation of an interpretability\nframework using Integrated Gradients, providing explainable insights crucial\nfor law enforcement. This work not only fills a critical gap in the literature\nbut also offers a scalable, machine learning-driven approach to combat human\nexploitation online. It serves as a foundation for future research and\npractical applications, emphasizing the role of machine learning in addressing\ncomplex social issues.\n","authors":["Alejandro Rodriguez Perez","Pablo Rivas"],"pdf_url":"https://arxiv.org/pdf/2311.13118v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13110v1","updated":"2023-11-22T02:23:32Z","published":"2023-11-22T02:23:32Z","title":"White-Box Transformers via Sparse Rate Reduction: Compression Is All\n  There Is?","summary":"  In this paper, we contend that a natural objective of representation learning\nis to compress and transform the distribution of the data, say sets of tokens,\ntowards a low-dimensional Gaussian mixture supported on incoherent subspaces.\nThe goodness of such a representation can be evaluated by a principled measure,\ncalled sparse rate reduction, that simultaneously maximizes the intrinsic\ninformation gain and extrinsic sparsity of the learned representation. From\nthis perspective, popular deep network architectures, including transformers,\ncan be viewed as realizing iterative schemes to optimize this measure.\nParticularly, we derive a transformer block from alternating optimization on\nparts of this objective: the multi-head self-attention operator compresses the\nrepresentation by implementing an approximate gradient descent step on the\ncoding rate of the features, and the subsequent multi-layer perceptron\nsparsifies the features. This leads to a family of white-box transformer-like\ndeep network architectures, named CRATE, which are mathematically fully\ninterpretable. We show, by way of a novel connection between denoising and\ncompression, that the inverse to the aforementioned compressive encoding can be\nrealized by the same class of CRATE architectures. Thus, the so-derived\nwhite-box architectures are universal to both encoders and decoders.\nExperiments show that these networks, despite their simplicity, indeed learn to\ncompress and sparsify representations of large-scale real-world image and text\ndatasets, and achieve performance very close to highly engineered\ntransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the\nproposed computational framework demonstrates great potential in bridging the\ngap between theory and practice of deep learning, from a unified perspective of\ndata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .\n","authors":["Yaodong Yu","Sam Buchanan","Druv Pai","Tianzhe Chu","Ziyang Wu","Shengbang Tong","Hao Bai","Yuexiang Zhai","Benjamin D. Haeffele","Yi Ma"],"pdf_url":"https://arxiv.org/pdf/2311.13110v1.pdf","comment":"This paper integrates the works arXiv:2306.01129 and\n  arXiv:2308.16271, as well as this under-review work:\n  https://openreview.net/forum?id=PvyOYleymy into a complete story. In this\n  paper, we improve the writing and organization, and also add conceptual,\n  empirical, and theoretical improvements over the previous work"},{"id":"http://arxiv.org/abs/2311.13105v1","updated":"2023-11-22T02:12:36Z","published":"2023-11-22T02:12:36Z","title":"Perceptual Structure in the Absence of Grounding for LLMs: The Impact of\n  Abstractedness and Subjectivity in Color Language","summary":"  The need for grounding in language understanding is an active research topic.\nPrevious work has suggested that color perception and color language appear as\na suitable test bed to empirically study the problem, given its cognitive\nsignificance and showing that there is considerable alignment between a defined\ncolor space and the feature space defined by a language model. To further study\nthis issue, we collect a large scale source of colors and their descriptions,\ncontaining almost a 1 million examples , and perform an empirical analysis to\ncompare two kinds of alignments: (i) inter-space, by learning a mapping between\nembedding space and color space, and (ii) intra-space, by means of prompting\ncomparatives between color descriptions. Our results show that while color\nspace alignment holds for monolexemic, highly pragmatic color descriptions,\nthis alignment drops considerably in the presence of examples that exhibit\nelements of real linguistic usage such as subjectivity and abstractedness,\nsuggesting that grounding may be required in such cases.\n","authors":["Pablo Loyola","Edison Marrese-Taylor","Andres Hoyos-Idobro"],"pdf_url":"https://arxiv.org/pdf/2311.13105v1.pdf","comment":"EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2311.13102v1","updated":"2023-11-22T02:04:35Z","published":"2023-11-22T02:04:35Z","title":"Detecting out-of-distribution text using topological features of\n  transformer-based language models","summary":"  We attempt to detect out-of-distribution (OOD) text samples though applying\nTopological Data Analysis (TDA) to attention maps in transformer-based language\nmodels. We evaluate our proposed TDA-based approach for out-of-distribution\ndetection on BERT, a transformer-based language model, and compare the to a\nmore traditional OOD approach based on BERT CLS embeddings. We found that our\nTDA approach outperforms the CLS embedding approach at distinguishing\nin-distribution data (politics and entertainment news articles from HuffPost)\nfrom far out-of-domain samples (IMDB reviews), but its effectiveness\ndeteriorates with near out-of-domain (CNN/Dailymail) or same-domain (business\nnews articles from HuffPost) datasets.\n","authors":["Andres Pollano","Anupam Chaudhuri","Anj Simmons"],"pdf_url":"https://arxiv.org/pdf/2311.13102v1.pdf","comment":"12 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2311.13095v1","updated":"2023-11-22T01:51:50Z","published":"2023-11-22T01:51:50Z","title":"Enhancing Logical Reasoning in Large Language Models to Facilitate Legal\n  Applications","summary":"  Language serves as a vehicle for conveying thought, enabling communication\namong individuals. The ability to distinguish between diverse concepts,\nidentify fairness and injustice, and comprehend a range of legal notions\nfundamentally relies on logical reasoning. Large Language Models (LLMs) attempt\nto emulate human language understanding and generation, but their competency in\nlogical reasoning remains limited. This paper seeks to address the\nphilosophical question: How can we effectively teach logical reasoning to LLMs\nwhile maintaining a deep understanding of the intricate relationship between\nlanguage and logic? By focusing on bolstering LLMs' capabilities in logical\nreasoning, we aim to expand their applicability in law and other\nlogic-intensive disciplines. To this end, we propose a Reinforcement Learning\nfrom Logical Feedback (RLLF) approach, which serves as a potential framework\nfor refining LLMs' reasoning capacities. Through RLLF and a revised evaluation\nmethodology, we explore new avenues for research in this domain and contribute\nto the development of LLMs capable of handling complex legal reasoning tasks\nwhile acknowledging the fundamental connection between language and logic.\n","authors":["Ha-Thanh Nguyen","Wachara Fungwacharakorn","Ken Satoh"],"pdf_url":"https://arxiv.org/pdf/2311.13095v1.pdf","comment":"ALP@JURIX2023"},{"id":"http://arxiv.org/abs/2310.12942v3","updated":"2023-11-22T01:39:59Z","published":"2023-10-19T17:39:47Z","title":"On the Representational Capacity of Recurrent Neural Language Models","summary":"  This work investigates the computational expressivity of language models\n(LMs) based on recurrent neural networks (RNNs). Siegelmann and Sontag (1992)\nfamously showed that RNNs with rational weights and hidden states and unbounded\ncomputation time are Turing complete. However, LMs define weightings over\nstrings in addition to just (unweighted) language membership and the analysis\nof the computational power of RNN LMs (RLMs) should reflect this. We extend the\nTuring completeness result to the probabilistic case, showing how a rationally\nweighted RLM with unbounded computation time can simulate any deterministic\nprobabilistic Turing machine (PTM) with rationally weighted transitions. Since,\nin practice, RLMs work in real-time, processing a symbol at every time step, we\ntreat the above result as an upper bound on the expressivity of RLMs. We also\nprovide a lower bound by showing that under the restriction to real-time\ncomputation, such models can simulate deterministic real-time rational PTMs.\n","authors":["Franz Nowak","Anej Svete","Li Du","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2310.12942v3.pdf","comment":"To be published at EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.10057v3","updated":"2023-11-22T21:22:11Z","published":"2023-11-16T17:52:21Z","title":"The Song Describer Dataset: a Corpus of Audio Captions for\n  Music-and-Language Evaluation","summary":"  We introduce the Song Describer dataset (SDD), a new crowdsourced corpus of\nhigh-quality audio-caption pairs, designed for the evaluation of\nmusic-and-language models. The dataset consists of 1.1k human-written natural\nlanguage descriptions of 706 music recordings, all publicly accessible and\nreleased under Creative Common licenses. To showcase the use of our dataset, we\nbenchmark popular models on three key music-and-language tasks (music\ncaptioning, text-to-music generation and music-language retrieval). Our\nexperiments highlight the importance of cross-dataset evaluation and offer\ninsights into how researchers can use SDD to gain a broader understanding of\nmodel performance.\n","authors":["Ilaria Manco","Benno Weck","SeungHeon Doh","Minz Won","Yixiao Zhang","Dmitry Bogdanov","Yusong Wu","Ke Chen","Philip Tovstogan","Emmanouil Benetos","Elio Quinton","György Fazekas","Juhan Nam"],"pdf_url":"https://arxiv.org/pdf/2311.10057v3.pdf","comment":"Accepted to NeurIPS 2023 Workshop on Machine Learning for Audio"},{"id":"http://arxiv.org/abs/2305.12401v2","updated":"2023-11-22T23:56:43Z","published":"2023-05-21T08:51:24Z","title":"WOT-Class: Weakly Supervised Open-world Text Classification","summary":"  State-of-the-art weakly supervised text classification methods, while\nsignificantly reduced the required human supervision, still requires the\nsupervision to cover all the classes of interest. This is never easy to meet in\npractice when human explore new, large corpora without complete pictures. In\nthis paper, we work on a novel yet important problem of weakly supervised\nopen-world text classification, where supervision is only needed for a few\nexamples from a few known classes and the machine should handle both known and\nunknown classes in test time. General open-world classification has been\nstudied mostly using image classification; however, existing methods typically\nassume the availability of sufficient known-class supervision and strong\nunknown-class prior knowledge (e.g., the number and/or data distribution). We\npropose a novel framework WOT-Class that lifts those strong assumptions.\nSpecifically, it follows an iterative process of (a) clustering text to new\nclasses, (b) mining and ranking indicative words for each class, and (c)\nmerging redundant classes by using the overlapped indicative words as a bridge.\nExtensive experiments on 7 popular text classification datasets demonstrate\nthat WOT-Class outperforms strong baselines consistently with a large margin,\nattaining 23.33% greater average absolute macro-F1 over existing approaches\nacross all datasets. Such competent accuracy illuminates the practical\npotential of further reducing human effort for text classification.\n","authors":["Tianle Wang","Zihan Wang","Weitang Liu","Jingbo Shang"],"pdf_url":"https://arxiv.org/pdf/2305.12401v2.pdf","comment":"Accepted by CIKM 2023"},{"id":"http://arxiv.org/abs/2311.13735v1","updated":"2023-11-22T23:35:13Z","published":"2023-11-22T23:35:13Z","title":"Surpassing GPT-4 Medical Coding with a Two-Stage Approach","summary":"  Recent advances in large language models (LLMs) show potential for clinical\napplications, such as clinical decision support and trial recommendations.\nHowever, the GPT-4 LLM predicts an excessive number of ICD codes for medical\ncoding tasks, leading to high recall but low precision. To tackle this\nchallenge, we introduce LLM-codex, a two-stage approach to predict ICD codes\nthat first generates evidence proposals using an LLM and then employs an\nLSTM-based verification stage. The LSTM learns from both the LLM's high recall\nand human expert's high precision, using a custom loss function. Our model is\nthe only approach that simultaneously achieves state-of-the-art results in\nmedical coding accuracy, accuracy on rare codes, and sentence-level evidence\nidentification to support coding decisions without training on human-annotated\nevidence according to experiments on the MIMIC dataset.\n","authors":["Zhichao Yang","Sanjit Singh Batra","Joel Stremmel","Eran Halperin"],"pdf_url":"https://arxiv.org/pdf/2311.13735v1.pdf","comment":"Extended Abstract presented at Machine Learning for Health (ML4H)\n  symposium 2023, December 10th, 2023, New Orleans, United States, 19 pages"},{"id":"http://arxiv.org/abs/2311.13729v1","updated":"2023-11-22T22:52:00Z","published":"2023-11-22T22:52:00Z","title":"Comparison of pipeline, sequence-to-sequence, and GPT models for\n  end-to-end relation extraction: experiments with the rare disease use-case","summary":"  End-to-end relation extraction (E2ERE) is an important and realistic\napplication of natural language processing (NLP) in biomedicine. In this paper,\nwe aim to compare three prevailing paradigms for E2ERE using a complex dataset\nfocused on rare diseases involving discontinuous and nested entities. We use\nthe RareDis information extraction dataset to evaluate three competing\napproaches (for E2ERE): NER $\\rightarrow$ RE pipelines, joint sequence to\nsequence models, and generative pre-trained transformer (GPT) models. We use\ncomparable state-of-the-art models and best practices for each of these\napproaches and conduct error analyses to assess their failure modes. Our\nfindings reveal that pipeline models are still the best, while\nsequence-to-sequence models are not far behind; GPT models with eight times as\nmany parameters are worse than even sequence-to-sequence models and lose to\npipeline models by over 10 F1 points. Partial matches and discontinuous\nentities caused many NER errors contributing to lower overall E2E performances.\nWe also verify these findings on a second E2ERE dataset for chemical-protein\ninteractions. Although generative LM-based methods are more suitable for\nzero-shot settings, when training data is available, our results show that it\nis better to work with more conventional models trained and tailored for E2ERE.\nMore innovative methods are needed to marry the best of the both worlds from\nsmaller encoder-decoder pipeline models and the larger GPT models to improve\nE2ERE. As of now, we see that well designed pipeline models offer substantial\nperformance gains at a lower cost and carbon footprint for E2ERE. Our\ncontribution is also the first to conduct E2ERE for the RareDis dataset.\n","authors":["Shashank Gupta","Xuguang Ai","Ramakanth Kavuluru"],"pdf_url":"https://arxiv.org/pdf/2311.13729v1.pdf","comment":"The dataset and code for all our experiments are publicly available:\n  https://github.com/shashank140195/Raredis"},{"id":"http://arxiv.org/abs/2311.13708v1","updated":"2023-11-22T21:59:46Z","published":"2023-11-22T21:59:46Z","title":"Dynamic Analysis Method for Hidden Dangers in Substation Based on\n  Knowledge Graph","summary":"  To address the challenge of identifying and understanding hidden dangers in\nsubstations from unstructured text data, a novel dynamic analysis method is\nproposed. This approach begins by analyzing and extracting data from the\nunstructured text related to hidden dangers. It then leverages a flexible,\ndistributed data search engine built on Elastic-Search to handle this\ninformation. Following this, the hidden Markov model is employed to train the\ndata within the engine. The Viterbi algorithm is integrated to decipher the\nhidden state sequences, facilitating the segmentation and labeling of entities\nrelated to hidden dangers. The final step involves using the Neo4j graph\ndatabase to dynamically create a knowledge map that visualizes hidden dangers\nin the substation. This method's effectiveness is demonstrated through an\nexample analysis using data from a specific substation's hidden dangers.\n","authors":["Weiwei Li","Xing Liu","Wei Wang","Lu Chen","Sizhe Li","Hui Fan"],"pdf_url":"https://arxiv.org/pdf/2311.13708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13668v1","updated":"2023-11-22T19:45:40Z","published":"2023-11-22T19:45:40Z","title":"MAIRA-1: A specialised large multimodal model for radiology report\n  generation","summary":"  We present a radiology-specific multimodal model for the task for generating\nradiological reports from chest X-rays (CXRs). Our work builds on the idea that\nlarge language model(s) can be equipped with multimodal capabilities through\nalignment with pre-trained vision encoders. On natural images, this has been\nshown to allow multimodal models to gain image understanding and description\ncapabilities. Our proposed model (MAIRA-1) leverages a CXR-specific image\nencoder in conjunction with a fine-tuned large language model based on\nVicuna-7B, and text-based data augmentation, to produce reports with\nstate-of-the-art quality. In particular, MAIRA-1 significantly improves on the\nradiologist-aligned RadCliQ metric and across all lexical metrics considered.\nManual review of model outputs demonstrates promising fluency and accuracy of\ngenerated reports while uncovering failure modes not captured by existing\nevaluation practices. More information and resources can be found on the\nproject website: https://aka.ms/maira.\n","authors":["Stephanie L. Hyland","Shruthi Bannur","Kenza Bouzid","Daniel C. Castro","Mercy Ranjit","Anton Schwaighofer","Fernando Pérez-García","Valentina Salvatelli","Shaury Srivastav","Anja Thieme","Noel Codella","Matthew P. Lungren","Maria Teodora Wetscherek","Ozan Oktay","Javier Alvarez-Valle"],"pdf_url":"https://arxiv.org/pdf/2311.13668v1.pdf","comment":"18 pages, 9 tables, 5 figures"},{"id":"http://arxiv.org/abs/2311.13657v1","updated":"2023-11-22T19:19:37Z","published":"2023-11-22T19:19:37Z","title":"Efficient Transformer Knowledge Distillation: A Performance Review","summary":"  As pretrained transformer language models continue to achieve\nstate-of-the-art performance, the Natural Language Processing community has\npushed for advances in model compression and efficient attention mechanisms to\naddress high computational requirements and limited input sequence length.\nDespite these separate efforts, no investigation has been done into the\nintersection of these two fields. In this work, we provide an evaluation of\nmodel compression via knowledge distillation on efficient attention\ntransformers. We provide cost-performance trade-offs for the compression of\nstate-of-the-art efficient attention architectures and the gains made in\nperformance in comparison to their full attention counterparts. Furthermore, we\nintroduce a new long-context Named Entity Recognition dataset, GONERD, to train\nand test the performance of NER models on long sequences. We find that\ndistilled efficient attention transformers can preserve a significant amount of\noriginal model performance, preserving up to 98.6% across short-context tasks\n(GLUE, SQUAD, CoNLL-2003), up to 94.6% across long-context\nQuestion-and-Answering tasks (HotpotQA, TriviaQA), and up to 98.8% on\nlong-context Named Entity Recognition (GONERD), while decreasing inference\ntimes by up to 57.8%. We find that, for most models on most tasks, performing\nknowledge distillation is an effective method to yield high-performing\nefficient attention models with low costs.\n","authors":["Nathan Brown","Ashton Williamson","Tahj Anderson","Logan Lawrence"],"pdf_url":"https://arxiv.org/pdf/2311.13657v1.pdf","comment":"Accepted to EMNLP 2023. 12 pages, 1 figure, 11 tables. Models and\n  data available at https://huggingface.co/giant-oak"},{"id":"http://arxiv.org/abs/2311.13647v1","updated":"2023-11-22T19:04:04Z","published":"2023-11-22T19:04:04Z","title":"Language Model Inversion","summary":"  Language models produce a distribution over the next token; can we use this\ninformation to recover the prompt tokens? We consider the problem of language\nmodel inversion and show that next-token probabilities contain a surprising\namount of information about the preceding text. Often we can recover the text\nin cases where it is hidden from the user, motivating a method for recovering\nunknown prompts given only the model's current distribution output. We consider\na variety of model access scenarios, and show how even without predictions for\nevery token in the vocabulary we can recover the probability vector through\nsearch. On Llama-2 7b, our inversion method reconstructs prompts with a BLEU of\n$59$ and token-level F1 of $78$ and recovers $27\\%$ of prompts exactly. Code\nfor reproducing all experiments is available at\nhttp://github.com/jxmorris12/vec2text.\n","authors":["John X. Morris","Wenting Zhao","Justin T. Chiu","Vitaly Shmatikov","Alexander M. Rush"],"pdf_url":"https://arxiv.org/pdf/2311.13647v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13628v1","updated":"2023-11-22T18:50:47Z","published":"2023-11-22T18:50:47Z","title":"Prompt Risk Control: A Rigorous Framework for Responsible Deployment of\n  Large Language Models","summary":"  The recent explosion in the capabilities of large language models has led to\na wave of interest in how best to prompt a model to perform a given task. While\nit may be tempting to simply choose a prompt based on average performance on a\nvalidation set, this can lead to a deployment where unexpectedly poor responses\nare generated, especially for the worst-off users. To mitigate this prospect,\nwe propose Prompt Risk Control, a lightweight framework for selecting a prompt\nbased on rigorous upper bounds on families of informative risk measures. We\noffer methods for producing bounds on a diverse set of metrics, including\nquantities that measure worst-case responses and disparities in generation\nquality across the population of users. In addition, we extend the underlying\nstatistical bounding techniques to accommodate the possibility of distribution\nshifts in deployment. Experiments on applications such as open-ended chat,\nmedical question summarization, and code generation highlight how such a\nframework can foster responsible deployment by reducing the risk of the worst\noutcomes.\n","authors":["Thomas P. Zollo","Todd Morrill","Zhun Deng","Jake C. Snell","Toniann Pitassi","Richard Zemel"],"pdf_url":"https://arxiv.org/pdf/2311.13628v1.pdf","comment":"33 pages, 10 figures, and accepted to the Socially Responsible\n  Language Modelling Research (SoLaR) workshop at NeurIPS 2023"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2311.12764v2","updated":"2023-11-22T18:52:11Z","published":"2023-11-21T18:18:50Z","title":"Investigating Weight-Perturbed Deep Neural Networks With Application in\n  Iris Presentation Attack Detection","summary":"  Deep neural networks (DNNs) exhibit superior performance in various machine\nlearning tasks, e.g., image classification, speech recognition, biometric\nrecognition, object detection, etc. However, it is essential to analyze their\nsensitivity to parameter perturbations before deploying them in real-world\napplications. In this work, we assess the sensitivity of DNNs against\nperturbations to their weight and bias parameters. The sensitivity analysis\ninvolves three DNN architectures (VGG, ResNet, and DenseNet), three types of\nparameter perturbations (Gaussian noise, weight zeroing, and weight scaling),\nand two settings (entire network and layer-wise). We perform experiments in the\ncontext of iris presentation attack detection and evaluate on two publicly\navailable datasets: LivDet-Iris-2017 and LivDet-Iris-2020. Based on the\nsensitivity analysis, we propose improved models simply by perturbing\nparameters of the network without undergoing training. We further combine these\nperturbed models at the score-level and at the parameter-level to improve the\nperformance over the original model. The ensemble at the parameter-level shows\nan average improvement of 43.58% on the LivDet-Iris-2017 dataset and 9.25% on\nthe LivDet-Iris-2020 dataset. The source code is available at\nhttps://github.com/redwankarimsony/WeightPerturbation-MSU.\n","authors":["Renu Sharma","Redwan Sony","Arun Ross"],"pdf_url":"https://arxiv.org/pdf/2311.12764v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12655v2","updated":"2023-11-22T09:00:02Z","published":"2023-11-21T14:57:24Z","title":"Hand-Eye Calibration","summary":"  Whenever a sensor is mounted on a robot hand it is important to know the\nrelationship between the sensor and the hand. The problem of determining this\nrelationship is referred to as hand-eye calibration, which is important in at\nleast two types of tasks: (i) map sensor centered measurements into the robot\nworkspace and (ii) allow the robot to precisely move the sensor. In the past\nsome solutions were proposed in the particular case of a camera. With almost no\nexception, all existing solutions attempt to solve the homogeneous matrix\nequation AX=XB. First we show that there are two possible formulations of the\nhand-eye calibration problem. One formulation is the classical one that we just\nmentioned. A second formulation takes the form of the following homogeneous\nmatrix equation: MY=M'YB. The advantage of the latter is that the extrinsic and\nintrinsic camera parameters need not be made explicit. Indeed, this formulation\ndirectly uses the 3 by 4 perspective matrices (M and M') associated with two\npositions of the camera. Moreover, this formulation together with the classical\none cover a wider range of camera-based sensors to be calibrated with respect\nto the robot hand. Second, we develop a common mathematical framework to solve\nfor the hand-eye calibration problem using either of the two formulations. We\npresent two methods, (i) a rotation then translation and (ii) a non-linear\nsolver for rotation and translation. Third, we perform a stability analysis\nboth for our two methods and for the classical linear method of Tsai and Lenz\n(1989). In the light of this comparison, the non-linear optimization method,\nthat solves for rotation and translation simultaneously, seems to be the most\nrobust one with respect to noise and to measurement errors.\n","authors":["Radu Horaud","Fadi Dornaika"],"pdf_url":"https://arxiv.org/pdf/2311.12655v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12603v2","updated":"2023-11-22T02:15:51Z","published":"2023-11-21T13:43:16Z","title":"Surgical Temporal Action-aware Network with Sequence Regularization for\n  Phase Recognition","summary":"  To assist surgeons in the operating theatre, surgical phase recognition is\ncritical for developing computer-assisted surgical systems, which requires\ncomprehensive understanding of surgical videos. Although existing studies made\ngreat progress, there are still two significant limitations worthy of\nimprovement. First, due to the compromise of resource consumption, frame-wise\nvisual features are extracted by 2D networks and disregard spatial and temporal\nknowledge of surgical actions, which hinders subsequent inter-frame modeling\nfor phase prediction. Second, these works simply utilize ordinary\nclassification loss with one-hot phase labels to optimize the phase\npredictions, and cannot fully explore surgical videos under inadequate\nsupervision. To overcome these two limitations, we propose a Surgical Temporal\nAction-aware Network with sequence Regularization, named STAR-Net, to recognize\nsurgical phases more accurately from input videos. Specifically, we propose an\nefficient multi-scale surgical temporal action (MS-STA) module, which\nintegrates visual features with spatial and temporal knowledge of surgical\nactions at the cost of 2D networks. Moreover, we devise the dual-classifier\nsequence regularization (DSR) to facilitate the training of STAR-Net by the\nsequence guidance of an auxiliary classifier with a smaller capacity. Our\nSTAR-Net with MS-STA and DSR can exploit visual features of surgical actions\nwith effective regularization, thereby leading to the superior performance of\nsurgical phase recognition. Extensive experiments on a large-scale gastrectomy\nsurgery dataset and the public Cholec80 benchmark prove that our STAR-Net\nsignificantly outperforms state-of-the-arts of surgical phase recognition.\n","authors":["Zhen Chen","Yuhao Zhai","Jun Zhang","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12603v2.pdf","comment":"Accepted by 2023 IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM 2023)"},{"id":"http://arxiv.org/abs/2311.12467v2","updated":"2023-11-22T06:01:46Z","published":"2023-11-21T09:27:30Z","title":"GLAD: Global-Local View Alignment and Background Debiasing for\n  Unsupervised Video Domain Adaptation with Large Domain Gap","summary":"  In this work, we tackle the challenging problem of unsupervised video domain\nadaptation (UVDA) for action recognition. We specifically focus on scenarios\nwith a substantial domain gap, in contrast to existing works primarily deal\nwith small domain gaps between labeled source domains and unlabeled target\ndomains. To establish a more realistic setting, we introduce a novel UVDA\nscenario, denoted as Kinetics->BABEL, with a more considerable domain gap in\nterms of both temporal dynamics and background shifts. To tackle the temporal\nshift, i.e., action duration difference between the source and target domains,\nwe propose a global-local view alignment approach. To mitigate the background\nshift, we propose to learn temporal order sensitive representations by temporal\norder learning and background invariant representations by background\naugmentation. We empirically validate that the proposed method shows\nsignificant improvement over the existing methods on the Kinetics->BABEL\ndataset with a large domain gap. The code is available at\nhttps://github.com/KHUVLL/GLAD.\n","authors":["Hyogun Lee","Kyungho Bae","Seong Jong Ha","Yumin Ko","Gyeong-Moon Park","Jinwoo Choi"],"pdf_url":"https://arxiv.org/pdf/2311.12467v2.pdf","comment":"This is an accepted WACV 2024 paper. Our code is available at\n  https://github.com/KHUVLL/GLAD"},{"id":"http://arxiv.org/abs/2310.08897v3","updated":"2023-11-22T05:15:38Z","published":"2023-10-13T06:58:52Z","title":"Self supervised convolutional kernel based handcrafted feature\n  harmonization: Enhanced left ventricle hypertension disease phenotyping on\n  echocardiography","summary":"  Radiomics, a medical imaging technique, extracts quantitative handcrafted\nfeatures from images to predict diseases. Harmonization in those features\nensures consistent feature extraction across various imaging devices and\nprotocols. Methods for harmonization include standardized imaging protocols,\nstatistical adjustments, and evaluating feature robustness. Myocardial diseases\nsuch as Left Ventricular Hypertrophy (LVH) and Hypertensive Heart Disease (HHD)\nare diagnosed via echocardiography, but variable imaging settings pose\nchallenges. Harmonization techniques are crucial for applying handcrafted\nfeatures in disease diagnosis in such scenario. Self-supervised learning (SSL)\nenhances data understanding within limited datasets and adapts to diverse data\nsettings. ConvNeXt-V2 integrates convolutional layers into SSL, displaying\nsuperior performance in various tasks. This study focuses on convolutional\nfilters within SSL, using them as preprocessing to convert images into feature\nmaps for handcrafted feature harmonization. Our proposed method excelled in\nharmonization evaluation and exhibited superior LVH classification performance\ncompared to existing methods.\n","authors":["Jina Lee","Youngtaek Hong","Dawun Jeong","Yeonggul Jang","Jaeik Jeon","Sihyeon Jeong","Taekgeun Jung","Yeonyee E. Yoon","Inki Moon","Seung-Ah Lee","Hyuk-Jae Chang"],"pdf_url":"https://arxiv.org/pdf/2310.08897v3.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.12437v2","updated":"2023-11-22T11:38:46Z","published":"2023-11-21T08:47:08Z","title":"Learning Site-specific Styles for Multi-institutional Unsupervised\n  Cross-modality Domain Adaptation","summary":"  Unsupervised cross-modality domain adaptation is a challenging task in\nmedical image analysis, and it becomes more challenging when source and target\ndomain data are collected from multiple institutions. In this paper, we present\nour solution to tackle the multi-institutional unsupervised domain adaptation\nfor the crossMoDA 2023 challenge. First, we perform unpaired image translation\nto translate the source domain images to the target domain, where we design a\ndynamic network to generate synthetic target domain images with controllable,\nsite-specific styles. Afterwards, we train a segmentation model using the\nsynthetic images and further reduce the domain gap by self-training. Our\nsolution achieved the 1st place during both the validation and testing phases\nof the challenge. The code repository is publicly available at\nhttps://github.com/MedICL-VU/crossmoda2023.\n","authors":["Han Liu","Yubo Fan","Zhoubing Xu","Benoit M. Dawant","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2311.12437v2.pdf","comment":"crossMoDA 2023 challenge 1st place solution"},{"id":"http://arxiv.org/abs/2304.07647v3","updated":"2023-11-22T05:20:22Z","published":"2023-04-15T22:24:05Z","title":"LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene\n  Graphs with Weak Supervision","summary":"  We propose LASER, a neuro-symbolic approach to learn semantic video\nrepresentations that capture rich spatial and temporal properties in video data\nby leveraging high-level logic specifications. In particular, we formulate the\nproblem in terms of alignment between raw videos and spatio-temporal logic\nspecifications. The alignment algorithm leverages a differentiable symbolic\nreasoner and a combination of contrastive, temporal, and semantics losses. It\neffectively and efficiently trains low-level perception models to extract\nfine-grained video representation in the form of a spatio-temporal scene graph\nthat conforms to the desired high-level specification. In doing so, we explore\na novel methodology that weakly supervises the learning of video semantic\nrepresentations through logic specifications. We evaluate our method on two\ndatasets with rich spatial and temporal specifications:\n20BN-Something-Something and MUGEN. We demonstrate that our method learns\nbetter fine-grained video semantics than existing baselines.\n","authors":["Jiani Huang","Ziyang Li","Mayur Naik","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2304.07647v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12198v2","updated":"2023-11-22T06:46:18Z","published":"2023-11-20T21:34:52Z","title":"PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics","summary":"  We introduce PhysGaussian, a new method that seamlessly integrates physically\ngrounded Newtonian dynamics within 3D Gaussians to achieve high-quality novel\nmotion synthesis. Employing a custom Material Point Method (MPM), our approach\nenriches 3D Gaussian kernels with physically meaningful kinematic deformation\nand mechanical stress attributes, all evolved in line with continuum mechanics\nprinciples. A defining characteristic of our method is the seamless integration\nbetween physical simulation and visual rendering: both components utilize the\nsame 3D Gaussian kernels as their discrete representations. This negates the\nnecessity for triangle/tetrahedron meshing, marching cubes, \"cage meshes,\" or\nany other geometry embedding, highlighting the principle of \"what you see is\nwhat you simulate (WS$^2$).\" Our method demonstrates exceptional versatility\nacross a wide variety of materials--including elastic entities, metals,\nnon-Newtonian fluids, and granular materials--showcasing its strong\ncapabilities in creating diverse visual content with novel viewpoints and\nmovements. Our project page is at: https://xpandora.github.io/PhysGaussian/\n","authors":["Tianyi Xie","Zeshun Zong","Yuxing Qiu","Xuan Li","Yutao Feng","Yin Yang","Chenfanfu Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.12198v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12161v2","updated":"2023-11-22T03:23:17Z","published":"2023-11-20T20:27:42Z","title":"ChemScraper: Graphics Extraction, Molecular Diagram Parsing, and\n  Annotated Data Generation for PDF Images","summary":"  Existing visual parsers for molecule diagrams translate pixel-based raster\nimages such as PNGs to chemical structure representations (e.g., SMILES).\nHowever, PDFs created by word processors including LaTeX and Word provide\nexplicit locations and shapes for characters, lines, and polygons. We extract\nsymbols from born-digital PDF molecule images and then apply simple graph\ntransformations to capture both visual and chemical structure in editable\nChemDraw files (CDXML). Our fast ( PDF $\\rightarrow$ visual graph $\\rightarrow$\nchemical graph ) pipeline does not require GPUs, Optical Character Recognition\n(OCR) or vectorization. We evaluate on standard benchmarks using SMILES\nstrings, along with a novel evaluation that provides graph-based metrics and\nerror compilation using LgEval. The geometric information in born-digital PDFs\nproduces a highly accurate parser, motivating generating training data for\nvisual parsers that recognize from raster images, with extracted graphics,\nvisual structure, and chemical structure as annotations. To do this we render\nSMILES strings in Indigo, parse molecule structure, and then validate\nrecognized structure to select correct files.\n","authors":["Ayush Kumar Shah","Bryan Manrique Amador","Abhisek Dey","Ming Creekmore","Blake Ocampo","Scott Denmark","Richard Zanibbi"],"pdf_url":"https://arxiv.org/pdf/2311.12161v2.pdf","comment":"20 pages without references, 10 figures, 3 Tables, submitted to\n  International Journal on Document Analysis and Recognition (IJDAR)"},{"id":"http://arxiv.org/abs/2311.12144v2","updated":"2023-11-22T02:19:41Z","published":"2023-11-20T19:45:27Z","title":"Applications of Large Scale Foundation Models for Autonomous Driving","summary":"  Since DARPA Grand Challenges (rural) in 2004/05 and Urban Challenges in 2007,\nautonomous driving has been the most active field of AI applications. Recently\npowered by large language models (LLMs), chat systems, such as chatGPT and\nPaLM, emerge and rapidly become a promising direction to achieve artificial\ngeneral intelligence (AGI) in natural language processing (NLP). There comes a\nnatural thinking that we could employ these abilities to reformulate autonomous\ndriving. By combining LLM with foundation models, it is possible to utilize the\nhuman knowledge, commonsense and reasoning to rebuild autonomous driving\nsystems from the current long-tailed AI dilemma. In this paper, we investigate\nthe techniques of foundation models and LLMs applied for autonomous driving,\ncategorized as simulation, world model, data annotation and planning or E2E\nsolutions etc.\n","authors":["Yu Huang","Yue Chen","Zhu Li"],"pdf_url":"https://arxiv.org/pdf/2311.12144v2.pdf","comment":"23 pages. arXiv admin note: text overlap with arXiv:2304.03589,\n  arXiv:2111.05849, arXiv:2306.03000, arXiv:2301.02691, arXiv:2309.16292,\n  arXiv:2309.17080, arXiv:2309.10228, arXiv:2310.01415 by other authors"},{"id":"http://arxiv.org/abs/2311.11772v2","updated":"2023-11-22T17:06:31Z","published":"2023-11-20T13:58:26Z","title":"A Good Feature Extractor Is All You Need for Weakly Supervised Learning\n  in Histopathology","summary":"  Deep learning is revolutionising pathology, offering novel opportunities in\ndisease prognosis and personalised treatment. Historically, stain normalisation\nhas been a crucial preprocessing step in computational pathology pipelines, and\npersists into the deep learning era. Yet, with the emergence of feature\nextractors trained using self-supervised learning (SSL) on diverse pathology\ndatasets, we call this practice into question. In an empirical evaluation of\npublicly available feature extractors, we find that omitting stain\nnormalisation and image augmentations does not compromise downstream\nperformance, while incurring substantial savings in memory and compute.\nFurther, we show that the top-performing feature extractors are remarkably\nrobust to variations in stain and augmentations like rotation in their latent\nspace. Contrary to previous patch-level benchmarking studies, our approach\nemphasises clinical relevance by focusing on slide-level prediction tasks in a\nweakly supervised setting with external validation cohorts. This work\nrepresents the most comprehensive robustness evaluation of public pathology SSL\nfeature extractors to date, involving more than 6,000 training runs across nine\ntasks, five datasets, three downstream architectures, and various preprocessing\nsetups. Our findings stand to streamline digital pathology workflows by\nminimising preprocessing needs and informing the selection of feature\nextractors.\n","authors":["Georg Wölflein","Dyke Ferber","Asier Rabasco Meneghetti","Omar S. M. El Nahhas","Daniel Truhn","Zunamys I. Carrero","David J. Harrison","Ognjen Arandjelović","Jakob N. Kather"],"pdf_url":"https://arxiv.org/pdf/2311.11772v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13602v1","updated":"2023-11-22T18:59:53Z","published":"2023-11-22T18:59:53Z","title":"Retrieval-Augmented Layout Transformer for Content-Aware Layout\n  Generation","summary":"  Content-aware graphic layout generation aims to automatically arrange visual\nelements along with a given content, such as an e-commerce product image. In\nthis paper, we argue that the current layout generation approaches suffer from\nthe limited training data for the high-dimensional layout structure. We show\nthat a simple retrieval augmentation can significantly improve the generation\nquality. Our model, which is named Retrieval-Augmented Layout Transformer\n(RALF), retrieves nearest neighbor layout examples based on an input image and\nfeeds these results into an autoregressive generator. Our model can apply\nretrieval augmentation to various controllable generation tasks and yield\nhigh-quality layouts within a unified architecture. Our extensive experiments\nshow that RALF successfully generates content-aware layouts in both constrained\nand unconstrained settings and significantly outperforms the baselines.\n","authors":["Daichi Horita","Naoto Inoue","Kotaro Kikuchi","Kota Yamaguchi","Kiyoharu Aizawa"],"pdf_url":"https://arxiv.org/pdf/2311.13602v1.pdf","comment":"Webpage: https://udonda.github.io/RALF/"},{"id":"http://arxiv.org/abs/2311.13601v1","updated":"2023-11-22T18:59:48Z","published":"2023-11-22T18:59:48Z","title":"Visual In-Context Prompting","summary":"  In-context prompting in large language models (LLMs) has become a prevalent\napproach to improve zero-shot capabilities, but this idea is less explored in\nthe vision domain. Existing visual prompting methods focus on referring\nsegmentation to segment the most relevant object, falling short of addressing\nmany generic vision tasks like open-set segmentation and detection. In this\npaper, we introduce a universal visual in-context prompting framework for both\ntasks. In particular, we build on top of an encoder-decoder architecture, and\ndevelop a versatile prompt encoder to support a variety of prompts like\nstrokes, boxes, and points. We further enhance it to take an arbitrary number\nof reference image segments as the context. Our extensive explorations show\nthat the proposed visual in-context prompting elicits extraordinary referring\nand generic segmentation capabilities to refer and detect, yielding competitive\nperformance to close-set in-domain datasets and showing promising results on\nmany open-set segmentation datasets. By joint training on COCO and SA-1B, our\nmodel achieves $57.7$ PQ on COCO and $23.2$ PQ on ADE20K. Code will be\navailable at https://github.com/UX-Decoder/DINOv.\n","authors":["Feng Li","Qing Jiang","Hao Zhang","Tianhe Ren","Shilong Liu","Xueyan Zou","Huaizhe Xu","Hongyang Li","Chunyuan Li","Jianwei Yang","Lei Zhang","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2311.13601v1.pdf","comment":"technical report"},{"id":"http://arxiv.org/abs/2311.13600v1","updated":"2023-11-22T18:59:36Z","published":"2023-11-22T18:59:36Z","title":"ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs","summary":"  Methods for finetuning generative models for concept-driven personalization\ngenerally achieve strong results for subject-driven or style-driven generation.\nRecently, low-rank adaptations (LoRA) have been proposed as a\nparameter-efficient way of achieving concept-driven personalization. While\nrecent work explores the combination of separate LoRAs to achieve joint\ngeneration of learned styles and subjects, existing techniques do not reliably\naddress the problem; they often compromise either subject fidelity or style\nfidelity. We propose ZipLoRA, a method to cheaply and effectively merge\nindependently trained style and subject LoRAs in order to achieve generation of\nany user-provided subject in any user-provided style. Experiments on a wide\nrange of subject and style combinations show that ZipLoRA can generate\ncompelling results with meaningful improvements over baselines in subject and\nstyle fidelity while preserving the ability to recontextualize. Project page:\nhttps://ziplora.github.io\n","authors":["Viraj Shah","Nataniel Ruiz","Forrester Cole","Erika Lu","Svetlana Lazebnik","Yuanzhen Li","Varun Jampani"],"pdf_url":"https://arxiv.org/pdf/2311.13600v1.pdf","comment":"Project page: https://ziplora.github.io"},{"id":"http://arxiv.org/abs/2311.13596v1","updated":"2023-11-22T18:57:24Z","published":"2023-11-22T18:57:24Z","title":"T-Rex: Counting by Visual Prompting","summary":"  We introduce T-Rex, an interactive object counting model designed to first\ndetect and then count any objects. We formulate object counting as an open-set\nobject detection task with the integration of visual prompts. Users can specify\nthe objects of interest by marking points or boxes on a reference image, and\nT-Rex then detects all objects with a similar pattern. Guided by the visual\nfeedback from T-Rex, users can also interactively refine the counting results\nby prompting on missing or falsely-detected objects. T-Rex has achieved\nstate-of-the-art performance on several class-agnostic counting benchmarks. To\nfurther exploit its potential, we established a new counting benchmark\nencompassing diverse scenarios and challenges. Both quantitative and\nqualitative results show that T-Rex possesses exceptional zero-shot counting\ncapabilities. We also present various practical application scenarios for\nT-Rex, illustrating its potential in the realm of visual prompting.\n","authors":["Qing Jiang","Feng Li","Tianhe Ren","Shilong Liu","Zhaoyang Zeng","Kent Yu","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.13596v1.pdf","comment":"Technical report. Work in progress"},{"id":"http://arxiv.org/abs/2311.13574v1","updated":"2023-11-22T18:30:42Z","published":"2023-11-22T18:30:42Z","title":"XAGen: 3D Expressive Human Avatars Generation","summary":"  Recent advances in 3D-aware GAN models have enabled the generation of\nrealistic and controllable human body images. However, existing methods focus\non the control of major body joints, neglecting the manipulation of expressive\nattributes, such as facial expressions, jaw poses, hand poses, and so on. In\nthis work, we present XAGen, the first 3D generative model for human avatars\ncapable of expressive control over body, face, and hands. To enhance the\nfidelity of small-scale regions like face and hands, we devise a multi-scale\nand multi-part 3D representation that models fine details. Based on this\nrepresentation, we propose a multi-part rendering technique that disentangles\nthe synthesis of body, face, and hands to ease model training and enhance\ngeometric quality. Furthermore, we design multi-part discriminators that\nevaluate the quality of the generated avatars with respect to their appearance\nand fine-grained control capabilities. Experiments show that XAGen surpasses\nstate-of-the-art methods in terms of realism, diversity, and expressive control\nabilities. Code and data will be made available at\nhttps://showlab.github.io/xagen.\n","authors":["Zhongcong Xu","Jianfeng Zhang","Jun Hao Liew","Jiashi Feng","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2311.13574v1.pdf","comment":"Accepted to NeurIPS 2023, Project Page at\n  https://showlab.github.io/xagen"},{"id":"http://arxiv.org/abs/2311.13570v1","updated":"2023-11-22T18:25:51Z","published":"2023-11-22T18:25:51Z","title":"WildFusion: Learning 3D-Aware Latent Diffusion Models in View Space","summary":"  Modern learning-based approaches to 3D-aware image synthesis achieve high\nphotorealism and 3D-consistent viewpoint changes for the generated images.\nExisting approaches represent instances in a shared canonical space. However,\nfor in-the-wild datasets a shared canonical system can be difficult to define\nor might not even exist. In this work, we instead model instances in view\nspace, alleviating the need for posed images and learned camera distributions.\nWe find that in this setting, existing GAN-based methods are prone to\ngenerating flat geometry and struggle with distribution coverage. We hence\npropose WildFusion, a new approach to 3D-aware image synthesis based on latent\ndiffusion models (LDMs). We first train an autoencoder that infers a compressed\nlatent representation, which additionally captures the images' underlying 3D\nstructure and enables not only reconstruction but also novel view synthesis. To\nlearn a faithful 3D representation, we leverage cues from monocular depth\nprediction. Then, we train a diffusion model in the 3D-aware latent space,\nthereby enabling synthesis of high-quality 3D-consistent image samples,\noutperforming recent state-of-the-art GAN-based methods. Importantly, our\n3D-aware LDM is trained without any direct supervision from multiview images or\n3D geometry and does not require posed images or learned pose or camera\ndistributions. It directly learns a 3D representation without relying on\ncanonical camera coordinates. This opens up promising research avenues for\nscalable 3D-aware image synthesis and 3D content creation from in-the-wild\nimage data. See https://katjaschwarz.github.io/wildfusion for videos of our 3D\nresults.\n","authors":["Katja Schwarz","Seung Wook Kim","Jun Gao","Sanja Fidler","Andreas Geiger","Karsten Kreis"],"pdf_url":"https://arxiv.org/pdf/2311.13570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13562v1","updated":"2023-11-22T18:15:43Z","published":"2023-11-22T18:15:43Z","title":"Soulstyler: Using Large Language Model to Guide Image Style Transfer for\n  Target Object","summary":"  Image style transfer occupies an important place in both computer graphics\nand computer vision. However, most current methods require reference to\nstylized images and cannot individually stylize specific objects. To overcome\nthis limitation, we propose the \"Soulstyler\" framework, which allows users to\nguide the stylization of specific objects in an image through simple textual\ndescriptions. We introduce a large language model to parse the text and\nidentify stylization goals and specific styles. Combined with a CLIP-based\nsemantic visual embedding encoder, the model understands and matches text and\nimage content. We also introduce a novel localized text-image block matching\nloss that ensures that style transfer is performed only on specified target\nobjects, while non-target regions remain in their original style. Experimental\nresults demonstrate that our model is able to accurately perform style transfer\non target objects according to textual descriptions without affecting the style\nof background regions. Our code will be available at\nhttps://github.com/yisuanwang/Soulstyler.\n","authors":["Junhao Chen","Peng Rong","Jingbo Sun","Chao Li","Xiang Li","Hongwu Lv"],"pdf_url":"https://arxiv.org/pdf/2311.13562v1.pdf","comment":"5 pages,3 figures,ICASSP2024"},{"id":"http://arxiv.org/abs/2311.13559v1","updated":"2023-11-22T18:09:42Z","published":"2023-11-22T18:09:42Z","title":"Transfer Learning-based Real-time Handgun Detection","summary":"  Traditional surveillance systems rely on human attention, limiting their\neffectiveness. This study employs convolutional neural networks and transfer\nlearning to develop a real-time computer vision system for automatic handgun\ndetection. Comprehensive analysis of online handgun detection methods is\nconducted, emphasizing reducing false positives and learning time. Transfer\nlearning is demonstrated as an effective approach. Despite technical\nchallenges, the proposed system achieves a precision rate of 84.74%,\ndemonstrating promising performance comparable to related works, enabling\nfaster learning and accurate automatic handgun detection for enhanced security.\nThis research advances security measures by reducing human monitoring\ndependence, showcasing the potential of transfer learning-based approaches for\nefficient and reliable handgun detection.\n","authors":["Youssef Elmir","Sid Ahmed Laouar","Larbi Hamdaoui"],"pdf_url":"https://arxiv.org/pdf/2311.13559v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13549v1","updated":"2023-11-22T17:44:29Z","published":"2023-11-22T17:44:29Z","title":"ADriver-I: A General World Model for Autonomous Driving","summary":"  Typically, autonomous driving adopts a modular design, which divides the full\nstack into perception, prediction, planning and control parts. Though\ninterpretable, such modular design tends to introduce a substantial amount of\nredundancy. Recently, multimodal large language models (MLLM) and diffusion\ntechniques have demonstrated their superior performance on comprehension and\ngeneration ability. In this paper, we first introduce the concept of\ninterleaved vision-action pair, which unifies the format of visual features and\ncontrol signals. Based on the vision-action pairs, we construct a general world\nmodel based on MLLM and diffusion model for autonomous driving, termed\nADriver-I. It takes the vision-action pairs as inputs and autoregressively\npredicts the control signal of the current frame. The generated control signals\ntogether with the historical vision-action pairs are further conditioned to\npredict the future frames. With the predicted next frame, ADriver-I performs\nfurther control signal prediction. Such a process can be repeated infinite\ntimes, ADriver-I achieves autonomous driving in the world created by itself.\nExtensive experiments are conducted on nuScenes and our large-scale private\ndatasets. ADriver-I shows impressive performance compared to several\nconstructed baselines. We hope our ADriver-I can provide some new insights for\nfuture autonomous driving and embodied intelligence.\n","authors":["Fan Jia","Weixin Mao","Yingfei Liu","Yucheng Zhao","Yuqing Wen","Chi Zhang","Xiangyu Zhang","Tiancai Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13549v1.pdf","comment":"Tech Report"},{"id":"http://arxiv.org/abs/2311.13547v1","updated":"2023-11-22T17:42:33Z","published":"2023-11-22T17:42:33Z","title":"Medical Image Retrieval Using Pretrained Embeddings","summary":"  A wide range of imaging techniques and data formats available for medical\nimages make accurate retrieval from image databases challenging.\n  Efficient retrieval systems are crucial in advancing medical research,\nenabling large-scale studies and innovative diagnostic tools. Thus, addressing\nthe challenges of medical image retrieval is essential for the continued\nenhancement of healthcare and research.\n  In this study, we evaluated the feasibility of employing four\nstate-of-the-art pretrained models for medical image retrieval at modality,\nbody region, and organ levels and compared the results of two similarity\nindexing approaches. Since the employed networks take 2D images, we analyzed\nthe impacts of weighting and sampling strategies to incorporate 3D information\nduring retrieval of 3D volumes. We showed that medical image retrieval is\nfeasible using pretrained networks without any additional training or\nfine-tuning steps. Using pretrained embeddings, we achieved a recall of 1 for\nvarious tasks at modality, body region, and organ level.\n","authors":["Farnaz Khun Jush","Tuan Truong","Steffen Vogler","Matthias Lenga"],"pdf_url":"https://arxiv.org/pdf/2311.13547v1.pdf","comment":"8 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.13535v1","updated":"2023-11-22T17:16:44Z","published":"2023-11-22T17:16:44Z","title":"DiffusionMat: Alpha Matting as Sequential Refinement Learning","summary":"  In this paper, we introduce DiffusionMat, a novel image matting framework\nthat employs a diffusion model for the transition from coarse to refined alpha\nmattes. Diverging from conventional methods that utilize trimaps merely as\nloose guidance for alpha matte prediction, our approach treats image matting as\na sequential refinement learning process. This process begins with the addition\nof noise to trimaps and iteratively denoises them using a pre-trained diffusion\nmodel, which incrementally guides the prediction towards a clean alpha matte.\nThe key innovation of our framework is a correction module that adjusts the\noutput at each denoising step, ensuring that the final result is consistent\nwith the input image's structures. We also introduce the Alpha Reliability\nPropagation, a novel technique designed to maximize the utility of available\nguidance by selectively enhancing the trimap regions with confident alpha\ninformation, thus simplifying the correction task. To train the correction\nmodule, we devise specialized loss functions that target the accuracy of the\nalpha matte's edges and the consistency of its opaque and transparent regions.\nWe evaluate our model across several image matting benchmarks, and the results\nindicate that DiffusionMat consistently outperforms existing methods. Project\npage at~\\url{https://cnnlstm.github.io/DiffusionMat\n","authors":["Yangyang Xu","Shengfeng He","Wenqi Shao","Kwan-Yee K. Wong","Yu Qiao","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2311.13535v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13531v1","updated":"2023-11-22T17:06:57Z","published":"2023-11-22T17:06:57Z","title":"Leveraging CNNs and Ensemble Learning for Automated Disaster Image\n  Classification","summary":"  Natural disasters act as a serious threat globally, requiring effective and\nefficient disaster management and recovery. This paper focuses on classifying\nnatural disaster images using Convolutional Neural Networks (CNNs). Multiple\nCNN architectures were built and trained on a dataset containing images of\nearthquakes, floods, wildfires, and volcanoes. A stacked CNN ensemble approach\nproved to be the most effective, achieving 95% accuracy and an F1 score going\nup to 0.96 for individual classes. Tuning hyperparameters of individual models\nfor optimization was critical to maximize the models' performance. The stacking\nof CNNs with XGBoost acting as the meta-model utilizes the strengths of the CNN\nand ResNet models to improve the overall accuracy of the classification.\nResults obtained from the models illustrated the potency of CNN-based models\nfor automated disaster image classification. This lays the foundation for\nexpanding these techniques to build robust systems for disaster response,\ndamage assessment, and recovery management.\n","authors":["Archit Rathod","Veer Pariawala","Mokshit Surana","Kumkum Saxena"],"pdf_url":"https://arxiv.org/pdf/2311.13531v1.pdf","comment":"13 pages, 11 figures, 4 tables, ICSISCET 2023 Conference"},{"id":"http://arxiv.org/abs/2311.11284v2","updated":"2023-11-22T16:54:17Z","published":"2023-11-19T09:59:09Z","title":"LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval\n  Score Matching","summary":"  The recent advancements in text-to-3D generation mark a significant milestone\nin generative models, unlocking new possibilities for creating imaginative 3D\nassets across various real-world scenarios. While recent advancements in\ntext-to-3D generation have shown promise, they often fall short in rendering\ndetailed and high-quality 3D models. This problem is especially prevalent as\nmany methods base themselves on Score Distillation Sampling (SDS). This paper\nidentifies a notable deficiency in SDS, that it brings inconsistent and\nlow-quality updating direction for the 3D model, causing the over-smoothing\neffect. To address this, we propose a novel approach called Interval Score\nMatching (ISM). ISM employs deterministic diffusing trajectories and utilizes\ninterval-based score matching to counteract over-smoothing. Furthermore, we\nincorporate 3D Gaussian Splatting into our text-to-3D generation pipeline.\nExtensive experiments show that our model largely outperforms the\nstate-of-the-art in quality and training efficiency.\n","authors":["Yixun Liang","Xin Yang","Jiantao Lin","Haodong Li","Xiaogang Xu","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.11284v2.pdf","comment":"The first two authors contributed equally to this work. Our code will\n  be available at: https://github.com/EnVision-Research/LucidDreamer"},{"id":"http://arxiv.org/abs/2311.13512v1","updated":"2023-11-22T16:35:43Z","published":"2023-11-22T16:35:43Z","title":"Hybrid Whale-Mud-Ring Optimization for Precise Color Skin Cancer Image\n  Segmentation","summary":"  Timely identification and treatment of rapidly progressing skin cancers can\nsignificantly contribute to the preservation of patients' health and\nwell-being. Dermoscopy, a dependable and accessible tool, plays a pivotal role\nin the initial stages of skin cancer detection. Consequently, the effective\nprocessing of digital dermoscopy images holds significant importance in\nelevating the accuracy of skin cancer diagnoses. Multilevel thresholding is a\nkey tool in medical imaging that extracts objects within the image to\nfacilitate its analysis. In this paper, an enhanced version of the Mud Ring\nAlgorithm hybridized with the Whale Optimization Algorithm, named WMRA, is\nproposed. The proposed approach utilizes bubble-net attack and mud ring\nstrategy to overcome stagnation in local optima and obtain optimal thresholds.\nThe experimental results show that WMRA is powerful against a cluster of recent\nmethods in terms of fitness, Peak Signal to Noise Ratio (PSNR), and Mean Square\nError (MSE).\n","authors":["Amir Hamza","Badis Lekouaghet","Yassine Himeur"],"pdf_url":"https://arxiv.org/pdf/2311.13512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15755v2","updated":"2023-11-22T16:16:43Z","published":"2023-06-27T19:15:06Z","title":"Adversarial Backdoor Attack by Naturalistic Data Poisoning on Trajectory\n  Prediction in Autonomous Driving","summary":"  In autonomous driving, behavior prediction is fundamental for safe motion\nplanning, hence the security and robustness of prediction models against\nadversarial attacks are of paramount importance. We propose a novel adversarial\nbackdoor attack against trajectory prediction models as a means of studying\ntheir potential vulnerabilities. Our attack affects the victim at training time\nvia naturalistic, hence stealthy, poisoned samples crafted using a novel\ntwo-step approach. First, the triggers are crafted by perturbing the trajectory\nof attacking vehicle and then disguised by transforming the scene using a\nbi-level optimization technique. The proposed attack does not depend on a\nparticular model architecture and operates in a black-box manner, thus can be\neffective without any knowledge of the victim model. We conduct extensive\nempirical studies using state-of-the-art prediction models on two benchmark\ndatasets using metrics customized for trajectory prediction. We show that the\nproposed attack is highly effective, as it can significantly hinder the\nperformance of prediction models, unnoticeable by the victims, and efficient as\nit forces the victim to generate malicious behavior even under constrained\nconditions. Via ablative studies, we analyze the impact of different attack\ndesign choices followed by an evaluation of existing defence mechanisms against\nthe proposed attack.\n","authors":["Mozhgan Pourkeshavarz","Mohammad Sabokrou","Amir Rasouli"],"pdf_url":"https://arxiv.org/pdf/2306.15755v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13485v1","updated":"2023-11-22T16:01:44Z","published":"2023-11-22T16:01:44Z","title":"Deep-learning-based acceleration of MRI for radiotherapy planning of\n  pediatric patients with brain tumors","summary":"  Magnetic Resonance Imaging (MRI) is a non-invasive diagnostic and\nradiotherapy (RT) planning tool, offering detailed insights into the anatomy of\nthe human body. The extensive scan time is stressful for patients, who must\nremain motionless in a prolonged imaging procedure that prioritizes reduction\nof imaging artifacts. This is challenging for pediatric patients who may\nrequire measures for managing voluntary motions such as anesthesia. Several\ncomputational approaches reduce scan time (fast MRI), by recording fewer\nmeasurements and digitally recovering full information via post-acquisition\nreconstruction. However, most fast MRI approaches were developed for diagnostic\nimaging, without addressing reconstruction challenges specific to RT planning.\nIn this work, we developed a deep learning-based method (DeepMRIRec) for MRI\nreconstruction from undersampled data acquired with RT-specific receiver coil\narrangements. We evaluated our method against fully sampled data of T1-weighted\nMR images acquired from 73 children with brain tumors/surgical beds using loop\nand posterior coils (12 channels), with and without applying virtual\ncompression of coil elements. DeepMRIRec reduced scanning time by a factor of\nfour producing a structural similarity score surpassing the evaluated\nstate-of-the-art method (0.960 vs 0.896), thereby demonstrating its potential\nfor accelerating MRI scanning for RT planning.\n","authors":["Shahinur Alam","Jinsoo Uh","Alexander Dresner","Chia-ho Hua","Khaled Khairy"],"pdf_url":"https://arxiv.org/pdf/2311.13485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03105v2","updated":"2023-11-22T15:46:00Z","published":"2023-11-06T13:54:52Z","title":"Pelvic floor MRI segmentation based on semi-supervised deep learning","summary":"  The semantic segmentation of pelvic organs via MRI has important clinical\nsignificance. Recently, deep learning-enabled semantic segmentation has\nfacilitated the three-dimensional geometric reconstruction of pelvic floor\norgans, providing clinicians with accurate and intuitive diagnostic results.\nHowever, the task of labeling pelvic floor MRI segmentation, typically\nperformed by clinicians, is labor-intensive and costly, leading to a scarcity\nof labels. Insufficient segmentation labels limit the precise segmentation and\nreconstruction of pelvic floor organs. To address these issues, we propose a\nsemi-supervised framework for pelvic organ segmentation. The implementation of\nthis framework comprises two stages. In the first stage, it performs\nself-supervised pre-training using image restoration tasks. Subsequently,\nfine-tuning of the self-supervised model is performed, using labeled data to\ntrain the segmentation model. In the second stage, the self-supervised\nsegmentation model is used to generate pseudo labels for unlabeled data.\nUltimately, both labeled and unlabeled data are utilized in semi-supervised\ntraining. Upon evaluation, our method significantly enhances the performance in\nthe semantic segmentation and geometric reconstruction of pelvic organs, Dice\ncoefficient can increase by 2.65% averagely. Especially for organs that are\ndifficult to segment, such as the uterus, the accuracy of semantic segmentation\ncan be improved by up to 3.70%.\n","authors":["Jianwei Zuo","Fei Feng","Zhuhui Wang","James A. Ashton-Miller","John O. L. Delancey","Jiajia Luo"],"pdf_url":"https://arxiv.org/pdf/2311.03105v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.02673v2","updated":"2023-11-22T15:27:53Z","published":"2021-07-06T15:27:00Z","title":"Attention-based Adversarial Appearance Learning of Augmented Pedestrians","summary":"  Synthetic data became already an essential component of machine\nlearning-based perception in the field of autonomous driving. Yet it still\ncannot replace real data completely due to the sim2real domain shift. In this\nwork, we propose a method that leverages the advantages of the augmentation\nprocess and adversarial training to synthesize realistic data for the\npedestrian recognition task. Our approach utilizes an attention mechanism\ndriven by an adversarial loss to learn domain discrepancies and improve\nsim2real adaptation. Our experiments confirm that the proposed adaptation\nmethod is robust to such discrepancies and reveals both visual realism and\nsemantic consistency. Furthermore, we evaluate our data generation pipeline on\nthe task of pedestrian recognition and demonstrate that generated data resemble\nproperties of the real domain.\n","authors":["Kevin Strauss","Artem Savkin","Federico Tombari"],"pdf_url":"https://arxiv.org/pdf/2107.02673v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02931v3","updated":"2023-11-22T15:23:44Z","published":"2022-12-06T12:40:45Z","title":"Leveraging Different Learning Styles for Improved Knowledge Distillation\n  in Biomedical Imaging","summary":"  Learning style refers to a type of training mechanism adopted by an\nindividual to gain new knowledge. As suggested by the VARK model, humans have\ndifferent learning preferences, like Visual (V), Auditory (A), Read/Write (R),\nand Kinesthetic (K), for acquiring and effectively processing information. Our\nwork endeavors to leverage this concept of knowledge diversification to improve\nthe performance of model compression techniques like Knowledge Distillation\n(KD) and Mutual Learning (ML). Consequently, we use a single-teacher and\ntwo-student network in a unified framework that not only allows for the\ntransfer of knowledge from teacher to students (KD) but also encourages\ncollaborative learning between students (ML). Unlike the conventional approach,\nwhere the teacher shares the same knowledge in the form of predictions or\nfeature representations with the student network, our proposed approach employs\na more diversified strategy by training one student with predictions and the\nother with feature maps from the teacher. We further extend this knowledge\ndiversification by facilitating the exchange of predictions and feature maps\nbetween the two student networks, enriching their learning experiences. We have\nconducted comprehensive experiments with three benchmark datasets for both\nclassification and segmentation tasks using two different network architecture\ncombinations. These experimental results demonstrate that knowledge\ndiversification in a combined KD and ML framework outperforms conventional KD\nor ML techniques (with similar network configuration) that only use predictions\nwith an average improvement of 2%. Furthermore, consistent improvement in\nperformance across different tasks, with various network architectures, and\nover state-of-the-art techniques establishes the robustness and\ngeneralizability of the proposed model\n","authors":["Usma Niyaz","Abhishek Singh Sambyal","Deepti R. Bathula"],"pdf_url":"https://arxiv.org/pdf/2212.02931v3.pdf","comment":"Accepted in Computers in Biology and Medicine"},{"id":"http://arxiv.org/abs/2311.13444v1","updated":"2023-11-22T15:09:59Z","published":"2023-11-22T15:09:59Z","title":"SkeletonGait: Gait Recognition Using Skeleton Maps","summary":"  The choice of the representations is essential for deep gait recognition\nmethods. The binary silhouettes and skeletal coordinates are two dominant\nrepresentations in recent literature, achieving remarkable advances in many\nscenarios. However, inherent challenges remain, in which silhouettes are not\nalways guaranteed in unconstrained scenes, and structural cues have not been\nfully utilized from skeletons. In this paper, we introduce a novel skeletal\ngait representation named Skeleton Map, together with SkeletonGait, a\nskeleton-based method to exploit structural information from human skeleton\nmaps. Specifically, the skeleton map represents the coordinates of human joints\nas a heatmap with Gaussian approximation, exhibiting a silhouette-like image\ndevoid of exact body structure. Beyond achieving state-of-the-art performances\nover five popular gait datasets, more importantly, SkeletonGait uncovers novel\ninsights about how important structural features are in describing gait and\nwhen do they play a role. Furthermore, we propose a multi-branch architecture,\nnamed SkeletonGait++, to make use of complementary features from both skeletons\nand silhouettes. Experiments indicate that SkeletonGait++ outperforms existing\nstate-of-the-art methods by a significant margin in various scenarios. For\ninstance, it achieves an impressive rank-1 accuracy of over $85\\%$ on the\nchallenging GREW dataset. All the source code will be available at\nhttps://github.com/ShiqiYu/OpenGait.\n","authors":["Chao Fan","Jingzhe Ma","Dongyang Jin","Chuanfu Shen","Shiqi Yu"],"pdf_url":"https://arxiv.org/pdf/2311.13444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13443v1","updated":"2023-11-22T15:07:59Z","published":"2023-11-22T15:07:59Z","title":"Guided Flows for Generative Modeling and Decision Making","summary":"  Classifier-free guidance is a key component for improving the performance of\nconditional generative models for many downstream tasks. It drastically\nimproves the quality of samples produced, but has so far only been used for\ndiffusion models. Flow Matching (FM), an alternative simulation-free approach,\ntrains Continuous Normalizing Flows (CNFs) based on regressing vector fields.\nIt remains an open question whether classifier-free guidance can be performed\nfor Flow Matching models, and to what extent does it improve performance. In\nthis paper, we explore the usage of Guided Flows for a variety of downstream\napplications involving conditional image generation, speech synthesis, and\nreinforcement learning. In particular, we are the first to apply flow models to\nthe offline reinforcement learning setting. We also show that Guided Flows\nsignificantly improves the sample quality in image generation and zero-shot\ntext-to-speech synthesis, and can make use of drastically low amounts of\ncomputation without affecting the agent's overall performance.\n","authors":["Qinqing Zheng","Matt Le","Neta Shaul","Yaron Lipman","Aditya Grover","Ricky T. Q. Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13435v1","updated":"2023-11-22T14:48:30Z","published":"2023-11-22T14:48:30Z","title":"PG-Video-LLaVA: Pixel Grounding Large Video-Language Models","summary":"  Extending image-based Large Multimodal Models (LMM) to videos is challenging\ndue to the inherent complexity of video data. The recent approaches extending\nimage-based LMM to videos either lack the grounding capabilities (e.g.,\nVideoChat, Video-ChatGPT, Video-LLaMA) or do not utilize the audio-signals for\nbetter video understanding (e.g., Video-ChatGPT). Addressing these gaps, we\npropose Video-LLaVA, the first LMM with pixel-level grounding capability,\nintegrating audio cues by transcribing them into text to enrich video-context\nunderstanding. Our framework uses an off-the-shelf tracker and a novel\ngrounding module, enabling it to spatially and temporally localize objects in\nvideos following user instructions. We evaluate Video-LLaVA using video-based\ngenerative and question-answering benchmarks and introduce new benchmarks\nspecifically designed to measure prompt-based object grounding performance in\nvideos. Further, we propose the use of Vicuna over GPT-3.5, as utilized in\nVideo-ChatGPT, for video-based conversation benchmarking, ensuring\nreproducibility of results which is a concern with the proprietary nature of\nGPT-3.5. Our framework builds on SoTA image-based LLaVA model and extends its\nadvantages to the video domain, delivering promising gains on video-based\nconversation and grounding tasks. Project Page:\nhttps://github.com/mbzuai-oryx/Video-LLaVA\n","authors":["Shehan Munasinghe","Rusiru Thushara","Muhammad Maaz","Hanoona Abdul Rasheed","Salman Khan","Mubarak Shah","Fahad Khan"],"pdf_url":"https://arxiv.org/pdf/2311.13435v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2311.08936v2","updated":"2023-11-22T14:25:55Z","published":"2023-11-15T13:19:02Z","title":"Confident Naturalness Explanation (CNE): A Framework to Explain and\n  Assess Patterns Forming Naturalness","summary":"  Protected natural areas are regions that have been minimally affected by\nhuman activities such as urbanization, agriculture, and other human\ninterventions. To better understand and map the naturalness of these areas,\nmachine learning models can be used to analyze satellite imagery. Specifically,\nexplainable machine learning methods show promise in uncovering patterns that\ncontribute to the concept of naturalness within these protected environments.\nAdditionally, addressing the uncertainty inherent in machine learning models is\ncrucial for a comprehensive understanding of this concept. However, existing\napproaches have limitations. They either fail to provide explanations that are\nboth valid and objective or struggle to offer a quantitative metric that\naccurately measures the contribution of specific patterns to naturalness, along\nwith the associated confidence. In this paper, we propose a novel framework\ncalled the Confident Naturalness Explanation (CNE) framework. This framework\ncombines explainable machine learning and uncertainty quantification to assess\nand explain naturalness. We introduce a new quantitative metric that describes\nthe confident contribution of patterns to the concept of naturalness.\nFurthermore, we generate an uncertainty-aware segmentation mask for each input\nsample, highlighting areas where the model lacks knowledge. To demonstrate the\neffectiveness of our framework, we apply it to a study site in Fennoscandia\nusing two open-source satellite datasets.\n","authors":["Ahmed Emam","Mohamed Farag","Ribana Roscher"],"pdf_url":"https://arxiv.org/pdf/2311.08936v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13409v1","updated":"2023-11-22T14:13:27Z","published":"2023-11-22T14:13:27Z","title":"CompenHR: Efficient Full Compensation for High-resolution Projector","summary":"  Full projector compensation is a practical task of projector-camera systems.\nIt aims to find a projector input image, named compensation image, such that\nwhen projected it cancels the geometric and photometric distortions due to the\nphysical environment and hardware. State-of-the-art methods use deep learning\nto address this problem and show promising performance for low-resolution\nsetups. However, directly applying deep learning to high-resolution setups is\nimpractical due to the long training time and high memory cost. To address this\nissue, this paper proposes a practical full compensation solution. Firstly, we\ndesign an attention-based grid refinement network to improve geometric\ncorrection quality. Secondly, we integrate a novel sampling scheme into an\nend-to-end compensation network to alleviate computation and introduce\nattention blocks to preserve key features. Finally, we construct a benchmark\ndataset for high-resolution projector full compensation. In experiments, our\nmethod demonstrates clear advantages in both efficiency and quality.\n","authors":["Yuxi Wang","Haibin Ling","Bingyao Huang"],"pdf_url":"https://arxiv.org/pdf/2311.13409v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13404v1","updated":"2023-11-22T14:00:23Z","published":"2023-11-22T14:00:23Z","title":"Animatable 3D Gaussians for High-fidelity Synthesis of Human Motions","summary":"  We present a novel animatable 3D Gaussian model for rendering high-fidelity\nfree-view human motions in real time. Compared to existing NeRF-based methods,\nthe model owns better capability in synthesizing high-frequency details without\nthe jittering problem across video frames. The core of our model is a novel\naugmented 3D Gaussian representation, which attaches each Gaussian with a\nlearnable code. The learnable code serves as a pose-dependent appearance\nembedding for refining the erroneous appearance caused by geometric\ntransformation of Gaussians, based on which an appearance refinement model is\nlearned to produce residual Gaussian properties to match the appearance in\ntarget pose. To force the Gaussians to learn the foreground human only without\nbackground interference, we further design a novel alpha loss to explicitly\nconstrain the Gaussians within the human body. We also propose to jointly\noptimize the human joint parameters to improve the appearance accuracy. The\nanimatable 3D Gaussian model can be learned with shallow MLPs, so new human\nmotions can be synthesized in real time (66 fps on avarage). Experiments show\nthat our model has superior performance over NeRF-based methods.\n","authors":["Keyang Ye","Tianjia Shao","Kun Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.13404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.02185v4","updated":"2023-11-22T13:56:48Z","published":"2023-09-05T12:42:26Z","title":"BEVTrack: A Simple and Strong Baseline for 3D Single Object Tracking in\n  Bird's-Eye View","summary":"  3D Single Object Tracking (SOT) is a fundamental task of computer vision,\nproving essential for applications like autonomous driving. It remains\nchallenging to localize the target from surroundings due to appearance\nvariations, distractors, and the high sparsity of point clouds. The spatial\ninformation indicating objects' spatial adjacency across consecutive frames is\ncrucial for effective object tracking. However, existing trackers typically\nemploy point-wise representation with irregular formats, leading to\ninsufficient use of this important spatial knowledge. As a result, these\ntrackers usually require elaborate designs and solving multiple subtasks. In\nthis paper, we propose BEVTrack, a simple yet effective baseline that performs\ntracking in Bird's-Eye View (BEV). This representation greatly retains spatial\ninformation owing to its ordered structure and inherently encodes the implicit\nmotion relations of the target as well as distractors. To achieve accurate\nregression for targets with diverse attributes (\\textit{e.g.}, sizes and motion\npatterns), BEVTrack constructs the likelihood function with the learned\nunderlying distributions adapted to different targets, rather than making a\nfixed Laplace or Gaussian assumption as in previous works. This provides\nvaluable priors for tracking and thus further boosts performance. While only\nusing a single regression loss with a plain convolutional architecture,\nBEVTrack achieves state-of-the-art performance on three large-scale datasets,\nKITTI, NuScenes, and Waymo Open Dataset while maintaining a high inference\nspeed of about 200 FPS. The code will be released at\nhttps://github.com/xmm-prio/BEVTrack.\n","authors":["Yuxiang Yang","Yingqi Deng","Jing Zhang","Jiahao Nie","Zheng-Jun Zha"],"pdf_url":"https://arxiv.org/pdf/2309.02185v4.pdf","comment":"The code will be released at https://github.com/xmm-prio/BEVTrack"},{"id":"http://arxiv.org/abs/2311.13398v1","updated":"2023-11-22T13:53:04Z","published":"2023-11-22T13:53:04Z","title":"Depth-Regularized Optimization for 3D Gaussian Splatting in Few-Shot\n  Images","summary":"  In this paper, we present a method to optimize Gaussian splatting with a\nlimited number of images while avoiding overfitting. Representing a 3D scene by\ncombining numerous Gaussian splats has yielded outstanding visual quality.\nHowever, it tends to overfit the training views when only a small number of\nimages are available. To address this issue, we introduce a dense depth map as\na geometry guide to mitigate overfitting. We obtained the depth map using a\npre-trained monocular depth estimation model and aligning the scale and offset\nusing sparse COLMAP feature points. The adjusted depth aids in the color-based\noptimization of 3D Gaussian splatting, mitigating floating artifacts, and\nensuring adherence to geometric constraints. We verify the proposed method on\nthe NeRF-LLFF dataset with varying numbers of few images. Our approach\ndemonstrates robust geometry compared to the original method that relies solely\non images.\n","authors":["Jaeyoung Chung","Jeongtaek Oh","Kyoung Mu Lee"],"pdf_url":"https://arxiv.org/pdf/2311.13398v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.13385v1","updated":"2023-11-22T13:27:36Z","published":"2023-11-22T13:27:36Z","title":"SegVol: Universal and Interactive Volumetric Medical Image Segmentation","summary":"  Precise image segmentation provides clinical study with meaningful and\nwell-structured information. Despite the remarkable progress achieved in\nmedical image segmentation, there is still an absence of foundation\nsegmentation model that can segment a wide range of anatomical categories with\neasy user interaction. In this paper, we propose a universal and interactive\nvolumetric medical image segmentation model, named SegVol. By training on 90k\nunlabeled Computed Tomography (CT) volumes and 6k labeled CTs, this foundation\nmodel supports the segmentation of over 200 anatomical categories using\nsemantic and spatial prompts. Extensive experiments verify that SegVol\noutperforms the state of the art by a large margin on multiple segmentation\nbenchmarks. Notably, on three challenging lesion datasets, our method achieves\naround 20% higher Dice score than nnU-Net. The model and data are publicly\navailable at: https://github.com/BAAI-DCAI/SegVol.\n","authors":["Yuxin Du","Fan Bai","Tiejun Huang","Bo Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.13385v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13384v1","updated":"2023-11-22T13:27:34Z","published":"2023-11-22T13:27:34Z","title":"LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes","summary":"  With the widespread usage of VR devices and contents, demands for 3D scene\ngeneration techniques become more popular. Existing 3D scene generation models,\nhowever, limit the target scene to specific domain, primarily due to their\ntraining strategies using 3D scan dataset that is far from the real-world. To\naddress such limitation, we propose LucidDreamer, a domain-free scene\ngeneration pipeline by fully leveraging the power of existing large-scale\ndiffusion-based generative model. Our LucidDreamer has two alternate steps:\nDreaming and Alignment. First, to generate multi-view consistent images from\ninputs, we set the point cloud as a geometrical guideline for each image\ngeneration. Specifically, we project a portion of point cloud to the desired\nview and provide the projection as a guidance for inpainting using the\ngenerative model. The inpainted images are lifted to 3D space with estimated\ndepth maps, composing a new points. Second, to aggregate the new points into\nthe 3D scene, we propose an aligning algorithm which harmoniously integrates\nthe portions of newly generated 3D scenes. The finally obtained 3D scene serves\nas initial points for optimizing Gaussian splats. LucidDreamer produces\nGaussian splats that are highly-detailed compared to the previous 3D scene\ngeneration methods, with no constraint on domain of the target scene.\n","authors":["Jaeyoung Chung","Suyoung Lee","Hyeongjin Nam","Jaerin Lee","Kyoung Mu Lee"],"pdf_url":"https://arxiv.org/pdf/2311.13384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13378v1","updated":"2023-11-22T13:19:41Z","published":"2023-11-22T13:19:41Z","title":"Point Projection Mapping System for Tracking, Registering, Labeling and\n  Validating Optical Tissue Measurements","summary":"  Validation of newly developed optical tissue sensing techniques for tumor\ndetection during cancer surgery requires an accurate correlation with\nhistological results. Additionally, such accurate correlation facilitates\nprecise data labeling for developing high-performance machine-learning tissue\nclassification models. In this paper, a newly developed Point Projection\nMapping system will be introduced, which allows non-destructive tracking of the\nmeasurement locations on tissue specimens. Additionally, a framework for\naccurate registration, validation, and labeling with histopathology results is\nproposed and validated on a case study. The proposed framework provides a more\nrobust and accurate method for tracking and validation of optical tissue\nsensing techniques, which saves time and resources compared to conventional\ntechniques available.\n","authors":["Lianne Feenstra","Stefan D. van der Stel","Marcos Da Silva Guimaraes","Theo J. M Ruers","Behdad Dashtbozorg"],"pdf_url":"https://arxiv.org/pdf/2311.13378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13372v1","updated":"2023-11-22T13:13:19Z","published":"2023-11-22T13:13:19Z","title":"MRGazer: Decoding Eye Gaze Points from Functional Magnetic Resonance\n  Imaging in Individual Space","summary":"  Eye-tracking research has proven valuable in understanding numerous cognitive\nfunctions. Recently, Frey et al. provided an exciting deep learning method for\nlearning eye movements from fMRI data. However, it needed to co-register fMRI\ninto standard space to obtain eyeballs masks, and thus required additional\ntemplates and was time consuming. To resolve this issue, in this paper, we\npropose a framework named MRGazer for predicting eye gaze points from fMRI in\nindividual space. The MRGazer consisted of eyeballs extraction module and a\nresidual network-based eye gaze prediction. Compared to the previous method,\nthe proposed framework skips the fMRI co-registration step, simplifies the\nprocessing protocol and achieves end-to-end eye gaze regression. The proposed\nmethod achieved superior performance in a variety of eye movement tasks than\nthe co-registration-based method, and delivered objective results within a\nshorter time (~ 0.02 Seconds for each volume) than prior method (~0.3 Seconds\nfor each volume).\n","authors":["Xiuwen Wu","Rongjie Hu","Jie Liang","Yanming Wang","Bensheng Qiu","Xiaoxiao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11317v2","updated":"2023-11-22T12:52:41Z","published":"2023-11-19T13:07:06Z","title":"Discrete approximations of Gaussian smoothing and Gaussian derivatives","summary":"  This paper develops an in-depth treatment concerning the problem of\napproximating the Gaussian smoothing and Gaussian derivative computations in\nscale-space theory for application on discrete data. With close connections to\nprevious axiomatic treatments of continuous and discrete scale-space theory, we\nconsider three main ways discretizing these scale-space operations in terms of\nexplicit discrete convolutions, based on either (i) sampling the Gaussian\nkernels and the Gaussian derivative kernels, (ii) locally integrating the\nGaussian kernels and the Gaussian derivative kernels over each pixel support\nregion and (iii) basing the scale-space analysis on the discrete analogue of\nthe Gaussian kernel, and then computing derivative approximations by applying\nsmall-support central difference operators to the spatially smoothed image\ndata.\n  We study the properties of these three main discretization methods both\ntheoretically and experimentally, and characterize their performance by\nquantitative measures, including the results they give rise to with respect to\nthe task of scale selection, investigated for four different use cases, and\nwith emphasis on the behaviour at fine scales. The results show that the\nsampled Gaussian kernels and derivatives as well as the integrated Gaussian\nkernels and derivatives perform very poorly at very fine scales. At very fine\nscales, the discrete analogue of the Gaussian kernel with its corresponding\ndiscrete derivative approximations performs substantially better. The sampled\nGaussian kernel and the sampled Gaussian derivatives do, on the other hand,\nlead to numerically very good approximations of the corresponding continuous\nresults, when the scale parameter is sufficiently large, in the experiments\npresented in the paper, when the scale parameter is greater than a value of\nabout 1, in units of the grid spacing.\n","authors":["Tony Lindeberg"],"pdf_url":"https://arxiv.org/pdf/2311.11317v2.pdf","comment":"38 pages, 34 figures"},{"id":"http://arxiv.org/abs/2311.13355v1","updated":"2023-11-22T12:47:12Z","published":"2023-11-22T12:47:12Z","title":"Unified Classification and Rejection: A One-versus-All Framework","summary":"  Classifying patterns of known classes and rejecting ambiguous and novel (also\ncalled as out-of-distribution (OOD)) inputs are involved in open world pattern\nrecognition. Deep neural network models usually excel in closed-set\nclassification while performing poorly in rejecting OOD. To tackle this\nproblem, numerous methods have been designed to perform open set recognition\n(OSR) or OOD rejection/detection tasks. Previous methods mostly take\npost-training score transformation or hybrid models to ensure low scores on OOD\ninputs while separating known classes. In this paper, we attempt to build a\nunified framework for building open set classifiers for both classification and\nOOD rejection. We formulate the open set recognition of $ K $-known-class as a\n$ (K + 1) $-class classification problem with model trained on known-class\nsamples only. By decomposing the $ K $-class problem into $ K $ one-versus-all\n(OVA) binary classification tasks and binding some parameters, we show that\ncombining the scores of OVA classifiers can give $ (K + 1) $-class posterior\nprobabilities, which enables classification and OOD rejection in a unified\nframework. To maintain the closed-set classification accuracy of the OVA\ntrained classifier, we propose a hybrid training strategy combining OVA loss\nand multi-class cross-entropy loss. We implement the OVA framework and hybrid\ntraining strategy on the recently proposed convolutional prototype network.\nExperiments on popular OSR and OOD detection datasets demonstrate that the\nproposed framework, using a single multi-class classifier, yields competitive\nperformance in closed-set classification, OOD detection, and misclassification\ndetection.\n","authors":["Zhen Cheng","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04225v2","updated":"2023-11-22T12:35:08Z","published":"2023-06-07T08:02:17Z","title":"Efficient Vision Transformer for Human Pose Estimation via Patch\n  Selection","summary":"  While Convolutional Neural Networks (CNNs) have been widely successful in 2D\nhuman pose estimation, Vision Transformers (ViTs) have emerged as a promising\nalternative to CNNs, boosting state-of-the-art performance. However, the\nquadratic computational complexity of ViTs has limited their applicability for\nprocessing high-resolution images. In this paper, we propose three methods for\nreducing ViT's computational complexity, which are based on selecting and\nprocessing a small number of most informative patches while disregarding\nothers. The first two methods leverage a lightweight pose estimation network to\nguide the patch selection process, while the third method utilizes a set of\nlearnable joint tokens to ensure that the selected patches contain the most\nimportant information about body joints. Experiments across six benchmarks show\nthat our proposed methods achieve a significant reduction in computational\ncomplexity, ranging from 30% to 44%, with only a minimal drop in accuracy\nbetween 0% and 3.5%.\n","authors":["Kaleab A. Kinfu","Rene Vidal"],"pdf_url":"https://arxiv.org/pdf/2306.04225v2.pdf","comment":"BMVC 2023 Oral Paper: https://proceedings.bmvc2023.org/167/"},{"id":"http://arxiv.org/abs/2211.14605v2","updated":"2023-11-22T12:16:28Z","published":"2022-11-26T16:13:32Z","title":"Looking at the posterior: accuracy and uncertainty of neural-network\n  predictions","summary":"  Bayesian inference can quantify uncertainty in the predictions of neural\nnetworks using posterior distributions for model parameters and network output.\nBy looking at these posterior distributions, one can separate the origin of\nuncertainty into aleatoric and epistemic contributions. One goal of uncertainty\nquantification is to inform on prediction accuracy. Here we show that\nprediction accuracy depends on both epistemic and aleatoric uncertainty in an\nintricate fashion that cannot be understood in terms of marginalized\nuncertainty distributions alone. How the accuracy relates to epistemic and\naleatoric uncertainties depends not only on the model architecture, but also on\nthe properties of the dataset. We discuss the significance of these results for\nactive learning and introduce a novel acquisition function that outperforms\ncommon uncertainty-based methods. To arrive at our results, we approximated the\nposteriors using deep ensembles, for fully-connected, convolutional and\nattention-based neural networks.\n","authors":["H. Linander","O. Balabanov","H. Yang","B. Mehlig"],"pdf_url":"https://arxiv.org/pdf/2211.14605v2.pdf","comment":"26 pages, 10 figures, 5 tables"},{"id":"http://arxiv.org/abs/2311.13338v1","updated":"2023-11-22T12:03:33Z","published":"2023-11-22T12:03:33Z","title":"High-Quality Face Caricature via Style Translation","summary":"  Caricature is an exaggerated form of artistic portraiture that accentuates\nunique yet subtle characteristics of human faces. Recently, advancements in\ndeep end-to-end techniques have yielded encouraging outcomes in capturing both\nstyle and elevated exaggerations in creating face caricatures. Most of these\napproaches tend to produce cartoon-like results that could be more practical\nfor real-world applications. In this study, we proposed a high-quality,\nunpaired face caricature method that is appropriate for use in the real world\nand uses computer vision techniques and GAN models. We attain the exaggeration\nof facial features and the stylization of appearance through a two-step\nprocess: Face caricature generation and face caricature projection. The face\ncaricature generation step creates new caricature face datasets from real\nimages and trains a generative model using the real and newly created\ncaricature datasets. The Face caricature projection employs an encoder trained\nwith real and caricature faces with the pretrained generator to project real\nand caricature faces. We perform an incremental facial exaggeration from the\nreal image to the caricature faces using the encoder and generator's latent\nspace. Our projection preserves the facial identity, attributes, and\nexpressions from the input image. Also, it accounts for facial occlusions, such\nas reading glasses or sunglasses, to enhance the robustness of our model.\nFurthermore, we conducted a comprehensive comparison of our approach with\nvarious state-of-the-art face caricature methods, highlighting our process's\ndistinctiveness and exceptional realism.\n","authors":["Lamyanba Laishram","Muhammad Shaheryar","Jong Taek Lee","Soon Ki Jung"],"pdf_url":"https://arxiv.org/pdf/2311.13338v1.pdf","comment":"14 pages, 21 figures"},{"id":"http://arxiv.org/abs/2311.13335v1","updated":"2023-11-22T11:55:41Z","published":"2023-11-22T11:55:41Z","title":"Quantum learning and essential cognition under the traction of\n  meta-characteristics in an open world","summary":"  Artificial intelligence has made significant progress in the Close World\nproblem, being able to accurately recognize old knowledge through training and\nclassification. However, AI faces significant challenges in the Open World\nproblem, as it involves a new and unknown exploration journey. AI is not\ninherently proactive in exploration, and its challenge lies in not knowing how\nto approach and adapt to the unknown world. How do humans acquire knowledge of\nthe unknown world. Humans identify new knowledge through intrinsic cognition.\nIn the process of recognizing new colors, the cognitive cues are different from\nknown color features and involve hue, saturation, brightness, and other\ncharacteristics. When AI encounters objects with different features in the new\nworld, it faces another challenge: where are the distinguishing features\nbetween influential features of new and old objects? AI often mistakes a new\nworld's brown bear for a known dog because it has not learned the differences\nin feature distributions between knowledge systems. This is because things in\nthe new and old worlds have different units and dimensions for their features.\nThis paper proposes an open-world model and elemental feature system that\nfocuses on fundamentally recognizing the distribution differences in objective\nfeatures between the new and old worlds. The quantum tunneling effect of\nlearning ability in the new and old worlds is realized through the tractive\nforce of meta-characteristic. The outstanding performance of the model system\nin learning new knowledge (using pedestrian re-identification datasets as an\nexample) demonstrates that AI has acquired the ability to recognize the new\nworld with an accuracy of $96.71\\%$ at most and has gained the capability to\nexplore new knowledge, similar to humans.\n","authors":["Jin Wang","Changlin Song"],"pdf_url":"https://arxiv.org/pdf/2311.13335v1.pdf","comment":"8 pages,5 pages"},{"id":"http://arxiv.org/abs/2201.04819v2","updated":"2023-11-22T11:32:46Z","published":"2022-01-13T07:25:06Z","title":"Deep Rank-Consistent Pyramid Model for Enhanced Crowd Counting","summary":"  Most conventional crowd counting methods utilize a fully-supervised learning\nframework to establish a mapping between scene images and crowd density maps.\nThey usually rely on a large quantity of costly and time-intensive pixel-level\nannotations for training supervision. One way to mitigate the intensive\nlabeling effort and improve counting accuracy is to leverage large amounts of\nunlabeled images. This is attributed to the inherent self-structural\ninformation and rank consistency within a single image, offering additional\nqualitative relation supervision during training. Contrary to earlier methods\nthat utilized the rank relations at the original image level, we explore such\nrank-consistency relation within the latent feature spaces. This approach\nenables the incorporation of numerous pyramid partial orders, strengthening the\nmodel representation capability. A notable advantage is that it can also\nincrease the utilization ratio of unlabeled samples. Specifically, we propose a\nDeep Rank-consistEnt pyrAmid Model (DREAM), which makes full use of rank\nconsistency across coarse-to-fine pyramid features in latent spaces for\nenhanced crowd counting with massive unlabeled images. In addition, we have\ncollected a new unlabeled crowd counting dataset, FUDAN-UCC, comprising 4,000\nimages for training purposes. Extensive experiments on four benchmark datasets,\nnamely UCF-QNRF, ShanghaiTech PartA and PartB, and UCF-CC-50, show the\neffectiveness of our method compared with previous semi-supervised methods. The\ncodes are available at https://github.com/bridgeqiqi/DREAM.\n","authors":["Jiaqi Gao","Zhizhong Huang","Yiming Lei","Hongming Shan","James Z. Wang","Fei-Yue Wang","Junping Zhang"],"pdf_url":"https://arxiv.org/pdf/2201.04819v2.pdf","comment":"Accepted by IEEE Transactions on Neural Networks and Learning Systems"},{"id":"http://arxiv.org/abs/2311.13321v1","updated":"2023-11-22T11:24:04Z","published":"2023-11-22T11:24:04Z","title":"Revisiting Supervision for Continual Representation Learning","summary":"  In the field of continual learning, models are designed to learn tasks one\nafter the other. While most research has centered on supervised continual\nlearning, recent studies have highlighted the strengths of self-supervised\ncontinual representation learning. The improved transferability of\nrepresentations built with self-supervised methods is often associated with the\nrole played by the multi-layer perceptron projector. In this work, we depart\nfrom this observation and reexamine the role of supervision in continual\nrepresentation learning. We reckon that additional information, such as human\nannotations, should not deteriorate the quality of representations. Our\nfindings show that supervised models when enhanced with a multi-layer\nperceptron head, can outperform self-supervised models in continual\nrepresentation learning.\n","authors":["Daniel Marczak","Sebastian Cygert","Tomasz Trzciński","Bartłomiej Twardowski"],"pdf_url":"https://arxiv.org/pdf/2311.13321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13319v1","updated":"2023-11-22T11:15:38Z","published":"2023-11-22T11:15:38Z","title":"Deep Learning for Vascular Segmentation and Applications in Phase\n  Contrast Tomography Imaging","summary":"  Automated blood vessel segmentation is vital for biomedical imaging, as\nvessel changes indicate many pathologies. Still, precise segmentation is\ndifficult due to the complexity of vascular structures, anatomical variations\nacross patients, the scarcity of annotated public datasets, and the quality of\nimages. We present a thorough literature review, highlighting the state of\nmachine learning techniques across diverse organs. Our goal is to provide a\nfoundation on the topic and identify a robust baseline model for application to\nvascular segmentation in a new imaging modality, Hierarchical Phase Contrast\nTomography (HiP CT). Introduced in 2020 at the European Synchrotron Radiation\nFacility, HiP CT enables 3D imaging of complete organs at an unprecedented\nresolution of ca. 20mm per voxel, with the capability for localized zooms in\nselected regions down to 1mm per voxel without sectioning. We have created a\ntraining dataset with double annotator validated vascular data from three\nkidneys imaged with HiP CT in the context of the Human Organ Atlas Project.\nFinally, utilising the nnU Net model, we conduct experiments to assess the\nmodels performance on both familiar and unseen samples, employing vessel\nspecific metrics. Our results show that while segmentations yielded reasonably\nhigh scores such as clDice values ranging from 0.82 to 0.88, certain errors\npersisted. Large vessels that collapsed due to the lack of hydrostatic pressure\n(HiP CT is an ex vivo technique) were segmented poorly. Moreover, decreased\nconnectivity in finer vessels and higher segmentation errors at vessel\nboundaries were observed. Such errors obstruct the understanding of the\nstructures by interrupting vascular tree connectivity. Through our review and\noutputs, we aim to set a benchmark for subsequent model evaluations using\nvarious modalities, especially with the HiP CT imaging database.\n","authors":["Ekin Yagis","Shahab Aslani","Yashvardhan Jain","Yang Zhou","Shahrokh Rahmani","Joseph Brunet","Alexandre Bellier","Christopher Werlein","Maximilian Ackermann","Danny Jonigk","Paul Tafforeau","Peter D Lee","Claire Walsh"],"pdf_url":"https://arxiv.org/pdf/2311.13319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13317v1","updated":"2023-11-22T11:10:45Z","published":"2023-11-22T11:10:45Z","title":"Recognition-Guided Diffusion Model for Scene Text Image Super-Resolution","summary":"  Scene Text Image Super-Resolution (STISR) aims to enhance the resolution and\nlegibility of text within low-resolution (LR) images, consequently elevating\nrecognition accuracy in Scene Text Recognition (STR). Previous methods\npredominantly employ discriminative Convolutional Neural Networks (CNNs)\naugmented with diverse forms of text guidance to address this issue.\nNevertheless, they remain deficient when confronted with severely blurred\nimages, due to their insufficient generation capability when little structural\nor semantic information can be extracted from original images. Therefore, we\nintroduce RGDiffSR, a Recognition-Guided Diffusion model for scene text image\nSuper-Resolution, which exhibits great generative diversity and fidelity even\nin challenging scenarios. Moreover, we propose a Recognition-Guided Denoising\nNetwork, to guide the diffusion model generating LR-consistent results through\nsuccinct semantic guidance. Experiments on the TextZoom dataset demonstrate the\nsuperiority of RGDiffSR over prior state-of-the-art methods in both text\nrecognition accuracy and image fidelity.\n","authors":["Yuxuan Zhou","Liangcai Gao","Zhi Tang","Baole Wei"],"pdf_url":"https://arxiv.org/pdf/2311.13317v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.00846v2","updated":"2023-11-22T11:02:35Z","published":"2023-09-02T07:13:47Z","title":"pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time\n  Adaptation","summary":"  Test Time Adaptation (TTA) is a pivotal concept in machine learning, enabling\nmodels to perform well in real-world scenarios, where test data distribution\ndiffers from training. In this work, we propose a novel approach called pseudo\nSource guided Target Clustering (pSTarC) addressing the relatively unexplored\narea of TTA under real-world domain shifts. This method draws inspiration from\ntarget clustering techniques and exploits the source classifier for generating\npseudo-source samples. The test samples are strategically aligned with these\npseudo-source samples, facilitating their clustering and thereby enhancing TTA\nperformance. pSTarC operates solely within the fully test-time adaptation\nprotocol, removing the need for actual source data. Experimental validation on\na variety of domain shift datasets, namely VisDA, Office-Home, DomainNet-126,\nCIFAR-100C verifies pSTarC's effectiveness. This method exhibits significant\nimprovements in prediction accuracy along with efficient computational\nrequirements. Furthermore, we also demonstrate the universality of the pSTarC\nframework by showing its effectiveness for the continuous TTA framework. The\nsource code for our method is available at https://manogna-s.github.io/pstarc\n","authors":["Manogna Sreenivas","Goirik Chakrabarty","Soma Biswas"],"pdf_url":"https://arxiv.org/pdf/2309.00846v2.pdf","comment":"Accepted in WACV 2024"},{"id":"http://arxiv.org/abs/2311.13307v1","updated":"2023-11-22T10:55:36Z","published":"2023-11-22T10:55:36Z","title":"Rethinking Radiology Report Generation via Causal Reasoning and\n  Counterfactual Augmentation","summary":"  Radiology Report Generation (RRG) draws attention as an interaction between\nvision and language fields. Previous works inherited the ideology of\nvision-to-language generation tasks,aiming to generate paragraphs with high\nconsistency as reports. However, one unique characteristic of RRG, the\nindependence between diseases, was neglected, leading to the injection of the\nspurious confounder, i.e., the disease co-occurrence. Unfortunately, this\nconfounder confuses the process of report generation worse because of the\nbiased RRG data distribution. In this paper, to rethink this issue thoroughly,\nwe reason about its causes and effects from a novel perspective of statistics\nand causality, where the Joint Vision Coupling and the Conditional Sentence\nCoherence Coupling are two aspects prone to implicitly decrease the accuracy of\nreports. Then, a counterfactual augmentation strategy that contains the\nCounterfactual Sample Synthesis and the Counterfactual Report Reconstruction\nsub-methods is proposed to break these two aspects of spurious effects.\nExperimental results and further analyses on two widely used datasets justify\nour reasoning and proposed methods.\n","authors":["Xiao Song","Jiafan Liu","Yun Li","Wenbin Lei","Ruxin Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13307v1.pdf","comment":"10 pages,5 figures"},{"id":"http://arxiv.org/abs/2311.13297v1","updated":"2023-11-22T10:27:19Z","published":"2023-11-22T10:27:19Z","title":"Retargeting Visual Data with Deformation Fields","summary":"  Seam carving is an image editing method that enable content-aware resizing,\nincluding operations like removing objects. However, the seam-finding strategy\nbased on dynamic programming or graph-cut limits its applications to broader\nvisual data formats and degrees of freedom for editing. Our observation is that\ndescribing the editing and retargeting of images more generally by a\ndisplacement field yields a generalisation of content-aware deformations. We\npropose to learn a deformation with a neural network that keeps the output\nplausible while trying to deform it only in places with low information\ncontent. This technique applies to different kinds of visual data, including\nimages, 3D scenes given as neural radiance fields, or even polygon meshes.\nExperiments conducted on different visual data show that our method achieves\nbetter content-aware retargeting compared to previous methods.\n","authors":["Tim Elsner","Julia Berger","Tong Wu","Victor Czech","Lin Gao","Leif Kobbelt"],"pdf_url":"https://arxiv.org/pdf/2311.13297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.13289v2","updated":"2023-11-22T10:14:04Z","published":"2023-09-23T07:08:57Z","title":"USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion\n  Segmentation","summary":"  Unsupervised skin lesion segmentation offers several benefits, including\nconserving expert human resources, reducing discrepancies due to subjective\nhuman labeling, and adapting to novel environments. However, segmenting\ndermoscopic images without manual labeling guidance presents significant\nchallenges due to dermoscopic image artifacts such as hair noise, blister\nnoise, and subtle edge differences. To address these challenges, we introduce\nan innovative Uncertainty Self-Learning Network (USL-Net) designed for skin\nlesion segmentation. The USL-Net can effectively segment a range of lesions,\neliminating the need for manual labeling guidance. Initially, features are\nextracted using contrastive learning, followed by the generation of Class\nActivation Maps (CAMs) as saliency maps using these features. The different CAM\nlocations correspond to the importance of the lesion region based on their\nsaliency. High-saliency regions in the map serve as pseudo-labels for lesion\nregions while low-saliency regions represent the background. However,\nintermediate regions can be hard to classify, often due to their proximity to\nlesion edges or interference from hair or blisters. Rather than risk potential\npseudo-labeling errors or learning confusion by forcefully classifying these\nregions, we consider them as uncertainty regions, exempting them from\npseudo-labeling and allowing the network to self-learn. Further, we employ\nconnectivity detection and centrality detection to refine foreground\npseudo-labels and reduce noise-induced errors. The application of cycle\nrefining enhances performance further. Our method underwent thorough\nexperimental validation on the ISIC-2017, ISIC-2018, and PH2 datasets,\ndemonstrating that its performance is on par with weakly supervised and\nsupervised methods, and exceeds that of other existing unsupervised methods.\n","authors":["Xiaofan Li","Bo Peng","Jie Hu","Changyou Ma","Daipeng Yang","Zhuyang Xie"],"pdf_url":"https://arxiv.org/pdf/2309.13289v2.pdf","comment":"14 pages, 9 figures, 71 references"},{"id":"http://arxiv.org/abs/2308.10631v3","updated":"2023-11-22T09:53:36Z","published":"2023-08-21T11:06:43Z","title":"PsyMo: A Dataset for Estimating Self-Reported Psychological Traits from\n  Gait","summary":"  Psychological trait estimation from external factors such as movement and\nappearance is a challenging and long-standing problem in psychology, and is\nprincipally based on the psychological theory of embodiment. To date, attempts\nto tackle this problem have utilized private small-scale datasets with\nintrusive body-attached sensors. Potential applications of an automated system\nfor psychological trait estimation include estimation of occupational fatigue\nand psychology, and marketing and advertisement. In this work, we propose PsyMo\n(Psychological traits from Motion), a novel, multi-purpose and multi-modal\ndataset for exploring psychological cues manifested in walking patterns. We\ngathered walking sequences from 312 subjects in 7 different walking variations\nand 6 camera angles. In conjunction with walking sequences, participants filled\nin 6 psychological questionnaires, totalling 17 psychometric attributes related\nto personality, self-esteem, fatigue, aggressiveness and mental health. We\npropose two evaluation protocols for psychological trait estimation. Alongside\nthe estimation of self-reported psychological traits from gait, the dataset can\nbe used as a drop-in replacement to benchmark methods for gait recognition. We\nanonymize all cues related to the identity of the subjects and publicly release\nonly silhouettes, 2D / 3D human skeletons and 3D SMPL human meshes.\n","authors":["Adrian Cosma","Emilian Radoi"],"pdf_url":"https://arxiv.org/pdf/2308.10631v3.pdf","comment":"Accepted at 2024 IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV)"},{"id":"http://arxiv.org/abs/2311.13267v1","updated":"2023-11-22T09:37:33Z","published":"2023-11-22T09:37:33Z","title":"FedFN: Feature Normalization for Alleviating Data Heterogeneity Problem\n  in Federated Learning","summary":"  Federated Learning (FL) is a collaborative method for training models while\npreserving data privacy in decentralized settings. However, FL encounters\nchallenges related to data heterogeneity, which can result in performance\ndegradation. In our study, we observe that as data heterogeneity increases,\nfeature representation in the FedAVG model deteriorates more significantly\ncompared to classifier weight. Additionally, we observe that as data\nheterogeneity increases, the gap between higher feature norms for observed\nclasses, obtained from local models, and feature norms of unobserved classes\nwidens, in contrast to the behavior of classifier weight norms. This widening\ngap extends to encompass the feature norm disparities between local and the\nglobal models. To address these issues, we introduce Federated Averaging with\nFeature Normalization Update (FedFN), a straightforward learning method. We\ndemonstrate the superior performance of FedFN through extensive experiments,\neven when applied to pretrained ResNet18. Subsequently, we confirm the\napplicability of FedFN to foundation models.\n","authors":["Seongyoon Kim","Gihun Lee","Jaehoon Oh","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2311.13267v1.pdf","comment":"NeurIPS Workshop: \"Federated Learning in the Age of Foundation\n  Models\" 2023"},{"id":"http://arxiv.org/abs/2311.13263v1","updated":"2023-11-22T09:27:46Z","published":"2023-11-22T09:27:46Z","title":"CMFDFormer: Transformer-based Copy-Move Forgery Detection with Continual\n  Learning","summary":"  Copy-move forgery detection aims at detecting duplicated regions in a\nsuspected forged image, and deep learning based copy-move forgery detection\nmethods are in the ascendant. These deep learning based methods heavily rely on\nsynthetic training data, and the performance will degrade when facing new\ntasks. In this paper, we propose a Transformer-style copy-move forgery\ndetection network named as CMFDFormer, and provide a novel PCSD (Pooled Cube\nand Strip Distillation) continual learning framework to help CMFDFormer handle\nnew tasks. CMFDFormer consists of a MiT (Mix Transformer) backbone network and\na PHD (Pluggable Hybrid Decoder) mask prediction network. The MiT backbone\nnetwork is a Transformer-style network which is adopted on the basis of\ncomprehensive analyses with CNN-style and MLP-style backbones. The PHD network\nis constructed based on self-correlation computation, hierarchical feature\nintegration, a multi-scale cycle fully-connected block and a mask\nreconstruction block. The PHD network is applicable to feature extractors of\ndifferent styles for hierarchical multi-scale information extraction, achieving\ncomparable performance. Last but not least, we propose a PCSD continual\nlearning framework to improve the forgery detectability and avoid catastrophic\nforgetting when handling new tasks. Our continual learning framework restricts\nintermediate features from the PHD network, and takes advantage of both cube\npooling and strip pooling. Extensive experiments on publicly available datasets\ndemonstrate the good performance of CMFDFormer and the effectiveness of the\nPCSD continual learning framework.\n","authors":["Yaqi Liu","Chao Xia","Song Xiao","Qingxiao Guan","Wenqian Dong","Yifan Zhang","Nenghai Yu"],"pdf_url":"https://arxiv.org/pdf/2311.13263v1.pdf","comment":"12pages,6 figures"},{"id":"http://arxiv.org/abs/2311.13261v1","updated":"2023-11-22T09:25:08Z","published":"2023-11-22T09:25:08Z","title":"Immunohistochemistry guided segmentation of benign epithelial cells, in\n  situ lesions, and invasive epithelial cells in breast cancer slides","summary":"  Digital pathology enables automatic analysis of histopathological sections\nusing artificial intelligence (AI). Automatic evaluation could improve\ndiagnostic efficiency and help find associations between morphological features\nand clinical outcome. For development of such prediction models, identifying\ninvasive epithelial cells, and separating these from benign epithelial cells\nand in situ lesions would be the first step. In this study, we aimed to develop\nan AI model for segmentation of epithelial cells in sections from breast\ncancer. We generated epithelial ground truth masks by restaining hematoxylin\nand eosin (HE) sections with cytokeratin (CK) AE1/AE3, and by pathologists'\nannotations. HE/CK image pairs were used to train a convolutional neural\nnetwork, and data augmentation was used to make the model more robust. Tissue\nmicroarrays (TMAs) from 839 patients, and whole slide images from two patients\nwere used for training and evaluation of the models. The sections were derived\nfrom four cohorts of breast cancer patients. TMAs from 21 patients from a fifth\ncohort was used as a second test set. In quantitative evaluation, a mean Dice\nscore of 0.70, 0.79, and 0.75 for invasive epithelial cells, benign epithelial\ncells, and in situ lesions, respectively, were achieved. In qualitative scoring\n(0-5) by pathologists, results were best for all epithelium and invasive\nepithelium, with scores of 4.7 and 4.4. Scores for benign epithelium and in\nsitu lesions were 3.7 and 2.0. The proposed model segmented epithelial cells in\nHE stained breast cancer slides well, but further work is needed for accurate\ndivision between the classes. Immunohistochemistry, together with pathologists'\nannotations, enabled the creation of accurate ground truths. The model is made\nfreely available in FastPathology and the code is available at\nhttps://github.com/AICAN-Research/breast-epithelium-segmentation\n","authors":["Maren Høibø","André Pedersen","Vibeke Grotnes Dale","Sissel Marie Berget","Borgny Ytterhus","Cecilia Lindskog","Elisabeth Wik","Lars A. Akslen","Ingerid Reinertsen","Erik Smistad","Marit Valla"],"pdf_url":"https://arxiv.org/pdf/2311.13261v1.pdf","comment":"19 pages, 6 figures. Submitted to a scientific journal"},{"id":"http://arxiv.org/abs/2311.13258v1","updated":"2023-11-22T09:23:34Z","published":"2023-11-22T09:23:34Z","title":"ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided\n  Code-Vision Representation","summary":"  State-of-the-art vision-language models (VLMs) still have limited performance\nin structural knowledge extraction, such as relations between objects. In this\nwork, we present ViStruct, a training framework to learn VLMs for effective\nvisual structural knowledge extraction. Two novel designs are incorporated.\nFirst, we propose to leverage the inherent structure of programming language to\ndepict visual structural information. This approach enables explicit and\nconsistent representation of visual structural information of multiple\ngranularities, such as concepts, relations, and events, in a well-organized\nstructured format. Second, we introduce curriculum-based learning for VLMs to\nprogressively comprehend visual structures, from fundamental visual concepts to\nintricate event structures. Our intuition is that lower-level knowledge may\ncontribute to complex visual structure understanding. Furthermore, we compile\nand release a collection of datasets tailored for visual structural knowledge\nextraction. We adopt a weakly-supervised approach to directly generate visual\nevent structures from captions for ViStruct training, capitalizing on abundant\nimage-caption pairs from the web. In experiments, we evaluate ViStruct on\nvisual structure prediction tasks, demonstrating its effectiveness in improving\nthe understanding of visual structures. The code is public at\n\\url{https://github.com/Yangyi-Chen/vi-struct}.\n","authors":["Yangyi Chen","Xingyao Wang","Manling Li","Derek Hoiem","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2311.13258v1.pdf","comment":"Accepted to EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13254v1","updated":"2023-11-22T09:18:49Z","published":"2023-11-22T09:18:49Z","title":"DA-STC: Domain Adaptive Video Semantic Segmentation via Spatio-Temporal\n  Consistency","summary":"  Video semantic segmentation is a pivotal aspect of video representation\nlearning. However, significant domain shifts present a challenge in effectively\nlearning invariant spatio-temporal features across the labeled source domain\nand unlabeled target domain for video semantic segmentation. To solve the\nchallenge, we propose a novel DA-STC method for domain adaptive video semantic\nsegmentation, which incorporates a bidirectional multi-level spatio-temporal\nfusion module and a category-aware spatio-temporal feature alignment module to\nfacilitate consistent learning for domain-invariant features. Firstly, we\nperform bidirectional spatio-temporal fusion at the image sequence level and\nshallow feature level, leading to the construction of two fused intermediate\nvideo domains. This prompts the video semantic segmentation model to\nconsistently learn spatio-temporal features of shared patch sequences which are\ninfluenced by domain-specific contexts, thereby mitigating the feature gap\nbetween the source and target domain. Secondly, we propose a category-aware\nfeature alignment module to promote the consistency of spatio-temporal\nfeatures, facilitating adaptation to the target domain. Specifically, we\nadaptively aggregate the domain-specific deep features of each category along\nspatio-temporal dimensions, which are further constrained to achieve\ncross-domain intra-class feature alignment and inter-class feature separation.\nExtensive experiments demonstrate the effectiveness of our method, which\nachieves state-of-the-art mIOUs on multiple challenging benchmarks.\nFurthermore, we extend the proposed DA-STC to the image domain, where it also\nexhibits superior performance for domain adaptive semantic segmentation. The\nsource code and models will be made available at\n\\url{https://github.com/ZHE-SAPI/DA-STC}.\n","authors":["Zhe Zhang","Gaochang Wu","Jing Zhang","Chunhua Shen","Dacheng Tao","Tianyou Chai"],"pdf_url":"https://arxiv.org/pdf/2311.13254v1.pdf","comment":"18 pages,9 figures"},{"id":"http://arxiv.org/abs/2311.13250v1","updated":"2023-11-22T09:12:50Z","published":"2023-11-22T09:12:50Z","title":"Towards Hetero-Client Federated Multi-Task Learning","summary":"  Federated Learning (FL) enables joint training across distributed clients\nusing their local data privately. Federated Multi-Task Learning (FMTL) builds\non FL to handle multiple tasks, assuming model congruity that identical model\narchitecture is deployed in each client. To relax this assumption and thus\nextend real-world applicability, we introduce a novel problem setting,\nHetero-Client Federated Multi-Task Learning (HC-FMTL), to accommodate diverse\ntask setups. The main challenge of HC-FMTL is the model incongruity issue that\ninvalidates conventional aggregation methods. It also escalates the\ndifficulties in accurate model aggregation to deal with data and task\nheterogeneity inherent in FMTL. To address these challenges, we propose the\nFedHCA$^2$ framework, which allows for federated training of personalized\nmodels by modeling relationships among heterogeneous clients. Drawing on our\ntheoretical insights into the difference between multi-task and federated\noptimization, we propose the Hyper Conflict-Averse Aggregation scheme to\nmitigate conflicts during encoder updates. Additionally, inspired by task\ninteraction in MTL, the Hyper Cross Attention Aggregation scheme uses\nlayer-wise cross attention to enhance decoder interactions while alleviating\nmodel incongruity. Moreover, we employ learnable Hyper Aggregation Weights for\neach client to customize personalized parameter updates. Extensive experiments\ndemonstrate the superior performance of FedHCA$^2$ in various HC-FMTL scenarios\ncompared to representative methods. Our code will be made publicly available.\n","authors":["Yuxiang Lu","Suizhi Huang","Yuwen Yang","Shalayiding Sirejiding","Yue Ding","Hongtao Lu"],"pdf_url":"https://arxiv.org/pdf/2311.13250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15670v2","updated":"2023-11-22T08:49:44Z","published":"2023-06-27T17:59:46Z","title":"Symphonize 3D Semantic Scene Completion with Contextual Instance Queries","summary":"  `3D Semantic Scene Completion (SSC) has emerged as a nascent and pivotal\nundertaking in autonomous driving, aiming to predict voxel occupancy within\nvolumetric scenes. However, prevailing methodologies primarily focus on\nvoxel-wise feature aggregation, while neglecting instance semantics and scene\ncontext. In this paper, we present a novel paradigm termed Symphonies\n(Scene-from-Insts), that delves into the integration of instance queries to\norchestrate 2D-to-3D reconstruction and 3D scene modeling. Leveraging our\nproposed Serial Instance-Propagated Attentions, Symphonies dynamically encodes\ninstance-centric semantics, facilitating intricate interactions between\nimage-based and volumetric domains. Simultaneously, Symphonies enables holistic\nscene comprehension by capturing context through the efficient fusion of\ninstance queries, alleviating geometric ambiguity such as occlusion and\nperspective errors through contextual scene reasoning. Experimental results\ndemonstrate that Symphonies achieves state-of-the-art performance on\nchallenging benchmarks SemanticKITTI and SSCBench-KITTI-360, yielding\nremarkable mIoU scores of 15.04 and 18.58, respectively. These results showcase\nthe paradigm's promising advancements. The code is available at\nhttps://github.com/hustvl/Symphonies.\n","authors":["Haoyi Jiang","Tianheng Cheng","Naiyu Gao","Haoyang Zhang","Tianwei Lin","Wenyu Liu","Xinggang Wang"],"pdf_url":"https://arxiv.org/pdf/2306.15670v2.pdf","comment":"Technical report. Code and models at:\n  https://github.com/hustvl/Symphonies"},{"id":"http://arxiv.org/abs/2311.13234v1","updated":"2023-11-22T08:45:01Z","published":"2023-11-22T08:45:01Z","title":"TSegFormer: 3D Tooth Segmentation in Intraoral Scans with Geometry\n  Guided Transformer","summary":"  Optical Intraoral Scanners (IOS) are widely used in digital dentistry to\nprovide detailed 3D information of dental crowns and the gingiva. Accurate 3D\ntooth segmentation in IOSs is critical for various dental applications, while\nprevious methods are error-prone at complicated boundaries and exhibit\nunsatisfactory results across patients. In this paper, we propose TSegFormer\nwhich captures both local and global dependencies among different teeth and the\ngingiva in the IOS point clouds with a multi-task 3D transformer architecture.\nMoreover, we design a geometry-guided loss based on a novel point curvature to\nrefine boundaries in an end-to-end manner, avoiding time-consuming\npost-processing to reach clinically applicable segmentation. In addition, we\ncreate a dataset with 16,000 IOSs, the largest ever IOS dataset to the best of\nour knowledge. The experimental results demonstrate that our TSegFormer\nconsistently surpasses existing state-of-the-art baselines. The superiority of\nTSegFormer is corroborated by extensive analysis, visualizations and real-world\nclinical applicability tests. Our code is available at\nhttps://github.com/huiminxiong/TSegFormer.\n","authors":["Huimin Xiong","Kunle Li","Kaiyuan Tan","Yang Feng","Joey Tianyi Zhou","Jin Hao","Haochao Ying","Jian Wu","Zuozhu Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13234v1.pdf","comment":"MICCAI 2023, STAR(Student Travel) award. 11 pages, 3 figures, 5\n  tables. arXiv admin note: text overlap with arXiv:2210.16627"},{"id":"http://arxiv.org/abs/2311.13231v1","updated":"2023-11-22T08:42:46Z","published":"2023-11-22T08:42:46Z","title":"Using Human Feedback to Fine-tune Diffusion Models without Any Reward\n  Model","summary":"  Using reinforcement learning with human feedback (RLHF) has shown significant\npromise in fine-tuning diffusion models. Previous methods start by training a\nreward model that aligns with human preferences, then leverage RL techniques to\nfine-tune the underlying models. However, crafting an efficient reward model\ndemands extensive datasets, optimal architecture, and manual hyperparameter\ntuning, making the process both time and cost-intensive. The direct preference\noptimization (DPO) method, effective in fine-tuning large language models,\neliminates the necessity for a reward model. However, the extensive GPU memory\nrequirement of the diffusion model's denoising process hinders the direct\napplication of the DPO method. To address this issue, we introduce the Direct\nPreference for Denoising Diffusion Policy Optimization (D3PO) method to\ndirectly fine-tune diffusion models. The theoretical analysis demonstrates that\nalthough D3PO omits training a reward model, it effectively functions as the\noptimal reward model trained using human feedback data to guide the learning\nprocess. This approach requires no training of a reward model, proving to be\nmore direct, cost-effective, and minimizing computational overhead. In\nexperiments, our method uses the relative scale of objectives as a proxy for\nhuman preference, delivering comparable results to methods using ground-truth\nrewards. Moreover, D3PO demonstrates the ability to reduce image distortion\nrates and generate safer images, overcoming challenges lacking robust reward\nmodels.\n","authors":["Kai Yang","Jian Tao","Jiafei Lyu","Chunjiang Ge","Jiaxin Chen","Qimai Li","Weihan Shen","Xiaolong Zhu","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2311.13231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13222v1","updated":"2023-11-22T08:25:15Z","published":"2023-11-22T08:25:15Z","title":"Towards Detecting, Recognizing, and Parsing the Address Information from\n  Bangla Signboard: A Deep Learning-based Approach","summary":"  Retrieving textual information from natural scene images is an active\nresearch area in the field of computer vision with numerous practical\napplications. Detecting text regions and extracting text from signboards is a\nchallenging problem due to special characteristics like reflecting lights,\nuneven illumination, or shadows found in real-life natural scene images. With\nthe advent of deep learning-based methods, different sophisticated techniques\nhave been proposed for text detection and text recognition from the natural\nscene. Though a significant amount of effort has been devoted to extracting\nnatural scene text for resourceful languages like English, little has been done\nfor low-resource languages like Bangla. In this research work, we have proposed\nan end-to-end system with deep learning-based models for efficiently detecting,\nrecognizing, correcting, and parsing address information from Bangla\nsignboards. We have created manually annotated datasets and synthetic datasets\nto train signboard detection, address text detection, address text recognition,\naddress text correction, and address text parser models. We have conducted a\ncomparative study among different CTC-based and Encoder-Decoder model\narchitectures for Bangla address text recognition. Moreover, we have designed a\nnovel address text correction model using a sequence-to-sequence\ntransformer-based network to improve the performance of Bangla address text\nrecognition model by post-correction. Finally, we have developed a Bangla\naddress text parser using the state-of-the-art transformer-based pre-trained\nlanguage model.\n","authors":["Hasan Murad","Mohammed Eunus Ali"],"pdf_url":"https://arxiv.org/pdf/2311.13222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03943v2","updated":"2023-11-22T07:52:06Z","published":"2023-11-07T12:36:20Z","title":"CLIP Guided Image-perceptive Prompt Learning for Image Enhancement","summary":"  Image enhancement is a significant research area in the fields of computer\nvision and image processing. In recent years, many learning-based methods for\nimage enhancement have been developed, where the Look-up-table (LUT) has proven\nto be an effective tool. In this paper, we delve into the potential of\nContrastive Language-Image Pre-Training (CLIP) Guided Prompt Learning,\nproposing a simple structure called CLIP-LUT for image enhancement. We found\nthat the prior knowledge of CLIP can effectively discern the quality of\ndegraded images, which can provide reliable guidance. To be specific, We\ninitially learn image-perceptive prompts to distinguish between original and\ntarget images using CLIP model, in the meanwhile, we introduce a very simple\nnetwork by incorporating a simple baseline to predict the weights of three\ndifferent LUT as enhancement network. The obtained prompts are used to steer\nthe enhancement network like a loss function and improve the performance of\nmodel. We demonstrate that by simply combining a straightforward method with\nCLIP, we can obtain satisfactory results.\n","authors":["Weiwen Chen","Qiuhong Ke","Zinuo Li"],"pdf_url":"https://arxiv.org/pdf/2311.03943v2.pdf","comment":"A trial work to the image enhancement"},{"id":"http://arxiv.org/abs/2311.13209v1","updated":"2023-11-22T07:47:39Z","published":"2023-11-22T07:47:39Z","title":"Test-time Adaptive Vision-and-Language Navigation","summary":"  Vision-and-Language Navigation (VLN) has witnessed significant advancements\nin recent years, largely attributed to meticulously curated datasets and\nproficiently trained models. Nevertheless, when tested in diverse environments,\nthe trained models inevitably encounter significant shifts in data\ndistribution, highlighting that relying solely on pre-trained and fixed\nnavigation models is insufficient. To enhance models' generalization ability,\ntest-time adaptation (TTA) demonstrates significant potential in the computer\nvision field by leveraging unlabeled test samples for model updates. However,\nsimply applying existing TTA methods to the VLN task cannot well handle the\nadaptability-stability dilemma of VLN models, i.e., frequent updates can result\nin drastic changes in model parameters, while occasional updates can make the\nmodels ill-equipped to handle dynamically changing environments. Therefore, we\npropose a Fast-Slow Test-Time Adaptation (FSTTA) approach for VLN by performing\ndecomposition-accumulation analysis for both gradients and parameters in a\nunified framework. Specifically, in the fast update phase, gradients generated\nduring the recent multi-step navigation process are decomposed into components\nwith varying levels of consistency. Then, these components are adaptively\naccumulated to pinpoint a concordant direction for fast model adaptation. In\nthe slow update phase, historically recorded parameters are gathered, and a\nsimilar decomposition-accumulation analysis is conducted to revert the model to\na stable state. Extensive experiments show that our method obtains impressive\nperformance gains on four popular benchmarks.\n","authors":["Junyu Gao","Xuan Yao","Changsheng Xu"],"pdf_url":"https://arxiv.org/pdf/2311.13209v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2305.16213v2","updated":"2023-11-22T07:34:38Z","published":"2023-05-25T16:19:18Z","title":"ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with\n  Variational Score Distillation","summary":"  Score distillation sampling (SDS) has shown great promise in text-to-3D\ngeneration by distilling pretrained large-scale text-to-image diffusion models,\nbut suffers from over-saturation, over-smoothing, and low-diversity problems.\nIn this work, we propose to model the 3D parameter as a random variable instead\nof a constant as in SDS and present variational score distillation (VSD), a\nprincipled particle-based variational framework to explain and address the\naforementioned issues in text-to-3D generation. We show that SDS is a special\ncase of VSD and leads to poor samples with both small and large CFG weights. In\ncomparison, VSD works well with various CFG weights as ancestral sampling from\ndiffusion models and simultaneously improves the diversity and sample quality\nwith a common CFG weight (i.e., $7.5$). We further present various improvements\nin the design space for text-to-3D such as distillation time schedule and\ndensity initialization, which are orthogonal to the distillation algorithm yet\nnot well explored. Our overall approach, dubbed ProlificDreamer, can generate\nhigh rendering resolution (i.e., $512\\times512$) and high-fidelity NeRF with\nrich structure and complex effects (e.g., smoke and drops). Further,\ninitialized from NeRF, meshes fine-tuned by VSD are meticulously detailed and\nphoto-realistic. Project page and codes:\nhttps://ml.cs.tsinghua.edu.cn/prolificdreamer/\n","authors":["Zhengyi Wang","Cheng Lu","Yikai Wang","Fan Bao","Chongxuan Li","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2305.16213v2.pdf","comment":"NeurIPS 2023 (Spotlight)"},{"id":"http://arxiv.org/abs/2311.13200v1","updated":"2023-11-22T07:07:55Z","published":"2023-11-22T07:07:55Z","title":"Self-guided Few-shot Semantic Segmentation for Remote Sensing Imagery\n  Based on Large Vision Models","summary":"  The Segment Anything Model (SAM) exhibits remarkable versatility and\nzero-shot learning abilities, owing largely to its extensive training data\n(SA-1B). Recognizing SAM's dependency on manual guidance given its\ncategory-agnostic nature, we identified unexplored potential within few-shot\nsemantic segmentation tasks for remote sensing imagery. This research\nintroduces a structured framework designed for the automation of few-shot\nsemantic segmentation. It utilizes the SAM model and facilitates a more\nefficient generation of semantically discernible segmentation outcomes. Central\nto our methodology is a novel automatic prompt learning approach, leveraging\nprior guided masks to produce coarse pixel-wise prompts for SAM. Extensive\nexperiments on the DLRSD datasets underline the superiority of our approach,\noutperforming other available few-shot methodologies.\n","authors":["Xiyu Qi","Yifan Wu","Yongqiang Mao","Wenhui Zhang","Yidan Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.13200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13199v1","updated":"2023-11-22T07:06:38Z","published":"2023-11-22T07:06:38Z","title":"DRIFu: Differentiable Rendering and Implicit Function-based Single-View\n  3D Reconstruction","summary":"  The Differentiable Rendering and Implicit Function-based model (DRIFu) draws\nits roots from the Pixel-aligned Implicit Function (PIFU), a pioneering 3D\ndigitization technique initially designed for clothed human bodies. PIFU excels\nin capturing nuanced body shape variations within a low-dimensional space and\nhas been extensively trained on human 3D scans. However, the application of\nPIFU to live animals poses significant challenges, primarily due to the\ninherent difficulty in obtaining the cooperation of animals for 3D scanning. In\nresponse to this challenge, we introduce the DRIFu model, specifically tailored\nfor animal digitization. To train DRIFu, we employ a curated set of synthetic\n3D animal models, encompassing diverse shapes, sizes, and even accounting for\nvariations such as baby birds. Our innovative alignment tools play a pivotal\nrole in mapping these diverse synthetic animal models onto a unified template,\nfacilitating precise predictions of animal shape and texture. Crucially, our\ntemplate alignment strategy establishes a shared shape space, allowing for the\nseamless sampling of new animal shapes, posing them realistically, animating\nthem, and aligning them with real-world data. This groundbreaking approach\nrevolutionizes our capacity to comprehensively understand and represent avian\nforms. For further details and access to the project, the project website can\nbe found at https://github.com/kuangzijian/drifu-for-animals\n","authors":["Zijian Kuang","Lihang Ying","Shi Jin"],"pdf_url":"https://arxiv.org/pdf/2311.13199v1.pdf","comment":"arXiv admin note: text overlap with arXiv:1905.05172 by other authors"},{"id":"http://arxiv.org/abs/2311.13198v1","updated":"2023-11-22T07:05:54Z","published":"2023-11-22T07:05:54Z","title":"DoubleAUG: Single-domain Generalized Object Detector in Urban via Color\n  Perturbation and Dual-style Memory","summary":"  Object detection in urban scenarios is crucial for autonomous driving in\nintelligent traffic systems. However, unlike conventional object detection\ntasks, urban-scene images vary greatly in style. For example, images taken on\nsunny days differ significantly from those taken on rainy days. Therefore,\nmodels trained on sunny day images may not generalize well to rainy day images.\nIn this paper, we aim to solve the single-domain generalizable object detection\ntask in urban scenarios, meaning that a model trained on images from one\nweather condition should be able to perform well on images from any other\nweather conditions. To address this challenge, we propose a novel Double\nAUGmentation (DoubleAUG) method that includes image- and feature-level\naugmentation schemes. In the image-level augmentation, we consider the\nvariation in color information across different weather conditions and propose\na Color Perturbation (CP) method that randomly exchanges the RGB channels to\ngenerate various images. In the feature-level augmentation, we propose to\nutilize a Dual-Style Memory (DSM) to explore the diverse style information on\nthe entire dataset, further enhancing the model's generalization capability.\nExtensive experiments demonstrate that our proposed method outperforms\nstate-of-the-art methods. Furthermore, ablation studies confirm the\neffectiveness of each module in our proposed method. Moreover, our method is\nplug-and-play and can be integrated into existing methods to further improve\nmodel performance.\n","authors":["Lei Qi","Peng Dong","Tan Xiong","Hui Xue","Xin Geng"],"pdf_url":"https://arxiv.org/pdf/2311.13198v1.pdf","comment":"Accepted by ACM Transactions on Multimedia Computing, Communications,\n  and Applications"},{"id":"http://arxiv.org/abs/2311.13194v1","updated":"2023-11-22T06:46:37Z","published":"2023-11-22T06:46:37Z","title":"Towards Improving Document Understanding: An Exploration on\n  Text-Grounding via MLLMs","summary":"  In the field of document understanding, significant advances have been made\nin the fine-tuning of Multimodal Large Language Models (MLLMs) with\ninstruction-following data. Nevertheless, the potential of text-grounding\ncapability within text-rich scenarios remains underexplored. In this paper, we\npresent a text-grounding document understanding model, termed TGDoc, which\naddresses this deficiency by enhancing MLLMs with the ability to discern the\nspatial positioning of text within images. Empirical evidence suggests that\ntext-grounding improves the model's interpretation of textual content, thereby\nelevating its proficiency in comprehending text-rich images. Specifically, we\ncompile a dataset containing 99K PowerPoint presentations sourced from the\ninternet. We formulate instruction tuning tasks including text detection,\nrecognition, and spotting to facilitate the cohesive alignment between the\nvisual encoder and large language model. Moreover, we curate a collection of\ntext-rich images and prompt the text-only GPT-4 to generate 12K high-quality\nconversations, featuring textual locations within text-rich scenarios. By\nintegrating text location data into the instructions, TGDoc is adept at\ndiscerning text locations during the visual question process. Extensive\nexperiments demonstrate that our method achieves state-of-the-art performance\nacross multiple text-rich benchmarks, validating the effectiveness of our\nmethod.\n","authors":["Yonghui Wang","Wengang Zhou","Hao Feng","Keyi Zhou","Houqiang Li"],"pdf_url":"https://arxiv.org/pdf/2311.13194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13187v1","updated":"2023-11-22T06:28:30Z","published":"2023-11-22T06:28:30Z","title":"NeISF: Neural Incident Stokes Field for Geometry and Material Estimation","summary":"  Multi-view inverse rendering is the problem of estimating the scene\nparameters such as shapes, materials, or illuminations from a sequence of\nimages captured under different viewpoints. Many approaches, however, assume\nsingle light bounce and thus fail to recover challenging scenarios like\ninter-reflections. On the other hand, simply extending those methods to\nconsider multi-bounced light requires more assumptions to alleviate the\nambiguity. To address this problem, we propose Neural Incident Stokes Fields\n(NeISF), a multi-view inverse rendering framework that reduces ambiguities\nusing polarization cues. The primary motivation for using polarization cues is\nthat it is the accumulation of multi-bounced light, providing rich information\nabout geometry and material. Based on this knowledge, the proposed incident\nStokes field efficiently models the accumulated polarization effect with the\naid of an original physically-based differentiable polarimetric renderer.\nLastly, experimental results show that our method outperforms the existing\nworks in synthetic and real scenarios.\n","authors":["Chenhao Li","Taishi Ono","Takeshi Uemori","Hajime Mihara","Alexander Gatto","Hajime Nagahara","Yuseke Moriuchi"],"pdf_url":"https://arxiv.org/pdf/2311.13187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13186v1","updated":"2023-11-22T06:26:24Z","published":"2023-11-22T06:26:24Z","title":"Applications of Spiking Neural Networks in Visual Place Recognition","summary":"  In robotics, Spiking Neural Networks (SNNs) are increasingly recognized for\ntheir largely-unrealized potential energy efficiency and low latency\nparticularly when implemented on neuromorphic hardware. Our paper highlights\nthree advancements for SNNs in Visual Place Recognition (VPR). First, we\npropose Modular SNNs, where each SNN represents a set of non-overlapping\ngeographically distinct places, enabling scalable networks for large\nenvironments. Secondly, we present Ensembles of Modular SNNs, where multiple\nnetworks represent the same place, significantly enhancing accuracy compared to\nsingle-network models. Our SNNs are compact and small, comprising only 1500\nneurons and 474k synapses, which makes them ideally suited for ensembling due\nto this small size. Lastly, we investigate the role of sequence matching in\nSNN-based VPR, a technique where consecutive images are used to refine place\nrecognition. We analyze the responsiveness of SNNs to ensembling and sequence\nmatching compared to other VPR techniques. Our contributions highlight the\nviability of SNNs for VPR, offering scalable and robust solutions, paving the\nway for their application in various energy-sensitive robotic tasks.\n","authors":["Somayeh Hussaini","Michael Milford","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2311.13186v1.pdf","comment":"17 pages, 8 figures, under review"},{"id":"http://arxiv.org/abs/2311.13182v1","updated":"2023-11-22T06:13:39Z","published":"2023-11-22T06:13:39Z","title":"Differentiable Radio Frequency Ray Tracing for Millimeter-Wave Sensing","summary":"  Millimeter wave (mmWave) sensing is an emerging technology with applications\nin 3D object characterization and environment mapping. However, realizing\nprecise 3D reconstruction from sparse mmWave signals remains challenging.\nExisting methods rely on data-driven learning, constrained by dataset\navailability and difficulty in generalization. We propose DiffSBR, a\ndifferentiable framework for mmWave-based 3D reconstruction. DiffSBR\nincorporates a differentiable ray tracing engine to simulate radar point clouds\nfrom virtual 3D models. A gradient-based optimizer refines the model parameters\nto minimize the discrepancy between simulated and real point clouds.\nExperiments using various radar hardware validate DiffSBR's capability for\nfine-grained 3D reconstruction, even for novel objects unseen by the radar\npreviously. By integrating physics-based simulation with gradient optimization,\nDiffSBR transcends the limitations of data-driven approaches and pioneers a new\nparadigm for mmWave sensing.\n","authors":["Xingyu Chen","Xinyu Zhang","Qiyue Xia","Xinmin Fang","Chris Xiaoxuan Lu","Zhengxiong Li"],"pdf_url":"https://arxiv.org/pdf/2311.13182v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13177v1","updated":"2023-11-22T05:44:51Z","published":"2023-11-22T05:44:51Z","title":"Volumetric Reconstruction Resolves Off-Resonance Artifacts in Static and\n  Dynamic PROPELLER MRI","summary":"  Off-resonance artifacts in magnetic resonance imaging (MRI) are visual\ndistortions that occur when the actual resonant frequencies of spins within the\nimaging volume differ from the expected frequencies used to encode spatial\ninformation. These discrepancies can be caused by a variety of factors,\nincluding magnetic field inhomogeneities, chemical shifts, or susceptibility\ndifferences within the tissues. Such artifacts can manifest as blurring,\nghosting, or misregistration of the reconstructed image, and they often\ncompromise its diagnostic quality. We propose to resolve these artifacts by\nlifting the 2D MRI reconstruction problem to 3D, introducing an additional\n\"spectral\" dimension to model this off-resonance. Our approach is inspired by\nrecent progress in modeling radiance fields, and is capable of reconstructing\nboth static and dynamic MR images as well as separating fat and water, which is\nof independent clinical interest. We demonstrate our approach in the context of\nPROPELLER (Periodically Rotated Overlapping ParallEL Lines with Enhanced\nReconstruction) MRI acquisitions, which are popular for their robustness to\nmotion artifacts. Our method operates in a few minutes on a single GPU, and to\nour knowledge is the first to correct for chemical shift in gradient echo\nPROPELLER MRI reconstruction without additional measurements or pretraining\ndata.\n","authors":["Annesha Ghosh","Gordon Wetzstein","Mert Pilanci","Sara Fridovich-Keil"],"pdf_url":"https://arxiv.org/pdf/2311.13177v1.pdf","comment":"Code is available at\n  https://github.com/sarafridov/volumetric-propeller"},{"id":"http://arxiv.org/abs/2311.13172v1","updated":"2023-11-22T05:31:06Z","published":"2023-11-22T05:31:06Z","title":"Learning to Complement with Multiple Humans (LECOMH): Integrating\n  Multi-rater and Noisy-Label Learning into Human-AI Collaboration","summary":"  The advent of learning with noisy labels (LNL), multi-rater learning, and\nhuman-AI collaboration has revolutionised the development of robust\nclassifiers, enabling them to address the challenges posed by different types\nof data imperfections and complex decision processes commonly encountered in\nreal-world applications. While each of these methodologies has individually\nmade significant strides in addressing their unique challenges, the development\nof techniques that can simultaneously tackle these three problems remains\nunderexplored. This paper addresses this research gap by integrating\nnoisy-label learning, multi-rater learning, and human-AI collaboration with new\nbenchmarks and the innovative Learning to Complement with Multiple Humans\n(LECOMH) approach. LECOMH optimises the level of human collaboration during\ntesting, aiming to optimise classification accuracy while minimising\ncollaboration costs that vary from 0 to M, where M is the maximum number of\nhuman collaborators. We quantitatively compare LECOMH with leading human-AI\ncollaboration methods using our proposed benchmarks. LECOMH consistently\noutperforms the competition, with accuracy improving as collaboration costs\nincrease. Notably, LECOMH is the only method enhancing human labeller\nperformance across all benchmarks.\n","authors":["Zheng Zhang","Kevin Wells","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2311.13172v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2311.13168v1","updated":"2023-11-22T05:24:35Z","published":"2023-11-22T05:24:35Z","title":"3D Face Style Transfer with a Hybrid Solution of NeRF and Mesh\n  Rasterization","summary":"  Style transfer for human face has been widely researched in recent years.\nMajority of the existing approaches work in 2D image domain and have 3D\ninconsistency issue when applied on different viewpoints of the same face. In\nthis paper, we tackle the problem of 3D face style transfer which aims at\ngenerating stylized novel views of a 3D human face with multi-view consistency.\nWe propose to use a neural radiance field (NeRF) to represent 3D human face and\ncombine it with 2D style transfer to stylize the 3D face. We find that directly\ntraining a NeRF on stylized images from 2D style transfer brings in 3D\ninconsistency issue and causes blurriness. On the other hand, training a NeRF\njointly with 2D style transfer objectives shows poor convergence due to the\nidentity and head pose gap between style image and content image. It also poses\nchallenge in training time and memory due to the need of volume rendering for\nfull image to apply style transfer loss functions. We therefore propose a\nhybrid framework of NeRF and mesh rasterization to combine the benefits of high\nfidelity geometry reconstruction of NeRF and fast rendering speed of mesh. Our\nframework consists of three stages: 1. Training a NeRF model on input face\nimages to learn the 3D geometry; 2. Extracting a mesh from the trained NeRF\nmodel and optimizing it with style transfer objectives via differentiable\nrasterization; 3. Training a new color network in NeRF conditioned on a style\nembedding to enable arbitrary style transfer to the 3D face. Experiment results\nshow that our approach generates high quality face style transfer with great 3D\nconsistency, while also enabling a flexible style control.\n","authors":["Jianwei Feng","Prateek Singhal"],"pdf_url":"https://arxiv.org/pdf/2311.13168v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.05254v2","updated":"2023-11-22T05:00:56Z","published":"2023-09-11T06:18:05Z","title":"Towards Better Data Exploitation in Self-Supervised Monocular Depth\n  Estimation","summary":"  Depth estimation plays an important role in the robotic perception system.\nSelf-supervised monocular paradigm has gained significant attention since it\ncan free training from the reliance on depth annotations. Despite recent\nadvancements, existing self-supervised methods still underutilize the available\ntraining data, limiting their generalization ability. In this paper, we take\ntwo data augmentation techniques, namely Resizing-Cropping and\nSplitting-Permuting, to fully exploit the potential of training datasets.\nSpecifically, the original image and the generated two augmented images are fed\ninto the training pipeline simultaneously and we leverage them to conduct\nself-distillation. Additionally, we introduce the detail-enhanced DepthNet with\nan extra full-scale branch in the encoder and a grid decoder to enhance the\nrestoration of fine details in depth maps. Experimental results demonstrate our\nmethod can achieve state-of-the-art performance on the KITTI benchmark, with\nboth raw ground truth and improved ground truth. Moreover, our models also show\nsuperior generalization performance when transferring to Make3D and NYUv2\ndatasets. Our codes are available at https://github.com/Sauf4896/BDEdepth.\n","authors":["Jinfeng Liu","Lingtong Kong","Jie Yang","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2309.05254v2.pdf","comment":"8 pages, 6 figures, accepted by IEEE Robotics and Automation Letters\n  (RA-L, 2023)"},{"id":"http://arxiv.org/abs/2311.13152v1","updated":"2023-11-22T04:31:09Z","published":"2023-11-22T04:31:09Z","title":"Test-Time Augmentation for 3D Point Cloud Classification and\n  Segmentation","summary":"  Data augmentation is a powerful technique to enhance the performance of a\ndeep learning task but has received less attention in 3D deep learning. It is\nwell known that when 3D shapes are sparsely represented with low point density,\nthe performance of the downstream tasks drops significantly. This work explores\ntest-time augmentation (TTA) for 3D point clouds. We are inspired by the recent\nrevolution of learning implicit representation and point cloud upsampling,\nwhich can produce high-quality 3D surface reconstruction and\nproximity-to-surface, respectively. Our idea is to leverage the implicit field\nreconstruction or point cloud upsampling techniques as a systematic way to\naugment point cloud data. Mainly, we test both strategies by sampling points\nfrom the reconstructed results and using the sampled point cloud as test-time\naugmented data. We show that both strategies are effective in improving\naccuracy. We observed that point cloud upsampling for test-time augmentation\ncan lead to more significant performance improvement on downstream tasks such\nas object classification and segmentation on the ModelNet40, ShapeNet,\nScanObjectNN, and SemanticKITTI datasets, especially for sparse point clouds.\n","authors":["Tuan-Anh Vu","Srinjay Sarkar","Zhiyuan Zhang","Binh-Son Hua","Sai-Kit Yeung"],"pdf_url":"https://arxiv.org/pdf/2311.13152v1.pdf","comment":"This paper is accepted in 3DV 2024"},{"id":"http://arxiv.org/abs/2308.09936v2","updated":"2023-11-22T04:29:33Z","published":"2023-08-19T07:53:43Z","title":"BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual\n  Questions","summary":"  Vision Language Models (VLMs), which extend Large Language Models (LLM) by\nincorporating visual understanding capability, have demonstrated significant\nadvancements in addressing open-ended visual question-answering (VQA) tasks.\nHowever, these models cannot accurately interpret images infused with text, a\ncommon occurrence in real-world scenarios. Standard procedures for extracting\ninformation from images often involve learning a fixed set of query embeddings.\nThese embeddings are designed to encapsulate image contexts and are later used\nas soft prompt inputs in LLMs. Yet, this process is limited to the token count,\npotentially curtailing the recognition of scenes with text-rich context. To\nimprove upon them, the present study introduces BLIVA: an augmented version of\nInstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings\nfrom InstructBLIP and also directly projects encoded patch embeddings into the\nLLM, a technique inspired by LLaVA. This approach assists the model to capture\nintricate details potentially missed during the query decoding process.\nEmpirical evidence demonstrates that our model, BLIVA, significantly enhances\nperformance in processing text-rich VQA benchmarks (up to 17.76% in OCR-VQA\nbenchmark) and in undertaking general (not particularly text-rich) VQA\nbenchmarks (up to 7.9% in Visual Spatial Reasoning benchmark), comparing to our\nbaseline InstructBLIP. BLIVA demonstrates significant capability in decoding\nreal-world images, irrespective of text presence. To demonstrate the broad\nindustry applications enabled by BLIVA, we evaluate the model using a new\ndataset comprising YouTube thumbnails paired with question-answer sets across\n11 diverse categories. For researchers interested in further exploration, our\ncode and models are freely accessible at https://github.com/mlpc-ucsd/BLIVA.\n","authors":["Wenbo Hu","Yifan Xu","Yi Li","Weiyue Li","Zeyuan Chen","Zhuowen Tu"],"pdf_url":"https://arxiv.org/pdf/2308.09936v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13144v1","updated":"2023-11-22T04:14:42Z","published":"2023-11-22T04:14:42Z","title":"Single Image Compressed Sensing MRI via a Self-Supervised Deep Denoising\n  Approach","summary":"  Popular methods in compressed sensing (CS) are dependent on deep learning\n(DL), where large amounts of data are used to train non-linear reconstruction\nmodels. However, ensuring generalisability over and access to multiple datasets\nis challenging to realise for real-world applications. To address these\nconcerns, this paper proposes a single image, self-supervised (SS) CS-MRI\nframework that enables a joint deep and sparse regularisation of CS artefacts.\nThe approach effectively dampens structured CS artefacts, which can be\ndifficult to remove assuming sparse reconstruction, or relying solely on the\ninductive biases of CNN to produce noise-free images. Image quality is thereby\nimproved compared to either approach alone. Metrics are evaluated using\nCartesian 1D masks on a brain and knee dataset, with PSNR improving by 2-4dB on\naverage.\n","authors":["Marlon Bran Lorenzana","Feng Liu","Shekhar S. Chandra"],"pdf_url":"https://arxiv.org/pdf/2311.13144v1.pdf","comment":"5 pages, 4 figures, 2 tables, conference"},{"id":"http://arxiv.org/abs/2311.12068v2","updated":"2023-11-22T04:13:38Z","published":"2023-11-19T17:28:28Z","title":"Enhancing Novel Object Detection via Cooperative Foundational Models","summary":"  In this work, we address the challenging and emergent problem of novel object\ndetection (NOD), focusing on the accurate detection of both known and novel\nobject categories during inference. Traditional object detection algorithms are\ninherently closed-set, limiting their capability to handle NOD. We present a\nnovel approach to transform existing closed-set detectors into open-set\ndetectors. This transformation is achieved by leveraging the complementary\nstrengths of pre-trained foundational models, specifically CLIP and SAM,\nthrough our cooperative mechanism. Furthermore, by integrating this mechanism\nwith state-of-the-art open-set detectors such as GDINO, we establish new\nbenchmarks in object detection performance. Our method achieves 17.42 mAP in\nnovel object detection and 42.08 mAP for known objects on the challenging LVIS\ndataset. Adapting our approach to the COCO OVD split, we surpass the current\nstate-of-the-art by a margin of 7.2 $ \\text{AP}_{50} $ for novel classes. Our\ncode is available at\nhttps://github.com/rohit901/cooperative-foundational-models .\n","authors":["Rohit Bharadwaj","Muzammal Naseer","Salman Khan","Fahad Shahbaz Khan"],"pdf_url":"https://arxiv.org/pdf/2311.12068v2.pdf","comment":"Code: https://github.com/rohit901/cooperative-foundational-models"},{"id":"http://arxiv.org/abs/2311.13141v1","updated":"2023-11-22T04:06:39Z","published":"2023-11-22T04:06:39Z","title":"Diffusion360: Seamless 360 Degree Panoramic Image Generation based on\n  Diffusion Models","summary":"  This is a technical report on the 360-degree panoramic image generation task\nbased on diffusion models. Unlike ordinary 2D images, 360-degree panoramic\nimages capture the entire $360^\\circ\\times 180^\\circ$ field of view. So the\nrightmost and the leftmost sides of the 360 panoramic image should be\ncontinued, which is the main challenge in this field. However, the current\ndiffusion pipeline is not appropriate for generating such a seamless 360-degree\npanoramic image. To this end, we propose a circular blending strategy on both\nthe denoising and VAE decoding stages to maintain the geometry continuity.\nBased on this, we present two models for \\textbf{Text-to-360-panoramas} and\n\\textbf{Single-Image-to-360-panoramas} tasks. The code has been released as an\nopen-source project at\n\\href{https://github.com/ArcherFMY/SD-T2I-360PanoImage}{https://github.com/ArcherFMY/SD-T2I-360PanoImage}\nand\n\\href{https://www.modelscope.cn/models/damo/cv_diffusion_text-to-360panorama-image_generation/summary}{ModelScope}\n","authors":["Mengyang Feng","Jinlin Liu","Miaomiao Cui","Xuansong Xie"],"pdf_url":"https://arxiv.org/pdf/2311.13141v1.pdf","comment":"2 pages, 8 figures, Tech. Report"},{"id":"http://arxiv.org/abs/2311.13134v1","updated":"2023-11-22T03:41:13Z","published":"2023-11-22T03:41:13Z","title":"Lightweight High-Speed Photography Built on Coded Exposure and Implicit\n  Neural Representation of Videos","summary":"  The compact cameras recording high-speed scenes with high resolution are\nhighly demanded, but the required high bandwidth often leads to bulky, heavy\nsystems, which limits their applications on low-capacity platforms. Adopting a\ncoded exposure setup to encode a frame sequence into a blurry snapshot and\nretrieve the latent sharp video afterward can serve as a lightweight solution.\nHowever, restoring motion from blur is quite challenging due to the high\nill-posedness of motion blur decomposition, intrinsic ambiguity in motion\ndirection, and diverse motions in natural videos. In this work, by leveraging\nclassical coded exposure imaging technique and emerging implicit neural\nrepresentation for videos, we tactfully embed the motion direction cues into\nthe blurry image during the imaging process and develop a novel self-recursive\nneural network to sequentially retrieve the latent video sequence from the\nblurry image utilizing the embedded motion direction cues. To validate the\neffectiveness and efficiency of the proposed framework, we conduct extensive\nexperiments on benchmark datasets and real-captured blurry images. The results\ndemonstrate that our proposed framework significantly outperforms existing\nmethods in quality and flexibility. The code for our work is available at\nhttps://github.com/zhihongz/BDINR\n","authors":["Zhihong Zhang","Runzhao Yang","Jinli Suo","Yuxiao Cheng","Qionghai Dai"],"pdf_url":"https://arxiv.org/pdf/2311.13134v1.pdf","comment":"19 pages, 10 figures"},{"id":"http://arxiv.org/abs/2309.08273v2","updated":"2023-11-22T03:36:22Z","published":"2023-09-15T09:34:05Z","title":"Unsupervised Disentangling of Facial Representations with 3D-aware\n  Latent Diffusion Models","summary":"  Unsupervised learning of facial representations has gained increasing\nattention for face understanding ability without heavily relying on large-scale\nannotated datasets. However, it remains unsolved due to the coupling of facial\nidentities, expressions, and external factors like pose and light. Prior\nmethods primarily focus on 2D factors and pixel-level consistency, leading to\nincomplete disentangling and suboptimal performance in downstream tasks. In\nthis paper, we propose LatentFace, a novel unsupervised disentangling framework\nfor facial expression and identity representation. We suggest the disentangling\nproblem should be performed in latent space and propose the solution using a\n3D-aware latent diffusion model. First, we introduce a 3D-aware autoencoder to\nencode face images into 3D latent embeddings. Second, we propose a novel\nrepresentation diffusion model (RDM) to disentangle 3D latent into facial\nidentity and expression. Consequently, our method achieves state-of-the-art\nperformance in facial expression recognition and face verification among\nunsupervised facial representation learning models. Codes are available at\n\\url{https://github.com/ryanhe312/LatentFace}.\n","authors":["Ruian He","Zhen Xing","Weimin Tan","Bo Yan"],"pdf_url":"https://arxiv.org/pdf/2309.08273v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13128v1","updated":"2023-11-22T03:33:00Z","published":"2023-11-22T03:33:00Z","title":"P2RBox: A Single Point is All You Need for Oriented Object Detection","summary":"  Oriented object detection, a specialized subfield in computer vision, finds\napplications across diverse scenarios, excelling particularly when dealing with\nobjects of arbitrary orientations. Conversely, point annotation, which treats\nobjects as single points, offers a cost-effective alternative to rotated and\nhorizontal bounding boxes but sacrifices performance due to the loss of size\nand orientation information. In this study, we introduce the P2RBox network,\nwhich leverages point annotations and a mask generator to create mask\nproposals, followed by filtration through our Inspector Module and Constrainer\nModule. This process selects high-quality masks, which are subsequently\nconverted into rotated box annotations for training a fully supervised\ndetector. Specifically, we've thoughtfully crafted an Inspector Module rooted\nin multi-instance learning principles to evaluate the semantic score of masks.\nWe've also proposed a more robust mask quality assessment in conjunction with\nthe Constrainer Module. Furthermore, we've introduced a Symmetry Axis\nEstimation (SAE) Module inspired by the spectral theorem for symmetric matrices\nto transform the top-performing mask proposal into rotated bounding boxes.\nP2RBox performs well with three fully supervised rotated object detectors:\nRetinaNet, Rotated FCOS, and Oriented R-CNN. By combining with Oriented R-CNN,\nP2RBox achieves 62.26% on DOTA-v1.0 test dataset. As far as we know, this is\nthe first attempt at training an oriented object detector with point\nsupervision.\n","authors":["Guangming Cao","Xuehui Yu","Wenwen Yu","Xumeng Han","Xue Yang","Guorong Li","Jianbin Jiao","Zhenjun Han"],"pdf_url":"https://arxiv.org/pdf/2311.13128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13127v1","updated":"2023-11-22T03:31:31Z","published":"2023-11-22T03:31:31Z","title":"Toward Robust Imperceptible Perturbation against Unauthorized\n  Text-to-image Diffusion-based Synthesis","summary":"  Text-to-image diffusion models allow seamless generation of personalized\nimages from scant reference photos. Yet, these tools, in the wrong hands, can\nfabricate misleading or harmful content, endangering individuals. To address\nthis problem, existing poisoning-based approaches perturb user images in an\nimperceptible way to render them \"unlearnable\" from malicious uses. We identify\ntwo limitations of these defending approaches: i) sub-optimal due to the\nhand-crafted heuristics for solving the intractable bilevel optimization and\nii) lack of robustness against simple data transformations like Gaussian\nfiltering. To solve these challenges, we propose MetaCloak, which solves the\nbi-level poisoning problem with a meta-learning framework with an additional\ntransformation sampling process to craft transferable and robust perturbation.\nSpecifically, we employ a pool of surrogate diffusion models to craft\ntransferable and model-agnostic perturbation. Furthermore, by incorporating an\nadditional transformation process, we design a simple denoising-error\nmaximization loss that is sufficient for causing transformation-robust semantic\ndistortion and degradation in a personalized generation. Extensive experiments\non the VGGFace2 and CelebA-HQ datasets show that MetaCloak outperforms existing\napproaches. Notably, MetaCloak can successfully fool online training services\nlike Replicate, in a black-box manner, demonstrating the effectiveness of\nMetaCloak in real-world scenarios. Our code is available at\nhttps://github.com/liuyixin-louis/MetaCloak.\n","authors":["Yixin Liu","Chenrui Fan","Yutong Dai","Xun Chen","Pan Zhou","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2311.13127v1.pdf","comment":"26 pages, 15 figures, 8 tables"},{"id":"http://arxiv.org/abs/2311.13125v1","updated":"2023-11-22T03:26:07Z","published":"2023-11-22T03:26:07Z","title":"DAE-Net: Deforming Auto-Encoder for fine-grained shape co-segmentation","summary":"  We present an unsupervised 3D shape co-segmentation method which learns a set\nof deformable part templates from a shape collection. To accommodate structural\nvariations in the collection, our network composes each shape by a selected\nsubset of template parts which are affine-transformed. To maximize the\nexpressive power of the part templates, we introduce a per-part deformation\nnetwork to enable the modeling of diverse parts with substantial geometry\nvariations, while imposing constraints on the deformation capacity to ensure\nfidelity to the originally represented parts. We also propose a training scheme\nto effectively overcome local minima. Architecturally, our network is a\nbranched autoencoder, with a CNN encoder taking a voxel shape as input and\nproducing per-part transformation matrices, latent codes, and part existence\nscores, and the decoder outputting point occupancies to define the\nreconstruction loss. Our network, coined DAE-Net for Deforming Auto-Encoder,\ncan achieve unsupervised 3D shape co-segmentation that yields fine-grained,\ncompact, and meaningful parts that are consistent across diverse shapes. We\nconduct extensive experiments on the ShapeNet Part dataset, DFAUST, and an\nanimal subset of Objaverse to show superior performance over prior methods.\n","authors":["Zhiqin Chen","Qimin Chen","Hang Zhou","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.13125v1.pdf","comment":"Code: https://github.com/czq142857/DAE-Net"},{"id":"http://arxiv.org/abs/2306.04889v2","updated":"2023-11-22T03:02:46Z","published":"2023-06-08T02:35:30Z","title":"ShaDDR: Interactive Example-Based Geometry and Texture Generation via 3D\n  Shape Detailization and Differentiable Rendering","summary":"  We present ShaDDR, an example-based deep generative neural network which\nproduces a high-resolution textured 3D shape through geometry detailization and\nconditional texture generation applied to an input coarse voxel shape. Trained\non a small set of detailed and textured exemplar shapes, our method learns to\ndetailize the geometry via multi-resolution voxel upsampling and generate\ntextures on voxel surfaces via differentiable rendering against exemplar\ntexture images from a few views. The generation is interactive, taking less\nthan 1 second to produce a 3D model with voxel resolutions up to 512^3. The\ngenerated shape preserves the overall structure of the input coarse voxel\nmodel, while the style of the generated geometric details and textures can be\nmanipulated through learned latent codes. In the experiments, we show that our\nmethod can generate higher-resolution shapes with plausible and improved\ngeometric details and clean textures compared to prior works. Furthermore, we\nshowcase the ability of our method to learn geometric details and textures from\nshapes reconstructed from real-world photos. In addition, we have developed an\ninteractive modeling application to demonstrate the generalizability of our\nmethod to various user inputs and the controllability it offers, allowing users\nto interactively sculpt a coarse voxel shape to define the overall structure of\nthe detailized 3D shape. Code and data are available at\nhttps://github.com/qiminchen/ShaDDR.\n","authors":["Qimin Chen","Zhiqin Chen","Hang Zhou","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.04889v2.pdf","comment":"Accepted to SIGGRAPH Asia 2023 conference track. Code:\n  https://github.com/qiminchen/ShaDDR"},{"id":"http://arxiv.org/abs/2311.13120v1","updated":"2023-11-22T02:46:57Z","published":"2023-11-22T02:46:57Z","title":"Multi-modal In-Context Learning Makes an Ego-evolving Scene Text\n  Recognizer","summary":"  Scene text recognition (STR) in the wild frequently encounters challenges\nwhen coping with domain variations, font diversity, shape deformations, etc. A\nstraightforward solution is performing model fine-tuning tailored to a specific\nscenario, but it is computationally intensive and requires multiple model\ncopies for various scenarios. Recent studies indicate that large language\nmodels (LLMs) can learn from a few demonstration examples in a training-free\nmanner, termed \"In-Context Learning\" (ICL). Nevertheless, applying LLMs as a\ntext recognizer is unacceptably resource-consuming. Moreover, our pilot\nexperiments on LLMs show that ICL fails in STR, mainly attributed to the\ninsufficient incorporation of contextual information from diverse samples in\nthe training stage. To this end, we introduce E$^2$STR, a STR model trained\nwith context-rich scene text sequences, where the sequences are generated via\nour proposed in-context training strategy. E$^2$STR demonstrates that a\nregular-sized model is sufficient to achieve effective ICL capabilities in STR.\nExtensive experiments show that E$^2$STR exhibits remarkable training-free\nadaptation in various scenarios and outperforms even the fine-tuned\nstate-of-the-art approaches on public benchmarks.\n","authors":["Zhen Zhao","Can Huang","Binghong Wu","Chunhui Lin","Hao Liu","Zhizhong Zhang","Xin Tan","Jingqun Tang","Yuan Xie"],"pdf_url":"https://arxiv.org/pdf/2311.13120v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.08326v2","updated":"2023-11-22T02:43:01Z","published":"2023-06-14T07:58:14Z","title":"Early Detection of Late Blight Tomato Disease using Histogram Oriented\n  Gradient based Support Vector Machine","summary":"  The tomato is one of the most important fruits on earth. It plays an\nimportant and useful role in the agricultural production of any country. This\nresearch propose a novel smart technique for early detection of late blight\ndiseases in tomatoes. This work improve the dataset with an increase in images\nfrom the field (the Plant Village dataset) and proposed a hybrid algorithm\ncomposed of support vector machines (SVM) and histogram-oriented gradients\n(HOG) for real-time detection of late blight tomato disease. To propose a\nHOG-based SVM model for early detection of late blight tomato leaf disease. To\ncheck the performance of the proposed model in terms of MSE, accuracy,\nprecision, and recall as compared to Decision Tree and KNN. The integration of\nadvanced technology in agriculture has the potential to revolutionize the\nindustry, making it more efficient, sustainable, and profitable. This research\nwork on the early detection of tomato diseases contributes to the growing\nimportance of smart farming, the need for climate-smart agriculture, the rising\nneed to more efficiently utilize natural resources, and the demand for higher\ncrop yields. The proposed hybrid algorithm of SVM and HOG has significant\npotential for the early detection of late blight disease in tomato plants. The\nperformance of the proposed model against decision tree and KNN algorithms and\nthe results may assist in selecting the best algorithm for future applications.\nThe research work can help farmers make data-driven decisions to optimize crop\nyield and quality while also reducing the environmental impact of farming\npractices.\n","authors":["M. Ishaq","M. Waqas"],"pdf_url":"https://arxiv.org/pdf/2306.08326v2.pdf","comment":"The article titled \"Early Detection of Late Blight Tomato Disease\n  using Histogram Oriented Gradient based Support Vector Machine\" need to be\n  withdrawn there are other contributors in the improvement of this article"},{"id":"http://arxiv.org/abs/2311.13110v1","updated":"2023-11-22T02:23:32Z","published":"2023-11-22T02:23:32Z","title":"White-Box Transformers via Sparse Rate Reduction: Compression Is All\n  There Is?","summary":"  In this paper, we contend that a natural objective of representation learning\nis to compress and transform the distribution of the data, say sets of tokens,\ntowards a low-dimensional Gaussian mixture supported on incoherent subspaces.\nThe goodness of such a representation can be evaluated by a principled measure,\ncalled sparse rate reduction, that simultaneously maximizes the intrinsic\ninformation gain and extrinsic sparsity of the learned representation. From\nthis perspective, popular deep network architectures, including transformers,\ncan be viewed as realizing iterative schemes to optimize this measure.\nParticularly, we derive a transformer block from alternating optimization on\nparts of this objective: the multi-head self-attention operator compresses the\nrepresentation by implementing an approximate gradient descent step on the\ncoding rate of the features, and the subsequent multi-layer perceptron\nsparsifies the features. This leads to a family of white-box transformer-like\ndeep network architectures, named CRATE, which are mathematically fully\ninterpretable. We show, by way of a novel connection between denoising and\ncompression, that the inverse to the aforementioned compressive encoding can be\nrealized by the same class of CRATE architectures. Thus, the so-derived\nwhite-box architectures are universal to both encoders and decoders.\nExperiments show that these networks, despite their simplicity, indeed learn to\ncompress and sparsify representations of large-scale real-world image and text\ndatasets, and achieve performance very close to highly engineered\ntransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the\nproposed computational framework demonstrates great potential in bridging the\ngap between theory and practice of deep learning, from a unified perspective of\ndata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .\n","authors":["Yaodong Yu","Sam Buchanan","Druv Pai","Tianzhe Chu","Ziyang Wu","Shengbang Tong","Hao Bai","Yuexiang Zhai","Benjamin D. Haeffele","Yi Ma"],"pdf_url":"https://arxiv.org/pdf/2311.13110v1.pdf","comment":"This paper integrates the works arXiv:2306.01129 and\n  arXiv:2308.16271, as well as this under-review work:\n  https://openreview.net/forum?id=PvyOYleymy into a complete story. In this\n  paper, we improve the writing and organization, and also add conceptual,\n  empirical, and theoretical improvements over the previous work"},{"id":"http://arxiv.org/abs/2309.00168v2","updated":"2023-11-22T02:16:48Z","published":"2023-08-31T23:17:44Z","title":"Pose-Graph Attentional Graph Neural Network for Lidar Place Recognition","summary":"  This paper proposes a pose-graph attentional graph neural network, called\nP-GAT, which compares (key)nodes between sequential and non-sequential\nsub-graphs for place recognition tasks as opposed to a common frame-to-frame\nretrieval problem formulation currently implemented in SOTA place recognition\nmethods. P-GAT uses the maximum spatial and temporal information between\nneighbour cloud descriptors -- generated by an existing encoder -- utilising\nthe concept of pose-graph SLAM. Leveraging intra- and inter-attention and graph\nneural network, P-GAT relates point clouds captured in nearby locations in\nEuclidean space and their embeddings in feature space. Experimental results on\nthe large-scale publically available datasets demonstrate the effectiveness of\nour approach in scenes lacking distinct features and when training and testing\nenvironments have different distributions (domain adaptation). Further, an\nexhaustive comparison with the state-of-the-art shows improvements in\nperformance gains. Code is available at\nhttps://github.com/csiro-robotics/P-GAT.\n","authors":["Milad Ramezani","Liang Wang","Joshua Knights","Zhibin Li","Pauline Pounds","Peyman Moghadam"],"pdf_url":"https://arxiv.org/pdf/2309.00168v2.pdf","comment":"10 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2311.13100v1","updated":"2023-11-22T01:59:19Z","published":"2023-11-22T01:59:19Z","title":"Automated Measurement of Pericoronary Adipose Tissue Attenuation and\n  Volume in CT Angiography","summary":"  Pericoronary adipose tissue (PCAT) is the deposition of fat in the vicinity\nof the coronary arteries. It is an indicator of coronary inflammation and\nassociated with coronary artery disease. Non-invasive coronary CT angiography\n(CCTA) is presently used to obtain measures of the thickness, volume, and\nattenuation of fat deposition. However, prior works solely focus on measuring\nPCAT using semi-automated approaches at the right coronary artery (RCA) over\nthe left coronary artery (LCA). In this pilot work, we developed a fully\nautomated approach for the measurement of PCAT mean attenuation and volume in\nthe region around both coronary arteries. First, we used a large subset of\npatients from the public ImageCAS dataset (n = 735) to train a 3D full\nresolution nnUNet to segment LCA and RCA. Then, we automatically measured PCAT\nin the surrounding arterial regions. We evaluated our method on a held-out test\nset of patients (n = 183) from the same dataset. A mean Dice score of 83% and\nPCAT attenuation of -73.81 $\\pm$ 12.69 HU was calculated for the RCA, while a\nmean Dice score of 81% and PCAT attenuation of -77.51 $\\pm$ 7.94 HU was\ncomputed for the LCA. To the best of our knowledge, we are the first to develop\na fully automated method to measure PCAT attenuation and volume at both the RCA\nand LCA. Our work underscores how automated PCAT measurement holds promise as a\nbiomarker for identification of inflammation and cardiac disease.\n","authors":["Andrew M. Nguyen","Tejas Sudharshan Mathai","Liangchen Liu","Jianfei Liu","Ronald M. Summers"],"pdf_url":"https://arxiv.org/pdf/2311.13100v1.pdf","comment":"5 pages, 4 figures, IEE ISBI2024 conference"},{"id":"http://arxiv.org/abs/2311.13099v1","updated":"2023-11-22T01:58:26Z","published":"2023-11-22T01:58:26Z","title":"PIE-NeRF: Physics-based Interactive Elastodynamics with NeRF","summary":"  We show that physics-based simulations can be seamlessly integrated with NeRF\nto generate high-quality elastodynamics of real-world objects. Unlike existing\nmethods, we discretize nonlinear hyperelasticity in a meshless way, obviating\nthe necessity for intermediate auxiliary shape proxies like a tetrahedral mesh\nor voxel grid. A quadratic generalized moving least square (Q-GMLS) is employed\nto capture nonlinear dynamics and large deformation on the implicit model. Such\nmeshless integration enables versatile simulations of complex and codimensional\nshapes. We adaptively place the least-square kernels according to the NeRF\ndensity field to significantly reduce the complexity of the nonlinear\nsimulation. As a result, physically realistic animations can be conveniently\nsynthesized using our method for a wide range of hyperelastic materials at an\ninteractive rate. For more information, please visit our project page at\nhttps://fytalon.github.io/pienerf/.\n","authors":["Yutao Feng","Yintong Shang","Xuan Li","Tianjia Shao","Chenfanfu Jiang","Yin Yang"],"pdf_url":"https://arxiv.org/pdf/2311.13099v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13091v1","updated":"2023-11-22T01:43:57Z","published":"2023-11-22T01:43:57Z","title":"Stable Unlearnable Example: Enhancing the Robustness of Unlearnable\n  Examples via Stable Error-Minimizing Noise","summary":"  The open source of large amounts of image data promotes the development of\ndeep learning techniques. Along with this comes the privacy risk of these\nopen-source image datasets being exploited by unauthorized third parties to\ntrain deep learning models for commercial or illegal purposes. To avoid the\nabuse of public data, a poisoning-based technique, the unlearnable example, is\nproposed to significantly degrade the generalization performance of models by\nadding a kind of imperceptible noise to the data. To further enhance its\nrobustness against adversarial training, existing works leverage iterative\nadversarial training on both the defensive noise and the surrogate model.\nHowever, it still remains unknown whether the robustness of unlearnable\nexamples primarily comes from the effect of enhancement in the surrogate model\nor the defensive noise. Observing that simply removing the adversarial noise on\nthe training process of the defensive noise can improve the performance of\nrobust unlearnable examples, we identify that solely the surrogate model's\nrobustness contributes to the performance. Furthermore, we found a negative\ncorrelation exists between the robustness of defensive noise and the protection\nperformance, indicating defensive noise's instability issue. Motivated by this,\nto further boost the robust unlearnable example, we introduce stable\nerror-minimizing noise (SEM), which trains the defensive noise against random\nperturbation instead of the time-consuming adversarial perturbation to improve\nthe stability of defensive noise. Through extensive experiments, we demonstrate\nthat SEM achieves a new state-of-the-art performance on CIFAR-10, CIFAR-100,\nand ImageNet Subset in terms of both effectiveness and efficiency. The code is\navailable at https://github.com/liuyixin-louis/Stable-Unlearnable-Example.\n","authors":["Yixin Liu","Kaidi Xu","Xun Chen","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2311.13091v1.pdf","comment":"14 pages, 11 figures, 13 tables"},{"id":"http://arxiv.org/abs/2311.13090v1","updated":"2023-11-22T01:42:23Z","published":"2023-11-22T01:42:23Z","title":"On the Limitation of Diffusion Models for Synthesizing Training Datasets","summary":"  Synthetic samples from diffusion models are promising for leveraging in\ntraining discriminative models as replications of real training datasets.\nHowever, we found that the synthetic datasets degrade classification\nperformance over real datasets even when using state-of-the-art diffusion\nmodels. This means that modern diffusion models do not perfectly represent the\ndata distribution for the purpose of replicating datasets for training\ndiscriminative tasks. This paper investigates the gap between synthetic and\nreal samples by analyzing the synthetic samples reconstructed from real samples\nthrough the diffusion and reverse process. By varying the time steps starting\nthe reverse process in the reconstruction, we can control the trade-off between\nthe information in the original real data and the information added by\ndiffusion models. Through assessing the reconstructed samples and trained\nmodels, we found that the synthetic data are concentrated in modes of the\ntraining data distribution as the reverse step increases, and thus, they are\ndifficult to cover the outer edges of the distribution. Our findings imply that\nmodern diffusion models are insufficient to replicate training data\ndistribution perfectly, and there is room for the improvement of generative\nmodeling in the replication of training datasets.\n","authors":["Shin'ya Yamaguchi","Takuma Fukuda"],"pdf_url":"https://arxiv.org/pdf/2311.13090v1.pdf","comment":"NeurIPS 2023 SyntheticData4ML Workshop"},{"id":"http://arxiv.org/abs/2309.04153v2","updated":"2023-11-22T01:36:14Z","published":"2023-09-08T06:37:25Z","title":"Mapping EEG Signals to Visual Stimuli: A Deep Learning Approach to Match\n  vs. Mismatch Classification","summary":"  Existing approaches to modeling associations between visual stimuli and brain\nresponses are facing difficulties in handling between-subject variance and\nmodel generalization. Inspired by the recent progress in modeling speech-brain\nresponse, we propose in this work a \"match-vs-mismatch\" deep learning model to\nclassify whether a video clip induces excitatory responses in recorded EEG\nsignals and learn associations between the visual content and corresponding\nneural recordings. Using an exclusive experimental dataset, we demonstrate that\nthe proposed model is able to achieve the highest accuracy on unseen subjects\nas compared to other baseline models. Furthermore, we analyze the inter-subject\nnoise using a subject-level silhouette score in the embedding space and show\nthat the developed model is able to mitigate inter-subject noise and\nsignificantly reduce the silhouette score. Moreover, we examine the Grad-CAM\nactivation score and show that the brain regions associated with language\nprocessing contribute most to the model predictions, followed by regions\nassociated with visual processing. These results have the potential to\nfacilitate the development of neural recording-based video reconstruction and\nits related applications.\n","authors":["Yiqian Yang","Zhengqiao Zhao","Qian Wang","Yan Yang","Jingdong Chen"],"pdf_url":"https://arxiv.org/pdf/2309.04153v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13073v1","updated":"2023-11-22T00:26:15Z","published":"2023-11-22T00:26:15Z","title":"FusionFrames: Efficient Architectural Aspects for Text-to-Video\n  Generation Pipeline","summary":"  Multimedia generation approaches occupy a prominent place in artificial\nintelligence research. Text-to-image models achieved high-quality results over\nthe last few years. However, video synthesis methods recently started to\ndevelop. This paper presents a new two-stage latent diffusion text-to-video\ngeneration architecture based on the text-to-image diffusion model. The first\nstage concerns keyframes synthesis to figure the storyline of a video, while\nthe second one is devoted to interpolation frames generation to make movements\nof the scene and objects smooth. We compare several temporal conditioning\napproaches for keyframes generation. The results show the advantage of using\nseparate temporal blocks over temporal layers in terms of metrics reflecting\nvideo generation quality aspects and human preference. The design of our\ninterpolation model significantly reduces computational costs compared to other\nmasked frame interpolation approaches. Furthermore, we evaluate different\nconfigurations of MoVQ-based video decoding scheme to improve consistency and\nachieve higher PSNR, SSIM, MSE, and LPIPS scores. Finally, we compare our\npipeline with existing solutions and achieve top-2 scores overall and top-1\namong open-source solutions: CLIPSIM = 0.2976 and FVD = 433.054. Project page:\nhttps://ai-forever.github.io/kandinsky-video/\n","authors":["Vladimir Arkhipkin","Zein Shaheen","Viacheslav Vasilev","Elizaveta Dakhova","Andrey Kuznetsov","Denis Dimitrov"],"pdf_url":"https://arxiv.org/pdf/2311.13073v1.pdf","comment":"Project page: https://ai-forever.github.io/kandinsky-video/"},{"id":"http://arxiv.org/abs/2311.13069v1","updated":"2023-11-22T00:03:16Z","published":"2023-11-22T00:03:16Z","title":"FuseNet: Self-Supervised Dual-Path Network for Medical Image\n  Segmentation","summary":"  Semantic segmentation, a crucial task in computer vision, often relies on\nlabor-intensive and costly annotated datasets for training. In response to this\nchallenge, we introduce FuseNet, a dual-stream framework for self-supervised\nsemantic segmentation that eliminates the need for manual annotation. FuseNet\nleverages the shared semantic dependencies between the original and augmented\nimages to create a clustering space, effectively assigning pixels to\nsemantically related clusters, and ultimately generating the segmentation map.\nAdditionally, FuseNet incorporates a cross-modal fusion technique that extends\nthe principles of CLIP by replacing textual data with augmented images. This\napproach enables the model to learn complex visual representations, enhancing\nrobustness against variations similar to CLIP's text invariance. To further\nimprove edge alignment and spatial consistency between neighboring pixels, we\nintroduce an edge refinement loss. This loss function considers edge\ninformation to enhance spatial coherence, facilitating the grouping of nearby\npixels with similar visual features. Extensive experiments on skin lesion and\nlung segmentation datasets demonstrate the effectiveness of our method.\n\\href{https://github.com/xmindflow/FuseNet}{Codebase.}\n","authors":["Amirhossein Kazerouni","Sanaz Karimijafarbigloo","Reza Azad","Yury Velichko","Ulas Bagci","Dorit Merhof"],"pdf_url":"https://arxiv.org/pdf/2311.13069v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07075v2","updated":"2023-11-22T23:49:58Z","published":"2023-11-13T04:48:33Z","title":"GazeForensics: DeepFake Detection via Gaze-guided Spatial Inconsistency\n  Learning","summary":"  DeepFake detection is pivotal in personal privacy and public safety. With the\niterative advancement of DeepFake techniques, high-quality forged videos and\nimages are becoming increasingly deceptive. Prior research has seen numerous\nattempts by scholars to incorporate biometric features into the field of\nDeepFake detection. However, traditional biometric-based approaches tend to\nsegregate biometric features from general ones and freeze the biometric feature\nextractor. These approaches resulted in the exclusion of valuable general\nfeatures, potentially leading to a performance decline and, consequently, a\nfailure to fully exploit the potential of biometric information in assisting\nDeepFake detection. Moreover, insufficient attention has been dedicated to\nscrutinizing gaze authenticity within the realm of DeepFake detection in recent\nyears. In this paper, we introduce GazeForensics, an innovative DeepFake\ndetection method that utilizes gaze representation obtained from a 3D gaze\nestimation model to regularize the corresponding representation within our\nDeepFake detection model, while concurrently integrating general features to\nfurther enhance the performance of our model. Experiment results reveal that\nour proposed GazeForensics outperforms the current state-of-the-art methods.\n","authors":["Qinlin He","Chunlei Peng","Decheng Liu","Nannan Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2311.07075v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13719v1","updated":"2023-11-22T22:23:47Z","published":"2023-11-22T22:23:47Z","title":"Deep learning-based instance segmentation for the precise automated\n  quantification of digital breast cancer immunohistochemistry images","summary":"  The quantification of biomarkers on immunohistochemistry breast cancer images\nis essential for defining appropriate therapy for breast cancer patients, as\nwell as for extracting relevant information on disease prognosis. This is an\narduous and time-consuming task that may introduce a bias in the results due to\nintra- and inter-observer variability which could be alleviated by making use\nof automatic quantification tools. However, this is not a simple processing\ntask given the heterogeneity of breast tumors that results in non-uniformly\ndistributed tumor cells exhibiting different staining colors and intensity,\nsize, shape, and texture, of the nucleus, cytoplasm and membrane. In this\nresearch work, we demonstrate the feasibility of using a deep learning-based\ninstance segmentation architecture for the automatic quantification of both\nnuclear and membrane biomarkers applied to IHC-stained slides. We have solved\nthe cumbersome task of training set generation with the design and\nimplementation of a web platform, which has served as a hub for communication\nand feedback between researchers and pathologists as well as a system for the\nvalidation of the automatic image processing models. Through this tool, we have\ncollected annotations over samples of HE, ER and Ki-67 (nuclear biomarkers) and\nHER2 (membrane biomarker) IHC-stained images. Using the same deep learning\nnetwork architecture, we have trained two models, so-called nuclei- and\nmembrane-aware segmentation models, which, once successfully validated, have\nrevealed to be a promising method to segment nuclei instances in IHC-stained\nimages. The quantification method proposed in this work has been integrated\ninto the developed web platform and is currently being used as a\ndecision-support tool by pathologists.\n","authors":["Blanca Maria Priego-Torresa","Barbara Lobato-Delgado","Lidia Atienza-Cuevas","Daniel Sanchez-Morillo"],"pdf_url":"https://arxiv.org/pdf/2311.13719v1.pdf","comment":"19 pages, 12 figures, 7 tables"},{"id":"http://arxiv.org/abs/2311.13717v1","updated":"2023-11-22T22:21:26Z","published":"2023-11-22T22:21:26Z","title":"Importance of Feature Extraction in the Calculation of Fréchet\n  Distance for Medical Imaging","summary":"  Fr\\'echet Inception Distance is a widely used metric for evaluating synthetic\nimage quality that utilizes an ImageNet-trained InceptionV3 network as a\nfeature extractor. However, its application in medical imaging lacks a standard\nfeature extractor, leading to biased and inconsistent comparisons. This study\naimed to compare state-of-the-art feature extractors for computing Fr\\'echet\nDistances (FDs) in medical imaging. A StyleGAN2 network was trained with data\naugmentation techniques tailored for limited data domains on datasets\ncomprising three medical imaging modalities and four anatomical locations.\nHuman evaluation of generative quality (via a visual Turing test) was compared\nto FDs calculated using ImageNet-trained InceptionV3, ResNet50, SwAV, DINO, and\nSwin Transformer architectures, in addition to an InceptionV3 network trained\non a large medical dataset, RadImageNet. All ImageNet-based extractors were\nconsistent with each other, but only SwAV was significantly correlated with\nmedical expert judgment. The RadImageNet-based FD showed volatility and lacked\ncorrelation with human judgment. Caution is advised when using medical\nimage-trained extraction networks in the FD calculation. These networks should\nbe rigorously evaluated on the imaging modality under consideration and\npublicly released. ImageNet-based extractors, while imperfect, are consistent\nand widely understood. Training extraction networks with SwAV is a promising\napproach for synthetic medical image evaluation.\n","authors":["McKell Woodland","Mais Al Taie","Jessica Albuquerque Marques Silva","Mohamed Eltaher","Frank Mohn","Alexander Shieh","Austin Castelo","Suprateek Kundu","Joshua P. Yung","Ankit B. Patel","Kristy K. Brock"],"pdf_url":"https://arxiv.org/pdf/2311.13717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13716v1","updated":"2023-11-22T22:20:10Z","published":"2023-11-22T22:20:10Z","title":"DiverseNet: Decision Diversified Semi-supervised Semantic Segmentation\n  Networks for Remote Sensing Imagery","summary":"  Semi-supervised learning is designed to help reduce the cost of the manual\nlabelling process by exploiting the use of useful features from a large\nquantity of unlabelled data during training. Since pixel-level manual labelling\nin large-scale remote sensing imagery is expensive, semi-supervised learning\nbecomes an appropriate solution to this. However, most of the existing\nsemi-supervised learning methods still lack efficient perturbation methods to\npromote diversity of features and the precision of pseudo labels during\ntraining. In order to fill this gap, we propose DiverseNet architectures which\nexplore multi-head and multi-model semi-supervised learning algorithms by\nsimultaneously promoting precision and diversity during training. The two\nproposed methods of DiverseNet, namely the DiverseHead and DiverseModel,\nachieve the highest semantic segmentation performance in four widely utilised\nremote sensing imagery data sets compared to state-of-the-art semi-supervised\nlearning methods. Meanwhile, the proposed DiverseHead architecture is\nrelatively lightweight in terms of parameter space compared to the\nstate-of-the-art methods whilst reaching high-performance results for all the\ntested data sets.\n","authors":["Wanli Ma","Oktay Karakus","Paul L. Rosin"],"pdf_url":"https://arxiv.org/pdf/2311.13716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13713v1","updated":"2023-11-22T22:18:42Z","published":"2023-11-22T22:18:42Z","title":"A Somewhat Robust Image Watermark against Diffusion-based Editing Models","summary":"  Recently, diffusion models (DMs) have become the state-of-the-art method for\nimage synthesis. Editing models based on DMs, known for their high fidelity and\nprecision, have inadvertently introduced new challenges related to image\ncopyright infringement and malicious editing. Our work is the first to\nformalize and address this issue. After assessing and attempting to enhance\ntraditional image watermarking techniques, we recognize their limitations in\nthis emerging context. In response, we develop a novel technique, RIW (Robust\nInvisible Watermarking), to embed invisible watermarks leveraging adversarial\nexample techniques. Our technique ensures a high extraction accuracy of $96\\%$\nfor the invisible watermark after editing, compared to the $0\\%$ offered by\nconventional methods. We provide access to our code at\nhttps://github.com/BennyTMT/RIW.\n","authors":["Mingtian Tan","Tianhao Wang","Somesh Jha"],"pdf_url":"https://arxiv.org/pdf/2311.13713v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13710v1","updated":"2023-11-22T22:10:53Z","published":"2023-11-22T22:10:53Z","title":"A Comprehensive Review of Artificial Intelligence Applications in Major\n  Retinal Conditions","summary":"  This paper provides a systematic survey of retinal diseases that cause visual\nimpairments or blindness, emphasizing the importance of early detection for\neffective treatment. It covers both clinical and automated approaches for\ndetecting retinal disease, focusing on studies from the past decade. The survey\nevaluates various algorithms for identifying structural abnormalities and\ndiagnosing retinal diseases, and it identifies future research directions based\non a critical analysis of existing literature. This comprehensive study, which\nreviews both clinical and automated detection methods using different\nmodalities, appears to be unique in its scope. Additionally, the survey serves\nas a helpful guide for researchers interested in digital retinopathy.\n","authors":["Hina Raja","Taimur Hassan","Bilal Hassan","Muhammad Usman Akram","Hira Raja","Alaa A Abd-alrazaq","Siamak Yousefi","Naoufel Werghi"],"pdf_url":"https://arxiv.org/pdf/2311.13710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13706v1","updated":"2023-11-22T21:51:29Z","published":"2023-11-22T21:51:29Z","title":"Multi-view Hybrid Graph Convolutional Network for Volume-to-mesh\n  Reconstruction in Cardiovascular MRI","summary":"  Cardiovascular magnetic resonance imaging is emerging as a crucial tool to\nexamine cardiac morphology and function. Essential to this endeavour are\nanatomical 3D surface and volumetric meshes derived from CMR images, which\nfacilitate computational anatomy studies, biomarker discovery, and in-silico\nsimulations. However, conventional surface mesh generation methods, such as\nactive shape models and multi-atlas segmentation, are highly time-consuming and\nrequire complex processing pipelines to generate simulation-ready 3D meshes. In\nresponse, we introduce HybridVNet, a novel architecture for direct\nimage-to-mesh extraction seamlessly integrating standard convolutional neural\nnetworks with graph convolutions, which we prove can efficiently handle surface\nand volumetric meshes by encoding them as graph structures. To further enhance\naccuracy, we propose a multiview HybridVNet architecture which processes both\nlong axis and short axis CMR, showing that it can increase the performance of\ncardiac MR mesh generation. Our model combines traditional convolutional\nnetworks with variational graph generative models, deep supervision and\nmesh-specific regularisation. Experiments on a comprehensive dataset from the\nUK Biobank confirm the potential of HybridVNet to significantly advance cardiac\nimaging and computational cardiology by efficiently generating high-fidelity\nand simulation ready meshes from CMR images.\n","authors":["Nicolás Gaggion","Benjamin A. Matheson","Yan Xia","Rodrigo Bonazzola","Nishant Ravikumar","Zeike A. Taylor","Diego H. Milone","Alejandro F. Frangi","Enzo Ferrante"],"pdf_url":"https://arxiv.org/pdf/2311.13706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13688v1","updated":"2023-11-22T20:50:56Z","published":"2023-11-22T20:50:56Z","title":"Masked Conditional Diffusion Models for Image Analysis with Application\n  to Radiographic Diagnosis of Infant Abuse","summary":"  The classic metaphyseal lesion (CML) is a distinct injury that is highly\nspecific for infant abuse. It commonly occurs in the distal tibia. To aid\nradiologists detect these subtle fractures, we need to develop a model that can\nflag abnormal distal tibial radiographs (i.e. those with CMLs). Unfortunately,\nthe development of such a model requires a large and diverse training database,\nwhich is often not available. To address this limitation, we propose a novel\ngenerative model for data augmentation. Unlike previous models that fail to\ngenerate data that span the diverse radiographic appearance of the distal\ntibial CML, our proposed masked conditional diffusion model (MaC-DM) not only\ngenerates realistic-appearing and wide-ranging synthetic images of the distal\ntibial radiographs with and without CMLs, it also generates their associated\nsegmentation labels. To achieve these tasks, MaC-DM combines the weighted\nsegmentation masks of the tibias and the CML fracture sites as additional\nconditions for classifier guidance. The augmented images from our model\nimproved the performances of ResNet-34 in classifying normal radiographs and\nthose with CMLs. Further, the augmented images and their associated\nsegmentation masks enhanced the performance of the U-Net in labeling areas of\nthe CMLs on distal tibial radiographs.\n","authors":["Shaoju Wu","Sila Kurugol","Andy Tsai"],"pdf_url":"https://arxiv.org/pdf/2311.13688v1.pdf","comment":"Accepted by MICCAI DALI 2023"},{"id":"http://arxiv.org/abs/2311.13682v1","updated":"2023-11-22T20:31:33Z","published":"2023-11-22T20:31:33Z","title":"Single-Shot Plug-and-Play Methods for Inverse Problems","summary":"  The utilisation of Plug-and-Play (PnP) priors in inverse problems has become\nincreasingly prominent in recent years. This preference is based on the\nmathematical equivalence between the general proximal operator and the\nregularised denoiser, facilitating the adaptation of various off-the-shelf\ndenoiser priors to a wide range of inverse problems. However, existing PnP\nmodels predominantly rely on pre-trained denoisers using large datasets. In\nthis work, we introduce Single-Shot PnP methods (SS-PnP), shifting the focus to\nsolving inverse problems with minimal data. First, we integrate Single-Shot\nproximal denoisers into iterative methods, enabling training with single\ninstances. Second, we propose implicit neural priors based on a novel function\nthat preserves relevant frequencies to capture fine details while avoiding the\nissue of vanishing gradients. We demonstrate, through extensive numerical and\nvisual experiments, that our method leads to better approximations.\n","authors":["Yanqi Cheng","Lipei Zhang","Zhenda Shen","Shujun Wang","Lequan Yu","Raymond H. Chan","Carola-Bibiane Schönlieb","Angelica I Aviles-Rivero"],"pdf_url":"https://arxiv.org/pdf/2311.13682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13681v1","updated":"2023-11-22T20:31:16Z","published":"2023-11-22T20:31:16Z","title":"Compact 3D Gaussian Representation for Radiance Field","summary":"  Neural Radiance Fields (NeRFs) have demonstrated remarkable potential in\ncapturing complex 3D scenes with high fidelity. However, one persistent\nchallenge that hinders the widespread adoption of NeRFs is the computational\nbottleneck due to the volumetric rendering. On the other hand, 3D Gaussian\nsplatting (3DGS) has recently emerged as an alternative representation that\nleverages a 3D Gaussisan-based representation and adopts the rasterization\npipeline to render the images rather than volumetric rendering, achieving very\nfast rendering speed and promising image quality. However, a significant\ndrawback arises as 3DGS entails a substantial number of 3D Gaussians to\nmaintain the high fidelity of the rendered images, which requires a large\namount of memory and storage. To address this critical issue, we place a\nspecific emphasis on two key objectives: reducing the number of Gaussian points\nwithout sacrificing performance and compressing the Gaussian attributes, such\nas view-dependent color and covariance. To this end, we propose a learnable\nmask strategy that significantly reduces the number of Gaussians while\npreserving high performance. In addition, we propose a compact but effective\nrepresentation of view-dependent color by employing a grid-based neural field\nrather than relying on spherical harmonics. Finally, we learn codebooks to\ncompactly represent the geometric attributes of Gaussian by vector\nquantization. In our extensive experiments, we consistently show over\n10$\\times$ reduced storage and enhanced rendering speed, while maintaining the\nquality of the scene representation, compared to 3DGS. Our work provides a\ncomprehensive framework for 3D scene representation, achieving high\nperformance, fast training, compactness, and real-time rendering. Our project\npage is available at https://maincold2.github.io/c3dgs/.\n","authors":["Joo Chan Lee","Daniel Rho","Xiangyu Sun","Jong Hwan Ko","Eunbyung Park"],"pdf_url":"https://arxiv.org/pdf/2311.13681v1.pdf","comment":"Project page: http://maincold2.github.io/c3dgs/"},{"id":"http://arxiv.org/abs/2306.10988v2","updated":"2023-11-22T19:57:00Z","published":"2023-06-19T14:55:26Z","title":"Tame a Wild Camera: In-the-Wild Monocular Camera Calibration","summary":"  3D sensing for monocular in-the-wild images, e.g., depth estimation and 3D\nobject detection, has become increasingly important. However, the unknown\nintrinsic parameter hinders their development and deployment. Previous methods\nfor the monocular camera calibration rely on specific 3D objects or strong\ngeometry prior, such as using a checkerboard or imposing a Manhattan World\nassumption. This work solves the problem from the other perspective by\nexploiting the monocular 3D prior. Our method is assumption-free and calibrates\nthe complete $4$ Degree-of-Freedom (DoF) intrinsic parameters. First, we\ndemonstrate intrinsic is solved from two well-studied monocular priors, i.e.,\nmonocular depthmap, and surface normal map. However, this solution imposes a\nlow-bias and low-variance requirement for depth estimation. Alternatively, we\nintroduce a novel monocular 3D prior, the incidence field, defined as the\nincidence rays between points in 3D space and pixels in the 2D imaging plane.\nThe incidence field is a pixel-wise parametrization of the intrinsic invariant\nto image cropping and resizing. With the estimated incidence field, a robust\nRANSAC algorithm recovers intrinsic. We demonstrate the effectiveness of our\nmethod by showing superior performance on synthetic and zero-shot testing\ndatasets. Beyond calibration, we demonstrate downstream applications in image\nmanipulation detection & restoration, uncalibrated two-view pose estimation,\nand 3D sensing. Codes, models, and data will be held in\nhttps://github.com/ShngJZ/WildCamera.\n","authors":["Shengjie Zhu","Abhinav Kumar","Masa Hu","Xiaoming Liu"],"pdf_url":"https://arxiv.org/pdf/2306.10988v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13668v1","updated":"2023-11-22T19:45:40Z","published":"2023-11-22T19:45:40Z","title":"MAIRA-1: A specialised large multimodal model for radiology report\n  generation","summary":"  We present a radiology-specific multimodal model for the task for generating\nradiological reports from chest X-rays (CXRs). Our work builds on the idea that\nlarge language model(s) can be equipped with multimodal capabilities through\nalignment with pre-trained vision encoders. On natural images, this has been\nshown to allow multimodal models to gain image understanding and description\ncapabilities. Our proposed model (MAIRA-1) leverages a CXR-specific image\nencoder in conjunction with a fine-tuned large language model based on\nVicuna-7B, and text-based data augmentation, to produce reports with\nstate-of-the-art quality. In particular, MAIRA-1 significantly improves on the\nradiologist-aligned RadCliQ metric and across all lexical metrics considered.\nManual review of model outputs demonstrates promising fluency and accuracy of\ngenerated reports while uncovering failure modes not captured by existing\nevaluation practices. More information and resources can be found on the\nproject website: https://aka.ms/maira.\n","authors":["Stephanie L. Hyland","Shruthi Bannur","Kenza Bouzid","Daniel C. Castro","Mercy Ranjit","Anton Schwaighofer","Fernando Pérez-García","Valentina Salvatelli","Shaury Srivastav","Anja Thieme","Noel Codella","Matthew P. Lungren","Maria Teodora Wetscherek","Ozan Oktay","Javier Alvarez-Valle"],"pdf_url":"https://arxiv.org/pdf/2311.13668v1.pdf","comment":"18 pages, 9 tables, 5 figures"},{"id":"http://arxiv.org/abs/2311.13664v1","updated":"2023-11-22T19:36:47Z","published":"2023-11-22T19:36:47Z","title":"Sample as You Infer: Predictive Coding With Langevin Dynamics","summary":"  We present a novel algorithm for parameter learning in generic deep\ngenerative models that builds upon the predictive coding (PC) framework of\ncomputational neuroscience. Our approach modifies the standard PC algorithm to\nbring performance on-par and exceeding that obtained from standard variational\nauto-encoder (VAE) training. By injecting Gaussian noise into the PC inference\nprocedure we re-envision it as an overdamped Langevin sampling, which\nfacilitates optimisation with respect to a tight evidence lower bound (ELBO).\nWe improve the resultant encoder-free training method by incorporating an\nencoder network to provide an amortised warm-start to our Langevin sampling and\ntest three different objectives for doing so. Finally, to increase robustness\nto the sampling step size and reduce sensitivity to curvature, we validate a\nlightweight and easily computable form of preconditioning, inspired by Riemann\nManifold Langevin and adaptive optimizers from the SGD literature. We compare\nagainst VAEs by training like-for-like generative models using our technique\nagainst those trained with standard reparameterisation-trick-based ELBOs. We\nobserve our method out-performs or matches performance across a number of\nmetrics, including sample quality, while converging in a fraction of the number\nof SGD training iterations.\n","authors":["Umais Zahid","Qinghai Guo","Zafeirios Fountas"],"pdf_url":"https://arxiv.org/pdf/2311.13664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03561v2","updated":"2023-11-22T19:26:30Z","published":"2023-11-06T22:01:27Z","title":"Sea You Later: Metadata-Guided Long-Term Re-Identification for UAV-Based\n  Multi-Object Tracking","summary":"  Re-identification (ReID) in multi-object tracking (MOT) for UAVs in maritime\ncomputer vision has been challenging for several reasons. More specifically,\nshort-term re-identification (ReID) is difficult due to the nature of the\ncharacteristics of small targets and the sudden movement of the drone's gimbal.\nLong-term ReID suffers from the lack of useful appearance diversity. In\nresponse to these challenges, we present an adaptable motion-based MOT\nalgorithm, called Metadata Guided MOT (MG-MOT). This algorithm effectively\nmerges short-term tracking data into coherent long-term tracks, harnessing\ncrucial metadata from UAVs, including GPS position, drone altitude, and camera\norientations. Extensive experiments are conducted to validate the efficacy of\nour MOT algorithm. Utilizing the challenging SeaDroneSee tracking dataset,\nwhich encompasses the aforementioned scenarios, we achieve a much-improved\nperformance in the latest edition of the UAV-based Maritime Object Tracking\nChallenge with a state-of-the-art HOTA of 69.5% and an IDF1 of 85.9% on the\ntesting split.\n","authors":["Cheng-Yen Yang","Hsiang-Wei Huang","Zhongyu Jiang","Heng-Cheng Kuo","Jie Mei","Chung-I Huang","Jenq-Neng Hwang"],"pdf_url":"https://arxiv.org/pdf/2311.03561v2.pdf","comment":"1st place method (WACV Workshop Paper) of the UAV-based Multi-Object\n  Tracking with Reidentification Challenge in MaCVi WACV 2024"},{"id":"http://arxiv.org/abs/2311.13661v1","updated":"2023-11-22T19:25:31Z","published":"2023-11-22T19:25:31Z","title":"BenthIQ: a Transformer-Based Benthic Classification Model for Coral\n  Restoration","summary":"  Coral reefs are vital for marine biodiversity, coastal protection, and\nsupporting human livelihoods globally. However, they are increasingly\nthreatened by mass bleaching events, pollution, and unsustainable practices\nwith the advent of climate change. Monitoring the health of these ecosystems is\ncrucial for effective restoration and management. Current methods for creating\nbenthic composition maps often compromise between spatial coverage and\nresolution. In this paper, we introduce BenthIQ, a multi-label semantic\nsegmentation network designed for high-precision classification of underwater\nsubstrates, including live coral, algae, rock, and sand. Although commonly\ndeployed CNNs are limited in learning long-range semantic information,\ntransformer-based models have recently achieved state-of-the-art performance in\nvision tasks such as object detection and image classification. We integrate\nthe hierarchical Swin Transformer as the backbone of a U-shaped encoder-decoder\narchitecture for local-global semantic feature learning. Using a real-world\ncase study in French Polynesia, we demonstrate that our approach outperforms\ntraditional CNN and attention-based models on pixel-wise classification of\nshallow reef imagery.\n","authors":["Rupa Kurinchi-Vendhan","Drew Gray","Elijah Cole"],"pdf_url":"https://arxiv.org/pdf/2311.13661v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13656v1","updated":"2023-11-22T19:14:25Z","published":"2023-11-22T19:14:25Z","title":"Panda or not Panda? Understanding Adversarial Attacks with Interactive\n  Visualization","summary":"  Adversarial machine learning (AML) studies attacks that can fool machine\nlearning algorithms into generating incorrect outcomes as well as the defenses\nagainst worst-case attacks to strengthen model robustness. Specifically for\nimage classification, it is challenging to understand adversarial attacks due\nto their use of subtle perturbations that are not human-interpretable, as well\nas the variability of attack impacts influenced by diverse methodologies,\ninstance differences, and model architectures. Through a design study with AML\nlearners and teachers, we introduce AdvEx, a multi-level interactive\nvisualization system that comprehensively presents the properties and impacts\nof evasion attacks on different image classifiers for novice AML learners. We\nquantitatively and qualitatively assessed AdvEx in a two-part evaluation\nincluding user studies and expert interviews. Our results show that AdvEx is\nnot only highly effective as a visualization tool for understanding AML\nmechanisms, but also provides an engaging and enjoyable learning experience,\nthus demonstrating its overall benefits for AML learners.\n","authors":["Yuzhe You","Jarvis Tse","Jian Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.13656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13655v1","updated":"2023-11-22T19:13:00Z","published":"2023-11-22T19:13:00Z","title":"GAN-Avatar: Controllable Personalized GAN-based Human Head Avatar","summary":"  Digital humans and, especially, 3D facial avatars have raised a lot of\nattention in the past years, as they are the backbone of several applications\nlike immersive telepresence in AR or VR. Despite the progress, facial avatars\nreconstructed from commodity hardware are incomplete and miss out on parts of\nthe side and back of the head, severely limiting the usability of the avatar.\nThis limitation in prior work stems from their requirement of face tracking,\nwhich fails for profile and back views. To address this issue, we propose to\nlearn person-specific animatable avatars from images without assuming to have\naccess to precise facial expression tracking. At the core of our method, we\nleverage a 3D-aware generative model that is trained to reproduce the\ndistribution of facial expressions from the training data. To train this\nappearance model, we only assume to have a collection of 2D images with the\ncorresponding camera parameters. For controlling the model, we learn a mapping\nfrom 3DMM facial expression parameters to the latent space of the generative\nmodel. This mapping can be learned by sampling the latent space of the\nappearance model and reconstructing the facial parameters from a normalized\nfrontal view, where facial expression estimation performs well. With this\nscheme, we decouple 3D appearance reconstruction and animation control to\nachieve high fidelity in image synthesis. In a series of experiments, we\ncompare our proposed technique to state-of-the-art monocular methods and show\nsuperior quality while not requiring expression tracking of the training data.\n","authors":["Berna Kabadayi","Wojciech Zielonka","Bharat Lal Bhatnagar","Gerard Pons-Moll","Justus Thies"],"pdf_url":"https://arxiv.org/pdf/2311.13655v1.pdf","comment":"Website: https://ganavatar.github.io/ , Video:\n  https://www.youtube.com/watch?v=uAi5IVrzzZY&ab_channel=JustusThies , Accepted\n  to 3DV2024"},{"id":"http://arxiv.org/abs/2311.13629v1","updated":"2023-11-22T18:59:51Z","published":"2023-11-22T18:59:51Z","title":"Diffusion models meet image counter-forensics","summary":"  From its acquisition in the camera sensors to its storage, different\noperations are performed to generate the final image. This pipeline imprints\nspecific traces into the image to form a natural watermark. Tampering with an\nimage disturbs these traces; these disruptions are clues that are used by most\nmethods to detect and locate forgeries. In this article, we assess the\ncapabilities of diffusion models to erase the traces left by forgers and,\ntherefore, deceive forensics methods. Such an approach has been recently\nintroduced for adversarial purification, achieving significant performance. We\nshow that diffusion purification methods are well suited for counter-forensics\ntasks. Such approaches outperform already existing counter-forensics techniques\nboth in deceiving forensics methods and in preserving the natural look of the\npurified images. The source code is publicly available at\nhttps://github.com/mtailanian/diff-cf.\n","authors":["Matías Tailanian","Marina Gardella","Álvaro Pardo","Pablo Musé"],"pdf_url":"https://arxiv.org/pdf/2311.13629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13627v1","updated":"2023-11-22T17:44:24Z","published":"2023-11-22T17:44:24Z","title":"Vamos: Versatile Action Models for Video Understanding","summary":"  What makes good video representations for video understanding, such as\nanticipating future activities, or answering video-conditioned questions? While\nearlier approaches focus on end-to-end learning directly from video pixels, we\npropose to revisit text-based representations, such as discrete action labels,\nor free-form video captions, which are interpretable and can be directly\nconsumed by large language models (LLMs). Intuitively, different video\nunderstanding tasks may require representations that are complementary and at\ndifferent granularities. To this end, we propose versatile action models\n(Vamos), a learning framework powered by a large language model as the\n\"reasoner\", and can flexibly leverage visual embeddings, action labels, and\nfree-form descriptions extracted from videos as its input. We evaluate Vamos on\nfour complementary video understanding benchmarks, Ego4D, Next-QA, IntentQA,\nand EgoSchema, on its capability to model temporal dynamics, encode visual\nhistory, and perform reasoning. Surprisingly, we observe that text-based\nrepresentations consistently achieve competitive performance on all benchmarks,\nand that visual embeddings provide marginal or no performance improvement,\ndemonstrating the effectiveness of text-based video representation in the LLM\nera. We perform extensive ablation study and qualitative analysis to support\nour observations, and achieve state-of-the-art performance on three benchmarks.\n","authors":["Shijie Wang","Qi Zhao","Minh Quan Do","Nakul Agarwal","Kwonjoon Lee","Chen Sun"],"pdf_url":"https://arxiv.org/pdf/2311.13627v1.pdf","comment":"Under submission. Code and models will be released at\n  https://brown-palm.github.io/Vamos/"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2307.11494v3","updated":"2023-11-22T12:25:41Z","published":"2023-07-21T10:56:36Z","title":"Predict, Refine, Synthesize: Self-Guiding Diffusion Models for\n  Probabilistic Time Series Forecasting","summary":"  Diffusion models have achieved state-of-the-art performance in generative\nmodeling tasks across various domains. Prior works on time series diffusion\nmodels have primarily focused on developing conditional models tailored to\nspecific forecasting or imputation tasks. In this work, we explore the\npotential of task-agnostic, unconditional diffusion models for several time\nseries applications. We propose TSDiff, an unconditionally-trained diffusion\nmodel for time series. Our proposed self-guidance mechanism enables\nconditioning TSDiff for downstream tasks during inference, without requiring\nauxiliary networks or altering the training procedure. We demonstrate the\neffectiveness of our method on three different time series tasks: forecasting,\nrefinement, and synthetic data generation. First, we show that TSDiff is\ncompetitive with several task-specific conditional forecasting methods\n(predict). Second, we leverage the learned implicit probability density of\nTSDiff to iteratively refine the predictions of base forecasters with reduced\ncomputational overhead over reverse diffusion (refine). Notably, the generative\nperformance of the model remains intact -- downstream forecasters trained on\nsynthetic samples from TSDiff outperform forecasters that are trained on\nsamples from other state-of-the-art generative time series models, occasionally\neven outperforming models trained on real data (synthesize).\n","authors":["Marcel Kollovieh","Abdul Fatir Ansari","Michael Bohlke-Schneider","Jasper Zschiegner","Hao Wang","Yuyang Wang"],"pdf_url":"https://arxiv.org/pdf/2307.11494v3.pdf","comment":"Code available at\n  https://github.com/amazon-science/unconditional-time-series-diffusion"},{"id":"http://arxiv.org/abs/2311.12550v2","updated":"2023-11-22T09:45:11Z","published":"2023-11-21T11:59:16Z","title":"Explainable Anomaly Detection using Masked Latent Generative Modeling","summary":"  We present a novel time series anomaly detection method that achieves\nexcellent detection accuracy while offering a superior level of explainability.\nOur proposed method, TimeVQVAE-AD, leverages masked generative modeling adapted\nfrom the cutting-edge time series generation method known as TimeVQVAE. The\nprior model is trained on the discrete latent space of a time-frequency domain.\nNotably, the dimensional semantics of the time-frequency domain are preserved\nin the latent space, enabling us to compute anomaly scores across different\nfrequency bands, which provides a better insight into the detected anomalies.\nAdditionally, the generative nature of the prior model allows for sampling\nlikely normal states for detected anomalies, enhancing the explainability of\nthe detected anomalies through counterfactuals. Our experimental evaluation on\nthe UCR Time Series Anomaly archive demonstrates that TimeVQVAE-AD\nsignificantly surpasses the existing methods in terms of detection accuracy and\nexplainability.\n","authors":["Daesoo Lee","Sara Malacarne","Erlend Aune"],"pdf_url":"https://arxiv.org/pdf/2311.12550v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12538v2","updated":"2023-11-22T08:44:34Z","published":"2023-11-21T11:33:03Z","title":"In-Context Learning Functions with Varying Number of Minima","summary":"  Large Language Models (LLMs) have proven effective at In-Context Learning\n(ICL), an ability that allows them to create predictors from labeled examples.\nFew studies have explored the interplay between ICL and specific properties of\nfunctions it attempts to approximate. In our study, we use a formal framework\nto explore ICL and propose a new task of approximating functions with varying\nnumber of minima. We implement a method that allows for producing functions\nwith given inputs as minima. We find that increasing the number of minima\ndegrades ICL performance. At the same time, our evaluation shows that ICL\noutperforms 2-layer Neural Network (2NN) model. Furthermore, ICL learns faster\nthan 2NN in all settings. We validate the findings through a set of few-shot\nexperiments across various hyperparameter configurations.\n","authors":["David Oniani","Yanshan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12538v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12526v2","updated":"2023-11-22T09:39:02Z","published":"2023-11-21T11:12:03Z","title":"Neural Network Pruning by Gradient Descent","summary":"  The rapid increase in the parameters of deep learning models has led to\nsignificant costs, challenging computational efficiency and model\ninterpretability. In this paper, we introduce a novel and straightforward\nneural network pruning framework that incorporates the Gumbel-Softmax\ntechnique. This framework enables the simultaneous optimization of a network's\nweights and topology in an end-to-end process using stochastic gradient\ndescent. Empirical results demonstrate its exceptional compression capability,\nmaintaining high accuracy on the MNIST dataset with only 0.15\\% of the original\nnetwork parameters. Moreover, our framework enhances neural network\ninterpretability, not only by allowing easy extraction of feature importance\ndirectly from the pruned network but also by enabling visualization of feature\nsymmetry and the pathways of information propagation from features to outcomes.\nAlthough the pruning strategy is learned through deep learning, it is\nsurprisingly intuitive and understandable, focusing on selecting key\nrepresentative features and exploiting data patterns to achieve extreme sparse\npruning. We believe our method opens a promising new avenue for deep learning\npruning and the creation of interpretable machine learning systems.\n","authors":["Zhang Zhang","Ruyi Tao","Jiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12526v2.pdf","comment":"21 pages, 5 figures"},{"id":"http://arxiv.org/abs/2205.02645v4","updated":"2023-11-22T03:43:55Z","published":"2022-05-05T13:44:24Z","title":"Discovering stochastic dynamical equations from biological time series\n  data","summary":"  Stochastic differential equations (SDEs) are an important framework to model\ndynamics with randomness, as is common in most biological systems. The inverse\nproblem of integrating these models with empirical data remains a major\nchallenge. Here, we present a software package, PyDaDDy (Python Library for\nData Driven Dynamics) that takes time series data as an input and outputs an\ninterpretable SDE. We achieve this by combining traditional approaches from\nstochastic calculus literature with state-of-the-art equation discovery\ntechniques. We validate our approach on synthetic datasets, and demonstrate the\ngenerality and applicability of the method on two real-world datasets of vastly\ndifferent spatiotemporal scales: (i) collective movement of fish school where\nstochasticity plays a crucial role, and (ii) confined migration of a single\ncell, primarily following a relaxed oscillation. We make the method available\nas an easy-to-use, open-source Python package, PyDaddy (Python Library for Data\nDriven Dynamics).\n","authors":["Arshed Nabeel","Ashwin Karichannavar","Shuaib Palathingal","Jitesh Jhawar","David B. Brückner","Danny Raj M.","Vishwesha Guttal"],"pdf_url":"https://arxiv.org/pdf/2205.02645v4.pdf","comment":"15 pages (+ 9 page appendix), 6 figures (+ 8 appendix figures).\n  Updates: v3: Significantly reorganized the paper and added a section analysis\n  of a cell migration dataset. v4: Update arXiv title to match the updated\n  title of the manuscript"},{"id":"http://arxiv.org/abs/2310.08897v3","updated":"2023-11-22T05:15:38Z","published":"2023-10-13T06:58:52Z","title":"Self supervised convolutional kernel based handcrafted feature\n  harmonization: Enhanced left ventricle hypertension disease phenotyping on\n  echocardiography","summary":"  Radiomics, a medical imaging technique, extracts quantitative handcrafted\nfeatures from images to predict diseases. Harmonization in those features\nensures consistent feature extraction across various imaging devices and\nprotocols. Methods for harmonization include standardized imaging protocols,\nstatistical adjustments, and evaluating feature robustness. Myocardial diseases\nsuch as Left Ventricular Hypertrophy (LVH) and Hypertensive Heart Disease (HHD)\nare diagnosed via echocardiography, but variable imaging settings pose\nchallenges. Harmonization techniques are crucial for applying handcrafted\nfeatures in disease diagnosis in such scenario. Self-supervised learning (SSL)\nenhances data understanding within limited datasets and adapts to diverse data\nsettings. ConvNeXt-V2 integrates convolutional layers into SSL, displaying\nsuperior performance in various tasks. This study focuses on convolutional\nfilters within SSL, using them as preprocessing to convert images into feature\nmaps for handcrafted feature harmonization. Our proposed method excelled in\nharmonization evaluation and exhibited superior LVH classification performance\ncompared to existing methods.\n","authors":["Jina Lee","Youngtaek Hong","Dawun Jeong","Yeonggul Jang","Jaeik Jeon","Sihyeon Jeong","Taekgeun Jung","Yeonyee E. Yoon","Inki Moon","Seung-Ah Lee","Hyuk-Jae Chang"],"pdf_url":"https://arxiv.org/pdf/2310.08897v3.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2206.05077v5","updated":"2023-11-22T16:45:11Z","published":"2022-06-10T13:18:26Z","title":"Tensor Train for Global Optimization Problems in Robotics","summary":"  The convergence of many numerical optimization techniques is highly dependent\non the initial guess given to the solver. To address this issue, we propose a\nnovel approach that utilizes tensor methods to initialize existing optimization\nsolvers near global optima. Our method does not require access to a database of\ngood solutions. We first transform the cost function, which depends on both\ntask parameters and optimization variables, into a probability density\nfunction. Unlike existing approaches, the joint probability distribution of the\ntask parameters and optimization variables is approximated using the Tensor\nTrain model, which enables efficient conditioning and sampling. We treat the\ntask parameters as random variables, and for a given task, we generate samples\nfor decision variables from the conditional distribution to initialize the\noptimization solver. Our method can produce multiple solutions (when they\nexist) faster than existing methods. We first evaluate the approach on\nbenchmark functions for numerical optimization that are hard to solve using\ngradient-based optimization solvers with a naive initialization. The results\nshow that the proposed method can generate samples close to global optima and\nfrom multiple modes. We then demonstrate the generality and relevance of our\nframework to robotics by applying it to inverse kinematics with obstacles and\nmotion planning problems with a 7-DoF manipulator.\n","authors":["Suhan Shetty","Teguh Lembono","Tobias Loew","Sylvain Calinon"],"pdf_url":"https://arxiv.org/pdf/2206.05077v5.pdf","comment":"25 pages, 21 figures"},{"id":"http://arxiv.org/abs/2304.07647v3","updated":"2023-11-22T05:20:22Z","published":"2023-04-15T22:24:05Z","title":"LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene\n  Graphs with Weak Supervision","summary":"  We propose LASER, a neuro-symbolic approach to learn semantic video\nrepresentations that capture rich spatial and temporal properties in video data\nby leveraging high-level logic specifications. In particular, we formulate the\nproblem in terms of alignment between raw videos and spatio-temporal logic\nspecifications. The alignment algorithm leverages a differentiable symbolic\nreasoner and a combination of contrastive, temporal, and semantics losses. It\neffectively and efficiently trains low-level perception models to extract\nfine-grained video representation in the form of a spatio-temporal scene graph\nthat conforms to the desired high-level specification. In doing so, we explore\na novel methodology that weakly supervises the learning of video semantic\nrepresentations through logic specifications. We evaluate our method on two\ndatasets with rich spatial and temporal specifications:\n20BN-Something-Something and MUGEN. We demonstrate that our method learns\nbetter fine-grained video semantics than existing baselines.\n","authors":["Jiani Huang","Ziyang Li","Mayur Naik","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2304.07647v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10863v3","updated":"2023-11-22T03:01:59Z","published":"2023-11-17T20:51:24Z","title":"Verified Compositional Neuro-Symbolic Control for Stochastic Systems\n  with Temporal Logic Tasks","summary":"  Several methods have been proposed recently to learn neural network (NN)\ncontrollers for autonomous agents, with unknown and stochastic dynamics, tasked\nwith complex missions captured by Linear Temporal Logic (LTL). Due to the\nsample-inefficiency of the majority of these works, compositional learning\nmethods have been proposed decomposing the LTL specification into smaller\nsub-tasks. Then, separate controllers are learned and composed to satisfy the\noriginal task. A key challenge within these approaches is that they often lack\nsafety guarantees or the provided guarantees are impractical. This paper aims\nto address this challenge. Particularly, we consider autonomous systems with\nunknown and stochastic dynamics and LTL-encoded tasks. We assume that the\nsystem is equipped with a finite set of base skills modeled by trained NN\nfeedback controllers. Our goal is to check if there exists a temporal\ncomposition of the trained NN controllers - and if so, to compute it - that\nwill yield a composite system behavior that satisfies the assigned LTL task\nwith probability one. We propose a new approach that relies on a novel\nintegration of automata theory and data-driven reachability analysis tools for\nNN-controlled stochastic systems. The resulting neuro-symbolic controller\nallows the agent to generate safe behaviors for unseen complex temporal logic\ntasks in a zero-shot fashion by leveraging its base skills. We show correctness\nof the proposed method and we provide conditions under which it is complete. To\nthe best of our knowledge, this is the first work that designs verified\ntemporal compositions of NN controllers for unknown and stochastic systems.\nFinally, we provide extensive numerical simulations and hardware experiments on\nrobot navigation tasks to demonstrate the proposed method.\n","authors":["Jun Wang","Haojun Chen","Zihe Sun","Yiannis Kantaros"],"pdf_url":"https://arxiv.org/pdf/2311.10863v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2209.06130"},{"id":"http://arxiv.org/abs/2311.12198v2","updated":"2023-11-22T06:46:18Z","published":"2023-11-20T21:34:52Z","title":"PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics","summary":"  We introduce PhysGaussian, a new method that seamlessly integrates physically\ngrounded Newtonian dynamics within 3D Gaussians to achieve high-quality novel\nmotion synthesis. Employing a custom Material Point Method (MPM), our approach\nenriches 3D Gaussian kernels with physically meaningful kinematic deformation\nand mechanical stress attributes, all evolved in line with continuum mechanics\nprinciples. A defining characteristic of our method is the seamless integration\nbetween physical simulation and visual rendering: both components utilize the\nsame 3D Gaussian kernels as their discrete representations. This negates the\nnecessity for triangle/tetrahedron meshing, marching cubes, \"cage meshes,\" or\nany other geometry embedding, highlighting the principle of \"what you see is\nwhat you simulate (WS$^2$).\" Our method demonstrates exceptional versatility\nacross a wide variety of materials--including elastic entities, metals,\nnon-Newtonian fluids, and granular materials--showcasing its strong\ncapabilities in creating diverse visual content with novel viewpoints and\nmovements. Our project page is at: https://xpandora.github.io/PhysGaussian/\n","authors":["Tianyi Xie","Zeshun Zong","Yuxing Qiu","Xuan Li","Yutao Feng","Yin Yang","Chenfanfu Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.12198v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12166v2","updated":"2023-11-22T01:42:59Z","published":"2023-11-20T20:32:14Z","title":"Creating Temporally Correlated High-Resolution Power Injection Profiles\n  Using Physics-Aware GAN","summary":"  Traditional smart meter measurements lack the granularity needed for\nreal-time decision-making. To address this practical problem, we create a\ngenerative adversarial networks (GAN) model that enforces temporal consistency\non its high-resolution outputs via hard inequality constraints using a convex\noptimization layer. A unique feature of our GAN model is that it is trained\nsolely on slow timescale aggregated power information obtained from historical\nsmart meter data. The results demonstrate that the model can successfully\ncreate minutely interval temporally-correlated instantaneous power injection\nprofiles from 15-minute average power consumption information. This innovative\napproach, emphasizing inter-neuron constraints, offers a promising avenue for\nimproved high-speed state estimation in distribution systems and enhances the\napplicability of data-driven solutions for monitoring such systems.\n","authors":["Hritik Gopal Shah","Behrouz Azimian","Anamitra Pal"],"pdf_url":"https://arxiv.org/pdf/2311.12166v2.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2311.13601v1","updated":"2023-11-22T18:59:48Z","published":"2023-11-22T18:59:48Z","title":"Visual In-Context Prompting","summary":"  In-context prompting in large language models (LLMs) has become a prevalent\napproach to improve zero-shot capabilities, but this idea is less explored in\nthe vision domain. Existing visual prompting methods focus on referring\nsegmentation to segment the most relevant object, falling short of addressing\nmany generic vision tasks like open-set segmentation and detection. In this\npaper, we introduce a universal visual in-context prompting framework for both\ntasks. In particular, we build on top of an encoder-decoder architecture, and\ndevelop a versatile prompt encoder to support a variety of prompts like\nstrokes, boxes, and points. We further enhance it to take an arbitrary number\nof reference image segments as the context. Our extensive explorations show\nthat the proposed visual in-context prompting elicits extraordinary referring\nand generic segmentation capabilities to refer and detect, yielding competitive\nperformance to close-set in-domain datasets and showing promising results on\nmany open-set segmentation datasets. By joint training on COCO and SA-1B, our\nmodel achieves $57.7$ PQ on COCO and $23.2$ PQ on ADE20K. Code will be\navailable at https://github.com/UX-Decoder/DINOv.\n","authors":["Feng Li","Qing Jiang","Hao Zhang","Tianhe Ren","Shilong Liu","Xueyan Zou","Huaizhe Xu","Hongyang Li","Chunyuan Li","Jianwei Yang","Lei Zhang","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2311.13601v1.pdf","comment":"technical report"},{"id":"http://arxiv.org/abs/2311.13600v1","updated":"2023-11-22T18:59:36Z","published":"2023-11-22T18:59:36Z","title":"ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs","summary":"  Methods for finetuning generative models for concept-driven personalization\ngenerally achieve strong results for subject-driven or style-driven generation.\nRecently, low-rank adaptations (LoRA) have been proposed as a\nparameter-efficient way of achieving concept-driven personalization. While\nrecent work explores the combination of separate LoRAs to achieve joint\ngeneration of learned styles and subjects, existing techniques do not reliably\naddress the problem; they often compromise either subject fidelity or style\nfidelity. We propose ZipLoRA, a method to cheaply and effectively merge\nindependently trained style and subject LoRAs in order to achieve generation of\nany user-provided subject in any user-provided style. Experiments on a wide\nrange of subject and style combinations show that ZipLoRA can generate\ncompelling results with meaningful improvements over baselines in subject and\nstyle fidelity while preserving the ability to recontextualize. Project page:\nhttps://ziplora.github.io\n","authors":["Viraj Shah","Nataniel Ruiz","Forrester Cole","Erika Lu","Svetlana Lazebnik","Yuanzhen Li","Varun Jampani"],"pdf_url":"https://arxiv.org/pdf/2311.13600v1.pdf","comment":"Project page: https://ziplora.github.io"},{"id":"http://arxiv.org/abs/2311.13595v1","updated":"2023-11-22T18:55:27Z","published":"2023-11-22T18:55:27Z","title":"Covariance alignment: from maximum likelihood estimation to\n  Gromov-Wasserstein","summary":"  Feature alignment methods are used in many scientific disciplines for data\npooling, annotation, and comparison. As an instance of a permutation learning\nproblem, feature alignment presents significant statistical and computational\nchallenges. In this work, we propose the covariance alignment model to study\nand compare various alignment methods and establish a minimax lower bound for\ncovariance alignment that has a non-standard dimension scaling because of the\npresence of a nuisance parameter. This lower bound is in fact minimax optimal\nand is achieved by a natural quasi MLE. However, this estimator involves a\nsearch over all permutations which is computationally infeasible even when the\nproblem has moderate size. To overcome this limitation, we show that the\ncelebrated Gromov-Wasserstein algorithm from optimal transport which is more\namenable to fast implementation even on large-scale problems is also minimax\noptimal. These results give the first statistical justification for the\ndeployment of the Gromov-Wasserstein algorithm in practice.\n","authors":["Yanjun Han","Philippe Rigollet","George Stepaniants"],"pdf_url":"https://arxiv.org/pdf/2311.13595v1.pdf","comment":"41 pages, 2 figures"},{"id":"http://arxiv.org/abs/2311.13594v1","updated":"2023-11-22T18:55:25Z","published":"2023-11-22T18:55:25Z","title":"Labeling Neural Representations with Inverse Recognition","summary":"  Deep Neural Networks (DNNs) demonstrated remarkable capabilities in learning\ncomplex hierarchical data representations, but the nature of these\nrepresentations remains largely unknown. Existing global explainability\nmethods, such as Network Dissection, face limitations such as reliance on\nsegmentation masks, lack of statistical significance testing, and high\ncomputational demands. We propose Inverse Recognition (INVERT), a scalable\napproach for connecting learned representations with human-understandable\nconcepts by leveraging their capacity to discriminate between these concepts.\nIn contrast to prior work, INVERT is capable of handling diverse types of\nneurons, exhibits less computational complexity, and does not rely on the\navailability of segmentation masks. Moreover, INVERT provides an interpretable\nmetric assessing the alignment between the representation and its corresponding\nexplanation and delivering a measure of statistical significance, emphasizing\nits utility and credibility. We demonstrate the applicability of INVERT in\nvarious scenarios, including the identification of representations affected by\nspurious correlations, and the interpretation of the hierarchical structure of\ndecision-making within the models.\n","authors":["Kirill Bykov","Laura Kopf","Shinichi Nakajima","Marius Kloft","Marina M. -C. Höhne"],"pdf_url":"https://arxiv.org/pdf/2311.13594v1.pdf","comment":"24 pages, 16 figures"},{"id":"http://arxiv.org/abs/2311.13589v1","updated":"2023-11-22T18:50:06Z","published":"2023-11-22T18:50:06Z","title":"Risk-sensitive Markov Decision Process and Learning under General\n  Utility Functions","summary":"  Reinforcement Learning (RL) has gained substantial attention across diverse\napplication domains and theoretical investigations. Existing literature on RL\ntheory largely focuses on risk-neutral settings where the decision-maker learns\nto maximize the expected cumulative reward. However, in practical scenarios\nsuch as portfolio management and e-commerce recommendations, decision-makers\noften persist in heterogeneous risk preferences subject to outcome\nuncertainties, which can not be well-captured by the risk-neural framework.\nIncorporating these preferences can be approached through utility theory, yet\nthe development of risk-sensitive RL under general utility functions remains an\nopen question for theoretical exploration.\n  In this paper, we consider a scenario where the decision-maker seeks to\noptimize a general utility function of the cumulative reward in the framework\nof a Markov decision process (MDP). To facilitate the Dynamic Programming\nPrinciple and Bellman equation, we enlarge the state space with an additional\ndimension that accounts for the cumulative reward. We propose a discretized\napproximation scheme to the MDP under enlarged state space, which is tractable\nand key for algorithmic design. We then propose a modified value iteration\nalgorithm that employs an epsilon-covering over the space of cumulative reward.\nWhen a simulator is accessible, our algorithm efficiently learns a near-optimal\npolicy with guaranteed sample complexity. In the absence of a simulator, our\nalgorithm, designed with an upper-confidence-bound exploration approach,\nidentifies a near-optimal policy while ensuring a guaranteed regret bound. For\nboth algorithms, we match the theoretical lower bounds for the risk-neutral\nsetting.\n","authors":["Zhengqi Wu","Renyuan Xu"],"pdf_url":"https://arxiv.org/pdf/2311.13589v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2311.13587v1","updated":"2023-11-22T18:46:05Z","published":"2023-11-22T18:46:05Z","title":"A Survey of Serverless Machine Learning Model Inference","summary":"  Recent developments in Generative AI, Computer Vision, and Natural Language\nProcessing have led to an increased integration of AI models into various\nproducts. This widespread adoption of AI requires significant efforts in\ndeploying these models in production environments. When hosting machine\nlearning models for real-time predictions, it is important to meet defined\nService Level Objectives (SLOs), ensuring reliability, minimal downtime, and\noptimizing operational costs of the underlying infrastructure. Large machine\nlearning models often demand GPU resources for efficient inference to meet\nSLOs. In the context of these trends, there is growing interest in hosting AI\nmodels in a serverless architecture while still providing GPU access for\ninference tasks. This survey aims to summarize and categorize the emerging\nchallenges and optimization opportunities for large-scale deep learning serving\nsystems. By providing a novel taxonomy and summarizing recent trends, we hope\nthat this survey could shed light on new optimization perspectives and motivate\nnovel works in large-scale deep learning serving systems.\n","authors":["Kamil Kojs"],"pdf_url":"https://arxiv.org/pdf/2311.13587v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2311.13584v1","updated":"2023-11-22T18:40:45Z","published":"2023-11-22T18:40:45Z","title":"On diffusion-based generative models and their error bounds: The\n  log-concave case with full convergence estimates","summary":"  We provide full theoretical guarantees for the convergence behaviour of\ndiffusion-based generative models under the assumption of strongly logconcave\ndata distributions while our approximating class of functions used for score\nestimation is made of Lipschitz continuous functions. We demonstrate via a\nmotivating example, sampling from a Gaussian distribution with unknown mean,\nthe powerfulness of our approach. In this case, explicit estimates are provided\nfor the associated optimization problem, i.e. score approximation, while these\nare combined with the corresponding sampling estimates. As a result, we obtain\nthe best known upper bound estimates in terms of key quantities of interest,\nsuch as the dimension and rates of convergence, for the Wasserstein-2 distance\nbetween the data distribution (Gaussian with unknown mean) and our sampling\nalgorithm.\n  Beyond the motivating example and in order to allow for the use of a diverse\nrange of stochastic optimizers, we present our results using an $L^2$-accurate\nscore estimation assumption, which crucially is formed under an expectation\nwith respect to the stochastic optimizer and our novel auxiliary process that\nuses only known information. This approach yields the best known convergence\nrate for our sampling algorithm.\n","authors":["Stefano Bruno","Ying Zhang","Dong-Young Lim","Ömer Deniz Akyildiz","Sotirios Sabanis"],"pdf_url":"https://arxiv.org/pdf/2311.13584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13583v1","updated":"2023-11-22T18:40:18Z","published":"2023-11-22T18:40:18Z","title":"Adaptive Sampling for Deep Learning via Efficient Nonparametric Proxies","summary":"  Data sampling is an effective method to improve the training speed of neural\nnetworks, with recent results demonstrating that it can even break the neural\nscaling laws. These results critically rely on high-quality scores to estimate\nthe importance of an input to the network. We observe that there are two\ndominant strategies: static sampling, where the scores are determined before\ntraining, and dynamic sampling, where the scores can depend on the model\nweights. Static algorithms are computationally inexpensive but less effective\nthan their dynamic counterparts, which can cause end-to-end slowdown due to\ntheir need to explicitly compute losses. To address this problem, we propose a\nnovel sampling distribution based on nonparametric kernel regression that\nlearns an effective importance score as the neural network trains. However,\nnonparametric regression models are too computationally expensive to accelerate\nend-to-end training. Therefore, we develop an efficient sketch-based\napproximation to the Nadaraya-Watson estimator. Using recent techniques from\nhigh-dimensional statistics and randomized algorithms, we prove that our\nNadaraya-Watson sketch approximates the estimator with exponential convergence\nguarantees. Our sampling algorithm outperforms the baseline in terms of\nwall-clock time and accuracy on four datasets.\n","authors":["Shabnam Daghaghi","Benjamin Coleman","Benito Geordie","Anshumali Shrivastava"],"pdf_url":"https://arxiv.org/pdf/2311.13583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13580v1","updated":"2023-11-22T18:34:49Z","published":"2023-11-22T18:34:49Z","title":"$σ$-PCA: a unified neural model for linear and nonlinear principal\n  component analysis","summary":"  Linear principal component analysis (PCA), nonlinear PCA, and linear\nindependent component analysis (ICA) -- those are three methods with\nsingle-layer autoencoder formulations for learning linear transformations from\ndata. Linear PCA learns orthogonal transformations (rotations) that orient axes\nto maximise variance, but it suffers from a subspace rotational indeterminacy:\nit fails to find a unique rotation for axes that share the same variance. Both\nnonlinear PCA and linear ICA reduce the subspace indeterminacy from rotational\nto permutational by maximising statistical independence under the assumption of\nunit variance. The main difference between them is that nonlinear PCA only\nlearns rotations while linear ICA learns not just rotations but any linear\ntransformation with unit variance. The relationship between all three can be\nunderstood by the singular value decomposition of the linear ICA transformation\ninto a sequence of rotation, scale, rotation. Linear PCA learns the first\nrotation; nonlinear PCA learns the second. The scale is simply the inverse of\nthe standard deviations. The problem is that, in contrast to linear PCA,\nconventional nonlinear PCA cannot be used directly on the data to learn the\nfirst rotation, the first being special as it reduces dimensionality and orders\nby variances. In this paper, we have identified the cause, and as a solution we\npropose $\\sigma$-PCA: a unified neural model for linear and nonlinear PCA as\nsingle-layer autoencoders. One of its key ingredients: modelling not just the\nrotation but also the scale -- the variances. This model bridges the disparity\nbetween linear and nonlinear PCA. And so, like linear PCA, it can learn a\nsemi-orthogonal transformation that reduces dimensionality and orders by\nvariances, but, unlike linear PCA, it does not suffer from rotational\nindeterminacy.\n","authors":["Fahdi Kanavati","Lucy Katsnith","Masayuki Tsuneki"],"pdf_url":"https://arxiv.org/pdf/2311.13580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19274v2","updated":"2023-11-22T18:27:15Z","published":"2023-10-30T05:13:58Z","title":"Prediction of Effective Elastic Moduli of Rocks using Graph Neural\n  Networks","summary":"  This study presents a Graph Neural Networks (GNNs)-based approach for\npredicting the effective elastic moduli of rocks from their digital CT-scan\nimages. We use the Mapper algorithm to transform 3D digital rock images into\ngraph datasets, encapsulating essential geometrical information. These graphs,\nafter training, prove effective in predicting elastic moduli. Our GNN model\nshows robust predictive capabilities across various graph sizes derived from\nvarious subcube dimensions. Not only does it perform well on the test dataset,\nbut it also maintains high prediction accuracy for unseen rocks and unexplored\nsubcube sizes. Comparative analysis with Convolutional Neural Networks (CNNs)\nreveals the superior performance of GNNs in predicting unseen rock properties.\nMoreover, the graph representation of microstructures significantly reduces GPU\nmemory requirements (compared to the grid representation for CNNs), enabling\ngreater flexibility in the batch size selection. This work demonstrates the\npotential of GNN models in enhancing the prediction accuracy of rock properties\nand boosting the efficiency of digital rock analysis.\n","authors":["Jaehong Chung","Rasool Ahmad","WaiChing Sun","Wei Cai","Tapan Mukerji"],"pdf_url":"https://arxiv.org/pdf/2310.19274v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13552v1","updated":"2023-11-22T17:50:00Z","published":"2023-11-22T17:50:00Z","title":"A Unified Framework for Trace-induced Quantum Kernels","summary":"  Quantum kernel methods are promising candidates for achieving a practical\nquantum advantage for certain machine learning tasks. Similar to classical\nmachine learning, an exact form of a quantum kernel is expected to have a great\nimpact on the model performance. In this work we combine all trace-induced\nquantum kernels, including the commonly-used global fidelity and local\nprojected quantum kernels, into a common framework. We show how generalized\ntrace-induced quantum kernels can be constructed as combinations of the\nfundamental building blocks we coin \"Lego\" kernels, which impose an inductive\nbias on the resulting quantum models. We relate the expressive power and\ngeneralization ability to the number of non-zero weight Lego kernels and\npropose a systematic approach to increase the complexity of a quantum kernel\nmodel, leading to a new form of the local projected kernels that require fewer\nquantum resources in terms of the number of quantum gates and measurement\nshots. We show numerically that models based on local projected kernels can\nachieve comparable performance to the global fidelity quantum kernel. Our work\nunifies existing quantum kernels and provides a systematic framework to compare\ntheir properties.\n","authors":["Beng Yee Gan","Daniel Leykam","Supanut Thanasilp"],"pdf_url":"https://arxiv.org/pdf/2311.13552v1.pdf","comment":"12 + 15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.13548v1","updated":"2023-11-22T17:44:18Z","published":"2023-11-22T17:44:18Z","title":"Efficient Numerical Integration in Reproducing Kernel Hilbert Spaces via\n  Leverage Scores Sampling","summary":"  In this work we consider the problem of numerical integration, i.e.,\napproximating integrals with respect to a target probability measure using only\npointwise evaluations of the integrand. We focus on the setting in which the\ntarget distribution is only accessible through a set of $n$ i.i.d.\nobservations, and the integrand belongs to a reproducing kernel Hilbert space.\nWe propose an efficient procedure which exploits a small i.i.d. random subset\nof $m<n$ samples drawn either uniformly or using approximate leverage scores\nfrom the initial observations. Our main result is an upper bound on the\napproximation error of this procedure for both sampling strategies. It yields\nsufficient conditions on the subsample size to recover the standard (optimal)\n$n^{-1/2}$ rate while reducing drastically the number of functions evaluations,\nand thus the overall computational cost. Moreover, we obtain rates with respect\nto the number $m$ of evaluations of the integrand which adapt to its\nsmoothness, and match known optimal rates for instance for Sobolev spaces. We\nillustrate our theoretical findings with numerical experiments on real\ndatasets, which highlight the attractive efficiency-accuracy tradeoff of our\nmethod compared to existing randomized and greedy quadrature methods. We note\nthat, the problem of numerical integration in RKHS amounts to designing a\ndiscrete approximation of the kernel mean embedding of the target distribution.\nAs a consequence, direct applications of our results also include the efficient\ncomputation of maximum mean discrepancies between distributions and the design\nof efficient kernel-based tests.\n","authors":["Antoine Chatalic","Nicolas Schreuder","Ernesto De Vito","Lorenzo Rosasco"],"pdf_url":"https://arxiv.org/pdf/2311.13548v1.pdf","comment":"46 pages, 5 figures. Submitted to JMLR"},{"id":"http://arxiv.org/abs/2311.13541v1","updated":"2023-11-22T17:30:41Z","published":"2023-11-22T17:30:41Z","title":"Linear Log-Normal Attention with Unbiased Concentration","summary":"  Transformer models have achieved remarkable results in a wide range of\napplications. However, their scalability is hampered by the quadratic time and\nmemory complexity of the self-attention mechanism concerning the sequence\nlength. This limitation poses a substantial obstacle when dealing with long\ndocuments or high-resolution images. In this work, we study the self-attention\nmechanism by analyzing the distribution of the attention matrix and its\nconcentration ability. Furthermore, we propose instruments to measure these\nquantities and introduce a novel self-attention mechanism, Linear Log-Normal\nAttention, designed to emulate the distribution and concentration behavior of\nthe original self-attention. Our experimental results on popular natural\nlanguage benchmarks reveal that our proposed Linear Log-Normal Attention\noutperforms other linearized attention alternatives, offering a promising\navenue for enhancing the scalability of transformer models. Our code is\navailable in supplementary materials.\n","authors":["Yury Nahshan","Joseph Kampeas","Emir Haleva"],"pdf_url":"https://arxiv.org/pdf/2311.13541v1.pdf","comment":"22 pages, 20 figures, 5 tables, submitted to ICLR2024"},{"id":"http://arxiv.org/abs/2311.13539v1","updated":"2023-11-22T17:26:54Z","published":"2023-11-22T17:26:54Z","title":"Learned Nonlinear Predictor for Critically Sampled 3D Point Cloud\n  Attribute Compression","summary":"  We study 3D point cloud attribute compression via a volumetric approach:\nassuming point cloud geometry is known at both encoder and decoder, parameters\n$\\theta$ of a continuous attribute function $f: \\mathbb{R}^3 \\mapsto\n\\mathbb{R}$ are quantized to $\\hat{\\theta}$ and encoded, so that discrete\nsamples $f_{\\hat{\\theta}}(\\mathbf{x}_i)$ can be recovered at known 3D points\n$\\mathbf{x}_i \\in \\mathbb{R}^3$ at the decoder. Specifically, we consider a\nnested sequences of function subspaces $\\mathcal{F}^{(p)}_{l_0} \\subseteq\n\\cdots \\subseteq \\mathcal{F}^{(p)}_L$, where $\\mathcal{F}_l^{(p)}$ is a family\nof functions spanned by B-spline basis functions of order $p$, $f_l^*$ is the\nprojection of $f$ on $\\mathcal{F}_l^{(p)}$ and encoded as low-pass coefficients\n$F_l^*$, and $g_l^*$ is the residual function in orthogonal subspace\n$\\mathcal{G}_l^{(p)}$ (where $\\mathcal{G}_l^{(p)} \\oplus \\mathcal{F}_l^{(p)} =\n\\mathcal{F}_{l+1}^{(p)}$) and encoded as high-pass coefficients $G_l^*$. In\nthis paper, to improve coding performance over [1], we study predicting\n$f_{l+1}^*$ at level $l+1$ given $f_l^*$ at level $l$ and encoding of $G_l^*$\nfor the $p=1$ case (RAHT($1$)). For the prediction, we formalize RAHT(1) linear\nprediction in MPEG-PCC in a theoretical framework, and propose a new nonlinear\npredictor using a polynomial of bilateral filter. We derive equations to\nefficiently compute the critically sampled high-pass coefficients $G_l^*$\namenable to encoding. We optimize parameters in our resulting feed-forward\nnetwork on a large training set of point clouds by minimizing a rate-distortion\nLagrangian. Experimental results show that our improved framework outperformed\nthe MPEG G-PCC predictor by $11$ to $12\\%$ in bit rate reduction.\n","authors":["Tam Thuc Do","Philip A. Chou","Gene Cheung"],"pdf_url":"https://arxiv.org/pdf/2311.13539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02921v3","updated":"2023-11-22T17:26:08Z","published":"2023-11-06T07:28:16Z","title":"Edge2Node: Reducing Edge Prediction to Node Classification","summary":"  Despite the success of graph neural network models in node classification,\nedge prediction (the task of predicting missing or potential links between\nnodes in a graph) remains a challenging problem for these models. A common\napproach for edge prediction is to first obtain the embeddings of two nodes,\nand then a predefined scoring function is used to predict the existence of an\nedge between the two nodes. Here, we introduce a preliminary idea called\nEdge2Node which suggests to directly obtain an embedding for each edge, without\nthe need for a scoring function. This idea wants to create a new graph H based\non the graph G given for the edge prediction task, and then suggests reducing\nthe edge prediction task on G to a node classification task on H. We anticipate\nthat this introductory method could stimulate further investigations for edge\nprediction task.\n","authors":["Zahed Rahmati"],"pdf_url":"https://arxiv.org/pdf/2311.02921v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13538v1","updated":"2023-11-22T17:24:21Z","published":"2023-11-22T17:24:21Z","title":"Speak Like a Native: Prompting Large Language Models in a Native Style","summary":"  Existing work has found that the prompt engineering heavily influences the\nperformance of large language models (LLMs). Chain-of-thought (CoT), as a\npopular prompt engineering technique, prompted LLMs using in-context examples\nwith reasoning steps. In current studies, the few-shot examples of CoT are\ngenerally handcrafted by humans. However, how the text style of in-context\nexamples influence the outputs of LLMs still remains under-explored. This paper\npresents a novel and effective approach, named \\textbf{AlignCoT}, to improve\nthe reasoning capability of LLMs by aligning the in-context examples with the\nnative style of LLMs. ``Native'' refers to the inherent characteristic style of\nLLMs which can be probed by original zero-shot scenarios. AlignCoT is\northogonal to other prompt engineering methods, making it easy to combine with\nstate-of-the-art techniques to further improve the LLMs' performance. We\nconduct extensive and comprehensive experiments on several benchmarks. The\nempirical results demonstrate that our AlignCoTsignificantly improves\nperformance over the carefully handcrafted in-context examples. For instance,\nwith GPT-3.5-turbo, we observed a +2.5\\% improvement on GSM8K. Furthermore, our\nAlignCoT consistently improve the performance when combined with other\nstate-of-the-art prompt engineering methods. The source code and dataset will\nbe available at\n\\href{https://github.com/yangzhch6/AlignCoT}{https://github.com/yangzhch6/AlignCoT}.\n","authors":["Zhicheng Yang","Yiwei Wang","Yinya Huang","Jing Xiong","Xiaodan Liang","Jing Tang"],"pdf_url":"https://arxiv.org/pdf/2311.13538v1.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.13531v1","updated":"2023-11-22T17:06:57Z","published":"2023-11-22T17:06:57Z","title":"Leveraging CNNs and Ensemble Learning for Automated Disaster Image\n  Classification","summary":"  Natural disasters act as a serious threat globally, requiring effective and\nefficient disaster management and recovery. This paper focuses on classifying\nnatural disaster images using Convolutional Neural Networks (CNNs). Multiple\nCNN architectures were built and trained on a dataset containing images of\nearthquakes, floods, wildfires, and volcanoes. A stacked CNN ensemble approach\nproved to be the most effective, achieving 95% accuracy and an F1 score going\nup to 0.96 for individual classes. Tuning hyperparameters of individual models\nfor optimization was critical to maximize the models' performance. The stacking\nof CNNs with XGBoost acting as the meta-model utilizes the strengths of the CNN\nand ResNet models to improve the overall accuracy of the classification.\nResults obtained from the models illustrated the potency of CNN-based models\nfor automated disaster image classification. This lays the foundation for\nexpanding these techniques to build robust systems for disaster response,\ndamage assessment, and recovery management.\n","authors":["Archit Rathod","Veer Pariawala","Mokshit Surana","Kumkum Saxena"],"pdf_url":"https://arxiv.org/pdf/2311.13531v1.pdf","comment":"13 pages, 11 figures, 4 tables, ICSISCET 2023 Conference"},{"id":"http://arxiv.org/abs/2311.11772v2","updated":"2023-11-22T17:06:31Z","published":"2023-11-20T13:58:26Z","title":"A Good Feature Extractor Is All You Need for Weakly Supervised Learning\n  in Histopathology","summary":"  Deep learning is revolutionising pathology, offering novel opportunities in\ndisease prognosis and personalised treatment. Historically, stain normalisation\nhas been a crucial preprocessing step in computational pathology pipelines, and\npersists into the deep learning era. Yet, with the emergence of feature\nextractors trained using self-supervised learning (SSL) on diverse pathology\ndatasets, we call this practice into question. In an empirical evaluation of\npublicly available feature extractors, we find that omitting stain\nnormalisation and image augmentations does not compromise downstream\nperformance, while incurring substantial savings in memory and compute.\nFurther, we show that the top-performing feature extractors are remarkably\nrobust to variations in stain and augmentations like rotation in their latent\nspace. Contrary to previous patch-level benchmarking studies, our approach\nemphasises clinical relevance by focusing on slide-level prediction tasks in a\nweakly supervised setting with external validation cohorts. This work\nrepresents the most comprehensive robustness evaluation of public pathology SSL\nfeature extractors to date, involving more than 6,000 training runs across nine\ntasks, five datasets, three downstream architectures, and various preprocessing\nsetups. Our findings stand to streamline digital pathology workflows by\nminimising preprocessing needs and informing the selection of feature\nextractors.\n","authors":["Georg Wölflein","Dyke Ferber","Asier Rabasco Meneghetti","Omar S. M. El Nahhas","Daniel Truhn","Zunamys I. Carrero","David J. Harrison","Ognjen Arandjelović","Jakob N. Kather"],"pdf_url":"https://arxiv.org/pdf/2311.11772v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.12261v4","updated":"2023-11-22T16:59:55Z","published":"2022-07-06T13:56:48Z","title":"GraphCFC: A Directed Graph Based Cross-Modal Feature Complementation\n  Approach for Multimodal Conversational Emotion Recognition","summary":"  Emotion Recognition in Conversation (ERC) plays a significant part in\nHuman-Computer Interaction (HCI) systems since it can provide empathetic\nservices. Multimodal ERC can mitigate the drawbacks of uni-modal approaches.\nRecently, Graph Neural Networks (GNNs) have been widely used in a variety of\nfields due to their superior performance in relation modeling. In multimodal\nERC, GNNs are capable of extracting both long-distance contextual information\nand inter-modal interactive information. Unfortunately, since existing methods\nsuch as MMGCN directly fuse multiple modalities, redundant information may be\ngenerated and diverse information may be lost. In this work, we present a\ndirected Graph based Cross-modal Feature Complementation (GraphCFC) module that\ncan efficiently model contextual and interactive information. GraphCFC\nalleviates the problem of heterogeneity gap in multimodal fusion by utilizing\nmultiple subspace extractors and Pair-wise Cross-modal Complementary (PairCC)\nstrategy. We extract various types of edges from the constructed graph for\nencoding, thus enabling GNNs to extract crucial contextual and interactive\ninformation more accurately when performing message passing. Furthermore, we\ndesign a GNN structure called GAT-MLP, which can provide a new unified network\nframework for multimodal learning. The experimental results on two benchmark\ndatasets show that our GraphCFC outperforms the state-of-the-art (SOTA)\napproaches.\n","authors":["Jiang Li","Xiaoping Wang","Guoqing Lv","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2207.12261v4.pdf","comment":"Accepted by IEEE Transactions on Multimedia (TMM)"},{"id":"http://arxiv.org/abs/2311.13508v1","updated":"2023-11-22T16:34:12Z","published":"2023-11-22T16:34:12Z","title":"Naturalness of Attention: Revisiting Attention in Code Language Models","summary":"  Language models for code such as CodeBERT offer the capability to learn\nadvanced source code representation, but their opacity poses barriers to\nunderstanding of captured properties. Recent attention analysis studies provide\ninitial interpretability insights by focusing solely on attention weights\nrather than considering the wider context modeling of Transformers. This study\naims to shed some light on the previously ignored factors of the attention\nmechanism beyond the attention weights. We conduct an initial empirical study\nanalyzing both attention distributions and transformed representations in\nCodeBERT. Across two programming languages, Java and Python, we find that the\nscaled transformation norms of the input better capture syntactic structure\ncompared to attention weights alone. Our analysis reveals characterization of\nhow CodeBERT embeds syntactic code properties. The findings demonstrate the\nimportance of incorporating factors beyond just attention weights for\nrigorously understanding neural code models. This lays the groundwork for\ndeveloping more interpretable models and effective uses of attention mechanisms\nin program analysis.\n","authors":["Mootez Saad","Tushar Sharma"],"pdf_url":"https://arxiv.org/pdf/2311.13508v1.pdf","comment":"Accepted at ICSE-NIER (2024) track"},{"id":"http://arxiv.org/abs/2311.13507v1","updated":"2023-11-22T16:34:06Z","published":"2023-11-22T16:34:06Z","title":"Applying Dimensionality Reduction as Precursor to LSTM-CNN Models for\n  Classifying Imagery and Motor Signals in ECoG-Based BCIs","summary":"  Motor impairments, frequently caused by neurological incidents like strokes\nor traumatic brain injuries, present substantial obstacles in rehabilitation\ntherapy. This research aims to elevate the field by optimizing motor imagery\nclassification algorithms within Brain-Computer Interfaces (BCIs). By improving\nthe efficiency of BCIs, we offer a novel approach that holds significant\npromise for enhancing motor rehabilitation outcomes. Utilizing unsupervised\ntechniques for dimensionality reduction, namely Uniform Manifold Approximation\nand Projection (UMAP) coupled with K-Nearest Neighbors (KNN), we evaluate the\nnecessity of employing supervised methods such as Long Short-Term Memory (LSTM)\nand Convolutional Neural Networks (CNNs) for classification tasks. Importantly,\nparticipants who exhibited high KNN scores following UMAP dimensionality\nreduction also achieved high accuracy in supervised deep learning (DL) models.\nDue to individualized model requirements and massive neural training data,\ndimensionality reduction becomes an effective preprocessing step that minimizes\nthe need for extensive data labeling and supervised deep learning techniques.\nThis approach has significant implications not only for targeted therapies in\nmotor dysfunction but also for addressing regulatory, safety, and reliability\nconcerns in the rapidly evolving BCI field.\n","authors":["Soham Bafana"],"pdf_url":"https://arxiv.org/pdf/2311.13507v1.pdf","comment":"10 Pages, 12 Figures. The dataset used in this paper can be found\n  here: https://osf.io/ksqv8/download, from the Miller 2010 paper. All code\n  used in this research can be found at\n  https://github.com/bafanaS/dim-reduction-with-cnn-lstm.git"},{"id":"http://arxiv.org/abs/2311.13502v1","updated":"2023-11-22T16:20:24Z","published":"2023-11-22T16:20:24Z","title":"Bitformer: An efficient Transformer with bitwise operation-based\n  attention for Big Data Analytics at low-cost low-precision devices","summary":"  In the current landscape of large models, the Transformer stands as a\ncornerstone, playing a pivotal role in shaping the trajectory of modern models.\nHowever, its application encounters challenges attributed to the substantial\ncomputational intricacies intrinsic to its attention mechanism. Moreover, its\nreliance on high-precision floating-point operations presents specific hurdles,\nparticularly evident in computation-intensive scenarios such as edge computing\nenvironments. These environments, characterized by resource-constrained devices\nand a preference for lower precision, necessitate innovative solutions.\n  To tackle the exacting data processing demands posed by edge devices, we\nintroduce the Bitformer model, an inventive extension of the Transformer\nparadigm. Central to this innovation is a novel attention mechanism that\nadeptly replaces conventional floating-point matrix multiplication with bitwise\noperations. This strategic substitution yields dual advantages. Not only does\nit maintain the attention mechanism's prowess in capturing intricate long-range\ninformation dependencies, but it also orchestrates a profound reduction in the\ncomputational complexity inherent in the attention operation. The transition\nfrom an $O(n^2d)$ complexity, typical of floating-point operations, to an\n$O(n^2T)$ complexity characterizing bitwise operations, substantiates this\nadvantage. Notably, in this context, the parameter $T$ remains markedly smaller\nthan the conventional dimensionality parameter $d$.\n  The Bitformer model in essence endeavors to reconcile the indomitable\nrequirements of modern computing landscapes with the constraints posed by edge\ncomputing scenarios. By forging this innovative path, we bridge the gap between\nhigh-performing models and resource-scarce environments, thus unveiling a\npromising trajectory for further advancements in the field.\n","authors":["Gaoxiang Duan","Junkai Zhang","Xiaoying Zheng","Yongxin Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.13502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13495v1","updated":"2023-11-22T16:12:42Z","published":"2023-11-22T16:12:42Z","title":"Current Topological and Machine Learning Applications for Bias Detection\n  in Text","summary":"  Institutional bias can impact patient outcomes, educational attainment, and\nlegal system navigation. Written records often reflect bias, and once bias is\nidentified; it is possible to refer individuals for training to reduce bias.\nMany machine learning tools exist to explore text data and create predictive\nmodels that can search written records to identify real-time bias. However, few\nprevious studies investigate large language model embeddings and geometric\nmodels of biased text data to understand geometry's impact on bias modeling\naccuracy. To overcome this issue, this study utilizes the RedditBias database\nto analyze textual biases. Four transformer models, including BERT and RoBERTa\nvariants, were explored. Post-embedding, t-SNE allowed two-dimensional\nvisualization of data. KNN classifiers differentiated bias types, with lower\nk-values proving more effective. Findings suggest BERT, particularly mini BERT,\nexcels in bias classification, while multilingual models lag. The\nrecommendation emphasizes refining monolingual models and exploring\ndomain-specific biases.\n","authors":["Colleen Farrelly","Yashbir Singh","Quincy A. Hathaway","Gunnar Carlsson","Ashok Choudhary","Rahul Paul","Gianfranco Doretto","Yassine Himeur","Shadi Atalls","Wathiq Mansoor"],"pdf_url":"https://arxiv.org/pdf/2311.13495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19680v3","updated":"2023-11-22T16:12:39Z","published":"2023-10-30T16:00:13Z","title":"Integrating Pre-trained Language Model into Neural Machine Translation","summary":"  Neural Machine Translation (NMT) has become a significant technology in\nnatural language processing through extensive research and development.\nHowever, the deficiency of high-quality bilingual language pair data still\nposes a major challenge to improving NMT performance. Recent studies have been\nexploring the use of contextual information from pre-trained language model\n(PLM) to address this problem. Yet, the issue of incompatibility between PLM\nand NMT model remains unresolved. This study proposes PLM-integrated NMT\n(PiNMT) model to overcome the identified problems. PiNMT model consists of\nthree critical components, PLM Multi Layer Converter, Embedding Fusion, and\nCosine Alignment, each playing a vital role in providing effective PLM\ninformation to NMT. Furthermore, two training strategies, Separate Learning\nRates and Dual Step Training, are also introduced in this paper. By\nimplementing the proposed PiNMT model and training strategy, we achieve\nstate-of-the-art performance on the IWSLT'14 En$\\leftrightarrow$De dataset.\nThis study's outcomes are noteworthy as they demonstrate a novel approach for\nefficiently integrating PLM with NMT to overcome incompatibility and enhance\nperformance.\n","authors":["Soon-Jae Hwang","Chang-Sung Jeong"],"pdf_url":"https://arxiv.org/pdf/2310.19680v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13491v1","updated":"2023-11-22T16:08:38Z","published":"2023-11-22T16:08:38Z","title":"Grad-Shafranov equilibria via data-free physics informed neural networks","summary":"  A large number of magnetohydrodynamic (MHD) equilibrium calculations are\noften required for uncertainty quantification, optimization, and real-time\ndiagnostic information, making MHD equilibrium codes vital to the field of\nplasma physics. In this paper, we explore a method for solving the\nGrad-Shafranov equation by using Physics-Informed Neural Networks (PINNs). For\nPINNs, we optimize neural networks by directly minimizing the residual of the\nPDE as a loss function. We show that PINNs can accurately and effectively solve\nthe Grad-Shafranov equation with several different boundary conditions. We also\nexplore the parameter space by varying the size of the model, the learning\nrate, and boundary conditions to map various trade-offs such as between\nreconstruction error and computational speed. Additionally, we introduce a\nparameterized PINN framework, expanding the input space to include variables\nsuch as pressure, aspect ratio, elongation, and triangularity in order to\nhandle a broader range of plasma scenarios within a single network.\nParametrized PINNs could be used in future work to solve inverse problems such\nas shape optimization.\n","authors":["Byoungchan Jang","Alan A. Kaptanoglu","Rahul Gaur","Shaw Pan","Matt Landreman","William Dorland"],"pdf_url":"https://arxiv.org/pdf/2311.13491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13490v1","updated":"2023-11-22T16:07:32Z","published":"2023-11-22T16:07:32Z","title":"Benchmarking Toxic Molecule Classification using Graph Neural Networks\n  and Few Shot Learning","summary":"  Traditional methods like Graph Convolutional Networks (GCNs) face challenges\nwith limited data and class imbalance, leading to suboptimal performance in\ngraph classification tasks during toxicity prediction of molecules as a whole.\nTo address these issues, we harness the power of Graph Isomorphic Networks,\nMulti Headed Attention and Free Large-scale Adversarial Augmentation separately\non Graphs for precisely capturing the structural data of molecules and their\ntoxicological properties. Additionally, we incorporate Few-Shot Learning to\nimprove the model's generalization with limited annotated samples. Extensive\nexperiments on a diverse toxicology dataset demonstrate that our method\nachieves an impressive state-of-art AUC-ROC value of 0.816, surpassing the\nbaseline GCN model by 11.4%. This highlights the significance of our proposed\nmethodology and Few Shot Learning in advancing Toxic Molecular Classification,\nwith the potential to enhance drug discovery and environmental risk assessment\nprocesses.\n","authors":["Bhavya Mehta","Kush Kothari","Reshmika Nambiar","Seema Shrawne"],"pdf_url":"https://arxiv.org/pdf/2311.13490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13485v1","updated":"2023-11-22T16:01:44Z","published":"2023-11-22T16:01:44Z","title":"Deep-learning-based acceleration of MRI for radiotherapy planning of\n  pediatric patients with brain tumors","summary":"  Magnetic Resonance Imaging (MRI) is a non-invasive diagnostic and\nradiotherapy (RT) planning tool, offering detailed insights into the anatomy of\nthe human body. The extensive scan time is stressful for patients, who must\nremain motionless in a prolonged imaging procedure that prioritizes reduction\nof imaging artifacts. This is challenging for pediatric patients who may\nrequire measures for managing voluntary motions such as anesthesia. Several\ncomputational approaches reduce scan time (fast MRI), by recording fewer\nmeasurements and digitally recovering full information via post-acquisition\nreconstruction. However, most fast MRI approaches were developed for diagnostic\nimaging, without addressing reconstruction challenges specific to RT planning.\nIn this work, we developed a deep learning-based method (DeepMRIRec) for MRI\nreconstruction from undersampled data acquired with RT-specific receiver coil\narrangements. We evaluated our method against fully sampled data of T1-weighted\nMR images acquired from 73 children with brain tumors/surgical beds using loop\nand posterior coils (12 channels), with and without applying virtual\ncompression of coil elements. DeepMRIRec reduced scanning time by a factor of\nfour producing a structural similarity score surpassing the evaluated\nstate-of-the-art method (0.960 vs 0.896), thereby demonstrating its potential\nfor accelerating MRI scanning for RT planning.\n","authors":["Shahinur Alam","Jinsoo Uh","Alexander Dresner","Chia-ho Hua","Khaled Khairy"],"pdf_url":"https://arxiv.org/pdf/2311.13485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13475v1","updated":"2023-11-22T15:42:51Z","published":"2023-11-22T15:42:51Z","title":"Machine Translation to Control Formality Features in the Target Language","summary":"  Formality plays a significant role in language communication, especially in\nlow-resource languages such as Hindi, Japanese and Korean. These languages\nutilise formal and informal expressions to convey messages based on social\ncontexts and relationships. When a language translation technique is used to\ntranslate from a source language that does not pertain the formality (e.g.\nEnglish) to a target language that does, there is a missing information on\nformality that could be a challenge in producing an accurate outcome. This\nresearch explores how this issue should be resolved when machine learning\nmethods are used to translate from English to languages with formality, using\nHindi as the example data. This was done by training a bilingual model in a\nformality-controlled setting and comparing its performance with a pre-trained\nmultilingual model in a similar setting. Since there are not a lot of training\ndata with ground truth, automated annotation techniques were employed to\nincrease the data size. The primary modeling approach involved leveraging\ntransformer models, which have demonstrated effectiveness in various natural\nlanguage processing tasks. We evaluate the official formality accuracy(ACC) by\ncomparing the predicted masked tokens with the ground truth. This metric\nprovides a quantitative measure of how well the translations align with the\ndesired outputs. Our study showcases a versatile translation strategy that\nconsiders the nuances of formality in the target language, catering to diverse\nlanguage communication needs and scenarios.\n","authors":["Harshita Tyagi","Prashasta Jung","Hyowon Lee"],"pdf_url":"https://arxiv.org/pdf/2311.13475v1.pdf","comment":"9 pages, based on DCU MCM Practicum 2022/2023"},{"id":"http://arxiv.org/abs/2306.16430v2","updated":"2023-11-22T15:39:14Z","published":"2023-06-28T15:21:27Z","title":"DNA-TEQ: An Adaptive Exponential Quantization of Tensors for DNN\n  Inference","summary":"  Quantization is commonly used in Deep Neural Networks (DNNs) to reduce the\nstorage and computational complexity by decreasing the arithmetical precision\nof activations and weights, a.k.a. tensors. Efficient hardware architectures\nemploy linear quantization to enable the deployment of recent DNNs onto\nembedded systems and mobile devices. However, linear uniform quantization\ncannot usually reduce the numerical precision to less than 8 bits without\nsacrificing high performance in terms of model accuracy. The performance loss\nis due to the fact that tensors do not follow uniform distributions. In this\npaper, we show that a significant amount of tensors fit into an exponential\ndistribution. Then, we propose DNA-TEQ to exponentially quantize DNN tensors\nwith an adaptive scheme that achieves the best trade-off between numerical\nprecision and accuracy loss. The experimental results show that DNA-TEQ\nprovides a much lower quantization bit-width compared to previous proposals,\nresulting in an average compression ratio of 40% over the linear INT8 baseline,\nwith negligible accuracy loss and without retraining the DNNs. Besides, DNA-TEQ\nleads the way in performing dot-product operations in the exponential domain,\nwhich saves 66% of energy consumption on average for a set of widely used DNNs.\n","authors":["Bahareh Khabbazan","Marc Riera","Antonio González"],"pdf_url":"https://arxiv.org/pdf/2306.16430v2.pdf","comment":"10 pages, 8 figures, 5 tables"},{"id":"http://arxiv.org/abs/2305.13318v2","updated":"2023-11-22T15:38:47Z","published":"2023-05-12T14:21:14Z","title":"A principled deep learning approach for geological facies generation","summary":"  The simulation of geological facies in an unobservable volume is essential in\nvarious geoscience applications. Given the complexity of the problem, deep\ngenerative learning is a promising approach to overcome the limitations of\ntraditional geostatistical simulation models, in particular their lack of\nphysical realism. This research aims to investigate the application of\ngenerative adversarial networks and deep variational inference for\nconditionally simulating meandering channels in underground volumes. In this\npaper, we review the generative deep learning approaches, in particular the\nadversarial ones and the stabilization techniques that aim to facilitate their\ntraining. The proposed approach is tested on 2D and 3D simulations generated by\nthe stochastic process-based model Flumy. Morphological metrics are utilized to\ncompare our proposed method with earlier iterations of generative adversarial\nnetworks. The results indicate that by utilizing recent stabilization\ntechniques, generative adversarial networks can efficiently sample from target\ndata distributions. Moreover, we demonstrate the ability to simulate\nconditioned simulations through the latent variable model property of the\nproposed approach.\n","authors":["Ferdinand Bhavsar","Nicolas Desassis","Fabien Ors","Thomas Romary"],"pdf_url":"https://arxiv.org/pdf/2305.13318v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13471v1","updated":"2023-11-22T15:35:56Z","published":"2023-11-22T15:35:56Z","title":"Comparative Analysis of Linear Regression, Gaussian Elimination, and LU\n  Decomposition for CT Real Estate Purchase Decisions","summary":"  This paper presents a comprehensive evaluation of three distinct\ncomputational algorithms applied to the decision-making process of real estate\npurchases. Specifically, we analyze the efficacy of Linear Regression from\nScikit-learn library, Gaussian Elimination with partial pivoting, and LU\nDecomposition in predicting the advisability of buying a house in the State of\nConnecticut based on a set of financial and market-related parameters. The\nalgorithms' performances were compared using a dataset encompassing\ntown-specific details, yearly data, interest rates, and median sale ratios. Our\nresults demonstrate significant differences in predictive accuracy, with Linear\nRegression and LU Decomposition providing the most reliable recommendations and\nGaussian Elimination showing limitations in stability and performance. The\nstudy's findings emphasize the importance of algorithm selection in predictive\nanalytic and offer insights into the practical applications of computational\nmethods in real estate investment strategies. By evaluating model efficacy\nthrough metrics such as R-squared scores and Mean Squared Error, we provide a\nnuanced understanding of each method's strengths and weaknesses, contributing\nvaluable knowledge to the fields of real estate analysis and predictive\nmodeling.\n","authors":["Xilin Cheng"],"pdf_url":"https://arxiv.org/pdf/2311.13471v1.pdf","comment":"5 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.13469v1","updated":"2023-11-22T15:34:44Z","published":"2023-11-22T15:34:44Z","title":"Span-Based Optimal Sample Complexity for Average Reward MDPs","summary":"  We study the sample complexity of learning an $\\varepsilon$-optimal policy in\nan average-reward Markov decision process (MDP) under a generative model. We\nestablish the complexity bound $\\widetilde{O}\\left(SA\\frac{H}{\\varepsilon^2}\n\\right)$, where $H$ is the span of the bias function of the optimal policy and\n$SA$ is the cardinality of the state-action space. Our result is the first that\nis minimax optimal (up to log factors) in all parameters $S,A,H$ and\n$\\varepsilon$, improving on existing work that either assumes uniformly bounded\nmixing times for all policies or has suboptimal dependence on the parameters.\n  Our result is based on reducing the average-reward MDP to a discounted MDP.\nTo establish the optimality of this reduction, we develop improved bounds for\n$\\gamma$-discounted MDPs, showing that\n$\\widetilde{O}\\left(SA\\frac{H}{(1-\\gamma)^2\\varepsilon^2} \\right)$ samples\nsuffice to learn a $\\varepsilon$-optimal policy in weakly communicating MDPs\nunder the regime that $\\gamma \\geq 1 - \\frac{1}{H}$, circumventing the\nwell-known lower bound of\n$\\widetilde{\\Omega}\\left(SA\\frac{1}{(1-\\gamma)^3\\varepsilon^2} \\right)$ for\ngeneral $\\gamma$-discounted MDPs. Our analysis develops upper bounds on certain\ninstance-dependent variance parameters in terms of the span parameter. These\nbounds are tighter than those based on the mixing time or diameter of the MDP\nand may be of broader use.\n","authors":["Matthew Zurek","Yudong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13469v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2311.13466v1","updated":"2023-11-22T15:32:31Z","published":"2023-11-22T15:32:31Z","title":"Accelerating Inference in Molecular Diffusion Models with Latent\n  Representations of Protein Structure","summary":"  Diffusion generative models have emerged as a powerful framework for\naddressing problems in structural biology and structure-based drug design.\nThese models operate directly on 3D molecular structures. Due to the\nunfavorable scaling of graph neural networks (GNNs) with graph size as well as\nthe relatively slow inference speeds inherent to diffusion models, many\nexisting molecular diffusion models rely on coarse-grained representations of\nprotein structure to make training and inference feasible. However, such\ncoarse-grained representations discard essential information for modeling\nmolecular interactions and impair the quality of generated structures. In this\nwork, we present a novel GNN-based architecture for learning latent\nrepresentations of molecular structure. When trained end-to-end with a\ndiffusion model for de novo ligand design, our model achieves comparable\nperformance to one with an all-atom protein representation while exhibiting a\n3-fold reduction in inference time.\n","authors":["Ian Dunn","David Ryan Koes"],"pdf_url":"https://arxiv.org/pdf/2311.13466v1.pdf","comment":"This paper appeared as a spotlight paper at the NeurIPS 2023\n  Generative AI and Biology Workshop"},{"id":"http://arxiv.org/abs/2311.13460v1","updated":"2023-11-22T15:24:36Z","published":"2023-11-22T15:24:36Z","title":"Multi-Objective Bayesian Optimization with Active Preference Learning","summary":"  There are a lot of real-world black-box optimization problems that need to\noptimize multiple criteria simultaneously. However, in a multi-objective\noptimization (MOO) problem, identifying the whole Pareto front requires the\nprohibitive search cost, while in many practical scenarios, the decision maker\n(DM) only needs a specific solution among the set of the Pareto optimal\nsolutions. We propose a Bayesian optimization (BO) approach to identifying the\nmost preferred solution in the MOO with expensive objective functions, in which\na Bayesian preference model of the DM is adaptively estimated by an interactive\nmanner based on the two types of supervisions called the pairwise preference\nand improvement request. To explore the most preferred solution, we define an\nacquisition function in which the uncertainty both in the objective functions\nand the DM preference is incorporated. Further, to minimize the interaction\ncost with the DM, we also propose an active learning strategy for the\npreference estimation. We empirically demonstrate the effectiveness of our\nproposed method through the benchmark function optimization and the\nhyper-parameter optimization problems for machine learning models.\n","authors":["Ryota Ozaki","Kazuki Ishikawa","Youhei Kanzaki","Shinya Suzuki","Shion Takeno","Ichiro Takeuchi","Masayuki Karasuyama"],"pdf_url":"https://arxiv.org/pdf/2311.13460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13459v1","updated":"2023-11-22T15:24:29Z","published":"2023-11-22T15:24:29Z","title":"The Tempered Hilbert Simplex Distance and Its Application To Non-linear\n  Embeddings of TEMs","summary":"  Tempered Exponential Measures (TEMs) are a parametric generalization of the\nexponential family of distributions maximizing the tempered entropy function\namong positive measures subject to a probability normalization of their power\ndensities. Calculus on TEMs relies on a deformed algebra of arithmetic\noperators induced by the deformed logarithms used to define the tempered\nentropy. In this work, we introduce three different parameterizations of finite\ndiscrete TEMs via Legendre functions of the negative tempered entropy function.\nIn particular, we establish an isometry between such parameterizations in terms\nof a generalization of the Hilbert log cross-ratio simplex distance to a\ntempered Hilbert co-simplex distance. Similar to the Hilbert geometry, the\ntempered Hilbert distance is characterized as a $t$-symmetrization of the\noriented tempered Funk distance. We motivate our construction by introducing\nthe notion of $t$-lengths of smooth curves in a tautological Finsler manifold.\nWe then demonstrate the properties of our generalized structure in different\nsettings and numerically examine the quality of its differentiable\napproximations for optimization in machine learning settings.\n","authors":["Ehsan Amid","Frank Nielsen","Richard Nock","Manfred K. Warmuth"],"pdf_url":"https://arxiv.org/pdf/2311.13459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02931v3","updated":"2023-11-22T15:23:44Z","published":"2022-12-06T12:40:45Z","title":"Leveraging Different Learning Styles for Improved Knowledge Distillation\n  in Biomedical Imaging","summary":"  Learning style refers to a type of training mechanism adopted by an\nindividual to gain new knowledge. As suggested by the VARK model, humans have\ndifferent learning preferences, like Visual (V), Auditory (A), Read/Write (R),\nand Kinesthetic (K), for acquiring and effectively processing information. Our\nwork endeavors to leverage this concept of knowledge diversification to improve\nthe performance of model compression techniques like Knowledge Distillation\n(KD) and Mutual Learning (ML). Consequently, we use a single-teacher and\ntwo-student network in a unified framework that not only allows for the\ntransfer of knowledge from teacher to students (KD) but also encourages\ncollaborative learning between students (ML). Unlike the conventional approach,\nwhere the teacher shares the same knowledge in the form of predictions or\nfeature representations with the student network, our proposed approach employs\na more diversified strategy by training one student with predictions and the\nother with feature maps from the teacher. We further extend this knowledge\ndiversification by facilitating the exchange of predictions and feature maps\nbetween the two student networks, enriching their learning experiences. We have\nconducted comprehensive experiments with three benchmark datasets for both\nclassification and segmentation tasks using two different network architecture\ncombinations. These experimental results demonstrate that knowledge\ndiversification in a combined KD and ML framework outperforms conventional KD\nor ML techniques (with similar network configuration) that only use predictions\nwith an average improvement of 2%. Furthermore, consistent improvement in\nperformance across different tasks, with various network architectures, and\nover state-of-the-art techniques establishes the robustness and\ngeneralizability of the proposed model\n","authors":["Usma Niyaz","Abhishek Singh Sambyal","Deepti R. Bathula"],"pdf_url":"https://arxiv.org/pdf/2212.02931v3.pdf","comment":"Accepted in Computers in Biology and Medicine"},{"id":"http://arxiv.org/abs/2311.13454v1","updated":"2023-11-22T15:20:12Z","published":"2023-11-22T15:20:12Z","title":"Explaining high-dimensional text classifiers","summary":"  Explainability has become a valuable tool in the last few years, helping\nhumans better understand AI-guided decisions. However, the classic\nexplainability tools are sometimes quite limited when considering\nhigh-dimensional inputs and neural network classifiers. We present a new\nexplainability method using theoretically proven high-dimensional properties in\nneural network classifiers. We present two usages of it: 1) On the classical\nsentiment analysis task for the IMDB reviews dataset, and 2) our\nMalware-Detection task for our PowerShell scripts dataset.\n","authors":["Odelia Melamed","Rich Caruana"],"pdf_url":"https://arxiv.org/pdf/2311.13454v1.pdf","comment":"Accepted to \"XAI in Action\" workshop @ NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.13447v1","updated":"2023-11-22T15:12:42Z","published":"2023-11-22T15:12:42Z","title":"Differentially Private Non-Convex Optimization under the KL Condition\n  with Optimal Rates","summary":"  We study private empirical risk minimization (ERM) problem for losses\nsatisfying the $(\\gamma,\\kappa)$-Kurdyka-{\\L}ojasiewicz (KL) condition. The\nPolyak-{\\L}ojasiewicz (PL) condition is a special case of this condition when\n$\\kappa=2$. Specifically, we study this problem under the constraint of $\\rho$\nzero-concentrated differential privacy (zCDP). When $\\kappa\\in[1,2]$ and the\nloss function is Lipschitz and smooth over a sufficiently large region, we\nprovide a new algorithm based on variance reduced gradient descent that\nachieves the rate\n$\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^\\kappa\\big)$ on the\nexcess empirical risk, where $n$ is the dataset size and $d$ is the dimension.\nWe further show that this rate is nearly optimal. When $\\kappa \\geq 2$ and the\nloss is instead Lipschitz and weakly convex, we show it is possible to achieve\nthe rate $\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^\\kappa\\big)$\nwith a private implementation of the proximal point method. When the KL\nparameters are unknown, we provide a novel modification and analysis of the\nnoisy gradient descent algorithm and show that this algorithm achieves a rate\nof\n$\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^{\\frac{2\\kappa}{4-\\kappa}}\\big)$\nadaptively, which is nearly optimal when $\\kappa = 2$. We further show that,\nwithout assuming the KL condition, the same gradient descent algorithm can\nachieve fast convergence to a stationary point when the gradient stays\nsufficiently large during the run of the algorithm. Specifically, we show that\nthis algorithm can approximate stationary points of Lipschitz, smooth (and\npossibly nonconvex) objectives with rate as fast as\n$\\tilde{O}\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)$ and never worse than\n$\\tilde{O}\\big(\\big(\\frac{\\sqrt{d}}{n\\sqrt{\\rho}}\\big)^{1/2}\\big)$. The latter\nrate matches the best known rate for methods that do not rely on variance\nreduction.\n","authors":["Michael Menart","Enayat Ullah","Raman Arora","Raef Bassily","Cristóbal Guzmán"],"pdf_url":"https://arxiv.org/pdf/2311.13447v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13445v1","updated":"2023-11-22T15:11:35Z","published":"2023-11-22T15:11:35Z","title":"Transfer Attacks and Defenses for Large Language Models on Coding Tasks","summary":"  Modern large language models (LLMs), such as ChatGPT, have demonstrated\nimpressive capabilities for coding tasks including writing and reasoning about\ncode. They improve upon previous neural network models of code, such as\ncode2seq or seq2seq, that already demonstrated competitive results when\nperforming tasks such as code summarization and identifying code\nvulnerabilities. However, these previous code models were shown vulnerable to\nadversarial examples, i.e. small syntactic perturbations that do not change the\nprogram's semantics, such as the inclusion of \"dead code\" through false\nconditions or the addition of inconsequential print statements, designed to\n\"fool\" the models. LLMs can also be vulnerable to the same adversarial\nperturbations but a detailed study on this concern has been lacking so far. In\nthis paper we aim to investigate the effect of adversarial perturbations on\ncoding tasks with LLMs. In particular, we study the transferability of\nadversarial examples, generated through white-box attacks on smaller code\nmodels, to LLMs. Furthermore, to make the LLMs more robust against such\nadversaries without incurring the cost of retraining, we propose prompt-based\ndefenses that involve modifying the prompt to include additional information\nsuch as examples of adversarially perturbed code and explicit instructions for\nreversing adversarial perturbations. Our experiments show that adversarial\nexamples obtained with a smaller code model are indeed transferable, weakening\nthe LLMs' performance. The proposed defenses show promise in improving the\nmodel's resilience, paving the way to more robust defensive solutions for LLMs\nin code-related applications.\n","authors":["Chi Zhang","Zifan Wang","Ravi Mangal","Matt Fredrikson","Limin Jia","Corina Pasareanu"],"pdf_url":"https://arxiv.org/pdf/2311.13445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13443v1","updated":"2023-11-22T15:07:59Z","published":"2023-11-22T15:07:59Z","title":"Guided Flows for Generative Modeling and Decision Making","summary":"  Classifier-free guidance is a key component for improving the performance of\nconditional generative models for many downstream tasks. It drastically\nimproves the quality of samples produced, but has so far only been used for\ndiffusion models. Flow Matching (FM), an alternative simulation-free approach,\ntrains Continuous Normalizing Flows (CNFs) based on regressing vector fields.\nIt remains an open question whether classifier-free guidance can be performed\nfor Flow Matching models, and to what extent does it improve performance. In\nthis paper, we explore the usage of Guided Flows for a variety of downstream\napplications involving conditional image generation, speech synthesis, and\nreinforcement learning. In particular, we are the first to apply flow models to\nthe offline reinforcement learning setting. We also show that Guided Flows\nsignificantly improves the sample quality in image generation and zero-shot\ntext-to-speech synthesis, and can make use of drastically low amounts of\ncomputation without affecting the agent's overall performance.\n","authors":["Qinqing Zheng","Matt Le","Neta Shaul","Yaron Lipman","Aditya Grover","Ricky T. Q. Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13434v1","updated":"2023-11-22T14:47:54Z","published":"2023-11-22T14:47:54Z","title":"Recurrent neural networks and transfer learning for elasto-plasticity in\n  woven composites","summary":"  As a surrogate for computationally intensive meso-scale simulation of woven\ncomposites, this article presents Recurrent Neural Network (RNN) models.\nLeveraging the power of transfer learning, the initialization challenges and\nsparse data issues inherent in cyclic shear strain loads are addressed in the\nRNN models. A mean-field model generates a comprehensive data set representing\nelasto-plastic behavior. In simulations, arbitrary six-dimensional strain\nhistories are used to predict stresses under random walking as the source task\nand cyclic loading conditions as the target task. Incorporating sub-scale\nproperties enhances RNN versatility. In order to achieve accurate predictions,\nthe model uses a grid search method to tune network architecture and\nhyper-parameter configurations. The results of this study demonstrate that\ntransfer learning can be used to effectively adapt the RNN to varying strain\nconditions, which establishes its potential as a useful tool for modeling\npath-dependent responses in woven composites.\n","authors":["Ehsan Ghane","Martin Fagerström","Mohsen Mirkhalaf"],"pdf_url":"https://arxiv.org/pdf/2311.13434v1.pdf","comment":"There are 25 pages and 13 EPS images. The paper includes links to\n  supporting materials"},{"id":"http://arxiv.org/abs/2311.13431v1","updated":"2023-11-22T14:45:30Z","published":"2023-11-22T14:45:30Z","title":"Extracting individual variable information for their decoupling, direct\n  mutual information and multi-feature Granger causality","summary":"  Working with multiple variables they usually contain difficult to control\ncomplex dependencies. This article proposes extraction of their individual\ninformation, e.g. $\\overline{X|Y}$ as random variable containing information\nfrom $X$, but with removed information about $Y$, by using $(x,y)\n\\leftrightarrow (\\bar{x}=\\textrm{CDF}_{X|Y=y}(x),y)$ reversible normalization.\nOne application can be decoupling of individual information of variables:\nreversibly transform $(X_1,\\ldots,X_n)\\leftrightarrow(\\tilde{X}_1,\\ldots\n\\tilde{X}_n)$ together containing the same information, but being independent:\n$\\forall_{i\\neq j} \\tilde{X}_i\\perp \\tilde{X}_j, \\tilde{X}_i\\perp X_j$. It\nrequires detailed models of complex conditional probability distributions - it\nis generally a difficult task, but here can be done through multiple dependency\nreducing iterations, using imperfect methods (here HCR: Hierarchical\nCorrelation Reconstruction). It could be also used for direct mutual\ninformation - evaluating direct information transfer: without use of\nintermediate variables. For causality direction there is discussed\nmulti-feature Granger causality, e.g. to trace various types of individual\ninformation transfers between such decoupled variables, including propagation\ntime (delay).\n","authors":["Jarek Duda"],"pdf_url":"https://arxiv.org/pdf/2311.13431v1.pdf","comment":"3 pages, 1 figure"},{"id":"http://arxiv.org/abs/2311.10500v2","updated":"2023-11-22T14:42:12Z","published":"2023-11-17T13:01:09Z","title":"From Principle to Practice: Vertical Data Minimization for Machine\n  Learning","summary":"  Aiming to train and deploy predictive models, organizations collect large\namounts of detailed client data, risking the exposure of private information in\nthe event of a breach. To mitigate this, policymakers increasingly demand\ncompliance with the data minimization (DM) principle, restricting data\ncollection to only that data which is relevant and necessary for the task.\nDespite regulatory pressure, the problem of deploying machine learning models\nthat obey DM has so far received little attention. In this work, we address\nthis challenge in a comprehensive manner. We propose a novel vertical DM (vDM)\nworkflow based on data generalization, which by design ensures that no\nfull-resolution client data is collected during training and deployment of\nmodels, benefiting client privacy by reducing the attack surface in case of a\nbreach. We formalize and study the corresponding problem of finding\ngeneralizations that both maximize data utility and minimize empirical privacy\nrisk, which we quantify by introducing a diverse set of policy-aligned\nadversarial scenarios. Finally, we propose a range of baseline vDM algorithms,\nas well as Privacy-aware Tree (PAT), an especially effective vDM algorithm that\noutperforms all baselines across several settings. We plan to release our code\nas a publicly available library, helping advance the standardization of DM for\nmachine learning. Overall, we believe our work can help lay the foundation for\nfurther exploration and adoption of DM principles in real-world applications.\n","authors":["Robin Staab","Nikola Jovanović","Mislav Balunović","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2311.10500v2.pdf","comment":"Accepted at IEEE S&P 2024"},{"id":"http://arxiv.org/abs/2311.08936v2","updated":"2023-11-22T14:25:55Z","published":"2023-11-15T13:19:02Z","title":"Confident Naturalness Explanation (CNE): A Framework to Explain and\n  Assess Patterns Forming Naturalness","summary":"  Protected natural areas are regions that have been minimally affected by\nhuman activities such as urbanization, agriculture, and other human\ninterventions. To better understand and map the naturalness of these areas,\nmachine learning models can be used to analyze satellite imagery. Specifically,\nexplainable machine learning methods show promise in uncovering patterns that\ncontribute to the concept of naturalness within these protected environments.\nAdditionally, addressing the uncertainty inherent in machine learning models is\ncrucial for a comprehensive understanding of this concept. However, existing\napproaches have limitations. They either fail to provide explanations that are\nboth valid and objective or struggle to offer a quantitative metric that\naccurately measures the contribution of specific patterns to naturalness, along\nwith the associated confidence. In this paper, we propose a novel framework\ncalled the Confident Naturalness Explanation (CNE) framework. This framework\ncombines explainable machine learning and uncertainty quantification to assess\nand explain naturalness. We introduce a new quantitative metric that describes\nthe confident contribution of patterns to the concept of naturalness.\nFurthermore, we generate an uncertainty-aware segmentation mask for each input\nsample, highlighting areas where the model lacks knowledge. To demonstrate the\neffectiveness of our framework, we apply it to a study site in Fennoscandia\nusing two open-source satellite datasets.\n","authors":["Ahmed Emam","Mohamed Farag","Ribana Roscher"],"pdf_url":"https://arxiv.org/pdf/2311.08936v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13414v1","updated":"2023-11-22T14:20:15Z","published":"2023-11-22T14:20:15Z","title":"From Images to Connections: Can DQN with GNNs learn the Strategic Game\n  of Hex?","summary":"  The gameplay of strategic board games such as chess, Go and Hex is often\ncharacterized by combinatorial, relational structures -- capturing distinct\ninteractions and non-local patterns -- and not just images. Nonetheless, most\ncommon self-play reinforcement learning (RL) approaches simply approximate\npolicy and value functions using convolutional neural networks (CNN). A key\nfeature of CNNs is their relational inductive bias towards locality and\ntranslational invariance. In contrast, graph neural networks (GNN) can encode\nmore complicated and distinct relational structures. Hence, we investigate the\ncrucial question: Can GNNs, with their ability to encode complex connections,\nreplace CNNs in self-play reinforcement learning? To this end, we do a\ncomparison with Hex -- an abstract yet strategically rich board game -- serving\nas our experimental platform. Our findings reveal that GNNs excel at dealing\nwith long range dependency situations in game states and are less prone to\noverfitting, but also showing a reduced proficiency in discerning local\npatterns. This suggests a potential paradigm shift, signaling the use of\ngame-specific structures to reshape self-play reinforcement learning.\n","authors":["Yannik Keller","Jannis Blüml","Gopika Sudhakaran","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2311.13414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13411v1","updated":"2023-11-22T14:16:20Z","published":"2023-11-22T14:16:20Z","title":"Bayesian inference of a new Mallows model for characterising symptom\n  sequences applied in primary progressive aphasia","summary":"  Machine learning models offer the potential to understand diverse datasets in\na data-driven way, powering insights into individual disease experiences and\nensuring equitable healthcare. In this study, we explore Bayesian inference for\ncharacterising symptom sequences, and the associated modelling challenges. We\nadapted the Mallows model to account for partial rankings and right-censored\ndata, employing custom MCMC fitting. Our evaluation, encompassing synthetic\ndata and a primary progressive aphasia dataset, highlights the model's efficacy\nin revealing mean orderings and estimating ranking variance. This holds the\npotential to enhance clinical comprehension of symptom occurrence. However, our\nwork encounters limitations concerning model scalability and small dataset\nsizes.\n","authors":["Beatrice Taylor","Cameron Shand","Chris J. D. Hardy","Neil Oxtoby"],"pdf_url":"https://arxiv.org/pdf/2311.13411v1.pdf","comment":"Extended Abstract presented at Machine Learning for Health (ML4H)\n  symposium 2023, December 10th, 2023, New Orleans, United States, 8 pages"},{"id":"http://arxiv.org/abs/2204.06450v3","updated":"2023-11-22T14:10:56Z","published":"2022-04-13T15:17:00Z","title":"The effect of speech pathology on automatic speaker verification -- a\n  large-scale study","summary":"  Navigating the challenges of data-driven speech processing, one of the\nprimary hurdles is accessing reliable pathological speech data. While public\ndatasets appear to offer solutions, they come with inherent risks of potential\nunintended exposure of patient health information via re-identification\nattacks. Using a comprehensive real-world pathological speech corpus, with over\nn=3,800 test subjects spanning various age groups and speech disorders, we\nemployed a deep-learning-driven automatic speaker verification (ASV) approach.\nThis resulted in a notable mean equal error rate (EER) of 0.89% with a standard\ndeviation of 0.06%, outstripping traditional benchmarks. Our comprehensive\nassessments demonstrate that pathological speech overall faces heightened\nprivacy breach risks compared to healthy speech. Specifically, adults with\ndysphonia are at heightened re-identification risks, whereas conditions like\ndysarthria yield results comparable to those of healthy speakers. Crucially,\nspeech intelligibility does not influence the ASV system's performance metrics.\nIn pediatric cases, particularly those with cleft lip and palate, the recording\nenvironment plays a decisive role in re-identification. Merging data across\npathological types led to a marked EER decrease, suggesting the potential\nbenefits of pathological diversity in ASV, accompanied by a logarithmic boost\nin ASV effectiveness. In essence, this research sheds light on the dynamics\nbetween pathological speech and speaker verification, emphasizing its crucial\nrole in safeguarding patient confidentiality in our increasingly digitized\nhealthcare era.\n","authors":["Soroosh Tayebi Arasteh","Tobias Weise","Maria Schuster","Elmar Noeth","Andreas Maier","Seung Hee Yang"],"pdf_url":"https://arxiv.org/pdf/2204.06450v3.pdf","comment":"Published in Scientific Reports"},{"id":"http://arxiv.org/abs/2306.00560v2","updated":"2023-11-22T14:02:07Z","published":"2023-06-01T11:20:09Z","title":"Hinge-Wasserstein: Mitigating Overconfidence in Regression by\n  Classification","summary":"  Computer vision systems that are deployed in safety-critical applications\nneed to quantify their output uncertainty. We study regression from images to\nparameter values and here it is common to detect uncertainty by predicting\nprobability distributions. In this context, we investigate the\nregression-by-classification paradigm which can represent multimodal\ndistributions, without a prior assumption on the number of modes. Through\nexperiments on a specifically designed synthetic dataset, we demonstrate that\ntraditional loss functions lead to poor probability distribution estimates and\nsevere overconfidence, in the absence of full ground truth distributions. In\norder to alleviate these issues, we propose hinge-Wasserstein -- a simple\nimprovement of the Wasserstein loss that reduces the penalty for weak secondary\nmodes during training. This enables prediction of complex distributions with\nmultiple modes, and allows training on datasets where full ground truth\ndistributions are not available. In extensive experiments, we show that the\nproposed loss leads to substantially better uncertainty estimation on two\nchallenging computer vision tasks: horizon line detection and stereo disparity\nestimation.\n","authors":["Ziliang Xiong","Arvi Jonnarth","Abdelrahman Eldesokey","Joakim Johnander","Bastian Wandt","Per-Erik Forssen"],"pdf_url":"https://arxiv.org/pdf/2306.00560v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13381v1","updated":"2023-11-22T13:20:59Z","published":"2023-11-22T13:20:59Z","title":"Confidant: Customizing Transformer-based LLMs via Collaborative Edge\n  Training","summary":"  Transformer-based large language models (LLMs) have demonstrated impressive\ncapabilities in a variety of natural language processing (NLP) tasks.\nNonetheless, it is challenging to deploy and fine-tune LLMs on mobile edge\ndevices with limited computing, memory, and energy budgets. In this paper, we\npropose Confidant, a multi-backend collaborative training framework for\ncustomizing state-of-the-art LLMs on commodity mobile devices like smartphones.\nConfidant partitions an LLM into several sub-models so that each fits into a\nmobile device's memory. A pipeline parallel training mechanism is further\ndeveloped to ensure fast and efficient distributed training. In addition, we\npropose a novel backend scheduler to allocate different attention heads to\nheterogeneous compute hardware, including mobile CPU and GPUs, to maximize the\ncompute resource utilization on each edge device. Our preliminary experimental\nresults show that Confidant achieves at most 45.3% memory reduction and 8.03x\ninference speedup in practical settings.\n","authors":["Yuhao Chen","Yuxuan Yan","Qianqian Yang","Yuanchao Shu","Shibo He","Jiming Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13381v1.pdf","comment":"6 pages, 7 figures; Submitted to HotMobile 2024"},{"id":"http://arxiv.org/abs/2311.13374v1","updated":"2023-11-22T13:17:55Z","published":"2023-11-22T13:17:55Z","title":"An Empirical Study of Uncertainty Estimation Techniques for Detecting\n  Drift in Data Streams","summary":"  In safety-critical domains such as autonomous driving and medical diagnosis,\nthe reliability of machine learning models is crucial. One significant\nchallenge to reliability is concept drift, which can cause model deterioration\nover time. Traditionally, drift detectors rely on true labels, which are often\nscarce and costly. This study conducts a comprehensive empirical evaluation of\nusing uncertainty values as substitutes for error rates in detecting drifts,\naiming to alleviate the reliance on labeled post-deployment data. We examine\nfive uncertainty estimation methods in conjunction with the ADWIN detector\nacross seven real-world datasets. Our results reveal that while the SWAG method\nexhibits superior calibration, the overall accuracy in detecting drifts is not\nnotably impacted by the choice of uncertainty estimation method, with even the\nmost basic method demonstrating competitive performance. These findings offer\nvaluable insights into the practical applicability of uncertainty-based drift\ndetection in real-world, safety-critical applications.\n","authors":["Anton Winter","Nicolas Jourdan","Tristan Wirth","Volker Knauthe","Arjan Kuijper"],"pdf_url":"https://arxiv.org/pdf/2311.13374v1.pdf","comment":"NeurIPS 2023: Workshop on Distribution Shifts"},{"id":"http://arxiv.org/abs/2310.03789v2","updated":"2023-11-22T12:55:08Z","published":"2023-10-05T18:00:01Z","title":"Droplets of Good Representations: Grokking as a First Order Phase\n  Transition in Two Layer Networks","summary":"  A key property of deep neural networks (DNNs) is their ability to learn new\nfeatures during training. This intriguing aspect of deep learning stands out\nmost clearly in recently reported Grokking phenomena. While mainly reflected as\na sudden increase in test accuracy, Grokking is also believed to be a beyond\nlazy-learning/Gaussian Process (GP) phenomenon involving feature learning. Here\nwe apply a recent development in the theory of feature learning, the adaptive\nkernel approach, to two teacher-student models with cubic-polynomial and\nmodular addition teachers. We provide analytical predictions on feature\nlearning and Grokking properties of these models and demonstrate a mapping\nbetween Grokking and the theory of phase transitions. We show that after\nGrokking, the state of the DNN is analogous to the mixed phase following a\nfirst-order phase transition. In this mixed phase, the DNN generates useful\ninternal representations of the teacher that are sharply distinct from those\nbefore the transition.\n","authors":["Noa Rubin","Inbar Seroussi","Zohar Ringel"],"pdf_url":"https://arxiv.org/pdf/2310.03789v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13355v1","updated":"2023-11-22T12:47:12Z","published":"2023-11-22T12:47:12Z","title":"Unified Classification and Rejection: A One-versus-All Framework","summary":"  Classifying patterns of known classes and rejecting ambiguous and novel (also\ncalled as out-of-distribution (OOD)) inputs are involved in open world pattern\nrecognition. Deep neural network models usually excel in closed-set\nclassification while performing poorly in rejecting OOD. To tackle this\nproblem, numerous methods have been designed to perform open set recognition\n(OSR) or OOD rejection/detection tasks. Previous methods mostly take\npost-training score transformation or hybrid models to ensure low scores on OOD\ninputs while separating known classes. In this paper, we attempt to build a\nunified framework for building open set classifiers for both classification and\nOOD rejection. We formulate the open set recognition of $ K $-known-class as a\n$ (K + 1) $-class classification problem with model trained on known-class\nsamples only. By decomposing the $ K $-class problem into $ K $ one-versus-all\n(OVA) binary classification tasks and binding some parameters, we show that\ncombining the scores of OVA classifiers can give $ (K + 1) $-class posterior\nprobabilities, which enables classification and OOD rejection in a unified\nframework. To maintain the closed-set classification accuracy of the OVA\ntrained classifier, we propose a hybrid training strategy combining OVA loss\nand multi-class cross-entropy loss. We implement the OVA framework and hybrid\ntraining strategy on the recently proposed convolutional prototype network.\nExperiments on popular OSR and OOD detection datasets demonstrate that the\nproposed framework, using a single multi-class classifier, yields competitive\nperformance in closed-set classification, OOD detection, and misclassification\ndetection.\n","authors":["Zhen Cheng","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13350v1","updated":"2023-11-22T12:39:28Z","published":"2023-11-22T12:39:28Z","title":"Fact-based Court Judgment Prediction","summary":"  This extended abstract extends the research presented in \"ILDC for CJPE:\nIndian Legal Documents Corpus for Court Judgment Prediction and Explanation\"\n\\cite{malik-etal-2021-ildc}, focusing on fact-based judgment prediction within\nthe context of Indian legal documents. We introduce two distinct problem\nvariations: one based solely on facts, and another combining facts with rulings\nfrom lower courts (RLC). Our research aims to enhance early-phase case outcome\nprediction, offering significant benefits to legal professionals and the\ngeneral public. The results, however, indicated a performance decline compared\nto the original ILDC for CJPE study, even after implementing various weightage\nschemes in our DELSumm algorithm. Additionally, using only facts for legal\njudgment prediction with different transformer models yielded results inferior\nto the state-of-the-art outcomes reported in the \"ILDC for CJPE\" study.\n","authors":["Shubham Kumar Nigam","Aniket Deroy"],"pdf_url":"https://arxiv.org/pdf/2311.13350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04225v2","updated":"2023-11-22T12:35:08Z","published":"2023-06-07T08:02:17Z","title":"Efficient Vision Transformer for Human Pose Estimation via Patch\n  Selection","summary":"  While Convolutional Neural Networks (CNNs) have been widely successful in 2D\nhuman pose estimation, Vision Transformers (ViTs) have emerged as a promising\nalternative to CNNs, boosting state-of-the-art performance. However, the\nquadratic computational complexity of ViTs has limited their applicability for\nprocessing high-resolution images. In this paper, we propose three methods for\nreducing ViT's computational complexity, which are based on selecting and\nprocessing a small number of most informative patches while disregarding\nothers. The first two methods leverage a lightweight pose estimation network to\nguide the patch selection process, while the third method utilizes a set of\nlearnable joint tokens to ensure that the selected patches contain the most\nimportant information about body joints. Experiments across six benchmarks show\nthat our proposed methods achieve a significant reduction in computational\ncomplexity, ranging from 30% to 44%, with only a minimal drop in accuracy\nbetween 0% and 3.5%.\n","authors":["Kaleab A. Kinfu","Rene Vidal"],"pdf_url":"https://arxiv.org/pdf/2306.04225v2.pdf","comment":"BMVC 2023 Oral Paper: https://proceedings.bmvc2023.org/167/"},{"id":"http://arxiv.org/abs/2311.13349v1","updated":"2023-11-22T12:34:51Z","published":"2023-11-22T12:34:51Z","title":"REDS: Resource-Efficient Deep Subnetworks for Dynamic Resource\n  Constraints","summary":"  Deep models deployed on edge devices frequently encounter resource\nvariability, which arises from fluctuating energy levels, timing constraints,\nor prioritization of other critical tasks within the system. State-of-the-art\nmachine learning pipelines generate resource-agnostic models, not capable to\nadapt at runtime. In this work we introduce Resource-Efficient Deep Subnetworks\n(REDS) to tackle model adaptation to variable resources. In contrast to the\nstate-of-the-art, REDS use structured sparsity constructively by exploiting\npermutation invariance of neurons, which allows for hardware-specific\noptimizations. Specifically, REDS achieve computational efficiency by (1)\nskipping sequential computational blocks identified by a novel iterative\nknapsack optimizer, and (2) leveraging simple math to re-arrange the order of\noperations in REDS computational graph to take advantage of the data cache.\nREDS support conventional deep networks frequently deployed on the edge and\nprovide computational benefits even for small and simple networks. We evaluate\nREDS on six benchmark architectures trained on the Google Speech Commands,\nFMNIST and CIFAR10 datasets, and test on four off-the-shelf mobile and embedded\nhardware platforms. We provide a theoretical result and empirical evidence for\nREDS outstanding performance in terms of submodels' test set accuracy, and\ndemonstrate an adaptation time in response to dynamic resource constraints of\nunder 40$\\mu$s, utilizing a 2-layer fully-connected network on Arduino Nano 33\nBLE Sense.\n","authors":["Francesco Corti","Balz Maag","Joachim Schauer","Ulrich Pferschy","Olga Saukh"],"pdf_url":"https://arxiv.org/pdf/2311.13349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13348v1","updated":"2023-11-22T12:25:02Z","published":"2023-11-22T12:25:02Z","title":"MergeSFL: Split Federated Learning with Feature Merging and Batch Size\n  Regulation","summary":"  Recently, federated learning (FL) has emerged as a popular technique for edge\nAI to mine valuable knowledge in edge computing (EC) systems. To mitigate the\ncomputing/communication burden on resource-constrained workers and protect\nmodel privacy, split federated learning (SFL) has been released by integrating\nboth data and model parallelism. Despite resource limitations, SFL still faces\ntwo other critical challenges in EC, i.e., statistical heterogeneity and system\nheterogeneity. To address these challenges, we propose a novel SFL framework,\ntermed MergeSFL, by incorporating feature merging and batch size regulation in\nSFL. Concretely, feature merging aims to merge the features from workers into a\nmixed feature sequence, which is approximately equivalent to the features\nderived from IID data and is employed to promote model accuracy. While batch\nsize regulation aims to assign diverse and suitable batch sizes for\nheterogeneous workers to improve training efficiency. Moreover, MergeSFL\nexplores to jointly optimize these two strategies upon their coupled\nrelationship to better enhance the performance of SFL. Extensive experiments\nare conducted on a physical platform with 80 NVIDIA Jetson edge devices, and\nthe experimental results show that MergeSFL can improve the final model\naccuracy by 5.82% to 26.22%, with a speedup by about 1.74x to 4.14x, compared\nto the baselines.\n","authors":["Yunming Liao","Yang Xu","Hongli Xu","Lun Wang","Zhiwei Yao","Chunming Qiao"],"pdf_url":"https://arxiv.org/pdf/2311.13348v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14605v2","updated":"2023-11-22T12:16:28Z","published":"2022-11-26T16:13:32Z","title":"Looking at the posterior: accuracy and uncertainty of neural-network\n  predictions","summary":"  Bayesian inference can quantify uncertainty in the predictions of neural\nnetworks using posterior distributions for model parameters and network output.\nBy looking at these posterior distributions, one can separate the origin of\nuncertainty into aleatoric and epistemic contributions. One goal of uncertainty\nquantification is to inform on prediction accuracy. Here we show that\nprediction accuracy depends on both epistemic and aleatoric uncertainty in an\nintricate fashion that cannot be understood in terms of marginalized\nuncertainty distributions alone. How the accuracy relates to epistemic and\naleatoric uncertainties depends not only on the model architecture, but also on\nthe properties of the dataset. We discuss the significance of these results for\nactive learning and introduce a novel acquisition function that outperforms\ncommon uncertainty-based methods. To arrive at our results, we approximated the\nposteriors using deep ensembles, for fully-connected, convolutional and\nattention-based neural networks.\n","authors":["H. Linander","O. Balabanov","H. Yang","B. Mehlig"],"pdf_url":"https://arxiv.org/pdf/2211.14605v2.pdf","comment":"26 pages, 10 figures, 5 tables"},{"id":"http://arxiv.org/abs/2311.08228v2","updated":"2023-11-22T12:10:39Z","published":"2023-11-14T15:08:14Z","title":"Counterfactual Explanation for Regression via Disentanglement in Latent\n  Space","summary":"  Counterfactual Explanations (CEs) help address the question: How can the\nfactors that influence the prediction of a predictive model be changed to\nachieve a more favorable outcome from a user's perspective? Thus, they bear the\npotential to guide the user's interaction with AI systems since they represent\neasy-to-understand explanations. To be applicable, CEs need to be realistic and\nactionable. In the literature, various methods have been proposed to generate\nCEs. However, the majority of research on CEs focuses on classification\nproblems where questions like \"What should I do to get my rejected loan\napproved?\" are raised. In practice, answering questions like \"What should I do\nto increase my salary?\" are of a more regressive nature. In this paper, we\nintroduce a novel method to generate CEs for a pre-trained regressor by first\ndisentangling the label-relevant from the label-irrelevant dimensions in the\nlatent space. CEs are then generated by combining the label-irrelevant\ndimensions and the predefined output. The intuition behind this approach is\nthat the ideal counterfactual search should focus on the label-irrelevant\ncharacteristics of the input and suggest changes toward target-relevant\ncharacteristics. Searching in the latent space could help achieve this goal. We\nshow that our method maintains the characteristics of the query sample during\nthe counterfactual search. In various experiments, we demonstrate that the\nproposed method is competitive based on different quality measures on image and\ntabular datasets in regression problem settings. It efficiently returns results\ncloser to the original data manifold compared to three state-of-the-art\nmethods, which is essential for realistic high-dimensional machine learning\napplications. Our code will be made available as an open-source package upon\nthe publication of this work.\n","authors":["Xuan Zhao","Klaus Broelemann","Gjergji Kasneci"],"pdf_url":"https://arxiv.org/pdf/2311.08228v2.pdf","comment":"CXAI workshop @ ICDM 2023. arXiv admin note: text overlap with\n  arXiv:2307.13390"},{"id":"http://arxiv.org/abs/2311.13341v1","updated":"2023-11-22T12:08:01Z","published":"2023-11-22T12:08:01Z","title":"Learning principle and mathematical realization of the learning\n  mechanism in the brain","summary":"  While deep learning has achieved remarkable success, there is no clear\nexplanation about why it works so well. In order to discuss this question\nquantitatively, we need a mathematical framework that explains what learning is\nin the first place. After several considerations, we succeeded in constructing\na mathematical framework that can provide a unified understanding of all types\nof learning, including deep learning and learning in the brain. We call it\nlearning principle, and it follows that all learning is equivalent to\nestimating the probability of input data. We not only derived this principle,\nbut also mentioned its application to actual machine learning models. For\nexample, we found that conventional supervised learning is equivalent to\nestimating conditional probabilities, and succeeded in making supervised\nlearning more effective and generalized. We also proposed a new method of\ndefining the values of estimated probability using differentiation, and showed\nthat unsupervised learning can be performed on arbitrary dataset without any\nprior knowledge. Namely, this method is a general-purpose machine learning in\nthe true sense. Moreover, we succeeded in describing the learning mechanism in\nthe brain by considering the time evolution of a fully or partially connected\nmodel and applying this new method. The learning principle provides solutions\nto many unsolved problems in deep learning and cognitive neuroscience.\n","authors":["Taisuke Katayose"],"pdf_url":"https://arxiv.org/pdf/2311.13341v1.pdf","comment":"31 pages, 14 figures"},{"id":"http://arxiv.org/abs/2311.13326v1","updated":"2023-11-22T11:42:50Z","published":"2023-11-22T11:42:50Z","title":"Curriculum Learning and Imitation Learning for Model-free Control on\n  Financial Time-series","summary":"  Curriculum learning and imitation learning have been leveraged extensively in\nthe robotics domain. However, minimal research has been done on leveraging\nthese ideas on control tasks over highly stochastic time-series data. Here, we\ntheoretically and empirically explore these approaches in a representative\ncontrol task over complex time-series data. We implement the fundamental ideas\nof curriculum learning via data augmentation, while imitation learning is\nimplemented via policy distillation from an oracle. Our findings reveal that\ncurriculum learning should be considered a novel direction in improving\ncontrol-task performance over complex time-series. Our ample random-seed\nout-sample empirics and ablation studies are highly encouraging for curriculum\nlearning for time-series control. These findings are especially encouraging as\nwe tune all overlapping hyperparameters on the baseline -- giving an advantage\nto the baseline. On the other hand, we find that imitation learning should be\nused with caution.\n","authors":["Woosung Koh","Insu Choi","Yuntae Jang","Gimin Kang","Woo Chang Kim"],"pdf_url":"https://arxiv.org/pdf/2311.13326v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2311.13321v1","updated":"2023-11-22T11:24:04Z","published":"2023-11-22T11:24:04Z","title":"Revisiting Supervision for Continual Representation Learning","summary":"  In the field of continual learning, models are designed to learn tasks one\nafter the other. While most research has centered on supervised continual\nlearning, recent studies have highlighted the strengths of self-supervised\ncontinual representation learning. The improved transferability of\nrepresentations built with self-supervised methods is often associated with the\nrole played by the multi-layer perceptron projector. In this work, we depart\nfrom this observation and reexamine the role of supervision in continual\nrepresentation learning. We reckon that additional information, such as human\nannotations, should not deteriorate the quality of representations. Our\nfindings show that supervised models when enhanced with a multi-layer\nperceptron head, can outperform self-supervised models in continual\nrepresentation learning.\n","authors":["Daniel Marczak","Sebastian Cygert","Tomasz Trzciński","Bartłomiej Twardowski"],"pdf_url":"https://arxiv.org/pdf/2311.13321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13319v1","updated":"2023-11-22T11:15:38Z","published":"2023-11-22T11:15:38Z","title":"Deep Learning for Vascular Segmentation and Applications in Phase\n  Contrast Tomography Imaging","summary":"  Automated blood vessel segmentation is vital for biomedical imaging, as\nvessel changes indicate many pathologies. Still, precise segmentation is\ndifficult due to the complexity of vascular structures, anatomical variations\nacross patients, the scarcity of annotated public datasets, and the quality of\nimages. We present a thorough literature review, highlighting the state of\nmachine learning techniques across diverse organs. Our goal is to provide a\nfoundation on the topic and identify a robust baseline model for application to\nvascular segmentation in a new imaging modality, Hierarchical Phase Contrast\nTomography (HiP CT). Introduced in 2020 at the European Synchrotron Radiation\nFacility, HiP CT enables 3D imaging of complete organs at an unprecedented\nresolution of ca. 20mm per voxel, with the capability for localized zooms in\nselected regions down to 1mm per voxel without sectioning. We have created a\ntraining dataset with double annotator validated vascular data from three\nkidneys imaged with HiP CT in the context of the Human Organ Atlas Project.\nFinally, utilising the nnU Net model, we conduct experiments to assess the\nmodels performance on both familiar and unseen samples, employing vessel\nspecific metrics. Our results show that while segmentations yielded reasonably\nhigh scores such as clDice values ranging from 0.82 to 0.88, certain errors\npersisted. Large vessels that collapsed due to the lack of hydrostatic pressure\n(HiP CT is an ex vivo technique) were segmented poorly. Moreover, decreased\nconnectivity in finer vessels and higher segmentation errors at vessel\nboundaries were observed. Such errors obstruct the understanding of the\nstructures by interrupting vascular tree connectivity. Through our review and\noutputs, we aim to set a benchmark for subsequent model evaluations using\nvarious modalities, especially with the HiP CT imaging database.\n","authors":["Ekin Yagis","Shahab Aslani","Yashvardhan Jain","Yang Zhou","Shahrokh Rahmani","Joseph Brunet","Alexandre Bellier","Christopher Werlein","Maximilian Ackermann","Danny Jonigk","Paul Tafforeau","Peter D Lee","Claire Walsh"],"pdf_url":"https://arxiv.org/pdf/2311.13319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.00846v2","updated":"2023-11-22T11:02:35Z","published":"2023-09-02T07:13:47Z","title":"pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time\n  Adaptation","summary":"  Test Time Adaptation (TTA) is a pivotal concept in machine learning, enabling\nmodels to perform well in real-world scenarios, where test data distribution\ndiffers from training. In this work, we propose a novel approach called pseudo\nSource guided Target Clustering (pSTarC) addressing the relatively unexplored\narea of TTA under real-world domain shifts. This method draws inspiration from\ntarget clustering techniques and exploits the source classifier for generating\npseudo-source samples. The test samples are strategically aligned with these\npseudo-source samples, facilitating their clustering and thereby enhancing TTA\nperformance. pSTarC operates solely within the fully test-time adaptation\nprotocol, removing the need for actual source data. Experimental validation on\na variety of domain shift datasets, namely VisDA, Office-Home, DomainNet-126,\nCIFAR-100C verifies pSTarC's effectiveness. This method exhibits significant\nimprovements in prediction accuracy along with efficient computational\nrequirements. Furthermore, we also demonstrate the universality of the pSTarC\nframework by showing its effectiveness for the continuous TTA framework. The\nsource code for our method is available at https://manogna-s.github.io/pstarc\n","authors":["Manogna Sreenivas","Goirik Chakrabarty","Soma Biswas"],"pdf_url":"https://arxiv.org/pdf/2309.00846v2.pdf","comment":"Accepted in WACV 2024"},{"id":"http://arxiv.org/abs/2309.07675v2","updated":"2023-11-22T10:24:26Z","published":"2023-09-14T12:39:26Z","title":"Goal Space Abstraction in Hierarchical Reinforcement Learning via\n  Set-Based Reachability Analysis","summary":"  Open-ended learning benefits immensely from the use of symbolic methods for\ngoal representation as they offer ways to structure knowledge for efficient and\ntransferable learning. However, the existing Hierarchical Reinforcement\nLearning (HRL) approaches relying on symbolic reasoning are often limited as\nthey require a manual goal representation. The challenge in autonomously\ndiscovering a symbolic goal representation is that it must preserve critical\ninformation, such as the environment dynamics. In this paper, we propose a\ndevelopmental mechanism for goal discovery via an emergent representation that\nabstracts (i.e., groups together) sets of environment states that have similar\nroles in the task. We introduce a Feudal HRL algorithm that concurrently learns\nboth the goal representation and a hierarchical policy. The algorithm uses\nsymbolic reachability analysis for neural networks to approximate the\ntransition relation among sets of states and to refine the goal representation.\nWe evaluate our approach on complex navigation tasks, showing the learned\nrepresentation is interpretable, transferrable and results in data efficient\nlearning.\n","authors":["Mehdi Zadem","Sergio Mover","Sao Mai Nguyen"],"pdf_url":"https://arxiv.org/pdf/2309.07675v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13294v1","updated":"2023-11-22T10:23:14Z","published":"2023-11-22T10:23:14Z","title":"Probabilistic Inference in Reinforcement Learning Done Right","summary":"  A popular perspective in Reinforcement learning (RL) casts the problem as\nprobabilistic inference on a graphical model of the Markov decision process\n(MDP). The core object of study is the probability of each state-action pair\nbeing visited under the optimal policy. Previous approaches to approximate this\nquantity can be arbitrarily poor, leading to algorithms that do not implement\ngenuine statistical inference and consequently do not perform well in\nchallenging problems. In this work, we undertake a rigorous Bayesian treatment\nof the posterior probability of state-action optimality and clarify how it\nflows through the MDP. We first reveal that this quantity can indeed be used to\ngenerate a policy that explores efficiently, as measured by regret.\nUnfortunately, computing it is intractable, so we derive a new variational\nBayesian approximation yielding a tractable convex optimization problem and\nestablish that the resulting policy also explores efficiently. We call our\napproach VAPOR and show that it has strong connections to Thompson sampling,\nK-learning, and maximum entropy exploration. We conclude with some experiments\ndemonstrating the performance advantage of a deep RL version of VAPOR.\n","authors":["Jean Tarbouriech","Tor Lattimore","Brendan O'Donoghue"],"pdf_url":"https://arxiv.org/pdf/2311.13294v1.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.13293v1","updated":"2023-11-22T10:22:59Z","published":"2023-11-22T10:22:59Z","title":"The Influence of Neural Networks on Hydropower Plant Management in\n  Agriculture: Addressing Challenges and Exploring Untapped Opportunities","summary":"  Hydropower plants are crucial for stable renewable energy and serve as vital\nwater sources for sustainable agriculture. However, it is essential to assess\nthe current water management practices associated with hydropower plant\nmanagement software. A key concern is the potential conflict between\nelectricity generation and agricultural water needs. Prioritising water for\nelectricity generation can reduce irrigation availability in agriculture during\ncrucial periods like droughts, impacting crop yields and regional food\nsecurity. Coordination between electricity and agricultural water allocation is\nnecessary to ensure optimal and environmentally sound practices. Neural\nnetworks have become valuable tools for hydropower plant management, but their\nblack-box nature raises concerns about transparency in decision making.\nAdditionally, current approaches often do not take advantage of their potential\nto create a system that effectively balances water allocation.\n  This work is a call for attention and highlights the potential risks of\ndeploying neural network-based hydropower plant management software without\nproper scrutiny and control. To address these concerns, we propose the adoption\nof the Agriculture Conscious Hydropower Plant Management framework, aiming to\nmaximise electricity production while prioritising stable irrigation for\nagriculture. We also advocate reevaluating government-imposed minimum water\nguidelines for irrigation to ensure flexibility and effective water allocation.\nAdditionally, we suggest a set of regulatory measures to promote model\ntransparency and robustness, certifying software that makes conscious and\nintelligent water allocation decisions, ultimately safeguarding agriculture\nfrom undue strain during droughts.\n","authors":["C. Coelho","M. Fernanda P. Costa","L. L. Ferrás"],"pdf_url":"https://arxiv.org/pdf/2311.13293v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13285v1","updated":"2023-11-22T10:08:33Z","published":"2023-11-22T10:08:33Z","title":"Improving performance of heart rate time series classification by\n  grouping subjects","summary":"  Unlike the more commonly analyzed ECG or PPG data for activity\nclassification, heart rate time series data is less detailed, often noisier and\ncan contain missing data points. Using the BigIdeasLab_STEP dataset, which\nincludes heart rate time series annotated with specific tasks performed by\nindividuals, we sought to determine if general classification was achievable.\nOur analyses showed that the accuracy is sensitive to the choice of\nwindow/stride size. Moreover, we found variable classification performances\nbetween subjects due to differences in the physical structure of their hearts.\nVarious techniques were used to minimize this variability. First of all,\nnormalization proved to be a crucial step and significantly improved the\nperformance. Secondly, grouping subjects and performing classification inside a\ngroup helped to improve performance and decrease inter-subject variability.\nFinally, we show that including handcrafted features as input to a deep\nlearning (DL) network improves the classification performance further.\nTogether, these findings indicate that heart rate time series can be utilized\nfor classification tasks like predicting activity. However, normalization or\ngrouping techniques need to be chosen carefully to minimize the issue of\nsubject variability.\n","authors":["Michael Beekhuizen","Arman Naseri","David Tax","Ivo van der Bilt","Marcel Reinders"],"pdf_url":"https://arxiv.org/pdf/2311.13285v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.20477v2","updated":"2023-11-22T09:57:54Z","published":"2023-10-31T14:10:30Z","title":"Exploring Practitioner Perspectives On Training Data Attribution\n  Explanations","summary":"  Explainable AI (XAI) aims to provide insight into opaque model reasoning to\nhumans and as such is an interdisciplinary field by nature. In this paper, we\ninterviewed 10 practitioners to understand the possible usability of training\ndata attribution (TDA) explanations and to explore the design space of such an\napproach. We confirmed that training data quality is often the most important\nfactor for high model performance in practice and model developers mainly rely\non their own experience to curate data. End-users expect explanations to\nenhance their interaction with the model and do not necessarily prioritise but\nare open to training data as a means of explanation. Within our participants,\nwe found that TDA explanations are not well-known and therefore not used. We\nurge the community to focus on the utility of TDA techniques from the\nhuman-machine collaboration perspective and broaden the TDA evaluation to\nreflect common use cases in practice.\n","authors":["Elisa Nguyen","Evgenii Kortukov","Jean Y. Song","Seong Joon Oh"],"pdf_url":"https://arxiv.org/pdf/2310.20477v2.pdf","comment":"Accepted to NeurIPS XAI in Action workshop 2023"},{"id":"http://arxiv.org/abs/2311.13279v1","updated":"2023-11-22T09:55:20Z","published":"2023-11-22T09:55:20Z","title":"Comprehensive Evaluation of GNN Training Systems: A Data Management\n  Perspective","summary":"  Many Graph Neural Network (GNN) training systems have emerged recently to\nsupport efficient GNN training. Since GNNs embody complex data dependencies\nbetween training samples, the training of GNNs should address distinct\nchallenges different from DNN training in data management, such as data\npartitioning, batch preparation for mini-batch training, and data transferring\nbetween CPUs and GPUs. These factors, which take up a large proportion of\ntraining time, make data management in GNN training more significant. This\npaper reviews GNN training from a data management perspective and provides a\ncomprehensive analysis and evaluation of the representative approaches. We\nconduct extensive experiments on various benchmark datasets and show many\ninteresting and valuable results. We also provide some practical tips learned\nfrom these experiments, which are helpful for designing GNN training systems in\nthe future.\n","authors":["Hao Yuan","Yajiong Liu","Yanfeng Zhang","Xin Ai","Qiange Wang","Chaoyi Chen","Yu Gu","Ge Yu"],"pdf_url":"https://arxiv.org/pdf/2311.13279v1.pdf","comment":"12 pages, 17 figures"},{"id":"http://arxiv.org/abs/2311.13267v1","updated":"2023-11-22T09:37:33Z","published":"2023-11-22T09:37:33Z","title":"FedFN: Feature Normalization for Alleviating Data Heterogeneity Problem\n  in Federated Learning","summary":"  Federated Learning (FL) is a collaborative method for training models while\npreserving data privacy in decentralized settings. However, FL encounters\nchallenges related to data heterogeneity, which can result in performance\ndegradation. In our study, we observe that as data heterogeneity increases,\nfeature representation in the FedAVG model deteriorates more significantly\ncompared to classifier weight. Additionally, we observe that as data\nheterogeneity increases, the gap between higher feature norms for observed\nclasses, obtained from local models, and feature norms of unobserved classes\nwidens, in contrast to the behavior of classifier weight norms. This widening\ngap extends to encompass the feature norm disparities between local and the\nglobal models. To address these issues, we introduce Federated Averaging with\nFeature Normalization Update (FedFN), a straightforward learning method. We\ndemonstrate the superior performance of FedFN through extensive experiments,\neven when applied to pretrained ResNet18. Subsequently, we confirm the\napplicability of FedFN to foundation models.\n","authors":["Seongyoon Kim","Gihun Lee","Jaehoon Oh","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2311.13267v1.pdf","comment":"NeurIPS Workshop: \"Federated Learning in the Age of Foundation\n  Models\" 2023"},{"id":"http://arxiv.org/abs/2311.13265v1","updated":"2023-11-22T09:31:19Z","published":"2023-11-22T09:31:19Z","title":"Improved identification accuracy in equation learning via comprehensive\n  $\\boldsymbol{R^2}$-elimination and Bayesian model selection","summary":"  In the field of equation learning, exhaustively considering all possible\nequations derived from a basis function dictionary is infeasible. Sparse\nregression and greedy algorithms have emerged as popular approaches to tackle\nthis challenge. However, the presence of multicollinearity poses difficulties\nfor sparse regression techniques, and greedy steps may inadvertently exclude\nterms of the true equation, leading to reduced identification accuracy. In this\narticle, we present an approach that strikes a balance between\ncomprehensiveness and efficiency in equation learning. Inspired by stepwise\nregression, our approach combines the coefficient of determination, $R^2$, and\nthe Bayesian model evidence, $p(\\boldsymbol y|\\mathcal M)$, in a novel way. Our\nprocedure is characterized by a comprehensive search with just a minor\nreduction of the model space at each iteration step. With two flavors of our\napproach and the adoption of $p(\\boldsymbol y|\\mathcal M)$ for bi-directional\nstepwise regression, we present a total of three new avenues for equation\nlearning. Through three extensive numerical experiments involving random\npolynomials and dynamical systems, we compare our approach against four\nstate-of-the-art methods and two standard approaches. The results demonstrate\nthat our comprehensive search approach surpasses all other methods in terms of\nidentification accuracy. In particular, the second flavor of our approach\nestablishes an efficient overfitting penalty solely based on $R^2$, which\nachieves highest rates of exact equation recovery.\n","authors":["Daniel Nickelsen","Bubacarr Bah"],"pdf_url":"https://arxiv.org/pdf/2311.13265v1.pdf","comment":"12 pages main text and 11 pages appendix, accepted in Transactions on\n  Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2311.13261v1","updated":"2023-11-22T09:25:08Z","published":"2023-11-22T09:25:08Z","title":"Immunohistochemistry guided segmentation of benign epithelial cells, in\n  situ lesions, and invasive epithelial cells in breast cancer slides","summary":"  Digital pathology enables automatic analysis of histopathological sections\nusing artificial intelligence (AI). Automatic evaluation could improve\ndiagnostic efficiency and help find associations between morphological features\nand clinical outcome. For development of such prediction models, identifying\ninvasive epithelial cells, and separating these from benign epithelial cells\nand in situ lesions would be the first step. In this study, we aimed to develop\nan AI model for segmentation of epithelial cells in sections from breast\ncancer. We generated epithelial ground truth masks by restaining hematoxylin\nand eosin (HE) sections with cytokeratin (CK) AE1/AE3, and by pathologists'\nannotations. HE/CK image pairs were used to train a convolutional neural\nnetwork, and data augmentation was used to make the model more robust. Tissue\nmicroarrays (TMAs) from 839 patients, and whole slide images from two patients\nwere used for training and evaluation of the models. The sections were derived\nfrom four cohorts of breast cancer patients. TMAs from 21 patients from a fifth\ncohort was used as a second test set. In quantitative evaluation, a mean Dice\nscore of 0.70, 0.79, and 0.75 for invasive epithelial cells, benign epithelial\ncells, and in situ lesions, respectively, were achieved. In qualitative scoring\n(0-5) by pathologists, results were best for all epithelium and invasive\nepithelium, with scores of 4.7 and 4.4. Scores for benign epithelium and in\nsitu lesions were 3.7 and 2.0. The proposed model segmented epithelial cells in\nHE stained breast cancer slides well, but further work is needed for accurate\ndivision between the classes. Immunohistochemistry, together with pathologists'\nannotations, enabled the creation of accurate ground truths. The model is made\nfreely available in FastPathology and the code is available at\nhttps://github.com/AICAN-Research/breast-epithelium-segmentation\n","authors":["Maren Høibø","André Pedersen","Vibeke Grotnes Dale","Sissel Marie Berget","Borgny Ytterhus","Cecilia Lindskog","Elisabeth Wik","Lars A. Akslen","Ingerid Reinertsen","Erik Smistad","Marit Valla"],"pdf_url":"https://arxiv.org/pdf/2311.13261v1.pdf","comment":"19 pages, 6 figures. Submitted to a scientific journal"},{"id":"http://arxiv.org/abs/2311.13258v1","updated":"2023-11-22T09:23:34Z","published":"2023-11-22T09:23:34Z","title":"ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided\n  Code-Vision Representation","summary":"  State-of-the-art vision-language models (VLMs) still have limited performance\nin structural knowledge extraction, such as relations between objects. In this\nwork, we present ViStruct, a training framework to learn VLMs for effective\nvisual structural knowledge extraction. Two novel designs are incorporated.\nFirst, we propose to leverage the inherent structure of programming language to\ndepict visual structural information. This approach enables explicit and\nconsistent representation of visual structural information of multiple\ngranularities, such as concepts, relations, and events, in a well-organized\nstructured format. Second, we introduce curriculum-based learning for VLMs to\nprogressively comprehend visual structures, from fundamental visual concepts to\nintricate event structures. Our intuition is that lower-level knowledge may\ncontribute to complex visual structure understanding. Furthermore, we compile\nand release a collection of datasets tailored for visual structural knowledge\nextraction. We adopt a weakly-supervised approach to directly generate visual\nevent structures from captions for ViStruct training, capitalizing on abundant\nimage-caption pairs from the web. In experiments, we evaluate ViStruct on\nvisual structure prediction tasks, demonstrating its effectiveness in improving\nthe understanding of visual structures. The code is public at\n\\url{https://github.com/Yangyi-Chen/vi-struct}.\n","authors":["Yangyi Chen","Xingyao Wang","Manling Li","Derek Hoiem","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2311.13258v1.pdf","comment":"Accepted to EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13250v1","updated":"2023-11-22T09:12:50Z","published":"2023-11-22T09:12:50Z","title":"Towards Hetero-Client Federated Multi-Task Learning","summary":"  Federated Learning (FL) enables joint training across distributed clients\nusing their local data privately. Federated Multi-Task Learning (FMTL) builds\non FL to handle multiple tasks, assuming model congruity that identical model\narchitecture is deployed in each client. To relax this assumption and thus\nextend real-world applicability, we introduce a novel problem setting,\nHetero-Client Federated Multi-Task Learning (HC-FMTL), to accommodate diverse\ntask setups. The main challenge of HC-FMTL is the model incongruity issue that\ninvalidates conventional aggregation methods. It also escalates the\ndifficulties in accurate model aggregation to deal with data and task\nheterogeneity inherent in FMTL. To address these challenges, we propose the\nFedHCA$^2$ framework, which allows for federated training of personalized\nmodels by modeling relationships among heterogeneous clients. Drawing on our\ntheoretical insights into the difference between multi-task and federated\noptimization, we propose the Hyper Conflict-Averse Aggregation scheme to\nmitigate conflicts during encoder updates. Additionally, inspired by task\ninteraction in MTL, the Hyper Cross Attention Aggregation scheme uses\nlayer-wise cross attention to enhance decoder interactions while alleviating\nmodel incongruity. Moreover, we employ learnable Hyper Aggregation Weights for\neach client to customize personalized parameter updates. Extensive experiments\ndemonstrate the superior performance of FedHCA$^2$ in various HC-FMTL scenarios\ncompared to representative methods. Our code will be made publicly available.\n","authors":["Yuxiang Lu","Suizhi Huang","Yuwen Yang","Shalayiding Sirejiding","Yue Ding","Hongtao Lu"],"pdf_url":"https://arxiv.org/pdf/2311.13250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2006.09365v6","updated":"2023-11-22T09:08:15Z","published":"2020-06-16T17:58:53Z","title":"Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing","summary":"  In Byzantine robust distributed or federated learning, a central server wants\nto train a machine learning model over data distributed across multiple\nworkers. However, a fraction of these workers may deviate from the prescribed\nalgorithm and send arbitrary messages. While this problem has received\nsignificant attention recently, most current defenses assume that the workers\nhave identical data. For realistic cases when the data across workers are\nheterogeneous (non-iid), we design new attacks which circumvent current\ndefenses, leading to significant loss of performance. We then propose a simple\nbucketing scheme that adapts existing robust algorithms to heterogeneous\ndatasets at a negligible computational cost. We also theoretically and\nexperimentally validate our approach, showing that combining bucketing with\nexisting robust algorithms is effective against challenging attacks. Our work\nis the first to establish guaranteed convergence for the non-iid Byzantine\nrobust problem under realistic assumptions.\n","authors":["Sai Praneeth Karimireddy","Lie He","Martin Jaggi"],"pdf_url":"https://arxiv.org/pdf/2006.09365v6.pdf","comment":"v5 is the camera-ready version of this paper on ICLR 2022"},{"id":"http://arxiv.org/abs/2305.15851v3","updated":"2023-11-22T09:02:40Z","published":"2023-05-25T08:43:11Z","title":"On sampling determinantal and Pfaffian point processes on a quantum\n  computer","summary":"  DPPs were introduced by Macchi as a model in quantum optics the 1970s. Since\nthen, they have been widely used as models and subsampling tools in statistics\nand computer science. Most applications require sampling from a DPP, and given\ntheir quantum origin, it is natural to wonder whether sampling a DPP on a\nquantum computer is easier than on a classical one. We focus here on DPPs over\na finite state space, which are distributions over the subsets of\n$\\{1,\\dots,N\\}$ parametrized by an $N\\times N$ Hermitian kernel matrix. Vanilla\nsampling consists in two steps, of respective costs $\\mathcal{O}(N^3)$ and\n$\\mathcal{O}(Nr^2)$ operations on a classical computer, where $r$ is the rank\nof the kernel matrix. A large first part of the current paper consists in\nexplaining why the state-of-the-art in quantum simulation of fermionic systems\nalready yields quantum DPP sampling algorithms. We then modify existing quantum\ncircuits, and discuss their insertion in a full DPP sampling pipeline that\nstarts from practical kernel specifications. The bottom line is that, with $P$\n(classical) parallel processors, we can divide the preprocessing cost by $P$\nand build a quantum circuit with $\\mathcal{O}(Nr)$ gates that sample a given\nDPP, with depth varying from $\\mathcal{O}(N)$ to $\\mathcal{O}(r\\log N)$\ndepending on qubit-communication constraints on the target machine. We also\nconnect existing work on the simulation of superconductors to Pfaffian point\nprocesses, which generalize DPPs and would be a natural addition to the machine\nlearner's toolbox. In particular, we describe \"projective\" Pfaffian point\nprocesses, the cardinality of which has constant parity, almost surely.\nFinally, the circuits are empirically validated on a classical simulator and on\n5-qubit IBM machines.\n","authors":["Rémi Bardenet","Michaël Fanuel","Alexandre Feller"],"pdf_url":"https://arxiv.org/pdf/2305.15851v3.pdf","comment":"53 pages, 9 figures. Additional results about parity of cardinality\n  of PfPP samples. Minor corrections in Section 5 and slight generalization of\n  Lemma 5.4. Extra example and derivations in appendix"},{"id":"http://arxiv.org/abs/2311.13244v1","updated":"2023-11-22T09:02:04Z","published":"2023-11-22T09:02:04Z","title":"Hard Label Black Box Node Injection Attack on Graph Neural Networks","summary":"  While graph neural networks have achieved state-of-the-art performances in\nmany real-world tasks including graph classification and node classification,\nrecent works have demonstrated they are also extremely vulnerable to\nadversarial attacks. Most previous works have focused on attacking node\nclassification networks under impractical white-box scenarios. In this work, we\nwill propose a non-targeted Hard Label Black Box Node Injection Attack on Graph\nNeural Networks, which to the best of our knowledge, is the first of its kind.\nUnder this setting, more real world tasks can be studied because our attack\nassumes no prior knowledge about (1): the model architecture of the GNN we are\nattacking; (2): the model's gradients; (3): the output logits of the target GNN\nmodel. Our attack is based on an existing edge perturbation attack, from which\nwe restrict the optimization process to formulate a node injection attack. In\nthe work, we will evaluate the performance of the attack using three datasets,\nCOIL-DEL, IMDB-BINARY, and NCI1.\n","authors":["Yu Zhou","Zihao Dong","Guofeng Zhang","Jingchen Tang"],"pdf_url":"https://arxiv.org/pdf/2311.13244v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01483v2","updated":"2023-11-22T08:55:37Z","published":"2023-11-02T14:47:06Z","title":"FedSN: A General Federated Learning Framework over LEO Satellite\n  Networks","summary":"  Recently, a large number of Low Earth Orbit (LEO) satellites have been\nlaunched and deployed successfully in space by commercial companies, such as\nSpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve\nnot only for communication but also for various machine learning applications,\nsuch as space modulation recognition, remote sensing image classification, etc.\nHowever, the ground station (GS) may be incapable of downloading such a large\nvolume of raw sensing data for centralized model training due to the limited\ncontact time with LEO satellites (e.g. 5 minutes). Therefore, federated\nlearning (FL) has emerged as the promising solution to address this problem via\non-device training. Unfortunately, to enable FL on LEO satellites, we still\nface three critical challenges that are i) heterogeneous computing and memory\ncapabilities, ii) limited uplink rate, and iii) model staleness. To this end,\nwe propose FedSN as a general FL framework to tackle the above challenges, and\nfully explore data diversity on LEO satellites. Specifically, we first present\na novel sub-structure scheme to enable heterogeneous local model training\nconsidering different computing, memory, and communication constraints on LEO\nsatellites. Additionally, we propose a pseudo-synchronous model aggregation\nstrategy to dynamically schedule model aggregation for compensating model\nstaleness. To further demonstrate the effectiveness of the FedSN, we evaluate\nit using space modulation recognition and remote sensing image classification\ntasks by leveraging the data from real-world satellite networks. Extensive\nexperimental results demonstrate that FedSN framework achieves higher accuracy,\nlower computing, and communication overhead than the state-of-the-art\nbenchmarks and the effectiveness of each components in FedSN.\n","authors":["Zheng Lin","Zhe Chen","Zihan Fang","Xianhao Chen","Xiong Wang","Yue Gao"],"pdf_url":"https://arxiv.org/pdf/2311.01483v2.pdf","comment":"14 pages, 17 figures"},{"id":"http://arxiv.org/abs/2311.13231v1","updated":"2023-11-22T08:42:46Z","published":"2023-11-22T08:42:46Z","title":"Using Human Feedback to Fine-tune Diffusion Models without Any Reward\n  Model","summary":"  Using reinforcement learning with human feedback (RLHF) has shown significant\npromise in fine-tuning diffusion models. Previous methods start by training a\nreward model that aligns with human preferences, then leverage RL techniques to\nfine-tune the underlying models. However, crafting an efficient reward model\ndemands extensive datasets, optimal architecture, and manual hyperparameter\ntuning, making the process both time and cost-intensive. The direct preference\noptimization (DPO) method, effective in fine-tuning large language models,\neliminates the necessity for a reward model. However, the extensive GPU memory\nrequirement of the diffusion model's denoising process hinders the direct\napplication of the DPO method. To address this issue, we introduce the Direct\nPreference for Denoising Diffusion Policy Optimization (D3PO) method to\ndirectly fine-tune diffusion models. The theoretical analysis demonstrates that\nalthough D3PO omits training a reward model, it effectively functions as the\noptimal reward model trained using human feedback data to guide the learning\nprocess. This approach requires no training of a reward model, proving to be\nmore direct, cost-effective, and minimizing computational overhead. In\nexperiments, our method uses the relative scale of objectives as a proxy for\nhuman preference, delivering comparable results to methods using ground-truth\nrewards. Moreover, D3PO demonstrates the ability to reduce image distortion\nrates and generate safer images, overcoming challenges lacking robust reward\nmodels.\n","authors":["Kai Yang","Jian Tao","Jiafei Lyu","Chunjiang Ge","Jiaxin Chen","Qimai Li","Weihan Shen","Xiaolong Zhu","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2311.13231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13225v1","updated":"2023-11-22T08:26:42Z","published":"2023-11-22T08:26:42Z","title":"NeutronOrch: Rethinking Sample-based GNN Training under CPU-GPU\n  Heterogeneous Environments","summary":"  Graph Neural Networks (GNNs) have demonstrated outstanding performance in\nvarious applications. Existing frameworks utilize CPU-GPU heterogeneous\nenvironments to train GNN models and integrate mini-batch and sampling\ntechniques to overcome the GPU memory limitation. In CPU-GPU heterogeneous\nenvironments, we can divide sample-based GNN training into three steps: sample,\ngather, and train. Existing GNN systems use different task orchestrating\nmethods to employ each step on CPU or GPU. After extensive experiments and\nanalysis, we find that existing task orchestrating methods fail to fully\nutilize the heterogeneous resources, limited by inefficient CPU processing or\nGPU resource contention. In this paper, we propose NeutronOrch, a system for\nsample-based GNN training that incorporates a layer-based task orchestrating\nmethod and ensures balanced utilization of the CPU and GPU. NeutronOrch\ndecouples the training process by layer and pushes down the training task of\nthe bottom layer to the CPU. This significantly reduces the computational load\nand memory footprint of GPU training. To avoid inefficient CPU processing,\nNeutronOrch only offloads the training of frequently accessed vertices to the\nCPU and lets GPU reuse their embeddings with bounded staleness. Furthermore,\nNeutronOrch provides a fine-grained pipeline design for the layer-based task\norchestrating method, fully overlapping different tasks on heterogeneous\nresources while strictly guaranteeing bounded staleness. The experimental\nresults show that compared with the state-of-the-art GNN systems, NeutronOrch\ncan achieve up to 4.61x performance speedup.\n","authors":["Xin Ai","Qiange Wang","Chunyu Cao","Yanfeng Zhang","Chaoyi Chen","Hao Yuan","Yu Gu","Ge Yu"],"pdf_url":"https://arxiv.org/pdf/2311.13225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.10209v5","updated":"2023-11-22T08:08:14Z","published":"2022-02-21T13:35:03Z","title":"Degree-Preserving Randomized Response for Graph Neural Networks under\n  Local Differential Privacy","summary":"  Differentially private GNNs (Graph Neural Networks) have been recently\nstudied to provide high accuracy in various tasks on graph data while strongly\nprotecting user privacy. In particular, a recent study proposes an algorithm to\nprotect each user's feature vector in an attributed graph with LDP (Local\nDifferential Privacy), a strong privacy notion without a trusted third party.\nHowever, this algorithm does not protect edges (friendships) in a social graph,\nhence cannot protect user privacy in unattributed graphs. How to provide strong\nprivacy with high accuracy in unattributed graphs remains open.\n  In this paper, we propose a novel LDP algorithm called the DPRR\n(Degree-Preserving Randomized Response) to provide LDP for edges in GNNs. Our\nDPRR preserves each user's degree hence a graph structure while providing edge\nLDP. Technically, our DPRR uses Warner's RR (Randomized Response) and strategic\nedge sampling, where each user's sampling probability is automatically tuned\nusing the Laplacian mechanism to preserve the degree information under edge\nLDP. We also propose a privacy budget allocation method to make the noise in\nboth Warner's RR and the Laplacian mechanism small. We focus on graph\nclassification as a task of GNNs and evaluate the DPRR using three social graph\ndatasets. Our experimental results show that the DPRR significantly outperforms\nthree baselines and provides accuracy close to a non-private algorithm in all\ndatasets with a reasonable privacy budget, e.g., epsilon=1.\n","authors":["Seira Hidano","Takao Murakami"],"pdf_url":"https://arxiv.org/pdf/2202.10209v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.16213v2","updated":"2023-11-22T07:34:38Z","published":"2023-05-25T16:19:18Z","title":"ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with\n  Variational Score Distillation","summary":"  Score distillation sampling (SDS) has shown great promise in text-to-3D\ngeneration by distilling pretrained large-scale text-to-image diffusion models,\nbut suffers from over-saturation, over-smoothing, and low-diversity problems.\nIn this work, we propose to model the 3D parameter as a random variable instead\nof a constant as in SDS and present variational score distillation (VSD), a\nprincipled particle-based variational framework to explain and address the\naforementioned issues in text-to-3D generation. We show that SDS is a special\ncase of VSD and leads to poor samples with both small and large CFG weights. In\ncomparison, VSD works well with various CFG weights as ancestral sampling from\ndiffusion models and simultaneously improves the diversity and sample quality\nwith a common CFG weight (i.e., $7.5$). We further present various improvements\nin the design space for text-to-3D such as distillation time schedule and\ndensity initialization, which are orthogonal to the distillation algorithm yet\nnot well explored. Our overall approach, dubbed ProlificDreamer, can generate\nhigh rendering resolution (i.e., $512\\times512$) and high-fidelity NeRF with\nrich structure and complex effects (e.g., smoke and drops). Further,\ninitialized from NeRF, meshes fine-tuned by VSD are meticulously detailed and\nphoto-realistic. Project page and codes:\nhttps://ml.cs.tsinghua.edu.cn/prolificdreamer/\n","authors":["Zhengyi Wang","Cheng Lu","Yikai Wang","Fan Bao","Chongxuan Li","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2305.16213v2.pdf","comment":"NeurIPS 2023 (Spotlight)"},{"id":"http://arxiv.org/abs/2305.14032v4","updated":"2023-11-22T07:01:36Z","published":"2023-05-23T13:04:07Z","title":"Patch-Mix Contrastive Learning with Audio Spectrogram Transformer on\n  Respiratory Sound Classification","summary":"  Respiratory sound contains crucial information for the early diagnosis of\nfatal lung diseases. Since the COVID-19 pandemic, there has been a growing\ninterest in contact-free medical care based on electronic stethoscopes. To this\nend, cutting-edge deep learning models have been developed to diagnose lung\ndiseases; however, it is still challenging due to the scarcity of medical data.\nIn this study, we demonstrate that the pretrained model on large-scale visual\nand audio datasets can be generalized to the respiratory sound classification\ntask. In addition, we introduce a straightforward Patch-Mix augmentation, which\nrandomly mixes patches between different samples, with Audio Spectrogram\nTransformer (AST). We further propose a novel and effective Patch-Mix\nContrastive Learning to distinguish the mixed representations in the latent\nspace. Our method achieves state-of-the-art performance on the ICBHI dataset,\noutperforming the prior leading score by an improvement of 4.08%.\n","authors":["Sangmin Bae","June-Woo Kim","Won-Yang Cho","Hyerim Baek","Soyoun Son","Byungjo Lee","Changwan Ha","Kyongpil Tae","Sungnyun Kim","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2305.14032v4.pdf","comment":"INTERSPEECH 2023, Code URL:\n  https://github.com/raymin0223/patch-mix_contrastive_learning"},{"id":"http://arxiv.org/abs/2311.13188v1","updated":"2023-11-22T06:30:54Z","published":"2023-11-22T06:30:54Z","title":"Cracking the Code of Negative Transfer: A Cooperative Game Theoretic\n  Approach for Cross-Domain Sequential Recommendation","summary":"  This paper investigates Cross-Domain Sequential Recommendation (CDSR), a\npromising method that uses information from multiple domains (more than three)\nto generate accurate and diverse recommendations, and takes into account the\nsequential nature of user interactions. The effectiveness of these systems\noften depends on the complex interplay among the multiple domains. In this\ndynamic landscape, the problem of negative transfer arises, where heterogeneous\nknowledge between dissimilar domains leads to performance degradation due to\ndifferences in user preferences across these domains. As a remedy, we propose a\nnew CDSR framework that addresses the problem of negative transfer by assessing\nthe extent of negative transfer from one domain to another and adaptively\nassigning low weight values to the corresponding prediction losses. To this\nend, the amount of negative transfer is estimated by measuring the marginal\ncontribution of each domain to model performance based on a cooperative game\ntheory. In addition, a hierarchical contrastive learning approach that\nincorporates information from the sequence of coarse-level categories into that\nof fine-level categories (e.g., item level) when implementing contrastive\nlearning was developed to mitigate negative transfer. Despite the potentially\nlow relevance between domains at the fine-level, there may be higher relevance\nat the category level due to its generalised and broader preferences. We show\nthat our model is superior to prior works in terms of model performance on two\nreal-world datasets across ten different domains.\n","authors":["Chung Park","Taesan Kim","Taekyoon Choi","Junui Hong","Yelim Yu","Mincheol Cho","Kyunam Lee","Sungil Ryu","Hyungjun Yoon","Minsung Choi","Jaegul Choo"],"pdf_url":"https://arxiv.org/pdf/2311.13188v1.pdf","comment":"Accepted at 32nd ACM International Conference on Information and\n  Knowledge Management (CIKM 2023)"},{"id":"http://arxiv.org/abs/2311.13184v1","updated":"2023-11-22T06:23:18Z","published":"2023-11-22T06:23:18Z","title":"AS-LLM: When Algorithm Selection Meets Large Language Model","summary":"  Algorithm selection aims to identify the most suitable algorithm for solving\na specific problem before execution, which has become a critical process of the\nAutoML. Current mainstream algorithm selection techniques rely heavily on\nfeature representations of various problems and employ the performance of each\nalgorithm as supervised information. However, there is a significant research\ngap concerning the consideration of algorithm features. This gap is primarily\nattributed to the inherent complexity of algorithms, making it particularly\nchallenging to find a universally effective feature extraction method that is\napplicable across a diverse range of algorithms. Unfortunately, neglecting this\naspect undoubtedly impacts the accuracy of algorithm selection and indirectly\nnecessitates an increased volume of problem data for training purposes. This\npaper takes a significant stride towards addressing this gap by proposing an\napproach that integrates algorithm representation into the algorithm selection\nprocess. Specifically, our proposed model employs distinct modules to extract\nrepresentations of both problems and algorithms, where the algorithm\nrepresentation leverages the capabilities of pre-trained LLMs in the realm of\ncode comprehension. Following the extraction of embedding vectors for both\nalgorithms and problems, the most suitable algorithm is determined through\ncalculations of matching degrees. Our experiments not only validate the\neffectiveness of the proposed model but also showcase the performance of\ndifferent embedded pre-trained LLMs, which suggests that the proposed algorithm\nselection framework holds the potential to serve as a baseline task for\nevaluating the code representation capabilities of LLMs.\n","authors":["Xingyu Wu","Yan Zhong","Jibin Wu","Kay Chen Tan"],"pdf_url":"https://arxiv.org/pdf/2311.13184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10986v2","updated":"2023-11-22T06:15:00Z","published":"2023-11-18T06:40:39Z","title":"EdgeFM: Leveraging Foundation Model for Open-set Learning on the Edge","summary":"  Deep Learning (DL) models have been widely deployed on IoT devices with the\nhelp of advancements in DL algorithms and chips. However, the limited resources\nof edge devices make these on-device DL models hard to be generalizable to\ndiverse environments and tasks. Although the recently emerged foundation models\n(FMs) show impressive generalization power, how to effectively leverage the\nrich knowledge of FMs on resource-limited edge devices is still not explored.\nIn this paper, we propose EdgeFM, a novel edge-cloud cooperative system with\nopen-set recognition capability. EdgeFM selectively uploads unlabeled data to\nquery the FM on the cloud and customizes the specific knowledge and\narchitectures for edge models. Meanwhile, EdgeFM conducts dynamic model\nswitching at run-time taking into account both data uncertainty and dynamic\nnetwork variations, which ensures the accuracy always close to the original FM.\nWe implement EdgeFM using two FMs on two edge platforms. We evaluate EdgeFM on\nthree public datasets and two self-collected datasets. Results show that EdgeFM\ncan reduce the end-to-end latency up to 3.2x and achieve 34.3% accuracy\nincrease compared with the baseline.\n","authors":["Bufang Yang","Lixing He","Neiwen Ling","Zhenyu Yan","Guoliang Xing","Xian Shuai","Xiaozhe Ren","Xin Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.10986v2.pdf","comment":"Accepted to the 21th ACM Conference on Embedded Networked Sensor\n  Systems (SenSys 2023)"},{"id":"http://arxiv.org/abs/2311.13180v1","updated":"2023-11-22T06:06:54Z","published":"2023-11-22T06:06:54Z","title":"Provably Efficient High-Dimensional Bandit Learning with Batched\n  Feedbacks","summary":"  We study high-dimensional multi-armed contextual bandits with batched\nfeedback where the $T$ steps of online interactions are divided into $L$\nbatches. In specific, each batch collects data according to a policy that\ndepends on previous batches and the rewards are revealed only at the end of the\nbatch. Such a feedback structure is popular in applications such as\npersonalized medicine and online advertisement, where the online data often do\nnot arrive in a fully serial manner. We consider high-dimensional and linear\nsettings where the reward function of the bandit model admits either a sparse\nor low-rank structure and ask how small a number of batches are needed for a\ncomparable performance with fully dynamic data in which $L = T$. For these\nsettings, we design a provably sample-efficient algorithm which achieves a $\n\\mathcal{\\tilde O}(s_0^2 \\log^2 T)$ regret in the sparse case and $\n\\mathcal{\\tilde O} ( r ^2 \\log^2 T)$ regret in the low-rank case, using only $L\n= \\mathcal{O}( \\log T)$ batches. Here $s_0$ and $r$ are the sparsity and rank\nof the reward parameter in sparse and low-rank cases, respectively, and $\n\\mathcal{\\tilde O}(\\cdot)$ omits logarithmic factors involving the feature\ndimensions. In other words, our algorithm achieves regret bounds comparable to\nthose in fully sequential setting with only $\\mathcal{O}( \\log T)$ batches. Our\nalgorithm features a novel batch allocation method that adjusts the batch sizes\naccording to the estimation accuracy within each batch and cumulative regret.\nFurthermore, we also conduct experiments with synthetic and real-world data to\nvalidate our theory.\n","authors":["Jianqing Fan","Zhaoran Wang","Zhuoran Yang","Chenlu Ye"],"pdf_url":"https://arxiv.org/pdf/2311.13180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13174v1","updated":"2023-11-22T05:38:53Z","published":"2023-11-22T05:38:53Z","title":"SecureCut: Federated Gradient Boosting Decision Trees with Efficient\n  Machine Unlearning","summary":"  In response to legislation mandating companies to honor the \\textit{right to\nbe forgotten} by erasing user data, it has become imperative to enable data\nremoval in Vertical Federated Learning (VFL) where multiple parties provide\nprivate features for model training. In VFL, data removal, i.e.,\n\\textit{machine unlearning}, often requires removing specific features across\nall samples under privacy guarentee in federated learning. To address this\nchallenge, we propose \\methname, a novel Gradient Boosting Decision Tree (GBDT)\nframework that effectively enables both \\textit{instance unlearning} and\n\\textit{feature unlearning} without the need for retraining from scratch.\nLeveraging a robust GBDT structure, we enable effective data deletion while\nreducing degradation of model performance. Extensive experimental results on\npopular datasets demonstrate that our method achieves superior model utility\nand forgetfulness compared to \\textit{state-of-the-art} methods. To our best\nknowledge, this is the first work that investigates machine unlearning in VFL\nscenarios.\n","authors":["Jian Zhang","Bowen Li Jie Li","Chentao Wu"],"pdf_url":"https://arxiv.org/pdf/2311.13174v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.08837v2","updated":"2023-11-22T05:32:14Z","published":"2023-04-18T09:05:07Z","title":"Sensor Fault Detection and Isolation in Autonomous Nonlinear Systems\n  Using Neural Network-Based Observers","summary":"  This paper presents a novel observer-based approach to detect and isolate\nfaulty sensors in nonlinear systems. The proposed sensor fault detection and\nisolation (s-FDI) method applies to a general class of nonlinear systems. Our\nfocus is on s-FDI for two types of faults: complete failure and sensor\ndegradation. The key aspect of this approach lies in the utilization of a\nneural network-based Kazantzis-Kravaris/Luenberger (KKL) observer. The neural\nnetwork is trained to learn the dynamics of the observer, enabling accurate\noutput predictions of the system. Sensor faults are detected by comparing the\nactual output measurements with the predicted values. If the difference\nsurpasses a theoretical threshold, a sensor fault is detected. To identify and\nisolate which sensor is faulty, we compare the numerical difference of each\nsensor meassurement with an empirically derived threshold. We derive both\ntheoretical and empirical thresholds for detection and isolation, respectively.\nNotably, the proposed approach is robust to measurement noise and system\nuncertainties. Its effectiveness is demonstrated through numerical simulations\nof sensor faults in a network of Kuramoto oscillators.\n","authors":["John Cao","Muhammad Umar B. Niazi","Matthieu Barreau","Karl Henrik Johansson"],"pdf_url":"https://arxiv.org/pdf/2304.08837v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13171v1","updated":"2023-11-22T05:28:59Z","published":"2023-11-22T05:28:59Z","title":"ComPEFT: Compression for Communicating Parameter Efficient Updates via\n  Sparsification and Quantization","summary":"  Parameter-efficient fine-tuning (PEFT) techniques make it possible to\nefficiently adapt a language model to create \"expert\" models that specialize to\nnew tasks or domains. Recent techniques in model merging and compositional\ngeneralization leverage these expert models by dynamically composing modules to\nimprove zero/few-shot generalization. Despite the efficiency of PEFT methods,\nthe size of expert models can make it onerous to retrieve expert models per\nquery over high-latency networks like the Internet or serve multiple experts on\na single GPU. To address these issues, we present ComPEFT, a novel method for\ncompressing fine-tuning residuals (task vectors) of PEFT based models. ComPEFT\nemploys sparsification and ternary quantization to reduce the size of the PEFT\nmodule without performing any additional retraining while preserving or\nenhancing model performance. In extensive evaluation across T5, T0, and\nLLaMA-based models with 200M - 65B parameters, ComPEFT achieves compression\nratios of 8x - 50x. In particular, we show that ComPEFT improves with scale -\nstronger models exhibit higher compressibility and better performance. For\nexample, we show that ComPEFT applied to LLaMA outperforms QLoRA by 4.16% on\nMMLU with a storage size reduction of up to 26x. In addition, we show that the\ncompressed experts produced by ComPEFT maintain few-shot compositional\ngeneralization capabilities, facilitate efficient communication and\ncomputation, and exhibit enhanced performance when merged. Lastly, we provide\nan analysis of different method components, compare it with other PEFT methods,\nand test ComPEFT's efficacy for compressing the residual of full-finetuning.\nOur code is available at https://github.com/prateeky2806/compeft.\n","authors":["Prateek Yadav","Leshem Choshen","Colin Raffel","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2311.13171v1.pdf","comment":"25 Pages, 6 Figures, 16 Tables"},{"id":"http://arxiv.org/abs/2311.13169v1","updated":"2023-11-22T05:25:24Z","published":"2023-11-22T05:25:24Z","title":"SiGeo: Sub-One-Shot NAS via Information Theory and Geometry of Loss\n  Landscape","summary":"  Neural Architecture Search (NAS) has become a widely used tool for automating\nneural network design. While one-shot NAS methods have successfully reduced\ncomputational requirements, they often require extensive training. On the other\nhand, zero-shot NAS utilizes training-free proxies to evaluate a candidate\narchitecture's test performance but has two limitations: (1) inability to use\nthe information gained as a network improves with training and (2) unreliable\nperformance, particularly in complex domains like RecSys, due to the\nmulti-modal data inputs and complex architecture configurations. To synthesize\nthe benefits of both methods, we introduce a \"sub-one-shot\" paradigm that\nserves as a bridge between zero-shot and one-shot NAS. In sub-one-shot NAS, the\nsupernet is trained using only a small subset of the training data, a phase we\nrefer to as \"warm-up.\" Within this framework, we present SiGeo, a proxy founded\non a novel theoretical framework that connects the supernet warm-up with the\nefficacy of the proxy. Extensive experiments have shown that SiGeo, with the\nbenefit of warm-up, consistently outperforms state-of-the-art NAS proxies on\nvarious established NAS benchmarks. When a supernet is warmed up, it can\nachieve comparable performance to weight-sharing one-shot NAS methods, but with\na significant reduction ($\\sim 60$\\%) in computational costs.\n","authors":["Hua Zheng","Kuang-Hung Liu","Igor Fedorov","Xin Zhang","Wen-Yen Chen","Wei Wen"],"pdf_url":"https://arxiv.org/pdf/2311.13169v1.pdf","comment":"24 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.13166v1","updated":"2023-11-22T05:17:42Z","published":"2023-11-22T05:17:42Z","title":"AdaptiveFL: Adaptive Heterogeneous Federated Learning for\n  Resource-Constrained AIoT Systems","summary":"  Although Federated Learning (FL) is promising to enable collaborative\nlearning among Artificial Intelligence of Things (AIoT) devices, it suffers\nfrom the problem of low classification performance due to various heterogeneity\nfactors (e.g., computing capacity, memory size) of devices and uncertain\noperating environments. To address these issues, this paper introduces an\neffective FL approach named AdaptiveFL based on a novel fine-grained width-wise\nmodel pruning strategy, which can generate various heterogeneous local models\nfor heterogeneous AIoT devices. By using our proposed reinforcement\nlearning-based device selection mechanism, AdaptiveFL can adaptively dispatch\nsuitable heterogeneous models to corresponding AIoT devices on the fly based on\ntheir available resources for local training. Experimental results show that,\ncompared to state-of-the-art methods, AdaptiveFL can achieve up to 16.83%\ninference improvements for both IID and non-IID scenarios.\n","authors":["Chentao Jia","Ming Hu","Zekai Chen","Yanxin Yang","Xiaofei Xie","Yang Liu","Mingsong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13166v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13163v1","updated":"2023-11-22T05:09:50Z","published":"2023-11-22T05:09:50Z","title":"Have Your Cake and Eat It Too: Toward Efficient and Accurate Split\n  Federated Learning","summary":"  Due to its advantages in resource constraint scenarios, Split Federated\nLearning (SFL) is promising in AIoT systems. However, due to data heterogeneity\nand stragglers, SFL suffers from the challenges of low inference accuracy and\nlow efficiency. To address these issues, this paper presents a novel SFL\napproach, named Sliding Split Federated Learning (S$^2$FL), which adopts an\nadaptive sliding model split strategy and a data balance-based training\nmechanism. By dynamically dispatching different model portions to AIoT devices\naccording to their computing capability, S$^2$FL can alleviate the low training\nefficiency caused by stragglers. By combining features uploaded by devices with\ndifferent data distributions to generate multiple larger batches with a uniform\ndistribution for back-propagation, S$^2$FL can alleviate the performance\ndegradation caused by data heterogeneity. Experimental results demonstrate\nthat, compared to conventional SFL, S$^2$FL can achieve up to 16.5\\% inference\naccuracy improvement and 3.54X training acceleration.\n","authors":["Dengke Yan","Ming Hu","Zeke Xia","Yanxin Yang","Jun Xia","Xiaofei Xie","Mingsong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13163v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.08494v2","updated":"2023-11-22T04:59:04Z","published":"2022-02-17T07:56:46Z","title":"Learning continuous models for continuous physics","summary":"  Dynamical systems that evolve continuously over time are ubiquitous\nthroughout science and engineering. Machine learning (ML) provides data-driven\napproaches to model and predict the dynamics of such systems. A core issue with\nthis approach is that ML models are typically trained on discrete data, using\nML methodologies that are not aware of underlying continuity properties. This\nresults in models that often do not capture any underlying continuous dynamics\n-- either of the system of interest, or indeed of any related system. To\naddress this challenge, we develop a convergence test based on numerical\nanalysis theory. Our test verifies whether a model has learned a function that\naccurately approximates an underlying continuous dynamics. Models that fail\nthis test fail to capture relevant dynamics, rendering them of limited utility\nfor many scientific prediction tasks; while models that pass this test enable\nboth better interpolation and better extrapolation in multiple ways. Our\nresults illustrate how principled numerical analysis methods can be coupled\nwith existing ML training/testing methodologies to validate models for science\nand engineering applications.\n","authors":["Aditi S. Krishnapriyan","Alejandro F. Queiruga","N. Benjamin Erichson","Michael W. Mahoney"],"pdf_url":"https://arxiv.org/pdf/2202.08494v2.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2311.13159v1","updated":"2023-11-22T04:49:16Z","published":"2023-11-22T04:49:16Z","title":"Multi-Objective Optimization via Wasserstein-Fisher-Rao Gradient Flow","summary":"  Multi-objective optimization (MOO) aims to optimize multiple, possibly\nconflicting objectives with widespread applications. We introduce a novel\ninteracting particle method for MOO inspired by molecular dynamics simulations.\nOur approach combines overdamped Langevin and birth-death dynamics,\nincorporating a \"dominance potential\" to steer particles toward global Pareto\noptimality. In contrast to previous methods, our method is able to relocate\ndominated particles, making it particularly adept at managing Pareto fronts of\ncomplicated geometries. Our method is also theoretically grounded as a\nWasserstein-Fisher-Rao gradient flow with convergence guarantees. Extensive\nexperiments confirm that our approach outperforms state-of-the-art methods on\nchallenging synthetic and real-world datasets.\n","authors":["Yinuo Ren","Tesi Xiao","Tanmay Gangwani","Anshuka Rangi","Holakou Rahmanian","Lexing Ying","Subhajit Sanyal"],"pdf_url":"https://arxiv.org/pdf/2311.13159v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.14606v2","updated":"2023-11-22T04:34:57Z","published":"2023-08-28T14:20:53Z","title":"On the Tradeoff between Privacy Preservation and Byzantine-Robustness in\n  Decentralized Learning","summary":"  This paper jointly considers privacy preservation and Byzantine-robustness in\ndecentralized learning. In a decentralized network, honest-but-curious agents\nfaithfully follow the prescribed algorithm, but expect to infer their\nneighbors' private data from messages received during the learning process,\nwhile dishonest-and-Byzantine agents disobey the prescribed algorithm, and\ndeliberately disseminate wrong messages to their neighbors so as to bias the\nlearning process. For this novel setting, we investigate a generic\nprivacy-preserving and Byzantine-robust decentralized stochastic gradient\ndescent (SGD) framework, in which Gaussian noise is injected to preserve\nprivacy and robust aggregation rules are adopted to counteract Byzantine\nattacks. We analyze its learning error and privacy guarantee, discovering an\nessential tradeoff between privacy preservation and Byzantine-robustness in\ndecentralized learning -- the learning error caused by defending against\nByzantine attacks is exacerbated by the Gaussian noise added to preserve\nprivacy. For a class of state-of-the-art robust aggregation rules, we give\nunified analysis of the \"mixing abilities\". Building upon this analysis, we\nreveal how the \"mixing abilities\" affect the tradeoff between privacy\npreservation and Byzantine-robustness. The theoretical results provide\nguidelines for achieving a favorable tradeoff with proper design of robust\naggregation rules. Numerical experiments are conducted and corroborate our\ntheoretical findings.\n","authors":["Haoxiang Ye","Heng Zhu","Qing Ling"],"pdf_url":"https://arxiv.org/pdf/2308.14606v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13154v1","updated":"2023-11-22T04:34:09Z","published":"2023-11-22T04:34:09Z","title":"Testing Closeness of Multivariate Distributions via Ramsey Theory","summary":"  We investigate the statistical task of closeness (or equivalence) testing for\nmultidimensional distributions. Specifically, given sample access to two\nunknown distributions $\\mathbf p, \\mathbf q$ on $\\mathbb R^d$, we want to\ndistinguish between the case that $\\mathbf p=\\mathbf q$ versus $\\|\\mathbf\np-\\mathbf q\\|_{A_k} > \\epsilon$, where $\\|\\mathbf p-\\mathbf q\\|_{A_k}$ denotes\nthe generalized ${A}_k$ distance between $\\mathbf p$ and $\\mathbf q$ --\nmeasuring the maximum discrepancy between the distributions over any collection\nof $k$ disjoint, axis-aligned rectangles. Our main result is the first\ncloseness tester for this problem with {\\em sub-learning} sample complexity in\nany fixed dimension and a nearly-matching sample complexity lower bound.\n  In more detail, we provide a computationally efficient closeness tester with\nsample complexity $O\\left((k^{6/7}/ \\mathrm{poly}_d(\\epsilon))\n\\log^d(k)\\right)$. On the lower bound side, we establish a qualitatively\nmatching sample complexity lower bound of\n$\\Omega(k^{6/7}/\\mathrm{poly}(\\epsilon))$, even for $d=2$. These sample\ncomplexity bounds are surprising because the sample complexity of the problem\nin the univariate setting is $\\Theta(k^{4/5}/\\mathrm{poly}(\\epsilon))$. This\nhas the interesting consequence that the jump from one to two dimensions leads\nto a substantial increase in sample complexity, while increases beyond that do\nnot.\n  As a corollary of our general $A_k$ tester, we obtain $d_{\\mathrm\nTV}$-closeness testers for pairs of $k$-histograms on $\\mathbb R^d$ over a\ncommon unknown partition, and pairs of uniform distributions supported on the\nunion of $k$ unknown disjoint axis-aligned rectangles.\n  Both our algorithm and our lower bound make essential use of tools from\nRamsey theory.\n","authors":["Ilias Diakonikolas","Daniel M. Kane","Sihan Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13154v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.09936v2","updated":"2023-11-22T04:29:33Z","published":"2023-08-19T07:53:43Z","title":"BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual\n  Questions","summary":"  Vision Language Models (VLMs), which extend Large Language Models (LLM) by\nincorporating visual understanding capability, have demonstrated significant\nadvancements in addressing open-ended visual question-answering (VQA) tasks.\nHowever, these models cannot accurately interpret images infused with text, a\ncommon occurrence in real-world scenarios. Standard procedures for extracting\ninformation from images often involve learning a fixed set of query embeddings.\nThese embeddings are designed to encapsulate image contexts and are later used\nas soft prompt inputs in LLMs. Yet, this process is limited to the token count,\npotentially curtailing the recognition of scenes with text-rich context. To\nimprove upon them, the present study introduces BLIVA: an augmented version of\nInstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings\nfrom InstructBLIP and also directly projects encoded patch embeddings into the\nLLM, a technique inspired by LLaVA. This approach assists the model to capture\nintricate details potentially missed during the query decoding process.\nEmpirical evidence demonstrates that our model, BLIVA, significantly enhances\nperformance in processing text-rich VQA benchmarks (up to 17.76% in OCR-VQA\nbenchmark) and in undertaking general (not particularly text-rich) VQA\nbenchmarks (up to 7.9% in Visual Spatial Reasoning benchmark), comparing to our\nbaseline InstructBLIP. BLIVA demonstrates significant capability in decoding\nreal-world images, irrespective of text presence. To demonstrate the broad\nindustry applications enabled by BLIVA, we evaluate the model using a new\ndataset comprising YouTube thumbnails paired with question-answer sets across\n11 diverse categories. For researchers interested in further exploration, our\ncode and models are freely accessible at https://github.com/mlpc-ucsd/BLIVA.\n","authors":["Wenbo Hu","Yifan Xu","Yi Li","Weiyue Li","Zeyuan Chen","Zhuowen Tu"],"pdf_url":"https://arxiv.org/pdf/2308.09936v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13147v1","updated":"2023-11-22T04:18:23Z","published":"2023-11-22T04:18:23Z","title":"Optimal Transport with Cyclic Symmetry","summary":"  We propose novel fast algorithms for optimal transport (OT) utilizing a\ncyclic symmetry structure of input data. Such OT with cyclic symmetry appears\nuniversally in various real-world examples: image processing, urban planning,\nand graph processing. Our main idea is to reduce OT to a small optimization\nproblem that has significantly fewer variables by utilizing cyclic symmetry and\nvarious optimization techniques. On the basis of this reduction, our algorithms\nsolve the small optimization problem instead of the original OT. As a result,\nour algorithms obtain the optimal solution and the objective function value of\nthe original OT faster than solving the original OT directly. In this paper,\nour focus is on two crucial OT formulations: the linear programming OT (LOT)\nand the strongly convex-regularized OT, which includes the well-known\nentropy-regularized OT (EROT). Experiments show the effectiveness of our\nalgorithms for LOT and EROT in synthetic/real-world data that has a\nstrict/approximate cyclic symmetry structure. Through theoretical and\nexperimental results, this paper successfully introduces the concept of\nsymmetry into the OT research field for the first time.\n","authors":["Shoichiro Takeda","Yasunori Akagi","Naoki Marumo","Kenta Niwa"],"pdf_url":"https://arxiv.org/pdf/2311.13147v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12068v2","updated":"2023-11-22T04:13:38Z","published":"2023-11-19T17:28:28Z","title":"Enhancing Novel Object Detection via Cooperative Foundational Models","summary":"  In this work, we address the challenging and emergent problem of novel object\ndetection (NOD), focusing on the accurate detection of both known and novel\nobject categories during inference. Traditional object detection algorithms are\ninherently closed-set, limiting their capability to handle NOD. We present a\nnovel approach to transform existing closed-set detectors into open-set\ndetectors. This transformation is achieved by leveraging the complementary\nstrengths of pre-trained foundational models, specifically CLIP and SAM,\nthrough our cooperative mechanism. Furthermore, by integrating this mechanism\nwith state-of-the-art open-set detectors such as GDINO, we establish new\nbenchmarks in object detection performance. Our method achieves 17.42 mAP in\nnovel object detection and 42.08 mAP for known objects on the challenging LVIS\ndataset. Adapting our approach to the COCO OVD split, we surpass the current\nstate-of-the-art by a margin of 7.2 $ \\text{AP}_{50} $ for novel classes. Our\ncode is available at\nhttps://github.com/rohit901/cooperative-foundational-models .\n","authors":["Rohit Bharadwaj","Muzammal Naseer","Salman Khan","Fahad Shahbaz Khan"],"pdf_url":"https://arxiv.org/pdf/2311.12068v2.pdf","comment":"Code: https://github.com/rohit901/cooperative-foundational-models"},{"id":"http://arxiv.org/abs/2309.11983v2","updated":"2023-11-22T04:10:53Z","published":"2023-09-21T11:39:33Z","title":"Variational Connectionist Temporal Classification for Order-Preserving\n  Sequence Modeling","summary":"  Connectionist temporal classification (CTC) is commonly adopted for sequence\nmodeling tasks like speech recognition, where it is necessary to preserve order\nbetween the input and target sequences. However, CTC is only applied to\ndeterministic sequence models, where the latent space is discontinuous and\nsparse, which in turn makes them less capable of handling data variability when\ncompared to variational models. In this paper, we integrate CTC with a\nvariational model and derive loss functions that can be used to train more\ngeneralizable sequence models that preserve order. Specifically, we derive two\nversions of the novel variational CTC based on two reasonable assumptions, the\nfirst being that the variational latent variables at each time step are\nconditionally independent; and the second being that these latent variables are\nMarkovian. We show that both loss functions allow direct optimization of the\nvariational lower bound for the model log-likelihood, and present\ncomputationally tractable forms for implementing them.\n","authors":["Zheng Nan","Ting Dang","Vidhyasaharan Sethu","Beena Ahmed"],"pdf_url":"https://arxiv.org/pdf/2309.11983v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13133v1","updated":"2023-11-22T03:37:01Z","published":"2023-11-22T03:37:01Z","title":"LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms","summary":"  Large Language Models are traditionally finetuned on large instruction\ndatasets. However recent studies suggest that small, high-quality datasets can\nsuffice for general purpose instruction following. This lack of consensus\nsurrounding finetuning best practices is in part due to rapidly diverging\napproaches to LLM evaluation. In this study, we ask whether a small amount of\ndiverse finetuning samples can improve performance on both traditional\nperplexity-based NLP benchmarks, and on open-ended, model-based evaluation. We\nfinetune open-source MPT-7B and MPT-30B models on instruction finetuning\ndatasets of various sizes ranging from 1k to 60k samples. We find that subsets\nof 1k-6k instruction finetuning samples are sufficient to achieve good\nperformance on both (1) traditional NLP benchmarks and (2) model-based\nevaluation. Finally, we show that mixing textbook-style and open-ended QA\nfinetuning datasets optimizes performance on both evaluation paradigms.\n","authors":["Aditi Jha","Sam Havens","Jeremey Dohmann","Alex Trott","Jacob Portes"],"pdf_url":"https://arxiv.org/pdf/2311.13133v1.pdf","comment":"36 pages, 12 figures, NeurIPS 2023 Workshop on Instruction Tuning and\n  Instruction Following"},{"id":"http://arxiv.org/abs/2306.08280v2","updated":"2023-11-22T03:22:18Z","published":"2023-06-14T06:35:10Z","title":"Differentially Private Wireless Federated Learning Using Orthogonal\n  Sequences","summary":"  We propose a privacy-preserving uplink over-the-air computation (AirComp)\nmethod, termed FLORAS, for single-input single-output (SISO) wireless federated\nlearning (FL) systems. From the perspective of communication designs, FLORAS\neliminates the requirement of channel state information at the transmitters\n(CSIT) by leveraging the properties of orthogonal sequences. From the privacy\nperspective, we prove that FLORAS offers both item-level and client-level\ndifferential privacy (DP) guarantees. Moreover, by properly adjusting the\nsystem parameters, FLORAS can flexibly achieve different DP levels at no\nadditional cost. A new FL convergence bound is derived which, combined with the\nprivacy guarantees, allows for a smooth tradeoff between the achieved\nconvergence rate and differential privacy levels. Experimental results\ndemonstrate the advantages of FLORAS compared with the baseline AirComp method,\nand validate that the analytical results can guide the design of\nprivacy-preserving FL with different tradeoff requirements on the model\nconvergence and privacy levels.\n","authors":["Xizixiang Wei","Tianhao Wang","Ruiquan Huang","Cong Shen","Jing Yang","H. Vincent Poor"],"pdf_url":"https://arxiv.org/pdf/2306.08280v2.pdf","comment":"33 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.04889v2","updated":"2023-11-22T03:02:46Z","published":"2023-06-08T02:35:30Z","title":"ShaDDR: Interactive Example-Based Geometry and Texture Generation via 3D\n  Shape Detailization and Differentiable Rendering","summary":"  We present ShaDDR, an example-based deep generative neural network which\nproduces a high-resolution textured 3D shape through geometry detailization and\nconditional texture generation applied to an input coarse voxel shape. Trained\non a small set of detailed and textured exemplar shapes, our method learns to\ndetailize the geometry via multi-resolution voxel upsampling and generate\ntextures on voxel surfaces via differentiable rendering against exemplar\ntexture images from a few views. The generation is interactive, taking less\nthan 1 second to produce a 3D model with voxel resolutions up to 512^3. The\ngenerated shape preserves the overall structure of the input coarse voxel\nmodel, while the style of the generated geometric details and textures can be\nmanipulated through learned latent codes. In the experiments, we show that our\nmethod can generate higher-resolution shapes with plausible and improved\ngeometric details and clean textures compared to prior works. Furthermore, we\nshowcase the ability of our method to learn geometric details and textures from\nshapes reconstructed from real-world photos. In addition, we have developed an\ninteractive modeling application to demonstrate the generalizability of our\nmethod to various user inputs and the controllability it offers, allowing users\nto interactively sculpt a coarse voxel shape to define the overall structure of\nthe detailized 3D shape. Code and data are available at\nhttps://github.com/qiminchen/ShaDDR.\n","authors":["Qimin Chen","Zhiqin Chen","Hang Zhou","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.04889v2.pdf","comment":"Accepted to SIGGRAPH Asia 2023 conference track. Code:\n  https://github.com/qiminchen/ShaDDR"},{"id":"http://arxiv.org/abs/2311.13118v1","updated":"2023-11-22T02:45:01Z","published":"2023-11-22T02:45:01Z","title":"Combatting Human Trafficking in the Cyberspace: A Natural Language\n  Processing-Based Methodology to Analyze the Language in Online Advertisements","summary":"  This project tackles the pressing issue of human trafficking in online C2C\nmarketplaces through advanced Natural Language Processing (NLP) techniques. We\nintroduce a novel methodology for generating pseudo-labeled datasets with\nminimal supervision, serving as a rich resource for training state-of-the-art\nNLP models. Focusing on tasks like Human Trafficking Risk Prediction (HTRP) and\nOrganized Activity Detection (OAD), we employ cutting-edge Transformer models\nfor analysis. A key contribution is the implementation of an interpretability\nframework using Integrated Gradients, providing explainable insights crucial\nfor law enforcement. This work not only fills a critical gap in the literature\nbut also offers a scalable, machine learning-driven approach to combat human\nexploitation online. It serves as a foundation for future research and\npractical applications, emphasizing the role of machine learning in addressing\ncomplex social issues.\n","authors":["Alejandro Rodriguez Perez","Pablo Rivas"],"pdf_url":"https://arxiv.org/pdf/2311.13118v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08131v2","updated":"2023-11-22T02:35:37Z","published":"2022-12-15T20:36:10Z","title":"Bridging the Gap Between Offline and Online Reinforcement Learning\n  Evaluation Methodologies","summary":"  Reinforcement learning (RL) has shown great promise with algorithms learning\nin environments with large state and action spaces purely from scalar reward\nsignals. A crucial challenge for current deep RL algorithms is that they\nrequire a tremendous amount of environment interactions for learning. This can\nbe infeasible in situations where such interactions are expensive; such as in\nrobotics. Offline RL algorithms try to address this issue by bootstrapping the\nlearning process from existing logged data without needing to interact with the\nenvironment from the very beginning. While online RL algorithms are typically\nevaluated as a function of the number of environment interactions, there exists\nno single established protocol for evaluating offline RL methods.In this paper,\nwe propose a sequential approach to evaluate offline RL algorithms as a\nfunction of the training set size and thus by their data efficiency. Sequential\nevaluation provides valuable insights into the data efficiency of the learning\nprocess and the robustness of algorithms to distribution changes in the dataset\nwhile also harmonizing the visualization of the offline and online learning\nphases. Our approach is generally applicable and easy to implement. We compare\nseveral existing offline RL algorithms using this approach and present insights\nfrom a variety of tasks and offline datasets.\n","authors":["Shivakanth Sujit","Pedro H. M. Braga","Jorg Bornschein","Samira Ebrahimi Kahou"],"pdf_url":"https://arxiv.org/pdf/2212.08131v2.pdf","comment":"TMLR 2023"},{"id":"http://arxiv.org/abs/2305.16854v3","updated":"2023-11-22T02:29:13Z","published":"2023-05-26T12:04:59Z","title":"Channel and Gradient-Importance Aware Device Scheduling for Over-the-Air\n  Federated Learning","summary":"  Federated learning (FL) is a popular privacy-preserving distributed training\nscheme, where multiple devices collaborate to train machine learning models by\nuploading local model updates. To improve communication efficiency,\nover-the-air computation (AirComp) has been applied to FL, which leverages\nanalog modulation to harness the superposition property of radio waves such\nthat numerous devices can upload their model updates concurrently for\naggregation. However, the uplink channel noise incurs considerable model\naggregation distortion, which is critically determined by the device scheduling\nand compromises the learned model performance. In this paper, we propose a\nprobabilistic device scheduling framework for over-the-air FL, named PO-FL, to\nmitigate the negative impact of channel noise, where each device is scheduled\naccording to a certain probability and its model update is reweighted using\nthis probability in aggregation. We prove the unbiasedness of this aggregation\nscheme and demonstrate the convergence of PO-FL on both convex and non-convex\nloss functions. Our convergence bounds unveil that the device scheduling\naffects the learning performance through the communication distortion and\nglobal update variance. Based on the convergence analysis, we further develop a\nchannel and gradient-importance aware algorithm to optimize the device\nscheduling probabilities in PO-FL. Extensive simulation results show that the\nproposed PO-FL framework with channel and gradient-importance awareness\nachieves faster convergence and produces better models than baseline methods.\n","authors":["Yuchang Sun","Zehong lin","Yuyi Mao","Shi Jin","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.16854v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13110v1","updated":"2023-11-22T02:23:32Z","published":"2023-11-22T02:23:32Z","title":"White-Box Transformers via Sparse Rate Reduction: Compression Is All\n  There Is?","summary":"  In this paper, we contend that a natural objective of representation learning\nis to compress and transform the distribution of the data, say sets of tokens,\ntowards a low-dimensional Gaussian mixture supported on incoherent subspaces.\nThe goodness of such a representation can be evaluated by a principled measure,\ncalled sparse rate reduction, that simultaneously maximizes the intrinsic\ninformation gain and extrinsic sparsity of the learned representation. From\nthis perspective, popular deep network architectures, including transformers,\ncan be viewed as realizing iterative schemes to optimize this measure.\nParticularly, we derive a transformer block from alternating optimization on\nparts of this objective: the multi-head self-attention operator compresses the\nrepresentation by implementing an approximate gradient descent step on the\ncoding rate of the features, and the subsequent multi-layer perceptron\nsparsifies the features. This leads to a family of white-box transformer-like\ndeep network architectures, named CRATE, which are mathematically fully\ninterpretable. We show, by way of a novel connection between denoising and\ncompression, that the inverse to the aforementioned compressive encoding can be\nrealized by the same class of CRATE architectures. Thus, the so-derived\nwhite-box architectures are universal to both encoders and decoders.\nExperiments show that these networks, despite their simplicity, indeed learn to\ncompress and sparsify representations of large-scale real-world image and text\ndatasets, and achieve performance very close to highly engineered\ntransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the\nproposed computational framework demonstrates great potential in bridging the\ngap between theory and practice of deep learning, from a unified perspective of\ndata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .\n","authors":["Yaodong Yu","Sam Buchanan","Druv Pai","Tianzhe Chu","Ziyang Wu","Shengbang Tong","Hao Bai","Yuexiang Zhai","Benjamin D. Haeffele","Yi Ma"],"pdf_url":"https://arxiv.org/pdf/2311.13110v1.pdf","comment":"This paper integrates the works arXiv:2306.01129 and\n  arXiv:2308.16271, as well as this under-review work:\n  https://openreview.net/forum?id=PvyOYleymy into a complete story. In this\n  paper, we improve the writing and organization, and also add conceptual,\n  empirical, and theoretical improvements over the previous work"},{"id":"http://arxiv.org/abs/2311.13102v1","updated":"2023-11-22T02:04:35Z","published":"2023-11-22T02:04:35Z","title":"Detecting out-of-distribution text using topological features of\n  transformer-based language models","summary":"  We attempt to detect out-of-distribution (OOD) text samples though applying\nTopological Data Analysis (TDA) to attention maps in transformer-based language\nmodels. We evaluate our proposed TDA-based approach for out-of-distribution\ndetection on BERT, a transformer-based language model, and compare the to a\nmore traditional OOD approach based on BERT CLS embeddings. We found that our\nTDA approach outperforms the CLS embedding approach at distinguishing\nin-distribution data (politics and entertainment news articles from HuffPost)\nfrom far out-of-domain samples (IMDB reviews), but its effectiveness\ndeteriorates with near out-of-domain (CNN/Dailymail) or same-domain (business\nnews articles from HuffPost) datasets.\n","authors":["Andres Pollano","Anupam Chaudhuri","Anj Simmons"],"pdf_url":"https://arxiv.org/pdf/2311.13102v1.pdf","comment":"12 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2311.13099v1","updated":"2023-11-22T01:58:26Z","published":"2023-11-22T01:58:26Z","title":"PIE-NeRF: Physics-based Interactive Elastodynamics with NeRF","summary":"  We show that physics-based simulations can be seamlessly integrated with NeRF\nto generate high-quality elastodynamics of real-world objects. Unlike existing\nmethods, we discretize nonlinear hyperelasticity in a meshless way, obviating\nthe necessity for intermediate auxiliary shape proxies like a tetrahedral mesh\nor voxel grid. A quadratic generalized moving least square (Q-GMLS) is employed\nto capture nonlinear dynamics and large deformation on the implicit model. Such\nmeshless integration enables versatile simulations of complex and codimensional\nshapes. We adaptively place the least-square kernels according to the NeRF\ndensity field to significantly reduce the complexity of the nonlinear\nsimulation. As a result, physically realistic animations can be conveniently\nsynthesized using our method for a wide range of hyperelastic materials at an\ninteractive rate. For more information, please visit our project page at\nhttps://fytalon.github.io/pienerf/.\n","authors":["Yutao Feng","Yintong Shang","Xuan Li","Tianjia Shao","Chenfanfu Jiang","Yin Yang"],"pdf_url":"https://arxiv.org/pdf/2311.13099v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13094v1","updated":"2023-11-22T01:50:43Z","published":"2023-11-22T01:50:43Z","title":"Newton-CG methods for nonconvex unconstrained optimization with Hölder\n  continuous Hessian","summary":"  In this paper we consider a nonconvex unconstrained optimization problem\nminimizing a twice differentiable objective function with H\\\"older continuous\nHessian. Specifically, we first propose a Newton-conjugate gradient (Newton-CG)\nmethod for finding an approximate first-order stationary point (FOSP) of this\nproblem, assuming the associated the H\\\"older parameters are explicitly known.\nThen we develop a parameter-free Newton-CG method without requiring any prior\nknowledge of these parameters. To the best of our knowledge, this method is the\nfirst parameter-free second-order method achieving the best-known iteration and\noperation complexity for finding an approximate FOSP of this problem.\nFurthermore, we propose a Newton-CG method for finding an approximate\nsecond-order stationary point (SOSP) of the considered problem with high\nprobability and establish its iteration and operation complexity. Finally, we\npresent preliminary numerical results to demonstrate the superior practical\nperformance of our parameter-free Newton-CG method over a well-known\nregularized Newton method.\n","authors":["Chuan He","Zhaosong Lu"],"pdf_url":"https://arxiv.org/pdf/2311.13094v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2301.03139"},{"id":"http://arxiv.org/abs/2311.13091v1","updated":"2023-11-22T01:43:57Z","published":"2023-11-22T01:43:57Z","title":"Stable Unlearnable Example: Enhancing the Robustness of Unlearnable\n  Examples via Stable Error-Minimizing Noise","summary":"  The open source of large amounts of image data promotes the development of\ndeep learning techniques. Along with this comes the privacy risk of these\nopen-source image datasets being exploited by unauthorized third parties to\ntrain deep learning models for commercial or illegal purposes. To avoid the\nabuse of public data, a poisoning-based technique, the unlearnable example, is\nproposed to significantly degrade the generalization performance of models by\nadding a kind of imperceptible noise to the data. To further enhance its\nrobustness against adversarial training, existing works leverage iterative\nadversarial training on both the defensive noise and the surrogate model.\nHowever, it still remains unknown whether the robustness of unlearnable\nexamples primarily comes from the effect of enhancement in the surrogate model\nor the defensive noise. Observing that simply removing the adversarial noise on\nthe training process of the defensive noise can improve the performance of\nrobust unlearnable examples, we identify that solely the surrogate model's\nrobustness contributes to the performance. Furthermore, we found a negative\ncorrelation exists between the robustness of defensive noise and the protection\nperformance, indicating defensive noise's instability issue. Motivated by this,\nto further boost the robust unlearnable example, we introduce stable\nerror-minimizing noise (SEM), which trains the defensive noise against random\nperturbation instead of the time-consuming adversarial perturbation to improve\nthe stability of defensive noise. Through extensive experiments, we demonstrate\nthat SEM achieves a new state-of-the-art performance on CIFAR-10, CIFAR-100,\nand ImageNet Subset in terms of both effectiveness and efficiency. The code is\navailable at https://github.com/liuyixin-louis/Stable-Unlearnable-Example.\n","authors":["Yixin Liu","Kaidi Xu","Xun Chen","Lichao Sun"],"pdf_url":"https://arxiv.org/pdf/2311.13091v1.pdf","comment":"14 pages, 11 figures, 13 tables"},{"id":"http://arxiv.org/abs/2310.12942v3","updated":"2023-11-22T01:39:59Z","published":"2023-10-19T17:39:47Z","title":"On the Representational Capacity of Recurrent Neural Language Models","summary":"  This work investigates the computational expressivity of language models\n(LMs) based on recurrent neural networks (RNNs). Siegelmann and Sontag (1992)\nfamously showed that RNNs with rational weights and hidden states and unbounded\ncomputation time are Turing complete. However, LMs define weightings over\nstrings in addition to just (unweighted) language membership and the analysis\nof the computational power of RNN LMs (RLMs) should reflect this. We extend the\nTuring completeness result to the probabilistic case, showing how a rationally\nweighted RLM with unbounded computation time can simulate any deterministic\nprobabilistic Turing machine (PTM) with rationally weighted transitions. Since,\nin practice, RLMs work in real-time, processing a symbol at every time step, we\ntreat the above result as an upper bound on the expressivity of RLMs. We also\nprovide a lower bound by showing that under the restriction to real-time\ncomputation, such models can simulate deterministic real-time rational PTMs.\n","authors":["Franz Nowak","Anej Svete","Li Du","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2310.12942v3.pdf","comment":"To be published at EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13087v1","updated":"2023-11-22T01:32:06Z","published":"2023-11-22T01:32:06Z","title":"Predict-Then-Optimize by Proxy: Learning Joint Models of Prediction and\n  Optimization","summary":"  Many real-world decision processes are modeled by optimization problems whose\ndefining parameters are unknown and must be inferred from observable data. The\nPredict-Then-Optimize framework uses machine learning models to predict unknown\nparameters of an optimization problem from features before solving. Recent\nworks show that decision quality can be improved in this setting by solving and\ndifferentiating the optimization problem in the training loop, enabling\nend-to-end training with loss functions defined directly on the resulting\ndecisions. However, this approach can be inefficient and requires handcrafted,\nproblem-specific rules for backpropagation through the optimization step. This\npaper proposes an alternative method, in which optimal solutions are learned\ndirectly from the observable features by predictive models. The approach is\ngeneric, and based on an adaptation of the Learning-to-Optimize paradigm, from\nwhich a rich variety of existing techniques can be employed. Experimental\nevaluations show the ability of several Learning-to-Optimize methods to provide\nefficient, accurate, and flexible solutions to an array of challenging\nPredict-Then-Optimize problems.\n","authors":["James Kotary","Vincenzo Di Vito","Jacob Christopher","Pascal Van Hentenryck","Ferdinando Fioretto"],"pdf_url":"https://arxiv.org/pdf/2311.13087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.00527v3","updated":"2023-11-22T01:11:46Z","published":"2021-08-01T19:20:34Z","title":"Gates Are Not What You Need in RNNs","summary":"  Recurrent neural networks have flourished in many areas. Consequently, we can\nsee new RNN cells being developed continuously, usually by creating or using\ngates in a new, original way. But what if we told you that gates in RNNs are\nredundant? In this paper, we propose a new recurrent cell called Residual\nRecurrent Unit (RRU) which beats traditional cells and does not employ a single\ngate. It is based on the residual shortcut connection, linear transformations,\nReLU, and normalization. To evaluate our cell's effectiveness, we compare its\nperformance against the widely-used GRU and LSTM cells and the recently\nproposed Mogrifier LSTM on several tasks including, polyphonic music modeling,\nlanguage modeling, and sentiment analysis. Our experiments show that RRU\noutperforms the traditional gated units on most of these tasks. Also, it has\nbetter robustness to parameter selection, allowing immediate application in new\ntasks without much tuning. We have implemented the RRU in TensorFlow, and the\ncode is made available at https://github.com/LUMII-Syslab/RRU .\n","authors":["Ronalds Zakovskis","Andis Draguns","Eliza Gaile","Emils Ozolins","Karlis Freivalds"],"pdf_url":"https://arxiv.org/pdf/2108.00527v3.pdf","comment":"Published in Artificial Intelligence and Soft Computing. ICAISC 2023.\n  Lecture Notes in Computer Science(), vol 14125. Springer, Cham., and is\n  available online at https://doi.org/10.1007/978-3-031-42505-9_27"},{"id":"http://arxiv.org/abs/2311.13081v1","updated":"2023-11-22T01:06:45Z","published":"2023-11-22T01:06:45Z","title":"Learning to Fly in Seconds","summary":"  Learning-based methods, particularly Reinforcement Learning (RL), hold great\npromise for streamlining deployment, enhancing performance, and achieving\ngeneralization in the control of autonomous multirotor aerial vehicles. Deep RL\nhas been able to control complex systems with impressive fidelity and agility\nin simulation but the simulation-to-reality transfer often brings a\nhard-to-bridge reality gap. Moreover, RL is commonly plagued by prohibitively\nlong training times. In this work, we propose a novel asymmetric\nactor-critic-based architecture coupled with a highly reliable RL-based\ntraining paradigm for end-to-end quadrotor control. We show how curriculum\nlearning and a highly optimized simulator enhance sample complexity and lead to\nfast training times. To precisely discuss the challenges related to\nlow-level/end-to-end multirotor control, we also introduce a taxonomy that\nclassifies the existing levels of control abstractions as well as\nnon-linearities and domain parameters. Our framework enables\nSimulation-to-Reality (Sim2Real) transfer for direct RPM control after only 18\nseconds of training on a consumer-grade laptop as well as its deployment on\nmicrocontrollers to control a multirotor under real-time guarantees. Finally,\nour solution exhibits competitive performance in trajectory tracking, as\ndemonstrated through various experimental comparisons with existing\nstate-of-the-art control solutions using a real Crazyflie nano quadrotor. We\nopen source the code including a very fast multirotor dynamics simulator that\ncan simulate about 5 months of flight per second on a laptop GPU. The fast\ntraining times and deployment to a cheap, off-the-shelf quadrotor lower the\nbarriers to entry and help democratize the research and development of these\nsystems.\n","authors":["Jonas Eschmann","Dario Albani","Giuseppe Loianno"],"pdf_url":"https://arxiv.org/pdf/2311.13081v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06202v3","updated":"2023-11-22T00:57:54Z","published":"2023-06-09T19:10:16Z","title":"NeuroGraph: Benchmarks for Graph Machine Learning in Brain Connectomics","summary":"  Machine learning provides a valuable tool for analyzing high-dimensional\nfunctional neuroimaging data, and is proving effective in predicting various\nneurological conditions, psychiatric disorders, and cognitive patterns. In\nfunctional magnetic resonance imaging (MRI) research, interactions between\nbrain regions are commonly modeled using graph-based representations. The\npotency of graph machine learning methods has been established across myriad\ndomains, marking a transformative step in data interpretation and predictive\nmodeling. Yet, despite their promise, the transposition of these techniques to\nthe neuroimaging domain has been challenging due to the expansive number of\npotential preprocessing pipelines and the large parameter search space for\ngraph-based dataset construction. In this paper, we introduce NeuroGraph, a\ncollection of graph-based neuroimaging datasets, and demonstrated its utility\nfor predicting multiple categories of behavioral and cognitive traits. We delve\ndeeply into the dataset generation search space by crafting 35 datasets that\nencompass static and dynamic brain connectivity, running in excess of 15\nbaseline methods for benchmarking. Additionally, we provide generic frameworks\nfor learning on both static and dynamic graphs. Our extensive experiments lead\nto several key observations. Notably, using correlation vectors as node\nfeatures, incorporating larger number of regions of interest, and employing\nsparser graphs lead to improved performance. To foster further advancements in\ngraph-based data driven neuroimaging analysis, we offer a comprehensive\nopen-source Python package that includes the benchmark datasets, baseline\nimplementations, model training, and standard evaluation.\n","authors":["Anwar Said","Roza G. Bayrak","Tyler Derr","Mudassir Shabbir","Daniel Moyer","Catie Chang","Xenofon Koutsoukos"],"pdf_url":"https://arxiv.org/pdf/2306.06202v3.pdf","comment":"NeurIPS23"},{"id":"http://arxiv.org/abs/2311.13073v1","updated":"2023-11-22T00:26:15Z","published":"2023-11-22T00:26:15Z","title":"FusionFrames: Efficient Architectural Aspects for Text-to-Video\n  Generation Pipeline","summary":"  Multimedia generation approaches occupy a prominent place in artificial\nintelligence research. Text-to-image models achieved high-quality results over\nthe last few years. However, video synthesis methods recently started to\ndevelop. This paper presents a new two-stage latent diffusion text-to-video\ngeneration architecture based on the text-to-image diffusion model. The first\nstage concerns keyframes synthesis to figure the storyline of a video, while\nthe second one is devoted to interpolation frames generation to make movements\nof the scene and objects smooth. We compare several temporal conditioning\napproaches for keyframes generation. The results show the advantage of using\nseparate temporal blocks over temporal layers in terms of metrics reflecting\nvideo generation quality aspects and human preference. The design of our\ninterpolation model significantly reduces computational costs compared to other\nmasked frame interpolation approaches. Furthermore, we evaluate different\nconfigurations of MoVQ-based video decoding scheme to improve consistency and\nachieve higher PSNR, SSIM, MSE, and LPIPS scores. Finally, we compare our\npipeline with existing solutions and achieve top-2 scores overall and top-1\namong open-source solutions: CLIPSIM = 0.2976 and FVD = 433.054. Project page:\nhttps://ai-forever.github.io/kandinsky-video/\n","authors":["Vladimir Arkhipkin","Zein Shaheen","Viacheslav Vasilev","Elizaveta Dakhova","Andrey Kuznetsov","Denis Dimitrov"],"pdf_url":"https://arxiv.org/pdf/2311.13073v1.pdf","comment":"Project page: https://ai-forever.github.io/kandinsky-video/"},{"id":"http://arxiv.org/abs/2311.11254v2","updated":"2023-11-22T00:10:58Z","published":"2023-11-19T06:44:13Z","title":"BOIS: Bayesian Optimization of Interconnected Systems","summary":"  Bayesian optimization (BO) has proven to be an effective paradigm for the\nglobal optimization of expensive-to-sample systems. One of the main advantages\nof BO is its use of Gaussian processes (GPs) to characterize model uncertainty\nwhich can be leveraged to guide the learning and search process. However, BO\ntypically treats systems as black-boxes and this limits the ability to exploit\nstructural knowledge (e.g., physics and sparse interconnections). Composite\nfunctions of the form $f(x, y(x))$, wherein GP modeling is shifted from the\nperformance function $f$ to an intermediate function $y$, offer an avenue for\nexploiting structural knowledge. However, the use of composite functions in a\nBO framework is complicated by the need to generate a probability density for\n$f$ from the Gaussian density of $y$ calculated by the GP (e.g., when $f$ is\nnonlinear it is not possible to obtain a closed-form expression). Previous work\nhas handled this issue using sampling techniques; these are easy to implement\nand flexible but are computationally intensive. In this work, we introduce a\nnew paradigm which allows for the efficient use of composite functions in BO;\nthis uses adaptive linearizations of $f$ to obtain closed-form expressions for\nthe statistical moments of the composite function. We show that this simple\napproach (which we call BOIS) enables the exploitation of structural knowledge,\nsuch as that arising in interconnected systems as well as systems that embed\nmultiple GP models and combinations of physics and GP models. Using a chemical\nprocess optimization case study, we benchmark the effectiveness of BOIS against\nstandard BO and sampling approaches. Our results indicate that BOIS achieves\nperformance gains and accurately captures the statistics of composite\nfunctions.\n","authors":["Leonardo D. González","Victor M. Zavala"],"pdf_url":"https://arxiv.org/pdf/2311.11254v2.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2310.12036v2","updated":"2023-11-22T00:02:49Z","published":"2023-10-18T15:21:28Z","title":"A General Theoretical Paradigm to Understand Learning from Human\n  Preferences","summary":"  The prevalent deployment of learning from human preferences through\nreinforcement learning (RLHF) relies on two important approximations: the first\nassumes that pairwise preferences can be substituted with pointwise rewards.\nThe second assumes that a reward model trained on these pointwise rewards can\ngeneralize from collected data to out-of-distribution data sampled by the\npolicy. Recently, Direct Preference Optimisation (DPO) has been proposed as an\napproach that bypasses the second approximation and learn directly a policy\nfrom collected data without the reward modelling stage. However, this method\nstill heavily relies on the first approximation.\n  In this paper we try to gain a deeper theoretical understanding of these\npractical algorithms. In particular we derive a new general objective called\n$\\Psi$PO for learning from human preferences that is expressed in terms of\npairwise preferences and therefore bypasses both approximations. This new\ngeneral objective allows us to perform an in-depth analysis of the behavior of\nRLHF and DPO (as special cases of $\\Psi$PO) and to identify their potential\npitfalls. We then consider another special case for $\\Psi$PO by setting $\\Psi$\nsimply to Identity, for which we can derive an efficient optimisation\nprocedure, prove performance guarantees and demonstrate its empirical\nsuperiority to DPO on some illustrative examples.\n","authors":["Mohammad Gheshlaghi Azar","Mark Rowland","Bilal Piot","Daniel Guo","Daniele Calandriello","Michal Valko","Rémi Munos"],"pdf_url":"https://arxiv.org/pdf/2310.12036v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13491v1","updated":"2023-11-22T16:08:38Z","published":"2023-11-22T16:08:38Z","title":"Grad-Shafranov equilibria via data-free physics informed neural networks","summary":"  A large number of magnetohydrodynamic (MHD) equilibrium calculations are\noften required for uncertainty quantification, optimization, and real-time\ndiagnostic information, making MHD equilibrium codes vital to the field of\nplasma physics. In this paper, we explore a method for solving the\nGrad-Shafranov equation by using Physics-Informed Neural Networks (PINNs). For\nPINNs, we optimize neural networks by directly minimizing the residual of the\nPDE as a loss function. We show that PINNs can accurately and effectively solve\nthe Grad-Shafranov equation with several different boundary conditions. We also\nexplore the parameter space by varying the size of the model, the learning\nrate, and boundary conditions to map various trade-offs such as between\nreconstruction error and computational speed. Additionally, we introduce a\nparameterized PINN framework, expanding the input space to include variables\nsuch as pressure, aspect ratio, elongation, and triangularity in order to\nhandle a broader range of plasma scenarios within a single network.\nParametrized PINNs could be used in future work to solve inverse problems such\nas shape optimization.\n","authors":["Byoungchan Jang","Alan A. Kaptanoglu","Rahul Gaur","Shaowu Pan","Matt Landreman","William Dorland"],"pdf_url":"https://arxiv.org/pdf/2311.13491v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2311.11284v2","updated":"2023-11-22T16:54:17Z","published":"2023-11-19T09:59:09Z","title":"LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval\n  Score Matching","summary":"  The recent advancements in text-to-3D generation mark a significant milestone\nin generative models, unlocking new possibilities for creating imaginative 3D\nassets across various real-world scenarios. While recent advancements in\ntext-to-3D generation have shown promise, they often fall short in rendering\ndetailed and high-quality 3D models. This problem is especially prevalent as\nmany methods base themselves on Score Distillation Sampling (SDS). This paper\nidentifies a notable deficiency in SDS, that it brings inconsistent and\nlow-quality updating direction for the 3D model, causing the over-smoothing\neffect. To address this, we propose a novel approach called Interval Score\nMatching (ISM). ISM employs deterministic diffusing trajectories and utilizes\ninterval-based score matching to counteract over-smoothing. Furthermore, we\nincorporate 3D Gaussian Splatting into our text-to-3D generation pipeline.\nExtensive experiments show that our model largely outperforms the\nstate-of-the-art in quality and training efficiency.\n","authors":["Yixun Liang","Xin Yang","Jiantao Lin","Haodong Li","Xiaogang Xu","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.11284v2.pdf","comment":"The first two authors contributed equally to this work. Our code will\n  be available at: https://github.com/EnVision-Research/LucidDreamer"},{"id":"http://arxiv.org/abs/2207.11900v6","updated":"2023-11-22T17:05:42Z","published":"2022-07-25T04:22:41Z","title":"GA2MIF: Graph and Attention Based Two-Stage Multi-Source Information\n  Fusion for Conversational Emotion Detection","summary":"  Multimodal Emotion Recognition in Conversation (ERC) plays an influential\nrole in the field of human-computer interaction and conversational robotics\nsince it can motivate machines to provide empathetic services. Multimodal data\nmodeling is an up-and-coming research area in recent years, which is inspired\nby human capability to integrate multiple senses. Several graph-based\napproaches claim to capture interactive information between modalities, but the\nheterogeneity of multimodal data makes these methods prohibit optimal\nsolutions. In this work, we introduce a multimodal fusion approach named Graph\nand Attention based Two-stage Multi-source Information Fusion (GA2MIF) for\nemotion detection in conversation. Our proposed method circumvents the problem\nof taking heterogeneous graph as input to the model while eliminating complex\nredundant connections in the construction of graph. GA2MIF focuses on\ncontextual modeling and cross-modal modeling through leveraging Multi-head\nDirected Graph ATtention networks (MDGATs) and Multi-head Pairwise Cross-modal\nATtention networks (MPCATs), respectively. Extensive experiments on two public\ndatasets (i.e., IEMOCAP and MELD) demonstrate that the proposed GA2MIF has the\ncapacity to validly capture intra-modal long-range contextual information and\ninter-modal complementary information, as well as outperforms the prevalent\nState-Of-The-Art (SOTA) models by a remarkable margin.\n","authors":["Jiang Li","Xiaoping Wang","Guoqing Lv","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2207.11900v6.pdf","comment":"Accepted by IEEE Transactions on Affective Computing"},{"id":"http://arxiv.org/abs/2207.12261v4","updated":"2023-11-22T16:59:55Z","published":"2022-07-06T13:56:48Z","title":"GraphCFC: A Directed Graph Based Cross-Modal Feature Complementation\n  Approach for Multimodal Conversational Emotion Recognition","summary":"  Emotion Recognition in Conversation (ERC) plays a significant part in\nHuman-Computer Interaction (HCI) systems since it can provide empathetic\nservices. Multimodal ERC can mitigate the drawbacks of uni-modal approaches.\nRecently, Graph Neural Networks (GNNs) have been widely used in a variety of\nfields due to their superior performance in relation modeling. In multimodal\nERC, GNNs are capable of extracting both long-distance contextual information\nand inter-modal interactive information. Unfortunately, since existing methods\nsuch as MMGCN directly fuse multiple modalities, redundant information may be\ngenerated and diverse information may be lost. In this work, we present a\ndirected Graph based Cross-modal Feature Complementation (GraphCFC) module that\ncan efficiently model contextual and interactive information. GraphCFC\nalleviates the problem of heterogeneity gap in multimodal fusion by utilizing\nmultiple subspace extractors and Pair-wise Cross-modal Complementary (PairCC)\nstrategy. We extract various types of edges from the constructed graph for\nencoding, thus enabling GNNs to extract crucial contextual and interactive\ninformation more accurately when performing message passing. Furthermore, we\ndesign a GNN structure called GAT-MLP, which can provide a new unified network\nframework for multimodal learning. The experimental results on two benchmark\ndatasets show that our GraphCFC outperforms the state-of-the-art (SOTA)\napproaches.\n","authors":["Jiang Li","Xiaoping Wang","Guoqing Lv","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2207.12261v4.pdf","comment":"Accepted by IEEE Transactions on Multimedia (TMM)"},{"id":"http://arxiv.org/abs/2208.00339v4","updated":"2023-11-22T16:17:19Z","published":"2022-07-31T02:23:24Z","title":"GraphMFT: A Graph Network based Multimodal Fusion Technique for Emotion\n  Recognition in Conversation","summary":"  Multimodal machine learning is an emerging area of research, which has\nreceived a great deal of scholarly attention in recent years. Up to now, there\nare few studies on multimodal Emotion Recognition in Conversation (ERC). Since\nGraph Neural Networks (GNNs) possess the powerful capacity of relational\nmodeling, they have an inherent advantage in the field of multimodal learning.\nGNNs leverage the graph constructed from multimodal data to perform intra- and\ninter-modal information interaction, which effectively facilitates the\nintegration and complementation of multimodal data. In this work, we propose a\nnovel Graph network based Multimodal Fusion Technique (GraphMFT) for emotion\nrecognition in conversation. Multimodal data can be modeled as a graph, where\neach data object is regarded as a node, and both intra- and inter-modal\ndependencies existing between data objects can be regarded as edges. GraphMFT\nutilizes multiple improved graph attention networks to capture intra-modal\ncontextual information and inter-modal complementary information. In addition,\nthe proposed GraphMFT attempts to address the challenges of existing\ngraph-based multimodal conversational emotion recognition models such as MMGCN.\nEmpirical results on two public multimodal datasets reveal that our model\noutperforms the State-Of-The-Art (SOTA) approaches with the accuracy of 67.90%\nand 61.30%.\n","authors":["Jiang Li","Xiaoping Wang","Guoqing Lv","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2208.00339v4.pdf","comment":"Accepted by Neurocomputing"},{"id":"http://arxiv.org/abs/2311.13409v1","updated":"2023-11-22T14:13:27Z","published":"2023-11-22T14:13:27Z","title":"CompenHR: Efficient Full Compensation for High-resolution Projector","summary":"  Full projector compensation is a practical task of projector-camera systems.\nIt aims to find a projector input image, named compensation image, such that\nwhen projected it cancels the geometric and photometric distortions due to the\nphysical environment and hardware. State-of-the-art methods use deep learning\nto address this problem and show promising performance for low-resolution\nsetups. However, directly applying deep learning to high-resolution setups is\nimpractical due to the long training time and high memory cost. To address this\nissue, this paper proposes a practical full compensation solution. Firstly, we\ndesign an attention-based grid refinement network to improve geometric\ncorrection quality. Secondly, we integrate a novel sampling scheme into an\nend-to-end compensation network to alleviate computation and introduce\nattention blocks to preserve key features. Finally, we construct a benchmark\ndataset for high-resolution projector full compensation. In experiments, our\nmethod demonstrates clear advantages in both efficiency and quality.\n","authors":["Yuxi Wang","Haibin Ling","Bingyao Huang"],"pdf_url":"https://arxiv.org/pdf/2311.13409v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13307v1","updated":"2023-11-22T10:55:36Z","published":"2023-11-22T10:55:36Z","title":"Rethinking Radiology Report Generation via Causal Reasoning and\n  Counterfactual Augmentation","summary":"  Radiology Report Generation (RRG) draws attention as an interaction between\nvision and language fields. Previous works inherited the ideology of\nvision-to-language generation tasks,aiming to generate paragraphs with high\nconsistency as reports. However, one unique characteristic of RRG, the\nindependence between diseases, was neglected, leading to the injection of the\nspurious confounder, i.e., the disease co-occurrence. Unfortunately, this\nconfounder confuses the process of report generation worse because of the\nbiased RRG data distribution. In this paper, to rethink this issue thoroughly,\nwe reason about its causes and effects from a novel perspective of statistics\nand causality, where the Joint Vision Coupling and the Conditional Sentence\nCoherence Coupling are two aspects prone to implicitly decrease the accuracy of\nreports. Then, a counterfactual augmentation strategy that contains the\nCounterfactual Sample Synthesis and the Counterfactual Report Reconstruction\nsub-methods is proposed to break these two aspects of spurious effects.\nExperimental results and further analyses on two widely used datasets justify\nour reasoning and proposed methods.\n","authors":["Xiao Song","Jiafan Liu","Yun Li","Wenbin Lei","Ruxin Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13307v1.pdf","comment":"10 pages,5 figures"},{"id":"http://arxiv.org/abs/2311.13073v1","updated":"2023-11-22T00:26:15Z","published":"2023-11-22T00:26:15Z","title":"FusionFrames: Efficient Architectural Aspects for Text-to-Video\n  Generation Pipeline","summary":"  Multimedia generation approaches occupy a prominent place in artificial\nintelligence research. Text-to-image models achieved high-quality results over\nthe last few years. However, video synthesis methods recently started to\ndevelop. This paper presents a new two-stage latent diffusion text-to-video\ngeneration architecture based on the text-to-image diffusion model. The first\nstage concerns keyframes synthesis to figure the storyline of a video, while\nthe second one is devoted to interpolation frames generation to make movements\nof the scene and objects smooth. We compare several temporal conditioning\napproaches for keyframes generation. The results show the advantage of using\nseparate temporal blocks over temporal layers in terms of metrics reflecting\nvideo generation quality aspects and human preference. The design of our\ninterpolation model significantly reduces computational costs compared to other\nmasked frame interpolation approaches. Furthermore, we evaluate different\nconfigurations of MoVQ-based video decoding scheme to improve consistency and\nachieve higher PSNR, SSIM, MSE, and LPIPS scores. Finally, we compare our\npipeline with existing solutions and achieve top-2 scores overall and top-1\namong open-source solutions: CLIPSIM = 0.2976 and FVD = 433.054. Project page:\nhttps://ai-forever.github.io/kandinsky-video/\n","authors":["Vladimir Arkhipkin","Zein Shaheen","Viacheslav Vasilev","Elizaveta Dakhova","Andrey Kuznetsov","Denis Dimitrov"],"pdf_url":"https://arxiv.org/pdf/2311.13073v1.pdf","comment":"Project page: https://ai-forever.github.io/kandinsky-video/"},{"id":"http://arxiv.org/abs/2311.13687v1","updated":"2023-11-22T20:47:52Z","published":"2023-11-22T20:47:52Z","title":"Beat-Aligned Spectrogram-to-Sequence Generation of Rhythm-Game Charts","summary":"  In the heart of \"rhythm games\" - games where players must perform actions in\nsync with a piece of music - are \"charts\", the directives to be given to\nplayers. We newly formulate chart generation as a sequence generation task and\ntrain a Transformer using a large dataset. We also introduce tempo-informed\npreprocessing and training procedures, some of which are suggested to be\nintegral for a successful training. Our model is found to outperform the\nbaselines on a large dataset, and is also found to benefit from pretraining and\nfinetuning.\n","authors":["Jayeon Yi","Sungho Lee","Kyogu Lee"],"pdf_url":"https://arxiv.org/pdf/2311.13687v1.pdf","comment":"ISMIR 2023 LBD. Demo videos and code at stet-stet.github.io/goct"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2311.13565v1","updated":"2023-11-22T18:22:56Z","published":"2023-11-22T18:22:56Z","title":"Drilling Down into the Discourse Structure with LLMs for Long Document\n  Question Answering","summary":"  We address the task of evidence retrieval for long document question\nanswering, which involves locating relevant paragraphs within a document to\nanswer a question. We aim to assess the applicability of large language models\n(LLMs) in the task of zero-shot long document evidence retrieval, owing to\ntheir unprecedented performance across various NLP tasks. However, currently\nthe LLMs can consume limited context lengths as input, thus providing document\nchunks as inputs might overlook the global context while missing out on\ncapturing the inter-segment dependencies. Moreover, directly feeding the large\ninput sets can incur significant computational costs, particularly when\nprocessing the entire document (and potentially incurring monetary expenses\nwith enterprise APIs like OpenAI's GPT variants). To address these challenges,\nwe propose a suite of techniques that exploit the discourse structure commonly\nfound in documents. By utilizing this structure, we create a condensed\nrepresentation of the document, enabling a more comprehensive understanding and\nanalysis of relationships between different parts. We retain $99.6\\%$ of the\nbest zero-shot approach's performance, while processing only $26\\%$ of the\ntotal tokens used by the best approach in the information seeking evidence\nretrieval setup. We also show how our approach can be combined with\n\\textit{self-ask} reasoning agent to achieve best zero-shot performance in\ncomplex multi-hop question answering, just $\\approx 4\\%$ short of zero-shot\nperformance using gold evidence.\n","authors":["Inderjeet Nair","Shwetha Somasundaram","Apoorv Saxena","Koustava Goswami"],"pdf_url":"https://arxiv.org/pdf/2311.13565v1.pdf","comment":"Accepted to the Findings of EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.13534v1","updated":"2023-11-22T17:14:54Z","published":"2023-11-22T17:14:54Z","title":"LM-Cocktail: Resilient Tuning of Language Models via Model Merging","summary":"  The pre-trained language models are continually fine-tuned to better support\ndownstream applications. However, this operation may result in significant\nperformance degeneration on general tasks beyond the targeted domain. To\novercome this problem, we propose a novel method which enables the fine-tuned\nmodel to stay resilient in general perspectives. Our method is conducted in the\nform of model merging (namely LM-Cocktail), where the fine-tuned language model\nis merged with the pre-trained base model or the peer models from other domains\nthrough weighted average. Despite simplicity, LM-Cocktail is surprisingly\neffective: the resulted model is able to achieve a strong empirical performance\nin the whole scope of general tasks while preserving a superior capacity in its\ntargeted domain. We conduct comprehensive experiments with LLama and BGE model\non popular benchmarks, including FLAN, MMLU, MTEB, whose results validate the\nefficacy of our proposed method. The code and checkpoints are available at\nhttps://github.com/FlagOpen/FlagEmbedding.\n","authors":["Shitao Xiao","Zheng Liu","Peitian Zhang","Xingrun Xing"],"pdf_url":"https://arxiv.org/pdf/2311.13534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13494v1","updated":"2023-11-22T16:12:41Z","published":"2023-11-22T16:12:41Z","title":"A Comparative Analysis of Supportive Navigation on Movie Recommenders","summary":"  This literature review covers the research and thought process that went into\nmaking a solution for the infinite scrolling problem faced in streaming\nservices such as Netflix. Using the data collected, we have come to the\nconclusion that an alternate layout can somewhat alleviate the problems it\ntakes in navigating a list of movies. We also found out by a comparative\nanalysis that some layouts, the circular one in particular, is advantageous in\ncertain settings making it an ideal candidate for a movie recommender system.\n","authors":["Mohammad Sualeh Ali","Muhammed Maaz Tariq","Alina Ahmed","Abdul Razaque Soomro","Danysh Syed"],"pdf_url":"https://arxiv.org/pdf/2311.13494v1.pdf","comment":"This was an extensive survey and prototyping we did to purpose and\n  alternative user interface for movie recommender systems like Netflix"},{"id":"http://arxiv.org/abs/2311.13350v1","updated":"2023-11-22T12:39:28Z","published":"2023-11-22T12:39:28Z","title":"Fact-based Court Judgment Prediction","summary":"  This extended abstract extends the research presented in \"ILDC for CJPE:\nIndian Legal Documents Corpus for Court Judgment Prediction and Explanation\"\n\\cite{malik-etal-2021-ildc}, focusing on fact-based judgment prediction within\nthe context of Indian legal documents. We introduce two distinct problem\nvariations: one based solely on facts, and another combining facts with rulings\nfrom lower courts (RLC). Our research aims to enhance early-phase case outcome\nprediction, offering significant benefits to legal professionals and the\ngeneral public. The results, however, indicated a performance decline compared\nto the original ILDC for CJPE study, even after implementing various weightage\nschemes in our DELSumm algorithm. Additionally, using only facts for legal\njudgment prediction with different transformer models yielded results inferior\nto the state-of-the-art outcomes reported in the \"ILDC for CJPE\" study.\n","authors":["Shubham Kumar Nigam","Aniket Deroy"],"pdf_url":"https://arxiv.org/pdf/2311.13350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13277v1","updated":"2023-11-22T09:53:57Z","published":"2023-11-22T09:53:57Z","title":"Hierarchical Matrix Factorization for Interpretable Collaborative\n  Filtering","summary":"  Matrix factorization (MF) is a simple collaborative filtering technique that\nachieves superior recommendation accuracy by decomposing the user-item rating\nmatrix into user and item latent matrices. This approach relies on learning\nfrom user-item interactions, which may not effectively capture the underlying\nshared dependencies between users or items. Therefore, there is scope to\nexplicitly capture shared dependencies to further improve recommendation\naccuracy and the interpretability of learning results by summarizing user-item\ninteractions. Based on these insights, we propose \"Hierarchical Matrix\nFactorization\" (HMF), which incorporates clustering concepts to capture the\nhierarchy, where leaf nodes and other nodes correspond to users/items and\nclusters, respectively. Central to our approach, called hierarchical\nembeddings, is the additional decomposition of the user and item latent\nmatrices (embeddings) into probabilistic connection matrices, which link the\nhierarchy, and a root cluster latent matrix. Thus, each node is represented by\nthe weighted average of the embeddings of its parent clusters. The embeddings\nare differentiable, allowing simultaneous learning of interactions and\nclustering using a single gradient descent method. Furthermore, the obtained\ncluster-specific interactions naturally summarize user-item interactions and\nprovide interpretability. Experimental results on rating and ranking\npredictions demonstrated the competitiveness of HMF over vanilla and\nhierarchical MF methods, especially its robustness in sparse interactions.\nAdditionally, it was confirmed that the clustering integration of HMF has the\npotential for faster learning convergence and mitigation of overfitting\ncompared to MF, and also provides interpretability through a cluster-centered\ncase study.\n","authors":["Kai Sugahara","Kazushi Okamoto"],"pdf_url":"https://arxiv.org/pdf/2311.13277v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13121v1","updated":"2023-11-22T02:49:14Z","published":"2023-11-22T02:49:14Z","title":"GENET: Unleashing the Power of Side Information for Recommendation via\n  Hypergraph Pre-training","summary":"  Recommendation with side information has drawn significant research interest\ndue to its potential to mitigate user feedback sparsity. However, existing\nmodels struggle with generalization across diverse domains and types of side\ninformation. In particular, three challenges have not been addressed, and they\nare (1) the diverse formats of side information, including text sequences. (2)\nThe diverse semantics of side information that describes items and users from\nmulti-level in a context different from recommendation systems. (3) The diverse\ncorrelations in side information to measure similarity over multiple objects\nbeyond pairwise relations. In this paper, we introduce GENET (Generalized\nhypErgraph pretraiNing on sidE informaTion), which pre-trains user and item\nrepresentations on feedback-irrelevant side information and fine-tunes the\nrepresentations on user feedback data. GENET leverages pre-training as a means\nto prevent side information from overshadowing critical ID features and\nfeedback signals. It employs a hypergraph framework to accommodate various\ntypes of diverse side information. During pre-training, GENET integrates tasks\nfor hyperlink prediction and self-supervised contrast to capture fine-grained\nsemantics at both local and global levels. Additionally, it introduces a unique\nstrategy to enhance pre-training robustness by perturbing positive samples\nwhile maintaining high-order relations. Extensive experiments demonstrate that\nGENET exhibits strong generalization capabilities, outperforming the SOTA\nmethod by up to 38% in TOP-N recommendation and Sequential recommendation tasks\non various datasets with different side information.\n","authors":["Yang Li","Qi'ao Zhao","Chen Lin","Zhenjie Zhang","Xiaomin Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.13121v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13626v1","updated":"2023-11-22T17:36:46Z","published":"2023-11-22T17:36:46Z","title":"Physics-driven generative adversarial networks empower single-pixel\n  infrared hyperspectral imaging","summary":"  A physics-driven generative adversarial network (GAN) was established here\nfor single-pixel hyperspectral imaging (HSI) in the infrared spectrum, to\neliminate the extensive data training work required by traditional data-driven\nmodel. Within the GAN framework, the physical process of single-pixel imaging\n(SPI) was integrated into the generator, and the actual and estimated\none-dimensional (1D) bucket signals were employed as constraints in the\nobjective function to update the network's parameters and optimize the\ngenerator with the assistance of the discriminator. In comparison to\nsingle-pixel infrared HSI methods based on compressed sensing and\nphysics-driven convolution neural networks, our physics-driven GAN-based\nsingle-pixel infrared HSI can achieve higher imaging performance but with fewer\nmeasurements. We believe that this physics-driven GAN will promote practical\napplications of computational imaging, especially various SPI-based techniques.\n","authors":["Dong-Yin Wang","Shu-Hang Bie","Xi-Hao Chen","Wen-Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2311.13626v1.pdf","comment":"14 pages, 8 figures"}]},"2023-11-24T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2311.13110v2","updated":"2023-11-24T09:18:44Z","published":"2023-11-22T02:23:32Z","title":"White-Box Transformers via Sparse Rate Reduction: Compression Is All\n  There Is?","summary":"  In this paper, we contend that a natural objective of representation learning\nis to compress and transform the distribution of the data, say sets of tokens,\ntowards a low-dimensional Gaussian mixture supported on incoherent subspaces.\nThe goodness of such a representation can be evaluated by a principled measure,\ncalled sparse rate reduction, that simultaneously maximizes the intrinsic\ninformation gain and extrinsic sparsity of the learned representation. From\nthis perspective, popular deep network architectures, including transformers,\ncan be viewed as realizing iterative schemes to optimize this measure.\nParticularly, we derive a transformer block from alternating optimization on\nparts of this objective: the multi-head self-attention operator compresses the\nrepresentation by implementing an approximate gradient descent step on the\ncoding rate of the features, and the subsequent multi-layer perceptron\nsparsifies the features. This leads to a family of white-box transformer-like\ndeep network architectures, named CRATE, which are mathematically fully\ninterpretable. We show, by way of a novel connection between denoising and\ncompression, that the inverse to the aforementioned compressive encoding can be\nrealized by the same class of CRATE architectures. Thus, the so-derived\nwhite-box architectures are universal to both encoders and decoders.\nExperiments show that these networks, despite their simplicity, indeed learn to\ncompress and sparsify representations of large-scale real-world image and text\ndatasets, and achieve performance very close to highly engineered\ntransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the\nproposed computational framework demonstrates great potential in bridging the\ngap between theory and practice of deep learning, from a unified perspective of\ndata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .\n","authors":["Yaodong Yu","Sam Buchanan","Druv Pai","Tianzhe Chu","Ziyang Wu","Shengbang Tong","Hao Bai","Yuexiang Zhai","Benjamin D. Haeffele","Yi Ma"],"pdf_url":"https://arxiv.org/pdf/2311.13110v2.pdf","comment":"This paper integrates the works arXiv:2306.01129 and arXiv:2308.16271\n  into a complete story. In this paper, we improve the writing and\n  organization, and also add conceptual, empirical, and theoretical\n  improvements over the previous work. V2: small typo fixes and formatting\n  improvements"},{"id":"http://arxiv.org/abs/2311.12727v2","updated":"2023-11-24T03:27:31Z","published":"2023-11-21T17:03:21Z","title":"Soft Random Sampling: A Theoretical and Empirical Analysis","summary":"  Soft random sampling (SRS) is a simple yet effective approach for efficient\ntraining of large-scale deep neural networks when dealing with massive data.\nSRS selects a subset uniformly at random with replacement from the full data\nset in each epoch. In this paper, we conduct a theoretical and empirical\nanalysis of SRS. First, we analyze its sampling dynamics including data\ncoverage and occupancy. Next, we investigate its convergence with non-convex\nobjective functions and give the convergence rate. Finally, we provide its\ngeneralization performance. We empirically evaluate SRS for image recognition\non CIFAR10 and automatic speech recognition on Librispeech and an in-house\npayload dataset to demonstrate its effectiveness. Compared to existing\ncoreset-based data selection methods, SRS offers a better accuracy-efficiency\ntrade-off. Especially on real-world industrial scale data sets, it is shown to\nbe a powerful training strategy with significant speedup and competitive\nperformance with almost no additional computing cost.\n","authors":["Xiaodong Cui","Ashish Mittal","Songtao Lu","Wei Zhang","George Saon","Brian Kingsbury"],"pdf_url":"https://arxiv.org/pdf/2311.12727v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18333v2","updated":"2023-11-24T18:58:02Z","published":"2023-10-20T14:18:40Z","title":"She had Cobalt Blue Eyes: Prompt Testing to Create Aligned and\n  Sustainable Language Models","summary":"  As the use of large language models (LLMs) increases within society, as does\nthe risk of their misuse. Appropriate safeguards must be in place to ensure LLM\noutputs uphold the ethical standards of society, highlighting the positive role\nthat artificial intelligence technologies can have. Recent events indicate\nethical concerns around conventionally trained LLMs, leading to overall unsafe\nuser experiences. This motivates our research question: how do we ensure LLM\nalignment? In this work, we introduce a test suite of unique prompts to foster\nthe development of aligned LLMs that are fair, safe, and robust. We show that\nprompting LLMs at every step of the development pipeline, including data\ncuration, pre-training, and fine-tuning, will result in an overall more\nresponsible model. Our test suite evaluates outputs from four state-of-the-art\nlanguage models: GPT-3.5, GPT-4, OPT, and LLaMA-2. The assessment presented in\nthis paper highlights a gap between societal alignment and the capabilities of\ncurrent LLMs. Additionally, implementing a test suite such as ours lowers the\nenvironmental overhead of making models safe and fair.\n","authors":["Veronica Chatrath","Oluwanifemi Bamgbose","Shaina Raza"],"pdf_url":"https://arxiv.org/pdf/2310.18333v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17455v3","updated":"2023-11-24T18:39:02Z","published":"2023-05-27T12:07:21Z","title":"CrossGET: Cross-Guided Ensemble of Tokens for Accelerating\n  Vision-Language Transformers","summary":"  Recent vision-language models have achieved tremendous progress far beyond\nwhat we ever expected. However, their computational costs are also dramatically\ngrowing with rapid development, especially for the large models. It makes model\nacceleration exceedingly critical in a scenario of limited resources. Although\nextensively studied for unimodal models, the acceleration for multimodal\nmodels, especially the vision-language Transformers, is relatively\nunder-explored. To pursue more efficient and accessible vision-language\nTransformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided\n\\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal\nacceleration framework for vision-language Transformers. This framework\nadaptively combines tokens through real-time, cross-modal guidance, thereby\nachieving substantial acceleration while keeping high performance.\n\\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and\nEnsemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and\nensemble to exploit cross-modal information effectively, only introducing\ncross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph\nSoft Matching}. In contrast to the existing bipartite soft matching approach,\n\\textit{CrossGET} introduces a complete-graph soft matching policy to achieve\nmore reliable token-matching results while maintaining parallelizability and\nhigh efficiency. Extensive experiments are conducted on various vision-language\ntasks, including image-text retrieval, visual reasoning, image captioning, and\nvisual question answering. Performance on both classic multimodal architectures\nand emerging multimodal LLMs demonstrate the effectiveness and versatility of\nthe proposed \\textit{CrossGET} framework. The code will be at\n\\url{https://github.com/sdc17/CrossGET}.\n","authors":["Dachuan Shi","Chaofan Tao","Anyi Rao","Zhendong Yang","Chun Yuan","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2305.17455v3.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2311.14652v1","updated":"2023-11-24T18:35:00Z","published":"2023-11-24T18:35:00Z","title":"One Pass Streaming Algorithm for Super Long Token Attention\n  Approximation in Sublinear Space","summary":"  Deploying Large Language Models (LLMs) in streaming applications that involve\nlong contexts, particularly for extended dialogues and text analysis, is of\nparamount importance but presents two significant challenges. Firstly, the\nmemory consumption is substantial during the decoding phase due to the caching\nof Key and Value states (KV) of previous tokens. Secondly, attention\ncomputation is time-consuming with a time complexity of $O(n^2)$ for the\ngeneration of each token. In recent OpenAI DevDay (Nov 6, 2023), OpenAI\nreleased a new model that is able to support a 128K-long document, in our\npaper, we focus on the memory-efficient issue when context length $n$ is much\ngreater than 128K ($n \\gg 2^d$). Considering a single-layer self-attention with\nQuery, Key, and Value matrices $Q, K, V \\in \\mathbb{R}^{n \\times d}$, the\npolynomial method approximates the attention output $T \\in \\mathbb{R}^{n \\times\nd}$. It accomplishes this by constructing $U_1, U_2 \\in \\mathbb{R}^{n \\times\nt}$ to expedite attention ${\\sf Attn}(Q, K, V)$ computation within $n^{1+o(1)}$\ntime executions. Despite this, storing the Key and Value matrices $K, V \\in\n\\mathbb{R}^{n \\times d}$ still necessitates $O( n d)$ space, leading to\nsignificant memory usage. In response to these challenges, we introduce a new\nalgorithm that only reads one pass of the data in streaming fashion. This\nmethod employs sublinear space $o(n)$ to store three sketch matrices,\nalleviating the need for exact $K, V$ storage. Notably, our algorithm exhibits\nexceptional memory-efficient performance with super-long tokens. As the token\nlength $n$ increases, our error guarantee diminishes while the memory usage\nremains nearly constant. This unique attribute underscores the potential of our\ntechnique in efficiently handling LLMs in streaming applications.\n","authors":["Raghav Addanki","Chenyang Li","Zhao Song","Chiwun Yang"],"pdf_url":"https://arxiv.org/pdf/2311.14652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14648v1","updated":"2023-11-24T18:29:50Z","published":"2023-11-24T18:29:50Z","title":"Calibrated Language Models Must Hallucinate","summary":"  Recent language models have a mysterious tendency to generate false but\nplausible-sounding text. Such \"hallucinations\" are an obstacle to the usability\nof language-based AI systems and can harm people who rely upon their outputs.\nThis work shows shows that there is an inherent statistical reason that\npretrained language models hallucinate certain types of facts, having nothing\nto do with the transformer LM architecture or data quality. For \"arbitrary\"\nfacts whose veracity cannot be determined from the training data, we show that\nhallucination is necessary for language models that satisfy a statistical\ncalibration condition appropriate for generative language models. Specifically,\nif the maximum probability of any fact is bounded, we show that the probability\nof generating a hallucination is close to the fraction of facts that occur\nexactly once in the training data (a \"Good-Turing\" estimate), even assuming\nideal training data without errors.\n  One conclusion is that models pretrained to be sufficiently good predictors\n(i.e., calibrated) may require post-training to mitigate hallucinations on the\ntype of arbitrary facts that tend to appear once in the training set. However,\nour analysis also suggests that there is no statistical reason that pretraining\nwill lead to hallucination on facts that tend to appear more than once in the\ntraining data (like references to publications such as articles and books,\nwhose hallucinations have been particularly notable and problematic) or on\nsystematic facts (like arithmetic calculations). Therefore, different\narchitectures and learning algorithms may mitigate these latter types of\nhallucinations.\n","authors":["Adam Tauman Kalai","Santosh S. Vempala"],"pdf_url":"https://arxiv.org/pdf/2311.14648v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2311.09433v2","updated":"2023-11-24T16:22:41Z","published":"2023-11-15T23:07:40Z","title":"Backdoor Activation Attack: Attack Large Language Models using\n  Activation Steering for Safety-Alignment","summary":"  To ensure AI safety, instruction-tuned Large Language Models (LLMs) are\nspecifically trained to ensure alignment, which refers to making models behave\nin accordance with human intentions. While these models have demonstrated\ncommendable results on various safety benchmarks, the vulnerability of their\nsafety alignment has not been extensively studied. This is particularly\ntroubling given the potential harm that LLMs can inflict. Existing attack\nmethods on LLMs often rely on poisoned training data or the injection of\nmalicious prompts. These approaches compromise the stealthiness and\ngeneralizability of the attacks, making them susceptible to detection.\nAdditionally, these models often demand substantial computational resources for\nimplementation, making them less practical for real-world applications.\nInspired by recent success in modifying model behavior through steering vectors\nwithout the need for optimization, and drawing on its effectiveness in\nred-teaming LLMs, we conducted experiments employing activation steering to\ntarget four key aspects of LLMs: truthfulness, toxicity, bias, and harmfulness\n- across a varied set of attack settings. To establish a universal attack\nstrategy applicable to diverse target alignments without depending on manual\nanalysis, we automatically select the intervention layer based on contrastive\nlayer search. Our experiment results show that activation attacks are highly\neffective and add little or no overhead to attack efficiency. Additionally, we\ndiscuss potential countermeasures against such activation attacks. Our code and\ndata are available at https://github.com/wang2226/Backdoor-Activation-Attack\nWarning: this paper contains content that can be offensive or upsetting.\n","authors":["Haoran Wang","Kai Shu"],"pdf_url":"https://arxiv.org/pdf/2311.09433v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06607v2","updated":"2023-11-24T16:21:39Z","published":"2023-11-11T16:37:41Z","title":"Monkey: Image Resolution and Text Label Are Important Things for Large\n  Multi-modal Models","summary":"  Large Multimodal Models (LMMs) have shown promise in vision-language tasks\nbut struggle with high-resolution input and detailed scene understanding.\nAddressing these challenges, we introduce Monkey to enhance LMM capabilities.\nFirstly, Monkey processes input images by dividing them into uniform patches,\neach matching the size (e.g., 448x448) used in the original training of the\nwell-trained vision encoder. Equipped with individual adapter for each patch,\nMonkey can handle higher resolutions up to 1344x896 pixels, enabling the\ndetailed capture of complex visual information. Secondly, it employs a\nmulti-level description generation method, enriching the context for\nscene-object associations. This two-part strategy ensures more effective\nlearning from generated data: the higher resolution allows for a more detailed\ncapture of visuals, which in turn enhances the effectiveness of comprehensive\ndescriptions. Extensive ablative results validate the effectiveness of our\ndesigns. Additionally, experiments on 18 datasets further demonstrate that\nMonkey surpasses existing LMMs in many tasks like Image Captioning and various\nVisual Question Answering formats. Specially, in qualitative tests focused on\ndense text question answering, Monkey has exhibited encouraging results\ncompared with GPT4V. Code is available at\nhttps://github.com/Yuliang-Liu/Monkey.\n","authors":["Zhang Li","Biao Yang","Qiang Liu","Zhiyin Ma","Shuo Zhang","Jingxu Yang","Yabo Sun","Yuliang Liu","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2311.06607v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14583v1","updated":"2023-11-24T16:19:04Z","published":"2023-11-24T16:19:04Z","title":"GPT Struct Me: Probing GPT Models on Narrative Entity Extraction","summary":"  The importance of systems that can extract structured information from\ntextual data becomes increasingly pronounced given the ever-increasing volume\nof text produced on a daily basis. Having a system that can effectively extract\nsuch information in an interoperable manner would be an asset for several\ndomains, be it finance, health, or legal. Recent developments in natural\nlanguage processing led to the production of powerful language models that can,\nto some degree, mimic human intelligence. Such effectiveness raises a pertinent\nquestion: Can these models be leveraged for the extraction of structured\ninformation? In this work, we address this question by evaluating the\ncapabilities of two state-of-the-art language models -- GPT-3 and GPT-3.5,\ncommonly known as ChatGPT -- in the extraction of narrative entities, namely\nevents, participants, and temporal expressions. This study is conducted on the\nText2Story Lusa dataset, a collection of 119 Portuguese news articles whose\nannotation framework includes a set of entity structures along with several\ntags and attribute values. We first select the best prompt template through an\nablation study over prompt components that provide varying degrees of\ninformation on a subset of documents of the dataset. Subsequently, we use the\nbest templates to evaluate the effectiveness of the models on the remaining\ndocuments. The results obtained indicate that GPT models are competitive with\nout-of-the-box baseline systems, presenting an all-in-one alternative for\npractitioners with limited resources. By studying the strengths and limitations\nof these models in the context of information extraction, we offer insights\nthat can guide future improvements and avenues to explore in this field.\n","authors":["Hugo Sousa","Nuno Guimarães","Alípio Jorge","Ricardo Campos"],"pdf_url":"https://arxiv.org/pdf/2311.14583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04643v3","updated":"2023-11-24T16:13:18Z","published":"2023-01-11T18:55:22Z","title":"tieval: An Evaluation Framework for Temporal Information Extraction\n  Systems","summary":"  Temporal information extraction (TIE) has attracted a great deal of interest\nover the last two decades, leading to the development of a significant number\nof datasets. Despite its benefits, having access to a large volume of corpora\nmakes it difficult when it comes to benchmark TIE systems. On the one hand,\ndifferent datasets have different annotation schemes, thus hindering the\ncomparison between competitors across different corpora. On the other hand, the\nfact that each corpus is commonly disseminated in a different format requires a\nconsiderable engineering effort for a researcher/practitioner to develop\nparsers for all of them. This constraint forces researchers to select a limited\namount of datasets to evaluate their systems which consequently limits the\ncomparability of the systems. Yet another obstacle that hinders the\ncomparability of the TIE systems is the evaluation metric employed. While most\nresearch works adopt traditional metrics such as precision, recall, and $F_1$,\na few others prefer temporal awareness -- a metric tailored to be more\ncomprehensive on the evaluation of temporal systems. Although the reason for\nthe absence of temporal awareness in the evaluation of most systems is not\nclear, one of the factors that certainly weights this decision is the necessity\nto implement the temporal closure algorithm in order to compute temporal\nawareness, which is not straightforward to implement neither is currently\neasily available. All in all, these problems have limited the fair comparison\nbetween approaches and consequently, the development of temporal extraction\nsystems. To mitigate these problems, we have developed tieval, a Python library\nthat provides a concise interface for importing different corpora and\nfacilitates system evaluation. In this paper, we present the first public\nrelease of tieval and highlight its most relevant features.\n","authors":["Hugo Sousa","Alípio Jorge","Ricardo Campos"],"pdf_url":"https://arxiv.org/pdf/2301.04643v3.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2311.14543v1","updated":"2023-11-24T15:20:36Z","published":"2023-11-24T15:20:36Z","title":"Data-Efficient Alignment of Large Language Models with Human Feedback\n  Through Natural Language","summary":"  Learning from human feedback is a prominent technique to align the output of\nlarge language models (LLMs) with human expectations. Reinforcement learning\nfrom human feedback (RLHF) leverages human preference signals that are in the\nform of ranking of response pairs to perform this alignment. However, human\npreference on LLM outputs can come in much richer forms including natural\nlanguage, which may provide detailed feedback on strengths and weaknesses of a\ngiven response. In this work we investigate data efficiency of modeling human\nfeedback that is in natural language. Specifically, we fine-tune an open-source\nLLM, e.g., Falcon-40B-Instruct, on a relatively small amount (1000 records or\neven less) of human feedback in natural language in the form of critiques and\nrevisions of responses. We show that this model is able to improve the quality\nof responses from even some of the strongest LLMs such as ChatGPT, BARD, and\nVicuna, through critique and revision of those responses. For instance, through\none iteration of revision of ChatGPT responses, the revised responses have\n56.6% win rate over the original ones, and this win rate can be further\nimproved to 65.9% after applying the revision for five iterations.\n","authors":["Di Jin","Shikib Mehri","Devamanyu Hazarika","Aishwarya Padmakumar","Sungjin Lee","Yang Liu","Mahdi Namazifar"],"pdf_url":"https://arxiv.org/pdf/2311.14543v1.pdf","comment":"Accepted by Workshop on Instruction Tuning and Instruction Following\n  at NeurIPS 2023, Submitted to AAAI 2024"},{"id":"http://arxiv.org/abs/2311.14539v1","updated":"2023-11-24T15:10:56Z","published":"2023-11-24T15:10:56Z","title":"CMed-GPT: Prompt Tuning for Entity-Aware Chinese Medical Dialogue\n  Generation","summary":"  Medical dialogue generation relies on natural language generation techniques\nto enable online medical consultations. Recently, the widespread adoption of\nlarge-scale models in the field of natural language processing has facilitated\nrapid advancements in this technology. Existing medical dialogue models are\nmostly based on BERT and pre-trained on English corpora, but there is a lack of\nhigh-performing models on the task of Chinese medical dialogue generation. To\nsolve the above problem, this paper proposes CMed-GPT, which is the GPT\npre-training language model based on Chinese medical domain text. The model is\navailable in two versions, namely, base and large, with corresponding\nperplexity values of 8.64 and 8.01. Additionally, we incorporate lexical and\nentity embeddings into the dialogue text in a uniform manner to meet the\nrequirements of downstream dialogue generation tasks. By applying both\nfine-tuning and p-tuning to CMed-GPT, we lowered the PPL from 8.44 to 7.35.\nThis study not only confirms the exceptional performance of the CMed-GPT model\nin generating Chinese biomedical text but also highlights the advantages of\np-tuning over traditional fine-tuning with prefix prompts. Furthermore, we\nvalidate the significance of incorporating external information in medical\ndialogue generation, which enhances the quality of dialogue generation.\n","authors":["Zhijie Qu","Juan Li","Zerui Ma","Jianqiang Li"],"pdf_url":"https://arxiv.org/pdf/2311.14539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07848v9","updated":"2023-11-24T15:04:50Z","published":"2023-06-13T15:28:10Z","title":"GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio\n  Pretraining for Accurate Speech Emotion Recognition","summary":"  Contrastive cross-modality pretraining has recently exhibited impressive\nsuccess in diverse fields, whereas there is limited research on their merits in\nspeech emotion recognition (SER). In this paper, we propose GEmo-CLAP, a kind\nof gender-attribute-enhanced contrastive language-audio pretraining (CLAP)\nmethod for SER. Specifically, we first construct an effective emotion CLAP\n(Emo-CLAP) for SER, using pre-trained text and audio encoders. Second, given\nthe significance of gender information in SER, two novel multi-task learning\nbased GEmo-CLAP (ML-GEmo-CLAP) and soft label based GEmo-CLAP (SL-GEmo-CLAP)\nmodels are further proposed to incorporate gender information of speech\nsignals, forming more reasonable objectives. Experiments on IEMOCAP indicate\nthat our proposed two GEmo-CLAPs consistently outperform Emo-CLAP with\ndifferent pre-trained models. Remarkably, the proposed WavLM-based SL-GEmo-CLAP\nobtains the best UAR of 81.43\\% and WAR of 83.16\\%, which performs better than\nstate-of-the-art SER methods.\n","authors":["Yu Pan","Yanni Hu","Yuguang Yang","Wen Fei","Jixun Yao","Heng Lu","Lei Ma","Jianjun Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.07848v9.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2311.14530v1","updated":"2023-11-24T14:55:23Z","published":"2023-11-24T14:55:23Z","title":"Machine Translation for Ge'ez Language","summary":"  Machine translation (MT) for low-resource languages such as Ge'ez, an ancient\nlanguage that is no longer spoken in daily life, faces challenges such as\nout-of-vocabulary words, domain mismatches, and lack of sufficient labeled\ntraining data. In this work, we explore various methods to improve Ge'ez MT,\nincluding transfer-learning from related languages, optimizing shared\nvocabulary and token segmentation approaches, finetuning large pre-trained\nmodels, and using large language models (LLMs) for few-shot translation with\nfuzzy matches. We develop a multilingual neural machine translation (MNMT)\nmodel based on languages relatedness, which brings an average performance\nimprovement of about 4 BLEU compared to standard bilingual models. We also\nattempt to finetune the NLLB-200 model, one of the most advanced translation\nmodels available today, but find that it performs poorly with only 4k training\nsamples for Ge'ez. Furthermore, we experiment with using GPT-3.5, a\nstate-of-the-art LLM, for few-shot translation with fuzzy matches, which\nleverages embedding similarity-based retrieval to find context examples from a\nparallel corpus. We observe that GPT-3.5 achieves a remarkable BLEU score of\n9.2 with no initial knowledge of Ge'ez, but still lower than the MNMT baseline\nof 15.2. Our work provides insights into the potential and limitations of\ndifferent approaches for low-resource and ancient language MT.\n","authors":["Aman Kassahun Wassie"],"pdf_url":"https://arxiv.org/pdf/2311.14530v1.pdf","comment":"10 pages, 1 figure"},{"id":"http://arxiv.org/abs/2311.14517v1","updated":"2023-11-24T14:45:53Z","published":"2023-11-24T14:45:53Z","title":"tinyCLAP: Distilling Constrastive Language-Audio Pretrained Models","summary":"  Contrastive Language-Audio Pretraining (CLAP) became of crucial importance in\nthe field of audio and speech processing. Its employment ranges from sound\nevent detection to text-to-audio generation. However, one of the main\nlimitations is the considerable amount of data required in the training process\nand the overall computational complexity during inference. This paper\ninvestigates how we can reduce the complexity of contrastive language-audio\npre-trained models, yielding an efficient model that we call tinyCLAP. We\nderive an unimodal distillation loss from first principles and explore how the\ndimensionality of the shared, multimodal latent space can be reduced via\npruning. TinyCLAP uses only 6% of the original Microsoft CLAP parameters with a\nminimal reduction (less than 5%) in zero-shot classification performance across\nthe three sound event detection datasets on which it was tested\n","authors":["Francesco Paissan","Elisabetta Farella"],"pdf_url":"https://arxiv.org/pdf/2311.14517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.05028v4","updated":"2023-11-24T14:34:57Z","published":"2023-10-08T06:17:39Z","title":"Revisiting Large Language Models as Zero-shot Relation Extractors","summary":"  Relation extraction (RE) consistently involves a certain degree of labeled or\nunlabeled data even if under zero-shot setting. Recent studies have shown that\nlarge language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt, which provides the possibility of extracting\nrelations from text without any data and parameter tuning. This work focuses on\nthe study of exploring LLMs, such as ChatGPT, as zero-shot relation extractors.\nOn the one hand, we analyze the drawbacks of existing RE prompts and attempt to\nincorporate recent prompt techniques such as chain-of-thought (CoT) to improve\nzero-shot RE. We propose the summarize-and-ask (\\textsc{SumAsk}) prompting, a\nsimple prompt recursively using LLMs to transform RE inputs to the effective\nquestion answering (QA) format. On the other hand, we conduct comprehensive\nexperiments on various benchmarks and settings to investigate the capabilities\nof LLMs on zero-shot RE. Specifically, we have the following findings: (i)\n\\textsc{SumAsk} consistently and significantly improves LLMs performance on\ndifferent model sizes, benchmarks and settings; (ii) Zero-shot prompting with\nChatGPT achieves competitive or superior results compared with zero-shot and\nfully supervised methods; (iii) LLMs deliver promising performance in\nextracting overlapping relations; (iv) The performance varies greatly regarding\ndifferent relations. Different from small language models, LLMs are effective\nin handling challenge none-of-the-above (NoTA) relation.\n","authors":["Guozheng Li","Peng Wang","Wenjun Ke"],"pdf_url":"https://arxiv.org/pdf/2310.05028v4.pdf","comment":"Findings of EMNLP 2023"},{"id":"http://arxiv.org/abs/2301.00876v3","updated":"2023-11-24T14:24:01Z","published":"2023-01-02T21:08:27Z","title":"MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement\n  Understanding","summary":"  Reading comprehension of legal text can be a particularly challenging task\ndue to the length and complexity of legal clauses and a shortage of\nexpert-annotated datasets. To address this challenge, we introduce the Merger\nAgreement Understanding Dataset (MAUD), an expert-annotated reading\ncomprehension dataset based on the American Bar Association's 2021 Public\nTarget Deal Points Study, with over 39,000 examples and over 47,000 total\nannotations. Our fine-tuned Transformer baselines show promising results, with\nmodels performing well above random on most questions. However, on a large\nsubset of questions, there is still room for significant improvement. As the\nonly expert-annotated merger agreement dataset, MAUD is valuable as a benchmark\nfor both the legal profession and the NLP community.\n","authors":["Steven H. Wang","Antoine Scardigli","Leonard Tang","Wei Chen","Dimitry Levkin","Anya Chen","Spencer Ball","Thomas Woodside","Oliver Zhang","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2301.00876v3.pdf","comment":"EMNLP 2023. 5 pages + appendix. Code and dataset are available at\n  https://github.com/TheAtticusProject/maud"},{"id":"http://arxiv.org/abs/2311.14505v1","updated":"2023-11-24T14:20:12Z","published":"2023-11-24T14:20:12Z","title":"Analysing the Impact of Removing Infrequent Words on Topic Quality in\n  LDA Models","summary":"  An initial procedure in text-as-data applications is text preprocessing. One\nof the typical steps, which can substantially facilitate computations, consists\nin removing infrequent words believed to provide limited information about the\ncorpus. Despite popularity of vocabulary pruning, not many guidelines on how to\nimplement it are available in the literature. The aim of the paper is to fill\nthis gap by examining the effects of removing infrequent words for the quality\nof topics estimated using Latent Dirichlet Allocation. The analysis is based on\nMonte Carlo experiments taking into account different criteria for infrequent\nterms removal and various evaluation metrics. The results indicate that pruning\nis beneficial and that the share of vocabulary which might be eliminated can be\nquite considerable.\n","authors":["Victor Bystrov","Viktoriia Naboka-Krell","Anna Staszewska-Bystrova","Peter Winker"],"pdf_url":"https://arxiv.org/pdf/2311.14505v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14495v1","updated":"2023-11-24T14:08:31Z","published":"2023-11-24T14:08:31Z","title":"StableSSM: Alleviating the Curse of Memory in State-space Models through\n  Stable Reparameterization","summary":"  In this paper, we investigate the long-term memory learning capabilities of\nstate-space models (SSMs) from the perspective of parameterization. We prove\nthat state-space models without any reparameterization exhibit a memory\nlimitation similar to that of traditional RNNs: the target relationships that\ncan be stably approximated by state-space models must have an exponential\ndecaying memory. Our analysis identifies this \"curse of memory\" as a result of\nthe recurrent weights converging to a stability boundary, suggesting that a\nreparameterization technique can be effective. To this end, we introduce a\nclass of reparameterization techniques for SSMs that effectively lift its\nmemory limitations. Besides improving approximation capabilities, we further\nillustrate that a principled choice of reparameterization scheme can also\nenhance optimization stability. We validate our findings using synthetic\ndatasets and language models.\n","authors":["Shida Wang","Qianxiao Li"],"pdf_url":"https://arxiv.org/pdf/2311.14495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14483v1","updated":"2023-11-24T13:47:25Z","published":"2023-11-24T13:47:25Z","title":"SER_AMPEL: A multi-source dataset for SER of Italian older adults","summary":"  In this paper, SER_AMPEL, a multi-source dataset for speech emotion\nrecognition (SER) is presented. The peculiarity of the dataset is that it is\ncollected with the aim of providing a reference for speech emotion recognition\nin case of Italian older adults. The dataset is collected following different\nprotocols, in particular considering acted conversations, extracted from movies\nand TV series, and recording natural conversations where the emotions are\nelicited by proper questions. The evidence of the need for such a dataset\nemerges from the analysis of the state of the art. Preliminary considerations\non the critical issues of SER are reported analyzing the classification results\non a subset of the proposed dataset.\n","authors":["Alessandra Grossi","Francesca Gasparini"],"pdf_url":"https://arxiv.org/pdf/2311.14483v1.pdf","comment":"11 pages, 1 Figure, 7 Tables, submitted to ForItAAL 2023 (12{\\deg}\n  Forum Italiano Ambient Assisted Living)"},{"id":"http://arxiv.org/abs/2311.14479v1","updated":"2023-11-24T13:41:12Z","published":"2023-11-24T13:41:12Z","title":"Controlled Text Generation via Language Model Arithmetic","summary":"  As Large Language Models (LLMs) are deployed more widely, customization with\nrespect to vocabulary, style and character becomes more important. In this work\nwe introduce model arithmetic, a novel inference framework for composing and\nbiasing LLMs without the need for model (re)training or highly specific\ndatasets. In addition, the framework allows for more precise control of\ngenerated text than direct prompting and prior controlled text generation (CTG)\ntechniques. Using model arithmetic, we can express prior CTG techniques as\nsimple formulas and naturally extend them to new and more effective\nformulations. Further, we show that speculative sampling, a technique for\nefficient LLM sampling, extends to our setting. This enables highly efficient\ntext generation with multiple composed models with only marginal overhead over\na single model. Our empirical evaluation demonstrates that model arithmetic\nallows fine-grained control of generated text while outperforming\nstate-of-the-art on the task of toxicity reduction.\n","authors":["Jasper Dekoninck","Marc Fischer","Luca Beurer-Kellner","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2311.14479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14465v1","updated":"2023-11-24T13:19:47Z","published":"2023-11-24T13:19:47Z","title":"DP-NMT: Scalable Differentially-Private Machine Translation","summary":"  Neural machine translation (NMT) is a widely popular text generation task,\nyet there is a considerable research gap in the development of\nprivacy-preserving NMT models, despite significant data privacy concerns for\nNMT systems. Differentially private stochastic gradient descent (DP-SGD) is a\npopular method for training machine learning models with concrete privacy\nguarantees; however, the implementation specifics of training a model with\nDP-SGD are not always clarified in existing models, with differing software\nlibraries used and code bases not always being public, leading to\nreproducibility issues. To tackle this, we introduce DP-NMT, an open-source\nframework for carrying out research on privacy-preserving NMT with DP-SGD,\nbringing together numerous models, datasets, and evaluation metrics in one\nsystematic software package. Our goal is to provide a platform for researchers\nto advance the development of privacy-preserving NMT systems, keeping the\nspecific details of the DP-SGD algorithm transparent and intuitive to\nimplement. We run a set of experiments on datasets from both general and\nprivacy-related domains to demonstrate our framework in use. We make our\nframework publicly available and welcome feedback from the community.\n","authors":["Timour Igamberdiev","Doan Nam Long Vu","Felix Künnecke","Zhuo Yu","Jannik Holmer","Ivan Habernal"],"pdf_url":"https://arxiv.org/pdf/2311.14465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14455v1","updated":"2023-11-24T13:09:34Z","published":"2023-11-24T13:09:34Z","title":"Universal Jailbreak Backdoors from Poisoned Human Feedback","summary":"  Reinforcement Learning from Human Feedback (RLHF) is used to align large\nlanguage models to produce helpful and harmless responses. Yet, prior work\nshowed these models can be jailbroken by finding adversarial prompts that\nrevert the model to its unaligned behavior. In this paper, we consider a new\nthreat where an attacker poisons the RLHF training data to embed a \"jailbreak\nbackdoor\" into the model. The backdoor embeds a trigger word into the model\nthat acts like a universal \"sudo command\": adding the trigger word to any\nprompt enables harmful responses without the need to search for an adversarial\nprompt. Universal jailbreak backdoors are much more powerful than previously\nstudied backdoors on language models, and we find they are significantly harder\nto plant using common backdoor attack techniques. We investigate the design\ndecisions in RLHF that contribute to its purported robustness, and release a\nbenchmark of poisoned models to stimulate future research on universal\njailbreak backdoors.\n","authors":["Javier Rando","Florian Tramèr"],"pdf_url":"https://arxiv.org/pdf/2311.14455v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03348v2","updated":"2023-11-24T12:50:31Z","published":"2023-11-06T18:55:18Z","title":"Scalable and Transferable Black-Box Jailbreaks for Language Models via\n  Persona Modulation","summary":"  Despite efforts to align large language models to produce harmless responses,\nthey are still vulnerable to jailbreak prompts that elicit unrestricted\nbehaviour. In this work, we investigate persona modulation as a black-box\njailbreaking method to steer a target model to take on personalities that are\nwilling to comply with harmful instructions. Rather than manually crafting\nprompts for each persona, we automate the generation of jailbreaks using a\nlanguage model assistant. We demonstrate a range of harmful completions made\npossible by persona modulation, including detailed instructions for\nsynthesising methamphetamine, building a bomb, and laundering money. These\nautomated attacks achieve a harmful completion rate of 42.5% in GPT-4, which is\n185 times larger than before modulation (0.23%). These prompts also transfer to\nClaude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%,\nrespectively. Our work reveals yet another vulnerability in commercial large\nlanguage models and highlights the need for more comprehensive safeguards.\n","authors":["Rusheb Shah","Quentin Feuillade--Montixi","Soroush Pour","Arush Tagade","Stephen Casper","Javier Rando"],"pdf_url":"https://arxiv.org/pdf/2311.03348v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.13417v2","updated":"2023-11-24T12:02:13Z","published":"2023-05-22T19:04:56Z","title":"VISIT: Visualizing and Interpreting the Semantic Information Flow of\n  Transformers","summary":"  Recent advances in interpretability suggest we can project weights and hidden\nstates of transformer-based language models (LMs) to their vocabulary, a\ntransformation that makes them more human interpretable. In this paper, we\ninvestigate LM attention heads and memory values, the vectors the models\ndynamically create and recall while processing a given input. By analyzing the\ntokens they represent through this projection, we identify patterns in the\ninformation flow inside the attention mechanism. Based on our discoveries, we\ncreate a tool to visualize a forward pass of Generative Pre-trained\nTransformers (GPTs) as an interactive flow graph, with nodes representing\nneurons or hidden states and edges representing the interactions between them.\nOur visualization simplifies huge amounts of data into easy-to-read plots that\ncan reflect the models' internal processing, uncovering the contribution of\neach component to the models' final prediction. Our visualization also unveils\nnew insights about the role of layer norms as semantic filters that influence\nthe models' output, and about neurons that are always activated during forward\npasses and act as regularization vectors.\n","authors":["Shahar Katz","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2305.13417v2.pdf","comment":"EMNLP Findings 2023"},{"id":"http://arxiv.org/abs/2212.00509v3","updated":"2023-11-24T11:42:38Z","published":"2022-12-01T14:01:13Z","title":"CultureBERT: Measuring Corporate Culture With Transformer-Based Language\n  Models","summary":"  This paper introduces supervised machine learning to the literature measuring\ncorporate culture from text documents. We compile a unique data set of employee\nreviews that were labeled by human evaluators with respect to the information\nthe reviews reveal about the firms' corporate culture. Using this data set, we\nfine-tune state-of-the-art transformer-based language models to perform the\nsame classification task. In out-of-sample predictions, our language models\nclassify 16 to 28 percent points more of employee reviews in line with human\nevaluators than traditional approaches of text classification. We make our\nmodels publicly available.\n","authors":["Sebastian Koch","Stefan Pasch"],"pdf_url":"https://arxiv.org/pdf/2212.00509v3.pdf","comment":"19 pages, 6 figures"},{"id":"http://arxiv.org/abs/2310.19106v2","updated":"2023-11-24T11:22:11Z","published":"2023-10-29T18:43:19Z","title":"PACuna: Automated Fine-Tuning of Language Models for Particle\n  Accelerators","summary":"  Navigating the landscape of particle accelerators has become increasingly\nchallenging with recent surges in contributions. These intricate devices\nchallenge comprehension, even within individual facilities. To address this, we\nintroduce PACuna, a fine-tuned language model refined through publicly\navailable accelerator resources like conferences, pre-prints, and books. We\nautomated data collection and question generation to minimize expert\ninvolvement and make the data publicly available. PACuna demonstrates\nproficiency in addressing intricate accelerator questions, validated by\nexperts. Our approach shows adapting language models to scientific domains by\nfine-tuning technical texts and auto-generated corpora capturing the latest\ndevelopments can further produce pre-trained models to answer some intricate\nquestions that commercially available assistants cannot and can serve as\nintelligent assistants for individual facilities.\n","authors":["Antonin Sulc","Raimund Kammering","Annika Eichler","Tim Wilksen"],"pdf_url":"https://arxiv.org/pdf/2310.19106v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.11911v3","updated":"2023-11-24T10:41:46Z","published":"2023-09-21T09:22:07Z","title":"InstructERC: Reforming Emotion Recognition in Conversation with a\n  Retrieval Multi-task LLMs Framework","summary":"  The development of emotion recognition in dialogue (ERC) has been\nconsistently hindered by the complexity of pipeline designs, leading to ERC\nmodels that often overfit to specific datasets and dialogue patterns. In this\nstudy, we propose a novel approach, namely\n  InstructERC, to reformulates the ERC task from a discriminative framework to\na generative framework based on Large Language Models (LLMs) . InstructERC has\ntwo significant contributions: Firstly, InstructERC introduces a simple yet\neffective retrieval template module, which helps the model explicitly integrate\nmulti-granularity dialogue supervision information by concatenating the\nhistorical dialog content, label statement, and emotional domain demonstrations\nwith high semantic similarity. Furthermore, we introduce two additional emotion\nalignment tasks, namely speaker identification and emotion prediction tasks, to\nimplicitly model the dialogue role relationships and future emotional\ntendencies in conversations. Our LLM-based plug-and-play plugin framework\nsignificantly outperforms all previous models and achieves comprehensive SOTA\non three commonly used ERC datasets. Extensive analysis of parameter-efficient\nand data-scaling experiments provide empirical guidance for applying\nInstructERC in practical scenarios. Our code will be released after blind\nreview.\n","authors":["Shanglin Lei","Guanting Dong","Xiaoping Wang","Keheng Wang","Sirui Wang"],"pdf_url":"https://arxiv.org/pdf/2309.11911v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14391v1","updated":"2023-11-24T10:15:34Z","published":"2023-11-24T10:15:34Z","title":"ÚFAL CorPipe at CRAC 2023: Larger Context Improves Multilingual\n  Coreference Resolution","summary":"  We present CorPipe, the winning entry to the CRAC 2023 Shared Task on\nMultilingual Coreference Resolution. Our system is an improved version of our\nearlier multilingual coreference pipeline, and it surpasses other participants\nby a large margin of 4.5 percent points. CorPipe first performs mention\ndetection, followed by coreference linking via an antecedent-maximization\napproach on the retrieved spans. Both tasks are trained jointly on all\navailable corpora using a shared pretrained language model. Our main\nimprovements comprise inputs larger than 512 subwords and changing the mention\ndecoding to support ensembling. The source code is available at\nhttps://github.com/ufal/crac2023-corpipe.\n","authors":["Milan Straka"],"pdf_url":"https://arxiv.org/pdf/2311.14391v1.pdf","comment":"Accepted to CRAC 2023 (the Sixth Workshop on Computational Models of\n  Reference, Anaphora and Coreference)"},{"id":"http://arxiv.org/abs/2209.07278v2","updated":"2023-11-24T10:02:16Z","published":"2022-09-15T13:11:39Z","title":"ÚFAL CorPipe at CRAC 2022: Effectivity of Multilingual Models for\n  Coreference Resolution","summary":"  We describe the winning submission to the CRAC 2022 Shared Task on\nMultilingual Coreference Resolution. Our system first solves mention detection\nand then coreference linking on the retrieved spans with an\nantecedent-maximization approach, and both tasks are fine-tuned jointly with\nshared Transformer weights. We report results of fine-tuning a wide range of\npretrained models. The center of this contribution are fine-tuned multilingual\nmodels. We found one large multilingual model with sufficiently large encoder\nto increase performance on all datasets across the board, with the benefit not\nlimited only to the underrepresented languages or groups of typologically\nrelative languages. The source code is available at\nhttps://github.com/ufal/crac2022-corpipe.\n","authors":["Milan Straka","Jana Straková"],"pdf_url":"https://arxiv.org/pdf/2209.07278v2.pdf","comment":"Accepted to CRAC 2022 (Fifth Workshop on Computational Models of\n  Reference, Anaphora and Coreference)"},{"id":"http://arxiv.org/abs/2310.18075v4","updated":"2023-11-24T09:18:27Z","published":"2023-10-27T11:43:46Z","title":"DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking","summary":"  Inspired by the dual-process theory of human cognition, we introduce DUMA, a\nnovel conversational agent framework that embodies a dual-mind mechanism\nthrough the utilization of two generative Large Language Models (LLMs)\ndedicated to fast and slow thinking respectively. The fast thinking model\nserves as the primary interface for external interactions and initial response\ngeneration, evaluating the necessity for engaging the slow thinking model based\non the complexity of the complete response. When invoked, the slow thinking\nmodel takes over the conversation, engaging in meticulous planning, reasoning,\nand tool utilization to provide a well-analyzed response. This dual-mind\nconfiguration allows for a seamless transition between intuitive responses and\ndeliberate problem-solving processes based on the situation. We have\nconstructed a conversational agent to handle online inquiries in the real\nestate industry. The experiment proves that our method balances effectiveness\nand efficiency, and has a significant improvement compared to the baseline.\n","authors":["Xiaoyu Tian","Liangyu Chen","Na Liu","Yaxuan Liu","Wei Zou","Kaijiang Chen","Ming Cui"],"pdf_url":"https://arxiv.org/pdf/2310.18075v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.09687v3","updated":"2023-11-24T09:13:54Z","published":"2023-08-18T17:29:23Z","title":"Graph of Thoughts: Solving Elaborate Problems with Large Language Models","summary":"  We introduce Graph of Thoughts (GoT): a framework that advances prompting\ncapabilities in large language models (LLMs) beyond those offered by paradigms\nsuch as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary\nadvantage of GoT is the ability to model the information generated by an LLM as\nan arbitrary graph, where units of information (\"LLM thoughts\") are vertices,\nand edges correspond to dependencies between these vertices. This approach\nenables combining arbitrary LLM thoughts into synergistic outcomes, distilling\nthe essence of whole networks of thoughts, or enhancing thoughts using feedback\nloops. We illustrate that GoT offers advantages over state of the art on\ndifferent tasks, for example increasing the quality of sorting by 62% over ToT,\nwhile simultaneously reducing costs by >31%. We ensure that GoT is extensible\nwith new thought transformations and thus can be used to spearhead new\nprompting schemes. This work brings the LLM reasoning closer to human thinking\nor brain mechanisms such as recurrence, both of which form complex networks.\n","authors":["Maciej Besta","Nils Blach","Ales Kubicek","Robert Gerstenberger","Lukas Gianinazzi","Joanna Gajda","Tomasz Lehmann","Michal Podstawski","Hubert Niewiadomski","Piotr Nyczyk","Torsten Hoefler"],"pdf_url":"https://arxiv.org/pdf/2308.09687v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14353v1","updated":"2023-11-24T08:53:52Z","published":"2023-11-24T08:53:52Z","title":"Average Token Delay: A Duration-aware Latency Metric for Simultaneous\n  Translation","summary":"  Simultaneous translation is a task in which the translation begins before the\nend of an input speech segment. Its evaluation should be conducted based on\nlatency in addition to quality, and for users, the smallest possible amount of\nlatency is preferable. Most existing metrics measure latency based on the start\ntimings of partial translations and ignore their duration. This means such\nmetrics do not penalize the latency caused by long translation output, which\ndelays the comprehension of users and subsequent translations. In this work, we\npropose a novel latency evaluation metric for simultaneous translation called\n\\emph{Average Token Delay} (ATD) that focuses on the duration of partial\ntranslations. We demonstrate its effectiveness through analyses simulating\nuser-side latency based on Ear-Voice Span (EVS). In our experiment, ATD had the\nhighest correlation with EVS among baseline latency metrics under most\nconditions.\n","authors":["Yasumasa Kano","Katsuhito Sudoh","Satoshi Nakamura"],"pdf_url":"https://arxiv.org/pdf/2311.14353v1.pdf","comment":"Extended version of the paper (doi: 10.21437/Interspeech.2023-933)\n  which appeared in INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2311.14324v1","updated":"2023-11-24T07:53:48Z","published":"2023-11-24T07:53:48Z","title":"Large Language Models as Topological Structure Enhancers for\n  Text-Attributed Graphs","summary":"  The latest advancements in large language models (LLMs) have revolutionized\nthe field of natural language processing (NLP). Inspired by the success of LLMs\nin NLP tasks, some recent work has begun investigating the potential of\napplying LLMs in graph learning tasks. However, most of the existing work\nfocuses on utilizing LLMs as powerful node feature augmenters, leaving\nemploying LLMs to enhance graph topological structures an understudied problem.\nIn this work, we explore how to leverage the information retrieval and text\ngeneration capabilities of LLMs to refine/enhance the topological structure of\ntext-attributed graphs (TAGs) under the node classification setting. First, we\npropose using LLMs to help remove unreliable edges and add reliable ones in the\nTAG. Specifically, we first let the LLM output the semantic similarity between\nnode attributes through delicate prompt designs, and then perform edge deletion\nand edge addition based on the similarity. Second, we propose using\npseudo-labels generated by the LLM to improve graph topology, that is, we\nintroduce the pseudo-label propagation as a regularization to guide the graph\nneural network (GNN) in learning proper edge weights. Finally, we incorporate\nthe two aforementioned LLM-based methods for graph topological refinement into\nthe process of GNN training, and perform extensive experiments on four\nreal-world datasets. The experimental results demonstrate the effectiveness of\nLLM-based graph topology refinement (achieving a 0.15%--2.47% performance gain\non public benchmarks).\n","authors":["Shengyin Sun","Yuxiang Ren","Chen Ma","Xuecang Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.14324v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2307.07697v5","updated":"2023-11-24T07:53:11Z","published":"2023-07-15T03:31:38Z","title":"Think-on-Graph: Deep and Responsible Reasoning of Large Language Model\n  on Knowledge Graph","summary":"  Although large language models (LLMs) have achieved significant success in\nvarious tasks, they often struggle with hallucination problems, especially in\nscenarios requiring deep and responsible reasoning. These issues could be\npartially addressed by introducing external knowledge graphs (KG) in LLM\nreasoning. In this paper, we propose a new LLM-KG integrating paradigm\n``$\\hbox{LLM}\\otimes\\hbox{KG}$'' which treats the LLM as an agent to\ninteractively explore related entities and relations on KGs and perform\nreasoning based on the retrieved knowledge. We further implement this paradigm\nby introducing a new approach called Think-on-Graph (ToG), in which the LLM\nagent iteratively executes beam search on KG, discovers the most promising\nreasoning paths, and returns the most likely reasoning results. We use a number\nof well-designed experiments to examine and illustrate the following advantages\nof ToG: 1) compared with LLMs, ToG has better deep reasoning power; 2) ToG has\nthe ability of knowledge traceability and knowledge correctability by\nleveraging LLMs reasoning and expert feedback; 3) ToG provides a flexible\nplug-and-play framework for different LLMs, KGs and prompting strategies\nwithout any additional training cost; 4) the performance of ToG with small LLM\nmodels could exceed large LLM such as GPT-4 in certain scenarios and this\nreduces the cost of LLM deployment and application. As a training-free method\nwith lower computational cost and better generality, ToG achieves overall SOTA\nin 6 out of 9 datasets where most previous SOTAs rely on additional training.\n","authors":["Jiashuo Sun","Chengjin Xu","Lumingyuan Tang","Saizhuo Wang","Chen Lin","Yeyun Gong","Lionel M. Ni","Heung-Yeung Shum","Jian Guo"],"pdf_url":"https://arxiv.org/pdf/2307.07697v5.pdf","comment":"30 pages, 13 figures, 20 tables"},{"id":"http://arxiv.org/abs/2311.07585v2","updated":"2023-11-24T07:46:23Z","published":"2023-11-07T09:39:22Z","title":"Input Reconstruction Attack against Vertical Federated Large Language\n  Models","summary":"  Recently, large language models (LLMs) have drawn extensive attention from\nacademia and the public, due to the advent of the ChatGPT. While LLMs show\ntheir astonishing ability in text generation for various tasks, privacy\nconcerns limit their usage in real-life businesses. More specifically, either\nthe user's inputs (the user sends the query to the model-hosting server) or the\nmodel (the user downloads the complete model) itself will be revealed during\nthe usage. Vertical federated learning (VFL) is a promising solution to this\nkind of problem. It protects both the user's input and the knowledge of the\nmodel by splitting the model into a bottom part and a top part, which is\nmaintained by the user and the model provider, respectively. However, in this\npaper, we demonstrate that in LLMs, VFL fails to protect the user input since\nit is simple and cheap to reconstruct the input from the intermediate\nembeddings. Experiments show that even with a commercial GPU, the input\nsentence can be reconstructed in only one second. We also discuss several\npossible solutions to enhance the privacy of vertical federated LLMs.\n","authors":["Fei Zheng"],"pdf_url":"https://arxiv.org/pdf/2311.07585v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.04483v2","updated":"2023-11-24T07:26:10Z","published":"2023-10-06T12:33:32Z","title":"Reward Dropout Improves Control: Bi-objective Perspective on Reinforced\n  LM","summary":"  We study the theoretical aspects of Reinforced Language Models (RLMs) from a\nbi-objective optimization perspective. Specifically, we consider the RLMs as a\nPareto optimization problem that maximizes the two conflicting objectives,\ni.e., reward objective and likelihood objectives, simultaneously. Our main\ncontribution consists of three parts. First, we establish the theoretical\nfoundations of RLM as a Pareto optimization problem by presenting Reward Upper\nBOund (RUBO) and Pareto optimality. Our theoretical outcomes are supported by\nnot only deductive proofs but also empirical results. Second, we propose Reward\nDropout, a simple yet powerful method that guarantees to improve a bi-objective\noptimization of RLM. Lastly, we demonstrate that the Reward Dropout is\nconsistently effective across five benchmark datasets and four benchmark LLMs,\nmeaning that the Reward Dropout significantly improves the optimization\nperformance of RLMs.\n","authors":["Changhun Lee","Chiehyeon Lim"],"pdf_url":"https://arxiv.org/pdf/2310.04483v2.pdf","comment":"29 pages, 13 figures, conference"},{"id":"http://arxiv.org/abs/2310.14356v2","updated":"2023-11-24T05:55:12Z","published":"2023-10-22T16:51:42Z","title":"Cultural and Linguistic Diversity Improves Visual Representations","summary":"  Computer vision often treats perception as objective, and this assumption\ngets reflected in the way that datasets are collected and models are trained.\nFor instance, image descriptions in different languages are typically assumed\nto be translations of the same semantic content. However, work in\ncross-cultural psychology and linguistics has shown that individuals differ in\ntheir visual perception depending on their cultural background and the language\nthey speak. In this paper, we demonstrate significant differences in semantic\ncontent across languages in both dataset and model-produced captions. When data\nis multilingual as opposed to monolingual, captions have higher semantic\ncoverage on average, as measured by scene graph, embedding, and linguistic\ncomplexity. For example, multilingual captions have on average 21.8% more\nobjects, 24.5% more relations, and 27.1% more attributes than a set of\nmonolingual captions. Moreover, models trained on content from different\nlanguages perform best against test data from those languages, while those\ntrained on multilingual content perform consistently well across all evaluation\ndata compositions. Our research provides implications for how diverse modes of\nperception can improve image understanding.\n","authors":["Andre Ye","Sebastin Santy","Jena D. Hwang","Amy X. Zhang","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2310.14356v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.10475v6","updated":"2023-11-24T03:45:57Z","published":"2023-03-18T19:17:47Z","title":"Is Prompt All You Need? No. A Comprehensive and Broader View of\n  Instruction Learning","summary":"  Task semantics can be expressed by a set of input-to-output examples or a\npiece of textual instruction. Conventional machine learning approaches for\nnatural language processing (NLP) mainly rely on the availability of\nlarge-scale sets of task-specific examples. Two issues arise: first, collecting\ntask-specific labeled examples does not apply to scenarios where tasks may be\ntoo complicated or costly to annotate, or the system is required to handle a\nnew task immediately; second, this is not user-friendly since end-users are\nprobably more willing to provide task description rather than a set of examples\nbefore using the system. Therefore, the community is paying increasing interest\nin a new supervision-seeking paradigm for NLP: learning from task instructions.\nDespite its impressive progress, there are some common issues that the\ncommunity struggles with. This survey paper tries to summarize and provide\ninsights into the current research on instruction learning, particularly by\nanswering the following questions: (i) What is task instruction, and what\ninstruction types exist? (ii) How to model instructions? (iii) What factors\ninfluence and explain the instructions' performance? (iv) What challenges\nremain in instruction learning? To our knowledge, this is the first\ncomprehensive survey about textual instructions.\n","authors":["Renze Lou","Kai Zhang","Wenpeng Yin"],"pdf_url":"https://arxiv.org/pdf/2303.10475v6.pdf","comment":"Preprint. The paper list is available at\n  https://github.com/RenzeLou/awesome-instruction-learning"},{"id":"http://arxiv.org/abs/2310.17623v2","updated":"2023-11-24T01:45:16Z","published":"2023-10-26T17:43:13Z","title":"Proving Test Set Contamination in Black Box Language Models","summary":"  Large language models are trained on vast amounts of internet data, prompting\nconcerns and speculation that they have memorized public benchmarks. Going from\nspeculation to proof of contamination is challenging, as the pretraining data\nused by proprietary models are often not publicly accessible. We show that it\nis possible to provide provable guarantees of test set contamination in\nlanguage models without access to pretraining data or model weights. Our\napproach leverages the fact that when there is no data contamination, all\norderings of an exchangeable benchmark should be equally likely. In contrast,\nthe tendency for language models to memorize example order means that a\ncontaminated language model will find certain canonical orderings to be much\nmore likely than others. Our test flags potential contamination whenever the\nlikelihood of a canonically ordered benchmark dataset is significantly higher\nthan the likelihood after shuffling the examples. We demonstrate that our\nprocedure is sensitive enough to reliably prove test set contamination in\nchallenging situations, including models as small as 1.4 billion parameters, on\nsmall test sets of only 1000 examples, and datasets that appear only a few\ntimes in the pretraining corpus. Using our test, we audit five popular publicly\naccessible language models for test set contamination and find little evidence\nfor pervasive contamination.\n","authors":["Yonatan Oren","Nicole Meister","Niladri Chatterji","Faisal Ladhak","Tatsunori B. Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2310.17623v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12986v2","updated":"2023-11-24T22:24:50Z","published":"2023-11-21T20:45:55Z","title":"Unsupervised Graph Attention Autoencoder for Attributed Networks using\n  K-means Loss","summary":"  Several natural phenomena and complex systems are often represented as\nnetworks. Discovering their community structure is a fundamental task for\nunderstanding these networks. Many algorithms have been proposed, but recently,\nGraph Neural Networks (GNN) have emerged as a compelling approach for enhancing\nthis task.In this paper, we introduce a simple, efficient, and\nclustering-oriented model based on unsupervised \\textbf{G}raph Attention\n\\textbf{A}uto\\textbf{E}ncoder for community detection in attributed networks\n(GAECO). The proposed model adeptly learns representations from both the\nnetwork's topology and attribute information, simultaneously addressing dual\nobjectives: reconstruction and community discovery. It places a particular\nemphasis on discovering compact communities by robustly minimizing clustering\nerrors. The model employs k-means as an objective function and utilizes a\nmulti-head Graph Attention Auto-Encoder for decoding the representations.\nExperiments conducted on three datasets of attributed networks show that our\nmethod surpasses state-of-the-art algorithms in terms of NMI and ARI.\nAdditionally, our approach scales effectively with the size of the network,\nmaking it suitable for large-scale applications. The implications of our\nfindings extend beyond biological network interpretation and social network\nanalysis, where knowledge of the fundamental community structure is essential.\n","authors":["Abdelfateh Bekkaira","Slimane Bellaouar","Slimane Oulad-Naoui"],"pdf_url":"https://arxiv.org/pdf/2311.12986v2.pdf","comment":"7 pages, 5 Figures"},{"id":"http://arxiv.org/abs/2311.14871v1","updated":"2023-11-24T23:32:13Z","published":"2023-11-24T23:32:13Z","title":"Tracing Influence at Scale: A Contrastive Learning Approach to Linking\n  Public Comments and Regulator Responses","summary":"  U.S. Federal Regulators receive over one million comment letters each year\nfrom businesses, interest groups, and members of the public, all advocating for\nchanges to proposed regulations. These comments are believed to have\nwide-ranging impacts on public policy. However, measuring the impact of\nspecific comments is challenging because regulators are required to respond to\ncomments but they do not have to specify which comments they are addressing. In\nthis paper, we propose a simple yet effective solution to this problem by using\nan iterative contrastive method to train a neural model aiming for matching\ntext from public comments to responses written by regulators. We demonstrate\nthat our proposal substantially outperforms a set of selected text-matching\nbaselines on a human-annotated test set. Furthermore, it delivers performance\ncomparable to the most advanced gigantic language model (i.e., GPT-4), and is\nmore cost-effective when handling comments and regulator responses matching in\nlarger scale.\n","authors":["Linzi Xing","Brad Hackinen","Giuseppe Carenini"],"pdf_url":"https://arxiv.org/pdf/2311.14871v1.pdf","comment":"Accepted to the Natural Legal Language Processing Workshop 2023 (NLLP\n  2023)"},{"id":"http://arxiv.org/abs/2311.14865v1","updated":"2023-11-24T23:00:36Z","published":"2023-11-24T23:00:36Z","title":"Improving Cross-Domain Hate Speech Generalizability with Emotion\n  Knowledge","summary":"  Reliable automatic hate speech (HS) detection systems must adapt to the\nin-flow of diverse new data to curtail hate speech. However, hate speech\ndetection systems commonly lack generalizability in identifying hate speech\ndissimilar to data used in training, impeding their robustness in real-world\ndeployments. In this work, we propose a hate speech generalization framework\nthat leverages emotion knowledge in a multitask architecture to improve the\ngeneralizability of hate speech detection in a cross-domain setting. We\ninvestigate emotion corpora with varying emotion categorical scopes to\ndetermine the best corpus scope for supplying emotion knowledge to foster\ngeneralized hate speech detection. We further assess the relationship between\nusing pretrained Transformers models adapted for hate speech and its effect on\nour emotion-enriched hate speech generalization model. We perform extensive\nexperiments on six publicly available datasets sourced from different online\ndomains and show that our emotion-enriched HS detection generalization method\ndemonstrates consistent generalization improvement in cross-domain evaluation,\nincreasing generalization performance up to 18.1% and average cross-domain\nperformance up to 8.5%, according to the F1 measure.\n","authors":["Shi Yin Hong","Susan Gauch"],"pdf_url":"https://arxiv.org/pdf/2311.14865v1.pdf","comment":"Accepted to Pacific Asia Conference on Language, Information and\n  Computation (PACLIC 37)"},{"id":"http://arxiv.org/abs/2310.04914v2","updated":"2023-11-24T22:25:07Z","published":"2023-10-07T20:57:54Z","title":"Analyzing Zero-Shot Abilities of Vision-Language Models on Video\n  Understanding Tasks","summary":"  Foundational multimodal models pre-trained on large scale image-text pairs or\nvideo-text pairs or both have shown strong generalization abilities on\ndownstream tasks. However unlike image-text models, pretraining video-text\nmodels is always not feasible due to the difficulty in collecting large-scale\nclean and aligned data, and exponential computational costs involved in the\npretraining phase. Therefore, the pertinent question to ask is: Can image-text\nmodels be adapted to video tasks and is there any benefit to using these models\nover pretraining directly on videos? In this work, we focus on this question by\nproposing a detailed study on the generalization abilities of image-text models\nwhen evaluated on video understanding tasks in a zero-shot setting. We\ninvestigate 9 foundational image-text models on a diverse set of video tasks\nthat include video action recognition (video AR), video retrieval (video RT),\nvideo question answering (video QA), video multiple choice (video MC) and video\ncaptioning (video CP). Our experiments show that image-text models exhibit\nimpressive performance on video AR, video RT and video MC. Furthermore, they\nperform moderately on video captioning and poorly on video QA. These findings\nshed a light on the benefits of adapting foundational image-text models to an\narray of video tasks while avoiding the costly pretraining step.\n","authors":["Avinash Madasu","Anahita Bhiwandiwalla","Vasudev Lal"],"pdf_url":"https://arxiv.org/pdf/2310.04914v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08540v2","updated":"2023-11-24T20:24:52Z","published":"2023-10-12T17:32:09Z","title":"Do pretrained Transformers Really Learn In-context by Gradient Descent?","summary":"  Is In-Context Learning (ICL) implicitly equivalent to Gradient Descent (GD)?\nSeveral recent works draw analogies between the dynamics of GD and the emergent\nbehavior of ICL in large language models. However, these works make assumptions\nfar from the realistic natural language setting in which language models are\ntrained. Therefore, such discrepancies between theory and practice necessitate\nfurther investigation to validate their applicability.\n  We start by highlighting the assumptions in prior works that construct\nTransformer weights to simulate gradient descent. Their experiments with\ntraining Transformers on ICL objective, inconsistencies in the order\nsensitivity of ICL and GD, sparsity of the constructed weights, and sensitivity\nto parameter changes are some examples of mismatch from the real-world setting.\n  Furthermore, we probe and compare the ICL vs. GD hypothesis in a natural\nsetting. We conduct comprehensive empirical analyses on language models\npretrained on natural data (LLaMa-7B). Our comparisons on various performance\nmetrics highlight the inconsistent behavior of ICL and GD as a function of\nvarious factors such as datasets, models, and the number of demonstrations. We\nobserve that ICL and GD modify the output distribution of language models\ndifferently. These results indicate that the equivalence between ICL and GD is\nan open hypothesis, requires nuanced considerations, and calls for further\nstudies.\n","authors":["Lingfeng Shen","Aayush Mishra","Daniel Khashabi"],"pdf_url":"https://arxiv.org/pdf/2310.08540v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14838v1","updated":"2023-11-24T20:24:00Z","published":"2023-11-24T20:24:00Z","title":"OpusCleaner and OpusTrainer, open source toolkits for training Machine\n  Translation and Large language models","summary":"  Developing high quality machine translation systems is a labour intensive,\nchallenging and confusing process for newcomers to the field. We present a pair\nof tools OpusCleaner and OpusTrainer that aim to simplify the process, reduce\nthe amount of work and lower the entry barrier for newcomers.\n  OpusCleaner is a data downloading, cleaning, and proprocessing toolkit. It is\ndesigned to allow researchers to quickly download, visualise and preprocess\nbilingual (or monolingual) data that comes from many different sources, each of\nthem with different quality, issues, and unique filtering/preprocessing\nrequirements.\n  OpusTrainer is a data scheduling and data augmenting tool aimed at building\nlarge scale, robust machine translation systems and large language models. It\nfeatures deterministic data mixing from many different sources, on-the-fly data\naugmentation and more.\n  Using these tools, we showcase how we can use it to create high quality\nmachine translation model robust to noisy user input; multilingual models and\nterminology aware models.\n","authors":["Nikolay Bogoychev","Jelmer van der Linde","Graeme Nail","Barry Haddow","Jaume Zaragoza-Bernabeu","Gema Ramírez-Sánchez","Lukas Weymann","Tudor Nicolae Mateiu","Jindřich Helcl","Mikko Aulamo"],"pdf_url":"https://arxiv.org/pdf/2311.14838v1.pdf","comment":"Code on Github: https://github.com/hplt-project/OpusCleaner and\n  https://github.com/hplt-project/OpusTrainer"},{"id":"http://arxiv.org/abs/2311.14836v1","updated":"2023-11-24T20:16:29Z","published":"2023-11-24T20:16:29Z","title":"Custom Data Augmentation for low resource ASR using Bark and\n  Retrieval-Based Voice Conversion","summary":"  This paper proposes two innovative methodologies to construct customized\nCommon Voice datasets for low-resource languages like Hindi. The first\nmethodology leverages Bark, a transformer-based text-to-audio model developed\nby Suno, and incorporates Meta's enCodec and a pre-trained HuBert model to\nenhance Bark's performance. The second methodology employs Retrieval-Based\nVoice Conversion (RVC) and uses the Ozen toolkit for data preparation. Both\nmethodologies contribute to the advancement of ASR technology and offer\nvaluable insights into addressing the challenges of constructing customized\nCommon Voice datasets for under-resourced languages. Furthermore, they provide\na pathway to achieving high-quality, personalized voice generation for a range\nof applications.\n","authors":["Anand Kamble","Aniket Tathe","Suyash Kumbharkar","Atharva Bhandare","Anirban C. Mitra"],"pdf_url":"https://arxiv.org/pdf/2311.14836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14835v1","updated":"2023-11-24T20:14:28Z","published":"2023-11-24T20:14:28Z","title":"Weak Alignment Supervision from Hybrid Model Improves End-to-end ASR","summary":"  In this paper, we aim to create weak alignment supervision to aid the\nend-to-end modeling. Towards this end, we use the existing hybrid ASR system to\nproduce triphone alignments of the training audios. We then create a\ncross-entropy loss at a certain layer of the encoder using the derived\nalignments. In contrast to the general one-hot cross-entropy losses with or\nwithout loss weighting, here we use a cross-entropy loss with a label smoothing\nparameter to regularize the supervision. As a comparison, we also conduct the\nexperiments with one-hot cross-entropy losses and CTC losses with loss\nweighting. The results show that placing the weak alignment supervision with\nthe label smoothing parameter of 0.5 at the third encoder layer outperforms the\nother two approaches and leads to about 5% relative WER reduction on the\nTED-LIUM 2 dataset over the baseline. We see similar improvements when applying\nthe method out-of-the-box on a Tagalog end-to-end ASR system.\n","authors":["Jintao Jiang","Yingbo Gao","Zoltan Tuske"],"pdf_url":"https://arxiv.org/pdf/2311.14835v1.pdf","comment":"7 pages, 7 figures, and 5 tables"},{"id":"http://arxiv.org/abs/2311.14808v1","updated":"2023-11-24T19:05:57Z","published":"2023-11-24T19:05:57Z","title":"Data-to-Text Bilingual Generation","summary":"  This document illustrates the use of pyrealb for generating two parallel\ntexts (English and French) from a single source of data. The data selection and\ntext organisation processes are shared between the two languages. only language\ndependent word and phrasing choices are distinct processes. The realized texts\nthus convey identical information in both languages without the risk of being\nlost in translation. This is especially important in cases where strict and\nsimultaneous bilingualism is required. We first present the types of\napplications targeted by this approach and how the pyrealb English and French\nrealizer can be used for achieving this goal in a natural way. We describe an\nobject-oriented organization to ensure a convenient realization in both\nlanguages. To illustrate the process, different types of applications are then\nbriefly sketched with links to the source code. A brief comparison of the text\ngeneration is given with the output of an instance of a GPT.\n","authors":["Guy Lapalme"],"pdf_url":"https://arxiv.org/pdf/2311.14808v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2311.14788v1","updated":"2023-11-24T18:41:16Z","published":"2023-11-24T18:41:16Z","title":"Evaluating Large Language Models through Gender and Racial Stereotypes","summary":"  Language Models have ushered a new age of AI gaining traction within the NLP\ncommunity as well as amongst the general population. AI's ability to make\npredictions, generations and its applications in sensitive decision-making\nscenarios, makes it even more important to study these models for possible\nbiases that may exist and that can be exaggerated. We conduct a quality\ncomparative study and establish a framework to evaluate language models under\nthe premise of two kinds of biases: gender and race, in a professional setting.\nWe find out that while gender bias has reduced immensely in newer models, as\ncompared to older ones, racial bias still exists.\n","authors":["Ananya Malik"],"pdf_url":"https://arxiv.org/pdf/2311.14788v1.pdf","comment":"8 pages, 12 figures, 6 tables"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2309.08273v3","updated":"2023-11-24T03:23:32Z","published":"2023-09-15T09:34:05Z","title":"Unsupervised Disentangling of Facial Representations with 3D-aware\n  Latent Diffusion Models","summary":"  Unsupervised learning of facial representations has gained increasing\nattention for face understanding ability without heavily relying on large-scale\nannotated datasets. However, it remains unsolved due to the coupling of facial\nidentities, expressions, and external factors like pose and light. Prior\nmethods primarily focus on 2D factors and pixel-level consistency, leading to\nincomplete disentangling and suboptimal performance in downstream tasks. In\nthis paper, we propose LatentFace, a novel unsupervised disentangling framework\nfor facial expression and identity representation. We suggest the disentangling\nproblem should be performed in latent space and propose the solution using a\n3D-aware latent diffusion model. First, we introduce a 3D-aware autoencoder to\nencode face images into 3D latent embeddings. Second, we propose a novel\nrepresentation diffusion model (RDM) to disentangle 3D latent into facial\nidentity and expression. Consequently, our method achieves state-of-the-art\nperformance in facial expression recognition and face verification among\nunsupervised facial representation learning models. Codes are available at\n\\url{https://github.com/ryanhe312/LatentFace}.\n","authors":["Ruian He","Zhen Xing","Weimin Tan","Bo Yan"],"pdf_url":"https://arxiv.org/pdf/2309.08273v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13110v2","updated":"2023-11-24T09:18:44Z","published":"2023-11-22T02:23:32Z","title":"White-Box Transformers via Sparse Rate Reduction: Compression Is All\n  There Is?","summary":"  In this paper, we contend that a natural objective of representation learning\nis to compress and transform the distribution of the data, say sets of tokens,\ntowards a low-dimensional Gaussian mixture supported on incoherent subspaces.\nThe goodness of such a representation can be evaluated by a principled measure,\ncalled sparse rate reduction, that simultaneously maximizes the intrinsic\ninformation gain and extrinsic sparsity of the learned representation. From\nthis perspective, popular deep network architectures, including transformers,\ncan be viewed as realizing iterative schemes to optimize this measure.\nParticularly, we derive a transformer block from alternating optimization on\nparts of this objective: the multi-head self-attention operator compresses the\nrepresentation by implementing an approximate gradient descent step on the\ncoding rate of the features, and the subsequent multi-layer perceptron\nsparsifies the features. This leads to a family of white-box transformer-like\ndeep network architectures, named CRATE, which are mathematically fully\ninterpretable. We show, by way of a novel connection between denoising and\ncompression, that the inverse to the aforementioned compressive encoding can be\nrealized by the same class of CRATE architectures. Thus, the so-derived\nwhite-box architectures are universal to both encoders and decoders.\nExperiments show that these networks, despite their simplicity, indeed learn to\ncompress and sparsify representations of large-scale real-world image and text\ndatasets, and achieve performance very close to highly engineered\ntransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the\nproposed computational framework demonstrates great potential in bridging the\ngap between theory and practice of deep learning, from a unified perspective of\ndata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .\n","authors":["Yaodong Yu","Sam Buchanan","Druv Pai","Tianzhe Chu","Ziyang Wu","Shengbang Tong","Hao Bai","Yuexiang Zhai","Benjamin D. Haeffele","Yi Ma"],"pdf_url":"https://arxiv.org/pdf/2311.13110v2.pdf","comment":"This paper integrates the works arXiv:2306.01129 and arXiv:2308.16271\n  into a complete story. In this paper, we improve the writing and\n  organization, and also add conceptual, empirical, and theoretical\n  improvements over the previous work. V2: small typo fixes and formatting\n  improvements"},{"id":"http://arxiv.org/abs/2311.14671v1","updated":"2023-11-24T18:59:42Z","published":"2023-11-24T18:59:42Z","title":"SEGIC: Unleashing the Emergent Correspondence for In-Context\n  Segmentation","summary":"  In-context segmentation aims at segmenting novel images using a few labeled\nexample images, termed as \"in-context examples\", exploring content similarities\nbetween examples and the target. The resulting models can be generalized\nseamlessly to novel segmentation tasks, significantly reducing the labeling and\ntraining costs compared with conventional pipelines. However, in-context\nsegmentation is more challenging than classic ones due to its meta-learning\nnature, requiring the model to learn segmentation rules conditioned on a few\nsamples, not just the segmentation. Unlike previous work with ad-hoc or\nnon-end-to-end designs, we propose SEGIC, an end-to-end segment-in-context\nframework built upon a single vision foundation model (VFM). In particular,\nSEGIC leverages the emergent correspondence within VFM to capture dense\nrelationships between target images and in-context samples. As such,\ninformation from in-context samples is then extracted into three types of\ninstructions, i.e. geometric, visual, and meta instructions, serving as\nexplicit conditions for the final mask prediction. SEGIC is a straightforward\nyet effective approach that yields state-of-the-art performance on one-shot\nsegmentation benchmarks. Notably, SEGIC can be easily generalized to diverse\ntasks, including video object segmentation and open-vocabulary segmentation.\nCode will be available at \\url{https://github.com/MengLcool/SEGIC}.\n","authors":["Lingchen Meng","Shiyi Lan","Hengduo Li","Jose M. Alvarez","Zuxuan Wu","Yu-Gang Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.14671v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14665v1","updated":"2023-11-24T18:55:53Z","published":"2023-11-24T18:55:53Z","title":"Understanding Self-Supervised Features for Learning Unsupervised\n  Instance Segmentation","summary":"  Self-supervised learning (SSL) can be used to solve complex visual tasks\nwithout human labels. Self-supervised representations encode useful semantic\ninformation about images, and as a result, they have already been used for\ntasks such as unsupervised semantic segmentation. In this paper, we investigate\nself-supervised representations for instance segmentation without any manual\nannotations. We find that the features of different SSL methods vary in their\nlevel of instance-awareness. In particular, DINO features, which are known to\nbe excellent semantic descriptors, lack behind MAE features in their\nsensitivity for separating instances.\n","authors":["Paul Engstler","Luke Melas-Kyriazi","Christian Rupprecht","Iro Laina"],"pdf_url":"https://arxiv.org/pdf/2311.14665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11744v3","updated":"2023-11-24T18:53:31Z","published":"2022-11-21T18:59:33Z","title":"Visual Dexterity: In-Hand Reorientation of Novel and Complex Object\n  Shapes","summary":"  In-hand object reorientation is necessary for performing many dexterous\nmanipulation tasks, such as tool use in less structured environments that\nremain beyond the reach of current robots. Prior works built reorientation\nsystems assuming one or many of the following: reorienting only specific\nobjects with simple shapes, limited range of reorientation, slow or quasistatic\nmanipulation, simulation-only results, the need for specialized and costly\nsensor suites, and other constraints which make the system infeasible for\nreal-world deployment. We present a general object reorientation controller\nthat does not make these assumptions. It uses readings from a single commodity\ndepth camera to dynamically reorient complex and new object shapes by any\nrotation in real-time, with the median reorientation time being close to seven\nseconds. The controller is trained using reinforcement learning in simulation\nand evaluated in the real world on new object shapes not used for training,\nincluding the most challenging scenario of reorienting objects held in the air\nby a downward-facing hand that must counteract gravity during reorientation.\nOur hardware platform only uses open-source components that cost less than five\nthousand dollars. Although we demonstrate the ability to overcome assumptions\nin prior work, there is ample scope for improving absolute performance. For\ninstance, the challenging duck-shaped object not used for training was dropped\nin 56 percent of the trials. When it was not dropped, our controller reoriented\nthe object within 0.4 radians (23 degrees) 75 percent of the time. Videos are\navailable at: https://taochenshh.github.io/projects/visual-dexterity.\n","authors":["Tao Chen","Megha Tippur","Siyang Wu","Vikash Kumar","Edward Adelson","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2211.11744v3.pdf","comment":"Published in Science Robotics:\n  https://www.science.org/doi/10.1126/scirobotics.adc9244"},{"id":"http://arxiv.org/abs/2311.14656v1","updated":"2023-11-24T18:46:02Z","published":"2023-11-24T18:46:02Z","title":"Charting New Territories: Exploring the Geographic and Geospatial\n  Capabilities of Multimodal LLMs","summary":"  Multimodal large language models (MLLMs) have shown remarkable capabilities\nacross a broad range of tasks but their knowledge and abilities in the\ngeographic and geospatial domains are yet to be explored, despite potential\nwide-ranging benefits to navigation, environmental research, urban development,\nand disaster response. We conduct a series of experiments exploring various\nvision capabilities of MLLMs within these domains, particularly focusing on the\nfrontier model GPT-4V, and benchmark its performance against open-source\ncounterparts. Our methodology involves challenging these models with a\nsmall-scale geographic benchmark consisting of a suite of visual tasks, testing\ntheir abilities across a spectrum of complexity. The analysis uncovers not only\nwhere such models excel, including instances where they outperform humans, but\nalso where they falter, providing a balanced view of their capabilities in the\ngeographic domain. To enable the comparison and evaluation of future models,\nour benchmark will be publicly released.\n","authors":["Jonathan Roberts","Timo Lüddecke","Rehan Sheikh","Kai Han","Samuel Albanie"],"pdf_url":"https://arxiv.org/pdf/2311.14656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.05303v3","updated":"2023-11-24T18:43:54Z","published":"2023-08-10T02:47:36Z","title":"Multi-Visual-Inertial System: Analysis, Calibration and Estimation","summary":"  In this paper, we study state estimation of multi-visual-inertial systems\n(MVIS) and develop sensor fusion algorithms to optimally fuse an arbitrary\nnumber of asynchronous inertial measurement units (IMUs) or gyroscopes and\nglobal and(or) rolling shutter cameras. We are especially interested in the\nfull calibration of the associated visual-inertial sensors, including the IMU\nor camera intrinsics and the IMU-IMU(or camera) spatiotemporal extrinsics as\nwell as the image readout time of rolling-shutter cameras (if used). To this\nend, we develop a new analytic combined IMU integration with intrinsics-termed\nACI3-to preintegrate IMU measurements, which is leveraged to fuse auxiliary\nIMUs and(or) gyroscopes alongside a base IMU. We model the multi-inertial\nmeasurements to include all the necessary inertial intrinsic and IMU-IMU\nspatiotemporal extrinsic parameters, while leveraging IMU-IMU rigid-body\nconstraints to eliminate the necessity of auxiliary inertial poses and thus\nreducing computational complexity. By performing observability analysis of\nMVIS, we prove that the standard four unobservable directions remain - no\nmatter how many inertial sensors are used, and also identify, for the first\ntime, degenerate motions for IMU-IMU spatiotemporal extrinsics and auxiliary\ninertial intrinsics. In addition to the extensive simulations that validate our\nanalysis and algorithms, we have built our own MVIS sensor rig and collected\nover 25 real-world datasets to experimentally verify the proposed calibration\nagainst the state-of-the-art calibration method such as Kalibr. We show that\nthe proposed MVIS calibration is able to achieve competing accuracy with\nimproved convergence and repeatability, which is open sourced to better benefit\nthe community.\n","authors":["Yulin Yang","Patrick Geneva","Guoquan Huang"],"pdf_url":"https://arxiv.org/pdf/2308.05303v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17455v3","updated":"2023-11-24T18:39:02Z","published":"2023-05-27T12:07:21Z","title":"CrossGET: Cross-Guided Ensemble of Tokens for Accelerating\n  Vision-Language Transformers","summary":"  Recent vision-language models have achieved tremendous progress far beyond\nwhat we ever expected. However, their computational costs are also dramatically\ngrowing with rapid development, especially for the large models. It makes model\nacceleration exceedingly critical in a scenario of limited resources. Although\nextensively studied for unimodal models, the acceleration for multimodal\nmodels, especially the vision-language Transformers, is relatively\nunder-explored. To pursue more efficient and accessible vision-language\nTransformers, this paper introduces \\textbf{Cross}-\\textbf{G}uided\n\\textbf{E}nsemble of \\textbf{T}okens (\\textbf{\\emph{CrossGET}}), a universal\nacceleration framework for vision-language Transformers. This framework\nadaptively combines tokens through real-time, cross-modal guidance, thereby\nachieving substantial acceleration while keeping high performance.\n\\textit{CrossGET} has two key innovations: 1) \\textit{Cross-Guided Matching and\nEnsemble}. \\textit{CrossGET} incorporates cross-modal guided token matching and\nensemble to exploit cross-modal information effectively, only introducing\ncross-modal tokens with negligible extra parameters. 2) \\textit{Complete-Graph\nSoft Matching}. In contrast to the existing bipartite soft matching approach,\n\\textit{CrossGET} introduces a complete-graph soft matching policy to achieve\nmore reliable token-matching results while maintaining parallelizability and\nhigh efficiency. Extensive experiments are conducted on various vision-language\ntasks, including image-text retrieval, visual reasoning, image captioning, and\nvisual question answering. Performance on both classic multimodal architectures\nand emerging multimodal LLMs demonstrate the effectiveness and versatility of\nthe proposed \\textit{CrossGET} framework. The code will be at\n\\url{https://github.com/sdc17/CrossGET}.\n","authors":["Dachuan Shi","Chaofan Tao","Anyi Rao","Zhendong Yang","Chun Yuan","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2305.17455v3.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2311.14642v1","updated":"2023-11-24T18:16:28Z","published":"2023-11-24T18:16:28Z","title":"Continuous football player tracking from discrete broadcast data","summary":"  Player tracking data remains out of reach for many professional football\nteams as their video feeds are not sufficiently high quality for computer\nvision technologies to be used. To help bridge this gap, we present a method\nthat can estimate continuous full-pitch tracking data from discrete data made\nfrom broadcast footage. Such data could be collected by clubs or players at a\nsimilar cost to event data, which is widely available down to semi-professional\nlevel. We test our method using open-source tracking data, and include a\nversion that can be applied to a large set of over 200 games with such discrete\ndata.\n","authors":["Matthew J. Penn","Christl A. Donnelly","Samir Bhatt"],"pdf_url":"https://arxiv.org/pdf/2311.14642v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.14639v1","updated":"2023-11-24T18:12:06Z","published":"2023-11-24T18:12:06Z","title":"Unsupervised high-throughput segmentation of cells and cell nuclei in\n  quantitative phase images","summary":"  In the effort to aid cytologic diagnostics by establishing automatic single\ncell screening using high throughput digital holographic microscopy for\nclinical studies thousands of images and millions of cells are captured. The\nbottleneck lies in an automatic, fast, and unsupervised segmentation technique\nthat does not limit the types of cells which might occur. We propose an\nunsupervised multistage method that segments correctly without confusing noise\nor reflections with cells and without missing cells that also includes the\ndetection of relevant inner structures, especially the cell nucleus in the\nunstained cell. In an effort to make the information reasonable and\ninterpretable for cytopathologists, we also introduce new cytoplasmic and\nnuclear features of potential help for cytologic diagnoses which exploit the\nquantitative phase information inherent to the measurement scheme. We show that\nthe segmentation provides consistently good results over many experiments on\npatient samples in a reasonable per cell analysis time.\n","authors":["Julia Sistermanns","Ellen Emken","Gregor Weirich","Oliver Hayden","Wolfgang Utschick"],"pdf_url":"https://arxiv.org/pdf/2311.14639v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2311.14635v1","updated":"2023-11-24T18:08:42Z","published":"2023-11-24T18:08:42Z","title":"Automated Detection and Counting of Windows using UAV Imagery based\n  Remote Sensing","summary":"  Despite the technological advancements in the construction and surveying\nsector, the inspection of salient features like windows in an\nunder-construction or existing building is predominantly a manual process.\nMoreover, the number of windows present in a building is directly related to\nthe magnitude of deformation it suffers under earthquakes. In this research, a\nmethod to accurately detect and count the number of windows of a building by\ndeploying an Unmanned Aerial Vehicle (UAV) based remote sensing system is\nproposed. The proposed two-stage method automates the identification and\ncounting of windows by developing computer vision pipelines that utilize data\nfrom UAV's onboard camera and other sensors. Quantitative and Qualitative\nresults show the effectiveness of our proposed approach in accurately detecting\nand counting the windows compared to the existing method.\n","authors":["Dhruv Patel","Shivani Chepuri","Sarvesh Thakur","K. Harikumar","Ravi Kiran S.","K. Madhava Krishna"],"pdf_url":"https://arxiv.org/pdf/2311.14635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14633v1","updated":"2023-11-24T18:02:14Z","published":"2023-11-24T18:02:14Z","title":"One Strike, You're Out: Detecting Markush Structures in Low\n  Signal-to-Noise Ratio Images","summary":"  Modern research increasingly relies on automated methods to assist\nresearchers. An example of this is Optical Chemical Structure Recognition\n(OCSR), which aids chemists in retrieving information about chemicals from\nlarge amounts of documents. Markush structures are chemical structures that\ncannot be parsed correctly by OCSR and cause errors. The focus of this research\nwas to propose and test a novel method for classifying Markush structures.\nWithin this method, a comparison was made between fixed-feature extraction and\nend-to-end learning (CNN). The end-to-end method performed significantly better\nthan the fixed-feature method, achieving 0.928 (0.035 SD) Macro F1 compared to\nthe fixed-feature method's 0.701 (0.052 SD). Because of the nature of the\nexperiment, these figures are a lower bound and can be improved further. These\nresults suggest that Markush structures can be filtered out effectively and\naccurately using the proposed method. When implemented into OCSR pipelines,\nthis method can improve their performance and use to other researchers.\n","authors":["Thomas Jurriaans","Kinga Szarkowska","Eric Nalisnick","Markus Schwoerer","Camilo Thorne","Saber Akhondi"],"pdf_url":"https://arxiv.org/pdf/2311.14633v1.pdf","comment":"15 pages, 9 tables, 16 figures"},{"id":"http://arxiv.org/abs/2311.14631v1","updated":"2023-11-24T17:55:10Z","published":"2023-11-24T17:55:10Z","title":"CatVersion: Concatenating Embeddings for Diffusion-Based Text-to-Image\n  Personalization","summary":"  We propose CatVersion, an inversion-based method that learns the personalized\nconcept through a handful of examples. Subsequently, users can utilize text\nprompts to generate images that embody the personalized concept, thereby\nachieving text-to-image personalization. In contrast to existing approaches\nthat emphasize word embedding learning or parameter fine-tuning for the\ndiffusion model, which potentially causes concept dilution or overfitting, our\nmethod concatenates embeddings on the feature-dense space of the text encoder\nin the diffusion model to learn the gap between the personalized concept and\nits base class, aiming to maximize the preservation of prior knowledge in\ndiffusion models while restoring the personalized concepts. To this end, we\nfirst dissect the text encoder's integration in the image generation process to\nidentify the feature-dense space of the encoder. Afterward, we concatenate\nembeddings on the Keys and Values in this space to learn the gap between the\npersonalized concept and its base class. In this way, the concatenated\nembeddings ultimately manifest as a residual on the original attention output.\nTo more accurately and unbiasedly quantify the results of personalized image\ngeneration, we improve the CLIP image alignment score based on masks.\nQualitatively and quantitatively, CatVersion helps to restore personalization\nconcepts more faithfully and enables more robust editing.\n","authors":["Ruoyu Zhao","Mingrui Zhu","Shiyin Dong","Nannan Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2311.14631v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2311.14625v1","updated":"2023-11-24T17:40:31Z","published":"2023-11-24T17:40:31Z","title":"ARIA: On the interaction between Architectures, Aggregation methods and\n  Initializations in federated visual classification","summary":"  Federated Learning (FL) is a collaborative training paradigm that allows for\nprivacy-preserving learning of cross-institutional models by eliminating the\nexchange of sensitive data and instead relying on the exchange of model\nparameters between the clients and a server. Despite individual studies on how\nclient models are aggregated, and, more recently, on the benefits of ImageNet\npre-training, there is a lack of understanding of the effect the architecture\nchosen for the federation has, and of how the aforementioned elements\ninterconnect. To this end, we conduct the first joint\nARchitecture-Initialization-Aggregation study and benchmark ARIAs across a\nrange of medical image classification tasks. We find that, contrary to current\npractices, ARIA elements have to be chosen together to achieve the best\npossible performance. Our results also shed light on good choices for each\nelement depending on the task, the effect of normalisation layers, and the\nutility of SSL pre-training, pointing to potential directions for designing\nFL-specific architectures and training pipelines.\n","authors":["Vasilis Siomos","Sergio Naval-Marimont","Jonathan Passerat-Palmbach","Giacomo Tarroni"],"pdf_url":"https://arxiv.org/pdf/2311.14625v1.pdf","comment":"Under review at the 21st IEEE International Symposium on Biomedical\n  Imaging"},{"id":"http://arxiv.org/abs/2311.14617v1","updated":"2023-11-24T17:25:12Z","published":"2023-11-24T17:25:12Z","title":"Neural Style Transfer for Computer Games","summary":"  Neural Style Transfer (NST) research has been applied to images, videos, 3D\nmeshes and radiance fields, but its application to 3D computer games remains\nrelatively unexplored. Whilst image and video NST systems can be used as a\npost-processing effect for a computer game, this results in undesired artefacts\nand diminished post-processing effects. Here, we present an approach for\ninjecting depth-aware NST as part of the 3D rendering pipeline. Qualitative and\nquantitative experiments are used to validate our in-game stylisation\nframework. We demonstrate temporally consistent results of artistically\nstylised game scenes, outperforming state-of-the-art image and video NST\nmethods.\n","authors":["Eleftherios Ioannou","Steve Maddock"],"pdf_url":"https://arxiv.org/pdf/2311.14617v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.14603v1","updated":"2023-11-24T16:47:05Z","published":"2023-11-24T16:47:05Z","title":"Animate124: Animating One Image to 4D Dynamic Scene","summary":"  We introduce Animate124 (Animate-one-image-to-4D), the first work to animate\na single in-the-wild image into 3D video through textual motion descriptions,\nan underexplored problem with significant applications. Our 4D generation\nleverages an advanced 4D grid dynamic Neural Radiance Field (NeRF) model,\noptimized in three distinct stages using multiple diffusion priors. Initially,\na static model is optimized using the reference image, guided by 2D and 3D\ndiffusion priors, which serves as the initialization for the dynamic NeRF.\nSubsequently, a video diffusion model is employed to learn the motion specific\nto the subject. However, the object in the 3D videos tends to drift away from\nthe reference image over time. This drift is mainly due to the misalignment\nbetween the text prompt and the reference image in the video diffusion model.\nIn the final stage, a personalized diffusion prior is therefore utilized to\naddress the semantic drift. As the pioneering image-text-to-4D generation\nframework, our method demonstrates significant advancements over existing\nbaselines, evidenced by comprehensive quantitative and qualitative assessments.\n","authors":["Yuyang Zhao","Zhiwen Yan","Enze Xie","Lanqing Hong","Zhenguo Li","Gim Hee Lee"],"pdf_url":"https://arxiv.org/pdf/2311.14603v1.pdf","comment":"Project Page: https://animate124.github.io"},{"id":"http://arxiv.org/abs/2203.04838v5","updated":"2023-11-24T16:29:19Z","published":"2022-03-09T16:12:08Z","title":"CMX: Cross-Modal Fusion for RGB-X Semantic Segmentation with\n  Transformers","summary":"  Scene understanding based on image segmentation is a crucial component of\nautonomous vehicles. Pixel-wise semantic segmentation of RGB images can be\nadvanced by exploiting complementary features from the supplementary modality\n(X-modality). However, covering a wide variety of sensors with a\nmodality-agnostic model remains an unresolved problem due to variations in\nsensor characteristics among different modalities. Unlike previous\nmodality-specific methods, in this work, we propose a unified fusion framework,\nCMX, for RGB-X semantic segmentation. To generalize well across different\nmodalities, that often include supplements as well as uncertainties, a unified\ncross-modal interaction is crucial for modality fusion. Specifically, we design\na Cross-Modal Feature Rectification Module (CM-FRM) to calibrate bi-modal\nfeatures by leveraging the features from one modality to rectify the features\nof the other modality. With rectified feature pairs, we deploy a Feature Fusion\nModule (FFM) to perform sufficient exchange of long-range contexts before\nmixing. To verify CMX, for the first time, we unify five modalities\ncomplementary to RGB, i.e., depth, thermal, polarization, event, and LiDAR.\nExtensive experiments show that CMX generalizes well to diverse multi-modal\nfusion, achieving state-of-the-art performances on five RGB-Depth benchmarks,\nas well as RGB-Thermal, RGB-Polarization, and RGB-LiDAR datasets. Besides, to\ninvestigate the generalizability to dense-sparse data fusion, we establish an\nRGB-Event semantic segmentation benchmark based on the EventScape dataset, on\nwhich CMX sets the new state-of-the-art. The source code of CMX is publicly\navailable at https://github.com/huaaaliu/RGBX_Semantic_Segmentation.\n","authors":["Jiaming Zhang","Huayao Liu","Kailun Yang","Xinxin Hu","Ruiping Liu","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2203.04838v5.pdf","comment":"Accepted to IEEE Transactions on Intelligent Transportation Systems\n  (T-ITS). The source code of CMX is publicly available at\n  https://github.com/huaaaliu/RGBX_Semantic_Segmentation"},{"id":"http://arxiv.org/abs/2304.00933v2","updated":"2023-11-24T16:24:33Z","published":"2023-04-03T12:45:52Z","title":"Knowledge Accumulation in Continually Learned Representations and the\n  Issue of Feature Forgetting","summary":"  While it is established that neural networks suffer from catastrophic\nforgetting ``at the output level'', it is debated whether this is also the case\nat the level of representations. Some studies ascribe a certain level of innate\nrobustness to representations, that they only forget minimally and no critical\ninformation, while others claim that representations are also severely affected\nby forgetting. To settle this debate, we first discuss how this apparent\ndisagreement might stem from the coexistence of two phenomena that affect the\nquality of continually learned representations: knowledge accumulation and\nfeature forgetting. We then show that, even though it is true that feature\nforgetting can be small in absolute terms, newly learned information is\nforgotten just as catastrophically at the level of representations as it is at\nthe output level. Next we show that this feature forgetting is problematic as\nit substantially slows down knowledge accumulation. We further show that\nrepresentations that are continually learned through both supervised and\nself-supervised learning suffer from feature forgetting. Finally, we study how\nfeature forgetting and knowledge accumulation are affected by different types\nof continual learning methods.\n","authors":["Timm Hess","Eli Verwimp","Gido M. van de Ven","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2304.00933v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06607v2","updated":"2023-11-24T16:21:39Z","published":"2023-11-11T16:37:41Z","title":"Monkey: Image Resolution and Text Label Are Important Things for Large\n  Multi-modal Models","summary":"  Large Multimodal Models (LMMs) have shown promise in vision-language tasks\nbut struggle with high-resolution input and detailed scene understanding.\nAddressing these challenges, we introduce Monkey to enhance LMM capabilities.\nFirstly, Monkey processes input images by dividing them into uniform patches,\neach matching the size (e.g., 448x448) used in the original training of the\nwell-trained vision encoder. Equipped with individual adapter for each patch,\nMonkey can handle higher resolutions up to 1344x896 pixels, enabling the\ndetailed capture of complex visual information. Secondly, it employs a\nmulti-level description generation method, enriching the context for\nscene-object associations. This two-part strategy ensures more effective\nlearning from generated data: the higher resolution allows for a more detailed\ncapture of visuals, which in turn enhances the effectiveness of comprehensive\ndescriptions. Extensive ablative results validate the effectiveness of our\ndesigns. Additionally, experiments on 18 datasets further demonstrate that\nMonkey surpasses existing LMMs in many tasks like Image Captioning and various\nVisual Question Answering formats. Specially, in qualitative tests focused on\ndense text question answering, Monkey has exhibited encouraging results\ncompared with GPT4V. Code is available at\nhttps://github.com/Yuliang-Liu/Monkey.\n","authors":["Zhang Li","Biao Yang","Qiang Liu","Zhiyin Ma","Shuo Zhang","Jingxu Yang","Yabo Sun","Yuliang Liu","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2311.06607v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14580v1","updated":"2023-11-24T16:12:05Z","published":"2023-11-24T16:12:05Z","title":"Large Language Models as Automated Aligners for benchmarking\n  Vision-Language Models","summary":"  With the advancements in Large Language Models (LLMs), Vision-Language Models\n(VLMs) have reached a new level of sophistication, showing notable competence\nin executing intricate cognition and reasoning tasks. However, existing\nevaluation benchmarks, primarily relying on rigid, hand-crafted datasets to\nmeasure task-specific performance, face significant limitations in assessing\nthe alignment of these increasingly anthropomorphic models with human\nintelligence. In this work, we address the limitations via Auto-Bench, which\ndelves into exploring LLMs as proficient aligners, measuring the alignment\nbetween VLMs and human intelligence and value through automatic data curation\nand assessment. Specifically, for data curation, Auto-Bench utilizes LLMs\n(e.g., GPT-4) to automatically generate a vast set of question-answer-reasoning\ntriplets via prompting on visual symbolic representations (e.g., captions,\nobject locations, instance relationships, and etc.). The curated data closely\nmatches human intent, owing to the extensive world knowledge embedded in LLMs.\nThrough this pipeline, a total of 28.5K human-verified and 3,504K unfiltered\nquestion-answer-reasoning triplets have been curated, covering 4 primary\nabilities and 16 sub-abilities. We subsequently engage LLMs like GPT-3.5 to\nserve as judges, implementing the quantitative and qualitative automated\nassessments to facilitate a comprehensive evaluation of VLMs. Our validation\nresults reveal that LLMs are proficient in both evaluation data curation and\nmodel assessment, achieving an average agreement rate of 85%. We envision\nAuto-Bench as a flexible, scalable, and comprehensive benchmark for evaluating\nthe evolving sophisticated VLMs.\n","authors":["Yuanfeng Ji","Chongjian Ge","Weikai Kong","Enze Xie","Zhengying Liu","Zhengguo Li","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2311.14580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06031v3","updated":"2023-11-24T15:37:06Z","published":"2023-11-10T12:38:16Z","title":"Diagonal Hierarchical Consistency Learning for Semi-supervised Medical\n  Image Segmentation","summary":"  Medical image segmentation, which is essential for many clinical\napplications, has achieved almost human-level performance via data-driven deep\nlearning technologies. Nevertheless, its performance is predicated upon the\ncostly process of manually annotating a vast amount of medical images. To this\nend, we propose a novel framework for robust semi-supervised medical image\nsegmentation using diagonal hierarchical consistency learning (DiHC-Net).\nFirst, it is composed of multiple sub-models with identical multi-scale\narchitecture but with distinct sub-layers, such as up-sampling and\nnormalisation layers. Second, with mutual consistency, a novel consistency\nregularisation is enforced between one model's intermediate and final\nprediction and soft pseudo labels from other models in a diagonal hierarchical\nfashion. A series of experiments verifies the efficacy of our simple framework,\noutperforming all previous approaches on public Left Atrium (LA) dataset.\n","authors":["Heejoon Koo"],"pdf_url":"https://arxiv.org/pdf/2311.06031v3.pdf","comment":"5 pages, 2 figures, and 2 tables"},{"id":"http://arxiv.org/abs/2311.14552v1","updated":"2023-11-24T15:35:07Z","published":"2023-11-24T15:35:07Z","title":"Griffon: Spelling out All Object Locations at Any Granularity with Large\n  Language Models","summary":"  Replicating the innate human ability to detect all objects based on free-form\ntexts at any granularity remains a formidable challenge for Vision-Language\nmodels. Current Large Vision Language Models (LVLMs) are predominantly\nconstrained to grounding a single, pre-existing object, relying solely on data\nfrom Referring Expression Comprehension tasks. The limitation leads to a\ncompromise in model design, necessitating the introduction of visual expert\nmodels or the integration of customized head structures. Beyond these\nconstraints, our research delves into the untapped potential of LVLMs and\nuncover their inherent capability for basic object perception, allowing them to\naccurately identify and locate objects of interest. Building on this insight,\nwe introduce a novel language-prompted localization dataset designed to fully\nunleash the capabilities of LVLMs in integrating fine-grained object perception\nwith precise location awareness. More importantly, we present\n$\\textbf{Griffon}$, a purely LVLM-based baseline, which does not require the\nintroduction of any special tokens, expert models, or additional detection\nmodules. It simply maintains a consistent structure with popular LVLMs by\nunifying data formats across various localization-related scenarios and is\ntrained end-to-end through a well-designed pipeline. Comprehensive experiments\ndemonstrate that $\\textbf{Griffon}$ not only achieves state-of-the-art\nperformance on the fine-grained RefCOCO series but also approaches the\ncapabilities of the expert model Faster RCNN on the detection benchmark MSCOCO.\n","authors":["Yufei Zhan","Yousong Zhu","Zhiyang Chen","Fan Yang","Ming Tang","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.14552v1.pdf","comment":"Technical report. The codes and dataset will be released soon"},{"id":"http://arxiv.org/abs/2310.09600v2","updated":"2023-11-24T15:29:08Z","published":"2023-10-14T15:20:33Z","title":"Hawkeye: A PyTorch-based Library for Fine-Grained Image Recognition with\n  Deep Learning","summary":"  Fine-Grained Image Recognition (FGIR) is a fundamental and challenging task\nin computer vision and multimedia that plays a crucial role in Intellectual\nEconomy and Industrial Internet applications. However, the absence of a unified\nopen-source software library covering various paradigms in FGIR poses a\nsignificant challenge for researchers and practitioners in the field. To\naddress this gap, we present Hawkeye, a PyTorch-based library for FGIR with\ndeep learning. Hawkeye is designed with a modular architecture, emphasizing\nhigh-quality code and human-readable configuration, providing a comprehensive\nsolution for FGIR tasks. In Hawkeye, we have implemented 16 state-of-the-art\nfine-grained methods, covering 6 different paradigms, enabling users to explore\nvarious approaches for FGIR. To the best of our knowledge, Hawkeye represents\nthe first open-source PyTorch-based library dedicated to FGIR. It is publicly\navailable at https://github.com/Hawkeye-FineGrained/Hawkeye/, providing\nresearchers and practitioners with a powerful tool to advance their research\nand development in the field of FGIR.\n","authors":["Jiabei He","Yang Shen","Xiu-Shen Wei","Ye Wu"],"pdf_url":"https://arxiv.org/pdf/2310.09600v2.pdf","comment":"ACM Multimedia 2023 Open Source Software Competition Winner Entry.\n  X.-S. Wei is the corresponding author"},{"id":"http://arxiv.org/abs/2302.14460v3","updated":"2023-11-24T15:25:26Z","published":"2023-02-28T10:08:11Z","title":"Interpretable and intervenable ultrasonography-based machine learning\n  models for pediatric appendicitis","summary":"  Appendicitis is among the most frequent reasons for pediatric abdominal\nsurgeries. Previous decision support systems for appendicitis have focused on\nclinical, laboratory, scoring, and computed tomography data and have ignored\nabdominal ultrasound, despite its noninvasive nature and widespread\navailability. In this work, we present interpretable machine learning models\nfor predicting the diagnosis, management and severity of suspected appendicitis\nusing ultrasound images. Our approach utilizes concept bottleneck models (CBM)\nthat facilitate interpretation and interaction with high-level concepts\nunderstandable to clinicians. Furthermore, we extend CBMs to prediction\nproblems with multiple views and incomplete concept sets. Our models were\ntrained on a dataset comprising 579 pediatric patients with 1709 ultrasound\nimages accompanied by clinical and laboratory data. Results show that our\nproposed method enables clinicians to utilize a human-understandable and\nintervenable predictive model without compromising performance or requiring\ntime-consuming image annotation when deployed. For predicting the diagnosis,\nthe extended multiview CBM attained an AUROC of 0.80 and an AUPR of 0.92,\nperforming comparably to similar black-box neural networks trained and tested\non the same dataset.\n","authors":["Ričards Marcinkevičs","Patricia Reis Wolfertstetter","Ugne Klimiene","Kieran Chin-Cheong","Alyssia Paschke","Julia Zerres","Markus Denzinger","David Niederberger","Sven Wellmann","Ece Ozkan","Christian Knorr","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2302.14460v3.pdf","comment":"Published in Medical Image Analysis (Elsevier)"},{"id":"http://arxiv.org/abs/2311.14544v1","updated":"2023-11-24T15:23:47Z","published":"2023-11-24T15:23:47Z","title":"Inferring Latent Class Statistics from Text for Robust Visual Few-Shot\n  Learning","summary":"  In the realm of few-shot learning, foundation models like CLIP have proven\neffective but exhibit limitations in cross-domain robustness especially in\nfew-shot settings. Recent works add text as an extra modality to enhance the\nperformance of these models. Most of these approaches treat text as an\nauxiliary modality without fully exploring its potential to elucidate the\nunderlying class visual features distribution. In this paper, we present a\nnovel approach that leverages text-derived statistics to predict the mean and\ncovariance of the visual feature distribution for each class. This predictive\nframework enriches the latent space, yielding more robust and generalizable\nfew-shot learning models. We demonstrate the efficacy of incorporating both\nmean and covariance statistics in improving few-shot classification performance\nacross various datasets. Our method shows that we can use text to predict the\nmean and covariance of the distribution offering promising improvements in\nfew-shot learning scenarios.\n","authors":["Yassir Bendou","Vincent Gripon","Bastien Pasdeloup","Giulia Lioi","Lukas Mauch","Fabien Cardinaux","Ghouthi Boukli Hacene"],"pdf_url":"https://arxiv.org/pdf/2311.14544v1.pdf","comment":"R0-FoMo: Workshop on Robustness of Few-shot and Zero-shot Learning in\n  Foundation Models at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.14542v1","updated":"2023-11-24T15:20:01Z","published":"2023-11-24T15:20:01Z","title":"ToddlerDiffusion: Flash Interpretable Controllable Diffusion Model","summary":"  Diffusion-based generative models excel in perceptually impressive synthesis\nbut face challenges in interpretability. This paper introduces\nToddlerDiffusion, an interpretable 2D diffusion image-synthesis framework\ninspired by the human generation system. Unlike traditional diffusion models\nwith opaque denoising steps, our approach decomposes the generation process\ninto simpler, interpretable stages; generating contours, a palette, and a\ndetailed colored image. This not only enhances overall performance but also\nenables robust editing and interaction capabilities. Each stage is meticulously\nformulated for efficiency and accuracy, surpassing Stable-Diffusion (LDM).\nExtensive experiments on datasets like LSUN-Churches and COCO validate our\napproach, consistently outperforming existing methods. ToddlerDiffusion\nachieves notable efficiency, matching LDM performance on LSUN-Churches while\noperating three times faster with a 3.76 times smaller architecture. Our source\ncode is provided in the supplementary material and will be publicly accessible.\n","authors":["Eslam Mohamed Bakr","Liangbing Zhao","Vincent Tao Hu","Matthieu Cord","Patrick Perez","Mohamed Elhoseiny"],"pdf_url":"https://arxiv.org/pdf/2311.14542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14521v1","updated":"2023-11-24T14:46:59Z","published":"2023-11-24T14:46:59Z","title":"GaussianEditor: Swift and Controllable 3D Editing with Gaussian\n  Splatting","summary":"  3D editing plays a crucial role in many areas such as gaming and virtual\nreality. Traditional 3D editing methods, which rely on representations like\nmeshes and point clouds, often fall short in realistically depicting complex\nscenes. On the other hand, methods based on implicit 3D representations, like\nNeural Radiance Field (NeRF), render complex scenes effectively but suffer from\nslow processing speeds and limited control over specific scene areas. In\nresponse to these challenges, our paper presents GaussianEditor, an innovative\nand efficient 3D editing algorithm based on Gaussian Splatting (GS), a novel 3D\nrepresentation. GaussianEditor enhances precision and control in editing\nthrough our proposed Gaussian semantic tracing, which traces the editing target\nthroughout the training process. Additionally, we propose Hierarchical Gaussian\nsplatting (HGS) to achieve stabilized and fine results under stochastic\ngenerative guidance from 2D diffusion models. We also develop editing\nstrategies for efficient object removal and integration, a challenging task for\nexisting methods. Our comprehensive experiments demonstrate GaussianEditor's\nsuperior control, efficacy, and rapid performance, marking a significant\nadvancement in 3D editing. Project Page:\nhttps://buaacyw.github.io/gaussian-editor/\n","authors":["Yiwen Chen","Zilong Chen","Chi Zhang","Feng Wang","Xiaofeng Yang","Yikai Wang","Zhongang Cai","Lei Yang","Huaping Liu","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2311.14521v1.pdf","comment":"Project Page: https://buaacyw.github.io/gaussian-editor/"},{"id":"http://arxiv.org/abs/2311.14506v1","updated":"2023-11-24T14:26:07Z","published":"2023-11-24T14:26:07Z","title":"Multi-Class Anomaly Detection based on Regularized Discriminative\n  Coupled hypersphere-based Feature Adaptation","summary":"  In anomaly detection, identification of anomalies across diverse product\ncategories is a complex task. This paper introduces a new model by including\nclass discriminative properties obtained by a modified Regularized\nDiscriminative Variational Auto-Encoder (RD-VAE) in the feature extraction\nprocess of Coupled-hypersphere-based Feature Adaptation (CFA). By doing so, the\nproposed Regularized Discriminative Coupled-hypersphere-based Feature\nAdaptation (RD-CFA), forms a solution for multi-class anomaly detection. By\nusing the discriminative power of RD-VAE to capture intricate class\ndistributions, combined with CFA's robust anomaly detection capability, the\nproposed method excels in discerning anomalies across various classes.\nExtensive evaluations on multi-class anomaly detection and localization using\nthe MVTec AD and BeanTech AD datasets showcase the effectiveness of RD-CFA\ncompared to eight leading contemporary methods.\n","authors":["Mehdi Rafiei","Alexandros Iosifidis"],"pdf_url":"https://arxiv.org/pdf/2311.14506v1.pdf","comment":"14 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2311.14494v1","updated":"2023-11-24T14:07:53Z","published":"2023-11-24T14:07:53Z","title":"MVControl: Adding Conditional Control to Multi-view Diffusion for\n  Controllable Text-to-3D Generation","summary":"  We introduce MVControl, a novel neural network architecture that enhances\nexisting pre-trained multi-view 2D diffusion models by incorporating additional\ninput conditions, e.g. edge maps. Our approach enables the generation of\ncontrollable multi-view images and view-consistent 3D content. To achieve\ncontrollable multi-view image generation, we leverage MVDream as our base\nmodel, and train a new neural network module as additional plugin for\nend-to-end task-specific condition learning. To precisely control the shapes\nand views of generated images, we innovatively propose a new conditioning\nmechanism that predicts an embedding encapsulating the input spatial and view\nconditions, which is then injected to the network globally. Once MVControl is\ntrained, score-distillation (SDS) loss based optimization can be performed to\ngenerate 3D content, in which process we propose to use a hybrid diffusion\nprior. The hybrid prior relies on a pre-trained Stable-Diffusion network and\nour trained MVControl for additional guidance. Extensive experiments\ndemonstrate that our method achieves robust generalization and enables the\ncontrollable generation of high-quality 3D content.\n","authors":["Zhiqi Li","Yiming Chen","Lingzhe Zhao","Peidong Liu"],"pdf_url":"https://arxiv.org/pdf/2311.14494v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14485v1","updated":"2023-11-24T13:48:37Z","published":"2023-11-24T13:48:37Z","title":"Towards Interpretable Classification of Leukocytes based on Deep\n  Learning","summary":"  Label-free approaches are attractive in cytological imaging due to their\nflexibility and cost efficiency. They are supported by machine learning\nmethods, which, despite the lack of labeling and the associated lower contrast,\ncan classify cells with high accuracy where the human observer has little\nchance to discriminate cells. In order to better integrate these workflows into\nthe clinical decision making process, this work investigates the calibration of\nconfidence estimation for the automated classification of leukocytes. In\naddition, different visual explanation approaches are compared, which should\nbring machine decision making closer to professional healthcare applications.\nFurthermore, we were able to identify general detection patterns in neural\nnetworks and demonstrate the utility of the presented approaches in different\nscenarios of blood cell analysis.\n","authors":["Stefan Röhrl","Johannes Groll","Manuel Lengl","Simon Schumann","Christian Klenk","Dominik Heim","Martin Knopp","Oliver Hayden","Klaus Diepold"],"pdf_url":"https://arxiv.org/pdf/2311.14485v1.pdf","comment":"Presented at the 3rd Workshop on Interpretable Machine Learning in\n  Healthcare (IMLH) @ ICML 2023"},{"id":"http://arxiv.org/abs/2311.14482v1","updated":"2023-11-24T13:45:58Z","published":"2023-11-24T13:45:58Z","title":"Sliding Window FastEdit: A Framework for Lesion Annotation in Whole-body\n  PET Images","summary":"  Deep learning has revolutionized the accurate segmentation of diseases in\nmedical imaging. However, achieving such results requires training with\nnumerous manual voxel annotations. This requirement presents a challenge for\nwhole-body Positron Emission Tomography (PET) imaging, where lesions are\nscattered throughout the body. To tackle this problem, we introduce SW-FastEdit\n- an interactive segmentation framework that accelerates the labeling by\nutilizing only a few user clicks instead of voxelwise annotations. While prior\ninteractive models crop or resize PET volumes due to memory constraints, we use\nthe complete volume with our sliding window-based interactive scheme. Our model\noutperforms existing non-sliding window interactive models on the AutoPET\ndataset and generalizes to the previously unseen HECKTOR dataset. A user study\nrevealed that annotators achieve high-quality predictions with only 10 click\niterations and a low perceived NASA-TLX workload. Our framework is implemented\nusing MONAI Label and is available:\nhttps://github.com/matt3o/AutoPET2-Submission/\n","authors":["Matthias Hadlich","Zdravko Marinov","Moon Kim","Enrico Nasca","Jens Kleesiek","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2311.14482v1.pdf","comment":"5 pages, 2 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.14473v1","updated":"2023-11-24T13:26:53Z","published":"2023-11-24T13:26:53Z","title":"Joint Diffusion: Mutual Consistency-Driven Diffusion Model for PET-MRI\n  Co-Reconstruction","summary":"  Positron Emission Tomography and Magnetic Resonance Imaging (PET-MRI) systems\ncan obtain functional and anatomical scans. PET suffers from a low\nsignal-to-noise ratio. Meanwhile, the k-space data acquisition process in MRI\nis time-consuming. The study aims to accelerate MRI and enhance PET image\nquality. Conventional approaches involve the separate reconstruction of each\nmodality within PET-MRI systems. However, there exists complementary\ninformation among multi-modal images. The complementary information can\ncontribute to image reconstruction. In this study, we propose a novel PET-MRI\njoint reconstruction model employing a mutual consistency-driven diffusion\nmode, namely MC-Diffusion. MC-Diffusion learns the joint probability\ndistribution of PET and MRI for utilizing complementary information. We\nconducted a series of contrast experiments about LPLS, Joint ISAT-net and\nMC-Diffusion by the ADNI dataset. The results underscore the qualitative and\nquantitative improvements achieved by MC-Diffusion, surpassing the\nstate-of-the-art method.\n","authors":["Taofeng Xie","Zhuo-Xu Cui","Chen Luo","Huayu Wang","Congcong Liu","Yuanzhi Zhang","Xuemei Wang","Yanjie Zhu","Qiyu Jin","Guoqing Chen","Yihang Zhou","Dong Liang","Haifeng Wang"],"pdf_url":"https://arxiv.org/pdf/2311.14473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14471v1","updated":"2023-11-24T13:25:29Z","published":"2023-11-24T13:25:29Z","title":"MRxaI: Black-Box Explainability for Image Classifiers in a Medical\n  Setting","summary":"  Existing tools for explaining the output of image classifiers can be divided\ninto white-box, which rely on access to the model internals, and black-box,\nagnostic to the model. As the usage of AI in the medical domain grows, so too\ndoes the usage of explainability tools. Existing work on medical image\nexplanations focuses on white-box tools, such as gradcam. However, there are\nclear advantages to switching to a black-box tool, including the ability to use\nit with any classifier and the wide selection of black-box tools available. On\nstandard images, black-box tools are as precise as white-box. In this paper we\ncompare the performance of several black-box methods against gradcam on a brain\ncancer MRI dataset. We demonstrate that most black-box tools are not suitable\nfor explaining medical image classifications and present a detailed analysis of\nthe reasons for their shortcomings. We also show that one black-box tool, a\ncausal explainability-based rex, performs as well as \\gradcam.\n","authors":["Nathan Blake","Hana Chockler","David A. Kelly","Santiago Calderon Pena","Akchunya Chanchal"],"pdf_url":"https://arxiv.org/pdf/2311.14471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14462v1","updated":"2023-11-24T13:14:10Z","published":"2023-11-24T13:14:10Z","title":"CT-xCOV: a CT-scan based Explainable Framework for COVid-19 diagnosis","summary":"  In this work, CT-xCOV, an explainable framework for COVID-19 diagnosis using\nDeep Learning (DL) on CT-scans is developed. CT-xCOV adopts an end-to-end\napproach from lung segmentation to COVID-19 detection and explanations of the\ndetection model's prediction. For lung segmentation, we used the well-known\nU-Net model. For COVID-19 detection, we compared three different CNN\narchitectures: a standard CNN, ResNet50, and DenseNet121. After the detection,\nvisual and textual explanations are provided. For visual explanations, we\napplied three different XAI techniques, namely, Grad-Cam, Integrated Gradient\n(IG), and LIME. Textual explanations are added by computing the percentage of\ninfection by lungs. To assess the performance of the used XAI techniques, we\npropose a ground-truth-based evaluation method, measuring the similarity\nbetween the visualization outputs and the ground-truth infections. The\nperformed experiments show that the applied DL models achieved good results.\nThe U-Net segmentation model achieved a high Dice coefficient (98%). The\nperformance of our proposed classification model (standard CNN) was validated\nusing 5-fold cross-validation (acc of 98.40% and f1-score 98.23%). Lastly, the\nresults of the comparison of XAI techniques show that Grad-Cam gives the best\nexplanations compared to LIME and IG, by achieving a Dice coefficient of 55%,\non COVID-19 positive scans, compared to 29% and 24% obtained by IG and LIME\nrespectively. The code and the dataset used in this paper are available in the\nGitHub repository [1].\n","authors":["Ismail Elbouknify","Afaf Bouhoute","Khalid Fardousse","Ismail Berrada","Abdelmajid Badri"],"pdf_url":"https://arxiv.org/pdf/2311.14462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14459v1","updated":"2023-11-24T13:11:36Z","published":"2023-11-24T13:11:36Z","title":"IDD-AW: A Benchmark for Safe and Robust Segmentation of Drive Scenes in\n  Unstructured Traffic and Adverse Weather","summary":"  Large-scale deployment of fully autonomous vehicles requires a very high\ndegree of robustness to unstructured traffic, and weather conditions, and\nshould prevent unsafe mispredictions. While there are several datasets and\nbenchmarks focusing on segmentation for drive scenes, they are not specifically\nfocused on safety and robustness issues. We introduce the IDD-AW dataset, which\nprovides 5000 pairs of high-quality images with pixel-level annotations,\ncaptured under rain, fog, low light, and snow in unstructured driving\nconditions. As compared to other adverse weather datasets, we provide i.) more\nannotated images, ii.) paired Near-Infrared (NIR) image for each frame, iii.)\nlarger label set with a 4-level label hierarchy to capture unstructured traffic\nconditions. We benchmark state-of-the-art models for semantic segmentation in\nIDD-AW. We also propose a new metric called ''Safe mean Intersection over Union\n(Safe mIoU)'' for hierarchical datasets which penalizes dangerous\nmispredictions that are not captured in the traditional definition of mean\nIntersection over Union (mIoU). The results show that IDD-AW is one of the most\nchallenging datasets to date for these tasks. The dataset and code will be\navailable here: http://iddaw.github.io.\n","authors":["Furqan Ahmed Shaik","Abhishek Malreddy","Nikhil Reddy Billa","Kunal Chaudhary","Sunny Manchanda","Girish Varma"],"pdf_url":"https://arxiv.org/pdf/2311.14459v1.pdf","comment":"8 pages excluding references. Accepted in WACV 2024"},{"id":"http://arxiv.org/abs/2310.19653v2","updated":"2023-11-24T13:02:55Z","published":"2023-10-30T15:38:39Z","title":"Upgrading VAE Training With Unlimited Data Plans Provided by Diffusion\n  Models","summary":"  Variational autoencoders (VAEs) are popular models for representation\nlearning but their encoders are susceptible to overfitting (Cremer et al.,\n2018) because they are trained on a finite training set instead of the true\n(continuous) data distribution $p_{\\mathrm{data}}(\\mathbf{x})$. Diffusion\nmodels, on the other hand, avoid this issue by keeping the encoder fixed. This\nmakes their representations less interpretable, but it simplifies training,\nenabling accurate and continuous approximations of\n$p_{\\mathrm{data}}(\\mathbf{x})$. In this paper, we show that overfitting\nencoders in VAEs can be effectively mitigated by training on samples from a\npre-trained diffusion model. These results are somewhat unexpected as recent\nfindings (Alemohammad et al., 2023; Shumailov et al., 2023) observe a decay in\ngenerative performance when models are trained on data generated by another\ngenerative model. We analyze generalization performance, amortization gap, and\nrobustness of VAEs trained with our proposed method on three different data\nsets. We find improvements in all metrics compared to both normal training and\nconventional data augmentation methods, and we show that a modest amount of\nsamples from the diffusion model suffices to obtain these gains.\n","authors":["Tim Z. Xiao","Johannes Zenn","Robert Bamler"],"pdf_url":"https://arxiv.org/pdf/2310.19653v2.pdf","comment":"9 pages + appendix"},{"id":"http://arxiv.org/abs/2211.04927v2","updated":"2023-11-24T12:59:12Z","published":"2022-11-09T14:57:27Z","title":"DeepDC: Deep Distance Correlation as a Perceptual Image Quality\n  Evaluator","summary":"  ImageNet pre-trained deep neural networks (DNNs) show notable transferability\nfor building effective image quality assessment (IQA) models. Such a remarkable\nbyproduct has often been identified as an emergent property in previous\nstudies. In this work, we attribute such capability to the intrinsic\ntexture-sensitive characteristic that classifies images using texture features.\nWe fully exploit this characteristic to develop a novel full-reference IQA\n(FR-IQA) model based exclusively on pre-trained DNN features. Specifically, we\ncompute the distance correlation, a highly promising yet relatively\nunder-investigated statistic, between reference and distorted images in the\ndeep feature domain. In addition, the distance correlation quantifies both\nlinear and nonlinear feature relationships, which is far beyond the widely used\nfirst-order and second-order statistics in the feature space. We conduct\ncomprehensive experiments to demonstrate the superiority of the proposed\nquality model on five standard IQA datasets, one perceptual similarity dataset,\ntwo texture similarity datasets, and one geometric transformation dataset.\nMoreover, we optimize the proposed model to generate a broad spectrum of\ntexture patterns, by treating the model as the style loss function for neural\nstyle transfer (NST). Extensive experiments demonstrate that the proposed\ntexture synthesis and NST methods achieve the best quantitative and qualitative\nresults. We release our code at https://github.com/h4nwei/DeepDC.\n","authors":["Hanwei Zhu","Baoliang Chen","Lingyu Zhu","Shiqi Wang","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2211.04927v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14450v1","updated":"2023-11-24T12:57:34Z","published":"2023-11-24T12:57:34Z","title":"Segment (Almost) Nothing: Prompt-Agnostic Adversarial Attacks on\n  Segmentation Models","summary":"  General purpose segmentation models are able to generate (semantic)\nsegmentation masks from a variety of prompts, including visual (points, boxed,\netc.) and textual (object names) ones. In particular, input images are\npre-processed by an image encoder to obtain embedding vectors which are later\nused for mask predictions. Existing adversarial attacks target the end-to-end\ntasks, i.e. aim at altering the segmentation mask predicted for a specific\nimage-prompt pair. However, this requires running an individual attack for each\nnew prompt for the same image. We propose instead to generate prompt-agnostic\nadversarial attacks by maximizing the $\\ell_2$-distance, in the latent space,\nbetween the embedding of the original and perturbed images. Since the encoding\nprocess only depends on the image, distorted image representations will cause\nperturbations in the segmentation masks for a variety of prompts. We show that\neven imperceptible $\\ell_\\infty$-bounded perturbations of radius\n$\\epsilon=1/255$ are often sufficient to drastically modify the masks predicted\nwith point, box and text prompts by recently proposed foundation models for\nsegmentation. Moreover, we explore the possibility of creating universal, i.e.\nnon image-specific, attacks which can be readily applied to any input without\nfurther computational cost.\n","authors":["Francesco Croce","Matthias Hein"],"pdf_url":"https://arxiv.org/pdf/2311.14450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14435v1","updated":"2023-11-24T12:22:00Z","published":"2023-11-24T12:22:00Z","title":"GCPV: Guided Concept Projection Vectors for the Explainable Inspection\n  of CNN Feature Spaces","summary":"  For debugging and verification of computer vision convolutional deep neural\nnetworks (CNNs) human inspection of the learned latent representations is\nimperative. Therefore, state-of-the-art eXplainable Artificial Intelligence\n(XAI) methods globally associate given natural language semantic concepts with\nrepresenting vectors or regions in the CNN latent space supporting manual\ninspection. Yet, this approach comes with two major disadvantages: They are\nlocally inaccurate when reconstructing a concept label and discard information\nabout the distribution of concept instance representations. The latter, though,\nis of particular interest for debugging, like finding and understanding\noutliers, learned notions of sub-concepts, and concept confusion. Furthermore,\ncurrent single-layer approaches neglect that information about a concept may be\nspread over the CNN depth. To overcome these shortcomings, we introduce the\nlocal-to-global Guided Concept Projection Vectors (GCPV) approach: It (1)\ngenerates local concept vectors that each precisely reconstruct a concept\nsegmentation label, and then (2) generalizes these to global concept and even\nsub-concept vectors by means of hiearchical clustering. Our experiments on\nobject detectors demonstrate improved performance compared to the\nstate-of-the-art, the benefit of multi-layer concept vectors, and robustness\nagainst low-quality concept segmentation labels. Finally, we demonstrate that\nGCPVs can be applied to find root causes for confusion of concepts like bus and\ntruck, and reveal interesting concept-level outliers. Thus, GCPVs pose a\npromising step towards interpretable model debugging and informed data\nimprovement.\n","authors":["Georgii Mikriukov","Gesina Schwalbe","Christian Hellert","Korinna Bade"],"pdf_url":"https://arxiv.org/pdf/2311.14435v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09178v3","updated":"2023-11-24T11:47:25Z","published":"2023-11-15T18:15:30Z","title":"RBPGAN: Recurrent Back-Projection GAN for Video Super Resolution","summary":"  Recently, video super resolution (VSR) has become a very impactful task in\nthe area of Computer Vision due to its various applications. In this paper, we\npropose Recurrent Back-Projection Generative Adversarial Network (RBPGAN) for\nVSR in an attempt to generate temporally coherent solutions while preserving\nspatial details. RBPGAN integrates two state-of-the-art models to get the best\nin both worlds without compromising the accuracy of produced video. The\ngenerator of the model is inspired by RBPN system, while the discriminator is\ninspired by TecoGAN. We also utilize Ping-Pong loss to increase temporal\nconsistency over time. Our contribution together results in a model that\noutperforms earlier work in terms of temporally consistent details, as we will\ndemonstrate qualitatively and quantitatively using different datasets.\n","authors":["Marwah Sulaiman","Zahraa Shehabeldin","Israa Fahmy","Mohammed Barakat","Mohammed El-Naggar","Dareen Hussein","Moustafa Youssef","Hesham Eraqi"],"pdf_url":"https://arxiv.org/pdf/2311.09178v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.08745v2","updated":"2023-11-24T11:18:10Z","published":"2023-09-15T20:16:17Z","title":"Improved Breast Cancer Diagnosis through Transfer Learning on\n  Hematoxylin and Eosin Stained Histology Images","summary":"  Breast cancer is one of the leading causes of death for women worldwide.\nEarly screening is essential for early identification, but the chance of\nsurvival declines as the cancer progresses into advanced stages. For this\nstudy, the most recent BRACS dataset of histological (H\\&E) stained images was\nused to classify breast cancer tumours, which contains both the whole-slide\nimages (WSI) and region-of-interest (ROI) images, however, for our study we\nhave considered ROI images. We have experimented using different pre-trained\ndeep learning models, such as Xception, EfficientNet, ResNet50, and\nInceptionResNet, pre-trained on the ImageNet weights. We pre-processed the\nBRACS ROI along with image augmentation, upsampling, and dataset split\nstrategies. For the default dataset split, the best results were obtained by\nResNet50 achieving 66% f1-score. For the custom dataset split, the best results\nwere obtained by performing upsampling and image augmentation which results in\n96.2% f1-score. Our second approach also reduced the number of false positive\nand false negative classifications to less than 3% for each class. We believe\nthat our study significantly impacts the early diagnosis and identification of\nbreast cancer tumors and their subtypes, especially atypical and malignant\ntumors, thus improving patient outcomes and reducing patient mortality rates.\nOverall, this study has primarily focused on identifying seven (7) breast\ncancer tumor subtypes, and we believe that the experimental models can be\nfine-tuned further to generalize over previous breast cancer histology datasets\nas well.\n","authors":["Fahad Ahmed","Reem Abdel-Salam","Leon Hamnett","Mary Adewunmi","Temitope Ayano"],"pdf_url":"https://arxiv.org/pdf/2309.08745v2.pdf","comment":"12 pages, 4 figures, 6 tables"},{"id":"http://arxiv.org/abs/2311.14414v1","updated":"2023-11-24T11:14:39Z","published":"2023-11-24T11:14:39Z","title":"Deformable multi-modal image registration for the correlation between\n  optical measurements and histology images","summary":"  The correlation of optical measurements with a correct pathology label is\noften hampered by imprecise registration caused by deformations in histology\nimages. This study explores an automated multi-modal image registration\ntechnique utilizing deep learning principles to align snapshot breast specimen\nimages with corresponding histology images. The input images, acquired through\ndifferent modalities, present challenges due to variations in intensities and\nstructural visibility, making linear assumptions inappropriate. An unsupervised\nand supervised learning approach, based on the VoxelMorph model, was explored,\nmaking use of a dataset with manually registered images used as ground truth.\nEvaluation metrics, including Dice scores and mutual information, reveal that\nthe unsupervised model outperforms the supervised (and manual approach)\nsignificantly, achieving superior image alignment. This automated registration\napproach holds promise for improving the validation of optical technologies by\nminimizing human errors and inconsistencies associated with manual\nregistration.\n","authors":["Lianne Feenstra","Maud Lambregts","Theo J. M Ruers","Behdad Dashtbozorg"],"pdf_url":"https://arxiv.org/pdf/2311.14414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14405v1","updated":"2023-11-24T10:56:27Z","published":"2023-11-24T10:56:27Z","title":"OneFormer3D: One Transformer for Unified Point Cloud Segmentation","summary":"  Semantic, instance, and panoptic segmentation of 3D point clouds have been\naddressed using task-specific models of distinct design. Thereby, the\nsimilarity of all segmentation tasks and the implicit relationship between them\nhave not been utilized effectively. This paper presents a unified, simple, and\neffective model addressing all these tasks jointly. The model, named\nOneFormer3D, performs instance and semantic segmentation consistently, using a\ngroup of learnable kernels, where each kernel is responsible for generating a\nmask for either an instance or a semantic category. These kernels are trained\nwith a transformer-based decoder with unified instance and semantic queries\npassed as an input. Such a design enables training a model end-to-end in a\nsingle run, so that it achieves top performance on all three segmentation tasks\nsimultaneously. Specifically, our OneFormer3D ranks 1st and sets a new\nstate-of-the-art (+2.1 mAP50) in the ScanNet test leaderboard. We also\ndemonstrate the state-of-the-art results in semantic, instance, and panoptic\nsegmentation of ScanNet (+21 PQ), ScanNet200 (+3.8 mAP50), and S3DIS (+0.8\nmIoU) datasets.\n","authors":["Maxim Kolodiazhnyi","Anna Vorontsova","Anton Konushin","Danila Rukhovich"],"pdf_url":"https://arxiv.org/pdf/2311.14405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14395v1","updated":"2023-11-24T10:23:57Z","published":"2023-11-24T10:23:57Z","title":"Multi-scale Semantic Correlation Mining for Visible-Infrared Person\n  Re-Identification","summary":"  The main challenge in the Visible-Infrared Person Re-Identification (VI-ReID)\ntask lies in how to extract discriminative features from different modalities\nfor matching purposes. While the existing well works primarily focus on\nminimizing the modal discrepancies, the modality information can not thoroughly\nbe leveraged. To solve this problem, a Multi-scale Semantic Correlation Mining\nnetwork (MSCMNet) is proposed to comprehensively exploit semantic features at\nmultiple scales and simultaneously reduce modality information loss as small as\npossible in feature extraction. The proposed network contains three novel\ncomponents. Firstly, after taking into account the effective utilization of\nmodality information, the Multi-scale Information Correlation Mining Block\n(MIMB) is designed to explore semantic correlations across multiple scales.\nSecondly, in order to enrich the semantic information that MIMB can utilize, a\nquadruple-stream feature extractor (QFE) with non-shared parameters is\nspecifically designed to extract information from different dimensions of the\ndataset. Finally, the Quadruple Center Triplet Loss (QCT) is further proposed\nto address the information discrepancy in the comprehensive features. Extensive\nexperiments on the SYSU-MM01, RegDB, and LLCM datasets demonstrate that the\nproposed MSCMNet achieves the greatest accuracy.\n","authors":["Ke Cheng","Xuecheng Hua","Hu Lu","Juanjuan Tu","Yuanquan Wang","Shitong Wang"],"pdf_url":"https://arxiv.org/pdf/2311.14395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14388v1","updated":"2023-11-24T10:07:14Z","published":"2023-11-24T10:07:14Z","title":"A Parameterized Generative Adversarial Network Using Cyclic Projection\n  for Explainable Medical Image Classification","summary":"  Although current data augmentation methods are successful to alleviate the\ndata insufficiency, conventional augmentation are primarily intra-domain while\nadvanced generative adversarial networks (GANs) generate images remaining\nuncertain, particularly in small-scale datasets. In this paper, we propose a\nparameterized GAN (ParaGAN) that effectively controls the changes of synthetic\nsamples among domains and highlights the attention regions for downstream\nclassification. Specifically, ParaGAN incorporates projection distance\nparameters in cyclic projection and projects the source images to the decision\nboundary to obtain the class-difference maps. Our experiments show that ParaGAN\ncan consistently outperform the existing augmentation methods with explainable\nclassification on two small-scale medical datasets.\n","authors":["Xiangyu Xiong","Yue Sun","Xiaohong Liu","ChanTong Lam","Tong Tong","Hao Chen","Qinquan Gao","Wei Ke","Tao Tan"],"pdf_url":"https://arxiv.org/pdf/2311.14388v1.pdf","comment":"5 pages, 4 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2310.17294v2","updated":"2023-11-24T09:47:06Z","published":"2023-10-26T10:18:51Z","title":"Scale-Adaptive Feature Aggregation for Efficient Space-Time Video\n  Super-Resolution","summary":"  The Space-Time Video Super-Resolution (STVSR) task aims to enhance the visual\nquality of videos, by simultaneously performing video frame interpolation (VFI)\nand video super-resolution (VSR). However, facing the challenge of the\nadditional temporal dimension and scale inconsistency, most existing STVSR\nmethods are complex and inflexible in dynamically modeling different motion\namplitudes. In this work, we find that choosing an appropriate processing scale\nachieves remarkable benefits in flow-based feature propagation. We propose a\nnovel Scale-Adaptive Feature Aggregation (SAFA) network that adaptively selects\nsub-networks with different processing scales for individual samples.\nExperiments on four public STVSR benchmarks demonstrate that SAFA achieves\nstate-of-the-art performance. Our SAFA network outperforms recent\nstate-of-the-art methods such as TMNet and VideoINR by an average improvement\nof over 0.5dB on PSNR, while requiring less than half the number of parameters\nand only 1/3 computational costs.\n","authors":["Zhewei Huang","Ailin Huang","Xiaotao Hu","Chen Hu","Jun Xu","Shuchang Zhou"],"pdf_url":"https://arxiv.org/pdf/2310.17294v2.pdf","comment":"WACV2024, 16 pages"},{"id":"http://arxiv.org/abs/2207.01072v2","updated":"2023-11-24T09:42:45Z","published":"2022-07-03T16:06:04Z","title":"Dynamic Sub-Cluster-Aware Network for Few-Shot Skin Disease\n  Classification","summary":"  This paper addresses the problem of few-shot skin disease classification by\nintroducing a novel approach called the Sub-Cluster-Aware Network (SCAN) that\nenhances accuracy in diagnosing rare skin diseases. The key insight motivating\nthe design of SCAN is the observation that skin disease images within a class\noften exhibit multiple sub-clusters, characterized by distinct variations in\nappearance. To improve the performance of few-shot learning, we focus on\nlearning a high-quality feature encoder that captures the unique sub-clustered\nrepresentations within each disease class, enabling better characterization of\nfeature distributions. Specifically, SCAN follows a dual-branch framework,\nwhere the first branch learns class-wise features to distinguish different skin\ndiseases, and the second branch aims to learn features which can effectively\npartition each class into several groups so as to preserve the sub-clustered\nstructure within each class. To achieve the objective of the second branch, we\npresent a cluster loss to learn image similarities via unsupervised clustering.\nTo ensure that the samples in each sub-cluster are from the same class, we\nfurther design a purity loss to refine the unsupervised clustering results. We\nevaluate the proposed approach on two public datasets for few-shot skin disease\nclassification. The experimental results validate that our framework\noutperforms the state-of-the-art methods by around 2% to 5% in terms of\nsensitivity, specificity, accuracy, and F1-score on the SD-198 and Derm7pt\ndatasets.\n","authors":["Shuhan LI","Xiaomeng Li","Xiaowei Xu","Kwang-Ting Cheng"],"pdf_url":"https://arxiv.org/pdf/2207.01072v2.pdf","comment":"Accepted by TNNLS 2023"},{"id":"http://arxiv.org/abs/2311.12401v2","updated":"2023-11-24T08:51:13Z","published":"2023-11-21T07:28:51Z","title":"CASR: Refining Action Segmentation via Magrinalizing Frame-levle Causal\n  Relationships","summary":"  Integrating deep learning and causal discovery has increased the\ninterpretability of Temporal Action Segmentation (TAS) tasks. However,\nframe-level causal relationships exist many complicated noises outside the\nsegment-level, making it infeasible to directly express macro action semantics.\nThus, we propose Causal Abstraction Segmentation Refiner (CASR), which can\nrefine TAS results from various models by enhancing video causality in\nmarginalizing frame-level casual relationships. Specifically, we define the\nequivalent frame-level casual model and segment-level causal model, so that the\ncausal adjacency matrix constructed from marginalized frame-level causal\nrelationships has the ability to represent the segmnet-level causal\nrelationships. CASR works out by reducing the difference in the causal\nadjacency matrix between we constructed and pre-segmentation results of\nbackbone models. In addition, we propose a novel evaluation metric Causal Edit\nDistance (CED) to evaluate the causal interpretability. Extensive experimental\nresults on mainstream datasets indicate that CASR significantly surpasses\nexisting various methods in action segmentation performance, as well as in\ncausal explainability and generalization.\n","authors":["Keqing Du","Xinyu Yang","Hang Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12401v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14343v1","updated":"2023-11-24T08:38:19Z","published":"2023-11-24T08:38:19Z","title":"Highly Detailed and Temporal Consistent Video Stylization via\n  Synchronized Multi-Frame Diffusion","summary":"  Text-guided video-to-video stylization transforms the visual appearance of a\nsource video to a different appearance guided on textual prompts. Existing\ntext-guided image diffusion models can be extended for stylized video\nsynthesis. However, they struggle to generate videos with both highly detailed\nappearance and temporal consistency. In this paper, we propose a synchronized\nmulti-frame diffusion framework to maintain both the visual details and the\ntemporal consistency. Frames are denoised in a synchronous fashion, and more\nimportantly, information of different frames is shared since the beginning of\nthe denoising process. Such information sharing ensures that a consensus, in\nterms of the overall structure and color distribution, among frames can be\nreached in the early stage of the denoising process before it is too late. The\noptical flow from the original video serves as the connection, and hence the\nvenue for information sharing, among frames. We demonstrate the effectiveness\nof our method in generating high-quality and diverse results in extensive\nexperiments. Our method shows superior qualitative and quantitative results\ncompared to state-of-the-art video editing methods.\n","authors":["Minshan Xie","Hanyuan Liu","Chengze Li","Tien-Tsin Wong"],"pdf_url":"https://arxiv.org/pdf/2311.14343v1.pdf","comment":"11 pages, 11 figures"},{"id":"http://arxiv.org/abs/2311.14339v1","updated":"2023-11-24T08:31:34Z","published":"2023-11-24T08:31:34Z","title":"Towards Concept-based Interpretability of Skin Lesion Diagnosis using\n  Vision-Language Models","summary":"  Concept-based models naturally lend themselves to the development of\ninherently interpretable skin lesion diagnosis, as medical experts make\ndecisions based on a set of visual patterns of the lesion. Nevertheless, the\ndevelopment of these models depends on the existence of concept-annotated\ndatasets, whose availability is scarce due to the specialized knowledge and\nexpertise required in the annotation process. In this work, we show that\nvision-language models can be used to alleviate the dependence on a large\nnumber of concept-annotated samples. In particular, we propose an embedding\nlearning strategy to adapt CLIP to the downstream task of skin lesion\nclassification using concept-based descriptions as textual embeddings. Our\nexperiments reveal that vision-language models not only attain better accuracy\nwhen using concepts as textual embeddings, but also require a smaller number of\nconcept-annotated samples to attain comparable performance to approaches\nspecifically devised for automatic concept generation.\n","authors":["Cristiano Patrício","Luís F. Teixeira","João C. Neves"],"pdf_url":"https://arxiv.org/pdf/2311.14339v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2311.14337v1","updated":"2023-11-24T08:24:31Z","published":"2023-11-24T08:24:31Z","title":"TVT: Training-Free Vision Transformer Search on Tiny Datasets","summary":"  Training-free Vision Transformer (ViT) architecture search is presented to\nsearch for a better ViT with zero-cost proxies. While ViTs achieve significant\ndistillation gains from CNN teacher models on small datasets, the current\nzero-cost proxies in ViTs do not generalize well to the distillation training\nparadigm according to our experimental observations. In this paper, for the\nfirst time, we investigate how to search in a training-free manner with the\nhelp of teacher models and devise an effective Training-free ViT (TVT) search\nframework. Firstly, we observe that the similarity of attention maps between\nViT and ConvNet teachers affects distill accuracy notably. Thus, we present a\nteacher-aware metric conditioned on the feature attention relations between\nteacher and student. Additionally, TVT employs the L2-Norm of the student's\nweights as the student-capability metric to improve ranking consistency.\nFinally, TVT searches for the best ViT for distilling with ConvNet teachers via\nour teacher-aware metric and student-capability metric, resulting in impressive\ngains in efficiency and effectiveness. Extensive experiments on various tiny\ndatasets and search spaces show that our TVT outperforms state-of-the-art\ntraining-free search methods. The code will be released.\n","authors":["Zimian Wei","Hengyue Pan","Lujun Li","Peijie Dong","Zhiliang Tian","Xin Niu","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2311.14337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14334v1","updated":"2023-11-24T08:16:10Z","published":"2023-11-24T08:16:10Z","title":"Maximizing Discrimination Capability of Knowledge Distillation with\n  Energy-based Score","summary":"  To apply the latest computer vision techniques that require a large\ncomputational cost in real industrial applications, knowledge distillation\nmethods (KDs) are essential. Existing logit-based KDs apply the constant\ntemperature scaling to all samples in dataset, limiting the utilization of\nknowledge inherent in each sample individually. In our approach, we classify\nthe dataset into two categories (i.e., low energy and high energy samples)\nbased on their energy score. Through experiments, we have confirmed that low\nenergy samples exhibit high confidence scores, indicating certain predictions,\nwhile high energy samples yield low confidence scores, meaning uncertain\npredictions. To distill optimal knowledge by adjusting non-target class\npredictions, we apply a higher temperature to low energy samples to create\nsmoother distributions and a lower temperature to high energy samples to\nachieve sharper distributions. When compared to previous logit-based and\nfeature-based methods, our energy-based KD (Energy KD) achieves better\nperformance on various datasets. Especially, Energy KD shows significant\nimprovements on CIFAR-100-LT and ImageNet datasets, which contain many\nchallenging samples. Furthermore, we propose high energy-based data\naugmentation (HE-DA) for further improving the performance. We demonstrate that\nmeaningful performance improvement could be achieved by augmenting only 20-50%\nof dataset, suggesting that it can be employed on resource-limited devices. To\nthe best of our knowledge, this paper represents the first attempt to make use\nof energy scores in KD and DA, and we believe it will greatly contribute to\nfuture research.\n","authors":["Seonghak Kim","Gyeongdo Ham","Suin Lee","Donggon Jang","Daeshik Kim"],"pdf_url":"https://arxiv.org/pdf/2311.14334v1.pdf","comment":"22 pages, 4 figures. This work has been submitted to the Elsevier for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2212.13766v2","updated":"2023-11-24T08:11:59Z","published":"2022-12-28T10:08:55Z","title":"OVO: One-shot Vision Transformer Search with Online distillation","summary":"  Pure transformers have shown great potential for vision tasks recently.\nHowever, their accuracy in small or medium datasets is not satisfactory.\nAlthough some existing methods introduce a CNN as a teacher to guide the\ntraining process by distillation, the gap between teacher and student networks\nwould lead to sub-optimal performance. In this work, we propose a new One-shot\nVision transformer search framework with Online distillation, namely OVO. OVO\nsamples sub-nets for both teacher and student networks for better distillation\nresults. Benefiting from the online distillation, thousands of subnets in the\nsupernet are well-trained without extra finetuning or retraining. In\nexperiments, OVO-Ti achieves 73.32% top-1 accuracy on ImageNet and 75.2% on\nCIFAR-100, respectively.\n","authors":["Zimian Wei","Hengyue Pan","Xin Niu","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2212.13766v2.pdf","comment":"The work is not implemented"},{"id":"http://arxiv.org/abs/2311.14323v1","updated":"2023-11-24T07:51:50Z","published":"2023-11-24T07:51:50Z","title":"Binarized 3D Whole-body Human Mesh Recovery","summary":"  3D whole-body human mesh recovery aims to reconstruct the 3D human body,\nface, and hands from a single image. Although powerful deep learning models\nhave achieved accurate estimation in this task, they require enormous memory\nand computational resources. Consequently, these methods can hardly be deployed\non resource-limited edge devices. In this work, we propose a Binarized Dual\nResidual Network (BiDRN), a novel quantization method to estimate the 3D human\nbody, face, and hands parameters efficiently. Specifically, we design a basic\nunit Binarized Dual Residual Block (BiDRB) composed of Local Convolution\nResidual (LCR) and Block Residual (BR), which can preserve full-precision\ninformation as much as possible. For LCR, we generalize it to four kinds of\nconvolutional modules so that full-precision information can be propagated even\nbetween mismatched dimensions. We also binarize the face and hands\nbox-prediction network as Binaried BoxNet, which can further reduce the model\nredundancy. Comprehensive quantitative and qualitative experiments demonstrate\nthe effectiveness of BiDRN, which has a significant improvement over\nstate-of-the-art binarization algorithms. Moreover, our proposed BiDRN achieves\ncomparable performance with full-precision method Hand4Whole while using just\n22.1% parameters and 14.8% operations. We will release all the code and\npretrained models.\n","authors":["Zhiteng Li","Yulun Zhang","Jing Lin","Haotong Qin","Jinjin Gu","Xin Yuan","Linghe Kong","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2311.14323v1.pdf","comment":"The code will be available at https://github.com/ZHITENGLI/BiDRN"},{"id":"http://arxiv.org/abs/2309.02301v2","updated":"2023-11-24T07:07:03Z","published":"2023-09-05T15:06:37Z","title":"CIEM: Contrastive Instruction Evaluation Method for Better Instruction\n  Tuning","summary":"  Nowadays, the research on Large Vision-Language Models (LVLMs) has been\nsignificantly promoted thanks to the success of Large Language Models (LLM).\nNevertheless, these Vision-Language Models (VLMs) are suffering from the\ndrawback of hallucination -- due to insufficient understanding of vision and\nlanguage modalities, VLMs may generate incorrect perception information when\ndoing downstream applications, for example, captioning a non-existent entity.\nTo address the hallucination phenomenon, on the one hand, we introduce a\nContrastive Instruction Evaluation Method (CIEM), which is an automatic\npipeline that leverages an annotated image-text dataset coupled with an LLM to\ngenerate factual/contrastive question-answer pairs for the evaluation of the\nhallucination of VLMs. On the other hand, based on CIEM, we further propose a\nnew instruction tuning method called CIT (the abbreviation of Contrastive\nInstruction Tuning) to alleviate the hallucination of VLMs by automatically\nproducing high-quality factual/contrastive question-answer pairs and\ncorresponding justifications for model tuning. Through extensive experiments on\nCIEM and CIT, we pinpoint the hallucination issues commonly present in existing\nVLMs, the disability of the current instruction-tuning dataset to handle the\nhallucination phenomenon and the superiority of CIT-tuned VLMs over both CIEM\nand public datasets.\n","authors":["Hongyu Hu","Jiyuan Zhang","Minyi Zhao","Zhenbang Sun"],"pdf_url":"https://arxiv.org/pdf/2309.02301v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12070v3","updated":"2023-11-24T07:00:54Z","published":"2023-06-21T07:43:23Z","title":"Task-Robust Pre-Training for Worst-Case Downstream Adaptation","summary":"  Pre-training has achieved remarkable success when transferred to downstream\ntasks. In machine learning, we care about not only the good performance of a\nmodel but also its behavior under reasonable shifts of condition. The same\nphilosophy holds when pre-training a foundation model. However, the foundation\nmodel may not uniformly behave well for a series of related downstream tasks.\nThis happens, for example, when conducting mask recovery regression where the\nrecovery ability or the training instances diverge like pattern features are\nextracted dominantly on pre-training, but semantic features are also required\non a downstream task. This paper considers pre-training a model that guarantees\na uniformly good performance over the downstream tasks. We call this goal as\n$\\textit{downstream-task robustness}$. Our method first separates the upstream\ntask into several representative ones and applies a simple minimax loss for\npre-training. We then design an efficient algorithm to solve the minimax loss\nand prove its convergence in the convex setting. In the experiments, we show\nboth on large-scale natural language processing and computer vision datasets\nour method increases the metrics on worse-case downstream tasks. Additionally,\nsome theoretical explanations for why our loss is beneficial are provided.\nSpecifically, we show fewer samples are inherently required for the most\nchallenging downstream task in some cases.\n","authors":["Jianghui Wang","Yang Chen","Xingyu Xie","Cong Fang","Zhouchen Lin"],"pdf_url":"https://arxiv.org/pdf/2306.12070v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14310v1","updated":"2023-11-24T06:43:26Z","published":"2023-11-24T06:43:26Z","title":"Stable Cluster Discrimination for Deep Clustering","summary":"  Deep clustering can optimize representations of instances (i.e.,\nrepresentation learning) and explore the inherent data distribution (i.e.,\nclustering) simultaneously, which demonstrates a superior performance over\nconventional clustering methods with given features. However, the coupled\nobjective implies a trivial solution that all instances collapse to the uniform\nfeatures. To tackle the challenge, a two-stage training strategy is developed\nfor decoupling, where it introduces an additional pre-training stage for\nrepresentation learning and then fine-tunes the obtained model for clustering.\nMeanwhile, one-stage methods are developed mainly for representation learning\nrather than clustering, where various constraints for cluster assignments are\ndesigned to avoid collapsing explicitly. Despite the success of these methods,\nan appropriate learning objective tailored for deep clustering has not been\ninvestigated sufficiently. In this work, we first show that the prevalent\ndiscrimination task in supervised learning is unstable for one-stage clustering\ndue to the lack of ground-truth labels and positive instances for certain\nclusters in each mini-batch. To mitigate the issue, a novel stable cluster\ndiscrimination (SeCu) task is proposed and a new hardness-aware clustering\ncriterion can be obtained accordingly. Moreover, a global entropy constraint\nfor cluster assignments is studied with efficient optimization. Extensive\nexperiments are conducted on benchmark data sets and ImageNet. SeCu achieves\nstate-of-the-art performance on all of them, which demonstrates the\neffectiveness of one-stage deep clustering. Code is available at\n\\url{https://github.com/idstcv/SeCu}.\n","authors":["Qi Qian"],"pdf_url":"https://arxiv.org/pdf/2311.14310v1.pdf","comment":"accepted by ICCV'23"},{"id":"http://arxiv.org/abs/2311.14307v1","updated":"2023-11-24T06:34:47Z","published":"2023-11-24T06:34:47Z","title":"Cosine Similarity Knowledge Distillation for Individual Class\n  Information Transfer","summary":"  Previous logits-based Knowledge Distillation (KD) have utilized predictions\nabout multiple categories within each sample (i.e., class predictions) and have\nemployed Kullback-Leibler (KL) divergence to reduce the discrepancy between the\nstudent and teacher predictions. Despite the proliferation of KD techniques,\nthe student model continues to fall short of achieving a similar level as\nteachers. In response, we introduce a novel and effective KD method capable of\nachieving results on par with or superior to the teacher models performance. We\nutilize teacher and student predictions about multiple samples for each\ncategory (i.e., batch predictions) and apply cosine similarity, a commonly used\ntechnique in Natural Language Processing (NLP) for measuring the resemblance\nbetween text embeddings. This metric's inherent scale-invariance property,\nwhich relies solely on vector direction and not magnitude, allows the student\nto dynamically learn from the teacher's knowledge, rather than being bound by a\nfixed distribution of the teacher's knowledge. Furthermore, we propose a method\ncalled cosine similarity weighted temperature (CSWT) to improve the\nperformance. CSWT reduces the temperature scaling in KD when the cosine\nsimilarity between the student and teacher models is high, and conversely, it\nincreases the temperature scaling when the cosine similarity is low. This\nadjustment optimizes the transfer of information from the teacher to the\nstudent model. Extensive experimental results show that our proposed method\nserves as a viable alternative to existing methods. We anticipate that this\napproach will offer valuable insights for future research on model compression.\n","authors":["Gyeongdo Ham","Seonghak Kim","Suin Lee","Jae-Hyeok Lee","Daeshik Kim"],"pdf_url":"https://arxiv.org/pdf/2311.14307v1.pdf","comment":"13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.14301v1","updated":"2023-11-24T06:22:38Z","published":"2023-11-24T06:22:38Z","title":"GeoViT: A Versatile Vision Transformer Architecture for Geospatial Image\n  Analysis","summary":"  Greenhouse gases are pivotal drivers of climate change, necessitating precise\nquantification and source identification to foster mitigation strategies. We\nintroduce GeoViT, a compact vision transformer model adept in processing\nsatellite imagery for multimodal segmentation, classification, and regression\ntasks targeting CO2 and NO2 emissions. Leveraging GeoViT, we attain superior\naccuracy in estimating power generation rates, fuel type, plume coverage for\nCO2, and high-resolution NO2 concentration mapping, surpassing previous\nstate-of-the-art models while significantly reducing model size. GeoViT\ndemonstrates the efficacy of vision transformer architectures in harnessing\nsatellite-derived data for enhanced GHG emission insights, proving instrumental\nin advancing climate change monitoring and emission regulation efforts\nglobally.\n","authors":["Madhav Khirwar","Ankur Narang"],"pdf_url":"https://arxiv.org/pdf/2311.14301v1.pdf","comment":"Extended Abstract, Preprint"},{"id":"http://arxiv.org/abs/2311.14294v1","updated":"2023-11-24T06:08:27Z","published":"2023-11-24T06:08:27Z","title":"Decouple Content and Motion for Conditional Image-to-Video Generation","summary":"  The goal of conditional image-to-video (cI2V) generation is to create a\nbelievable new video by beginning with the condition, i.e., one image and\ntext.The previous cI2V generation methods conventionally perform in RGB pixel\nspace, with limitations in modeling motion consistency and visual continuity.\nAdditionally, the efficiency of generating videos in pixel space is quite\nlow.In this paper, we propose a novel approach to address these challenges by\ndisentangling the target RGB pixels into two distinct components: spatial\ncontent and temporal motions. Specifically, we predict temporal motions which\ninclude motion vector and residual based on a 3D-UNet diffusion model. By\nexplicitly modeling temporal motions and warping them to the starting image, we\nimprove the temporal consistency of generated videos. This results in a\nreduction of spatial redundancy, emphasizing temporal details. Our proposed\nmethod achieves performance improvements by disentangling content and motion,\nall without introducing new structural complexities to the model. Extensive\nexperiments on various datasets confirm our approach's superior performance\nover the majority of state-of-the-art methods in both effectiveness and\nefficiency.\n","authors":["Cuifeng Shen","Yulu Gan","Chen Chen","Xiongwei Zhu","Lele Cheng","Jinzhi Wang"],"pdf_url":"https://arxiv.org/pdf/2311.14294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14356v2","updated":"2023-11-24T05:55:12Z","published":"2023-10-22T16:51:42Z","title":"Cultural and Linguistic Diversity Improves Visual Representations","summary":"  Computer vision often treats perception as objective, and this assumption\ngets reflected in the way that datasets are collected and models are trained.\nFor instance, image descriptions in different languages are typically assumed\nto be translations of the same semantic content. However, work in\ncross-cultural psychology and linguistics has shown that individuals differ in\ntheir visual perception depending on their cultural background and the language\nthey speak. In this paper, we demonstrate significant differences in semantic\ncontent across languages in both dataset and model-produced captions. When data\nis multilingual as opposed to monolingual, captions have higher semantic\ncoverage on average, as measured by scene graph, embedding, and linguistic\ncomplexity. For example, multilingual captions have on average 21.8% more\nobjects, 24.5% more relations, and 27.1% more attributes than a set of\nmonolingual captions. Moreover, models trained on content from different\nlanguages perform best against test data from those languages, while those\ntrained on multilingual content perform consistently well across all evaluation\ndata compositions. Our research provides implications for how diverse modes of\nperception can improve image understanding.\n","authors":["Andre Ye","Sebastin Santy","Jena D. Hwang","Amy X. Zhang","Ranjay Krishna"],"pdf_url":"https://arxiv.org/pdf/2310.14356v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14284v1","updated":"2023-11-24T05:17:01Z","published":"2023-11-24T05:17:01Z","title":"Paragraph-to-Image Generation with Information-Enriched Diffusion Model","summary":"  Text-to-image (T2I) models have recently experienced rapid development,\nachieving astonishing performance in terms of fidelity and textual alignment\ncapabilities. However, given a long paragraph (up to 512 words), these\ngeneration models still struggle to achieve strong alignment and are unable to\ngenerate images depicting complex scenes. In this paper, we introduce an\ninformation-enriched diffusion model for paragraph-to-image generation task,\ntermed ParaDiffusion, which delves into the transference of the extensive\nsemantic comprehension capabilities of large language models to the task of\nimage generation. At its core is using a large language model (e.g., Llama V2)\nto encode long-form text, followed by fine-tuning with LORA to alignthe\ntext-image feature spaces in the generation task. To facilitate the training of\nlong-text semantic alignment, we also curated a high-quality paragraph-image\npair dataset, namely ParaImage. This dataset contains a small amount of\nhigh-quality, meticulously annotated data, and a large-scale synthetic dataset\nwith long text descriptions being generated using a vision-language model.\nExperiments demonstrate that ParaDiffusion outperforms state-of-the-art models\n(SD XL, DeepFloyd IF) on ViLG-300 and ParaPrompts, achieving up to 15% and 45%\nhuman voting rate improvements for visual appeal and text faithfulness,\nrespectively. The code and dataset will be released to foster community\nresearch on long-text alignment.\n","authors":["Weijia Wu","Zhuang Li","Yefei He","Mike Zheng Shou","Chunhua Shen","Lele Cheng","Yan Li","Tingting Gao","Di Zhang","Zhongyuan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.14284v1.pdf","comment":"The project website is at:\n  https://weijiawu.github.io/ParaDiffusionPage/. Code:\n  https://github.com/weijiawu/ParaDiffusion"},{"id":"http://arxiv.org/abs/2311.14282v1","updated":"2023-11-24T05:11:35Z","published":"2023-11-24T05:11:35Z","title":"Image Super-Resolution with Text Prompt Diffusion","summary":"  Image super-resolution (SR) methods typically model degradation to improve\nreconstruction accuracy in complex and unknown degradation scenarios. However,\nextracting degradation information from low-resolution images is challenging,\nwhich limits the model performance. To boost image SR performance, one feasible\napproach is to introduce additional priors. Inspired by advancements in\nmulti-modal methods and text prompt image processing, we introduce text prompts\nto image SR to provide degradation priors. Specifically, we first design a\ntext-image generation pipeline to integrate text into SR dataset through the\ntext degradation representation and degradation model. The text representation\napplies a discretization manner based on the binning method to describe the\ndegradation abstractly. This representation method can also maintain the\nflexibility of language. Meanwhile, we propose the PromptSR to realize the text\nprompt SR. The PromptSR employs the diffusion model and the pre-trained\nlanguage model (e.g., T5 and CLIP). We train the model on the generated\ntext-image dataset. Extensive experiments indicate that introducing text\nprompts into image SR, yields excellent results on both synthetic and\nreal-world images. Code: https://github.com/zhengchen1999/PromptSR.\n","authors":["Zheng Chen","Yulun Zhang","Jinjin Gu","Xin Yuan","Linghe Kong","Guihai Chen","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2311.14282v1.pdf","comment":"Code is available at https://github.com/zhengchen1999/PromptSR"},{"id":"http://arxiv.org/abs/2311.14281v1","updated":"2023-11-24T05:06:28Z","published":"2023-11-24T05:06:28Z","title":"Multi-modal Instance Refinement for Cross-domain Action Recognition","summary":"  Unsupervised cross-domain action recognition aims at adapting the model\ntrained on an existing labeled source domain to a new unlabeled target domain.\nMost existing methods solve the task by directly aligning the feature\ndistributions of source and target domains. However, this would cause negative\ntransfer during domain adaptation due to some negative training samples in both\ndomains. In the source domain, some training samples are of low-relevance to\ntarget domain due to the difference in viewpoints, action styles, etc. In the\ntarget domain, there are some ambiguous training samples that can be easily\nclassified as another type of action under the case of source domain. The\nproblem of negative transfer has been explored in cross-domain object\ndetection, while it remains under-explored in cross-domain action recognition.\nTherefore, we propose a Multi-modal Instance Refinement (MMIR) method to\nalleviate the negative transfer based on reinforcement learning. Specifically,\na reinforcement learning agent is trained in both domains for every modality to\nrefine the training data by selecting out negative samples from each domain.\nOur method finally outperforms several other state-of-the-art baselines in\ncross-domain action recognition on the benchmark EPIC-Kitchens dataset, which\ndemonstrates the advantage of MMIR in reducing negative transfer.\n","authors":["Yuan Qing","Naixing Wu","Shaohua Wan","Lixin Duan"],"pdf_url":"https://arxiv.org/pdf/2311.14281v1.pdf","comment":"Accepted by PRCV 2023"},{"id":"http://arxiv.org/abs/2311.14280v1","updated":"2023-11-24T04:55:20Z","published":"2023-11-24T04:55:20Z","title":"Latent Diffusion Prior Enhanced Deep Unfolding for Spectral Image\n  Reconstruction","summary":"  Snapshot compressive spectral imaging reconstruction aims to reconstruct\nthree-dimensional spatial-spectral images from a single-shot two-dimensional\ncompressed measurement. Existing state-of-the-art methods are mostly based on\ndeep unfolding structures but have intrinsic performance bottlenecks: $i$) the\nill-posed problem of dealing with heavily degraded measurement, and $ii$) the\nregression loss-based reconstruction models being prone to recover images with\nfew details. In this paper, we introduce a generative model, namely the latent\ndiffusion model (LDM), to generate degradation-free prior to enhance the\nregression-based deep unfolding method. Furthermore, to overcome the large\ncomputational cost challenge in LDM, we propose a lightweight model to generate\nknowledge priors in deep unfolding denoiser, and integrate these priors to\nguide the reconstruction process for compensating high-quality spectral signal\ndetails. Numeric and visual comparisons on synthetic and real-world datasets\nillustrate the superiority of our proposed method in both reconstruction\nquality and computational efficiency. Code will be released.\n","authors":["Zongliang Wu","Ruiying Lu","Ying Fu","Xin Yuan"],"pdf_url":"https://arxiv.org/pdf/2311.14280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14276v1","updated":"2023-11-24T04:40:26Z","published":"2023-11-24T04:40:26Z","title":"Racing With ROS 2 A Navigation System for an Autonomous Formula Student\n  Race Car","summary":"  The advent of autonomous vehicle technologies has significantly impacted\nvarious sectors, including motorsport, where Formula Student and Formula:\nSociety of Automotive Engineers introduced autonomous racing classes. These\noffer new challenges to aspiring engineers, including the team at QUT\nMotorsport, but also raise the entry barrier due to the complexity of\nhigh-speed navigation and control. This paper presents an open-source solution\nusing the Robot Operating System 2, specifically its open-source navigation\nstack, to address these challenges in autonomous Formula Student race cars. We\ncompare off-the-shelf navigation libraries that this stack comprises of against\ntraditional custom-made programs developed by QUT Motorsport to evaluate their\napplicability in autonomous racing scenarios and integrate them onto an\nautonomous race car. Our contributions include quantitative and qualitative\ncomparisons of these packages against traditional navigation solutions, aiming\nto lower the entry barrier for autonomous racing. This paper also serves as a\ncomprehensive tutorial for teams participating in similar racing disciplines\nand other autonomous mobile robot applications.\n","authors":["Alastair Bradford","Grant van Breda","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2311.14276v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.14275v1","updated":"2023-11-24T04:30:31Z","published":"2023-11-24T04:30:31Z","title":"Cooperative Dual Attention for Audio-Visual Speech Enhancement with\n  Facial Cues","summary":"  In this work, we focus on leveraging facial cues beyond the lip region for\nrobust Audio-Visual Speech Enhancement (AVSE). The facial region, encompassing\nthe lip region, reflects additional speech-related attributes such as gender,\nskin color, nationality, etc., which contribute to the effectiveness of AVSE.\nHowever, static and dynamic speech-unrelated attributes also exist, causing\nappearance changes during speech. To address these challenges, we propose a\nDual Attention Cooperative Framework, DualAVSE, to ignore speech-unrelated\ninformation, capture speech-related information with facial cues, and\ndynamically integrate it with the audio signal for AVSE. Specifically, we\nintroduce a spatial attention-based visual encoder to capture and enhance\nvisual speech information beyond the lip region, incorporating global facial\ncontext and automatically ignoring speech-unrelated information for robust\nvisual feature extraction. Additionally, a dynamic visual feature fusion\nstrategy is introduced by integrating a temporal-dimensional self-attention\nmodule, enabling the model to robustly handle facial variations. The acoustic\nnoise in the speaking process is variable, impacting audio quality. Therefore,\na dynamic fusion strategy for both audio and visual features is introduced to\naddress this issue. By integrating cooperative dual attention in the visual\nencoder and audio-visual fusion strategy, our model effectively extracts\nbeneficial speech information from both audio and visual cues for AVSE.\nThorough analysis and comparison on different datasets, including normal and\nchallenging cases with unreliable or absent visual information, consistently\nshow our model outperforming existing methods across multiple metrics.\n","authors":["Feixiang Wang","Shuang Yang","Shiguang Shan","Xilin Chen"],"pdf_url":"https://arxiv.org/pdf/2311.14275v1.pdf","comment":"Accepted to BMVC 2023 15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2311.14272v1","updated":"2023-11-24T04:16:32Z","published":"2023-11-24T04:16:32Z","title":"CRISP: Hybrid Structured Sparsity for Class-aware Model Pruning","summary":"  Machine learning pipelines for classification tasks often train a universal\nmodel to achieve accuracy across a broad range of classes. However, a typical\nuser encounters only a limited selection of classes regularly. This disparity\nprovides an opportunity to enhance computational efficiency by tailoring models\nto focus on user-specific classes. Existing works rely on unstructured pruning,\nwhich introduces randomly distributed non-zero values in the model, making it\nunsuitable for hardware acceleration. Alternatively, some approaches employ\nstructured pruning, such as channel pruning, but these tend to provide only\nminimal compression and may lead to reduced model accuracy. In this work, we\npropose CRISP, a novel pruning framework leveraging a hybrid structured\nsparsity pattern that combines both fine-grained N:M structured sparsity and\ncoarse-grained block sparsity. Our pruning strategy is guided by a\ngradient-based class-aware saliency score, allowing us to retain weights\ncrucial for user-specific classes. CRISP achieves high accuracy with minimal\nmemory consumption for popular models like ResNet-50, VGG-16, and MobileNetV2\non ImageNet and CIFAR-100 datasets. Moreover, CRISP delivers up to 14$\\times$\nreduction in latency and energy consumption compared to existing pruning\nmethods while maintaining comparable accuracy. Our code is available at\nhttps://github.com/shivmgg/CRISP/.\n","authors":["Shivam Aggarwal","Kuluhan Binici","Tulika Mitra"],"pdf_url":"https://arxiv.org/pdf/2311.14272v1.pdf","comment":"6 pages, accepted in Design, Automation & Test in Europe Conference &\n  Exhibition (DATE) 2024"},{"id":"http://arxiv.org/abs/2311.14271v1","updated":"2023-11-24T04:15:10Z","published":"2023-11-24T04:15:10Z","title":"Segmentation-Based Parametric Painting","summary":"  We introduce a novel image-to-painting method that facilitates the creation\nof large-scale, high-fidelity paintings with human-like quality and stylistic\nvariation. To process large images and gain control over the painting process,\nwe introduce a segmentation-based painting process and a dynamic attention map\napproach inspired by human painting strategies, allowing optimization of brush\nstrokes to proceed in batches over different image regions, thereby capturing\nboth large-scale structure and fine details, while also allowing stylistic\ncontrol over detail. Our optimized batch processing and patch-based loss\nframework enable efficient handling of large canvases, ensuring our painted\noutputs are both aesthetically compelling and functionally superior as compared\nto previous methods, as confirmed by rigorous evaluations. Code available at:\nhttps://github.com/manuelladron/semantic\\_based\\_painting.git\n","authors":["Manuel Ladron de Guevara","Matthew Fisher","Aaron Hertzmann"],"pdf_url":"https://arxiv.org/pdf/2311.14271v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2311.14265v1","updated":"2023-11-24T03:43:59Z","published":"2023-11-24T03:43:59Z","title":"Bursting Spikes: Efficient and High-performance SNNs for Event-based\n  Vision","summary":"  Advancing event-driven vision through spiking neural networks (SNNs) is\ncrucial to empowering high-speed and efficient perception. While directly\nconverting the pre-trained artificial neural networks (ANNs) - by replacing the\nnon-linear activation with spiking neurons - can provide SNNs with good\nperformance, the resultant SNNs typically demand long timesteps and high energy\nconsumption to achieve their optimal performance. To address this challenge, we\nintroduce the burst-spike mechanism inspired by the biological nervous system,\nallowing multiple spikes per timestep to reduce conversion errors and produce\nlow-latency SNNs. To further bolster this enhancement, we leverage the Pareto\nFrontier-driven algorithm to reallocate burst-firing patterns. Moreover, to\nreduce energy consumption during the conversion process, we propose a\nsensitivity-driven spike compression technique, which automatically locates the\noptimal threshold ratio according to layer-specific sensitivity. Extensive\nexperiments demonstrate our approach outperforms state-of-the-art SNN methods,\nshowcasing superior performance and reduced energy usage across classification\nand object detection. Our code will be available at\nhttps://github.com/bic-L/burst-ann2snn.\n","authors":["Ziqing Wang","Yuetong Fang","Jiahang Cao","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2311.14265v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2311.14262v1","updated":"2023-11-24T03:19:17Z","published":"2023-11-24T03:19:17Z","title":"ZeroPS: High-quality Cross-modal Knowledge Transfer for Zero-Shot 3D\n  Part Segmentation","summary":"  Recently, many 2D pretrained foundational models have demonstrated impressive\nzero-shot prediction capabilities. In this work, we design a novel pipeline for\nzero-shot 3D part segmentation, called ZeroPS. It high-quality transfers\nknowledge from 2D pretrained foundational models to 3D point clouds. The main\nidea of our approach is to explore the natural relationship between multi-view\ncorrespondences and the prompt mechanism of foundational models and build\nbridges on it. Our pipeline consists of two components: 1) a self-extension\ncomponent that extends 2D groups from a single viewpoint to spatial\nglobal-level 3D groups; 2) a multi-modal labeling component that introduces a\ntwo-dimensional checking mechanism to vote each 2D predicted bounding box to\nthe best matching 3D part, and a Class Non-highest Vote Penalty function to\nrefine the Vote Matrix. Additionally, a merging algorithm is included to merge\npart-level 3D groups. Extensive evaluation of three zero-shot segmentation\ntasks on PartnetE datasets, achieving state-of-the-art results with significant\nimprovements (+19.6%, +5.2% and +4.9%, respectively) over existing methods. Our\nproposed approach does not need any training, fine-tuning or learnable\nparameters. It is hardly affected by domain shift. The code will be released.\n","authors":["Yuheng Xue","Nenglun Chen","Jun Liu","Wenyun Sun"],"pdf_url":"https://arxiv.org/pdf/2311.14262v1.pdf","comment":"11 pages, 6 figures; references added"},{"id":"http://arxiv.org/abs/2307.15064v2","updated":"2023-11-24T02:58:58Z","published":"2023-07-27T17:59:59Z","title":"Self-Supervised Visual Acoustic Matching","summary":"  Acoustic matching aims to re-synthesize an audio clip to sound as if it were\nrecorded in a target acoustic environment. Existing methods assume access to\npaired training data, where the audio is observed in both source and target\nenvironments, but this limits the diversity of training data or requires the\nuse of simulated data or heuristics to create paired samples. We propose a\nself-supervised approach to visual acoustic matching where training samples\ninclude only the target scene image and audio -- without acoustically\nmismatched source audio for reference. Our approach jointly learns to\ndisentangle room acoustics and re-synthesize audio into the target environment,\nvia a conditional GAN framework and a novel metric that quantifies the level of\nresidual acoustic information in the de-biased audio. Training with either\nin-the-wild web data or simulated data, we demonstrate it outperforms the\nstate-of-the-art on multiple challenging datasets and a wide variety of\nreal-world audio and environments.\n","authors":["Arjun Somayazulu","Changan Chen","Kristen Grauman"],"pdf_url":"https://arxiv.org/pdf/2307.15064v2.pdf","comment":"Project page: https://vision.cs.utexas.edu/projects/ss_vam/ .\n  Accepted at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2307.16449v2","updated":"2023-11-24T02:43:18Z","published":"2023-07-31T07:15:45Z","title":"MovieChat: From Dense Token to Sparse Memory for Long Video\n  Understanding","summary":"  Recently, integrating video foundation models and large language models to\nbuild a video understanding system can overcome the limitations of specific\npre-defined vision tasks. Yet, existing systems can only handle videos with\nvery few frames. For long videos, the computation complexity, memory cost, and\nlong-term temporal connection impose additional challenges. Taking advantage of\nthe Atkinson-Shiffrin memory model, with tokens in Transformers being employed\nas the carriers of memory in combination with our specially designed memory\nmechanism, we propose the MovieChat to overcome these challenges. MovieChat\nachieves state-of-the-art performance in long video understanding, along with\nthe released MovieChat-1K benchmark with 1K long video and 14K manual\nannotations for validation of the effectiveness of our method.\n","authors":["Enxin Song","Wenhao Chai","Guanhong Wang","Yucheng Zhang","Haoyang Zhou","Feiyang Wu","Haozhe Chi","Xun Guo","Tian Ye","Yanting Zhang","Yan Lu","Jenq-Neng Hwang","Gaoang Wang"],"pdf_url":"https://arxiv.org/pdf/2307.16449v2.pdf","comment":"Preprint. Project Website https://rese1f.github.io/MovieChat/"},{"id":"http://arxiv.org/abs/2311.14242v1","updated":"2023-11-24T01:15:57Z","published":"2023-11-24T01:15:57Z","title":"RSB-Pose: Robust Short-Baseline Binocular 3D Human Pose Estimation with\n  Occlusion Handling","summary":"  In the domain of 3D Human Pose Estimation, which finds widespread daily\napplications, the requirement for convenient acquisition equipment continues to\ngrow. To satisfy this demand, we set our sights on a short-baseline binocular\nsetting that offers both portability and a geometric measurement property that\nradically mitigates depth ambiguity. However, as the binocular baseline\nshortens, two serious challenges emerge: first, the robustness of 3D\nreconstruction against 2D errors deteriorates; and second, occlusion reoccurs\ndue to the limited visual differences between two views. To address the first\nchallenge, we propose the Stereo Co-Keypoints Estimation module to improve the\nview consistency of 2D keypoints and enhance the 3D robustness. In this module,\nthe disparity is utilized to represent the correspondence of binocular 2D\npoints and the Stereo Volume Feature is introduced to contain binocular\nfeatures across different disparities. Through the regression of SVF, two-view\n2D keypoints are simultaneously estimated in a collaborative way which\nrestricts their view consistency. Furthermore, to deal with occlusions, a\nPre-trained Pose Transformer module is introduced. Through this module, 3D\nposes are refined by perceiving pose coherence, a representation of joint\ncorrelations. This perception is injected by the Pose Transformer network and\nlearned through a pre-training task that recovers iterative masked joints.\nComprehensive experiments carried out on H36M and MHAD datasets, complemented\nby visualizations, validate the effectiveness of our approach in the\nshort-baseline binocular 3D Human Pose Estimation and occlusion handling.\n","authors":["Xiaoyue Wan","Zhuo Chen","Yiming Bao","Xu Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.14242v1.pdf","comment":"13 pages, 8 figures, currently under review at IEEE Transactions on\n  Image Processing journal"},{"id":"http://arxiv.org/abs/2311.14237v1","updated":"2023-11-24T00:36:17Z","published":"2023-11-24T00:36:17Z","title":"Pseudo-label Correction for Instance-dependent Noise Using\n  Teacher-student Framework","summary":"  The high capacity of deep learning models to learn complex patterns poses a\nsignificant challenge when confronted with label noise. The inability to\ndifferentiate clean and noisy labels ultimately results in poor generalization.\nWe approach this problem by reassigning the label for each image using a new\nteacher-student based framework termed P-LC (pseudo-label correction).\nTraditional teacher-student networks are composed of teacher and student\nclassifiers for knowledge distillation. In our novel approach, we reconfigure\nthe teacher network into a triple encoder, leveraging the triplet loss to\nestablish a pseudo-label correction system. As the student generates pseudo\nlabels for a set of given images, the teacher learns to choose between the\ninitially assigned labels and the pseudo labels. Experiments on MNIST,\nFashion-MNIST, and SVHN demonstrate P-LC's superior performance over existing\nstate-of-the-art methods across all noise levels, most notably in high noise.\nIn addition, we introduce a noise level estimation to help assess model\nperformance and inform the need for additional data cleaning procedures.\n","authors":["Eugene Kim"],"pdf_url":"https://arxiv.org/pdf/2311.14237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01017v2","updated":"2023-11-24T00:24:06Z","published":"2023-11-02T06:21:56Z","title":"Learning Unsupervised World Models for Autonomous Driving via Discrete\n  Diffusion","summary":"  Learning world models can teach an agent how the world works in an\nunsupervised manner. Even though it can be viewed as a special case of sequence\nmodeling, progress for scaling world models on robotic applications such as\nautonomous driving has been somewhat less rapid than scaling language models\nwith Generative Pre-trained Transformers (GPT). We identify two reasons as\nmajor bottlenecks: dealing with complex and unstructured observation space, and\nhaving a scalable generative model. Consequently, we propose a novel world\nmodeling approach that first tokenizes sensor observations with VQVAE, then\npredicts the future via discrete diffusion. To efficiently decode and denoise\ntokens in parallel, we recast Masked Generative Image Transformer into the\ndiscrete diffusion framework with a few simple changes, resulting in notable\nimprovement. When applied to learning world models on point cloud observations,\nour model reduces prior SOTA Chamfer distance by more than 65% for 1s\nprediction, and more than 50% for 3s prediction, across NuScenes, KITTI\nOdometry, and Argoverse2 datasets. Our results demonstrate that discrete\ndiffusion on tokenized agent experience can unlock the power of GPT-like\nunsupervised learning for robotic agents.\n","authors":["Lunjun Zhang","Yuwen Xiong","Ze Yang","Sergio Casas","Rui Hu","Raquel Urtasun"],"pdf_url":"https://arxiv.org/pdf/2311.01017v2.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2311.13180v2","updated":"2023-11-24T18:31:21Z","published":"2023-11-22T06:06:54Z","title":"Provably Efficient High-Dimensional Bandit Learning with Batched\n  Feedbacks","summary":"  We study high-dimensional multi-armed contextual bandits with batched\nfeedback where the $T$ steps of online interactions are divided into $L$\nbatches. In specific, each batch collects data according to a policy that\ndepends on previous batches and the rewards are revealed only at the end of the\nbatch. Such a feedback structure is popular in applications such as\npersonalized medicine and online advertisement, where the online data often do\nnot arrive in a fully serial manner. We consider high-dimensional and linear\nsettings where the reward function of the bandit model admits either a sparse\nor low-rank structure and ask how small a number of batches are needed for a\ncomparable performance with fully dynamic data in which $L = T$. For these\nsettings, we design a provably sample-efficient algorithm which achieves a $\n\\mathcal{\\tilde O}(s_0^2 \\log^2 T)$ regret in the sparse case and $\n\\mathcal{\\tilde O} ( r ^2 \\log^2 T)$ regret in the low-rank case, using only $L\n= \\mathcal{O}( \\log T)$ batches. Here $s_0$ and $r$ are the sparsity and rank\nof the reward parameter in sparse and low-rank cases, respectively, and $\n\\mathcal{\\tilde O}(\\cdot)$ omits logarithmic factors involving the feature\ndimensions. In other words, our algorithm achieves regret bounds comparable to\nthose in fully sequential setting with only $\\mathcal{O}( \\log T)$ batches. Our\nalgorithm features a novel batch allocation method that adjusts the batch sizes\naccording to the estimation accuracy within each batch and cumulative regret.\nFurthermore, we also conduct experiments with synthetic and real-world data to\nvalidate our theory.\n","authors":["Jianqing Fan","Zhaoran Wang","Zhuoran Yang","Chenlu Ye"],"pdf_url":"https://arxiv.org/pdf/2311.13180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13110v2","updated":"2023-11-24T09:18:44Z","published":"2023-11-22T02:23:32Z","title":"White-Box Transformers via Sparse Rate Reduction: Compression Is All\n  There Is?","summary":"  In this paper, we contend that a natural objective of representation learning\nis to compress and transform the distribution of the data, say sets of tokens,\ntowards a low-dimensional Gaussian mixture supported on incoherent subspaces.\nThe goodness of such a representation can be evaluated by a principled measure,\ncalled sparse rate reduction, that simultaneously maximizes the intrinsic\ninformation gain and extrinsic sparsity of the learned representation. From\nthis perspective, popular deep network architectures, including transformers,\ncan be viewed as realizing iterative schemes to optimize this measure.\nParticularly, we derive a transformer block from alternating optimization on\nparts of this objective: the multi-head self-attention operator compresses the\nrepresentation by implementing an approximate gradient descent step on the\ncoding rate of the features, and the subsequent multi-layer perceptron\nsparsifies the features. This leads to a family of white-box transformer-like\ndeep network architectures, named CRATE, which are mathematically fully\ninterpretable. We show, by way of a novel connection between denoising and\ncompression, that the inverse to the aforementioned compressive encoding can be\nrealized by the same class of CRATE architectures. Thus, the so-derived\nwhite-box architectures are universal to both encoders and decoders.\nExperiments show that these networks, despite their simplicity, indeed learn to\ncompress and sparsify representations of large-scale real-world image and text\ndatasets, and achieve performance very close to highly engineered\ntransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the\nproposed computational framework demonstrates great potential in bridging the\ngap between theory and practice of deep learning, from a unified perspective of\ndata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .\n","authors":["Yaodong Yu","Sam Buchanan","Druv Pai","Tianzhe Chu","Ziyang Wu","Shengbang Tong","Hao Bai","Yuexiang Zhai","Benjamin D. Haeffele","Yi Ma"],"pdf_url":"https://arxiv.org/pdf/2311.13110v2.pdf","comment":"This paper integrates the works arXiv:2306.01129 and arXiv:2308.16271\n  into a complete story. In this paper, we improve the writing and\n  organization, and also add conceptual, empirical, and theoretical\n  improvements over the previous work. V2: small typo fixes and formatting\n  improvements"},{"id":"http://arxiv.org/abs/2311.11995v3","updated":"2023-11-24T02:51:30Z","published":"2023-11-20T18:26:01Z","title":"BrainWash: A Poisoning Attack to Forget in Continual Learning","summary":"  Continual learning has gained substantial attention within the deep learning\ncommunity, offering promising solutions to the challenging problem of\nsequential learning. Yet, a largely unexplored facet of this paradigm is its\nsusceptibility to adversarial attacks, especially with the aim of inducing\nforgetting. In this paper, we introduce \"BrainWash,\" a novel data poisoning\nmethod tailored to impose forgetting on a continual learner. By adding the\nBrainWash noise to a variety of baselines, we demonstrate how a trained\ncontinual learner can be induced to forget its previously learned tasks\ncatastrophically, even when using these continual learning baselines. An\nimportant feature of our approach is that the attacker requires no access to\nprevious tasks' data and is armed merely with the model's current parameters\nand the data belonging to the most recent task. Our extensive experiments\nhighlight the efficacy of BrainWash, showcasing degradation in performance\nacross various regularization-based continual learning methods.\n","authors":["Ali Abbasi","Parsa Nooralinejad","Hamed Pirsiavash","Soheil Kolouri"],"pdf_url":"https://arxiv.org/pdf/2311.11995v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12727v2","updated":"2023-11-24T03:27:31Z","published":"2023-11-21T17:03:21Z","title":"Soft Random Sampling: A Theoretical and Empirical Analysis","summary":"  Soft random sampling (SRS) is a simple yet effective approach for efficient\ntraining of large-scale deep neural networks when dealing with massive data.\nSRS selects a subset uniformly at random with replacement from the full data\nset in each epoch. In this paper, we conduct a theoretical and empirical\nanalysis of SRS. First, we analyze its sampling dynamics including data\ncoverage and occupancy. Next, we investigate its convergence with non-convex\nobjective functions and give the convergence rate. Finally, we provide its\ngeneralization performance. We empirically evaluate SRS for image recognition\non CIFAR10 and automatic speech recognition on Librispeech and an in-house\npayload dataset to demonstrate its effectiveness. Compared to existing\ncoreset-based data selection methods, SRS offers a better accuracy-efficiency\ntrade-off. Especially on real-world industrial scale data sets, it is shown to\nbe a powerful training strategy with significant speedup and competitive\nperformance with almost no additional computing cost.\n","authors":["Xiaodong Cui","Ashish Mittal","Songtao Lu","Wei Zhang","George Saon","Brian Kingsbury"],"pdf_url":"https://arxiv.org/pdf/2311.12727v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14670v1","updated":"2023-11-24T18:59:04Z","published":"2023-11-24T18:59:04Z","title":"Differentiable and accelerated spherical harmonic and Wigner transforms","summary":"  Many areas of science and engineering encounter data defined on spherical\nmanifolds. Modelling and analysis of spherical data often necessitates\nspherical harmonic transforms, at high degrees, and increasingly requires\nefficient computation of gradients for machine learning or other differentiable\nprogramming tasks. We develop novel algorithmic structures for accelerated and\ndifferentiable computation of generalised Fourier transforms on the sphere\n$\\mathbb{S}^2$ and rotation group $\\text{SO}(3)$, i.e. spherical harmonic and\nWigner transforms, respectively. We present a recursive algorithm for the\ncalculation of Wigner $d$-functions that is both stable to high harmonic\ndegrees and extremely parallelisable. By tightly coupling this with separable\nspherical transforms, we obtain algorithms that exhibit an extremely\nparallelisable structure that is well-suited for the high throughput computing\nof modern hardware accelerators (e.g. GPUs). We also develop a hybrid automatic\nand manual differentiation approach so that gradients can be computed\nefficiently. Our algorithms are implemented within the JAX differentiable\nprogramming framework in the S2FFT software code. Numerous samplings of the\nsphere are supported, including equiangular and HEALPix sampling. Computational\nerrors are at the order of machine precision for spherical samplings that admit\na sampling theorem. When benchmarked against alternative C codes we observe up\nto a 400-fold acceleration. Furthermore, when distributing over multiple GPUs\nwe achieve very close to optimal linear scaling with increasing number of GPUs\ndue to the highly parallelised and balanced nature of our algorithms. Provided\naccess to sufficiently many GPUs our transforms thus exhibit an unprecedented\neffective linear time complexity.\n","authors":["Matthew A. Price","Jason D. McEwen"],"pdf_url":"https://arxiv.org/pdf/2311.14670v1.pdf","comment":"30 pages, 7 figures, code available at\n  https://github.com/astro-informatics/s2fft"},{"id":"http://arxiv.org/abs/2211.11744v3","updated":"2023-11-24T18:53:31Z","published":"2022-11-21T18:59:33Z","title":"Visual Dexterity: In-Hand Reorientation of Novel and Complex Object\n  Shapes","summary":"  In-hand object reorientation is necessary for performing many dexterous\nmanipulation tasks, such as tool use in less structured environments that\nremain beyond the reach of current robots. Prior works built reorientation\nsystems assuming one or many of the following: reorienting only specific\nobjects with simple shapes, limited range of reorientation, slow or quasistatic\nmanipulation, simulation-only results, the need for specialized and costly\nsensor suites, and other constraints which make the system infeasible for\nreal-world deployment. We present a general object reorientation controller\nthat does not make these assumptions. It uses readings from a single commodity\ndepth camera to dynamically reorient complex and new object shapes by any\nrotation in real-time, with the median reorientation time being close to seven\nseconds. The controller is trained using reinforcement learning in simulation\nand evaluated in the real world on new object shapes not used for training,\nincluding the most challenging scenario of reorienting objects held in the air\nby a downward-facing hand that must counteract gravity during reorientation.\nOur hardware platform only uses open-source components that cost less than five\nthousand dollars. Although we demonstrate the ability to overcome assumptions\nin prior work, there is ample scope for improving absolute performance. For\ninstance, the challenging duck-shaped object not used for training was dropped\nin 56 percent of the trials. When it was not dropped, our controller reoriented\nthe object within 0.4 radians (23 degrees) 75 percent of the time. Videos are\navailable at: https://taochenshh.github.io/projects/visual-dexterity.\n","authors":["Tao Chen","Megha Tippur","Siyang Wu","Vikash Kumar","Edward Adelson","Pulkit Agrawal"],"pdf_url":"https://arxiv.org/pdf/2211.11744v3.pdf","comment":"Published in Science Robotics:\n  https://www.science.org/doi/10.1126/scirobotics.adc9244"},{"id":"http://arxiv.org/abs/2311.14658v1","updated":"2023-11-24T18:46:54Z","published":"2023-11-24T18:46:54Z","title":"Convergence Analysis for Learning Orthonormal Deep Linear Neural\n  Networks","summary":"  Enforcing orthonormal or isometric property for the weight matrices has been\nshown to enhance the training of deep neural networks by mitigating gradient\nexploding/vanishing and increasing the robustness of the learned networks.\nHowever, despite its practical performance, the theoretical analysis of\northonormality in neural networks is still lacking; for example, how\northonormality affects the convergence of the training process. In this letter,\nwe aim to bridge this gap by providing convergence analysis for training\northonormal deep linear neural networks. Specifically, we show that Riemannian\ngradient descent with an appropriate initialization converges at a linear rate\nfor training orthonormal deep linear neural networks with a class of loss\nfunctions. Unlike existing works that enforce orthonormal weight matrices for\nall the layers, our approach excludes this requirement for one layer, which is\ncrucial to establish the convergence guarantee. Our results shed light on how\nincreasing the number of hidden layers can impact the convergence speed.\nExperimental results validate our theoretical analysis.\n","authors":["Zhen Qin","Xuwei Tan","Zhihui Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.14658v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14654v1","updated":"2023-11-24T18:38:13Z","published":"2023-11-24T18:38:13Z","title":"JetLOV: Enhancing Jet Tree Tagging through Neural Network Learning of\n  Optimal LundNet Variables","summary":"  Machine learning has played a pivotal role in advancing physics, with deep\nlearning notably contributing to solving complex classification problems such\nas jet tagging in the field of jet physics. In this experiment, we aim to\nharness the full potential of neural networks while acknowledging that, at\ntimes, we may lose sight of the underlying physics governing these models.\nNevertheless, we demonstrate that we can achieve remarkable results obscuring\nphysics knowledge and relying completely on the model's outcome. We introduce\nJetLOV, a composite comprising two models: a straightforward multilayer\nperceptron (MLP) and the well-established LundNet. Our study reveals that we\ncan attain comparable jet tagging performance without relying on the\npre-computed LundNet variables. Instead, we allow the network to autonomously\nlearn an entirely new set of variables, devoid of a priori knowledge of the\nunderlying physics. These findings hold promise, particularly in addressing the\nissue of model dependence, which can be mitigated through generalization and\ntraining on diverse data sets.\n","authors":["Mauricio A. Diaz","Giorgio Cerro","Jacan Chaplais","Srinandan Dasmahapatra","Stefano Moretti"],"pdf_url":"https://arxiv.org/pdf/2311.14654v1.pdf","comment":"Accepted at the NeurIPS 2023 workshop: Machine Learning and the\n  Physical Sciences"},{"id":"http://arxiv.org/abs/2311.14653v1","updated":"2023-11-24T18:37:52Z","published":"2023-11-24T18:37:52Z","title":"Data-driven Prior Learning for Bayesian Optimisation","summary":"  Transfer learning for Bayesian optimisation has generally assumed a strong\nsimilarity between optimisation tasks, with at least a subset having similar\noptimal inputs. This assumption can reduce computational costs, but it is\nviolated in a wide range of optimisation problems where transfer learning may\nnonetheless be useful. We replace this assumption with a weaker one only\nrequiring the shape of the optimisation landscape to be similar, and analyse\nthe recent method Prior Learning for Bayesian Optimisation - PLeBO - in this\nsetting. By learning priors for the hyperparameters of the Gaussian process\nsurrogate model we can better approximate the underlying function, especially\nfor few function evaluations. We validate the learned priors and compare to a\nbreadth of transfer learning approaches, using synthetic data and a recent air\npollution optimisation problem as benchmarks. We show that PLeBO and prior\ntransfer find good inputs in fewer evaluations.\n","authors":["Sigrid Passano Hellan","Christopher G. Lucas","Nigel H. Goddard"],"pdf_url":"https://arxiv.org/pdf/2311.14653v1.pdf","comment":"To be presented at the NeurIPS 2023 Workshop on Adaptive Experimental\n  Design and Active Learning in the Real World"},{"id":"http://arxiv.org/abs/2311.14652v1","updated":"2023-11-24T18:35:00Z","published":"2023-11-24T18:35:00Z","title":"One Pass Streaming Algorithm for Super Long Token Attention\n  Approximation in Sublinear Space","summary":"  Deploying Large Language Models (LLMs) in streaming applications that involve\nlong contexts, particularly for extended dialogues and text analysis, is of\nparamount importance but presents two significant challenges. Firstly, the\nmemory consumption is substantial during the decoding phase due to the caching\nof Key and Value states (KV) of previous tokens. Secondly, attention\ncomputation is time-consuming with a time complexity of $O(n^2)$ for the\ngeneration of each token. In recent OpenAI DevDay (Nov 6, 2023), OpenAI\nreleased a new model that is able to support a 128K-long document, in our\npaper, we focus on the memory-efficient issue when context length $n$ is much\ngreater than 128K ($n \\gg 2^d$). Considering a single-layer self-attention with\nQuery, Key, and Value matrices $Q, K, V \\in \\mathbb{R}^{n \\times d}$, the\npolynomial method approximates the attention output $T \\in \\mathbb{R}^{n \\times\nd}$. It accomplishes this by constructing $U_1, U_2 \\in \\mathbb{R}^{n \\times\nt}$ to expedite attention ${\\sf Attn}(Q, K, V)$ computation within $n^{1+o(1)}$\ntime executions. Despite this, storing the Key and Value matrices $K, V \\in\n\\mathbb{R}^{n \\times d}$ still necessitates $O( n d)$ space, leading to\nsignificant memory usage. In response to these challenges, we introduce a new\nalgorithm that only reads one pass of the data in streaming fashion. This\nmethod employs sublinear space $o(n)$ to store three sketch matrices,\nalleviating the need for exact $K, V$ storage. Notably, our algorithm exhibits\nexceptional memory-efficient performance with super-long tokens. As the token\nlength $n$ increases, our error guarantee diminishes while the memory usage\nremains nearly constant. This unique attribute underscores the potential of our\ntechnique in efficiently handling LLMs in streaming applications.\n","authors":["Raghav Addanki","Chenyang Li","Zhao Song","Chiwun Yang"],"pdf_url":"https://arxiv.org/pdf/2311.14652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01225v3","updated":"2023-11-24T18:32:25Z","published":"2023-10-02T14:12:53Z","title":"A path-norm toolkit for modern networks: consequences, promises and\n  challenges","summary":"  This work introduces the first toolkit around path-norms that is fully able\nto encompass general DAG ReLU networks with biases, skip connections and any\noperation based on the extraction of order statistics: max pooling, GroupSort\netc. This toolkit notably allows us to establish generalization bounds for\nmodern neural networks that are not only the most widely applicable path-norm\nbased ones, but also recover or beat the sharpest known bounds of this type.\nThese extended path-norms further enjoy the usual benefits of path-norms: ease\nof computation, invariance under the symmetries of the network, and improved\nsharpness on feedforward networks compared to the product of operators' norms,\nanother complexity measure most commonly used.\n  The versatility of the toolkit and its ease of implementation allow us to\nchallenge the concrete promises of path-norm-based generalization bounds, by\nnumerically evaluating the sharpest known bounds for ResNets on ImageNet.\n","authors":["Antoine Gonon","Nicolas Brisebarre","Elisa Riccietti","Rémi Gribonval"],"pdf_url":"https://arxiv.org/pdf/2310.01225v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14649v1","updated":"2023-11-24T18:31:11Z","published":"2023-11-24T18:31:11Z","title":"Learning in Deep Factor Graphs with Gaussian Belief Propagation","summary":"  We propose an approach to do learning in Gaussian factor graphs. We treat all\nrelevant quantities (inputs, outputs, parameters, latents) as random variables\nin a graphical model, and view both training and prediction as inference\nproblems with different observed nodes. Our experiments show that these\nproblems can be efficiently solved with belief propagation (BP), whose updates\nare inherently local, presenting exciting opportunities for distributed and\nasynchronous training. Our approach can be scaled to deep networks and provides\na natural means to do continual learning: use the BP-estimated parameter\nmarginals of the current task as parameter priors for the next. On a video\ndenoising task we demonstrate the benefit of learnable parameters over a\nclassical factor graph approach and we show encouraging performance of deep\nfactor graphs for continual image classification on MNIST.\n","authors":["Seth Nabarro","Mark van der Wilk","Andrew J Davison"],"pdf_url":"https://arxiv.org/pdf/2311.14649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14646v1","updated":"2023-11-24T18:27:41Z","published":"2023-11-24T18:27:41Z","title":"More is Better in Modern Machine Learning: when Infinite\n  Overparameterization is Optimal and Overfitting is Obligatory","summary":"  In our era of enormous neural networks, empirical progress has been driven by\nthe philosophy that more is better. Recent deep learning practice has found\nrepeatedly that larger model size, more data, and more computation (resulting\nin lower training loss) improves performance. In this paper, we give\ntheoretical backing to these empirical observations by showing that these three\nproperties hold in random feature (RF) regression, a class of models equivalent\nto shallow networks with only the last layer trained.\n  Concretely, we first show that the test risk of RF regression decreases\nmonotonically with both the number of features and the number of samples,\nprovided the ridge penalty is tuned optimally. In particular, this implies that\ninfinite width RF architectures are preferable to those of any finite width. We\nthen proceed to demonstrate that, for a large class of tasks characterized by\npowerlaw eigenstructure, training to near-zero training loss is obligatory:\nnear-optimal performance can only be achieved when the training error is much\nsmaller than the test error. Grounding our theory in real-world data, we find\nempirically that standard computer vision tasks with convolutional neural\ntangent kernels clearly fall into this class. Taken together, our results tell\na simple, testable story of the benefits of overparameterization, overfitting,\nand more data in random feature models.\n","authors":["James B. Simon","Dhruva Karkada","Nikhil Ghosh","Mikhail Belkin"],"pdf_url":"https://arxiv.org/pdf/2311.14646v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14645v1","updated":"2023-11-24T18:27:26Z","published":"2023-11-24T18:27:26Z","title":"A General Framework for User-Guided Bayesian Optimization","summary":"  The optimization of expensive-to-evaluate black-box functions is prevalent in\nvarious scientific disciplines. Bayesian optimization is an automatic, general\nand sample-efficient method to solve these problems with minimal knowledge of\nthe underlying function dynamics. However, the ability of Bayesian optimization\nto incorporate prior knowledge or beliefs about the function at hand in order\nto accelerate the optimization is limited, which reduces its appeal for\nknowledgeable practitioners with tight budgets. To allow domain experts to\ncustomize the optimization routine, we propose ColaBO, the first\nBayesian-principled framework for incorporating prior beliefs beyond the\ntypical kernel structure, such as the likely location of the optimizer or the\noptimal value. The generality of ColaBO makes it applicable across different\nMonte Carlo acquisition functions and types of user beliefs. We empirically\ndemonstrate ColaBO's ability to substantially accelerate optimization when the\nprior information is accurate, and to retain approximately default performance\nwhen it is misleading.\n","authors":["Carl Hvarfner","Frank Hutter","Luigi Nardi"],"pdf_url":"https://arxiv.org/pdf/2311.14645v1.pdf","comment":"18 pages, 11 figures"},{"id":"http://arxiv.org/abs/2310.01769v3","updated":"2023-11-24T18:08:25Z","published":"2023-10-03T03:34:22Z","title":"How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing:\n  The Curses of Symmetry and Initialization","summary":"  This paper rigorously shows how over-parameterization changes the convergence\nbehaviors of gradient descent (GD) for the matrix sensing problem, where the\ngoal is to recover an unknown low-rank ground-truth matrix from near-isotropic\nlinear measurements. First, we consider the symmetric setting with the\nsymmetric parameterization where $M^* \\in \\mathbb{R}^{n \\times n}$ is a\npositive semi-definite unknown matrix of rank $r \\ll n$, and one uses a\nsymmetric parameterization $XX^\\top$ to learn $M^*$. Here $X \\in \\mathbb{R}^{n\n\\times k}$ with $k > r$ is the factor matrix. We give a novel $\\Omega (1/T^2)$\nlower bound of randomly initialized GD for the over-parameterized case ($k >r$)\nwhere $T$ is the number of iterations. This is in stark contrast to the\nexact-parameterization scenario ($k=r$) where the convergence rate is $\\exp\n(-\\Omega (T))$. Next, we study asymmetric setting where $M^* \\in\n\\mathbb{R}^{n_1 \\times n_2}$ is the unknown matrix of rank $r \\ll\n\\min\\{n_1,n_2\\}$, and one uses an asymmetric parameterization $FG^\\top$ to\nlearn $M^*$ where $F \\in \\mathbb{R}^{n_1 \\times k}$ and $G \\in \\mathbb{R}^{n_2\n\\times k}$. Building on prior work, we give a global exact convergence result\nof randomly initialized GD for the exact-parameterization case ($k=r$) with an\n$\\exp (-\\Omega(T))$ rate. Furthermore, we give the first global exact\nconvergence result for the over-parameterization case ($k>r$) with an\n$\\exp(-\\Omega(\\alpha^2 T))$ rate where $\\alpha$ is the initialization scale.\nThis linear convergence result in the over-parameterization case is especially\nsignificant because one can apply the asymmetric parameterization to the\nsymmetric setting to speed up from $\\Omega (1/T^2)$ to linear convergence. On\nthe other hand, we propose a novel method that only modifies one step of GD and\nobtains a convergence rate independent of $\\alpha$, recovering the rate in the\nexact-parameterization case.\n","authors":["Nuoya Xiong","Lijun Ding","Simon S. Du"],"pdf_url":"https://arxiv.org/pdf/2310.01769v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14632v1","updated":"2023-11-24T17:56:44Z","published":"2023-11-24T17:56:44Z","title":"Differentially Private SGD Without Clipping Bias: An Error-Feedback\n  Approach","summary":"  Differentially Private Stochastic Gradient Descent with gradient clipping\n(DPSGD-GC) is a powerful tool for training deep learning models using sensitive\ndata, providing both a solid theoretical privacy guarantee and high efficiency.\nHowever, using DPSGD-GC to ensure Differential Privacy (DP) comes at the cost\nof model performance degradation due to DP noise injection and gradient\nclipping. Existing research has extensively analyzed the theoretical\nconvergence of DPSGD-GC, and has shown that it only converges when using large\nclipping thresholds that are dependent on problem-specific parameters.\nUnfortunately, these parameters are often unknown in practice, making it hard\nto choose the optimal clipping threshold. Therefore, in practice, DPSGD-GC\nsuffers from degraded performance due to the {\\it constant} bias introduced by\nthe clipping.\n  In our work, we propose a new error-feedback (EF) DP algorithm as an\nalternative to DPSGD-GC, which not only offers a diminishing utility bound\nwithout inducing a constant clipping bias, but more importantly, it allows for\nan arbitrary choice of clipping threshold that is independent of the problem.\nWe establish an algorithm-specific DP analysis for our proposed algorithm,\nproviding privacy guarantees based on R{\\'e}nyi DP. Additionally, we\ndemonstrate that under mild conditions, our algorithm can achieve nearly the\nsame utility bound as DPSGD without gradient clipping. Our empirical results on\nCifar-10/100 and E2E datasets, show that the proposed algorithm achieves higher\naccuracies than DPSGD while maintaining the same level of DP guarantee.\n","authors":["Xinwei Zhang","Zhiqi Bu","Zhiwei Steven Wu","Mingyi Hong"],"pdf_url":"https://arxiv.org/pdf/2311.14632v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02428v2","updated":"2023-11-24T17:26:56Z","published":"2023-10-03T20:49:00Z","title":"EGraFFBench: Evaluation of Equivariant Graph Neural Network Force Fields\n  for Atomistic Simulations","summary":"  Equivariant graph neural networks force fields (EGraFFs) have shown great\npromise in modelling complex interactions in atomic systems by exploiting the\ngraphs' inherent symmetries. Recent works have led to a surge in the\ndevelopment of novel architectures that incorporate equivariance-based\ninductive biases alongside architectural innovations like graph transformers\nand message passing to model atomic interactions. However, thorough evaluations\nof these deploying EGraFFs for the downstream task of real-world atomistic\nsimulations, is lacking. To this end, here we perform a systematic benchmarking\nof 6 EGraFF algorithms (NequIP, Allegro, BOTNet, MACE, Equiformer, TorchMDNet),\nwith the aim of understanding their capabilities and limitations for realistic\natomistic simulations. In addition to our thorough evaluation and analysis on\neight existing datasets based on the benchmarking literature, we release two\nnew benchmark datasets, propose four new metrics, and three challenging tasks.\nThe new datasets and tasks evaluate the performance of EGraFF to\nout-of-distribution data, in terms of different crystal structures,\ntemperatures, and new molecules. Interestingly, evaluation of the EGraFF models\nbased on dynamic simulations reveals that having a lower error on energy or\nforce does not guarantee stable or reliable simulation or faithful replication\nof the atomic structures. Moreover, we find that no model clearly outperforms\nother models on all datasets and tasks. Importantly, we show that the\nperformance of all the models on out-of-distribution datasets is unreliable,\npointing to the need for the development of a foundation model for force fields\nthat can be used in real-world simulations. In summary, this work establishes a\nrigorous framework for evaluating machine learning force fields in the context\nof atomic simulations and points to open research challenges within this\ndomain.\n","authors":["Vaibhav Bihani","Utkarsh Pratiush","Sajid Mannan","Tao Du","Zhimin Chen","Santiago Miret","Matthieu Micoulaut","Morten M Smedskjaer","Sayan Ranu","N M Anoop Krishnan"],"pdf_url":"https://arxiv.org/pdf/2310.02428v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.11954v3","updated":"2023-11-24T17:12:51Z","published":"2022-02-24T08:18:25Z","title":"XAutoML: A Visual Analytics Tool for Understanding and Validating\n  Automated Machine Learning","summary":"  In the last ten years, various automated machine learning (AutoM ) systems\nhave been proposed to build end-to-end machine learning (ML) pipelines with\nminimal human interaction. Even though such automatically synthesized ML\npipelines are able to achieve a competitive performance, recent studies have\nshown that users do not trust models constructed by AutoML due to missing\ntransparency of AutoML systems and missing explanations for the constructed ML\npipelines. In a requirements analysis study with 36 domain experts, data\nscientists, and AutoML researchers from different professions with vastly\ndifferent expertise in ML, we collect detailed informational needs for AutoML.\nWe propose XAutoML, an interactive visual analytics tool for explaining\narbitrary AutoML optimization procedures and ML pipelines constructed by\nAutoML. XAutoML combines interactive visualizations with established techniques\nfrom explainable artificial intelligence (XAI) to make the complete AutoML\nprocedure transparent and explainable. By integrating XAutoML with JupyterLab,\nexperienced users can extend the visual analytics with ad-hoc visualizations\nbased on information extracted from XAutoML. We validate our approach in a user\nstudy with the same diverse user group from the requirements analysis. All\nparticipants were able to extract useful information from XAutoML, leading to a\nsignificantly increased understanding of ML pipelines produced by AutoML and\nthe AutoML optimization itself.\n","authors":["Marc-André Zöller","Waldemar Titov","Thomas Schlegel","Marco F. Huber"],"pdf_url":"https://arxiv.org/pdf/2202.11954v3.pdf","comment":"Revised version accepted at ACM TiiS Special Issue on Human-centered\n  Explainable AI"},{"id":"http://arxiv.org/abs/2311.14609v1","updated":"2023-11-24T17:04:21Z","published":"2023-11-24T17:04:21Z","title":"Analysis of the expected $L_2$ error of an over-parametrized deep neural\n  network estimate learned by gradient descent without regularization","summary":"  Recent results show that estimates defined by over-parametrized deep neural\nnetworks learned by applying gradient descent to a regularized empirical $L_2$\nrisk are universally consistent and achieve good rates of convergence. In this\npaper, we show that the regularization term is not necessary to obtain similar\nresults. In the case of a suitably chosen initialization of the network, a\nsuitable number of gradient descent steps, and a suitable step size we show\nthat an estimate without a regularization term is universally consistent for\nbounded predictor variables. Additionally, we show that if the regression\nfunction is H\\\"older smooth with H\\\"older exponent $1/2 \\leq p \\leq 1$, the\n$L_2$ error converges to zero with a convergence rate of approximately\n$n^{-1/(1+d)}$. Furthermore, in case of an interaction model, where the\nregression function consists of a sum of H\\\"older smooth functions with $d^*$\ncomponents, a rate of convergence is derived which does not depend on the input\ndimension $d$.\n","authors":["Selina Drews","Michael Kohler"],"pdf_url":"https://arxiv.org/pdf/2311.14609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14601v1","updated":"2023-11-24T16:43:17Z","published":"2023-11-24T16:43:17Z","title":"A Metalearned Neural Circuit for Nonparametric Bayesian Inference","summary":"  Most applications of machine learning to classification assume a closed set\nof balanced classes. This is at odds with the real world, where class\noccurrence statistics often follow a long-tailed power-law distribution and it\nis unlikely that all classes are seen in a single sample. Nonparametric\nBayesian models naturally capture this phenomenon, but have significant\npractical barriers to widespread adoption, namely implementation complexity and\ncomputational inefficiency. To address this, we present a method for extracting\nthe inductive bias from a nonparametric Bayesian model and transferring it to\nan artificial neural network. By simulating data with a nonparametric Bayesian\nprior, we can metalearn a sequence model that performs inference over an\nunlimited set of classes. After training, this \"neural circuit\" has distilled\nthe corresponding inductive bias and can successfully perform sequential\ninference over an open set of classes. Our experimental results show that the\nmetalearned neural circuit achieves comparable or better performance than\nparticle filter-based methods for inference in these models while being faster\nand simpler to use than methods that explicitly incorporate Bayesian\nnonparametric inference.\n","authors":["Jake C. Snell","Gianluca Bencomo","Thomas L. Griffiths"],"pdf_url":"https://arxiv.org/pdf/2311.14601v1.pdf","comment":"13 pages, 3 figures. Code available at\n  https://github.com/jakesnell/neural-circuits"},{"id":"http://arxiv.org/abs/2211.00539v3","updated":"2023-11-24T16:27:22Z","published":"2022-11-01T15:43:29Z","title":"Dungeons and Data: A Large-Scale NetHack Dataset","summary":"  Recent breakthroughs in the development of agents to solve challenging\nsequential decision making problems such as Go, StarCraft, or DOTA, have relied\non both simulated environments and large-scale datasets. However, progress on\nthis research has been hindered by the scarcity of open-sourced datasets and\nthe prohibitive computational cost to work with them. Here we present the\nNetHack Learning Dataset (NLD), a large and highly-scalable dataset of\ntrajectories from the popular game of NetHack, which is both extremely\nchallenging for current methods and very fast to run. NLD consists of three\nparts: 10 billion state transitions from 1.5 million human trajectories\ncollected on the NAO public NetHack server from 2009 to 2020; 3 billion\nstate-action-score transitions from 100,000 trajectories collected from the\nsymbolic bot winner of the NetHack Challenge 2021; and, accompanying code for\nusers to record, load and stream any collection of such trajectories in a\nhighly compressed form. We evaluate a wide range of existing algorithms\nincluding online and offline RL, as well as learning from demonstrations,\nshowing that significant research advances are needed to fully leverage\nlarge-scale datasets for challenging sequential decision making tasks.\n","authors":["Eric Hambro","Roberta Raileanu","Danielle Rothermel","Vegard Mella","Tim Rocktäschel","Heinrich Küttler","Naila Murray"],"pdf_url":"https://arxiv.org/pdf/2211.00539v3.pdf","comment":"9 pages, published in the Proceedings of the 36th Conference on\n  Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and\n  Benchmarks. New links to hosting location. Revised results, same conclusions"},{"id":"http://arxiv.org/abs/2304.00933v2","updated":"2023-11-24T16:24:33Z","published":"2023-04-03T12:45:52Z","title":"Knowledge Accumulation in Continually Learned Representations and the\n  Issue of Feature Forgetting","summary":"  While it is established that neural networks suffer from catastrophic\nforgetting ``at the output level'', it is debated whether this is also the case\nat the level of representations. Some studies ascribe a certain level of innate\nrobustness to representations, that they only forget minimally and no critical\ninformation, while others claim that representations are also severely affected\nby forgetting. To settle this debate, we first discuss how this apparent\ndisagreement might stem from the coexistence of two phenomena that affect the\nquality of continually learned representations: knowledge accumulation and\nfeature forgetting. We then show that, even though it is true that feature\nforgetting can be small in absolute terms, newly learned information is\nforgotten just as catastrophically at the level of representations as it is at\nthe output level. Next we show that this feature forgetting is problematic as\nit substantially slows down knowledge accumulation. We further show that\nrepresentations that are continually learned through both supervised and\nself-supervised learning suffer from feature forgetting. Finally, we study how\nfeature forgetting and knowledge accumulation are affected by different types\nof continual learning methods.\n","authors":["Timm Hess","Eli Verwimp","Gido M. van de Ven","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2304.00933v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14581v1","updated":"2023-11-24T16:12:43Z","published":"2023-11-24T16:12:43Z","title":"Example-Based Explanations of Random Forest Predictions","summary":"  A random forest prediction can be computed by the scalar product of the\nlabels of the training examples and a set of weights that are determined by the\nleafs of the forest into which the test object falls; each prediction can hence\nbe explained exactly by the set of training examples for which the weights are\nnon-zero. The number of examples used in such explanations is shown to vary\nwith the dimensionality of the training set and hyperparameters of the random\nforest algorithm. This means that the number of examples involved in each\nprediction can to some extent be controlled by varying these parameters.\nHowever, for settings that lead to a required predictive performance, the\nnumber of examples involved in each prediction may be unreasonably large,\npreventing the user to grasp the explanations. In order to provide more useful\nexplanations, a modified prediction procedure is proposed, which includes only\nthe top-weighted examples. An investigation on regression and classification\ntasks shows that the number of examples used in each explanation can be\nsubstantially reduced while maintaining, or even improving, predictive\nperformance compared to the standard prediction procedure.\n","authors":["Henrik Boström"],"pdf_url":"https://arxiv.org/pdf/2311.14581v1.pdf","comment":"Submitted to 22nd International Symposium on Intelligent Data\n  Analysis, IDA 2024"},{"id":"http://arxiv.org/abs/2309.17296v2","updated":"2023-11-24T16:08:38Z","published":"2023-09-29T14:53:05Z","title":"Navigating the Design Space of Equivariant Diffusion-Based Generative\n  Models for De Novo 3D Molecule Generation","summary":"  Deep generative diffusion models are a promising avenue for 3D de novo\nmolecular design in materials science and drug discovery. However, their\nutility is still limited by suboptimal performance on large molecular\nstructures and limited training data. To address this gap, we explore the\ndesign space of E(3)-equivariant diffusion models, focusing on previously\nunexplored areas. Our extensive comparative analysis evaluates the interplay\nbetween continuous and discrete state spaces. From this investigation, we\npresent the EQGAT-diff model, which consistently outperforms established models\nfor the QM9 and GEOM-Drugs datasets. Significantly, EQGAT-diff takes continuous\natom positions, while chemical elements and bond types are categorical and uses\ntime-dependent loss weighting, substantially increasing training convergence,\nthe quality of generated samples, and inference time. We also showcase that\nincluding chemically motivated additional features like hybridization states in\nthe diffusion process enhances the validity of generated molecules. To further\nstrengthen the applicability of diffusion models to limited training data, we\ninvestigate the transferability of EQGAT-diff trained on the large PubChem3D\ndataset with implicit hydrogen atoms to target different data distributions.\nFine-tuning EQGAT-diff for just a few iterations shows an efficient\ndistribution shift, further improving performance throughout data sets.\nFinally, we test our model on the Crossdocked data set for structure-based de\nnovo ligand generation, underlining the importance of our findings showing\nstate-of-the-art performance on Vina docking scores.\n","authors":["Tuan Le","Julian Cremer","Frank Noé","Djork-Arné Clevert","Kristof Schütt"],"pdf_url":"https://arxiv.org/pdf/2309.17296v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14577v1","updated":"2023-11-24T16:07:35Z","published":"2023-11-24T16:07:35Z","title":"Predicting Failure of P2P Lending Platforms through Machine Learning:\n  The Case in China","summary":"  This study employs machine learning models to predict the failure of\nPeer-to-Peer (P2P) lending platforms, specifically in China. By employing the\nfilter method and wrapper method with forward selection and backward\nelimination, we establish a rigorous and practical procedure that ensures the\nrobustness and importance of variables in predicting platform failures. The\nresearch identifies a set of robust variables that consistently appear in the\nfeature subsets across different selection methods and models, suggesting their\nreliability and relevance in predicting platform failures. The study highlights\nthat reducing the number of variables in the feature subset leads to an\nincrease in the false acceptance rate while the performance metrics remain\nstable, with an AUC value of approximately 0.96 and an F1 score of around 0.88.\nThe findings of this research provide significant practical implications for\nregulatory authorities and investors operating in the Chinese P2P lending\nindustry.\n","authors":["Jen-Yin Yeh","Hsin-Yu Chiu","Jhih-Huei Huang"],"pdf_url":"https://arxiv.org/pdf/2311.14577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.09968v2","updated":"2023-11-24T15:33:30Z","published":"2023-09-18T17:49:09Z","title":"Generating and Imputing Tabular Data via Diffusion and Flow-based\n  Gradient-Boosted Trees","summary":"  Tabular data is hard to acquire and is subject to missing values. This paper\nproposes a novel approach to generate and impute mixed-type (continuous and\ncategorical) tabular data using score-based diffusion and conditional flow\nmatching. Contrary to previous work that relies on neural networks to learn the\nscore function or the vector field, we instead rely on XGBoost, a popular\nGradient-Boosted Tree (GBT) method. We empirically show on 27 different\ndatasets that our approach i) generates highly realistic synthetic data when\nthe training dataset is either clean or tainted by missing data and ii)\ngenerates diverse plausible data imputations. Furthermore, our method\noutperforms deep-learning generation methods on data generation and is\ncompetitive on data imputation. Finally, it can be trained in parallel using\nCPUs without the need for a GPU. To make it easily accessible, we release our\ncode through a Python library and an R package.\n","authors":["Alexia Jolicoeur-Martineau","Kilian Fatras","Tal Kachman"],"pdf_url":"https://arxiv.org/pdf/2309.09968v2.pdf","comment":"Code: https://github.com/SamsungSAILMontreal/ForestDiffusion"},{"id":"http://arxiv.org/abs/2311.14549v1","updated":"2023-11-24T15:31:26Z","published":"2023-11-24T15:31:26Z","title":"FRUITS: Feature Extraction Using Iterated Sums for Time Series\n  Classification","summary":"  We introduce a pipeline for time series classification that extracts features\nbased on the iterated-sums signature (ISS) and then applies a linear\nclassifier. These features are intrinsically nonlinear, capture chronological\ninformation, and, under certain settings, are invariant to time-warping. We are\ncompetitive with state-of-the-art methods on the UCR archive, both in terms of\naccuracy and speed. We make our code available at\n\\url{https://github.com/irkri/fruits}.\n","authors":["Joscha Diehl","Richard Krieg"],"pdf_url":"https://arxiv.org/pdf/2311.14549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14460v3","updated":"2023-11-24T15:25:26Z","published":"2023-02-28T10:08:11Z","title":"Interpretable and intervenable ultrasonography-based machine learning\n  models for pediatric appendicitis","summary":"  Appendicitis is among the most frequent reasons for pediatric abdominal\nsurgeries. Previous decision support systems for appendicitis have focused on\nclinical, laboratory, scoring, and computed tomography data and have ignored\nabdominal ultrasound, despite its noninvasive nature and widespread\navailability. In this work, we present interpretable machine learning models\nfor predicting the diagnosis, management and severity of suspected appendicitis\nusing ultrasound images. Our approach utilizes concept bottleneck models (CBM)\nthat facilitate interpretation and interaction with high-level concepts\nunderstandable to clinicians. Furthermore, we extend CBMs to prediction\nproblems with multiple views and incomplete concept sets. Our models were\ntrained on a dataset comprising 579 pediatric patients with 1709 ultrasound\nimages accompanied by clinical and laboratory data. Results show that our\nproposed method enables clinicians to utilize a human-understandable and\nintervenable predictive model without compromising performance or requiring\ntime-consuming image annotation when deployed. For predicting the diagnosis,\nthe extended multiview CBM attained an AUROC of 0.80 and an AUPR of 0.92,\nperforming comparably to similar black-box neural networks trained and tested\non the same dataset.\n","authors":["Ričards Marcinkevičs","Patricia Reis Wolfertstetter","Ugne Klimiene","Kieran Chin-Cheong","Alyssia Paschke","Julia Zerres","Markus Denzinger","David Niederberger","Sven Wellmann","Ece Ozkan","Christian Knorr","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2302.14460v3.pdf","comment":"Published in Medical Image Analysis (Elsevier)"},{"id":"http://arxiv.org/abs/2201.00292v4","updated":"2023-11-24T15:06:36Z","published":"2022-01-02T05:05:26Z","title":"Fair Data Representation for Machine Learning at the Pareto Frontier","summary":"  As machine learning powered decision-making becomes increasingly important in\nour daily lives, it is imperative to strive for fairness in the underlying data\nprocessing. We propose a pre-processing algorithm for fair data representation\nvia which supervised learning results in estimations of the Pareto frontier\nbetween prediction error and statistical disparity. Particularly, the present\nwork applies the optimal affine transport to approach the post-processing\nWasserstein-2 barycenter characterization of the optimal fair $L^2$-objective\nsupervised learning via a pre-processing data deformation. Furthermore, we show\nthat the Wasserstein-2 geodesics from the conditional (on sensitive\ninformation) distributions of the learning outcome to their barycenter\ncharacterizes the Pareto frontier between $L^2$-loss and the average pairwise\nWasserstein-2 distance among sensitive groups on the learning outcome.\nNumerical simulations underscore the advantages: (1) the pre-processing step is\ncompositive with arbitrary conditional expectation estimation supervised\nlearning methods and unseen data; (2) the fair representation protects the\nsensitive information by limiting the inference capability of the remaining\ndata with respect to the sensitive data; (3) the optimal affine maps are\ncomputationally efficient even for high-dimensional data.\n","authors":["Shizhou Xu","Thomas Strohmer"],"pdf_url":"https://arxiv.org/pdf/2201.00292v4.pdf","comment":"63 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.14534v1","updated":"2023-11-24T15:03:55Z","published":"2023-11-24T15:03:55Z","title":"Finding Foundation Models for Time Series Classification with a PreText\n  Task","summary":"  Over the past decade, Time Series Classification (TSC) has gained an\nincreasing attention. While various methods were explored, deep learning -\nparticularly through Convolutional Neural Networks (CNNs)-stands out as an\neffective approach. However, due to the limited availability of training data,\ndefining a foundation model for TSC that overcomes the overfitting problem is\nstill a challenging task. The UCR archive, encompassing a wide spectrum of\ndatasets ranging from motion recognition to ECG-based heart disease detection,\nserves as a prime example for exploring this issue in diverse TSC scenarios. In\nthis paper, we address the overfitting challenge by introducing pre-trained\ndomain foundation models. A key aspect of our methodology is a novel pretext\ntask that spans multiple datasets. This task is designed to identify the\noriginating dataset of each time series sample, with the goal of creating\nflexible convolution filters that can be applied across different datasets. The\nresearch process consists of two phases: a pre-training phase where the model\nacquires general features through the pretext task, and a subsequent\nfine-tuning phase for specific dataset classifications. Our extensive\nexperiments on the UCR archive demonstrate that this pre-training strategy\nsignificantly outperforms the conventional training approach without\npre-training. This strategy effectively reduces overfitting in small datasets\nand provides an efficient route for adapting these models to new datasets, thus\nadvancing the capabilities of deep learning in TSC.\n","authors":["Ali Ismail-Fawaz","Maxime Devanne","Stefano Berretti","Jonathan Weber","Germain Forestier"],"pdf_url":"https://arxiv.org/pdf/2311.14534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10359v2","updated":"2023-11-24T14:59:37Z","published":"2023-11-17T07:25:18Z","title":"FIKIT: Priority-Based Real-time GPU Multi-tasking Scheduling with Kernel\n  Identification","summary":"  Highly parallelized workloads like machine learning training, inferences and\ngeneral HPC tasks are greatly accelerated using GPU devices. In a cloud\ncomputing cluster, serving a GPU's computation power through multi-tasks\nsharing is highly demanded since there are always more task requests than the\nnumber of GPU available. Existing GPU sharing solutions focus on reducing\ntask-level waiting time or task-level switching costs when multiple jobs\ncompeting for a single GPU. Non-stopped computation requests come with\ndifferent priorities, having non-symmetric impact on QoS for sharing a GPU\ndevice. Existing work missed the kernel-level optimization opportunity brought\nby this setting. To address this problem, we present a novel kernel-level\nscheduling strategy called FIKIT: Filling Inter-kernel Idle Time. FIKIT\nincorporates task-level priority information, fine-grained kernel\nidentification, and kernel measurement, allowing low priorities task's\nexecution during high priority task's inter-kernel idle time. Thereby, filling\nthe GPU's device runtime fully, and reduce overall GPU sharing impact to cloud\nservices. Across a set of ML models, the FIKIT based inference system\naccelerated high priority tasks by 1.33 to 14.87 times compared to the JCT in\nGPU sharing mode, and more than half of the cases are accelerated by more than\n3.5 times. Alternatively, under preemptive sharing, the low-priority tasks have\na comparable to default GPU sharing mode JCT, with a 0.84 to 1 times ratio. We\nfurther limit the kernel measurement and runtime fine-grained kernel scheduling\noverhead to less than 10%.\n","authors":["Wenqing Wu"],"pdf_url":"https://arxiv.org/pdf/2311.10359v2.pdf","comment":"19 pages, 18 figures. Shorten the introduction section; Move some\n  content from the introduction to the design section; Add Dataset References"},{"id":"http://arxiv.org/abs/2311.14533v1","updated":"2023-11-24T14:56:36Z","published":"2023-11-24T14:56:36Z","title":"Comparing Feature Engineering and End-to-End Deep Learning for Autism\n  Spectrum Disorder Assessment based on Fullbody-Tracking","summary":"  Autism Spectrum Disorder (ASD) is characterized by challenges in social\ncommunication and restricted patterns, with motor abnormalities gaining\ntraction for early detection. However, kinematic analysis in ASD is limited,\noften lacking robust validation and relying on hand-crafted features for single\ntasks, leading to inconsistencies across studies. Thus, end-to-end models have\nbecome promising methods to overcome the need for feature engineering. Our aim\nis to assess both approaches across various kinematic tasks to measure the\nefficacy of commonly used features in ASD assessment, while comparing them to\nend-to-end models. Specifically, we developed a virtual reality environment\nwith multiple motor tasks and trained models using both classification\napproaches. We prioritized a reliable validation framework with repeated\ncross-validation. Our comparative analysis revealed that hand-crafted features\noutperformed our deep learning approach in specific tasks, achieving a\nstate-of-the-art area under the curve (AUC) of 0.90$\\pm$0.06. Conversely,\nend-to-end models provided more consistent results with less variability across\nall VR tasks, demonstrating domain generalization and reliability, with a\nmaximum task AUC of 0.89$\\pm$0.06. These findings show that end-to-end models\nenable less variable and context-independent ASD assessments without requiring\ndomain knowledge or task specificity. However, they also recognize the\neffectiveness of hand-crafted features in specific task scenarios.\n","authors":["Alberto Altozano","Maria Eleonora Minissi","Mariano Alcañiz","Javier Marín-Morales"],"pdf_url":"https://arxiv.org/pdf/2311.14533v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2308.07741v3","updated":"2023-11-24T14:53:50Z","published":"2023-08-15T12:40:56Z","title":"Real Robot Challenge 2022: Learning Dexterous Manipulation from Offline\n  Data in the Real World","summary":"  Experimentation on real robots is demanding in terms of time and costs. For\nthis reason, a large part of the reinforcement learning (RL) community uses\nsimulators to develop and benchmark algorithms. However, insights gained in\nsimulation do not necessarily translate to real robots, in particular for tasks\ninvolving complex interactions with the environment. The Real Robot Challenge\n2022 therefore served as a bridge between the RL and robotics communities by\nallowing participants to experiment remotely with a real robot - as easily as\nin simulation.\n  In the last years, offline reinforcement learning has matured into a\npromising paradigm for learning from pre-collected datasets, alleviating the\nreliance on expensive online interactions. We therefore asked the participants\nto learn two dexterous manipulation tasks involving pushing, grasping, and\nin-hand orientation from provided real-robot datasets. An extensive software\ndocumentation and an initial stage based on a simulation of the real set-up\nmade the competition particularly accessible. By giving each team plenty of\naccess budget to evaluate their offline-learned policies on a cluster of seven\nidentical real TriFinger platforms, we organized an exciting competition for\nmachine learners and roboticists alike.\n  In this work we state the rules of the competition, present the methods used\nby the winning teams and compare their results with a benchmark of\nstate-of-the-art offline RL algorithms on the challenge datasets.\n","authors":["Nico Gürtler","Felix Widmaier","Cansu Sancaktar","Sebastian Blaes","Pavel Kolev","Stefan Bauer","Manuel Wüthrich","Markus Wulfmeier","Martin Riedmiller","Arthur Allshire","Qiang Wang","Robert McCarthy","Hangyeol Kim","Jongchan Baek","Wookyong Kwon","Shanliang Qian","Yasunori Toshimitsu","Mike Yan Michelis","Amirhossein Kazemipour","Arman Raayatsanati","Hehui Zheng","Barnabas Gavin Cangan","Bernhard Schölkopf","Georg Martius"],"pdf_url":"https://arxiv.org/pdf/2308.07741v3.pdf","comment":"Typo in author list fixed"},{"id":"http://arxiv.org/abs/2308.08467v2","updated":"2023-11-24T14:52:05Z","published":"2023-08-16T16:15:47Z","title":"On Neural Quantum Support Vector Machines","summary":"  In \\cite{simon2023algorithms} we introduced four algorithms for the training\nof neural support vector machines (NSVMs) and demonstrated their feasibility.\nIn this note we introduce neural quantum support vector machines, that is,\nNSVMs with a quantum kernel, and extend our results to this setting.\n","authors":["Lars Simon","Manuel Radons"],"pdf_url":"https://arxiv.org/pdf/2308.08467v2.pdf","comment":"16 pages, 1 figure. arXiv admin note: substantial text overlap with\n  arXiv:2308.07204"},{"id":"http://arxiv.org/abs/2311.14517v1","updated":"2023-11-24T14:45:53Z","published":"2023-11-24T14:45:53Z","title":"tinyCLAP: Distilling Constrastive Language-Audio Pretrained Models","summary":"  Contrastive Language-Audio Pretraining (CLAP) became of crucial importance in\nthe field of audio and speech processing. Its employment ranges from sound\nevent detection to text-to-audio generation. However, one of the main\nlimitations is the considerable amount of data required in the training process\nand the overall computational complexity during inference. This paper\ninvestigates how we can reduce the complexity of contrastive language-audio\npre-trained models, yielding an efficient model that we call tinyCLAP. We\nderive an unimodal distillation loss from first principles and explore how the\ndimensionality of the shared, multimodal latent space can be reduced via\npruning. TinyCLAP uses only 6% of the original Microsoft CLAP parameters with a\nminimal reduction (less than 5%) in zero-shot classification performance across\nthe three sound event detection datasets on which it was tested\n","authors":["Francesco Paissan","Elisabetta Farella"],"pdf_url":"https://arxiv.org/pdf/2311.14517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02679v2","updated":"2023-11-24T14:25:58Z","published":"2023-11-05T15:32:37Z","title":"Regret Analysis of Learning-Based Linear Quadratic Gaussian Control with\n  Additive Exploration","summary":"  In this paper, we analyze the regret incurred by a computationally efficient\nexploration strategy, known as naive exploration, for controlling unknown\npartially observable systems within the Linear Quadratic Gaussian (LQG)\nframework. We introduce a two-phase control algorithm called LQG-NAIVE, which\ninvolves an initial phase of injecting Gaussian input signals to obtain a\nsystem model, followed by a second phase of an interplay between naive\nexploration and control in an episodic fashion. We show that LQG-NAIVE achieves\na regret growth rate of $\\tilde{\\mathcal{O}}(\\sqrt{T})$, i.e.,\n$\\mathcal{O}(\\sqrt{T})$ up to logarithmic factors after $T$ time steps, and we\nvalidate its performance through numerical simulations. Additionally, we\npropose LQG-IF2E, which extends the exploration signal to a `closed-loop'\nsetting by incorporating the Fisher Information Matrix (FIM). We provide\ncompelling numerical evidence of the competitive performance of LQG-IF2E\ncompared to LQG-NAIVE.\n","authors":["Archith Athrey","Othmane Mazhar","Meichen Guo","Bart De Schutter","Shengling Shi"],"pdf_url":"https://arxiv.org/pdf/2311.02679v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14495v1","updated":"2023-11-24T14:08:31Z","published":"2023-11-24T14:08:31Z","title":"StableSSM: Alleviating the Curse of Memory in State-space Models through\n  Stable Reparameterization","summary":"  In this paper, we investigate the long-term memory learning capabilities of\nstate-space models (SSMs) from the perspective of parameterization. We prove\nthat state-space models without any reparameterization exhibit a memory\nlimitation similar to that of traditional RNNs: the target relationships that\ncan be stably approximated by state-space models must have an exponential\ndecaying memory. Our analysis identifies this \"curse of memory\" as a result of\nthe recurrent weights converging to a stability boundary, suggesting that a\nreparameterization technique can be effective. To this end, we introduce a\nclass of reparameterization techniques for SSMs that effectively lift its\nmemory limitations. Besides improving approximation capabilities, we further\nillustrate that a principled choice of reparameterization scheme can also\nenhance optimization stability. We validate our findings using synthetic\ndatasets and language models.\n","authors":["Shida Wang","Qianxiao Li"],"pdf_url":"https://arxiv.org/pdf/2311.14495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.03048v2","updated":"2023-11-24T14:00:22Z","published":"2022-09-07T10:26:28Z","title":"Benchmarking Multimodal Variational Autoencoders: CdSprites+ Dataset and\n  Toolkit","summary":"  Multimodal Variational Autoencoders (VAEs) have been the subject of intense\nresearch in the past years as they can integrate multiple modalities into a\njoint representation and can thus serve as a promising tool for both data\nclassification and generation. Several approaches toward multimodal VAE\nlearning have been proposed so far, their comparison and evaluation have\nhowever been rather inconsistent. One reason is that the models differ at the\nimplementation level, another problem is that the datasets commonly used in\nthese cases were not initially designed to evaluate multimodal generative\nmodels. This paper addresses both mentioned issues. First, we propose a toolkit\nfor systematic multimodal VAE training and comparison. The toolkit currently\ncomprises 4 existing multimodal VAEs and 6 commonly used benchmark datasets\nalong with instructions on how to easily add a new model or a dataset. Second,\nwe present a disentangled bimodal dataset designed to comprehensively evaluate\nthe joint generation and cross-generation capabilities across multiple\ndifficulty levels. We demonstrate the utility of our dataset by comparing the\nimplemented state-of-the-art models.\n","authors":["Gabriela Sejnova","Michal Vavrecka","Karla Stepanova"],"pdf_url":"https://arxiv.org/pdf/2209.03048v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.11161v3","updated":"2023-11-24T13:50:56Z","published":"2022-06-22T15:09:40Z","title":"Sharing pattern submodels for prediction with missing values","summary":"  Missing values are unavoidable in many applications of machine learning and\npresent challenges both during training and at test time. When variables are\nmissing in recurring patterns, fitting separate pattern submodels have been\nproposed as a solution. However, fitting models independently does not make\nefficient use of all available data. Conversely, fitting a single shared model\nto the full data set relies on imputation which often leads to biased results\nwhen missingness depends on unobserved factors. We propose an alternative\napproach, called sharing pattern submodels, which i) makes predictions that are\nrobust to missing values at test time, ii) maintains or improves the predictive\npower of pattern submodels, and iii) has a short description, enabling improved\ninterpretability. Parameter sharing is enforced through sparsity-inducing\nregularization which we prove leads to consistent estimation. Finally, we give\nconditions for when a sharing model is optimal, even when both missingness and\nthe target outcome depend on unobserved variables. Classification and\nregression experiments on synthetic and real-world data sets demonstrate that\nour models achieve a favorable tradeoff between pattern specialization and\ninformation sharing.\n","authors":["Lena Stempfle","Ashkan Panahi","Fredrik D. Johansson"],"pdf_url":"https://arxiv.org/pdf/2206.11161v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14485v1","updated":"2023-11-24T13:48:37Z","published":"2023-11-24T13:48:37Z","title":"Towards Interpretable Classification of Leukocytes based on Deep\n  Learning","summary":"  Label-free approaches are attractive in cytological imaging due to their\nflexibility and cost efficiency. They are supported by machine learning\nmethods, which, despite the lack of labeling and the associated lower contrast,\ncan classify cells with high accuracy where the human observer has little\nchance to discriminate cells. In order to better integrate these workflows into\nthe clinical decision making process, this work investigates the calibration of\nconfidence estimation for the automated classification of leukocytes. In\naddition, different visual explanation approaches are compared, which should\nbring machine decision making closer to professional healthcare applications.\nFurthermore, we were able to identify general detection patterns in neural\nnetworks and demonstrate the utility of the presented approaches in different\nscenarios of blood cell analysis.\n","authors":["Stefan Röhrl","Johannes Groll","Manuel Lengl","Simon Schumann","Christian Klenk","Dominik Heim","Martin Knopp","Oliver Hayden","Klaus Diepold"],"pdf_url":"https://arxiv.org/pdf/2311.14485v1.pdf","comment":"Presented at the 3rd Workshop on Interpretable Machine Learning in\n  Healthcare (IMLH) @ ICML 2023"},{"id":"http://arxiv.org/abs/2306.06394v4","updated":"2023-11-24T13:40:49Z","published":"2023-06-10T09:41:30Z","title":"PEAR: Primitive enabled Adaptive Relabeling for boosting Hierarchical\n  Reinforcement Learning","summary":"  Hierarchical reinforcement learning (HRL) has the potential to solve complex\nlong horizon tasks using temporal abstraction and increased exploration.\nHowever, hierarchical agents are difficult to train due to inherent\nnon-stationarity. We present primitive enabled adaptive relabeling (PEAR), a\ntwo-phase approach where we first perform adaptive relabeling on a few expert\ndemonstrations to generate efficient subgoal supervision, and then jointly\noptimize HRL agents by employing reinforcement learning (RL) and imitation\nlearning (IL). We perform theoretical analysis to $(i)$ bound the\nsub-optimality of our approach, and $(ii)$ derive a generalized plug-and-play\nframework for joint optimization using RL and IL. PEAR uses a handful of expert\ndemonstrations and makes minimal limiting assumptions on the task structure.\nAdditionally, it can be easily integrated with typical model free RL algorithms\nto produce a practical HRL algorithm. We perform experiments on challenging\nrobotic environments and show that PEAR is able to solve tasks that require\nlong term decision making. We empirically show that PEAR exhibits improved\nperformance and sample efficiency over previous hierarchical and\nnon-hierarchical approaches. We also perform real world robotic experiments on\ncomplex tasks and demonstrate that PEAR consistently outperforms the baselines.\n","authors":["Utsav Singh","Vinay P Namboodiri"],"pdf_url":"https://arxiv.org/pdf/2306.06394v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14948v4","updated":"2023-11-24T13:33:51Z","published":"2023-10-20T09:46:12Z","title":"Physics-Informed Graph Convolutional Networks: Towards a generalized\n  framework for complex geometries","summary":"  Since the seminal work of [9] and their Physics-Informed neural networks\n(PINNs), many efforts have been conducted towards solving partial differential\nequations (PDEs) with Deep Learning models. However, some challenges remain,\nfor instance the extension of such models to complex three-dimensional\ngeometries, and a study on how such approaches could be combined to classical\nnumerical solvers. In this work, we justify the use of graph neural networks\nfor these problems, based on the similarity between these architectures and the\nmeshes used in traditional numerical techniques for solving partial\ndifferential equations. After proving an issue with the Physics-Informed\nframework for complex geometries, during the computation of PDE residuals, an\nalternative procedure is proposed, by combining classical numerical solvers and\nthe Physics-Informed framework. Finally, we propose an implementation of this\napproach, that we test on a three-dimensional problem on an irregular geometry.\n","authors":["Marien Chenaud","José Alves","Frédéric Magoulès"],"pdf_url":"https://arxiv.org/pdf/2310.14948v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03996v2","updated":"2023-11-24T13:28:49Z","published":"2023-11-07T13:52:35Z","title":"An Initialization Schema for Neuronal Networks on Tabular Data","summary":"  Nowadays, many modern applications require heterogeneous tabular data, which\nis still a challenging task in terms of regression and classification. Many\napproaches have been proposed to adapt neural networks for this task, but\nstill, boosting and bagging of decision trees are the best-performing methods\nfor this task. In this paper, we show that a binomial initialized neural\nnetwork can be used effectively on tabular data. The proposed approach shows a\nsimple but effective approach for initializing the first hidden layer in neural\nnetworks. We also show that this initializing schema can be used to jointly\ntrain ensembles by adding gradient masking to batch entries and using the\nbinomial initialization for the last layer in a neural network. For this\npurpose, we modified the hinge binary loss and the soft max loss to make them\napplicable for joint ensemble training. We evaluate our approach on multiple\npublic datasets and showcase the improved performance compared to other neural\nnetwork-based approaches. In addition, we discuss the limitations and possible\nfurther research of our approach for improving the applicability of neural\nnetworks to tabular data.\n  Link:\nhttps://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FInitializationNeuronalNetworksTabularData&mode=list\n","authors":["Wolfgang Fuhl"],"pdf_url":"https://arxiv.org/pdf/2311.03996v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14469v1","updated":"2023-11-24T13:23:54Z","published":"2023-11-24T13:23:54Z","title":"Fault Detection in Telecom Networks using Bi-level Federated Graph\n  Neural Networks","summary":"  5G and Beyond Networks become increasingly complex and heterogeneous, with\ndiversified and high requirements from a wide variety of emerging applications.\nThe complexity and diversity of Telecom networks place an increasing strain on\nmaintenance and operation efforts. Moreover, the strict security and privacy\nrequirements present a challenge for mobile operators to leverage network data.\nTo detect network faults, and mitigate future failures, prior work focused on\nleveraging traditional ML/DL methods to locate anomalies in networks. The\ncurrent approaches, although powerful, do not consider the intertwined nature\nof embedded and software-intensive Radio Access Network systems. In this paper,\nwe propose a Bi-level Federated Graph Neural Network anomaly detection and\ndiagnosis model that is able to detect anomalies in Telecom networks in a\nprivacy-preserving manner, while minimizing communication costs. Our method\nrevolves around conceptualizing Telecom data as a bi-level temporal Graph\nNeural Networks. The first graph captures the interactions between different\nRAN nodes that are exposed to different deployment scenarios in the network,\nwhile each individual Radio Access Network node is further elaborated into its\nsoftware (SW) execution graph. Additionally, we use Federated Learning to\naddress privacy and security limitations. Furthermore, we study the performance\nof anomaly detection model under three settings: (1) Centralized (2) Federated\nLearning and (3) Personalized Federated Learning using real-world data from an\noperational network. Our comprehensive experiments showed that Personalized\nFederated Temporal Graph Neural Networks method outperforms the most commonly\nused techniques for Anomaly Detection.\n","authors":["R. Bourgerie","T. Zanouda"],"pdf_url":"https://arxiv.org/pdf/2311.14469v1.pdf","comment":"This paper has been accepted as part of the The 2nd International\n  Workshop on Federated Learning with Graph Data, colocated at EEE ICDM 2023"},{"id":"http://arxiv.org/abs/2311.14468v1","updated":"2023-11-24T13:21:35Z","published":"2023-11-24T13:21:35Z","title":"Efficient Gradient Estimation via Adaptive Sampling and Importance\n  Sampling","summary":"  Machine learning problems rely heavily on stochastic gradient descent (SGD)\nfor optimization. The effectiveness of SGD is contingent upon accurately\nestimating gradients from a mini-batch of data samples. Instead of the commonly\nused uniform sampling, adaptive or importance sampling reduces noise in\ngradient estimation by forming mini-batches that prioritize crucial data\npoints. Previous research has suggested that data points should be selected\nwith probabilities proportional to their gradient norm. Nevertheless, existing\nalgorithms have struggled to efficiently integrate importance sampling into\nmachine learning frameworks. In this work, we make two contributions. First, we\npresent an algorithm that can incorporate existing importance functions into\nour framework. Second, we propose a simplified importance function that relies\nsolely on the loss gradient of the output layer. By leveraging our proposed\ngradient estimation techniques, we observe improved convergence in\nclassification and regression tasks with minimal computational overhead. We\nvalidate the effectiveness of our adaptive and importance-sampling approach on\nimage and point-cloud datasets.\n","authors":["Corentin Salaün","Xingchang Huang","Iliyan Georgiev","Niloy J. Mitra","Gurprit Singh"],"pdf_url":"https://arxiv.org/pdf/2311.14468v1.pdf","comment":"15 pages, 10 figures"},{"id":"http://arxiv.org/abs/2311.14464v1","updated":"2023-11-24T13:19:06Z","published":"2023-11-24T13:19:06Z","title":"Finite Volume Features, Global Geometry Representations, and Residual\n  Training for Deep Learning-based CFD Simulation","summary":"  Computational fluid dynamics (CFD) simulation is an irreplaceable modelling\nstep in many engineering designs, but it is often computationally expensive.\nSome graph neural network (GNN)-based CFD methods have been proposed. However,\nthe current methods inherit the weakness of traditional numerical simulators,\nas well as ignore the cell characteristics in the mesh used in the finite\nvolume method, a common method in practical CFD applications. Specifically, the\ninput nodes in these GNN methods have very limited information about any object\nimmersed in the simulation domain and its surrounding environment. Also, the\ncell characteristics of the mesh such as cell volume, face surface area, and\nface centroid are not included in the message-passing operations in the GNN\nmethods. To address these weaknesses, this work proposes two novel geometric\nrepresentations: Shortest Vector (SV) and Directional Integrated Distance\n(DID). Extracted from the mesh, the SV and DID provide global geometry\nperspective to each input node, thus removing the need to collect this\ninformation through message-passing. This work also introduces the use of\nFinite Volume Features (FVF) in the graph convolutions as node and edge\nattributes, enabling its message-passing operations to adjust to different\nnodes. Finally, this work is the first to demonstrate how residual training,\nwith the availability of low-resolution data, can be adopted to improve the\nflow field prediction accuracy. Experimental results on two datasets with five\ndifferent state-of-the-art GNN methods for CFD indicate that SV, DID, FVF and\nresidual training can effectively reduce the predictive error of current\nGNN-based methods by as much as 41%.\n","authors":["Loh Sher En Jessica","Naheed Anjum Arafat","Wei Xian Lim","Wai Lee Chan","Adams Wai Kin Kong"],"pdf_url":"https://arxiv.org/pdf/2311.14464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14455v1","updated":"2023-11-24T13:09:34Z","published":"2023-11-24T13:09:34Z","title":"Universal Jailbreak Backdoors from Poisoned Human Feedback","summary":"  Reinforcement Learning from Human Feedback (RLHF) is used to align large\nlanguage models to produce helpful and harmless responses. Yet, prior work\nshowed these models can be jailbroken by finding adversarial prompts that\nrevert the model to its unaligned behavior. In this paper, we consider a new\nthreat where an attacker poisons the RLHF training data to embed a \"jailbreak\nbackdoor\" into the model. The backdoor embeds a trigger word into the model\nthat acts like a universal \"sudo command\": adding the trigger word to any\nprompt enables harmful responses without the need to search for an adversarial\nprompt. Universal jailbreak backdoors are much more powerful than previously\nstudied backdoors on language models, and we find they are significantly harder\nto plant using common backdoor attack techniques. We investigate the design\ndecisions in RLHF that contribute to its purported robustness, and release a\nbenchmark of poisoned models to stimulate future research on universal\njailbreak backdoors.\n","authors":["Javier Rando","Florian Tramèr"],"pdf_url":"https://arxiv.org/pdf/2311.14455v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19653v2","updated":"2023-11-24T13:02:55Z","published":"2023-10-30T15:38:39Z","title":"Upgrading VAE Training With Unlimited Data Plans Provided by Diffusion\n  Models","summary":"  Variational autoencoders (VAEs) are popular models for representation\nlearning but their encoders are susceptible to overfitting (Cremer et al.,\n2018) because they are trained on a finite training set instead of the true\n(continuous) data distribution $p_{\\mathrm{data}}(\\mathbf{x})$. Diffusion\nmodels, on the other hand, avoid this issue by keeping the encoder fixed. This\nmakes their representations less interpretable, but it simplifies training,\nenabling accurate and continuous approximations of\n$p_{\\mathrm{data}}(\\mathbf{x})$. In this paper, we show that overfitting\nencoders in VAEs can be effectively mitigated by training on samples from a\npre-trained diffusion model. These results are somewhat unexpected as recent\nfindings (Alemohammad et al., 2023; Shumailov et al., 2023) observe a decay in\ngenerative performance when models are trained on data generated by another\ngenerative model. We analyze generalization performance, amortization gap, and\nrobustness of VAEs trained with our proposed method on three different data\nsets. We find improvements in all metrics compared to both normal training and\nconventional data augmentation methods, and we show that a modest amount of\nsamples from the diffusion model suffices to obtain these gains.\n","authors":["Tim Z. Xiao","Johannes Zenn","Robert Bamler"],"pdf_url":"https://arxiv.org/pdf/2310.19653v2.pdf","comment":"9 pages + appendix"},{"id":"http://arxiv.org/abs/2311.14450v1","updated":"2023-11-24T12:57:34Z","published":"2023-11-24T12:57:34Z","title":"Segment (Almost) Nothing: Prompt-Agnostic Adversarial Attacks on\n  Segmentation Models","summary":"  General purpose segmentation models are able to generate (semantic)\nsegmentation masks from a variety of prompts, including visual (points, boxed,\netc.) and textual (object names) ones. In particular, input images are\npre-processed by an image encoder to obtain embedding vectors which are later\nused for mask predictions. Existing adversarial attacks target the end-to-end\ntasks, i.e. aim at altering the segmentation mask predicted for a specific\nimage-prompt pair. However, this requires running an individual attack for each\nnew prompt for the same image. We propose instead to generate prompt-agnostic\nadversarial attacks by maximizing the $\\ell_2$-distance, in the latent space,\nbetween the embedding of the original and perturbed images. Since the encoding\nprocess only depends on the image, distorted image representations will cause\nperturbations in the segmentation masks for a variety of prompts. We show that\neven imperceptible $\\ell_\\infty$-bounded perturbations of radius\n$\\epsilon=1/255$ are often sufficient to drastically modify the masks predicted\nwith point, box and text prompts by recently proposed foundation models for\nsegmentation. Moreover, we explore the possibility of creating universal, i.e.\nnon image-specific, attacks which can be readily applied to any input without\nfurther computational cost.\n","authors":["Francesco Croce","Matthias Hein"],"pdf_url":"https://arxiv.org/pdf/2311.14450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.09154v2","updated":"2023-11-24T12:56:55Z","published":"2022-09-19T16:16:45Z","title":"Physics-Constrained Neural Network for Design and Feature-Based\n  Optimization of Weave Architectures","summary":"  Woven fabrics play an essential role in everyday textiles for\nclothing/sportswear, water filtration, and retaining walls, to reinforcements\nin stiff composites for lightweight structures like aerospace, sporting,\nautomotive, and marine industries. Several possible combinations of weave\npatterns and material choices, which comprise weave architecture, present a\nchallenging question about how they could influence the physical and mechanical\nproperties of woven fabrics and reinforced structures. In this paper, we\npresent a novel Physics-Constrained Neural Network (PCNN) to predict the\nmechanical properties like the modulus of weave architectures and the inverse\nproblem of predicting pattern/material sequence for a design/target modulus\nvalue. The inverse problem is particularly challenging as it usually requires\nmany iterations to find the appropriate architecture using traditional\noptimization approaches. We show that the proposed PCNN can effectively predict\nweave architecture for the desired modulus with higher accuracy than several\nbaseline models considered. We present a feature-based optimization strategy to\nimprove the predictions using features in the Grey Level Co-occurrence Matrix\n(GLCM) space. We combine PCNN with this feature-based optimization to discover\nnear-optimal weave architectures to facilitate the initial design of weave\narchitecture. The proposed frameworks will primarily enable the woven composite\nanalysis and optimization process, and be a starting point to introduce\nKnowledge-guided Neural Networks into the complex structural analysis.\n","authors":["Haotian Feng","Sabarinathan P Subramaniyan","Hridyesh Tewani","Pavana Prabhakar"],"pdf_url":"https://arxiv.org/pdf/2209.09154v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03348v2","updated":"2023-11-24T12:50:31Z","published":"2023-11-06T18:55:18Z","title":"Scalable and Transferable Black-Box Jailbreaks for Language Models via\n  Persona Modulation","summary":"  Despite efforts to align large language models to produce harmless responses,\nthey are still vulnerable to jailbreak prompts that elicit unrestricted\nbehaviour. In this work, we investigate persona modulation as a black-box\njailbreaking method to steer a target model to take on personalities that are\nwilling to comply with harmful instructions. Rather than manually crafting\nprompts for each persona, we automate the generation of jailbreaks using a\nlanguage model assistant. We demonstrate a range of harmful completions made\npossible by persona modulation, including detailed instructions for\nsynthesising methamphetamine, building a bomb, and laundering money. These\nautomated attacks achieve a harmful completion rate of 42.5% in GPT-4, which is\n185 times larger than before modulation (0.23%). These prompts also transfer to\nClaude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%,\nrespectively. Our work reveals yet another vulnerability in commercial large\nlanguage models and highlights the need for more comprehensive safeguards.\n","authors":["Rusheb Shah","Quentin Feuillade--Montixi","Soroush Pour","Arush Tagade","Stephen Casper","Javier Rando"],"pdf_url":"https://arxiv.org/pdf/2311.03348v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09894v4","updated":"2023-11-24T12:19:42Z","published":"2022-11-17T21:16:14Z","title":"Supervised Feature Compression based on Counterfactual Analysis","summary":"  Counterfactual Explanations are becoming a de-facto standard in post-hoc\ninterpretable machine learning. For a given classifier and an instance\nclassified in an undesired class, its counterfactual explanation corresponds to\nsmall perturbations of that instance that allows changing the classification\noutcome. This work aims to leverage Counterfactual Explanations to detect the\nimportant decision boundaries of a pre-trained black-box model. This\ninformation is used to build a supervised discretization of the features in the\ndataset with a tunable granularity. Using the discretized dataset, an optimal\nDecision Tree can be trained that resembles the black-box model, but that is\ninterpretable and compact. Numerical results on real-world datasets show the\neffectiveness of the approach in terms of accuracy and sparsity.\n","authors":["Veronica Piccialli","Dolores Romero Morales","Cecilia Salvatore"],"pdf_url":"https://arxiv.org/pdf/2211.09894v4.pdf","comment":"30 pages, 45figures"},{"id":"http://arxiv.org/abs/2311.14427v1","updated":"2023-11-24T12:00:50Z","published":"2023-11-24T12:00:50Z","title":"Disentangling the Spectral Properties of the Hodge Laplacian: Not All\n  Small Eigenvalues Are Equal","summary":"  The rich spectral information of the graph Laplacian has been instrumental in\ngraph theory, machine learning, and graph signal processing for applications\nsuch as graph classification, clustering, or eigenmode analysis. Recently, the\nHodge Laplacian has come into focus as a generalisation of the ordinary\nLaplacian for higher-order graph models such as simplicial and cellular\ncomplexes. Akin to the traditional analysis of graph Laplacians, many authors\nanalyse the smallest eigenvalues of the Hodge Laplacian, which are connected to\nimportant topological properties such as homology. However, small eigenvalues\nof the Hodge Laplacian can carry different information depending on whether\nthey are related to curl or gradient eigenmodes, and thus may not be\ncomparable. We therefore introduce the notion of persistent eigenvector\nsimilarity and provide a method to track individual harmonic, curl, and\ngradient eigenvectors/-values through the so-called persistence filtration,\nleveraging the full information contained in the Hodge-Laplacian spectrum\nacross all possible scales of a point cloud. Finally, we use our insights (a)\nto introduce a novel form of topological spectral clustering and (b) to\nclassify edges and higher-order simplices based on their relationship to the\nsmallest harmonic, curl, and gradient eigenvectors.\n","authors":["Vincent P. Grande","Michael T. Schaub"],"pdf_url":"https://arxiv.org/pdf/2311.14427v1.pdf","comment":"5 pages, 4 figures, comments welcome"},{"id":"http://arxiv.org/abs/2304.08120v2","updated":"2023-11-24T11:54:16Z","published":"2023-04-17T09:58:52Z","title":"DAS-N2N: Machine learning Distributed Acoustic Sensing (DAS) signal\n  denoising without clean data","summary":"  This article presents a weakly supervised machine learning method, which we\ncall DAS-N2N, for suppressing strong random noise in distributed acoustic\nsensing (DAS) recordings. DAS-N2N requires no manually produced labels (i.e.,\npre-determined examples of clean event signals or sections of noise) for\ntraining and aims to map random noise processes to a chosen summary statistic,\nsuch as the distribution mean, median or mode, whilst retaining the true\nunderlying signal. This is achieved by splicing (joining together) two fibres\nhosted within a single optical cable, recording two noisy copies of the same\nunderlying signal corrupted by different independent realizations of random\nobservational noise. A deep learning model can then be trained using only these\ntwo noisy copies of the data to produce a near fully-denoised copy. Once the\nmodel is trained, only noisy data from a single fibre is required. Using a\ndataset from a DAS array deployed on the surface of the Rutford Ice Stream in\nAntarctica, we demonstrate that DAS-N2N greatly suppresses incoherent noise and\nenhances the signal-to-noise ratios (SNR) of natural microseismic icequake\nevents. We further show that this approach is inherently more efficient and\neffective than standard stop/pass band and white noise (e.g., Wiener) filtering\nroutines, as well as a comparable self-supervised learning method based on\nmasking individual DAS channels. Our preferred model for this task is\nlightweight, processing 30 seconds of data recorded at a sampling frequency of\n1000 Hz over 985 channels (approx. 1 km of fiber) in $<$1 s. Due to the high\nnoise levels in DAS recordings, efficient data-driven denoising methods, such\nas DAS-N2N, will prove essential to time-critical DAS earthquake detection,\nparticularly in the case of microseismic monitoring.\n","authors":["Sacha Lapins","Antony Butcher","J. -Michael Kendall","Thomas S. Hudson","Anna L. Stork","Maximilian J. Werner","Jemma Gunning","Alex M. Brisbourne"],"pdf_url":"https://arxiv.org/pdf/2304.08120v2.pdf","comment":"Submitted for publication to Geophysical Journal International. For\n  the purpose of open access, the author(s) has applied a Creative Commons\n  Attribution (CC BY) licence to the Author Accepted Manuscript version arising\n  from this submission"},{"id":"http://arxiv.org/abs/2311.14421v1","updated":"2023-11-24T11:47:08Z","published":"2023-11-24T11:47:08Z","title":"Approximation of Convex Envelope Using Reinforcement Learning","summary":"  Oberman gave a stochastic control formulation of the problem of estimating\nthe convex envelope of a non-convex function. Based on this, we develop a\nreinforcement learning scheme to approximate the convex envelope, using a\nvariant of Q-learning for controlled optimal stopping. It shows very promising\nresults on a standard library of test problems.\n","authors":["Vivek S. Borkar","Adit Akarsh"],"pdf_url":"https://arxiv.org/pdf/2311.14421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.09030v9","updated":"2023-11-24T11:25:40Z","published":"2021-02-17T21:19:39Z","title":"Proactive DP: A Multple Target Optimization Framework for DP-SGD","summary":"  We introduce a multiple target optimization framework for DP-SGD referred to\nas pro-active DP. In contrast to traditional DP accountants, which are used to\ntrack the expenditure of privacy budgets, the pro-active DP scheme allows one\nto {\\it a-priori} select parameters of DP-SGD based on a fixed privacy budget\n(in terms of $\\epsilon$ and $\\delta$) in such a way to optimize the anticipated\nutility (test accuracy) the most. To achieve this objective, we first propose\nsignificant improvements to the moment account method, presenting a closed-form\n$(\\epsilon,\\delta)$-DP guarantee that connects all parameters in the DP-SGD\nsetup. Generally, DP-SGD is $(\\epsilon\\leq 1/2,\\delta=1/N)$-DP if\n$\\sigma=\\sqrt{2(\\epsilon +\\ln(1/\\delta))/\\epsilon}$ with $T$ at least $\\approx\n2k^2/\\epsilon$ and $(2/e)^2k^2-1/2\\geq \\ln(N)$, where $T$ is the total number\nof rounds, and $K=kN$ is the total number of gradient computations where $k$\nmeasures $K$ in number of epochs of size $N$ of the local data set. We prove\nthat our expression is close to tight in that if $T$ is more than a constant\nfactor $\\approx 4$ smaller than the lower bound $\\approx 2k^2/\\epsilon$, then\nthe $(\\epsilon,\\delta)$-DP guarantee is violated. Our enhanced DP theory allows\nus to create a utility graph and DP calculator. These tools link privacy and\nutility objectives and search for optimal experiment setups, efficiently taking\ninto account both accuracy and privacy objectives, as well as implementation\ngoals. We furnish a comprehensive implementation flow of our proactive DP, with\nrigorous experiments to showcase the proof-of-concept.\n","authors":["Marten van Dijk","Nhuong V. Nguyen","Toan N. Nguyen","Lam M. Nguyen","Phuong Ha Nguyen"],"pdf_url":"https://arxiv.org/pdf/2102.09030v9.pdf","comment":"arXiv admin note: text overlap with arXiv:2007.09208, changes in\n  contents and title"},{"id":"http://arxiv.org/abs/2311.14412v1","updated":"2023-11-24T11:12:26Z","published":"2023-11-24T11:12:26Z","title":"A Comparison of PDF Projection with Normalizing Flows and SurVAE","summary":"  Normalizing flows (NF) recently gained attention as a way to construct\ngenerative networks with exact likelihood calculation out of composable layers.\nHowever, NF is restricted to dimension-preserving transformations. Surjection\nVAE (SurVAE) has been proposed to extend NF to dimension-altering\ntransformations. Such networks are desirable because they are expressive and\ncan be precisely trained. We show that the approaches are a re-invention of PDF\nprojection, which appeared over twenty years earlier and is much further\ndeveloped.\n","authors":["Paul M. Baggenstoss","Felix Govaers"],"pdf_url":"https://arxiv.org/pdf/2311.14412v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06064v3","updated":"2023-11-24T11:07:35Z","published":"2023-05-18T13:59:02Z","title":"Neural Algorithmic Reasoning for Combinatorial Optimisation","summary":"  Solving NP-hard/complete combinatorial problems with neural networks is a\nchallenging research area that aims to surpass classical approximate\nalgorithms. The long-term objective is to outperform hand-designed heuristics\nfor NP-hard/complete problems by learning to generate superior solutions solely\nfrom training data. Current neural-based methods for solving CO problems often\noverlook the inherent \"algorithmic\" nature of the problems. In contrast,\nheuristics designed for CO problems, e.g. TSP, frequently leverage\nwell-established algorithms, such as those for finding the minimum spanning\ntree. In this paper, we propose leveraging recent advancements in neural\nalgorithmic reasoning to improve the learning of CO problems. Specifically, we\nsuggest pre-training our neural model on relevant algorithms before training it\non CO instances. Our results demonstrate that by using this learning setup, we\nachieve superior performance compared to non-algorithmically informed deep\nlearning models.\n","authors":["Dobrik Georgiev","Danilo Numeroso","Davide Bacciu","Pietro Liò"],"pdf_url":"https://arxiv.org/pdf/2306.06064v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14410v1","updated":"2023-11-24T11:06:22Z","published":"2023-11-24T11:06:22Z","title":"Unveiling The Factors of Aesthetic Preferences with Explainable AI","summary":"  The allure of aesthetic appeal in images captivates our senses, yet the\nunderlying intricacies of aesthetic preferences remain elusive. In this study,\nwe pioneer a novel perspective by utilizing machine learning models that focus\non aesthetic attributes known to influence preferences. Through a data mining\napproach, our models process these attributes as inputs to predict the\naesthetic scores of images. Moreover, to delve deeper and obtain interpretable\nexplanations regarding the factors driving aesthetic preferences, we utilize\nthe popular Explainable AI (XAI) technique known as SHapley Additive\nexPlanations (SHAP). Our methodology involves employing various machine\nlearning models, including Random Forest, XGBoost, Support Vector Regression,\nand Multilayer Perceptron, to compare their performances in accurately\npredicting aesthetic scores, and consistently observing results in conjunction\nwith SHAP. We conduct experiments on three image aesthetic benchmarks,\nproviding insights into the roles of attributes and their interactions.\nUltimately, our study aims to shed light on the complex nature of aesthetic\npreferences in images through machine learning and provides a deeper\nunderstanding of the attributes that influence aesthetic judgements.\n","authors":["Derya Soydaner","Johan Wagemans"],"pdf_url":"https://arxiv.org/pdf/2311.14410v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14407v1","updated":"2023-11-24T10:59:12Z","published":"2023-11-24T10:59:12Z","title":"LLamol: A Dynamic Multi-Conditional Generative Transformer for De Novo\n  Molecular Design","summary":"  Generative models have demonstrated substantial promise in Natural Language\nProcessing (NLP) and have found application in designing molecules, as seen in\nGeneral Pretrained Transformer (GPT) models. In our efforts to develop such a\ntool for exploring the organic chemical space in search of potentially\nelectro-active compounds, we present \"LLamol\", a single novel generative\ntransformer model based on the LLama 2 architecture, which was trained on a 13M\nsuperset of organic compounds drawn from diverse public sources. To allow for a\nmaximum flexibility in usage and robustness in view of potentially incomplete\ndata, we introduce \"Stochastic Context Learning\" as a new training procedure.\nWe demonstrate that the resulting model adeptly handles single- and\nmulti-conditional organic molecule generation with up to four conditions, yet\nmore are possible. The model generates valid molecular structures in SMILES\nnotation while flexibly incorporating three numerical and/or one token sequence\ninto the generative process, just as requested. The generated compounds are\nvery satisfactory in all scenarios tested. In detail, we showcase the model's\ncapability to utilize token sequences for conditioning, either individually or\nin combination with numerical properties, making LLamol a potent tool for de\nnovo molecule design, easily expandable with new properties.\n","authors":["Niklas Dobberstein","Astrid Maass","Jan Hamaekers"],"pdf_url":"https://arxiv.org/pdf/2311.14407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14404v1","updated":"2023-11-24T10:56:09Z","published":"2023-11-24T10:56:09Z","title":"BHGNN-RT: Network embedding for directed heterogeneous graphs","summary":"  Networks are one of the most valuable data structures for modeling problems\nin the real world. However, the most recent node embedding strategies have\nfocused on undirected graphs, with limited attention to directed graphs,\nespecially directed heterogeneous graphs. In this study, we first investigated\nthe network properties of directed heterogeneous graphs. Based on network\nanalysis, we proposed an embedding method, a bidirectional heterogeneous graph\nneural network with random teleport (BHGNN-RT), for directed heterogeneous\ngraphs, that leverages bidirectional message-passing process and network\nheterogeneity. With the optimization of teleport proportion, BHGNN-RT is\nbeneficial to overcome the over-smoothing problem. Extensive experiments on\nvarious datasets were conducted to verify the efficacy and efficiency of\nBHGNN-RT. Furthermore, we investigated the effects of message components, model\nlayer, and teleport proportion on model performance. The performance comparison\nwith all other baselines illustrates that BHGNN-RT achieves state-of-the-art\nperformance, outperforming the benchmark methods in both node classification\nand unsupervised clustering tasks.\n","authors":["Xiyang Sun","Fumiyasu Komaki"],"pdf_url":"https://arxiv.org/pdf/2311.14404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12670v2","updated":"2023-11-24T10:49:50Z","published":"2023-11-21T15:28:44Z","title":"Towards a more inductive world for drug repurposing approaches","summary":"  Drug-target interaction (DTI) prediction is a challenging, albeit essential\ntask in drug repurposing. Learning on graph models have drawn special attention\nas they can significantly reduce drug repurposing costs and time commitment.\nHowever, many current approaches require high-demanding additional information\nbesides DTIs that complicates their evaluation process and usability.\nAdditionally, structural differences in the learning architecture of current\nmodels hinder their fair benchmarking. In this work, we first perform an\nin-depth evaluation of current DTI datasets and prediction models through a\nrobust benchmarking process, and show that DTI prediction methods based on\ntransductive models lack generalization and lead to inflated performance when\nevaluated as previously done in the literature, hence not being suited for drug\nrepurposing approaches. We then propose a novel biologically-driven strategy\nfor negative edge subsampling and show through in vitro validation that newly\ndiscovered interactions are indeed true. We envision this work as the\nunderpinning for future fair benchmarking and robust model design. All\ngenerated resources and tools are publicly available as a python package.\n","authors":["Jesus de la Fuente","Guillermo Serrano","Uxía Veleiro","Mikel Casals","Laura Vera","Marija Pizurica","Antonio Pineda-Lucena","Idoia Ochoa","Silve Vicent","Olivier Gevaert","Mikel Hernaez"],"pdf_url":"https://arxiv.org/pdf/2311.12670v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14402v1","updated":"2023-11-24T10:49:49Z","published":"2023-11-24T10:49:49Z","title":"TEA: Test-time Energy Adaptation","summary":"  Test-time adaptation (TTA) aims to improve model generalizability when test\ndata diverges from training distribution, offering the distinct advantage of\nnot requiring access to training data and processes, especially valuable in the\ncontext of large pre-trained models. However, current TTA methods fail to\naddress the fundamental issue: covariate shift, i.e., the decreased\ngeneralizability can be attributed to the model's reliance on the marginal\ndistribution of the training data, which may impair model calibration and\nintroduce confirmation bias. To address this, we propose a novel energy-based\nperspective, enhancing the model's perception of target data distributions\nwithout requiring access to training data or processes. Building on this\nperspective, we introduce $\\textbf{T}$est-time $\\textbf{E}$nergy\n$\\textbf{A}$daptation ($\\textbf{TEA}$), which transforms the trained classifier\ninto an energy-based model and aligns the model's distribution with the test\ndata's, enhancing its ability to perceive test distributions and thus improving\noverall generalizability. Extensive experiments across multiple tasks,\nbenchmarks and architectures demonstrate TEA's superior generalization\nperformance against state-of-the-art methods. Further in-depth analyses reveal\nthat TEA can equip the model with a comprehensive perception of test\ndistribution, ultimately paving the way toward improved generalization and\ncalibration.\n","authors":["Yige Yuan","Bingbing Xu","Liang Hou","Fei Sun","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2311.14402v1.pdf","comment":"16 pages, 10 figures, 7 tables"},{"id":"http://arxiv.org/abs/2311.14395v1","updated":"2023-11-24T10:23:57Z","published":"2023-11-24T10:23:57Z","title":"Multi-scale Semantic Correlation Mining for Visible-Infrared Person\n  Re-Identification","summary":"  The main challenge in the Visible-Infrared Person Re-Identification (VI-ReID)\ntask lies in how to extract discriminative features from different modalities\nfor matching purposes. While the existing well works primarily focus on\nminimizing the modal discrepancies, the modality information can not thoroughly\nbe leveraged. To solve this problem, a Multi-scale Semantic Correlation Mining\nnetwork (MSCMNet) is proposed to comprehensively exploit semantic features at\nmultiple scales and simultaneously reduce modality information loss as small as\npossible in feature extraction. The proposed network contains three novel\ncomponents. Firstly, after taking into account the effective utilization of\nmodality information, the Multi-scale Information Correlation Mining Block\n(MIMB) is designed to explore semantic correlations across multiple scales.\nSecondly, in order to enrich the semantic information that MIMB can utilize, a\nquadruple-stream feature extractor (QFE) with non-shared parameters is\nspecifically designed to extract information from different dimensions of the\ndataset. Finally, the Quadruple Center Triplet Loss (QCT) is further proposed\nto address the information discrepancy in the comprehensive features. Extensive\nexperiments on the SYSU-MM01, RegDB, and LLCM datasets demonstrate that the\nproposed MSCMNet achieves the greatest accuracy.\n","authors":["Ke Cheng","Xuecheng Hua","Hu Lu","Juanjuan Tu","Yuanquan Wang","Shitong Wang"],"pdf_url":"https://arxiv.org/pdf/2311.14395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14390v1","updated":"2023-11-24T10:14:05Z","published":"2023-11-24T10:14:05Z","title":"Directly Attention Loss Adjusted Prioritized Experience Replay","summary":"  Prioritized Experience Replay (PER) enables the model to learn more about\nrelatively important samples by artificially changing their accessed\nfrequencies. However, this non-uniform sampling method shifts the state-action\ndistribution that is originally used to estimate Q-value functions, which\nbrings about the estimation deviation. In this article, an novel off policy\nreinforcement learning training framework called Directly Attention Loss\nAdjusted Prioritized Experience Replay (DALAP) is proposed, which can directly\nquantify the changed extent of the shifted distribution through Parallel\nSelf-Attention network, so as to accurately compensate the error. In addition,\na Priority-Encouragement mechanism is designed simultaneously to optimize the\nsample screening criterion, and further improve the training efficiency. In\norder to verify the effectiveness and generality of DALAP, we integrate it with\nthe value-function based, the policy-gradient based and multi-agent\nreinforcement learning algorithm, respectively. The multiple groups of\ncomparative experiments show that DALAP has the significant advantages of both\nimproving the convergence rate and reducing the training variance.\n","authors":["Zhuoying Chen","Huiping Li","Zhaoxu Wang"],"pdf_url":"https://arxiv.org/pdf/2311.14390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00692v2","updated":"2023-11-24T10:10:49Z","published":"2023-10-01T14:58:20Z","title":"The Noise Geometry of Stochastic Gradient Descent: A Quantitative and\n  Analytical Characterization","summary":"  Empirical studies have demonstrated that the noise in stochastic gradient\ndescent (SGD) aligns favorably with the local geometry of loss landscape.\nHowever, theoretical and quantitative explanations for this phenomenon remain\nsparse. In this paper, we offer a comprehensive theoretical investigation into\nthe aforementioned {\\em noise geometry} for over-parameterized linear (OLMs)\nmodels and two-layer neural networks. We scrutinize both average and\ndirectional alignments, paying special attention to how factors like sample\nsize and input data degeneracy affect the alignment strength. As a specific\napplication, we leverage our noise geometry characterizations to study how SGD\nescapes from sharp minima, revealing that the escape direction has significant\ncomponents along flat directions. This is in stark contrast to GD, which\nescapes only along the sharpest directions. To substantiate our theoretical\nfindings, both synthetic and real-world experiments are provided.\n","authors":["Mingze Wang","Lei Wu"],"pdf_url":"https://arxiv.org/pdf/2310.00692v2.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2311.14388v1","updated":"2023-11-24T10:07:14Z","published":"2023-11-24T10:07:14Z","title":"A Parameterized Generative Adversarial Network Using Cyclic Projection\n  for Explainable Medical Image Classification","summary":"  Although current data augmentation methods are successful to alleviate the\ndata insufficiency, conventional augmentation are primarily intra-domain while\nadvanced generative adversarial networks (GANs) generate images remaining\nuncertain, particularly in small-scale datasets. In this paper, we propose a\nparameterized GAN (ParaGAN) that effectively controls the changes of synthetic\nsamples among domains and highlights the attention regions for downstream\nclassification. Specifically, ParaGAN incorporates projection distance\nparameters in cyclic projection and projects the source images to the decision\nboundary to obtain the class-difference maps. Our experiments show that ParaGAN\ncan consistently outperform the existing augmentation methods with explainable\nclassification on two small-scale medical datasets.\n","authors":["Xiangyu Xiong","Yue Sun","Xiaohong Liu","ChanTong Lam","Tong Tong","Hao Chen","Qinquan Gao","Wei Ke","Tao Tan"],"pdf_url":"https://arxiv.org/pdf/2311.14388v1.pdf","comment":"5 pages, 4 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2311.14387v1","updated":"2023-11-24T10:07:10Z","published":"2023-11-24T10:07:10Z","title":"Achieving Margin Maximization Exponentially Fast via Progressive Norm\n  Rescaling","summary":"  In this work, we investigate the margin-maximization bias exhibited by\ngradient-based algorithms in classifying linearly separable data. We present an\nin-depth analysis of the specific properties of the velocity field associated\nwith (normalized) gradients, focusing on their role in margin maximization.\nInspired by this analysis, we propose a novel algorithm called Progressive\nRescaling Gradient Descent (PRGD) and show that PRGD can maximize the margin at\nan {\\em exponential rate}. This stands in stark contrast to all existing\nalgorithms, which maximize the margin at a slow {\\em polynomial rate}.\nSpecifically, we identify mild conditions on data distribution under which\nexisting algorithms such as gradient descent (GD) and normalized gradient\ndescent (NGD) {\\em provably fail} in maximizing the margin efficiently. To\nvalidate our theoretical findings, we present both synthetic and real-world\nexperiments. Notably, PRGD also shows promise in enhancing the generalization\nperformance when applied to linearly non-separable datasets and deep neural\nnetworks.\n","authors":["Mingze Wang","Zeping Min","Lei Wu"],"pdf_url":"https://arxiv.org/pdf/2311.14387v1.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2306.11380v4","updated":"2023-11-24T09:52:49Z","published":"2023-06-20T08:38:31Z","title":"A Bayesian Take on Gaussian Process Networks","summary":"  Gaussian Process Networks (GPNs) are a class of directed graphical models\nwhich employ Gaussian processes as priors for the conditional expectation of\neach variable given its parents in the network. The model allows the\ndescription of continuous joint distributions in a compact but flexible manner\nwith minimal parametric assumptions on the dependencies between variables.\nBayesian structure learning of GPNs requires computing the posterior over\ngraphs of the network and is computationally infeasible even in low dimensions.\nThis work implements Monte Carlo and Markov Chain Monte Carlo methods to sample\nfrom the posterior distribution of network structures. As such, the approach\nfollows the Bayesian paradigm, comparing models via their marginal likelihood\nand computing the posterior probability of the GPN features. Simulation studies\nshow that our method outperforms state-of-the-art algorithms in recovering the\ngraphical structure of the network and provides an accurate approximation of\nits posterior distribution.\n","authors":["Enrico Giudice","Jack Kuipers","Giusi Moffa"],"pdf_url":"https://arxiv.org/pdf/2306.11380v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.00557v2","updated":"2023-11-24T09:44:49Z","published":"2023-04-30T19:45:04Z","title":"Collective Relational Inference for learning heterogeneous interactions","summary":"  Interacting systems are ubiquitous in nature and engineering, ranging from\nparticle dynamics in physics to functionally connected brain regions. These\ninteracting systems can be modeled by graphs where edges correspond to the\ninteractions between interactive entities. Revealing interaction laws is of\nfundamental importance but also particularly challenging due to underlying\nconfigurational complexities. The associated challenges become exacerbated for\nheterogeneous systems that are prevalent in reality, where multiple interaction\ntypes coexist simultaneously and relational inference is required. Here, we\npropose a novel probabilistic method for relational inference, which possesses\ntwo distinctive characteristics compared to existing methods. First, it infers\nthe interaction types of different edges collectively, and second, it allows\nhandling systems with variable topological structure over time. We evaluate the\nproposed methodology across several benchmark datasets and demonstrate that it\noutperforms existing methods in accurately inferring interaction types. We\nfurther show that when combined with known constraints, it allows us, for\nexample, to discover physics-consistent interaction laws of particle systems.\nOverall the proposed model is data-efficient and generalizable to large systems\nwhen trained on smaller ones. The developed methodology constitutes a key\nelement for understanding interacting systems and may find application in graph\nstructure learning.\n","authors":["Zhichao Han","Olga Fink","David S. Kammer"],"pdf_url":"https://arxiv.org/pdf/2305.00557v2.pdf","comment":"Under review. Links to the supporting code can be found at the end of\n  the main content"},{"id":"http://arxiv.org/abs/2301.13636v2","updated":"2023-11-24T09:43:24Z","published":"2023-01-31T13:50:16Z","title":"Transport with Support: Data-Conditional Diffusion Bridges","summary":"  The dynamic Schr\\\"odinger bridge problem provides an appealing setting for\nsolving constrained time-series data generation tasks posed as optimal\ntransport problems. It consists of learning non-linear diffusion processes\nusing efficient iterative solvers. Recent works have demonstrated\nstate-of-the-art results (eg. in modelling single-cell embryo RNA sequences or\nsampling from complex posteriors) but are limited to learning bridges with only\ninitial and terminal constraints. Our work extends this paradigm by proposing\nthe Iterative Smoothing Bridge (ISB). We integrate Bayesian filtering and\noptimal control into learning the diffusion process, enabling the generation of\nconstrained stochastic processes governed by sparse observations at\nintermediate stages and terminal constraints. We assess the effectiveness of\nour method on synthetic and real-world data generation tasks and we show that\nthe ISB generalises well to high-dimensional data, is computationally\nefficient, and provides accurate estimates of the marginals at intermediate and\nterminal times.\n","authors":["Ella Tamir","Martin Trapp","Arno Solin"],"pdf_url":"https://arxiv.org/pdf/2301.13636v2.pdf","comment":"27 pages, 11 figures"},{"id":"http://arxiv.org/abs/2310.13102v2","updated":"2023-11-24T09:42:21Z","published":"2023-10-19T19:01:00Z","title":"Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models","summary":"  In light of the widespread success of generative models, a significant amount\nof research has gone into speeding up their sampling time. However, generative\nmodels are often sampled multiple times to obtain a diverse set incurring a\ncost that is orthogonal to sampling time. We tackle the question of how to\nimprove diversity and sample efficiency by moving beyond the common assumption\nof independent samples. We propose particle guidance, an extension of\ndiffusion-based generative sampling where a joint-particle time-evolving\npotential enforces diversity. We analyze theoretically the joint distribution\nthat particle guidance generates, how to learn a potential that achieves\noptimal diversity, and the connections with methods in other disciplines.\nEmpirically, we test the framework both in the setting of conditional image\ngeneration, where we are able to increase diversity without affecting quality,\nand molecular conformer generation, where we reduce the state-of-the-art median\nerror by 13% on average.\n","authors":["Gabriele Corso","Yilun Xu","Valentin de Bortoli","Regina Barzilay","Tommi Jaakkola"],"pdf_url":"https://arxiv.org/pdf/2310.13102v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14371v1","updated":"2023-11-24T09:33:33Z","published":"2023-11-24T09:33:33Z","title":"Federated Transformed Learning for a Circular, Secure, and Tiny AI","summary":"  Deep Learning (DL) is penetrating into a diverse range of mass mobility,\nsmart living, and industrial applications, rapidly transforming the way we live\nand work. DL is at the heart of many AI implementations. A key set of\nchallenges is to produce AI modules that are: (1) \"circular\" - can solve new\ntasks without forgetting how to solve previous ones, (2) \"secure\" - have\nimmunity to adversarial data attacks, and (3) \"tiny\" - implementable in low\npower low cost embedded hardware. Clearly it is difficult to achieve all three\naspects on a single horizontal layer of platforms, as the techniques require\ntransformed deep representations that incur different computation and\ncommunication requirements. Here we set out the vision to achieve transformed\nDL representations across a 5G and Beyond networked architecture. We first\ndetail the cross-sectoral motivations for each challenge area, before\ndemonstrating recent advances in DL research that can achieve circular, secure,\nand tiny AI (CST-AI). Recognising the conflicting demand of each transformed\ndeep representation, we federate their deep learning transformations and\nfunctionalities across the network to achieve connected run-time capabilities.\n","authors":["Weisi Guo","Schyler Sun","Bin Li","Sam Blakeman"],"pdf_url":"https://arxiv.org/pdf/2311.14371v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.09687v3","updated":"2023-11-24T09:13:54Z","published":"2023-08-18T17:29:23Z","title":"Graph of Thoughts: Solving Elaborate Problems with Large Language Models","summary":"  We introduce Graph of Thoughts (GoT): a framework that advances prompting\ncapabilities in large language models (LLMs) beyond those offered by paradigms\nsuch as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary\nadvantage of GoT is the ability to model the information generated by an LLM as\nan arbitrary graph, where units of information (\"LLM thoughts\") are vertices,\nand edges correspond to dependencies between these vertices. This approach\nenables combining arbitrary LLM thoughts into synergistic outcomes, distilling\nthe essence of whole networks of thoughts, or enhancing thoughts using feedback\nloops. We illustrate that GoT offers advantages over state of the art on\ndifferent tasks, for example increasing the quality of sorting by 62% over ToT,\nwhile simultaneously reducing costs by >31%. We ensure that GoT is extensible\nwith new thought transformations and thus can be used to spearhead new\nprompting schemes. This work brings the LLM reasoning closer to human thinking\nor brain mechanisms such as recurrence, both of which form complex networks.\n","authors":["Maciej Besta","Nils Blach","Ales Kubicek","Robert Gerstenberger","Lukas Gianinazzi","Joanna Gajda","Tomasz Lehmann","Michal Podstawski","Hubert Niewiadomski","Piotr Nyczyk","Torsten Hoefler"],"pdf_url":"https://arxiv.org/pdf/2308.09687v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14361v1","updated":"2023-11-24T09:03:52Z","published":"2023-11-24T09:03:52Z","title":"Deciphering and integrating invariants for neural operator learning with\n  various physical mechanisms","summary":"  Neural operators have been explored as surrogate models for simulating\nphysical systems to overcome the limitations of traditional partial\ndifferential equation (PDE) solvers. However, most existing operator learning\nmethods assume that the data originate from a single physical mechanism,\nlimiting their applicability and performance in more realistic scenarios. To\nthis end, we propose Physical Invariant Attention Neural Operator (PIANO) to\ndecipher and integrate the physical invariants (PI) for operator learning from\nthe PDE series with various physical mechanisms. PIANO employs self-supervised\nlearning to extract physical knowledge and attention mechanisms to integrate\nthem into dynamic convolutional layers. Compared to existing techniques, PIANO\ncan reduce the relative error by 13.6\\%-82.2\\% on PDE forecasting tasks across\nvarying coefficients, forces, or boundary conditions. Additionally, varied\ndownstream tasks reveal that the PI embeddings deciphered by PIANO align well\nwith the underlying invariants in the PDE systems, verifying the physical\nsignificance of PIANO. The source code will be publicly available at:\nhttps://github.com/optray/PIANO.\n","authors":["Rui Zhang","Qi Meng","Zhi-Ming Ma"],"pdf_url":"https://arxiv.org/pdf/2311.14361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14359v1","updated":"2023-11-24T09:02:24Z","published":"2023-11-24T09:02:24Z","title":"Thompson sampling for zero-inflated count outcomes with an application\n  to the Drink Less mobile health study","summary":"  Mobile health (mHealth) technologies aim to improve distal outcomes, such as\nclinical conditions, by optimizing proximal outcomes through just-in-time\nadaptive interventions. Contextual bandits provide a suitable framework for\ncustomizing such interventions according to individual time-varying contexts,\nintending to maximize cumulative proximal outcomes. However, unique challenges\nsuch as modeling count outcomes within bandit frameworks have hindered the\nwidespread application of contextual bandits to mHealth studies. The current\nwork addresses this challenge by leveraging count data models into online\ndecision-making approaches. Specifically, we combine four common offline count\ndata models (Poisson, negative binomial, zero-inflated Poisson, and\nzero-inflated negative binomial regressions) with Thompson sampling, a popular\ncontextual bandit algorithm. The proposed algorithms are motivated by and\nevaluated on a real dataset from the Drink Less trial, where they are shown to\nimprove user engagement with the mHealth system. The proposed methods are\nfurther evaluated on simulated data, achieving improvement in maximizing\ncumulative proximal outcomes over existing algorithms. Theoretical results on\nregret bounds are also derived. A user-friendly R package countts that\nimplements the proposed methods for assessing contextual bandit algorithms is\nmade publicly available at https://cran.r-project.org/web/packages/countts.\n","authors":["Xueqing Liu","Nina Deliu","Tanujit Chakraborty","Lauren Bell","Bibhas Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2311.14359v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.14415v4","updated":"2023-11-24T09:01:12Z","published":"2022-05-28T12:27:27Z","title":"Non-stationary Transformers: Exploring the Stationarity in Time Series\n  Forecasting","summary":"  Transformers have shown great power in time series forecasting due to their\nglobal-range modeling ability. However, their performance can degenerate\nterribly on non-stationary real-world data in which the joint distribution\nchanges over time. Previous studies primarily adopt stationarization to\nattenuate the non-stationarity of original series for better predictability.\nBut the stationarized series deprived of inherent non-stationarity can be less\ninstructive for real-world bursty events forecasting. This problem, termed\nover-stationarization in this paper, leads Transformers to generate\nindistinguishable temporal attentions for different series and impedes the\npredictive capability of deep models. To tackle the dilemma between series\npredictability and model capability, we propose Non-stationary Transformers as\na generic framework with two interdependent modules: Series Stationarization\nand De-stationary Attention. Concretely, Series Stationarization unifies the\nstatistics of each input and converts the output with restored statistics for\nbetter predictability. To address the over-stationarization problem,\nDe-stationary Attention is devised to recover the intrinsic non-stationary\ninformation into temporal dependencies by approximating distinguishable\nattentions learned from raw series. Our Non-stationary Transformers framework\nconsistently boosts mainstream Transformers by a large margin, which reduces\nMSE by 49.43% on Transformer, 47.34% on Informer, and 46.89% on Reformer,\nmaking them the state-of-the-art in time series forecasting. Code is available\nat this repository: https://github.com/thuml/Nonstationary_Transformers.\n","authors":["Yong Liu","Haixu Wu","Jianmin Wang","Mingsheng Long"],"pdf_url":"https://arxiv.org/pdf/2205.14415v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08745v2","updated":"2023-11-24T08:49:11Z","published":"2023-11-15T07:27:40Z","title":"Using Stochastic Gradient Descent to Smooth Nonconvex Functions:\n  Analysis of Implicit Graduated Optimization with Optimal Noise Scheduling","summary":"  The graduated optimization approach is a heuristic method for finding\nglobally optimal solutions for nonconvex functions and has been theoretically\nanalyzed in several studies. This paper defines a new family of nonconvex\nfunctions for graduated optimization, discusses their sufficient conditions,\nand provides a convergence analysis of the graduated optimization algorithm for\nthem. It shows that stochastic gradient descent (SGD) with mini-batch\nstochastic gradients has the effect of smoothing the function, the degree of\nwhich is determined by the learning rate and batch size. This finding provides\ntheoretical insights on why large batch sizes fall into sharp local minima, why\ndecaying learning rates and increasing batch sizes are superior to fixed\nlearning rates and batch sizes, and what the optimal learning rate scheduling\nis. To the best of our knowledge, this is the first paper to provide a\ntheoretical explanation for these aspects. Moreover, a new graduated\noptimization framework that uses a decaying learning rate and increasing batch\nsize is analyzed and experimental results of image classification that support\nour theoretical findings are reported.\n","authors":["Naoki Sato","Hideaki Iiduka"],"pdf_url":"https://arxiv.org/pdf/2311.08745v2.pdf","comment":"The latest version was updated on Nov. 24"},{"id":"http://arxiv.org/abs/2310.02970v2","updated":"2023-11-24T08:48:32Z","published":"2023-10-04T17:06:32Z","title":"Fast, Expressive SE$(n)$ Equivariant Networks through Weight-Sharing in\n  Position-Orientation Space","summary":"  Based on the theory of homogeneous spaces we derive \\textit{geometrically\noptimal edge attributes} to be used within the flexible message passing\nframework. We formalize the notion of weight sharing in convolutional networks\nas the sharing of message functions over point-pairs that should be treated\nequally. We define equivalence classes of point-pairs that are identical up to\na transformation in the group and derive attributes that uniquely identify\nthese classes. Weight sharing is then obtained by conditioning message\nfunctions on these attributes. As an application of the theory, we develop an\nefficient equivariant group convolutional network for processing 3D point\nclouds. The theory of homogeneous spaces tells us how to do group convolutions\nwith feature maps over the homogeneous space of positions $\\mathbb{R}^3$,\nposition and orientations $\\mathbb{R}^3 {\\times} S^2$, and the group SE$(3)$\nitself. Among these, $\\mathbb{R}^3 {\\times} S^2$ is an optimal choice due to\nthe ability to represent directional information, which $\\mathbb{R}^3$ methods\ncannot, and it significantly enhances computational efficiency compared to\nindexing features on the full SE$(3)$ group. We empirically support this claim\nby reaching state-of-the-art results -- in accuracy and speed -- on three\ndifferent benchmarks: interatomic potential energy prediction, trajectory\nforecasting in N-body systems, and generating molecules via equivariant\ndiffusion models.\n","authors":["Erik J Bekkers","Sharvaree Vadgama","Rob D Hesselink","Putri A van der Linden","David W Romero"],"pdf_url":"https://arxiv.org/pdf/2310.02970v2.pdf","comment":"Our code is publicly available at https://github.com/ebekkers/ponita"},{"id":"http://arxiv.org/abs/2311.14335v1","updated":"2023-11-24T08:16:39Z","published":"2023-11-24T08:16:39Z","title":"Comparative Analysis of Transformers for Modeling Tabular Data: A\n  Casestudy using Industry Scale Dataset","summary":"  We perform a comparative analysis of transformer-based models designed for\nmodeling tabular data, specifically on an industry-scale dataset. While earlier\nstudies demonstrated promising outcomes on smaller public or synthetic\ndatasets, the effectiveness did not extend to larger industry-scale datasets.\nThe challenges identified include handling high-dimensional data, the necessity\nfor efficient pre-processing of categorical and numerical features, and\naddressing substantial computational requirements.\n  To overcome the identified challenges, the study conducts an extensive\nexamination of various transformer-based models using both synthetic datasets\nand the default prediction Kaggle dataset (2022) from American Express. The\npaper presents crucial insights into optimal data pre-processing, compares\npre-training and direct supervised learning methods, discusses strategies for\nmanaging categorical and numerical features, and highlights trade-offs between\ncomputational resources and performance. Focusing on temporal financial data\nmodeling, the research aims to facilitate the systematic development and\ndeployment of transformer-based models in real-world scenarios, emphasizing\nscalability.\n","authors":["Usneek Singh","Piyush Arora","Shamika Ganesan","Mohit Kumar","Siddhant Kulkarni","Salil R. Joshi"],"pdf_url":"https://arxiv.org/pdf/2311.14335v1.pdf","comment":"Accepted at 7th Joint International Conference on Data Science &\n  Management of Data (11th ACMIKDD CODS and 29th COMAD)"},{"id":"http://arxiv.org/abs/2311.14333v1","updated":"2023-11-24T08:15:54Z","published":"2023-11-24T08:15:54Z","title":"Cycle Invariant Positional Encoding for Graph Representation Learning","summary":"  Cycles are fundamental elements in graph-structured data and have\ndemonstrated their effectiveness in enhancing graph learning models. To encode\nsuch information into a graph learning framework, prior works often extract a\nsummary quantity, ranging from the number of cycles to the more sophisticated\npersistence diagram summaries. However, more detailed information, such as\nwhich edges are encoded in a cycle, has not yet been used in graph neural\nnetworks. In this paper, we make one step towards addressing this gap, and\npropose a structure encoding module, called CycleNet, that encodes cycle\ninformation via edge structure encoding in a permutation invariant manner. To\nefficiently encode the space of all cycles, we start with a cycle basis (i.e.,\na minimal set of cycles generating the cycle space) which we compute via the\nkernel of the 1-dimensional Hodge Laplacian of the input graph. To guarantee\nthe encoding is invariant w.r.t. the choice of cycle basis, we encode the cycle\ninformation via the orthogonal projector of the cycle basis, which is inspired\nby BasisNet proposed by Lim et al. We also develop a more efficient variant\nwhich however requires that the input graph has a unique shortest cycle basis.\nTo demonstrate the effectiveness of the proposed module, we provide some\ntheoretical understandings of its expressive power. Moreover, we show via a\nrange of experiments that networks enhanced by our CycleNet module perform\nbetter in various benchmarks compared to several existing SOTA models.\n","authors":["Zuoyu Yan","Tengfei Ma","Liangcai Gao","Zhi Tang","Chao Chen","Yusu Wang"],"pdf_url":"https://arxiv.org/pdf/2311.14333v1.pdf","comment":"Accepted as oral presentation in the Learning on Graphs Conference\n  (LoG 2023)"},{"id":"http://arxiv.org/abs/2311.14332v1","updated":"2023-11-24T08:15:11Z","published":"2023-11-24T08:15:11Z","title":"GATGPT: A Pre-trained Large Language Model with Graph Attention Network\n  for Spatiotemporal Imputation","summary":"  The analysis of spatiotemporal data is increasingly utilized across diverse\ndomains, including transportation, healthcare, and meteorology. In real-world\nsettings, such data often contain missing elements due to issues like sensor\nmalfunctions and data transmission errors. The objective of spatiotemporal\nimputation is to estimate these missing values by understanding the inherent\nspatial and temporal relationships in the observed multivariate time series.\nTraditionally, spatiotemporal imputation has relied on specific, intricate\narchitectures designed for this purpose, which suffer from limited\napplicability and high computational complexity. In contrast, our approach\nintegrates pre-trained large language models (LLMs) into spatiotemporal\nimputation, introducing a groundbreaking framework, GATGPT. This framework\nmerges a graph attention mechanism with LLMs. We maintain most of the LLM\nparameters unchanged to leverage existing knowledge for learning temporal\npatterns, while fine-tuning the upper layers tailored to various applications.\nThe graph attention component enhances the LLM's ability to understand spatial\nrelationships. Through tests on three distinct real-world datasets, our\ninnovative approach demonstrates comparable results to established deep\nlearning benchmarks.\n","authors":["Yakun Chen","Xianzhi Wang","Guandong Xu"],"pdf_url":"https://arxiv.org/pdf/2311.14332v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.05052v3","updated":"2023-11-24T08:00:48Z","published":"2023-10-08T07:25:27Z","title":"Accurate battery lifetime prediction across diverse aging conditions\n  with deep learning","summary":"  Accurately predicting the lifetime of battery cells in early cycles holds\ntremendous value for battery research and development as well as numerous\ndownstream applications. This task is rather challenging because diverse\nconditions, such as electrode materials, operating conditions, and working\nenvironments, collectively determine complex capacity-degradation behaviors.\nHowever, current prediction methods are developed and validated under limited\naging conditions, resulting in questionable adaptability to varied aging\nconditions and an inability to fully benefit from historical data collected\nunder different conditions. Here we introduce a universal deep learning\napproach that is capable of accommodating various aging conditions and\nfacilitating effective learning under low-resource conditions by leveraging\ndata from rich conditions. Our key finding is that incorporating inter-cell\nfeature differences, rather than solely considering single-cell\ncharacteristics, significantly increases the accuracy of battery lifetime\nprediction and its cross-condition robustness. Accordingly, we develop a\nholistic learning framework accommodating both single-cell and inter-cell\nmodeling. A comprehensive benchmark is built for evaluation, encompassing 401\nbattery cells utilizing 5 prevalent electrode materials across 168 cycling\nconditions. We demonstrate remarkable capabilities in learning across diverse\naging conditions, exclusively achieving 10% prediction error using the first\n100 cycles, and in facilitating low-resource learning, almost halving the error\nof single-cell modeling in many cases. More broadly, by breaking the learning\nboundaries among different aging conditions, our approach could significantly\naccelerate the development and optimization of lithium-ion batteries.\n","authors":["Han Zhang","Yuqi Li","Shun Zheng","Ziheng Lu","Xiaofan Gui","Wei Xu","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2310.05052v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14324v1","updated":"2023-11-24T07:53:48Z","published":"2023-11-24T07:53:48Z","title":"Large Language Models as Topological Structure Enhancers for\n  Text-Attributed Graphs","summary":"  The latest advancements in large language models (LLMs) have revolutionized\nthe field of natural language processing (NLP). Inspired by the success of LLMs\nin NLP tasks, some recent work has begun investigating the potential of\napplying LLMs in graph learning tasks. However, most of the existing work\nfocuses on utilizing LLMs as powerful node feature augmenters, leaving\nemploying LLMs to enhance graph topological structures an understudied problem.\nIn this work, we explore how to leverage the information retrieval and text\ngeneration capabilities of LLMs to refine/enhance the topological structure of\ntext-attributed graphs (TAGs) under the node classification setting. First, we\npropose using LLMs to help remove unreliable edges and add reliable ones in the\nTAG. Specifically, we first let the LLM output the semantic similarity between\nnode attributes through delicate prompt designs, and then perform edge deletion\nand edge addition based on the similarity. Second, we propose using\npseudo-labels generated by the LLM to improve graph topology, that is, we\nintroduce the pseudo-label propagation as a regularization to guide the graph\nneural network (GNN) in learning proper edge weights. Finally, we incorporate\nthe two aforementioned LLM-based methods for graph topological refinement into\nthe process of GNN training, and perform extensive experiments on four\nreal-world datasets. The experimental results demonstrate the effectiveness of\nLLM-based graph topology refinement (achieving a 0.15%--2.47% performance gain\non public benchmarks).\n","authors":["Shengyin Sun","Yuxiang Ren","Chen Ma","Xuecang Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.14324v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2311.12612v2","updated":"2023-11-24T07:42:45Z","published":"2023-11-21T13:54:08Z","title":"A New Type Of Upper And Lower Bounds On Right-Tail Probabilities Of\n  Continuous Random Variables","summary":"  In this paper, I present a completely new type of upper and lower bounds on\nthe right-tail probabilities of continuous random variables with unbounded\nsupport and with semi-bounded support from the left. The presented upper and\nlower right-tail bounds depend only on the probability density function (PDF),\nits first derivative, and two parameters that are used for tightening the\nbounds. These tail bounds hold under certain conditions that depend on the PDF,\nits first and second derivatives, and the two parameters. The new tail bounds\nare shown to be tight for a wide range of continuous random variables via\nnumerical examples.\n","authors":["Nikola Zlatanov"],"pdf_url":"https://arxiv.org/pdf/2311.12612v2.pdf","comment":"Minor typos corrected"},{"id":"http://arxiv.org/abs/2310.04483v2","updated":"2023-11-24T07:26:10Z","published":"2023-10-06T12:33:32Z","title":"Reward Dropout Improves Control: Bi-objective Perspective on Reinforced\n  LM","summary":"  We study the theoretical aspects of Reinforced Language Models (RLMs) from a\nbi-objective optimization perspective. Specifically, we consider the RLMs as a\nPareto optimization problem that maximizes the two conflicting objectives,\ni.e., reward objective and likelihood objectives, simultaneously. Our main\ncontribution consists of three parts. First, we establish the theoretical\nfoundations of RLM as a Pareto optimization problem by presenting Reward Upper\nBOund (RUBO) and Pareto optimality. Our theoretical outcomes are supported by\nnot only deductive proofs but also empirical results. Second, we propose Reward\nDropout, a simple yet powerful method that guarantees to improve a bi-objective\noptimization of RLM. Lastly, we demonstrate that the Reward Dropout is\nconsistently effective across five benchmark datasets and four benchmark LLMs,\nmeaning that the Reward Dropout significantly improves the optimization\nperformance of RLMs.\n","authors":["Changhun Lee","Chiehyeon Lim"],"pdf_url":"https://arxiv.org/pdf/2310.04483v2.pdf","comment":"29 pages, 13 figures, conference"},{"id":"http://arxiv.org/abs/2305.19190v3","updated":"2023-11-24T07:23:12Z","published":"2023-05-30T16:34:28Z","title":"Inverse Approximation Theory for Nonlinear Recurrent Neural Networks","summary":"  We prove an inverse approximation theorem for the approximation of nonlinear\nsequence-to-sequence relationships using recurrent neural networks (RNNs). This\nis a so-called Bernstein-type result in approximation theory, which deduces\nproperties of a target function under the assumption that it can be effectively\napproximated by a hypothesis space. In particular, we show that nonlinear\nsequence relationships that can be stably approximated by nonlinear RNNs must\nhave an exponential decaying memory structure - a notion that can be made\nprecise. This extends the previously identified curse of memory in linear RNNs\ninto the general nonlinear setting, and quantifies the essential limitations of\nthe RNN architecture for learning sequential relationships with long-term\nmemory. Based on the analysis, we propose a principled reparameterization\nmethod to overcome the limitations. Our theoretical results are confirmed by\nnumerical experiments. The code has been released in\nhttps://github.com/radarFudan/Curse-of-memory\n","authors":["Shida Wang","Zhong Li","Qianxiao Li"],"pdf_url":"https://arxiv.org/pdf/2305.19190v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12070v3","updated":"2023-11-24T07:00:54Z","published":"2023-06-21T07:43:23Z","title":"Task-Robust Pre-Training for Worst-Case Downstream Adaptation","summary":"  Pre-training has achieved remarkable success when transferred to downstream\ntasks. In machine learning, we care about not only the good performance of a\nmodel but also its behavior under reasonable shifts of condition. The same\nphilosophy holds when pre-training a foundation model. However, the foundation\nmodel may not uniformly behave well for a series of related downstream tasks.\nThis happens, for example, when conducting mask recovery regression where the\nrecovery ability or the training instances diverge like pattern features are\nextracted dominantly on pre-training, but semantic features are also required\non a downstream task. This paper considers pre-training a model that guarantees\na uniformly good performance over the downstream tasks. We call this goal as\n$\\textit{downstream-task robustness}$. Our method first separates the upstream\ntask into several representative ones and applies a simple minimax loss for\npre-training. We then design an efficient algorithm to solve the minimax loss\nand prove its convergence in the convex setting. In the experiments, we show\nboth on large-scale natural language processing and computer vision datasets\nour method increases the metrics on worse-case downstream tasks. Additionally,\nsome theoretical explanations for why our loss is beneficial are provided.\nSpecifically, we show fewer samples are inherently required for the most\nchallenging downstream task in some cases.\n","authors":["Jianghui Wang","Yang Chen","Xingyu Xie","Cong Fang","Zhouchen Lin"],"pdf_url":"https://arxiv.org/pdf/2306.12070v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12379v2","updated":"2023-11-24T06:59:57Z","published":"2023-11-21T06:41:41Z","title":"Infinite forecast combinations based on Dirichlet process","summary":"  Forecast combination integrates information from various sources by\nconsolidating multiple forecast results from the target time series. Instead of\nthe need to select a single optimal forecasting model, this paper introduces a\ndeep learning ensemble forecasting model based on the Dirichlet process.\nInitially, the learning rate is sampled with three basis distributions as\nhyperparameters to convert the infinite mixture into a finite one. All\ncheckpoints are collected to establish a deep learning sub-model pool, and\nweight adjustment and diversity strategies are developed during the combination\nprocess. The main advantage of this method is its ability to generate the\nrequired base learners through a single training process, utilizing the\ndecaying strategy to tackle the challenge posed by the stochastic nature of\ngradient descent in determining the optimal learning rate. To ensure the\nmethod's generalizability and competitiveness, this paper conducts an empirical\nanalysis using the weekly dataset from the M4 competition and explores\nsensitivity to the number of models to be combined. The results demonstrate\nthat the ensemble model proposed offers substantial improvements in prediction\naccuracy and stability compared to a single benchmark model.\n","authors":["Yinuo Ren","Feng Li","Yanfei Kang","Jue Wang"],"pdf_url":"https://arxiv.org/pdf/2311.12379v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02818v3","updated":"2023-11-24T06:36:55Z","published":"2023-11-06T01:41:46Z","title":"Signal Processing Meets SGD: From Momentum to Filter","summary":"  In the field of deep learning, Stochastic Gradient Descent (SGD) and its\nmomentum-based variants are the predominant choices for optimization\nalgorithms. Despite all that, these momentum strategies, which accumulate\nhistorical gradients by using a fixed $\\beta$ hyperparameter to smooth the\noptimization processing, often neglect the potential impact of the variance of\nhistorical gradients on the current gradient estimation. In the gradient\nvariance during training, fluctuation indicates the objective function does not\nmeet the Lipschitz continuity condition at all time, which raises the\ntroublesome optimization problem. This paper aims to explore the potential\nbenefits of reducing the variance of historical gradients to make optimizer\nconverge to flat solutions. Moreover, we proposed a new optimization method\nbased on reducing the variance. We employed the Wiener filter theory to enhance\nthe first moment estimation of SGD, notably introducing an adaptive weight to\noptimizer. Specifically, the adaptive weight dynamically changes along with\ntemporal fluctuation of gradient variance during deep learning model training.\nExperimental results demonstrated our proposed adaptive weight optimizer, SGDF\n(Stochastic Gradient Descent With Filter), can achieve satisfactory performance\ncompared with state-of-the-art optimizers.\n","authors":["Zhipeng Yao","Guisong Chang","Jiaqi Zhang","Qi Zhang","Yu Zhang","Dazhou Li"],"pdf_url":"https://arxiv.org/pdf/2311.02818v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2010.07468 by other authors"},{"id":"http://arxiv.org/abs/2311.14305v1","updated":"2023-11-24T06:29:04Z","published":"2023-11-24T06:29:04Z","title":"New Epochs in AI Supervision: Design and Implementation of an Autonomous\n  Radiology AI Monitoring System","summary":"  With the increasingly widespread adoption of AI in healthcare, maintaining\nthe accuracy and reliability of AI models in clinical practice has become\ncrucial. In this context, we introduce novel methods for monitoring the\nperformance of radiology AI classification models in practice, addressing the\nchallenges of obtaining real-time ground truth for performance monitoring. We\npropose two metrics - predictive divergence and temporal stability - to be used\nfor preemptive alerts of AI performance changes. Predictive divergence,\nmeasured using Kullback-Leibler and Jensen-Shannon divergences, evaluates model\naccuracy by comparing predictions with those of two supplementary models.\nTemporal stability is assessed through a comparison of current predictions\nagainst historical moving averages, identifying potential model decay or data\ndrift. This approach was retrospectively validated using chest X-ray data from\na single-center imaging clinic, demonstrating its effectiveness in maintaining\nAI model reliability. By providing continuous, real-time insights into model\nperformance, our system ensures the safe and effective use of AI in clinical\ndecision-making, paving the way for more robust AI integration in healthcare\n","authors":["Vasantha Kumar Venugopal","Abhishek Gupta","Rohit Takhar","Vidur Mahajan"],"pdf_url":"https://arxiv.org/pdf/2311.14305v1.pdf","comment":"10 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2311.14304v1","updated":"2023-11-24T06:27:25Z","published":"2023-11-24T06:27:25Z","title":"AdaMedGraph: Adaboosting Graph Neural Networks for Personalized Medicine","summary":"  Precision medicine tailored to individual patients has gained significant\nattention in recent times. Machine learning techniques are now employed to\nprocess personalized data from various sources, including images, genetics, and\nassessments. These techniques have demonstrated good outcomes in many clinical\nprediction tasks. Notably, the approach of constructing graphs by linking\nsimilar patients and then applying graph neural networks (GNNs) stands out,\nbecause related information from analogous patients are aggregated and\nconsidered for prediction. However, selecting the appropriate edge feature to\ndefine patient similarity and construct the graph is challenging, given that\neach patient is depicted by high-dimensional features from diverse sources.\nPrevious studies rely on human expertise to select the edge feature, which is\nneither scalable nor efficient in pinpointing crucial edge features for complex\ndiseases. In this paper, we propose a novel algorithm named \\ours, which can\nautomatically select important features to construct multiple patient\nsimilarity graphs, and train GNNs based on these graphs as weak learners in\nadaptive boosting. \\ours{} is evaluated on two real-world medical scenarios and\nshows superiors performance.\n","authors":["Jie Lian","Xufang Luo","Caihua Shan","Dongqi Han","Varut Vardhanabhuti","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2311.14304v1.pdf","comment":"Extended Abstract presented at Machine Learning for Health (ML4H)\n  symposium 2023, December 10th, 2023, New Orleans, United States, 9 pages"},{"id":"http://arxiv.org/abs/2311.14301v1","updated":"2023-11-24T06:22:38Z","published":"2023-11-24T06:22:38Z","title":"GeoViT: A Versatile Vision Transformer Architecture for Geospatial Image\n  Analysis","summary":"  Greenhouse gases are pivotal drivers of climate change, necessitating precise\nquantification and source identification to foster mitigation strategies. We\nintroduce GeoViT, a compact vision transformer model adept in processing\nsatellite imagery for multimodal segmentation, classification, and regression\ntasks targeting CO2 and NO2 emissions. Leveraging GeoViT, we attain superior\naccuracy in estimating power generation rates, fuel type, plume coverage for\nCO2, and high-resolution NO2 concentration mapping, surpassing previous\nstate-of-the-art models while significantly reducing model size. GeoViT\ndemonstrates the efficacy of vision transformer architectures in harnessing\nsatellite-derived data for enhanced GHG emission insights, proving instrumental\nin advancing climate change monitoring and emission regulation efforts\nglobally.\n","authors":["Madhav Khirwar","Ankur Narang"],"pdf_url":"https://arxiv.org/pdf/2311.14301v1.pdf","comment":"Extended Abstract, Preprint"},{"id":"http://arxiv.org/abs/2309.15643v2","updated":"2023-11-24T06:20:25Z","published":"2023-09-27T13:29:38Z","title":"Why do Angular Margin Losses work well for Semi-Supervised Anomalous\n  Sound Detection?","summary":"  State-of-the-art anomalous sound detection systems often utilize angular\nmargin losses to learn suitable representations of acoustic data using an\nauxiliary task, which usually is a supervised or self-supervised classification\ntask. The underlying idea is that, in order to solve this auxiliary task,\nspecific information about normal data needs to be captured in the learned\nrepresentations and that this information is also sufficient to differentiate\nbetween normal and anomalous samples. Especially in noisy conditions,\ndiscriminative models based on angular margin losses tend to significantly\noutperform systems based on generative or one-class models. The goal of this\nwork is to investigate why using angular margin losses with auxiliary tasks\nworks well for detecting anomalous sounds. To this end, it is shown, both\ntheoretically and experimentally, that minimizing angular margin losses also\nminimizes compactness loss while inherently preventing learning trivial\nsolutions. Furthermore, multiple experiments are conducted to show that using a\nrelated classification task as an auxiliary task teaches the model to learn\nrepresentations suitable for detecting anomalous sounds in noisy conditions.\nAmong these experiments are performance evaluations, visualizing the embedding\nspace with t-SNE and visualizing the input representations with respect to the\nanomaly score using randomized input sampling for explanation.\n","authors":["Kevin Wilkinghoff","Frank Kurth"],"pdf_url":"https://arxiv.org/pdf/2309.15643v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02198v3","updated":"2023-11-24T06:08:20Z","published":"2023-11-03T19:03:20Z","title":"Imitation Bootstrapped Reinforcement Learning","summary":"  Despite the considerable potential of reinforcement learning (RL), robotics\ncontrol tasks predominantly rely on imitation learning (IL) owing to its better\nsample efficiency. However, given the high cost of collecting extensive\ndemonstrations, RL is still appealing if it can utilize limited imitation data\nfor efficient autonomous self-improvement. Existing RL methods that utilize\ndemonstrations either initialize the replay buffer with demonstrations and\noversample them during RL training, which does not benefit from the\ngeneralization potential of modern IL methods, or pretrain the RL policy with\nIL on the demonstrations, which requires additional mechanisms to prevent\ncatastrophic forgetting during RL fine-tuning. We propose imitation\nbootstrapped reinforcement learning (IBRL), a novel framework that first trains\nan IL policy on a limited number of demonstrations and then uses it to propose\nalternative actions for both online exploration and target value bootstrapping.\nIBRL achieves SoTA performance and sample efficiency on 7 challenging sparse\nreward continuous control tasks in simulation while learning directly from\npixels. As a highlight of our method, IBRL achieves $6.4\\times$ higher success\nrate than RLPD, a strong method that combines the idea of oversampling\ndemonstrations with modern RL improvements, under the budget of 10 demos and\n100K interactions in the challenging PickPlaceCan task in the Robomimic\nbenchmark.\n","authors":["Hengyuan Hu","Suvir Mirchandani","Dorsa Sadigh"],"pdf_url":"https://arxiv.org/pdf/2311.02198v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11588v3","updated":"2023-11-24T05:09:25Z","published":"2023-01-27T08:25:45Z","title":"Bounding Box-based Multi-objective Bayesian Optimization of Risk\n  Measures under Input Uncertainty","summary":"  In this study, we propose a novel multi-objective Bayesian optimization\n(MOBO) method to efficiently identify the Pareto front (PF) defined by risk\nmeasures for black-box functions under the presence of input uncertainty (IU).\nExisting BO methods for Pareto optimization in the presence of IU are\nrisk-specific or without theoretical guarantees, whereas our proposed method\naddresses general risk measures and has theoretical guarantees. The basic idea\nof the proposed method is to assume a Gaussian process (GP) model for the\nblack-box function and to construct high-probability bounding boxes for the\nrisk measures using the GP model. Furthermore, in order to reduce the\nuncertainty of non-dominated bounding boxes, we propose a method of selecting\nthe next evaluation point using a maximin distance defined by the maximum value\nof a quasi distance based on bounding boxes. As theoretical analysis, we prove\nthat the algorithm can return an arbitrary-accurate solution in a finite number\nof iterations with high probability, for various risk measures such as Bayes\nrisk, worst-case risk, and value-at-risk. We also give a theoretical analysis\nthat takes into account approximation errors because there exist non-negligible\napproximation errors (e.g., finite approximation of PFs and sampling-based\napproximation of bounding boxes) in practice. We confirm that the proposed\nmethod outperforms compared with existing methods not only in the setting with\nIU but also in the setting of ordinary MOBO through numerical experiments.\n","authors":["Yu Inatsu","Shion Takeno","Hiroyuki Hanada","Kazuki Iwata","Ichiro Takeuchi"],"pdf_url":"https://arxiv.org/pdf/2301.11588v3.pdf","comment":"39 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.14272v1","updated":"2023-11-24T04:16:32Z","published":"2023-11-24T04:16:32Z","title":"CRISP: Hybrid Structured Sparsity for Class-aware Model Pruning","summary":"  Machine learning pipelines for classification tasks often train a universal\nmodel to achieve accuracy across a broad range of classes. However, a typical\nuser encounters only a limited selection of classes regularly. This disparity\nprovides an opportunity to enhance computational efficiency by tailoring models\nto focus on user-specific classes. Existing works rely on unstructured pruning,\nwhich introduces randomly distributed non-zero values in the model, making it\nunsuitable for hardware acceleration. Alternatively, some approaches employ\nstructured pruning, such as channel pruning, but these tend to provide only\nminimal compression and may lead to reduced model accuracy. In this work, we\npropose CRISP, a novel pruning framework leveraging a hybrid structured\nsparsity pattern that combines both fine-grained N:M structured sparsity and\ncoarse-grained block sparsity. Our pruning strategy is guided by a\ngradient-based class-aware saliency score, allowing us to retain weights\ncrucial for user-specific classes. CRISP achieves high accuracy with minimal\nmemory consumption for popular models like ResNet-50, VGG-16, and MobileNetV2\non ImageNet and CIFAR-100 datasets. Moreover, CRISP delivers up to 14$\\times$\nreduction in latency and energy consumption compared to existing pruning\nmethods while maintaining comparable accuracy. Our code is available at\nhttps://github.com/shivmgg/CRISP/.\n","authors":["Shivam Aggarwal","Kuluhan Binici","Tulika Mitra"],"pdf_url":"https://arxiv.org/pdf/2311.14272v1.pdf","comment":"6 pages, accepted in Design, Automation & Test in Europe Conference &\n  Exhibition (DATE) 2024"},{"id":"http://arxiv.org/abs/2311.14271v1","updated":"2023-11-24T04:15:10Z","published":"2023-11-24T04:15:10Z","title":"Segmentation-Based Parametric Painting","summary":"  We introduce a novel image-to-painting method that facilitates the creation\nof large-scale, high-fidelity paintings with human-like quality and stylistic\nvariation. To process large images and gain control over the painting process,\nwe introduce a segmentation-based painting process and a dynamic attention map\napproach inspired by human painting strategies, allowing optimization of brush\nstrokes to proceed in batches over different image regions, thereby capturing\nboth large-scale structure and fine details, while also allowing stylistic\ncontrol over detail. Our optimized batch processing and patch-based loss\nframework enable efficient handling of large canvases, ensuring our painted\noutputs are both aesthetically compelling and functionally superior as compared\nto previous methods, as confirmed by rigorous evaluations. Code available at:\nhttps://github.com/manuelladron/semantic\\_based\\_painting.git\n","authors":["Manuel Ladron de Guevara","Matthew Fisher","Aaron Hertzmann"],"pdf_url":"https://arxiv.org/pdf/2311.14271v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2303.16210v4","updated":"2023-11-24T03:56:54Z","published":"2023-03-28T05:10:57Z","title":"Towards Reliable Uncertainty Quantification via Deep Ensembles in\n  Multi-output Regression Task","summary":"  This study aims to comprehensively investigate the deep ensemble approach, an\napproximate Bayesian inference, in the multi-output regression task for\npredicting the aerodynamic performance of a missile configuration. To this end,\nthe effect of the number of neural networks used in the ensemble, which has\nbeen blindly adopted in previous studies, is scrutinized. As a result, an\nobvious trend towards underestimation of uncertainty as it increases is\nobserved for the first time, and in this context, we propose the deep ensemble\nframework that applies the post-hoc calibration method to improve its\nuncertainty quantification performance. It is compared with Gaussian process\nregression and is shown to have superior performance in terms of regression\naccuracy ($\\uparrow55\\sim56\\%$), reliability of estimated uncertainty\n($\\uparrow38\\sim77\\%$), and training efficiency ($\\uparrow78\\%$). Finally, the\npotential impact of the suggested framework on the Bayesian optimization is\nbriefly examined, indicating that deep ensemble without calibration may lead to\nunintended exploratory behavior. This UQ framework can be seamlessly applied\nand extended to any regression task, as no special assumptions have been made\nfor the specific problem used in this study.\n","authors":["Sunwoong Yang","Kwanjung Yee"],"pdf_url":"https://arxiv.org/pdf/2303.16210v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.16483v2","updated":"2023-11-24T03:07:39Z","published":"2023-08-31T06:44:42Z","title":"Improving Out-of-Distribution Detection in Echocardiographic View\n  Classication through Enhancing Semantic Features","summary":"  In echocardiographic view classification, accurately detecting\nout-of-distribution (OOD) data is essential but challenging, especially given\nthe subtle differences between in-distribution and OOD data. While conventional\nOOD detection methods, such as Mahalanobis distance (MD) are effective in\nfar-OOD scenarios with clear distinctions between distributions, they struggle\nto discern the less obvious variations characteristic of echocardiographic\ndata. In this study, we introduce a novel use of label smoothing to enhance\nsemantic feature representation in echocardiographic images, demonstrating that\nthese enriched semantic features are key for significantly improving near-OOD\ninstance detection. By combining label smoothing with MD-based OOD detection,\nwe establish a new benchmark for accuracy in echocardiographic OOD detection.\n","authors":["Jaeik Jeon","Seongmin Ha","Yeonggul Jang","Yeonyee E. Yoon","Jiyeon Kim","Hyunseok Jeong","Dawun Jeong","Youngtaek Hong","Seung-Ah Lee Hyuk-Jae Chang"],"pdf_url":"https://arxiv.org/pdf/2308.16483v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14255v1","updated":"2023-11-24T02:42:42Z","published":"2023-11-24T02:42:42Z","title":"Out-of-Distribution Generalized Dynamic Graph Neural Network with\n  Disentangled Intervention and Invariance Promotion","summary":"  Dynamic graph neural networks (DyGNNs) have demonstrated powerful predictive\nabilities by exploiting graph structural and temporal dynamics. However, the\nexisting DyGNNs fail to handle distribution shifts, which naturally exist in\ndynamic graphs, mainly because the patterns exploited by DyGNNs may be variant\nwith respect to labels under distribution shifts. In this paper, we propose\nDisentangled Intervention-based Dynamic graph Attention networks with\nInvariance Promotion (I-DIDA) to handle spatio-temporal distribution shifts in\ndynamic graphs by discovering and utilizing invariant patterns, i.e.,\nstructures and features whose predictive abilities are stable across\ndistribution shifts. Specifically, we first propose a disentangled\nspatio-temporal attention network to capture the variant and invariant\npatterns. By utilizing the disentangled patterns, we design a spatio-temporal\nintervention mechanism to create multiple interventional distributions and an\nenvironment inference module to infer the latent spatio-temporal environments,\nand minimize the variance of predictions among these intervened distributions\nand environments, so that our model can make predictions based on invariant\npatterns with stable predictive abilities under distribution shifts. Extensive\nexperiments demonstrate the superiority of our method over state-of-the-art\nbaselines under distribution shifts. Our work is the first study of\nspatio-temporal distribution shifts in dynamic graphs, to the best of our\nknowledge.\n","authors":["Zeyang Zhang","Xin Wang","Ziwei Zhang","Haoyang Li","Wenwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.14255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.17623v2","updated":"2023-11-24T01:45:16Z","published":"2023-10-26T17:43:13Z","title":"Proving Test Set Contamination in Black Box Language Models","summary":"  Large language models are trained on vast amounts of internet data, prompting\nconcerns and speculation that they have memorized public benchmarks. Going from\nspeculation to proof of contamination is challenging, as the pretraining data\nused by proprietary models are often not publicly accessible. We show that it\nis possible to provide provable guarantees of test set contamination in\nlanguage models without access to pretraining data or model weights. Our\napproach leverages the fact that when there is no data contamination, all\norderings of an exchangeable benchmark should be equally likely. In contrast,\nthe tendency for language models to memorize example order means that a\ncontaminated language model will find certain canonical orderings to be much\nmore likely than others. Our test flags potential contamination whenever the\nlikelihood of a canonically ordered benchmark dataset is significantly higher\nthan the likelihood after shuffling the examples. We demonstrate that our\nprocedure is sensitive enough to reliably prove test set contamination in\nchallenging situations, including models as small as 1.4 billion parameters, on\nsmall test sets of only 1000 examples, and datasets that appear only a few\ntimes in the pretraining corpus. Using our test, we audit five popular publicly\naccessible language models for test set contamination and find little evidence\nfor pervasive contamination.\n","authors":["Yonatan Oren","Nicole Meister","Niladri Chatterji","Faisal Ladhak","Tatsunori B. Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2310.17623v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.14483v3","updated":"2023-11-24T00:58:48Z","published":"2023-03-25T14:29:20Z","title":"Spatio-Temporal Graph Neural Networks for Predictive Learning in Urban\n  Computing: A Survey","summary":"  With recent advances in sensing technologies, a myriad of spatio-temporal\ndata has been generated and recorded in smart cities. Forecasting the evolution\npatterns of spatio-temporal data is an important yet demanding aspect of urban\ncomputing, which can enhance intelligent management decisions in various\nfields, including transportation, environment, climate, public safety,\nhealthcare, and others. Traditional statistical and deep learning methods\nstruggle to capture complex correlations in urban spatio-temporal data. To this\nend, Spatio-Temporal Graph Neural Networks (STGNN) have been proposed,\nachieving great promise in recent years. STGNNs enable the extraction of\ncomplex spatio-temporal dependencies by integrating graph neural networks\n(GNNs) and various temporal learning methods. In this manuscript, we provide a\ncomprehensive survey on recent progress on STGNN technologies for predictive\nlearning in urban computing. Firstly, we provide a brief introduction to the\nconstruction methods of spatio-temporal graph data and the prevalent\ndeep-learning architectures used in STGNNs. We then sort out the primary\napplication domains and specific predictive learning tasks based on existing\nliterature. Afterward, we scrutinize the design of STGNNs and their combination\nwith some advanced technologies in recent years. Finally, we conclude the\nlimitations of existing research and suggest potential directions for future\nwork.\n","authors":["Guangyin Jin","Yuxuan Liang","Yuchen Fang","Zezhi Shao","Jincai Huang","Junbo Zhang","Yu Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.14483v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.07628v2","updated":"2023-11-24T00:38:52Z","published":"2021-12-14T18:13:36Z","title":"Training Multi-Layer Over-Parametrized Neural Network in Subquadratic\n  Time","summary":"  We consider the problem of training a multi-layer over-parametrized neural\nnetwork to minimize the empirical risk induced by a loss function. In the\ntypical setting of over-parametrization, the network width $m$ is much larger\nthan the data dimension $d$ and the number of training samples $n$\n($m=\\mathrm{poly}(n,d)$), which induces a prohibitive large weight matrix $W\\in\n\\mathbb{R}^{m\\times m}$ per layer. Naively, one has to pay $O(m^2)$ time to\nread the weight matrix and evaluate the neural network function in both forward\nand backward computation. In this work, we show how to reduce the training cost\nper iteration. Specifically, we propose a framework that uses $m^2$ cost only\nin the initialization phase and achieves \\emph{a truly subquadratic cost per\niteration} in terms of $m$, i.e., $m^{2-\\Omega(1)}$ per iteration. Our result\nhas implications beyond standard over-parametrization theory, as it can be\nviewed as designing an efficient data structure on top of a pre-trained large\nmodel to further speed up the fine-tuning process, a core procedure to deploy\nlarge language models (LLM).\n","authors":["Zhao Song","Lichen Zhang","Ruizhe Zhang"],"pdf_url":"https://arxiv.org/pdf/2112.07628v2.pdf","comment":"ITCS 2024"},{"id":"http://arxiv.org/abs/2311.14237v1","updated":"2023-11-24T00:36:17Z","published":"2023-11-24T00:36:17Z","title":"Pseudo-label Correction for Instance-dependent Noise Using\n  Teacher-student Framework","summary":"  The high capacity of deep learning models to learn complex patterns poses a\nsignificant challenge when confronted with label noise. The inability to\ndifferentiate clean and noisy labels ultimately results in poor generalization.\nWe approach this problem by reassigning the label for each image using a new\nteacher-student based framework termed P-LC (pseudo-label correction).\nTraditional teacher-student networks are composed of teacher and student\nclassifiers for knowledge distillation. In our novel approach, we reconfigure\nthe teacher network into a triple encoder, leveraging the triplet loss to\nestablish a pseudo-label correction system. As the student generates pseudo\nlabels for a set of given images, the teacher learns to choose between the\ninitially assigned labels and the pseudo labels. Experiments on MNIST,\nFashion-MNIST, and SVHN demonstrate P-LC's superior performance over existing\nstate-of-the-art methods across all noise levels, most notably in high noise.\nIn addition, we introduce a noise level estimation to help assess model\nperformance and inform the need for additional data cleaning procedures.\n","authors":["Eugene Kim"],"pdf_url":"https://arxiv.org/pdf/2311.14237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.09384v2","updated":"2023-11-24T00:25:38Z","published":"2023-09-17T21:43:18Z","title":"Mitigating Over-Smoothing and Over-Squashing using Augmentations of\n  Forman-Ricci Curvature","summary":"  While Graph Neural Networks (GNNs) have been successfully leveraged for\nlearning on graph-structured data across domains, several potential pitfalls\nhave been described recently. Those include the inability to accurately\nleverage information encoded in long-range connections (over-squashing), as\nwell as difficulties distinguishing the learned representations of nearby nodes\nwith growing network depth (over-smoothing). An effective way to characterize\nboth effects is discrete curvature: Long-range connections that underlie\nover-squashing effects have low curvature, whereas edges that contribute to\nover-smoothing have high curvature. This observation has given rise to rewiring\ntechniques, which add or remove edges to mitigate over-smoothing and\nover-squashing. Several rewiring approaches utilizing graph characteristics,\nsuch as curvature or the spectrum of the graph Laplacian, have been proposed.\nHowever, existing methods, especially those based on curvature, often require\nexpensive subroutines and careful hyperparameter tuning, which limits their\napplicability to large-scale graphs. Here we propose a rewiring technique based\non Augmented Forman-Ricci curvature (AFRC), a scalable curvature notation,\nwhich can be computed in linear time. We prove that AFRC effectively\ncharacterizes over-smoothing and over-squashing effects in message-passing\nGNNs. We complement our theoretical results with experiments, which demonstrate\nthat the proposed approach achieves state-of-the-art performance while\nsignificantly reducing the computational cost in comparison with other methods.\nUtilizing fundamental properties of discrete curvature, we propose effective\nheuristics for hyperparameters in curvature-based rewiring, which avoids\nexpensive hyperparameter searches, further improving the scalability of the\nproposed approach.\n","authors":["Lukas Fesser","Melanie Weber"],"pdf_url":"https://arxiv.org/pdf/2309.09384v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01017v2","updated":"2023-11-24T00:24:06Z","published":"2023-11-02T06:21:56Z","title":"Learning Unsupervised World Models for Autonomous Driving via Discrete\n  Diffusion","summary":"  Learning world models can teach an agent how the world works in an\nunsupervised manner. Even though it can be viewed as a special case of sequence\nmodeling, progress for scaling world models on robotic applications such as\nautonomous driving has been somewhat less rapid than scaling language models\nwith Generative Pre-trained Transformers (GPT). We identify two reasons as\nmajor bottlenecks: dealing with complex and unstructured observation space, and\nhaving a scalable generative model. Consequently, we propose a novel world\nmodeling approach that first tokenizes sensor observations with VQVAE, then\npredicts the future via discrete diffusion. To efficiently decode and denoise\ntokens in parallel, we recast Masked Generative Image Transformer into the\ndiscrete diffusion framework with a few simple changes, resulting in notable\nimprovement. When applied to learning world models on point cloud observations,\nour model reduces prior SOTA Chamfer distance by more than 65% for 1s\nprediction, and more than 50% for 3s prediction, across NuScenes, KITTI\nOdometry, and Argoverse2 datasets. Our results demonstrate that discrete\ndiffusion on tokenized agent experience can unlock the power of GPT-like\nunsupervised learning for robotic agents.\n","authors":["Lunjun Zhang","Yuwen Xiong","Ze Yang","Sergio Casas","Rui Hu","Raquel Urtasun"],"pdf_url":"https://arxiv.org/pdf/2311.01017v2.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2311.12401v2","updated":"2023-11-24T08:51:13Z","published":"2023-11-21T07:28:51Z","title":"CASR: Refining Action Segmentation via Magrinalizing Frame-levle Causal\n  Relationships","summary":"  Integrating deep learning and causal discovery has increased the\ninterpretability of Temporal Action Segmentation (TAS) tasks. However,\nframe-level causal relationships exist many complicated noises outside the\nsegment-level, making it infeasible to directly express macro action semantics.\nThus, we propose Causal Abstraction Segmentation Refiner (CASR), which can\nrefine TAS results from various models by enhancing video causality in\nmarginalizing frame-level casual relationships. Specifically, we define the\nequivalent frame-level casual model and segment-level causal model, so that the\ncausal adjacency matrix constructed from marginalized frame-level causal\nrelationships has the ability to represent the segmnet-level causal\nrelationships. CASR works out by reducing the difference in the causal\nadjacency matrix between we constructed and pre-segmentation results of\nbackbone models. In addition, we propose a novel evaluation metric Causal Edit\nDistance (CED) to evaluate the causal interpretability. Extensive experimental\nresults on mainstream datasets indicate that CASR significantly surpasses\nexisting various methods in action segmentation performance, as well as in\ncausal explainability and generalization.\n","authors":["Keqing Du","Xinyu Yang","Hang Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12401v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07848v9","updated":"2023-11-24T15:04:50Z","published":"2023-06-13T15:28:10Z","title":"GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio\n  Pretraining for Accurate Speech Emotion Recognition","summary":"  Contrastive cross-modality pretraining has recently exhibited impressive\nsuccess in diverse fields, whereas there is limited research on their merits in\nspeech emotion recognition (SER). In this paper, we propose GEmo-CLAP, a kind\nof gender-attribute-enhanced contrastive language-audio pretraining (CLAP)\nmethod for SER. Specifically, we first construct an effective emotion CLAP\n(Emo-CLAP) for SER, using pre-trained text and audio encoders. Second, given\nthe significance of gender information in SER, two novel multi-task learning\nbased GEmo-CLAP (ML-GEmo-CLAP) and soft label based GEmo-CLAP (SL-GEmo-CLAP)\nmodels are further proposed to incorporate gender information of speech\nsignals, forming more reasonable objectives. Experiments on IEMOCAP indicate\nthat our proposed two GEmo-CLAPs consistently outperform Emo-CLAP with\ndifferent pre-trained models. Remarkably, the proposed WavLM-based SL-GEmo-CLAP\nobtains the best UAR of 81.43\\% and WAR of 83.16\\%, which performs better than\nstate-of-the-art SER methods.\n","authors":["Yu Pan","Yanni Hu","Yuguang Yang","Wen Fei","Jixun Yao","Heng Lu","Lei Ma","Jianjun Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.07848v9.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2307.15064v2","updated":"2023-11-24T02:58:58Z","published":"2023-07-27T17:59:59Z","title":"Self-Supervised Visual Acoustic Matching","summary":"  Acoustic matching aims to re-synthesize an audio clip to sound as if it were\nrecorded in a target acoustic environment. Existing methods assume access to\npaired training data, where the audio is observed in both source and target\nenvironments, but this limits the diversity of training data or requires the\nuse of simulated data or heuristics to create paired samples. We propose a\nself-supervised approach to visual acoustic matching where training samples\ninclude only the target scene image and audio -- without acoustically\nmismatched source audio for reference. Our approach jointly learns to\ndisentangle room acoustics and re-synthesize audio into the target environment,\nvia a conditional GAN framework and a novel metric that quantifies the level of\nresidual acoustic information in the de-biased audio. Training with either\nin-the-wild web data or simulated data, we demonstrate it outperforms the\nstate-of-the-art on multiple challenging datasets and a wide variety of\nreal-world audio and environments.\n","authors":["Arjun Somayazulu","Changan Chen","Kristen Grauman"],"pdf_url":"https://arxiv.org/pdf/2307.15064v2.pdf","comment":"Project page: https://vision.cs.utexas.edu/projects/ss_vam/ .\n  Accepted at NeurIPS 2023"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2311.14583v1","updated":"2023-11-24T16:19:04Z","published":"2023-11-24T16:19:04Z","title":"GPT Struct Me: Probing GPT Models on Narrative Entity Extraction","summary":"  The importance of systems that can extract structured information from\ntextual data becomes increasingly pronounced given the ever-increasing volume\nof text produced on a daily basis. Having a system that can effectively extract\nsuch information in an interoperable manner would be an asset for several\ndomains, be it finance, health, or legal. Recent developments in natural\nlanguage processing led to the production of powerful language models that can,\nto some degree, mimic human intelligence. Such effectiveness raises a pertinent\nquestion: Can these models be leveraged for the extraction of structured\ninformation? In this work, we address this question by evaluating the\ncapabilities of two state-of-the-art language models -- GPT-3 and GPT-3.5,\ncommonly known as ChatGPT -- in the extraction of narrative entities, namely\nevents, participants, and temporal expressions. This study is conducted on the\nText2Story Lusa dataset, a collection of 119 Portuguese news articles whose\nannotation framework includes a set of entity structures along with several\ntags and attribute values. We first select the best prompt template through an\nablation study over prompt components that provide varying degrees of\ninformation on a subset of documents of the dataset. Subsequently, we use the\nbest templates to evaluate the effectiveness of the models on the remaining\ndocuments. The results obtained indicate that GPT models are competitive with\nout-of-the-box baseline systems, presenting an all-in-one alternative for\npractitioners with limited resources. By studying the strengths and limitations\nof these models in the context of information extraction, we offer insights\nthat can guide future improvements and avenues to explore in this field.\n","authors":["Hugo Sousa","Nuno Guimarães","Alípio Jorge","Ricardo Campos"],"pdf_url":"https://arxiv.org/pdf/2311.14583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.02892v2","updated":"2023-11-24T02:40:44Z","published":"2022-09-07T02:34:39Z","title":"A Systematical Evaluation for Next-Basket Recommendation Algorithms","summary":"  Next basket recommender systems (NBRs) aim to recommend a user's next\n(shopping) basket of items via modeling the user's preferences towards items\nbased on the user's purchase history, usually a sequence of historical baskets.\nDue to its wide applicability in the real-world E-commerce industry, the\nstudies NBR have attracted increasing attention in recent years. NBRs have been\nwidely studied and much progress has been achieved in this area with a variety\nof NBR approaches having been proposed. However, an important issue is that\nthere is a lack of a systematic and unified evaluation over the various NBR\napproaches. Different studies often evaluate NBR approaches on different\ndatasets, under different experimental settings, making it hard to fairly and\neffectively compare the performance of different NBR approaches. To bridge this\ngap, in this work, we conduct a systematical empirical study in NBR area.\nSpecifically, we review the representative work in NBR and analyze their cons\nand pros. Then, we run the selected NBR algorithms on the same datasets, under\nthe same experimental setting and evaluate their performances using the same\nmeasurements. This provides a unified framework to fairly compare different NBR\napproaches. We hope this study can provide a valuable reference for the future\nresearch in this vibrant area.\n","authors":["Zhufeng Shao","Shoujin Wang","Qian Zhang","Wenpeng Lu","Zhao Li","Xueping Peng"],"pdf_url":"https://arxiv.org/pdf/2209.02892v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14837v1","updated":"2023-11-24T20:16:38Z","published":"2023-11-24T20:16:38Z","title":"Benchmarking Robustness of Text-Image Composed Retrieval","summary":"  Text-image composed retrieval aims to retrieve the target image through the\ncomposed query, which is specified in the form of an image plus some text that\ndescribes desired modifications to the input image. It has recently attracted\nattention due to its ability to leverage both information-rich images and\nconcise language to precisely express the requirements for target images.\nHowever, the robustness of these approaches against real-world corruptions or\nfurther text understanding has never been studied. In this paper, we perform\nthe first robustness study and establish three new diversified benchmarks for\nsystematic analysis of text-image composed retrieval against natural\ncorruptions in both vision and text and further probe textural understanding.\nFor natural corruption analysis, we introduce two new large-scale benchmark\ndatasets, CIRR-C and FashionIQ-C for testing in open domain and fashion domain\nrespectively, both of which apply 15 visual corruptions and 7 textural\ncorruptions. For textural understanding analysis, we introduce a new diagnostic\ndataset CIRR-D by expanding the original raw data with synthetic data, which\ncontains modified text to better probe textual understanding ability including\nnumerical variation, attribute variation, object removal, background variation,\nand fine-grained evaluation. The code and benchmark datasets are available at\nhttps://github.com/SunTongtongtong/Benchmark-Robustness-Text-Image-Compose-Retrieval.\n","authors":["Shitong Sun","Jindong Gu","Shaogang Gong"],"pdf_url":"https://arxiv.org/pdf/2311.14837v1.pdf","comment":"Accepted by R0-FoMo: Workshop on Robustness of Few-shot and Zero-shot\n  Learning in Foundation Models at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.14778v1","updated":"2023-11-24T15:46:32Z","published":"2023-11-24T15:46:32Z","title":"Anomaly detection in cross-country money transfer temporal networks","summary":"  During the last decades, Anti-Financial Crime (AFC) entities and Financial\nInstitutions have put a constantly increasing effort to reduce financial crime\nand detect fraudulent activities, that are changing and developing in extremely\ncomplex ways. We propose an anomaly detection approach based on network\nanalysis to help AFC officers navigating through the high load of information\nthat is typical of AFC data-driven scenarios. By experimenting on a large\nfinancial dataset of more than 80M cross-country wire transfers, we leverage on\nthe properties of complex networks to develop a tool for explainable anomaly\ndetection, that can help in identifying outliers that could be engaged in\npotentially malicious activities according to financial regulations. We\nidentify a set of network centrality measures that provide useful insights on\nindividual nodes; by keeping track of the evolution over time of the\ncentrality-based node rankings, we are able to highlight sudden and unexpected\nchanges in the roles of individual nodes that deserve further attention by AFC\nofficers. Such changes can hardly be noticed by means of current AFC practices,\nthat sometimes can lack a higher-level, global vision of the system. This\napproach represents a preliminary step in the automation of AFC and AML\nprocesses, serving the purpose of facilitating the work of AFC officers by\nproviding them with a top-down view of the picture emerging from financial\ndata.\n","authors":["Salvatore Vilella","Arthur Thomas Edward Capozzi Lupi","Marco Fornasiero","Dario Moncalvo","Valeria Ricci","Silvia Ronchiadin","Giancarlo Ruffo"],"pdf_url":"https://arxiv.org/pdf/2311.14778v1.pdf","comment":null}]},"2023-11-23T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2311.11462v2","updated":"2023-11-23T12:52:05Z","published":"2023-11-19T23:59:22Z","title":"LLM aided semi-supervision for Extractive Dialog Summarization","summary":"  Generating high-quality summaries for chat dialogs often requires large\nlabeled datasets. We propose a method to efficiently use unlabeled data for\nextractive summarization of customer-agent dialogs. In our method, we frame\nsummarization as a question-answering problem and use state-of-the-art large\nlanguage models (LLMs) to generate pseudo-labels for a dialog. We then use\nthese pseudo-labels to fine-tune a chat summarization model, effectively\ntransferring knowledge from the large LLM into a smaller specialized model. We\ndemonstrate our method on the \\tweetsumm dataset, and show that using 10% of\nthe original labelled data set we can achieve 65.9/57.0/61.0 ROUGE-1/-2/-L,\nwhereas the current state-of-the-art trained on the entire training data set\nobtains 65.16/55.81/64.37 ROUGE-1/-2/-L. In other words, in the worst case\n(i.e., ROUGE-L) we still effectively retain 94.7% of the performance while\nusing only 10% of the data.\n","authors":["Nishant Mishra","Gaurav Sahu","Iacer Calixto","Ameen Abu-Hanna","Issam H. Laradji"],"pdf_url":"https://arxiv.org/pdf/2311.11462v2.pdf","comment":"to be published in EMNLP Findings"},{"id":"http://arxiv.org/abs/2311.14212v1","updated":"2023-11-23T21:54:22Z","published":"2023-11-23T21:54:22Z","title":"Annotation Sensitivity: Training Data Collection Methods Affect Model\n  Performance","summary":"  When training data are collected from human annotators, the design of the\nannotation instrument, the instructions given to annotators, the\ncharacteristics of the annotators, and their interactions can impact training\ndata. This study demonstrates that design choices made when creating an\nannotation instrument also impact the models trained on the resulting\nannotations.\n  We introduce the term annotation sensitivity to refer to the impact of\nannotation data collection methods on the annotations themselves and on\ndownstream model performance and predictions.\n  We collect annotations of hate speech and offensive language in five\nexperimental conditions of an annotation instrument, randomly assigning\nannotators to conditions. We then fine-tune BERT models on each of the five\nresulting datasets and evaluate model performance on a holdout portion of each\ncondition. We find considerable differences between the conditions for 1) the\nshare of hate speech/offensive language annotations, 2) model performance, 3)\nmodel predictions, and 4) model learning curves.\n  Our results emphasize the crucial role played by the annotation instrument\nwhich has received little attention in the machine learning literature. We call\nfor additional research into how and why the instrument impacts the annotations\nto inform the development of best practices in instrument design.\n","authors":["Christoph Kern","Stephanie Eckman","Jacob Beck","Rob Chew","Bolei Ma","Frauke Kreuter"],"pdf_url":"https://arxiv.org/pdf/2311.14212v1.pdf","comment":"EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2311.14199v1","updated":"2023-11-23T20:52:44Z","published":"2023-11-23T20:52:44Z","title":"A Systematic Review of Deep Learning-based Research on Radiology Report\n  Generation","summary":"  Radiology report generation (RRG) aims to automatically generate free-text\ndescriptions from clinical radiographs, e.g., chest X-Ray images. RRG plays an\nessential role in promoting clinical automation and presents significant help\nto provide practical assistance for inexperienced doctors and alleviate\nradiologists' workloads. Therefore, consider these meaningful potentials,\nresearch on RRG is experiencing explosive growth in the past half-decade,\nespecially with the rapid development of deep learning approaches. Existing\nstudies perform RRG from the perspective of enhancing different modalities,\nprovide insights on optimizing the report generation process with elaborated\nfeatures from both visual and textual information, and further facilitate RRG\nwith the cross-modal interactions among them. In this paper, we present a\ncomprehensive review of deep learning-based RRG from various perspectives.\nSpecifically, we firstly cover pivotal RRG approaches based on the\ntask-specific features of radiographs, reports, and the cross-modal relations\nbetween them, and then illustrate the benchmark datasets conventionally used\nfor this task with evaluation metrics, subsequently analyze the performance of\ndifferent approaches and finally offer our summary on the challenges and the\ntrends in future directions. Overall, the goal of this paper is to serve as a\ntool for understanding existing literature and inspiring potential valuable\nresearch in the field of RRG.\n","authors":["Chang Liu","Yuanhe Tian","Yan Song"],"pdf_url":"https://arxiv.org/pdf/2311.14199v1.pdf","comment":"26 pages, 6 figures"},{"id":"http://arxiv.org/abs/2307.06435v6","updated":"2023-11-23T19:23:19Z","published":"2023-07-12T20:01:52Z","title":"A Comprehensive Overview of Large Language Models","summary":"  Large Language Models (LLMs) have recently demonstrated remarkable\ncapabilities in natural language processing tasks and beyond. This success of\nLLMs has led to a large influx of research contributions in this direction.\nThese works encompass diverse topics such as architectural innovations, better\ntraining strategies, context length improvements, fine-tuning, multi-modal\nLLMs, robotics, datasets, benchmarking, efficiency, and more. With the rapid\ndevelopment of techniques and regular breakthroughs in LLM research, it has\nbecome considerably challenging to perceive the bigger picture of the advances\nin this direction. Considering the rapidly emerging plethora of literature on\nLLMs, it is imperative that the research community is able to benefit from a\nconcise yet comprehensive overview of the recent developments in this field.\nThis article provides an overview of the existing literature on a broad range\nof LLM-related concepts. Our self-contained comprehensive overview of LLMs\ndiscusses relevant background concepts along with covering the advanced topics\nat the frontier of research in LLMs. This review article is intended to not\nonly provide a systematic survey but also a quick comprehensive reference for\nthe researchers and practitioners to draw insights from extensive informative\nsummaries of the existing works to advance the LLM research.\n","authors":["Humza Naveed","Asad Ullah Khan","Shi Qiu","Muhammad Saqib","Saeed Anwar","Muhammad Usman","Naveed Akhtar","Nick Barnes","Ajmal Mian"],"pdf_url":"https://arxiv.org/pdf/2307.06435v6.pdf","comment":"Work in-progress"},{"id":"http://arxiv.org/abs/2311.14169v1","updated":"2023-11-23T19:20:59Z","published":"2023-11-23T19:20:59Z","title":"Evaluating GPT-4's Vision Capabilities on Brazilian University Admission\n  Exams","summary":"  Recent advancements in language models have showcased human-comparable\nperformance in academic entrance exams. However, existing studies often\noverlook questions that require the integration of visual comprehension, thus\ncompromising the full spectrum and complexity inherent in real-world scenarios.\nTo address this gap, we present a comprehensive framework to evaluate language\nmodels on entrance exams, which incorporates both textual and visual elements.\nWe evaluate the two most recent editions of Exame Nacional do Ensino M\\'edio\n(ENEM), the main standardized entrance examination adopted by Brazilian\nuniversities. Our study not only reaffirms the capabilities of GPT-4 as the\nstate of the art for handling complex multidisciplinary questions, but also\npioneers in offering a realistic assessment of multimodal language models on\nPortuguese examinations. One of the highlights is that text captions\ntranscribing visual content outperform the direct use of images, suggesting\nthat the vision model has room for improvement. Yet, despite improvements\nafforded by images or captions, mathematical questions remain a challenge for\nthese state-of-the-art models. The code and data used on experiments are\navailable at https://github.com/piresramon/gpt-4-enem.\n","authors":["Ramon Pires","Thales Sales Almeida","Hugo Abonizio","Rodrigo Nogueira"],"pdf_url":"https://arxiv.org/pdf/2311.14169v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2303.17003"},{"id":"http://arxiv.org/abs/2311.14126v1","updated":"2023-11-23T17:47:14Z","published":"2023-11-23T17:47:14Z","title":"Towards Auditing Large Language Models: Improving Text-based Stereotype\n  Detection","summary":"  Large Language Models (LLM) have made significant advances in the recent past\nbecoming more mainstream in Artificial Intelligence (AI) enabled human-facing\napplications. However, LLMs often generate stereotypical output inherited from\nhistorical data, amplifying societal biases and raising ethical concerns. This\nwork introduces i) the Multi-Grain Stereotype Dataset, which includes 52,751\ninstances of gender, race, profession and religion stereotypic text and ii) a\nnovel stereotype classifier for English text. We design several experiments to\nrigorously test the proposed model trained on the novel dataset. Our\nexperiments show that training the model in a multi-class setting can\noutperform the one-vs-all binary counterpart. Consistent feature importance\nsignals from different eXplainable AI tools demonstrate that the new model\nexploits relevant text features. We utilise the newly created model to assess\nthe stereotypic behaviour of the popular GPT family of models and observe the\nreduction of bias over time. In summary, our work establishes a robust and\npractical framework for auditing and evaluating the stereotypic bias in LLM.\n","authors":["Wu Zekun","Sahan Bulathwela","Adriano Soares Koshiyama"],"pdf_url":"https://arxiv.org/pdf/2311.14126v1.pdf","comment":"2023 NeurIPS SoLaR Workshop Accepted"},{"id":"http://arxiv.org/abs/2311.14115v1","updated":"2023-11-23T17:20:36Z","published":"2023-11-23T17:20:36Z","title":"A density estimation perspective on learning from pairwise human\n  preferences","summary":"  Learning from human feedback (LHF) -- and in particular learning from\npairwise preferences -- has recently become a crucial ingredient in training\nlarge language models (LLMs), and has been the subject of much research. Most\nrecent works frame it as a reinforcement learning problem, where a reward\nfunction is learned from pairwise preference data and the LLM is treated as a\npolicy which is adapted to maximize the rewards, often under additional\nregularization constraints. We propose an alternative interpretation which\ncenters on the generative process for pairwise preferences and treats LHF as a\ndensity estimation problem. We provide theoretical and empirical results\nshowing that for a family of generative processes defined via preference\nbehavior distribution equations, training a reward function on pairwise\npreferences effectively models an annotator's implicit preference distribution.\nFinally, we discuss and present findings on \"annotator misspecification\" --\nfailure cases where wrong modeling assumptions are made about annotator\nbehavior, resulting in poorly-adapted models -- suggesting that approaches that\nlearn from pairwise human preferences could have trouble learning from a\npopulation of annotators with diverse viewpoints.\n","authors":["Vincent Dumoulin","Daniel D. Johnson","Pablo Samuel Castro","Hugo Larochelle","Yann Dauphin"],"pdf_url":"https://arxiv.org/pdf/2311.14115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14096v1","updated":"2023-11-23T16:45:56Z","published":"2023-11-23T16:45:56Z","title":"Auditing and Mitigating Cultural Bias in LLMs","summary":"  Culture fundamentally shapes people's reasoning, behavior, and communication.\nGenerative artificial intelligence (AI) technologies may cause a shift towards\na dominant culture. As people increasingly use AI to expedite and even automate\nvarious professional and personal tasks, cultural values embedded in AI models\nmay bias authentic expression. We audit large language models for cultural\nbias, comparing their responses to nationally representative survey data, and\nevaluate country-specific prompting as a mitigation strategy. We find that\nGPT-4, 3.5 and 3 exhibit cultural values resembling English-speaking and\nProtestant European countries. Our mitigation strategy reduces cultural bias in\nrecent models but not for all countries/territories. To avoid cultural bias in\ngenerative AI, especially in high-stakes contexts, we suggest using culture\nmatching and ongoing cultural audits.\n","authors":["Yan Tao","Olga Viberg","Ryan S. Baker","Rene F. Kizilcec"],"pdf_url":"https://arxiv.org/pdf/2311.14096v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14087v1","updated":"2023-11-23T16:26:24Z","published":"2023-11-23T16:26:24Z","title":"Question Answering in Natural Language: the Special Case of Temporal\n  Expressions","summary":"  Although general question answering has been well explored in recent years,\ntemporal question answering is a task which has not received as much focus. Our\nwork aims to leverage a popular approach used for general question answering,\nanswer extraction, in order to find answers to temporal questions within a\nparagraph. To train our model, we propose a new dataset, inspired by SQuAD,\nspecifically tailored to provide rich temporal information. We chose to adapt\nthe corpus WikiWars, which contains several documents on history's greatest\nconflicts. Our evaluation shows that a deep learning model trained to perform\npattern matching, often used in general question answering, can be adapted to\ntemporal question answering, if we accept to ask questions whose answers must\nbe directly present within a text.\n","authors":["Armand Stricker"],"pdf_url":"https://arxiv.org/pdf/2311.14087v1.pdf","comment":"Accepted at Student Research Workshop associated with RANLP-2021"},{"id":"http://arxiv.org/abs/2311.14076v1","updated":"2023-11-23T16:08:39Z","published":"2023-11-23T16:08:39Z","title":"Searching for Snippets of Open-Domain Dialogue in Task-Oriented Dialogue\n  Datasets","summary":"  Most existing dialogue corpora and models have been designed to fit into 2\npredominant categories : task-oriented dialogues portray functional goals, such\nas making a restaurant reservation or booking a plane ticket, while\nchit-chat/open-domain dialogues focus on holding a socially engaging talk with\na user. However, humans tend to seamlessly switch between modes and even use\nchitchat to enhance task-oriented conversations. To bridge this gap, new\ndatasets have recently been created, blending both communication modes into\nconversation examples. The approaches used tend to rely on adding chit-chat\nsnippets to pre-existing, human-generated task-oriented datasets. Given the\ntendencies observed in humans, we wonder however if the latter do not\n\\textit{already} hold chit-chat sequences. By using topic modeling and\nsearching for topics which are most similar to a set of keywords related to\nsocial talk, we explore the training sets of Schema-Guided Dialogues and\nMultiWOZ. Our study shows that sequences related to social talk are indeed\nnaturally present, motivating further research on ways chitchat is combined\ninto task-oriented dialogues.\n","authors":["Armand Stricker","Patrick Paroubek"],"pdf_url":"https://arxiv.org/pdf/2311.14076v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14067v1","updated":"2023-11-23T15:50:42Z","published":"2023-11-23T15:50:42Z","title":"Enhancing Task-Oriented Dialogues with Chitchat: a Comparative Study\n  Based on Lexical Diversity and Divergence","summary":"  As a recent development, task-oriented dialogues (TODs) have been enriched\nwith chitchat in an effort to make dialogues more diverse and engaging. This\nenhancement is particularly valuable as TODs are often confined to narrow\ndomains, making the mitigation of repetitive and predictable responses a\nsignificant challenge. This paper presents a comparative analysis of three\nchitchat enhancements, aiming to identify the most effective approach in terms\nof diversity. Additionally, we quantify the divergence between the added\nchitchat, the original task-oriented language, and chitchat typically found in\nchitchat datasets, highlighting the top 20 divergent keywords for each\ncomparison. Our findings drive a discussion on future enhancements for\naugmenting TODs, emphasizing the importance of grounding dialogues beyond the\ntask to achieve more diverse and natural exchanges.\n","authors":["Armand Stricker","Patrick Paroubek"],"pdf_url":"https://arxiv.org/pdf/2311.14067v1.pdf","comment":"Accepted at ASRU 2023"},{"id":"http://arxiv.org/abs/2305.13455v3","updated":"2023-11-23T15:47:52Z","published":"2023-05-22T19:56:10Z","title":"Clembench: Using Game Play to Evaluate Chat-Optimized Language Models as\n  Conversational Agents","summary":"  Recent work has proposed a methodology for the systematic evaluation of\n\"Situated Language Understanding Agents\"-agents that operate in rich linguistic\nand non-linguistic contexts-through testing them in carefully constructed\ninteractive settings. Other recent work has argued that Large Language Models\n(LLMs), if suitably set up, can be understood as (simulators of) such agents. A\nconnection suggests itself, which this paper explores: Can LLMs be evaluated\nmeaningfully by exposing them to constrained game-like settings that are built\nto challenge specific capabilities? As a proof of concept, this paper\ninvestigates five interaction settings, showing that current chat-optimised\nLLMs are, to an extent, capable to follow game-play instructions. Both this\ncapability and the quality of the game play, measured by how well the\nobjectives of the different games are met, follows the development cycle, with\nnewer models performing better. The metrics even for the comparatively simple\nexample games are far from being saturated, suggesting that the proposed\ninstrument will remain to have diagnostic value. Our general framework for\nimplementing and evaluating games with LLMs is available at\nhttps://github.com/clembench .\n","authors":["Kranti Chalamalasetti","Jana Götze","Sherzod Hakimov","Brielen Madureira","Philipp Sadler","David Schlangen"],"pdf_url":"https://arxiv.org/pdf/2305.13455v3.pdf","comment":"EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.14063v1","updated":"2023-11-23T15:42:00Z","published":"2023-11-23T15:42:00Z","title":"Do VSR Models Generalize Beyond LRS3?","summary":"  The Lip Reading Sentences-3 (LRS3) benchmark has primarily been the focus of\nintense research in visual speech recognition (VSR) during the last few years.\nAs a result, there is an increased risk of overfitting to its excessively used\ntest set, which is only one hour duration. To alleviate this issue, we build a\nnew VSR test set named WildVSR, by closely following the LRS3 dataset creation\nprocesses. We then evaluate and analyse the extent to which the current VSR\nmodels generalize to the new test data. We evaluate a broad range of publicly\navailable VSR models and find significant drops in performance on our test set,\ncompared to their corresponding LRS3 results. Our results suggest that the\nincrease in word error rates is caused by the models inability to generalize to\nslightly harder and in the wild lip sequences than those found in the LRS3 test\nset. Our new test benchmark is made public in order to enable future research\ntowards more robust VSR models.\n","authors":["Yasser Abdelaziz Dahou Djilali","Sanath Narayan","Eustache Le Bihan","Haithem Boussaid","Ebtessam Almazrouei","Merouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2311.14063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13987v1","updated":"2023-11-23T13:13:48Z","published":"2023-11-23T13:13:48Z","title":"Jam-ALT: A Formatting-Aware Lyrics Transcription Benchmark","summary":"  Current automatic lyrics transcription (ALT) benchmarks focus exclusively on\nword content and ignore the finer nuances of written lyrics including\nformatting and punctuation, which leads to a potential misalignment with the\ncreative products of musicians and songwriters as well as listeners'\nexperiences. For example, line breaks are important in conveying information\nabout rhythm, emotional emphasis, rhyme, and high-level structure. To address\nthis issue, we introduce Jam-ALT, a new lyrics transcription benchmark based on\nthe JamendoLyrics dataset. Our contribution is twofold. Firstly, a complete\nrevision of the transcripts, geared specifically towards ALT evaluation by\nfollowing a newly created annotation guide that unifies the music industry's\nguidelines, covering aspects such as punctuation, line breaks, spelling,\nbackground vocals, and non-word sounds. Secondly, a suite of evaluation metrics\ndesigned, unlike the traditional word error rate, to capture such phenomena. We\nhope that the proposed benchmark contributes to the ALT task, enabling more\nprecise and reliable assessments of transcription systems and enhancing the\nuser experience in lyrics applications such as subtitle renderings for live\ncaptioning or karaoke.\n","authors":["Ondřej Cífka","Constantinos Dimitriou","Cheng-i Wang","Hendrik Schreiber","Luke Miner","Fabian-Robert Stöter"],"pdf_url":"https://arxiv.org/pdf/2311.13987v1.pdf","comment":"6 pages (3 pages main content); website:\n  https://audioshake.github.io/jam-alt/; data:\n  https://huggingface.co/datasets/audioshake/jam-alt; code:\n  https://github.com/audioshake/alt-eval/"},{"id":"http://arxiv.org/abs/2311.13982v1","updated":"2023-11-23T12:52:37Z","published":"2023-11-23T12:52:37Z","title":"Probabilistic Tree-of-thought Reasoning for Answering\n  Knowledge-intensive Complex Questions","summary":"  Large language models (LLMs) are capable of answering knowledge-intensive\ncomplex questions with chain-of-thought (CoT) reasoning. However, they tend to\ngenerate factually incorrect reasoning steps when the required knowledge is not\navailable or up-to-date in models' parameters. Recent works turn to retrieving\nexternal knowledge to augment CoT reasoning. Despite being promising, these\nchain-based methods suffer from: 1) Negative retrieval. Unnecessary or\nincorrect retrieval may mislead the reasoning; 2) Limited sight. Lacking the\nability to look backward or forward, a local error in one step will propagate\nalong the chain.\n  In this paper, we propose a novel approach: Probabilistic Tree-of-thought\nReasoning (ProbTree). First, LLMs translate a complex question into a query\ntree, in which each non-root node denotes a sub-question of its parent node.\nThen, probabilistic reasoning is conducted over the tree, by solving questions\nfrom leaf to root considering the confidence of both question decomposing and\nanswering. During reasoning, for leaf nodes, LLMs choose a more confident\nanswer from Closed-book QA that employs parametric knowledge and Open-book QA\nthat employs retrieved external knowledge, thus eliminating the negative\nretrieval problem. For non-leaf nodes, with the hierarchical structure, LLMs\nhave broader sights and are able to globally reason with the information from\nchild nodes, thus recovering from local errors. The experiments on three\nComplex QA datasets under the open-domain setting show that our approach\noutperforms SOTA methods significantly, demonstrating the effect of\nprobabilistic tree-of-thought reasoning.\n","authors":["Shulin Cao","Jiajie Zhang","Jiaxin Shi","Xin Lv","Zijun Yao","Qi Tian","Juanzi Li","Lei Hou"],"pdf_url":"https://arxiv.org/pdf/2311.13982v1.pdf","comment":"Accepted by EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.10642v2","updated":"2023-11-23T12:47:26Z","published":"2023-11-17T16:58:52Z","title":"Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as\n  an Alternative to Attention Layers in Transformers","summary":"  This work presents an analysis of the effectiveness of using standard shallow\nfeed-forward networks to mimic the behavior of the attention mechanism in the\noriginal Transformer model, a state-of-the-art architecture for\nsequence-to-sequence tasks. We substitute key elements of the attention\nmechanism in the Transformer with simple feed-forward networks, trained using\nthe original components via knowledge distillation. Our experiments, conducted\non the IWSLT2017 dataset, reveal the capacity of these \"attentionless\nTransformers\" to rival the performance of the original architecture. Through\nrigorous ablation studies, and experimenting with various replacement network\ntypes and sizes, we offer insights that support the viability of our approach.\nThis not only sheds light on the adaptability of shallow feed-forward networks\nin emulating attention mechanisms but also underscores their potential to\nstreamline complex architectures for sequence-to-sequence tasks.\n","authors":["Vukasin Bozic","Danilo Dordevic","Daniele Coppola","Joseph Thommes","Sidak Pal Singh"],"pdf_url":"https://arxiv.org/pdf/2311.10642v2.pdf","comment":"Accepted at AAAI24(https://aaai.org/aaai-conference/)"},{"id":"http://arxiv.org/abs/2311.13957v1","updated":"2023-11-23T12:15:56Z","published":"2023-11-23T12:15:56Z","title":"Efficient Trigger Word Insertion","summary":"  With the boom in the natural language processing (NLP) field these years,\nbackdoor attacks pose immense threats against deep neural network models.\nHowever, previous works hardly consider the effect of the poisoning rate. In\nthis paper, our main objective is to reduce the number of poisoned samples\nwhile still achieving a satisfactory Attack Success Rate (ASR) in text backdoor\nattacks. To accomplish this, we propose an efficient trigger word insertion\nstrategy in terms of trigger word optimization and poisoned sample selection.\nExtensive experiments on different datasets and models demonstrate that our\nproposed method can significantly improve attack effectiveness in text\nclassification tasks. Remarkably, our approach achieves an ASR of over 90% with\nonly 10 poisoned samples in the dirty-label setting and requires merely 1.5% of\nthe training data in the clean-label setting.\n","authors":["Yueqi Zeng","Ziqiang Li","Pengfei Xia","Lei Liu","Bin Li"],"pdf_url":"https://arxiv.org/pdf/2311.13957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10751v2","updated":"2023-11-23T12:14:08Z","published":"2023-11-02T14:32:16Z","title":"ProAgent: From Robotic Process Automation to Agentic Process Automation","summary":"  From ancient water wheels to robotic process automation (RPA), automation\ntechnology has evolved throughout history to liberate human beings from arduous\ntasks. Yet, RPA struggles with tasks needing human-like intelligence,\nespecially in elaborate design of workflow construction and dynamic\ndecision-making in workflow execution. As Large Language Models (LLMs) have\nemerged human-like intelligence, this paper introduces Agentic Process\nAutomation (APA), a groundbreaking automation paradigm using LLM-based agents\nfor advanced automation by offloading the human labor to agents associated with\nconstruction and execution. We then instantiate ProAgent, an LLM-based agent\ndesigned to craft workflows from human instructions and make intricate\ndecisions by coordinating specialized agents. Empirical experiments are\nconducted to detail its construction and execution procedure of workflow,\nshowcasing the feasibility of APA, unveiling the possibility of a new paradigm\nof automation driven by agents. Our code is public at\nhttps://github.com/OpenBMB/ProAgent.\n","authors":["Yining Ye","Xin Cong","Shizuo Tian","Jiannan Cao","Hao Wang","Yujia Qin","Yaxi Lu","Heyang Yu","Huadong Wang","Yankai Lin","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2311.10751v2.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2311.05286v2","updated":"2023-11-23T12:12:22Z","published":"2023-11-09T11:29:44Z","title":"Causal Inference from Text: Unveiling Interactions between Variables","summary":"  Adjusting for latent covariates is crucial for estimating causal effects from\nobservational textual data. Most existing methods only account for confounding\ncovariates that affect both treatment and outcome, potentially leading to\nbiased causal effects. This bias arises from insufficient consideration of\nnon-confounding covariates, which are relevant only to either the treatment or\nthe outcome. In this work, we aim to mitigate the bias by unveiling\ninteractions between different variables to disentangle the non-confounding\ncovariates when estimating causal effects from text. The disentangling process\nensures covariates only contribute to their respective objectives, enabling\nindependence between variables. Additionally, we impose a constraint to balance\nrepresentations from the treatment group and control group to alleviate\nselection bias. We conduct experiments on two different treatment factors under\nvarious scenarios, and the proposed model significantly outperforms recent\nstrong baselines. Furthermore, our thorough analysis on earnings call\ntranscripts demonstrates that our model can effectively disentangle the\nvariables, and further investigations into real-world scenarios provide\nguidance for investors to make informed decisions.\n","authors":["Yuxiang Zhou","Yulan He"],"pdf_url":"https://arxiv.org/pdf/2311.05286v2.pdf","comment":"EMNLP 2023 Findings (mark typo corrected)"},{"id":"http://arxiv.org/abs/2311.13951v1","updated":"2023-11-23T12:04:25Z","published":"2023-11-23T12:04:25Z","title":"MLLM-Bench, Evaluating Multi-modal LLMs using GPT-4V","summary":"  In the pursuit of Artificial General Intelligence (AGI), the integration of\nvision in language models has marked a significant milestone. The advent of\nvision-language models (MLLMs) like GPT-4V have expanded AI applications,\naligning with the multi-modal capabilities of the human brain. However,\nevaluating the efficacy of MLLMs poses a substantial challenge due to the\nsubjective nature of tasks that lack definitive answers. Existing automatic\nevaluation methodologies on multi-modal large language models rely on objective\nqueries that have standard answers, inadequately addressing the nuances of\ncreative and associative multi-modal tasks. To address this, we introduce\nMLLM-Bench, an innovative benchmark inspired by Vicuna, spanning a diverse\narray of scenarios, including Perception, Understanding, Applying, Analyzing,\nEvaluating, and Creation along with the ethical consideration. MLLM-Bench is\ndesigned to reflect user experience more accurately and provide a more holistic\nassessment of model performance. Comparative evaluations indicate a significant\nperformance gap between existing open-source models and GPT-4V. We posit that\nMLLM-Bench will catalyze progress in the open-source community towards\ndeveloping user-centric vision-language models that meet a broad spectrum of\nreal-world applications. See online leaderboard in\n\\url{https://mllm-bench.llmzoo.com}.\n","authors":["Wentao Ge","Shunian Chen","Guiming Chen","Junying Chen","Zhihong Chen","Shuo Yan","Chenghao Zhu","Ziyue Lin","Wenya Xie","Xidong Wang","Anningzhe Gao","Zhiyi Zhang","Jianquan Li","Xiang Wan","Benyou Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13951v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13937v1","updated":"2023-11-23T11:40:28Z","published":"2023-11-23T11:40:28Z","title":"Exploring Methods for Cross-lingual Text Style Transfer: The Case of\n  Text Detoxification","summary":"  Text detoxification is the task of transferring the style of text from toxic\nto neutral. While here are approaches yielding promising results in monolingual\nsetup, e.g., (Dale et al., 2021; Hallinan et al., 2022), cross-lingual transfer\nfor this task remains a challenging open problem (Moskovskiy et al., 2022). In\nthis work, we present a large-scale study of strategies for cross-lingual text\ndetoxification -- given a parallel detoxification corpus for one language; the\ngoal is to transfer detoxification ability to another language for which we do\nnot have such a corpus. Moreover, we are the first to explore a new task where\ntext translation and detoxification are performed simultaneously, providing\nseveral strong baselines for this task. Finally, we introduce new automatic\ndetoxification evaluation metrics with higher correlations with human judgments\nthan previous benchmarks. We assess the most promising approaches also with\nmanual markup, determining the answer for the best strategy to transfer the\nknowledge of text detoxification between languages.\n","authors":["Daryna Dementieva","Daniil Moskovskiy","David Dale","Alexander Panchenko"],"pdf_url":"https://arxiv.org/pdf/2311.13937v1.pdf","comment":"AACL 2023, main conference, long paper"},{"id":"http://arxiv.org/abs/2311.13921v1","updated":"2023-11-23T11:14:13Z","published":"2023-11-23T11:14:13Z","title":"Some Like It Small: Czech Semantic Embedding Models for Industry\n  Applications","summary":"  This article focuses on the development and evaluation of Small-sized Czech\nsentence embedding models. Small models are important components for real-time\nindustry applications in resource-constrained environments. Given the limited\navailability of labeled Czech data, alternative approaches, including\npre-training, knowledge distillation, and unsupervised contrastive fine-tuning,\nare investigated. Comprehensive intrinsic and extrinsic analyses are conducted,\nshowcasing the competitive performance of our models compared to significantly\nlarger counterparts, with approximately 8 times smaller size and 5 times faster\nspeed than conventional Base-sized models. To promote cooperation and\nreproducibility, both the models and the evaluation pipeline are made publicly\naccessible. Ultimately, this article presents practical applications of the\ndeveloped sentence embedding models in Seznam.cz, the Czech search engine.\nThese models have effectively replaced previous counterparts, enhancing the\noverall search experience for instance, in organic search, featured snippets,\nand image search. This transition has yielded improved performance.\n","authors":["Jiří Bednář","Jakub Náplava","Petra Barančíková","Ondřej Lisický"],"pdf_url":"https://arxiv.org/pdf/2311.13921v1.pdf","comment":"Accepted at the Thirty-Sixth Annual Conference on Innovative\n  Applications of Artificial Intelligence (IAAI-24). IAAI Innovative\n  Application Award. 9 pages"},{"id":"http://arxiv.org/abs/2311.06622v2","updated":"2023-11-23T10:57:10Z","published":"2023-11-11T17:39:24Z","title":"TrainerAgent: Customizable and Efficient Model Training through\n  LLM-Powered Multi-Agent System","summary":"  Training AI models has always been challenging, especially when there is a\nneed for custom models to provide personalized services. Algorithm engineers\noften face a lengthy process to iteratively develop models tailored to specific\nbusiness requirements, making it even more difficult for non-experts. The quest\nfor high-quality and efficient model development, along with the emergence of\nLarge Language Model (LLM) Agents, has become a key focus in the industry.\nLeveraging the powerful analytical, planning, and decision-making capabilities\nof LLM, we propose a TrainerAgent system comprising a multi-agent framework\nincluding Task, Data, Model and Server agents. These agents analyze\nuser-defined tasks, input data, and requirements (e.g., accuracy, speed),\noptimizing them comprehensively from both data and model perspectives to obtain\nsatisfactory models, and finally deploy these models as online service.\nExperimental evaluations on classical discriminative and generative tasks in\ncomputer vision and natural language processing domains demonstrate that our\nsystem consistently produces models that meet the desired criteria.\nFurthermore, the system exhibits the ability to critically identify and reject\nunattainable tasks, such as fantastical scenarios or unethical requests,\nensuring robustness and safety. This research presents a significant\nadvancement in achieving desired models with increased efficiency and quality\nas compared to traditional model development, facilitated by the integration of\nLLM-powered analysis, decision-making, and execution capabilities, as well as\nthe collaboration among four agents. We anticipate that our work will\ncontribute to the advancement of research on TrainerAgent in both academic and\nindustry communities, potentially establishing it as a new paradigm for model\ndevelopment in the field of AI.\n","authors":["Haoyuan Li","Hao Jiang","Tianke Zhang","Zhelun Yu","Aoxiong Yin","Hao Cheng","Siming Fu","Yuhao Zhang","Wanggui He"],"pdf_url":"https://arxiv.org/pdf/2311.06622v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13910v1","updated":"2023-11-23T10:56:14Z","published":"2023-11-23T10:56:14Z","title":"Dialogue Quality and Emotion Annotations for Customer Support\n  Conversations","summary":"  Task-oriented conversational datasets often lack topic variability and\nlinguistic diversity. However, with the advent of Large Language Models (LLMs)\npretrained on extensive, multilingual and diverse text data, these limitations\nseem overcome. Nevertheless, their generalisability to different languages and\ndomains in dialogue applications remains uncertain without benchmarking\ndatasets. This paper presents a holistic annotation approach for emotion and\nconversational quality in the context of bilingual customer support\nconversations. By performing annotations that take into consideration the\ncomplete instances that compose a conversation, one can form a broader\nperspective of the dialogue as a whole. Furthermore, it provides a unique and\nvaluable resource for the development of text classification models. To this\nend, we present benchmarks for Emotion Recognition and Dialogue Quality\nEstimation and show that further research is needed to leverage these models in\na production setting.\n","authors":["John Mendonça","Patrícia Pereira","Miguel Menezes","Vera Cabarrão","Ana C. Farinha","Helena Moniz","João Paulo Carvalho","Alon Lavie","Isabel Trancoso"],"pdf_url":"https://arxiv.org/pdf/2311.13910v1.pdf","comment":"Accepted at GEM (EMNLP Workshop)"},{"id":"http://arxiv.org/abs/2311.13892v1","updated":"2023-11-23T10:23:51Z","published":"2023-11-23T10:23:51Z","title":"General Phrase Debiaser: Debiasing Masked Language Models at a\n  Multi-Token Level","summary":"  The social biases and unwelcome stereotypes revealed by pretrained language\nmodels are becoming obstacles to their application. Compared to numerous\ndebiasing methods targeting word level, there has been relatively less\nattention on biases present at phrase level, limiting the performance of\ndebiasing in discipline domains. In this paper, we propose an automatic\nmulti-token debiasing pipeline called \\textbf{General Phrase Debiaser}, which\nis capable of mitigating phrase-level biases in masked language models.\nSpecifically, our method consists of a \\textit{phrase filter stage} that\ngenerates stereotypical phrases from Wikipedia pages as well as a \\textit{model\ndebias stage} that can debias models at the multi-token level to tackle bias\nchallenges on phrases. The latter searches for prompts that trigger model's\nbias, and then uses them for debiasing. State-of-the-art results on standard\ndatasets and metrics show that our approach can significantly reduce gender\nbiases on both career and multiple disciplines, across models with varying\nparameter sizes.\n","authors":["Bingkang Shi","Xiaodan Zhang","Dehan Kong","Yulei Wu","Zongzhen Liu","Honglei Lyu","Longtao Huang"],"pdf_url":"https://arxiv.org/pdf/2311.13892v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06025v2","updated":"2023-11-23T10:19:47Z","published":"2023-11-10T12:25:32Z","title":"ChiMed-GPT: A Chinese Medical Large Language Model with Full Training\n  Regime and Better Alignment to Human Preferences","summary":"  Recently, the increasing demand for superior medical services has highlighted\nthe discrepancies in the medical infrastructure. With big data, especially\ntexts, forming the foundation of medical services, there is an exigent need for\neffective natural language processing (NLP) solutions tailored to the\nhealthcare domain. Conventional approaches leveraging pre-trained models\npresent promising results in this domain and current large language models\n(LLMs) offer advanced foundation for medical text processing. However, most\nmedical LLMs are trained only with supervised fine-tuning (SFT), even though it\nefficiently empowers LLMs to understand and respond to medical instructions but\nis ineffective in learning domain knowledge and aligning with human preference.\nAnother engineering barrier that prevents current medical LLM from better text\nprocessing ability is their restricted context length (e.g., 2,048 tokens),\nmaking it hard for the LLMs to process long context, which is frequently\nrequired in the medical domain. In this work, we propose ChiMed-GPT, a new\nbenchmark LLM designed explicitly for Chinese medical domain, with enlarged\ncontext length to 4,096 tokens and undergoes a comprehensive training regime\nwith pre-training, SFT, and RLHF. Evaluations on real-world tasks including\ninformation extraction, question answering, and dialogue generation demonstrate\nChiMed-GPT's superior performance over general domain LLMs. Furthermore, we\nanalyze possible biases through prompting ChiMed-GPT to perform attitude scales\nregarding discrimination of patients, so as to contribute to further\nresponsible development of LLMs in the medical domain. The code and model are\nreleased at https://github.com/synlp/ChiMed-GPT.\n","authors":["Yuanhe Tian","Ruyi Gan","Yan Song","Jiaxing Zhang","Yongdong Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.06025v2.pdf","comment":"17 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.13878v1","updated":"2023-11-23T09:58:39Z","published":"2023-11-23T09:58:39Z","title":"Minimizing Factual Inconsistency and Hallucination in Large Language\n  Models","summary":"  Large Language Models (LLMs) are widely used in critical fields such as\nhealthcare, education, and finance due to their remarkable proficiency in\nvarious language-related tasks. However, LLMs are prone to generating factually\nincorrect responses or \"hallucinations,\" which can lead to a loss of\ncredibility and trust among users. To address this issue, we propose a\nmulti-stage framework that generates the rationale first, verifies and refines\nincorrect ones, and uses them as supporting references to generate the answer.\nThe generated rationale enhances the transparency of the answer and our\nframework provides insights into how the model arrived at this answer, by using\nthis rationale and the references to the context. In this paper, we demonstrate\nits effectiveness in improving the quality of responses to drug-related\ninquiries in the life sciences industry. Our framework improves traditional\nRetrieval Augmented Generation (RAG) by enabling OpenAI GPT-3.5-turbo to be\n14-25% more faithful and 16-22% more accurate on two datasets. Furthermore,\nfine-tuning samples based on our framework improves the accuracy of smaller\nopen-access LLMs by 33-42% and competes with RAG on commercial models.\n","authors":["Muneeswaran I","Shreya Saxena","Siva Prasad","M V Sai Prakash","Advaith Shankar","Varun V","Vishal Vaddina","Saisubramaniam Gopalakrishnan"],"pdf_url":"https://arxiv.org/pdf/2311.13878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13857v1","updated":"2023-11-23T08:56:41Z","published":"2023-11-23T08:56:41Z","title":"Challenges of Large Language Models for Mental Health Counseling","summary":"  The global mental health crisis is looming with a rapid increase in mental\ndisorders, limited resources, and the social stigma of seeking treatment. As\nthe field of artificial intelligence (AI) has witnessed significant\nadvancements in recent years, large language models (LLMs) capable of\nunderstanding and generating human-like text may be used in supporting or\nproviding psychological counseling. However, the application of LLMs in the\nmental health domain raises concerns regarding the accuracy, effectiveness, and\nreliability of the information provided. This paper investigates the major\nchallenges associated with the development of LLMs for psychological\ncounseling, including model hallucination, interpretability, bias, privacy, and\nclinical effectiveness. We explore potential solutions to these challenges that\nare practical and applicable to the current paradigm of AI. From our experience\nin developing and deploying LLMs for mental health, AI holds a great promise\nfor improving mental health care, if we can carefully navigate and overcome\npitfalls of LLMs.\n","authors":["Neo Christopher Chung","George Dyer","Lennart Brocki"],"pdf_url":"https://arxiv.org/pdf/2311.13857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13848v1","updated":"2023-11-23T08:34:37Z","published":"2023-11-23T08:34:37Z","title":"Grammatical Error Correction via Mixed-Grained Weighted Training","summary":"  The task of Grammatical Error Correction (GEC) aims to automatically correct\ngrammatical errors in natural texts. Almost all previous works treat annotated\ntraining data equally, but inherent discrepancies in data are neglected. In\nthis paper, the inherent discrepancies are manifested in two aspects, namely,\naccuracy of data annotation and diversity of potential annotations. To this\nend, we propose MainGEC, which designs token-level and sentence-level training\nweights based on inherent discrepancies in accuracy and potential diversity of\ndata annotation, respectively, and then conducts mixed-grained weighted\ntraining to improve the training effect for GEC. Empirical evaluation shows\nthat whether in the Seq2Seq or Seq2Edit manner, MainGEC achieves consistent and\nsignificant performance improvements on two benchmark datasets, demonstrating\nthe effectiveness and superiority of the mixed-grained weighted training.\nFurther ablation experiments verify the effectiveness of designed weights of\nboth granularities in MainGEC.\n","authors":["Jiahao Li","Quan Wang","Chiwei Zhu","Zhendong Mao","Yongdong Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.13848v1.pdf","comment":"EMNLP2023 Findings"},{"id":"http://arxiv.org/abs/2311.13833v1","updated":"2023-11-23T07:33:38Z","published":"2023-11-23T07:33:38Z","title":"Lego: Learning to Disentangle and Invert Concepts Beyond Object\n  Appearance in Text-to-Image Diffusion Models","summary":"  Diffusion models have revolutionized generative content creation and\ntext-to-image (T2I) diffusion models in particular have increased the creative\nfreedom of users by allowing scene synthesis using natural language. T2I models\nexcel at synthesizing concepts such as nouns, appearances, and styles. To\nenable customized content creation based on a few example images of a concept,\nmethods such as Textual Inversion and DreamBooth invert the desired concept and\nenable synthesizing it in new scenes. However, inverting more general concepts\nthat go beyond object appearance and style (adjectives and verbs) through\nnatural language, remains a challenge. Two key characteristics of these\nconcepts contribute to the limitations of current inversion methods. 1)\nAdjectives and verbs are entangled with nouns (subject) and can hinder\nappearance-based inversion methods, where the subject appearance leaks into the\nconcept embedding and 2) describing such concepts often extends beyond single\nword embeddings (being frozen in ice, walking on a tightrope, etc.) that\ncurrent methods do not handle.\n  In this study, we introduce Lego, a textual inversion method designed to\ninvert subject entangled concepts from a few example images. Lego disentangles\nconcepts from their associated subjects using a simple yet effective Subject\nSeparation step and employs a Context Loss that guides the inversion of\nsingle/multi-embedding concepts. In a thorough user study, Lego-generated\nconcepts were preferred over 70% of the time when compared to the baseline.\nAdditionally, visual question answering using a large language model suggested\nLego-generated concepts are better aligned with the text description of the\nconcept.\n","authors":["Saman Motamed","Danda Pani Paudel","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2311.13833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08899v2","updated":"2023-11-23T06:08:59Z","published":"2023-10-13T07:03:39Z","title":"Exploration with Principles for Diverse AI Supervision","summary":"  Training large transformers using next-token prediction has given rise to\ngroundbreaking advancements in AI. While this generative AI approach has\nproduced impressive results, it heavily leans on human supervision. Even\nstate-of-the-art AI models like ChatGPT depend on fine-tuning through human\ndemonstrations, demanding extensive human input and domain expertise. This\nstrong reliance on human oversight poses a significant hurdle to the\nadvancement of AI innovation. To address this limitation, we propose a novel\nparadigm termed Exploratory AI (EAI) aimed at autonomously generating\nhigh-quality training data. Drawing inspiration from unsupervised reinforcement\nlearning (RL) pretraining, EAI achieves exploration within the natural language\nspace. We accomplish this by harnessing large language models to assess the\nnovelty of generated content. Our approach employs two key components: an actor\nthat generates novel content following exploration principles and a critic that\nevaluates the generated content, offering critiques to guide the actor.\nEmpirical evaluations demonstrate that EAI significantly boosts model\nperformance on complex reasoning tasks, addressing the limitations of\nhuman-intensive supervision.\n","authors":["Hao Liu","Matei Zaharia","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2310.08899v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13806v1","updated":"2023-11-23T04:42:27Z","published":"2023-11-23T04:42:27Z","title":"AdaTyper: Adaptive Semantic Column Type Detection","summary":"  Understanding the semantics of relational tables is instrumental for\nautomation in data exploration and preparation systems. A key source for\nunderstanding a table is the semantics of its columns. With the rise of deep\nlearning, learned table representations are now available, which can be applied\nfor semantic type detection and achieve good performance on benchmarks.\nNevertheless, we observe a gap between this performance and its applicability\nin practice. In this paper, we propose AdaTyper to address one of the most\ncritical deployment challenges: adaptation. AdaTyper uses weak-supervision to\nadapt a hybrid type predictor towards new semantic types and shifted data\ndistributions at inference time, using minimal human feedback. The hybrid type\npredictor of AdaTyper combines rule-based methods and a light machine learning\nmodel for semantic column type detection. We evaluate the adaptation\nperformance of AdaTyper on real-world database tables hand-annotated with\nsemantic column types through crowdsourcing and find that the f1-score improves\nfor new and existing types. AdaTyper approaches an average precision of 0.6\nafter only seeing 5 examples, significantly outperforming existing adaptation\nmethods based on human-provided regular expressions or dictionaries.\n","authors":["Madelon Hulsebos","Paul Groth","Çağatay Demiralp"],"pdf_url":"https://arxiv.org/pdf/2311.13806v1.pdf","comment":"Submitted to VLDB'24"},{"id":"http://arxiv.org/abs/2311.13784v1","updated":"2023-11-23T03:03:54Z","published":"2023-11-23T03:03:54Z","title":"DaG LLM ver 1.0: Pioneering Instruction-Tuned Language Modeling for\n  Korean NLP","summary":"  This paper presents the DaG LLM (David and Goliath Large Language Model), a\nlanguage model specialized for Korean and fine-tuned through Instruction Tuning\nacross 41 tasks within 13 distinct categories.\n","authors":["Dongjun Jang","Sangah Lee","Sungjoo Byun","Jinwoong Kim","Jean Seo","Minseok Kim","Soyeon Kim","Chaeyoung Oh","Jaeyoon Kim","Hyemi Jo","Hyopil Shin"],"pdf_url":"https://arxiv.org/pdf/2311.13784v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00648v3","updated":"2023-11-23T02:33:36Z","published":"2023-10-01T12:07:44Z","title":"Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning","summary":"  Parameter-efficient fine-tuning (PEFT) enables efficient adaptation of\npre-trained language models (PLMs) to specific tasks. By tuning only a minimal\nset of (extra) parameters, PEFT achieves performance comparable to full\nfine-tuning. However, despite its prevalent use, the security implications of\nPEFT remain largely unexplored. In this paper, we conduct a pilot study\nrevealing that PEFT exhibits unique vulnerability to trojan attacks.\nSpecifically, we present PETA, a novel attack that accounts for downstream\nadaptation through bilevel optimization: the upper-level objective embeds the\nbackdoor into a PLM while the lower-level objective simulates PEFT to retain\nthe PLM's task-specific performance. With extensive evaluation across a variety\nof downstream tasks and trigger designs, we demonstrate PETA's effectiveness in\nterms of both attack success rate and unaffected clean accuracy, even after the\nvictim user performs PEFT over the backdoored PLM using untainted data.\nMoreover, we empirically provide possible explanations for PETA's efficacy: the\nbilevel optimization inherently 'orthogonalizes' the backdoor and PEFT modules,\nthereby retaining the backdoor throughout PEFT. Based on this insight, we\nexplore a simple defense that omits PEFT in selected layers of the backdoored\nPLM and unfreezes a subset of these layers' parameters, which is shown to\neffectively neutralize PETA.\n","authors":["Lauren Hong","Ting Wang"],"pdf_url":"https://arxiv.org/pdf/2310.00648v3.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2309.17169v2","updated":"2023-11-23T02:06:20Z","published":"2023-09-29T12:06:55Z","title":"An evaluation of GPT models for phenotype concept recognition","summary":"  Objective: Clinical deep phenotyping and phenotype annotation play a critical\nrole in both the diagnosis of patients with rare disorders as well as in\nbuilding computationally-tractable knowledge in the rare disorders field. These\nprocesses rely on using ontology concepts, often from the Human Phenotype\nOntology, in conjunction with a phenotype concept recognition task (supported\nusually by machine learning methods) to curate patient profiles or existing\nscientific literature. With the significant shift in the use of large language\nmodels (LLMs) for most NLP tasks, we examine the performance of the latest\nGenerative Pre-trained Transformer (GPT) models underpinning ChatGPT as a\nfoundation for the tasks of clinical phenotyping and phenotype annotation.\nMaterials and Methods: The experimental setup of the study included seven\nprompts of various levels of specificity, two GPT models (gpt-3.5-turbo and\ngpt-4.0) and two established gold standard corpora for phenotype recognition,\none consisting of publication abstracts and the other clinical observations.\nResults: Our results show that, with an appropriate setup, these models can\nachieve state of the art performance. The best run, using few-shot learning,\nachieved 0.58 macro F1 score on publication abstracts and 0.75 macro F1 score\non clinical observations, the former being comparable with the state of the\nart, while the latter surpassing the current best in class tool. Conclusion:\nWhile the results are promising, the non-deterministic nature of the outcomes,\nthe high cost and the lack of concordance between different runs using the same\nprompt and input make the use of these LLMs challenging for this particular\ntask.\n","authors":["Tudor Groza","Harry Caufield","Dylan Gration","Gareth Baynam","Melissa A Haendel","Peter N Robinson","Christopher J Mungall","Justin T Reese"],"pdf_url":"https://arxiv.org/pdf/2309.17169v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13755v1","updated":"2023-11-23T01:06:08Z","published":"2023-11-23T01:06:08Z","title":"Transformer-based Named Entity Recognition in Construction Supply Chain\n  Risk Management in Australia","summary":"  The construction industry in Australia is characterized by its intricate\nsupply chains and vulnerability to myriad risks. As such, effective supply\nchain risk management (SCRM) becomes imperative. This paper employs different\ntransformer models, and train for Named Entity Recognition (NER) in the context\nof Australian construction SCRM. Utilizing NER, transformer models identify and\nclassify specific risk-associated entities in news articles, offering a\ndetailed insight into supply chain vulnerabilities. By analysing news articles\nthrough different transformer models, we can extract relevant entities and\ninsights related to specific risk taxonomies local (milieu) to the Australian\nconstruction landscape. This research emphasises the potential of NLP-driven\nsolutions, like transformer models, in revolutionising SCRM for construction in\ngeo-media specific contexts.\n","authors":["Milad Baghalzadeh Shishehgarkhaneh","Robert C. Moehler","Yihai Fang","Amer A. Hijazi","Hamed Aboutorab"],"pdf_url":"https://arxiv.org/pdf/2311.13755v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be acceptable"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2311.13559v2","updated":"2023-11-23T19:10:01Z","published":"2023-11-22T18:09:42Z","title":"Transfer Learning-based Real-time Handgun Detection","summary":"  Traditional surveillance systems rely on human attention, limiting their\neffectiveness. This study employs convolutional neural networks and transfer\nlearning to develop a real-time computer vision system for automatic handgun\ndetection. Comprehensive analysis of online handgun detection methods is\nconducted, emphasizing reducing false positives and learning time. Transfer\nlearning is demonstrated as an effective approach. Despite technical\nchallenges, the proposed system achieves a precision rate of 84.74%,\ndemonstrating promising performance comparable to related works, enabling\nfaster learning and accurate automatic handgun detection for enhanced security.\nThis research advances security measures by reducing human monitoring\ndependence, showcasing the potential of transfer learning-based approaches for\nefficient and reliable handgun detection.\n","authors":["Youssef Elmir","Sid Ahmed Laouar","Larbi Hamdaoui"],"pdf_url":"https://arxiv.org/pdf/2311.13559v2.pdf","comment":"16 pages, 9 figures, and 3 tables. Accepted at The Iraqi Journal of\n  Science, issued by College of Science at University of Baghdad"},{"id":"http://arxiv.org/abs/2311.13384v2","updated":"2023-11-23T11:40:16Z","published":"2023-11-22T13:27:34Z","title":"LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes","summary":"  With the widespread usage of VR devices and contents, demands for 3D scene\ngeneration techniques become more popular. Existing 3D scene generation models,\nhowever, limit the target scene to specific domain, primarily due to their\ntraining strategies using 3D scan dataset that is far from the real-world. To\naddress such limitation, we propose LucidDreamer, a domain-free scene\ngeneration pipeline by fully leveraging the power of existing large-scale\ndiffusion-based generative model. Our LucidDreamer has two alternate steps:\nDreaming and Alignment. First, to generate multi-view consistent images from\ninputs, we set the point cloud as a geometrical guideline for each image\ngeneration. Specifically, we project a portion of point cloud to the desired\nview and provide the projection as a guidance for inpainting using the\ngenerative model. The inpainted images are lifted to 3D space with estimated\ndepth maps, composing a new points. Second, to aggregate the new points into\nthe 3D scene, we propose an aligning algorithm which harmoniously integrates\nthe portions of newly generated 3D scenes. The finally obtained 3D scene serves\nas initial points for optimizing Gaussian splats. LucidDreamer produces\nGaussian splats that are highly-detailed compared to the previous 3D scene\ngeneration methods, with no constraint on domain of the target scene. Project\npage: https://luciddreamer-cvlab.github.io/\n","authors":["Jaeyoung Chung","Suyoung Lee","Hyeongjin Nam","Jaerin Lee","Kyoung Mu Lee"],"pdf_url":"https://arxiv.org/pdf/2311.13384v2.pdf","comment":"Project page: https://luciddreamer-cvlab.github.io/"},{"id":"http://arxiv.org/abs/2311.13231v2","updated":"2023-11-23T11:56:46Z","published":"2023-11-22T08:42:46Z","title":"Using Human Feedback to Fine-tune Diffusion Models without Any Reward\n  Model","summary":"  Using reinforcement learning with human feedback (RLHF) has shown significant\npromise in fine-tuning diffusion models. Previous methods start by training a\nreward model that aligns with human preferences, then leverage RL techniques to\nfine-tune the underlying models. However, crafting an efficient reward model\ndemands extensive datasets, optimal architecture, and manual hyperparameter\ntuning, making the process both time and cost-intensive. The direct preference\noptimization (DPO) method, effective in fine-tuning large language models,\neliminates the necessity for a reward model. However, the extensive GPU memory\nrequirement of the diffusion model's denoising process hinders the direct\napplication of the DPO method. To address this issue, we introduce the Direct\nPreference for Denoising Diffusion Policy Optimization (D3PO) method to\ndirectly fine-tune diffusion models. The theoretical analysis demonstrates that\nalthough D3PO omits training a reward model, it effectively functions as the\noptimal reward model trained using human feedback data to guide the learning\nprocess. This approach requires no training of a reward model, proving to be\nmore direct, cost-effective, and minimizing computational overhead. In\nexperiments, our method uses the relative scale of objectives as a proxy for\nhuman preference, delivering comparable results to methods using ground-truth\nrewards. Moreover, D3PO demonstrates the ability to reduce image distortion\nrates and generate safer images, overcoming challenges lacking robust reward\nmodels. Our code is publicly available in\nhttps://github.com/yk7333/D3PO/tree/main.\n","authors":["Kai Yang","Jian Tao","Jiafei Lyu","Chunjiang Ge","Jiaxin Chen","Qimai Li","Weihan Shen","Xiaolong Zhu","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2311.13231v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13199v2","updated":"2023-11-23T18:59:55Z","published":"2023-11-22T07:06:38Z","title":"DRIFu: Differentiable Rendering and Implicit Function-based Single-View\n  3D Reconstruction","summary":"  The Differentiable Rendering and Implicit Function-based model (DRIFu) draws\nits roots from the Pixel-aligned Implicit Function (PIFU), a pioneering 3D\ndigitization technique initially designed for clothed human bodies. PIFU excels\nin capturing nuanced body shape variations within a low-dimensional space and\nhas been extensively trained on human 3D scans. However, the application of\nPIFU to live animals poses significant challenges, primarily due to the\ninherent difficulty in obtaining the cooperation of animals for 3D scanning. In\nresponse to this challenge, we introduce the DRIFu model, specifically tailored\nfor animal digitization. To train DRIFu, we employ a curated set of synthetic\n3D animal models, encompassing diverse shapes, sizes, and even accounting for\nvariations such as baby birds. Our innovative alignment tools play a pivotal\nrole in mapping these diverse synthetic animal models onto a unified template,\nfacilitating precise predictions of animal shape and texture. Crucially, our\ntemplate alignment strategy establishes a shared shape space, allowing for the\nseamless sampling of new animal shapes, posing them realistically, animating\nthem, and aligning them with real-world data. This groundbreaking approach\nrevolutionizes our capacity to comprehensively understand and represent avian\nforms. For further details and access to the project, the project website can\nbe found at https://github.com/kuangzijian/drifu-for-animals\n","authors":["Zijian Kuang","Lihang Ying","Shi Jin","Li Cheng"],"pdf_url":"https://arxiv.org/pdf/2311.13199v2.pdf","comment":"arXiv admin note: text overlap with arXiv:1905.05172 by other authors"},{"id":"http://arxiv.org/abs/2311.13120v2","updated":"2023-11-23T08:15:18Z","published":"2023-11-22T02:46:57Z","title":"Multi-modal In-Context Learning Makes an Ego-evolving Scene Text\n  Recognizer","summary":"  Scene text recognition (STR) in the wild frequently encounters challenges\nwhen coping with domain variations, font diversity, shape deformations, etc. A\nstraightforward solution is performing model fine-tuning tailored to a specific\nscenario, but it is computationally intensive and requires multiple model\ncopies for various scenarios. Recent studies indicate that large language\nmodels (LLMs) can learn from a few demonstration examples in a training-free\nmanner, termed \"In-Context Learning\" (ICL). Nevertheless, applying LLMs as a\ntext recognizer is unacceptably resource-consuming. Moreover, our pilot\nexperiments on LLMs show that ICL fails in STR, mainly attributed to the\ninsufficient incorporation of contextual information from diverse samples in\nthe training stage. To this end, we introduce E$^2$STR, a STR model trained\nwith context-rich scene text sequences, where the sequences are generated via\nour proposed in-context training strategy. E$^2$STR demonstrates that a\nregular-sized model is sufficient to achieve effective ICL capabilities in STR.\nExtensive experiments show that E$^2$STR exhibits remarkable training-free\nadaptation in various scenarios and outperforms even the fine-tuned\nstate-of-the-art approaches on public benchmarks.\n","authors":["Zhen Zhao","Jingqun Tang","Chunhui Lin","Binghong Wu","Hao Liu","Zhizhong Zhang","Xin Tan","Can Huang","Yuan Xie"],"pdf_url":"https://arxiv.org/pdf/2311.13120v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12144v3","updated":"2023-11-23T07:21:29Z","published":"2023-11-20T19:45:27Z","title":"Applications of Large Scale Foundation Models for Autonomous Driving","summary":"  Since DARPA Grand Challenges (rural) in 2004/05 and Urban Challenges in 2007,\nautonomous driving has been the most active field of AI applications. Recently\npowered by large language models (LLMs), chat systems, such as chatGPT and\nPaLM, emerge and rapidly become a promising direction to achieve artificial\ngeneral intelligence (AGI) in natural language processing (NLP). There comes a\nnatural thinking that we could employ these abilities to reformulate autonomous\ndriving. By combining LLM with foundation models, it is possible to utilize the\nhuman knowledge, commonsense and reasoning to rebuild autonomous driving\nsystems from the current long-tailed AI dilemma. In this paper, we investigate\nthe techniques of foundation models and LLMs applied for autonomous driving,\ncategorized as simulation, world model, data annotation and planning or E2E\nsolutions etc.\n","authors":["Yu Huang","Yue Chen","Zhu Li"],"pdf_url":"https://arxiv.org/pdf/2311.12144v3.pdf","comment":"23 pages. arXiv admin note: text overlap with arXiv:2304.03589,\n  arXiv:2111.05849, arXiv:2306.03000, arXiv:2309.17080, arXiv:2301.02691,\n  arXiv:2309.16292, arXiv:2309.10228, arXiv:2310.01415, arXiv:2309.09777 by\n  other authors"},{"id":"http://arxiv.org/abs/2309.00168v3","updated":"2023-11-23T01:42:12Z","published":"2023-08-31T23:17:44Z","title":"Pose-Graph Attentional Graph Neural Network for Lidar Place Recognition","summary":"  This paper proposes a pose-graph attentional graph neural network, called\nP-GAT, which compares (key)nodes between sequential and non-sequential\nsub-graphs for place recognition tasks as opposed to a common frame-to-frame\nretrieval problem formulation currently implemented in SOTA place recognition\nmethods. P-GAT uses the maximum spatial and temporal information between\nneighbour cloud descriptors -- generated by an existing encoder -- utilising\nthe concept of pose-graph SLAM. Leveraging intra- and inter-attention and graph\nneural network, P-GAT relates point clouds captured in nearby locations in\nEuclidean space and their embeddings in feature space. Experimental results on\nthe large-scale publically available datasets demonstrate the effectiveness of\nour approach in scenes lacking distinct features and when training and testing\nenvironments have different distributions (domain adaptation). Further, an\nexhaustive comparison with the state-of-the-art shows improvements in\nperformance gains. Code is available at\nhttps://github.com/csiro-robotics/P-GAT.\n","authors":["Milad Ramezani","Liang Wang","Joshua Knights","Zhibin Li","Pauline Pounds","Peyman Moghadam"],"pdf_url":"https://arxiv.org/pdf/2309.00168v3.pdf","comment":"10 pages, 5 figures, 5 tables, Accepted for Publication in the IEEE\n  Robotics and Automation Letters (RA-L)"},{"id":"http://arxiv.org/abs/2311.12651v2","updated":"2023-11-23T16:38:00Z","published":"2023-11-21T14:53:02Z","title":"Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for\n  Mobile Robots","summary":"  Precise and rapid delineation of sharp boundaries and robust semantics is\nessential for numerous downstream robotic tasks, such as robot grasping and\nmanipulation, real-time semantic mapping, and online sensor calibration\nperformed on edge computing units. Although boundary detection and semantic\nsegmentation are complementary tasks, most studies focus on lightweight models\nfor semantic segmentation but overlook the critical role of boundary detection.\nIn this work, we introduce Mobile-Seed, a lightweight, dual-task framework\ntailored for simultaneous semantic segmentation and boundary detection. Our\nframework features a two-stream encoder, an active fusion decoder (AFD) and a\ndual-task regularization approach. The encoder is divided into two pathways:\none captures category-aware semantic information, while the other discerns\nboundaries from multi-scale features. The AFD module dynamically adapts the\nfusion of semantic and boundary information by learning channel-wise\nrelationships, allowing for precise weight assignment of each channel.\nFurthermore, we introduce a regularization loss to mitigate the conflicts in\ndual-task learning and deep diversity supervision. Compared to existing\nmethods, the proposed Mobile-Seed offers a lightweight framework to\nsimultaneously improve semantic segmentation performance and accurately locate\nobject boundaries. Experiments on the Cityscapes dataset have shown that\nMobile-Seed achieves notable improvement over the state-of-the-art (SOTA)\nbaseline by 2.2 percentage points (pp) in mIoU and 4.2 pp in mF-score, while\nmaintaining an online inference speed of 23.9 frames-per-second (FPS) with\n1024x2048 resolution input on an RTX 2080 Ti GPU. Additional experiments on\nCamVid and PASCAL Context datasets confirm our method's generalizability. Code\nand additional results are publicly available at\nhttps://whu-usi3dv.github.io/Mobile-Seed/.\n","authors":["Youqi Liao","Shuhao Kang","Jianping Li","Yang Liu","Yun Liu","Zhen Dong","Bisheng Yang","Xieyuanli Chen"],"pdf_url":"https://arxiv.org/pdf/2311.12651v2.pdf","comment":"8 pages, IEEE conference/letter underreview. Code and additional\n  results are available at: https://github.com/WHU-USI3DV/Mobile-Seed"},{"id":"http://arxiv.org/abs/2311.12553v2","updated":"2023-11-23T09:10:46Z","published":"2023-11-21T12:05:56Z","title":"\"HoVer-UNet\": Accelerating HoVerNet with UNet-based multi-class nuclei\n  segmentation via knowledge distillation","summary":"  We present \"HoVer-UNet\", an approach to distill the knowledge of the\nmulti-branch HoVerNet framework for nuclei instance segmentation and\nclassification in histopathology. We propose a compact, streamlined single UNet\nnetwork with a Mix Vision Transformer backbone, and equip it with a custom loss\nfunction to optimally encode the distilled knowledge of HoVerNet, reducing\ncomputational requirements without compromising performances. We show that our\nmodel achieved results comparable to HoVerNet on the public PanNuke and Consep\ndatasets with a three-fold reduction in inference time. We make the code of our\nmodel publicly available at https://github.com/DIAGNijmegen/HoVer-UNet.\n","authors":["Cristian Tommasino","Cristiano Russo","Antonio Maria Rinaldi","Francesco Ciompi"],"pdf_url":"https://arxiv.org/pdf/2311.12553v2.pdf","comment":"4 pages, 2 figures, submitted to ISBI 2024"},{"id":"http://arxiv.org/abs/2311.14227v1","updated":"2023-11-23T23:40:01Z","published":"2023-11-23T23:40:01Z","title":"Robust and Interpretable COVID-19 Diagnosis on Chest X-ray Images using\n  Adversarial Training","summary":"  The novel 2019 Coronavirus disease (COVID-19) global pandemic is a defining\nhealth crisis. Recent efforts have been increasingly directed towards achieving\nquick and accurate detection of COVID-19 across symptomatic patients to\nmitigate the intensity and spread of the disease. Artificial intelligence (AI)\nalgorithms applied to chest X-ray (CXR) images have emerged as promising\ndiagnostic tools, and previous work has demonstrated impressive classification\nperformances. However, such methods have faced criticisms from physicians due\nto their black-box reasoning process and unpredictable nature. In contrast to\nprofessional radiologist diagnosis, AI systems often lack generalizability,\nexplainability, and robustness in the clinical decision making process. In our\nwork, we address these issues by first proposing an extensive baseline study,\ntraining and evaluating 21 convolutional neural network (CNN) models on a\ndiverse set of 33,000+ CXR images to classify between healthy, COVID-19, and\nnon-COVID-19 pneumonia CXRs. Our resulting models achieved a 3-way\nclassification accuracy, recall, and precision of up to 97.03\\%, 97.97\\%, and\n99.95\\%, respectively. Next, we investigate the effectiveness of adversarial\ntraining on model robustness and explainability via Gradient-weighted Class\nActivation Mapping (Grad-CAM) heatmaps. We find that adversarially trained\nmodels not only significantly outperform their standard counterparts on\nclassifying perturbed images, but also yield saliency maps that 1) better\nspecify clinically relevant features, 2) are robust against extraneous\nartifacts, and 3) agree considerably more with expert radiologist findings.\n","authors":["Karina Yang","Alexis Bennett","Dominique Duncan"],"pdf_url":"https://arxiv.org/pdf/2311.14227v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14218v1","updated":"2023-11-23T22:27:31Z","published":"2023-11-23T22:27:31Z","title":"A New Benchmark and Model for Challenging Image Manipulation Detection","summary":"  The ability to detect manipulation in multimedia data is vital in digital\nforensics. Existing Image Manipulation Detection (IMD) methods are mainly based\non detecting anomalous features arisen from image editing or double compression\nartifacts. All existing IMD techniques encounter challenges when it comes to\ndetecting small tampered regions from a large image. Moreover,\ncompression-based IMD approaches face difficulties in cases of double\ncompression of identical quality factors. To investigate the State-of-The-Art\n(SoTA) IMD methods in those challenging conditions, we introduce a new\nChallenging Image Manipulation Detection (CIMD) benchmark dataset, which\nconsists of two subsets, for evaluating editing-based and compression-based IMD\nmethods, respectively. The dataset images were manually taken and tampered with\nhigh-quality annotations. In addition, we propose a new two-branch network\nmodel based on HRNet that can better detect both the image-editing and\ncompression artifacts in those challenging conditions. Extensive experiments on\nthe CIMD benchmark show that our model significantly outperforms SoTA IMD\nmethods on CIMD.\n","authors":["Zhenfei Zhang","Mingyang Li","Ming-Ching Chang"],"pdf_url":"https://arxiv.org/pdf/2311.14218v1.pdf","comment":"8 pages, 6 figures, 3 tabels"},{"id":"http://arxiv.org/abs/2209.05954v4","updated":"2023-11-23T22:11:49Z","published":"2022-09-09T23:18:31Z","title":"Automatically Score Tissue Images Like a Pathologist by Transfer\n  Learning","summary":"  Cancer is the second leading cause of death in the world. Diagnosing cancer\nearly on can save many lives. Pathologists have to look at tissue microarray\n(TMA) images manually to identify tumors, which can be time-consuming,\ninconsistent and subjective. Existing automatic algorithms either have not\nachieved the accuracy level of a pathologist or require substantial human\ninvolvements. A major challenge is that TMA images with different shapes,\nsizes, and locations can have the same score. Learning staining patterns in TMA\nimages requires a huge number of images, which are severely limited due to\nprivacy and regulation concerns in medical organizations. TMA images from\ndifferent cancer types may share certain common characteristics, but combining\nthem directly harms the accuracy due to heterogeneity in their staining\npatterns. Transfer learning is an emerging learning paradigm that allows\nborrowing strength from similar problems. However, existing approaches\ntypically require a large sample from similar learning problems, while TMA\nimages of different cancer types are often available in small sample size and\nfurther existing algorithms are limited to transfer learning from one similar\nproblem. We propose a new transfer learning algorithm that could learn from\nmultiple related problems, where each problem has a small sample and can have a\nsubstantially different distribution from the original one. The proposed\nalgorithm has made it possible to break the critical accuracy barrier (the 75%\naccuracy level of pathologists), with a reported accuracy of 75.9% on breast\ncancer TMA images from the Stanford Tissue Microarray Database. It is supported\nby recent developments in transfer learning theory and empirical evidence in\nclustering technology. This will allow pathologists to confidently adopt\nautomatic algorithms in recognizing tumors consistently with a higher accuracy\nin real time.\n","authors":["Iris Yan"],"pdf_url":"https://arxiv.org/pdf/2209.05954v4.pdf","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.14208v1","updated":"2023-11-23T21:23:52Z","published":"2023-11-23T21:23:52Z","title":"ECRF: Entropy-Constrained Neural Radiance Fields Compression with\n  Frequency Domain Optimization","summary":"  Explicit feature-grid based NeRF models have shown promising results in terms\nof rendering quality and significant speed-up in training. However, these\nmethods often require a significant amount of data to represent a single scene\nor object. In this work, we present a compression model that aims to minimize\nthe entropy in the frequency domain in order to effectively reduce the data\nsize. First, we propose using the discrete cosine transform (DCT) on the\ntensorial radiance fields to compress the feature-grid. This feature-grid is\ntransformed into coefficients, which are then quantized and entropy encoded,\nfollowing a similar approach to the traditional video coding pipeline.\nFurthermore, to achieve a higher level of sparsity, we propose using an entropy\nparameterization technique for the frequency domain, specifically for DCT\ncoefficients of the feature-grid. Since the transformed coefficients are\noptimized during the training phase, the proposed model does not require any\nfine-tuning or additional information. Our model only requires a lightweight\ncompression pipeline for encoding and decoding, making it easier to apply\nvolumetric radiance field methods for real-world applications. Experimental\nresults demonstrate that our proposed frequency domain entropy model can\nachieve superior compression performance across various datasets. The source\ncode will be made publicly available.\n","authors":["Soonbin Lee","Fangwen Shu","Yago Sanchez","Thomas Schierl","Cornelius Hellge"],"pdf_url":"https://arxiv.org/pdf/2311.14208v1.pdf","comment":"10 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.14199v1","updated":"2023-11-23T20:52:44Z","published":"2023-11-23T20:52:44Z","title":"A Systematic Review of Deep Learning-based Research on Radiology Report\n  Generation","summary":"  Radiology report generation (RRG) aims to automatically generate free-text\ndescriptions from clinical radiographs, e.g., chest X-Ray images. RRG plays an\nessential role in promoting clinical automation and presents significant help\nto provide practical assistance for inexperienced doctors and alleviate\nradiologists' workloads. Therefore, consider these meaningful potentials,\nresearch on RRG is experiencing explosive growth in the past half-decade,\nespecially with the rapid development of deep learning approaches. Existing\nstudies perform RRG from the perspective of enhancing different modalities,\nprovide insights on optimizing the report generation process with elaborated\nfeatures from both visual and textual information, and further facilitate RRG\nwith the cross-modal interactions among them. In this paper, we present a\ncomprehensive review of deep learning-based RRG from various perspectives.\nSpecifically, we firstly cover pivotal RRG approaches based on the\ntask-specific features of radiographs, reports, and the cross-modal relations\nbetween them, and then illustrate the benchmark datasets conventionally used\nfor this task with evaluation metrics, subsequently analyze the performance of\ndifferent approaches and finally offer our summary on the challenges and the\ntrends in future directions. Overall, the goal of this paper is to serve as a\ntool for understanding existing literature and inspiring potential valuable\nresearch in the field of RRG.\n","authors":["Chang Liu","Yuanhe Tian","Yan Song"],"pdf_url":"https://arxiv.org/pdf/2311.14199v1.pdf","comment":"26 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.05784v2","updated":"2023-11-23T20:45:53Z","published":"2023-11-09T23:25:29Z","title":"Are \"Hierarchical\" Visual Representations Hierarchical?","summary":"  Learned visual representations often capture large amounts of semantic\ninformation for accurate downstream applications. Human understanding of the\nworld is fundamentally grounded in hierarchy. To mimic this and further improve\nrepresentation capabilities, the community has explored \"hierarchical\" visual\nrepresentations that aim at modeling the underlying hierarchy of the visual\nworld. In this work, we set out to investigate if hierarchical visual\nrepresentations truly capture the human perceived hierarchy better than\nstandard learned representations. To this end, we create HierNet, a suite of 12\ndatasets spanning 3 kinds of hierarchy from the BREEDs subset of ImageNet.\nAfter extensive evaluation of Hyperbolic and Matryoshka Representations across\ntraining setups, we conclude that they do not capture hierarchy any better than\nthe standard representations but can assist in other aspects like search\nefficiency and interpretability. Our benchmark and the datasets are\nopen-sourced at https://github.com/ethanlshen/HierNet.\n","authors":["Ethan Shen","Ali Farhadi","Aditya Kusupati"],"pdf_url":"https://arxiv.org/pdf/2311.05784v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14197v1","updated":"2023-11-23T20:41:46Z","published":"2023-11-23T20:41:46Z","title":"Enhancing mTBI Diagnosis with Residual Triplet Convolutional Neural\n  Network Using 3D CT","summary":"  Mild Traumatic Brain Injury (mTBI) is a common and challenging condition to\ndiagnose accurately. Timely and precise diagnosis is essential for effective\ntreatment and improved patient outcomes. Traditional diagnostic methods for\nmTBI often have limitations in terms of accuracy and sensitivity. In this\nstudy, we introduce an innovative approach to enhance mTBI diagnosis using 3D\nComputed Tomography (CT) images and a metric learning technique trained with\ntriplet loss. To address these challenges, we propose a Residual Triplet\nConvolutional Neural Network (RTCNN) model to distinguish between mTBI cases\nand healthy ones by embedding 3D CT scans into a feature space. The triplet\nloss function maximizes the margin between similar and dissimilar image pairs,\noptimizing feature representations. This facilitates better context placement\nof individual cases, aids informed decision-making, and has the potential to\nimprove patient outcomes. Our RTCNN model shows promising performance in mTBI\ndiagnosis, achieving an average accuracy of 94.3%, a sensitivity of 94.1%, and\na specificity of 95.2%, as confirmed through a five-fold cross-validation.\nImportantly, when compared to the conventional Residual Convolutional Neural\nNetwork (RCNN) model, the RTCNN exhibits a significant improvement, showcasing\na remarkable 22.5% increase in specificity, a notable 16.2% boost in accuracy,\nand an 11.3% enhancement in sensitivity. Moreover, RTCNN requires lower memory\nresources, making it not only highly effective but also resource-efficient in\nminimizing false positives while maximizing its diagnostic accuracy in\ndistinguishing normal CT scans from mTBI cases. The quantitative performance\nmetrics provided and utilization of occlusion sensitivity maps to visually\nexplain the model's decision-making process further enhance the\ninterpretability and transparency of our approach.\n","authors":["Hanem Ellethy","Shekhar S. Chandra","Viktor Vegh"],"pdf_url":"https://arxiv.org/pdf/2311.14197v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14189v1","updated":"2023-11-23T20:14:50Z","published":"2023-11-23T20:14:50Z","title":"HACD: Hand-Aware Conditional Diffusion for Monocular Hand-Held Object\n  Reconstruction","summary":"  Reconstructing hand-held objects from a single RGB image without known 3D\nobject templates, category prior, or depth information is a vital yet\nchallenging problem in computer vision. In contrast to prior works that utilize\ndeterministic modeling paradigms, which make it hard to account for the\nuncertainties introduced by hand- and self-occlusion, we employ a probabilistic\npoint cloud denoising diffusion model to tackle the above challenge. In this\nwork, we present Hand-Aware Conditional Diffusion for monocular hand-held\nobject reconstruction (HACD), modeling the hand-object interaction in two\naspects. First, we introduce hand-aware conditioning to model hand-object\ninteraction from both semantic and geometric perspectives. Specifically, a\nunified hand-object semantic embedding compensates for the 2D local feature\ndeficiency induced by hand occlusion, and a hand articulation embedding further\nencodes the relationship between object vertices and hand joints. Second, we\npropose a hand-constrained centroid fixing scheme, which utilizes hand vertices\npriors to restrict the centroid deviation of partially denoised point cloud\nduring diffusion and reverse process. Removing the centroid bias interference\nallows the diffusion models to focus on the reconstruction of shape, thus\nenhancing the stability and precision of local feature projection. Experiments\non the synthetic ObMan dataset and two real-world datasets, HO3D and MOW,\ndemonstrate our approach surpasses all existing methods by a large margin.\n","authors":["Bowen Fu","Yan Di","Chenyangguang Zhang","Gu Wang","Ziqin Huang","Zhiying Leng","Fabian Manhardt","Xiangyang Ji","Federico Tombari"],"pdf_url":"https://arxiv.org/pdf/2311.14189v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10754v2","updated":"2023-11-23T20:08:49Z","published":"2023-11-06T18:18:42Z","title":"A Recent Survey of the Advancements in Deep Learning Techniques for\n  Monkeypox Disease Detection","summary":"  Monkeypox (MPox) is a zoonotic infectious disease induced by the MPox Virus,\npart of the poxviridae orthopoxvirus group initially discovered in Africa and\ngained global attention in mid-2022 with cases reported outside endemic areas.\nSymptoms include headaches, chills, fever, smallpox, measles, and\nchickenpox-like skin manifestations and the WHO officially announced MPox as a\nglobal public health pandemic, in July 2022.Traditionally, PCR testing of skin\nlesions is considered a benchmark for the primary diagnosis by WHO, with\nsymptom management as the primary treatment and antiviral drugs like\ntecovirimat for severe cases. However, manual analysis within hospitals poses a\nsubstantial challenge including the substantial burden on healthcare\nprofessionals, limited facilities, availability and fatigue among doctors, and\nhuman error during public health emergencies. Therefore, this survey paper\nprovides an extensive and efficient analysis of deep learning (DL) methods for\nthe automatic detection of MPox in skin lesion images. These DL techniques are\nbroadly grouped into categories, including deep CNN, Deep CNNs ensemble, deep\nhybrid learning, the newly developed, and Vision transformer for diagnosing\nMPox. Moreover, this study offers a systematic exploration of the evolutionary\nprogression of DL techniques and identifies, and addresses limitations in\nprevious methods while highlighting the valuable contributions and innovation.\nAdditionally, the paper addresses benchmark datasets and their collection from\nvarious authentic sources, pre-processing techniques, and evaluation metrics.\nThe survey also briefly delves into emerging concepts, identifies research\ngaps, limitations, and applications, and outlines challenges in the diagnosis\nprocess. This survey furnishes valuable insights into the prospective areas of\nDL innovative ideas and is anticipated to serve as a path for researchers.\n","authors":["Saddam Hussain Khan","Rashid Iqbal","Saeeda Naz"],"pdf_url":"https://arxiv.org/pdf/2311.10754v2.pdf","comment":"53 pages, 16 figures, 7 tables"},{"id":"http://arxiv.org/abs/2311.14177v1","updated":"2023-11-23T19:49:59Z","published":"2023-11-23T19:49:59Z","title":"TCuPGAN: A novel framework developed for optimizing human-machine\n  interactions in citizen science","summary":"  In the era of big data in scientific research, there is a necessity to\nleverage techniques which reduce human effort in labeling and categorizing\nlarge datasets by involving sophisticated machine tools. To combat this\nproblem, we present a novel, general purpose model for 3D segmentation that\nleverages patch-wise adversariality and Long Short-Term Memory to encode\nsequential information. Using this model alongside citizen science projects\nwhich use 3D datasets (image cubes) on the Zooniverse platforms, we propose an\niterative human-machine optimization framework where only a fraction of the 2D\nslices from these cubes are seen by the volunteers. We leverage the patch-wise\ndiscriminator in our model to provide an estimate of which slices within these\nimage cubes have poorly generalized feature representations, and\ncorrespondingly poor machine performance. These images with corresponding\nmachine proposals would be presented to volunteers on Zooniverse for\ncorrection, leading to a drastic reduction in the volunteer effort on citizen\nscience projects. We trained our model on ~2300 liver tissue 3D electron\nmicrographs. Lipid droplets were segmented within these images through human\nannotation via the `Etch A Cell - Fat Checker' citizen science project, hosted\non the Zooniverse platform. In this work, we demonstrate this framework and the\nselection methodology which resulted in a measured reduction in volunteer\neffort by more than 60%. We envision this type of joint human-machine\npartnership will be of great use on future Zooniverse projects.\n","authors":["Ramanakumar Sankar","Kameswara Mantha","Lucy Fortson","Helen Spiers","Thomas Pengo","Douglas Mashek","Myat Mo","Mark Sanders","Trace Christensen","Jeffrey Salisbury","Laura Trouille"],"pdf_url":"https://arxiv.org/pdf/2311.14177v1.pdf","comment":"5 pages, 1 figure, accepted for publication at HLDM '23 (ECML PKDD\n  2023 workshop)"},{"id":"http://arxiv.org/abs/2311.14175v1","updated":"2023-11-23T19:44:50Z","published":"2023-11-23T19:44:50Z","title":"Appearance-based gaze estimation enhanced with synthetic images using\n  deep neural networks","summary":"  Human eye gaze estimation is an important cognitive ingredient for successful\nhuman-robot interaction, enabling the robot to read and predict human behavior.\nWe approach this problem using artificial neural networks and build a modular\nsystem estimating gaze from separately cropped eyes, taking advantage of\nexisting well-functioning components for face detection (RetinaFace) and head\npose estimation (6DRepNet). Our proposed method does not require any special\nhardware or infrared filters but uses a standard notebook-builtin RGB camera,\nas often approached with appearance-based methods. Using the MetaHuman tool, we\nalso generated a large synthetic dataset of more than 57,000 human faces and\nmade it publicly available. The inclusion of this dataset (with eye gaze and\nhead pose information) on top of the standard Columbia Gaze dataset into\ntraining the model led to better accuracy with a mean average error below two\ndegrees in eye pitch and yaw directions, which compares favourably to related\nmethods. We also verified the feasibility of our model by its preliminary\ntesting in real-world setting using the builtin 4K camera in NICO semi-humanoid\nrobot's eye.\n","authors":["Dmytro Herashchenko","Igor Farkaš"],"pdf_url":"https://arxiv.org/pdf/2311.14175v1.pdf","comment":"6 pages, 10 figures, accepted to 2023 IEEE Symposium Series on\n  Computational Intelligence"},{"id":"http://arxiv.org/abs/2311.14155v1","updated":"2023-11-23T18:55:03Z","published":"2023-11-23T18:55:03Z","title":"GigaPose: Fast and Robust Novel Object Pose Estimation via One\n  Correspondence","summary":"  We present GigaPose, a fast, robust, and accurate method for CAD-based novel\nobject pose estimation in RGB images. GigaPose first leverages discriminative\ntemplates, rendered images of the CAD models, to recover the out-of-plane\nrotation and then uses patch correspondences to estimate the four remaining\nparameters. Our approach samples templates in only a two-degrees-of-freedom\nspace instead of the usual three and matches the input image to the templates\nusing fast nearest neighbor search in feature space, results in a speedup\nfactor of 38x compared to the state of the art. Moreover, GigaPose is\nsignificantly more robust to segmentation errors. Our extensive evaluation on\nthe seven core datasets of the BOP challenge demonstrates that it achieves\nstate-of-the-art accuracy and can be seamlessly integrated with a refinement\nmethod. Additionally, we show the potential of GigaPose with 3D models\npredicted by recent work on 3D reconstruction from a single image, relaxing the\nneed for CAD models and making 6D pose object estimation much more convenient.\nOur source code and trained models are publicly available at\nhttps://github.com/nv-nguyen/gigaPose\n","authors":["Van Nguyen Nguyen","Thibault Groueix","Mathieu Salzmann","Vincent Lepetit"],"pdf_url":"https://arxiv.org/pdf/2311.14155v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14148v1","updated":"2023-11-23T18:37:26Z","published":"2023-11-23T18:37:26Z","title":"Automated 3D Tumor Segmentation using Temporal Cubic PatchGAN (TCuP-GAN)","summary":"  Development of robust general purpose 3D segmentation frameworks using the\nlatest deep learning techniques is one of the active topics in various\nbio-medical domains. In this work, we introduce Temporal Cubic PatchGAN\n(TCuP-GAN), a volume-to-volume translational model that marries the concepts of\na generative feature learning framework with Convolutional Long Short-Term\nMemory Networks (LSTMs), for the task of 3D segmentation. We demonstrate the\ncapabilities of our TCuP-GAN on the data from four segmentation challenges\n(Adult Glioma, Meningioma, Pediatric Tumors, and Sub-Saharan Africa subset)\nfeatured within the 2023 Brain Tumor Segmentation (BraTS) Challenge and\nquantify its performance using LesionWise Dice similarity and $95\\%$ Hausdorff\nDistance metrics. We demonstrate the successful learning of our framework to\npredict robust multi-class segmentation masks across all the challenges. This\nbenchmarking work serves as a stepping stone for future efforts towards\napplying TCuP-GAN on other multi-class tasks such as multi-organelle\nsegmentation in electron microscopy imaging.\n","authors":["Kameswara Bharadwaj Mantha","Ramanakumar Sankar","Lucy Fortson"],"pdf_url":"https://arxiv.org/pdf/2311.14148v1.pdf","comment":"Submitted as a short paper to the proceedings of the 2023 Brain Tumor\n  Segmentation (BraTS) Challenge"},{"id":"http://arxiv.org/abs/2311.14146v1","updated":"2023-11-23T18:35:26Z","published":"2023-11-23T18:35:26Z","title":"Class Balanced Dynamic Acquisition for Domain Adaptive Semantic\n  Segmentation using Active Learning","summary":"  Domain adaptive active learning is leading the charge in label-efficient\ntraining of neural networks. For semantic segmentation, state-of-the-art models\njointly use two criteria of uncertainty and diversity to select training\nlabels, combined with a pixel-wise acquisition strategy. However, we show that\nsuch methods currently suffer from a class imbalance issue which degrades their\nperformance for larger active learning budgets. We then introduce Class\nBalanced Dynamic Acquisition (CBDA), a novel active learning method that\nmitigates this issue, especially in high-budget regimes. The more balanced\nlabels increase minority class performance, which in turn allows the model to\noutperform the previous baseline by 0.6, 1.7, and 2.4 mIoU for budgets of 5%,\n10%, and 20%, respectively. Additionally, the focus on minority classes leads\nto improvements of the minimum class performance of 0.5, 2.9, and 4.6 IoU\nrespectively. The top-performing model even exceeds the fully supervised\nbaseline, showing that a more balanced label than the entire ground truth can\nbe beneficial.\n","authors":["Marc Schachtsiek","Simone Rossi","Thomas Hannagan"],"pdf_url":"https://arxiv.org/pdf/2311.14146v1.pdf","comment":"NeurIPS 2023 Workshop on Adaptive Experimental Design and Active\n  Learning in the Real World"},{"id":"http://arxiv.org/abs/2311.12024v2","updated":"2023-11-23T17:59:42Z","published":"2023-11-20T18:57:55Z","title":"PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape\n  Prediction","summary":"  We propose a Pose-Free Large Reconstruction Model (PF-LRM) for reconstructing\na 3D object from a few unposed images even with little visual overlap, while\nsimultaneously estimating the relative camera poses in ~1.3 seconds on a single\nA100 GPU. PF-LRM is a highly scalable method utilizing the self-attention\nblocks to exchange information between 3D object tokens and 2D image tokens; we\npredict a coarse point cloud for each view, and then use a differentiable\nPerspective-n-Point (PnP) solver to obtain camera poses. When trained on a huge\namount of multi-view posed data of ~1M objects, PF-LRM shows strong\ncross-dataset generalization ability, and outperforms baseline methods by a\nlarge margin in terms of pose prediction accuracy and 3D reconstruction quality\non various unseen evaluation datasets. We also demonstrate our model's\napplicability in downstream text/image-to-3D task with fast feed-forward\ninference. Our project website is at: https://totoro97.github.io/pf-lrm .\n","authors":["Peng Wang","Hao Tan","Sai Bi","Yinghao Xu","Fujun Luan","Kalyan Sunkavalli","Wenping Wang","Zexiang Xu","Kai Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12024v2.pdf","comment":"Project website: https://totoro97.github.io/pf-lrm ; add more\n  experiments"},{"id":"http://arxiv.org/abs/2305.01569v2","updated":"2023-11-23T17:07:58Z","published":"2023-05-02T16:18:11Z","title":"Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image\n  Generation","summary":"  The ability to collect a large dataset of human preferences from\ntext-to-image users is usually limited to companies, making such datasets\ninaccessible to the public. To address this issue, we create a web app that\nenables text-to-image users to generate images and specify their preferences.\nUsing this web app we build Pick-a-Pic, a large, open dataset of text-to-image\nprompts and real users' preferences over generated images. We leverage this\ndataset to train a CLIP-based scoring function, PickScore, which exhibits\nsuperhuman performance on the task of predicting human preferences. Then, we\ntest PickScore's ability to perform model evaluation and observe that it\ncorrelates better with human rankings than other automatic evaluation metrics.\nTherefore, we recommend using PickScore for evaluating future text-to-image\ngeneration models, and using Pick-a-Pic prompts as a more relevant dataset than\nMS-COCO. Finally, we demonstrate how PickScore can enhance existing\ntext-to-image models via ranking.\n","authors":["Yuval Kirstain","Adam Polyak","Uriel Singer","Shahbuland Matiana","Joe Penna","Omer Levy"],"pdf_url":"https://arxiv.org/pdf/2305.01569v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.02205v3","updated":"2023-11-23T17:04:26Z","published":"2022-03-04T09:31:20Z","title":"Evaluating Object (mis)Detection from a Safety and Reliability\n  Perspective: Discussion and Measures","summary":"  We argue that object detectors in the safety critical domain should\nprioritize detection of objects that are most likely to interfere with the\nactions of the autonomous actor. Especially, this applies to objects that can\nimpact the actor's safety and reliability. To quantify the impact of object\n(mis)detection on safety and reliability in the context of autonomous driving,\nwe propose new object detection measures that reward the correct identification\nof objects that are most dangerous and most likely to affect driving decisions.\nTo achieve this, we build an object criticality model to reward the detection\nof the objects based on proximity, orientation, and relative velocity with\nrespect to the subject vehicle. Then, we apply our model on the recent\nautonomous driving dataset nuScenes, and we compare nine object detectors.\nResults show that, in several settings, object detectors that perform best\naccording to the nuScenes ranking are not the preferable ones when the focus is\nshifted on safety and reliability.\n","authors":["Andrea Ceccarelli","Leonardo Montecchi"],"pdf_url":"https://arxiv.org/pdf/2203.02205v3.pdf","comment":"journal version, open access"},{"id":"http://arxiv.org/abs/2212.05911v2","updated":"2023-11-23T16:49:58Z","published":"2022-12-07T15:10:40Z","title":"Adaptive Self-Training for Object Detection","summary":"  Deep learning has emerged as an effective solution for solving the task of\nobject detection in images but at the cost of requiring large labeled datasets.\nTo mitigate this cost, semi-supervised object detection methods, which consist\nin leveraging abundant unlabeled data, have been proposed and have already\nshown impressive results. However, most of these methods require linking a\npseudo-label to a ground-truth object by thresholding. In previous works, this\nthreshold value is usually determined empirically, which is time consuming, and\nonly done for a single data distribution. When the domain, and thus the data\ndistribution, changes, a new and costly parameter search is necessary. In this\nwork, we introduce our method Adaptive Self-Training for Object Detection\n(ASTOD), which is a simple yet effective teacher-student method. ASTOD\ndetermines without cost a threshold value based directly on the ground value of\nthe score histogram. To improve the quality of the teacher predictions, we also\npropose a novel pseudo-labeling procedure. We use different views of the\nunlabeled images during the pseudo-labeling step to reduce the number of missed\npredictions and thus obtain better candidate labels. Our teacher and our\nstudent are trained separately, and our method can be used in an iterative\nfashion by replacing the teacher by the student. On the MS-COCO dataset, our\nmethod consistently performs favorably against state-of-the-art methods that do\nnot require a threshold parameter, and shows competitive results with methods\nthat require a parameter sweep search. Additional experiments with respect to a\nsupervised baseline on the DIOR dataset containing satellite images lead to\nsimilar conclusions, and prove that it is possible to adapt the score threshold\nautomatically in self-training, regardless of the data distribution. The code\nis available at https:// github.com/rvandeghen/ASTOD\n","authors":["Renaud Vandeghen","Gilles Louppe","Marc Van Droogenbroeck"],"pdf_url":"https://arxiv.org/pdf/2212.05911v2.pdf","comment":"10 pages, 4 figures, 5 tables, 1 page of supplementary material"},{"id":"http://arxiv.org/abs/2311.14097v1","updated":"2023-11-23T16:49:06Z","published":"2023-11-23T16:49:06Z","title":"ACT: Adversarial Consistency Models","summary":"  Though diffusion models excel in image generation, their step-by-step\ndenoising leads to slow generation speeds. Consistency training addresses this\nissue with single-step sampling but often produces lower-quality generations\nand requires high training costs. In this paper, we show that optimizing\nconsistency training loss minimizes the Wasserstein distance between target and\ngenerated distributions. As timestep increases, the upper bound accumulates\nprevious consistency training losses. Therefore, larger batch sizes are needed\nto reduce both current and accumulated losses. We propose Adversarial\nConsistency Training (ACT), which directly minimizes the Jensen-Shannon (JS)\ndivergence between distributions at each timestep using a discriminator.\nTheoretically, ACT enhances generation quality, and convergence. By\nincorporating a discriminator into the consistency training framework, our\nmethod achieves improved FID scores on CIFAR10 and ImageNet 64$\\times$64,\nretains zero-shot image inpainting capabilities, and uses less than $1/6$ of\nthe original batch size and fewer than $1/2$ of the model parameters and\ntraining steps compared to the baseline method, this leads to a substantial\nreduction in resource consumption.\n","authors":["Fei Kong","Jinhao Duan","Lichao Sun","Hao Cheng","Renjing Xu","Hengtao Shen","Xiaofeng Zhu","Xiaoshuang Shi","Kaidi Xu"],"pdf_url":"https://arxiv.org/pdf/2311.14097v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14095v1","updated":"2023-11-23T16:41:30Z","published":"2023-11-23T16:41:30Z","title":"Video Anomaly Detection using GAN","summary":"  Accounting for the increased concern for public safety, automatic abnormal\nevent detection and recognition in a surveillance scene is crucial. It is a\ncurrent open study subject because of its intricacy and utility. The\nidentification of aberrant events automatically, it's a difficult undertaking\nbecause everyone's idea of abnormality is different. A typical occurrence in\none circumstance could be seen as aberrant in another. Automatic anomaly\nidentification becomes particularly challenging in the surveillance footage\nwith a large crowd due to congestion and high occlusion. With the use of\nmachine learning techniques, this thesis study aims to offer the solution for\nthis use case so that human resources won't be required to keep an eye out for\nany unusual activity in the surveillance system records. We have developed a\nnovel generative adversarial network (GAN) based anomaly detection model. This\nmodel is trained such that it learns together about constructing a high\ndimensional picture space and determining the latent space from the video's\ncontext. The generator uses a residual Autoencoder architecture made up of a\nmulti-stage channel attention-based decoder and a two-stream, deep\nconvolutional encoder that can realise both spatial and temporal data. We have\nalso offered a technique for refining the GAN model that reduces training time\nwhile also generalising the model by utilising transfer learning between\ndatasets. Using a variety of assessment measures, we compare our model to the\ncurrent state-of-the-art techniques on four benchmark datasets. The empirical\nfindings indicate that, in comparison to existing techniques, our network\nperforms favourably on all datasets.\n","authors":["Anikeit Sethi","Krishanu Saini","Sai Mounika Mididoddi"],"pdf_url":"https://arxiv.org/pdf/2311.14095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.19621v2","updated":"2023-11-23T16:37:25Z","published":"2023-05-31T07:41:10Z","title":"XTransCT: Ultra-Fast Volumetric CT Reconstruction using Two Orthogonal\n  X-Ray Projections for Image-guided Radiation Therapy via a Transformer\n  Network","summary":"  Computed tomography (CT) scans offer a detailed, three-dimensional\nrepresentation of patients' internal organs. However, conventional CT\nreconstruction techniques necessitate acquiring hundreds or thousands of x-ray\nprojections through a complete rotational scan of the body, making navigation\nor positioning during surgery infeasible. In image-guided radiation therapy, a\nmethod that reconstructs ultra-sparse X-ray projections into CT images, we can\nexploit the substantially reduced radiation dose and minimize equipment burden\nfor localization and navigation. In this study, we introduce a novel\nTransformer architecture, termed XTransCT, devised to facilitate real-time\nreconstruction of CT images from two-dimensional X-ray images. We assess our\napproach regarding image quality and structural reliability using a dataset of\nfifty patients, supplied by a hospital, as well as the larger public dataset\nLIDC-IDRI, which encompasses thousands of patients. Additionally, we validated\nour algorithm's generalizability on the LNDb dataset. Our findings indicate\nthat our algorithm surpasses other methods in image quality, structural\nprecision, and generalizability. Moreover, in comparison to previous 3D\nconvolution-based approaches, we note a substantial speed increase of\napproximately 300 %, achieving 44 ms per 3D image reconstruction.\n","authors":["Chulong Zhang","Lin Liu","Jingjing Dai","Xuan Liu","Wenfeng He","Yinping Chan","Yaoqin Xie","Feng Chi","Xiaokun Liang"],"pdf_url":"https://arxiv.org/pdf/2305.19621v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14090v1","updated":"2023-11-23T16:36:03Z","published":"2023-11-23T16:36:03Z","title":"Class Uncertainty: A Measure to Mitigate Class Imbalance","summary":"  Class-wise characteristics of training examples affect the performance of\ndeep classifiers. A well-studied example is when the number of training\nexamples of classes follows a long-tailed distribution, a situation that is\nlikely to yield sub-optimal performance for under-represented classes. This\nclass imbalance problem is conventionally addressed by approaches relying on\nthe class-wise cardinality of training examples, such as data resampling. In\nthis paper, we demonstrate that considering solely the cardinality of classes\ndoes not cover all issues causing class imbalance. To measure class imbalance,\nwe propose \"Class Uncertainty\" as the average predictive uncertainty of the\ntraining examples, and we show that this novel measure captures the differences\nacross classes better than cardinality. We also curate SVCI-20 as a novel\ndataset in which the classes have equal number of training examples but they\ndiffer in terms of their hardness; thereby causing a type of class imbalance\nwhich cannot be addressed by the approaches relying on cardinality. We\nincorporate our \"Class Uncertainty\" measure into a diverse set of ten class\nimbalance mitigation methods to demonstrate its effectiveness on long-tailed\ndatasets as well as on our SVCI-20. Code and datasets will be made available.\n","authors":["Z. S. Baltaci","K. Oksuz","S. Kuzucu","K. Tezoren","B. K. Konar","A. Ozkan","E. Akbas","S. Kalkan"],"pdf_url":"https://arxiv.org/pdf/2311.14090v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14086v1","updated":"2023-11-23T16:24:26Z","published":"2023-11-23T16:24:26Z","title":"Brain MRI Screening Tool with Federated Learning","summary":"  In clinical practice, we often see significant delays between MRI scans and\nthe diagnosis made by radiologists, even for severe cases. In some cases, this\nmay be caused by the lack of additional information and clues, so even the\nsevere cases need to wait in the queue for diagnosis. This can be avoided if\nthere is an automatic software tool, which would supplement additional\ninformation, alerting radiologists that the particular patient may be a severe\ncase.\n  We are presenting an automatic brain MRI Screening Tool and we are\ndemonstrating its capabilities for detecting tumor-like pathologies. It is the\nfirst version on the path toward a robust multi-pathology screening solution.\nThe tool supports Federated Learning, so multiple institutions may contribute\nto the model without disclosing their private data.\n","authors":["Roman Stoklasa","Ioannis Stathopoulos","Efstratios Karavasilis","Efstathios Efstathopoulos","Marek Dostál","Miloš Keřkovský","Michal Kozubek","Luigi Serio"],"pdf_url":"https://arxiv.org/pdf/2311.14086v1.pdf","comment":"5 pages, 2 figures. Submitted to ISBI 2024 conference"},{"id":"http://arxiv.org/abs/2311.14084v1","updated":"2023-11-23T16:22:58Z","published":"2023-11-23T16:22:58Z","title":"AI-Generated Images Introduce Invisible Relevance Bias to Text-Image\n  Retrieval","summary":"  With the advancement of generation models, AI-generated content (AIGC) is\nbecoming more realistic, flooding the Internet. A recent study suggests that\nthis phenomenon has elevated the issue of source bias in text retrieval for web\nsearches. Specifically, neural retrieval models tend to rank generated texts\nhigher than human-written texts. In this paper, we extend the study of this\nbias to cross-modal retrieval. Firstly, we successfully construct a suitable\nbenchmark to explore the existence of the bias. Subsequent extensive\nexperiments on this benchmark reveal that AI-generated images introduce an\ninvisible relevance bias to text-image retrieval models. Specifically, our\nexperiments show that text-image retrieval models tend to rank the AI-generated\nimages higher than the real images, even though the AI-generated images do not\nexhibit more visually relevant features to the query than real images. This\ninvisible relevance bias is prevalent across retrieval models with varying\ntraining data and architectures. Furthermore, our subsequent exploration\nreveals that the inclusion of AI-generated images in the training data of the\nretrieval models exacerbates the invisible relevance bias. The above phenomenon\ntriggers a vicious cycle, which makes the invisible relevance bias become more\nand more serious. To elucidate the potential causes of invisible relevance and\naddress the aforementioned issues, we introduce an effective training method\naimed at alleviating the invisible relevance bias. Subsequently, we apply our\nproposed debiasing method to retroactively identify the causes of invisible\nrelevance, revealing that the AI-generated images induce the image encoder to\nembed additional information into their representation. This information\nexhibits a certain consistency across generated images with different semantics\nand can make the retriever estimate a higher relevance score.\n","authors":["Shicheng Xu","Danyang Hou","Liang Pang","Jingcheng Deng","Jun Xu","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2311.14084v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2311.14081v1","updated":"2023-11-23T16:19:59Z","published":"2023-11-23T16:19:59Z","title":"You Only Explain Once","summary":"  In this paper, we propose a new black-box explainability algorithm and tool,\nYO-ReX, for efficient explanation of the outputs of object detectors. The new\nalgorithm computes explanations for all objects detected in the image\nsimultaneously. Hence, compared to the baseline, the new algorithm reduces the\nnumber of queries by a factor of 10X for the case of ten detected objects. The\nspeedup increases further with with the number of objects. Our experimental\nresults demonstrate that YO-ReX can explain the outputs of YOLO with a\nnegligible overhead over the running time of YOLO. We also demonstrate similar\nresults for explaining SSD and Faster R-CNN. The speedup is achieved by\navoiding backtracking by combining aggressive pruning with a causal analysis.\n","authors":["David A. Kelly","Hana Chockler","Daniel Kroening","Nathan Blake","Aditi Ramaswamy","Melane Navaratnarajah","Aaditya Shivakumar"],"pdf_url":"https://arxiv.org/pdf/2311.14081v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14073v1","updated":"2023-11-23T16:04:41Z","published":"2023-11-23T16:04:41Z","title":"Learning Saliency From Fixations","summary":"  We present a novel approach for saliency prediction in images, leveraging\nparallel decoding in transformers to learn saliency solely from fixation maps.\nModels typically rely on continuous saliency maps, to overcome the difficulty\nof optimizing for the discrete fixation map. We attempt to replicate the\nexperimental setup that generates saliency datasets. Our approach treats\nsaliency prediction as a direct set prediction problem, via a global loss that\nenforces unique fixations prediction through bipartite matching and a\ntransformer encoder-decoder architecture. By utilizing a fixed set of learned\nfixation queries, the cross-attention reasons over the image features to\ndirectly output the fixation points, distinguishing it from other modern\nsaliency predictors. Our approach, named Saliency TRansformer (SalTR), achieves\nmetric scores on par with state-of-the-art approaches on the Salicon and MIT300\nbenchmarks.\n","authors":["Yasser Abdelaziz Dahou Djilali","Kevin McGuiness","Noel O'Connor"],"pdf_url":"https://arxiv.org/pdf/2311.14073v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.10192v2","updated":"2023-11-23T15:44:52Z","published":"2023-08-20T07:45:03Z","title":"EDDense-Net: Fully Dense Encoder Decoder Network for Joint Segmentation\n  of Optic Cup and Disc","summary":"  Glaucoma is an eye disease that causes damage to the optic nerve, which can\nlead to visual loss and permanent blindness. Early glaucoma detection is\ntherefore critical in order to avoid permanent blindness. The estimation of the\ncup-to-disc ratio (CDR) during an examination of the optical disc (OD) is used\nfor the diagnosis of glaucoma. In this paper, we present the EDDense-Net\nsegmentation network for the joint segmentation of OC and OD. The encoder and\ndecoder in this network are made up of dense blocks with a grouped\nconvolutional layer in each block, allowing the network to acquire and convey\nspatial information from the image while simultaneously reducing the network's\ncomplexity. To reduce spatial information loss, the optimal number of filters\nin all convolution layers were utilised. In semantic segmentation, dice pixel\nclassification is employed in the decoder to alleviate the problem of class\nimbalance. The proposed network was evaluated on two publicly available\ndatasets where it outperformed existing state-of-the-art methods in terms of\naccuracy and efficiency. For the diagnosis and analysis of glaucoma, this\nmethod can be used as a second opinion system to assist medical\nophthalmologists.\n","authors":["Mehwish Mehmood","Khuram Naveed","Khursheed Aurangzeb","Haroon Ahmed Khan","Musaed Alhussein","Syed Saud Naqvi"],"pdf_url":"https://arxiv.org/pdf/2308.10192v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14064v1","updated":"2023-11-23T15:42:42Z","published":"2023-11-23T15:42:42Z","title":"HGCLIP: Exploring Vision-Language Models with Graph Representations for\n  Hierarchical Understanding","summary":"  Object categories are typically organized into a multi-granularity taxonomic\nhierarchy. When classifying categories at different hierarchy levels,\ntraditional uni-modal approaches focus primarily on image features, revealing\nlimitations in complex scenarios. Recent studies integrating Vision-Language\nModels (VLMs) with class hierarchies have shown promise, yet they fall short of\nfully exploiting the hierarchical relationships. These efforts are constrained\nby their inability to perform effectively across varied granularity of\ncategories. To tackle this issue, we propose a novel framework (HGCLIP) that\neffectively combines CLIP with a deeper exploitation of the Hierarchical class\nstructure via Graph representation learning. We explore constructing the class\nhierarchy into a graph, with its nodes representing the textual or image\nfeatures of each category. After passing through a graph encoder, the textual\nfeatures incorporate hierarchical structure information, while the image\nfeatures emphasize class-aware features derived from prototypes through the\nattention mechanism. Our approach demonstrates significant improvements on both\ngeneric and fine-grained visual recognition benchmarks. Our codes are fully\navailable at https://github.com/richard-peng-xia/HGCLIP.\n","authors":["Peng Xia","Xingtong Yu","Ming Hu","Lie Ju","Zhiyong Wang","Peibo Duan","Zongyuan Ge"],"pdf_url":"https://arxiv.org/pdf/2311.14064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14063v1","updated":"2023-11-23T15:42:00Z","published":"2023-11-23T15:42:00Z","title":"Do VSR Models Generalize Beyond LRS3?","summary":"  The Lip Reading Sentences-3 (LRS3) benchmark has primarily been the focus of\nintense research in visual speech recognition (VSR) during the last few years.\nAs a result, there is an increased risk of overfitting to its excessively used\ntest set, which is only one hour duration. To alleviate this issue, we build a\nnew VSR test set named WildVSR, by closely following the LRS3 dataset creation\nprocesses. We then evaluate and analyse the extent to which the current VSR\nmodels generalize to the new test data. We evaluate a broad range of publicly\navailable VSR models and find significant drops in performance on our test set,\ncompared to their corresponding LRS3 results. Our results suggest that the\nincrease in word error rates is caused by the models inability to generalize to\nslightly harder and in the wild lip sequences than those found in the LRS3 test\nset. Our new test benchmark is made public in order to enable future research\ntowards more robust VSR models.\n","authors":["Yasser Abdelaziz Dahou Djilali","Sanath Narayan","Eustache Le Bihan","Haithem Boussaid","Ebtessam Almazrouei","Merouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2311.14063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14062v1","updated":"2023-11-23T15:38:13Z","published":"2023-11-23T15:38:13Z","title":"Hardware Resilience Properties of Text-Guided Image Classifiers","summary":"  This paper presents a novel method to enhance the reliability of image\nclassification models during deployment in the face of transient hardware\nerrors. By utilizing enriched text embeddings derived from GPT-3 with question\nprompts per class and CLIP pretrained text encoder, we investigate their impact\nas an initialization for the classification layer. Our approach achieves a\nremarkable $5.5\\times$ average increase in hardware reliability (and up to 14x)\nacross various architectures in the most critical layer, with minimal accuracy\ndrop (0.3% on average) compared to baseline PyTorch models. Furthermore, our\nmethod seamlessly integrates with any image classification backbone, showcases\nresults across various network architectures, decreases parameter and FLOPs\noverhead, and follows a consistent training recipe. This research offers a\npractical and efficient solution to bolster the robustness of image\nclassification models against hardware failures, with potential implications\nfor future studies in this domain. Our code and models are released at\nhttps://github.com/TalalWasim/TextGuidedResilience.\n","authors":["Syed Talal Wasim","Kabila Haile Saboka","Abdulrahman Mahmoud","Salman Khan","David Brooks","Gu-Yeon Wei"],"pdf_url":"https://arxiv.org/pdf/2311.14062v1.pdf","comment":"Accepted at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2305.12476v3","updated":"2023-11-23T15:22:39Z","published":"2023-05-21T14:40:48Z","title":"Zero-shot Visual Relation Detection via Composite Visual Cues from Large\n  Language Models","summary":"  Pretrained vision-language models, such as CLIP, have demonstrated strong\ngeneralization capabilities, making them promising tools in the realm of\nzero-shot visual recognition. Visual relation detection (VRD) is a typical task\nthat identifies relationship (or interaction) types between object pairs within\nan image. However, naively utilizing CLIP with prevalent class-based prompts\nfor zero-shot VRD has several weaknesses, e.g., it struggles to distinguish\nbetween different fine-grained relation types and it neglects essential spatial\ninformation of two objects. To this end, we propose a novel method for\nzero-shot VRD: RECODE, which solves RElation detection via COmposite\nDEscription prompts. Specifically, RECODE first decomposes each predicate\ncategory into subject, object, and spatial components. Then, it leverages large\nlanguage models (LLMs) to generate description-based prompts (or visual cues)\nfor each component. Different visual cues enhance the discriminability of\nsimilar relation categories from different perspectives, which significantly\nboosts performance in VRD. To dynamically fuse different cues, we further\nintroduce a chain-of-thought method that prompts LLMs to generate reasonable\nweights for different visual cues. Extensive experiments on four VRD benchmarks\nhave demonstrated the effectiveness and interpretability of RECODE.\n","authors":["Lin Li","Jun Xiao","Guikun Chen","Jian Shao","Yueting Zhuang","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2305.12476v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14049v1","updated":"2023-11-23T15:05:12Z","published":"2023-11-23T15:05:12Z","title":"Assessment of Deep Learning Segmentation for Real-Time Free-Breathing\n  Cardiac Magnetic Resonance Imaging","summary":"  In recent years, a variety of deep learning networks for cardiac MRI (CMR)\nsegmentation have been developed and analyzed. However, nearly all of them are\nfocused on cine CMR under breathold. In this work, accuracy of deep learning\nmethods is assessed for volumetric analysis (via segmentation) of the left\nventricle in real-time free-breathing CMR at rest and under exercise stress.\nData from healthy volunteers (n=15) for cine and real-time free-breathing CMR\nwere analyzed retrospectively. Segmentations of a commercial software (comDL)\nand a freely available neural network (nnU-Net), were compared to a reference\ncreated via the manual correction of comDL segmentation. Segmentation of left\nventricular endocardium (LV), left ventricular myocardium (MYO), and right\nventricle (RV) is evaluated for both end-systolic and end-diastolic phases and\nanalyzed with Dice's coefficient (DC). The volumetric analysis includes LV\nend-diastolic volume (EDV), LV end-systolic volume (ESV), and LV ejection\nfraction (EF). For cine CMR, nnU-Net and comDL achieve a DC above 0.95 for LV\nand 0.9 for MYO, and RV. For real-time CMR, the accuracy of nnU-Net exceeds\nthat of comDL overall. For real-time CMR at rest, nnU-Net achieves a DC of 0.94\nfor LV, 0.89 for MYO, and 0.90 for RV; mean absolute differences between\nnnU-Net and reference are 2.9mL for EDV, 3.5mL for ESV and 2.6% for EF. For\nreal-time CMR under exercise stress, nnU-Net achieves a DC of 0.92 for LV, 0.85\nfor MYO, and 0.83 for RV; mean absolute differences between nnU-Net and\nreference are 11.4mL for EDV, 2.9mL for ESV and 3.6% for EF. Deep learning\nmethods designed or trained for cine CMR segmentation can perform well on\nreal-time CMR. For real-time free-breathing CMR at rest, the performance of\ndeep learning methods is comparable to inter-observer variability in cine CMR\nand is usable or fully automatic segmentation.\n","authors":["Martin Schilling","Christina Unterberg-Buchwald","Joachim Lotz","Martin Uecker"],"pdf_url":"https://arxiv.org/pdf/2311.14049v1.pdf","comment":"*These authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2311.14029v1","updated":"2023-11-23T14:33:53Z","published":"2023-11-23T14:33:53Z","title":"Understanding the Vulnerability of CLIP to Image Compression","summary":"  CLIP is a widely used foundational vision-language model that is used for\nzero-shot image recognition and other image-text alignment tasks. We\ndemonstrate that CLIP is vulnerable to change in image quality under\ncompression. This surprising result is further analysed using an attribution\nmethod-Integrated Gradients. Using this attribution method, we are able to\nbetter understand both quantitatively and qualitatively exactly the nature in\nwhich the compression affects the zero-shot recognition accuracy of this model.\nWe evaluate this extensively on CIFAR-10 and STL-10. Our work provides the\nbasis to understand this vulnerability of CLIP and can help us develop more\neffective methods to improve the robustness of CLIP and other vision-language\nmodels.\n","authors":["Cangxiong Chen","Vinay P. Namboodiri","Julian Padget"],"pdf_url":"https://arxiv.org/pdf/2311.14029v1.pdf","comment":"R0-FoMo: Workshop on Robustness of Few-shot and Zero-shot Learning in\n  Foundation Models at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.14028v1","updated":"2023-11-23T14:33:03Z","published":"2023-11-23T14:33:03Z","title":"Continual Learning of Diffusion Models with Generative Distillation","summary":"  Diffusion models are powerful generative models that achieve state-of-the-art\nperformance in tasks such as image synthesis. However, training them demands\nsubstantial amounts of data and computational resources. Continual learning\nwould allow for incrementally learning new tasks and accumulating knowledge,\nthus reusing already trained models would be possible. One potentially suitable\napproach is generative replay, where a copy of a generative model trained on\nprevious tasks produces synthetic data that are interleaved with data from the\ncurrent task. However, standard generative replay applied to diffusion models\nresults in a catastrophic loss in denoising capabilities. In this paper, we\npropose generative distillation, an approach that distils the entire reverse\nprocess of a diffusion model. We demonstrate that our approach significantly\nimproves the continual learning performance of generative replay with only a\nmoderate increase in the computational costs.\n","authors":["Sergi Masip","Pau Rodriguez","Tinne Tuytelaars","Gido M. van de Ven"],"pdf_url":"https://arxiv.org/pdf/2311.14028v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14024v1","updated":"2023-11-23T14:28:28Z","published":"2023-11-23T14:28:28Z","title":"Creating and Benchmarking a Synthetic Dataset for Cloud Optical\n  Thickness Estimation","summary":"  Cloud formations often obscure optical satellite-based monitoring of the\nEarth's surface, thus limiting Earth observation (EO) activities such as land\ncover mapping, ocean color analysis, and cropland monitoring. The integration\nof machine learning (ML) methods within the remote sensing domain has\nsignificantly improved performance on a wide range of EO tasks, including cloud\ndetection and filtering, but there is still much room for improvement. A key\nbottleneck is that ML methods typically depend on large amounts of annotated\ndata for training, which is often difficult to come by in EO contexts. This is\nespecially true for the task of cloud optical thickness (COT) estimation. A\nreliable estimation of COT enables more fine-grained and application-dependent\ncontrol compared to using pre-specified cloud categories, as is commonly done\nin practice. To alleviate the COT data scarcity problem, in this work we\npropose a novel synthetic dataset for COT estimation, where top-of-atmosphere\nradiances have been simulated for 12 of the spectral bands of the\nMulti-Spectral Instrument (MSI) sensor onboard Sentinel-2 platforms. These data\npoints have been simulated under consideration of different cloud types, COTs,\nand ground surface and atmospheric profiles. Extensive experimentation of\ntraining several ML models to predict COT from the measured reflectivity of the\nspectral bands demonstrates the usefulness of our proposed dataset.\nGeneralization to real data is also demonstrated on two satellite image\ndatasets -- one that is publicly available, and one which we have collected and\nannotated. The synthetic data, the newly collected real dataset, code and\nmodels have been made publicly available at\nhttps://github.com/aleksispi/ml-cloud-opt-thick.\n","authors":["Aleksis Pirinen","Nosheen Abid","Nuria Agues Paszkowsky","Thomas Ohlson Timoudas","Ronald Scheirer","Chiara Ceccobello","György Kovács","Anders Persson"],"pdf_url":"https://arxiv.org/pdf/2311.14024v1.pdf","comment":"Code, data and models available at\n  https://github.com/aleksispi/ml-cloud-opt-thick"},{"id":"http://arxiv.org/abs/2311.14012v1","updated":"2023-11-23T14:07:35Z","published":"2023-11-23T14:07:35Z","title":"Shadow: A Novel Loss Function for Efficient Training in Siamese Networks","summary":"  Despite significant recent advances in similarity detection tasks, existing\napproaches pose substantial challenges under memory constraints. One of the\nprimary reasons for this is the use of computationally expensive metric\nlearning loss functions such as Triplet Loss in Siamese networks. In this\npaper, we present a novel loss function called Shadow Loss that compresses the\ndimensions of an embedding space during loss calculation without loss of\nperformance. The distance between the projections of the embeddings is learned\nfrom inputs on a compact projection space where distances directly correspond\nto a measure of class similarity. Projecting on a lower-dimension projection\nspace, our loss function converges faster, and the resulting classified image\nclusters have higher inter-class and smaller intra-class distances. Shadow Loss\nnot only reduces embedding dimensions favoring memory constraint devices but\nalso consistently performs better than the state-of-the-art Triplet Margin Loss\nby an accuracy of 5\\%-10\\% across diverse datasets. The proposed loss function\nis also model agnostic, upholding its performance across several tested models.\nIts effectiveness and robustness across balanced, imbalanced, medical, and\nnon-medical image datasets suggests that it is not specific to a particular\nmodel or dataset but demonstrates superior performance consistently while using\nless memory and computation.\n","authors":["Alif Elham Khan","Mohammad Junayed Hasan","Humayra Anjum","Nabeel Mohammed"],"pdf_url":"https://arxiv.org/pdf/2311.14012v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14006v1","updated":"2023-11-23T13:43:14Z","published":"2023-11-23T13:43:14Z","title":"High-resolution Population Maps Derived from Sentinel-1 and Sentinel-2","summary":"  Detailed population maps play an important role in diverse fields ranging\nfrom humanitarian action to urban planning. Generating such maps in a timely\nand scalable manner presents a challenge, especially in data-scarce regions. To\naddress it we have developed POPCORN, a population mapping method whose only\ninputs are free, globally available satellite images from Sentinel-1 and\nSentinel-2; and a small number of aggregate population counts over coarse\ncensus districts for calibration. Despite the minimal data requirements our\napproach surpasses the mapping accuracy of existing schemes, including several\nthat rely on building footprints derived from high-resolution imagery. E.g., we\nwere able to produce population maps for Rwanda with 100m GSD based on less\nthan 400 regional census counts. In Kigali, those maps reach an $R^2$ score of\n66% w.r.t. a ground truth reference map, with an average error of only $\\pm$10\ninhabitants/ha. Conveniently, POPCORN retrieves explicit maps of built-up areas\nand of local building occupancy rates, making the mapping process interpretable\nand offering additional insights, for instance about the distribution of\nbuilt-up, but unpopulated areas, e.g., industrial warehouses. Moreover, we find\nthat, once trained, the model can be applied repeatedly to track population\nchanges; and that it can be transferred to geographically similar regions,\ne.g., from Uganda to Rwanda). With our work we aim to democratize access to\nup-to-date and high-resolution population maps, recognizing that some regions\nfaced with particularly strong population dynamics may lack the resources for\ncostly micro-census campaigns.\n","authors":["Nando Metzger","Rodrigo Caye Daudt","Devis Tuia","Konrad Schindler"],"pdf_url":"https://arxiv.org/pdf/2311.14006v1.pdf","comment":"17 pages, 10 tables, 7 Figures"},{"id":"http://arxiv.org/abs/2311.13997v1","updated":"2023-11-23T13:32:06Z","published":"2023-11-23T13:32:06Z","title":"GRJointNET: Synergistic Completion and Part Segmentation on 3D\n  Incomplete Point Clouds","summary":"  Segmentation of three-dimensional (3D) point clouds is an important task for\nautonomous systems. However, success of segmentation algorithms depends greatly\non the quality of the underlying point clouds (resolution, completeness etc.).\nIn particular, incomplete point clouds might reduce a downstream model's\nperformance. GRNet is proposed as a novel and recent deep learning solution to\ncomplete point clouds, but it is not capable of part segmentation. On the other\nhand, our proposed solution, GRJointNet, is an architecture that can perform\njoint completion and segmentation on point clouds as a successor of GRNet.\nFeatures extracted for the two tasks are also utilized by each other to\nincrease the overall performance. We evaluated our proposed network on the\nShapeNet-Part dataset and compared its performance to GRNet. Our results\ndemonstrate GRJointNet can outperform GRNet on point completion. It should also\nbe noted that GRNet is not capable of segmentation while GRJointNet is. This\nstudy1, therefore, holds a promise to enhance practicality and utility of point\nclouds in 3D vision for autonomous systems.\n","authors":["Yigit Gurses","Melisa Taspinar","Mahmut Yurt","Sedat Ozer"],"pdf_url":"https://arxiv.org/pdf/2311.13997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13993v1","updated":"2023-11-23T13:20:42Z","published":"2023-11-23T13:20:42Z","title":"EIGEN: Expert-Informed Joint Learning Aggregation for High-Fidelity\n  Information Extraction from Document Images","summary":"  Information Extraction (IE) from document images is challenging due to the\nhigh variability of layout formats. Deep models such as LayoutLM and BROS have\nbeen proposed to address this problem and have shown promising results.\nHowever, they still require a large amount of field-level annotations for\ntraining these models. Other approaches using rule-based methods have also been\nproposed based on the understanding of the layout and semantics of a form such\nas geometric position, or type of the fields, etc. In this work, we propose a\nnovel approach, EIGEN (Expert-Informed Joint Learning aGgrEatioN), which\ncombines rule-based methods with deep learning models using data programming\napproaches to circumvent the requirement of annotation of large amounts of\ntraining data. Specifically, EIGEN consolidates weak labels induced from\nmultiple heuristics through generative models and use them along with a small\nnumber of annotated labels to jointly train a deep model. In our framework, we\npropose the use of labeling functions that include incorporating contextual\ninformation thus capturing the visual and language context of a word for\naccurate categorization. We empirically show that our EIGEN framework can\nsignificantly improve the performance of state-of-the-art deep models with the\navailability of very few labeled data instances. The source code is available\nat\nhttps://github.com/ayushayush591/EIGEN-High-Fidelity-Extraction-Document-Images.\n","authors":["Abhishek Singh","Venkatapathy Subramanian","Ayush Maheshwari","Pradeep Narayan","Devi Prasad Shetty","Ganesh Ramakrishnan"],"pdf_url":"https://arxiv.org/pdf/2311.13993v1.pdf","comment":"In Proceedings of ML for Health Conference, 2023 (co-located with\n  Neurips)"},{"id":"http://arxiv.org/abs/2311.13986v1","updated":"2023-11-23T13:07:21Z","published":"2023-11-23T13:07:21Z","title":"FViT-Grasp: Grasping Objects With Using Fast Vision Transformers","summary":"  This study addresses the challenge of manipulation, a prominent issue in\nrobotics. We have devised a novel methodology for swiftly and precisely\nidentifying the optimal grasp point for a robot to manipulate an object. Our\napproach leverages a Fast Vision Transformer (FViT), a type of neural network\ndesigned for processing visual data and predicting the most suitable grasp\nlocation. Demonstrating state-of-the-art performance in terms of speed while\nmaintaining a high level of accuracy, our method holds promise for potential\ndeployment in real-time robotic grasping applications. We believe that this\nstudy provides a baseline for future research in vision-based robotic grasp\napplications. Its high speed and accuracy bring researchers closer to real-life\napplications.\n","authors":["Arda Sarp Yenicesu","Berk Cicek","Ozgur S. Oguz"],"pdf_url":"https://arxiv.org/pdf/2311.13986v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.11952v2","updated":"2023-11-23T12:54:39Z","published":"2022-05-24T10:32:32Z","title":"3D helical CT Reconstruction with a Memory Efficient Learned Primal-Dual\n  Architecture","summary":"  Deep learning based computed tomography (CT) reconstruction has demonstrated\noutstanding performance on simulated 2D low-dose CT data. This applies in\nparticular to domain adapted neural networks, which incorporate a handcrafted\nphysics model for CT imaging. Empirical evidence shows that employing such\narchitectures reduces the demand for training data and improves upon\ngeneralisation. However, their training requires large computational resources\nthat quickly become prohibitive in 3D helical CT, which is the most common\nacquisition geometry used for medical imaging. Furthermore, clinical data also\ncomes with other challenges not accounted for in simulations, like errors in\nflux measurement, resolution mismatch and, most importantly, the absence of the\nreal ground truth. The necessity to have a computationally feasible training\ncombined with the need to address these issues has made it difficult to\nevaluate deep learning based reconstruction on clinical 3D helical CT. This\npaper modifies a domain adapted neural network architecture, the Learned\nPrimal-Dual (LPD), so that it can be trained and applied to reconstruction in\nthis setting. We achieve this by splitting the helical trajectory into sections\nand applying the unrolled LPD iterations to those sections sequentially. To the\nbest of our knowledge, this work is the first to apply an unrolled deep\nlearning architecture for reconstruction on full-sized clinical data, like\nthose in the Low dose CT image and projection data set (LDCT). Moreover,\ntraining and testing is done on a single GPU card with 24GB of memory.\n","authors":["Jevgenija Rudzusika","Buda Bajić","Thomas Koehler","Ozan Öktem"],"pdf_url":"https://arxiv.org/pdf/2205.11952v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13976v1","updated":"2023-11-23T12:42:52Z","published":"2023-11-23T12:42:52Z","title":"Low Latency Instance Segmentation by Continuous Clustering for Rotating\n  LiDAR Sensors","summary":"  Low-latency instance segmentation of LiDAR point clouds is crucial in\nreal-world applications because it serves as an initial and frequently-used\nbuilding block in a robot's perception pipeline, where every task adds further\ndelay. Particularly in dynamic environments, this total delay can result in\nsignificant positional offsets of dynamic objects, as seen in highway\nscenarios. To address this issue, we employ continuous clustering of obstacle\npoints in order to obtain an instance-segmented point cloud. Unlike most\nexisting approaches, which use a full revolution of the LiDAR sensor, we\nprocess the data stream in a continuous and seamless fashion. More\nspecifically, each column of a range image is processed as soon it is\navailable. Obstacle points are clustered to existing instances in real-time and\nit is checked at a high-frequency which instances are completed and are ready\nto be published. An additional advantage is that no problematic discontinuities\nbetween the points of the start and the end of a scan are observed. In this\nwork we describe the two-layered data structure and the corresponding algorithm\nfor continuous clustering, which is able to cluster the incoming data in real\ntime. We explain the importance of a large perceptive field of view.\nFurthermore, we describe and evaluate important architectural design choices,\nwhich could be relevant to design an architecture for deep learning based\nlow-latency instance segmentation. We are publishing the source code at\nhttps://github.com/UniBwTAS/continuous_clustering.\n","authors":["Andreas Reich","Hans-Joachim Wuensche"],"pdf_url":"https://arxiv.org/pdf/2311.13976v1.pdf","comment":"Accompanying Video: https://www.youtube.com/watch?v=DZKuAQBngNE"},{"id":"http://arxiv.org/abs/2207.11209v4","updated":"2023-11-23T12:40:56Z","published":"2022-07-22T17:19:00Z","title":"Divide and Conquer: 3D Point Cloud Instance Segmentation With Point-Wise\n  Binarization","summary":"  Instance segmentation on point clouds is crucially important for 3D scene\nunderstanding. Most SOTAs adopt distance clustering, which is typically\neffective but does not perform well in segmenting adjacent objects with the\nsame semantic label (especially when they share neighboring points). Due to the\nuneven distribution of offset points, these existing methods can hardly cluster\nall instance points. To this end, we design a novel divide-and-conquer strategy\nnamed PBNet that binarizes each point and clusters them separately to segment\ninstances. Our binary clustering divides offset instance points into two\ncategories: high and low density points (HPs vs. LPs). Adjacent objects can be\nclearly separated by removing LPs, and then be completed and refined by\nassigning LPs via a neighbor voting method. To suppress potential\nover-segmentation, we propose to construct local scenes with the weight mask\nfor each instance. As a plug-in, the proposed binary clustering can replace\ntraditional distance clustering and lead to consistent performance gains on\nmany mainstream baselines. A series of experiments on ScanNetV2 and S3DIS\ndatasets indicate the superiority of our model. In particular, PBNet ranks\nfirst on the ScanNetV2 official benchmark challenge, achieving the highest mAP.\nCode will be available publicly at https://github.com/weiguangzhao/PBNet.\n","authors":["Weiguang Zhao","Yuyao Yan","Chaolong Yang","Jianan Ye","Xi Yang","Kaizhu Huang"],"pdf_url":"https://arxiv.org/pdf/2207.11209v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13964v1","updated":"2023-11-23T12:26:08Z","published":"2023-11-23T12:26:08Z","title":"Deep Interactive Segmentation of Medical Images: A Systematic Review and\n  Taxonomy","summary":"  Interactive segmentation is a crucial research area in medical image analysis\naiming to boost the efficiency of costly annotations by incorporating human\nfeedback. This feedback takes the form of clicks, scribbles, or masks and\nallows for iterative refinement of the model output so as to efficiently guide\nthe system towards the desired behavior. In recent years, deep learning-based\napproaches have propelled results to a new level causing a rapid growth in the\nfield with 121 methods proposed in the medical imaging domain alone. In this\nreview, we provide a structured overview of this emerging field featuring a\ncomprehensive taxonomy, a systematic review of existing methods, and an\nin-depth analysis of current practices. Based on these contributions, we\ndiscuss the challenges and opportunities in the field. For instance, we find\nthat there is a severe lack of comparison across methods which needs to be\ntackled by standardized baselines and benchmarks.\n","authors":["Zdravko Marinov","Paul F. Jäger","Jan Egger","Jens Kleesiek","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2311.13964v1.pdf","comment":"26 pages, 8 figures, 10 tables; Zdravko Marinov and Paul F. J\\\"ager\n  and co-first authors; This work has been submitted to the IEEE for possible\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible"},{"id":"http://arxiv.org/abs/2311.13963v1","updated":"2023-11-23T12:24:02Z","published":"2023-11-23T12:24:02Z","title":"Investigating the use of publicly available natural videos to learn\n  Dynamic MR image reconstruction","summary":"  Purpose: To develop and assess a deep learning (DL) pipeline to learn dynamic\nMR image reconstruction from publicly available natural videos (Inter4K).\n  Materials and Methods: Learning was performed for a range of DL architectures\n(VarNet, 3D UNet, FastDVDNet) and corresponding sampling patterns (Cartesian,\nradial, spiral) either from true multi-coil cardiac MR data (N=692) or from\npseudo-MR data simulated from Inter4K natural videos (N=692). Real-time\nundersampled dynamic MR images were reconstructed using DL networks trained\nwith cardiac data and natural videos, and compressed sensing (CS). Differences\nwere assessed in simulations (N=104 datasets) in terms of MSE, PSNR, and SSIM\nand prospectively for cardiac (short axis, four chambers, N=20) and speech\n(N=10) data in terms of subjective image quality ranking, SNR and Edge\nsharpness. Friedman Chi Square tests with post-hoc Nemenyi analysis were\nperformed to assess statistical significance.\n  Results: For all simulation metrics, DL networks trained with cardiac data\noutperformed DL networks trained with natural videos, which outperformed CS\n(p<0.05). However, in prospective experiments DL reconstructions using both\ntraining datasets were ranked similarly (and higher than CS) and presented no\nstatistical differences in SNR and Edge Sharpness for most conditions.\nAdditionally, high SSIM was measured between the DL methods with cardiac data\nand natural videos (SSIM>0.85).\n  Conclusion: The developed pipeline enabled learning dynamic MR reconstruction\nfrom natural videos preserving DL reconstruction advantages such as high\nquality fast and ultra-fast reconstructions while overcoming some limitations\n(data scarcity or sharing). The natural video dataset, code and pre-trained\nnetworks are made readily available on github.\n  Key Words: real-time; dynamic MRI; deep learning; image reconstruction;\nmachine learning;\n","authors":["Olivier Jaubert","Michele Pascale","Javier Montalt-Tordera","Julius Akesson","Ruta Virsinskaite","Daniel Knight","Simon Arridge","Jennifer Steeden","Vivek Muthurangu"],"pdf_url":"https://arxiv.org/pdf/2311.13963v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13959v1","updated":"2023-11-23T12:17:45Z","published":"2023-11-23T12:17:45Z","title":"RankFeat\\&RankWeight: Rank-1 Feature/Weight Removal for\n  Out-of-distribution Detection","summary":"  The task of out-of-distribution (OOD) detection is crucial for deploying\nmachine learning models in real-world settings. In this paper, we observe that\nthe singular value distributions of the in-distribution (ID) and OOD features\nare quite different: the OOD feature matrix tends to have a larger dominant\nsingular value than the ID feature, and the class predictions of OOD samples\nare largely determined by it. This observation motivates us to propose\n\\texttt{RankFeat}, a simple yet effective \\emph{post hoc} approach for OOD\ndetection by removing the rank-1 matrix composed of the largest singular value\nand the associated singular vectors from the high-level feature.\n\\texttt{RankFeat} achieves \\emph{state-of-the-art} performance and reduces the\naverage false positive rate (FPR95) by 17.90\\% compared with the previous best\nmethod. The success of \\texttt{RankFeat} motivates us to investigate whether a\nsimilar phenomenon would exist in the parameter matrices of neural networks. We\nthus propose \\texttt{RankWeight} which removes the rank-1 weight from the\nparameter matrices of a single deep layer. Our \\texttt{RankWeight}is also\n\\emph{post hoc} and only requires computing the rank-1 matrix once. As a\nstandalone approach, \\texttt{RankWeight} has very competitive performance\nagainst other methods across various backbones. Moreover, \\texttt{RankWeight}\nenjoys flexible compatibility with a wide range of OOD detection methods. The\ncombination of \\texttt{RankWeight} and \\texttt{RankFeat} refreshes the new\n\\emph{state-of-the-art} performance, achieving the FPR95 as low as 16.13\\% on\nthe ImageNet-1k benchmark. Extensive ablation studies and comprehensive\ntheoretical analyses are presented to support the empirical results.\n","authors":["Yue Song","Nicu Sebe","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13959v1.pdf","comment":"submitted to T-PAMI"},{"id":"http://arxiv.org/abs/2311.13958v1","updated":"2023-11-23T12:16:33Z","published":"2023-11-23T12:16:33Z","title":"High-Order Tensor Recovery with A Tensor $U_1$ Norm","summary":"  Recently, numerous tensor SVD (t-SVD)-based tensor recovery methods have\nemerged, showing promise in processing visual data. However, these methods\noften suffer from performance degradation when confronted with high-order\ntensor data exhibiting non-smooth changes, commonly observed in real-world\nscenarios but ignored by the traditional t-SVD-based methods. Our objective in\nthis study is to provide an effective tensor recovery technique for handling\nnon-smooth changes in tensor data and efficiently explore the correlations of\nhigh-order tensor data across its various dimensions without introducing\nnumerous variables and weights. To this end, we introduce a new tensor\ndecomposition and a new tensor norm called the Tensor $U_1$ norm. We utilize\nthese novel techniques in solving the problem of high-order tensor completion\nproblem and provide theoretical guarantees for the exact recovery of the\nresulting tensor completion models. An optimization algorithm is proposed to\nsolve the resulting tensor completion model iteratively by combining the\nproximal algorithm with the Alternating Direction Method of Multipliers.\nTheoretical analysis showed the convergence of the algorithm to the\nKarush-Kuhn-Tucker (KKT) point of the optimization problem. Numerical\nexperiments demonstrated the effectiveness of the proposed method in high-order\ntensor completion, especially for tensor data with non-smooth changes.\n","authors":["Jingjing Zheng","Wenzhe Wang","Xiaoqin Zhang","Yankai Cao","Xianta Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.13958v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13954v1","updated":"2023-11-23T12:09:49Z","published":"2023-11-23T12:09:49Z","title":"Electric Network Frequency Optical Sensing Devices","summary":"  Electric Network Frequency (ENF) acts as a fingerprint in multimedia\nforensics applications. In indoor environments, ENF variations affect the\nintensity of light sources connected to power mains. Accordingly, the light\nintensity variations captured by sensing devices can be exploited to estimate\nthe ENF. A first optical sensing device based on a photodiode is developed for\ncapturing ENF variations in indoor lighting environments. In addition, a device\nthat captures the ENF directly from power mains is implemented. This device\nserves as a ground truth ENF collector. Video recordings captured by a camera\nare also employed to estimate the ENF. The camera serves as a second optical\nsensor. The factors affecting the ENF estimation are thoroughly studied. The\nmaximum correlation coefficient between the ENF estimated by the two optical\nsensors and that estimated directly from power mains is used to measure the\nestimation accuracy. The paper's major contribution is in the disclosure of\nextensive experimental evidence on ENF estimation in scenes ranging from static\nones capturing a white wall to non-static ones, including human activity.\n","authors":["Christos Moysiadis","Georgios Karantaidis","Constantine Kotropoulos"],"pdf_url":"https://arxiv.org/pdf/2311.13954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.17389v3","updated":"2023-11-23T11:51:00Z","published":"2023-09-29T16:50:38Z","title":"Prompt-based test-time real image dehazing: a novel pipeline","summary":"  Existing methods attempt to improve models' generalization ability on\nreal-world hazy images by exploring well-designed training schemes (e.g.,\nCycleGAN, prior loss). However, most of them need very complicated training\nprocedures to achieve satisfactory results. In this work, we present a totally\nnovel testing pipeline called Prompt-based Test-Time Dehazing (PTTD) to help\ngenerate visually pleasing results of real-captured hazy images during the\ninference phase. We experimentally find that given a dehazing model trained on\nsynthetic data, by fine-tuning the statistics (i.e., mean and standard\ndeviation) of encoding features, PTTD is able to narrow the domain gap,\nboosting the performance of real image dehazing. Accordingly, we first apply a\nprompt generation module (PGM) to generate a visual prompt, which is the source\nof appropriate statistical perturbations for mean and standard deviation. And\nthen, we employ the feature adaptation module (FAM) into the existing dehazing\nmodels for adjusting the original statistics with the guidance of the generated\nprompt. Note that, PTTD is model-agnostic and can be equipped with various\nstate-of-the-art dehazing models trained on synthetic hazy-clean pairs.\nExtensive experimental results demonstrate that our PTTD is flexible meanwhile\nachieves superior performance against state-of-the-art dehazing methods in\nreal-world scenarios. The source code of our PTTD will be made available at\nhttps://github.com/cecret3350/PTTD-Dehazing.\n","authors":["Zixuan Chen","Zewei He","Ziqian Lu","Xuecheng Sun","Zhe-Ming Lu"],"pdf_url":"https://arxiv.org/pdf/2309.17389v3.pdf","comment":"update github link (https://github.com/cecret3350/PTTD-Dehazing)"},{"id":"http://arxiv.org/abs/2304.05390v2","updated":"2023-11-23T11:45:02Z","published":"2023-04-11T17:59:13Z","title":"HRS-Bench: Holistic, Reliable and Scalable Benchmark for Text-to-Image\n  Models","summary":"  In recent years, Text-to-Image (T2I) models have been extensively studied,\nespecially with the emergence of diffusion models that achieve state-of-the-art\nresults on T2I synthesis tasks. However, existing benchmarks heavily rely on\nsubjective human evaluation, limiting their ability to holistically assess the\nmodel's capabilities. Furthermore, there is a significant gap between efforts\nin developing new T2I architectures and those in evaluation. To address this,\nwe introduce HRS-Bench, a concrete evaluation benchmark for T2I models that is\nHolistic, Reliable, and Scalable. Unlike existing bench-marks that focus on\nlimited aspects, HRS-Bench measures 13 skills that can be categorized into five\nmajor categories: accuracy, robustness, generalization, fairness, and bias. In\naddition, HRS-Bench covers 50 scenarios, including fashion, animals,\ntransportation, food, and clothes. We evaluate nine recent large-scale T2I\nmodels using metrics that cover a wide range of skills. A human evaluation\naligned with 95% of our evaluations on average was conducted to probe the\neffectiveness of HRS-Bench. Our experiments demonstrate that existing models\noften struggle to generate images with the desired count of objects, visual\ntext, or grounded emotions. We hope that our benchmark help ease future\ntext-to-image generation research. The code and data are available at\nhttps://eslambakr.github.io/hrsbench.github.io\n","authors":["Eslam Mohamed Bakr","Pengzhan Sun","Xiaoqian Shen","Faizan Farooq Khan","Li Erran Li","Mohamed Elhoseiny"],"pdf_url":"https://arxiv.org/pdf/2304.05390v2.pdf","comment":"ICCV 2023"},{"id":"http://arxiv.org/abs/2311.13934v1","updated":"2023-11-23T11:34:48Z","published":"2023-11-23T11:34:48Z","title":"Robustness-Reinforced Knowledge Distillation with Correlation Distance\n  and Network Pruning","summary":"  The improvement in the performance of efficient and lightweight models (i.e.,\nthe student model) is achieved through knowledge distillation (KD), which\ninvolves transferring knowledge from more complex models (i.e., the teacher\nmodel). However, most existing KD techniques rely on Kullback-Leibler (KL)\ndivergence, which has certain limitations. First, if the teacher distribution\nhas high entropy, the KL divergence's mode-averaging nature hinders the\ntransfer of sufficient target information. Second, when the teacher\ndistribution has low entropy, the KL divergence tends to excessively focus on\nspecific modes, which fails to convey an abundant amount of valuable knowledge\nto the student. Consequently, when dealing with datasets that contain numerous\nconfounding or challenging samples, student models may struggle to acquire\nsufficient knowledge, resulting in subpar performance. Furthermore, in previous\nKD approaches, we observed that data augmentation, a technique aimed at\nenhancing a model's generalization, can have an adverse impact. Therefore, we\npropose a Robustness-Reinforced Knowledge Distillation (R2KD) that leverages\ncorrelation distance and network pruning. This approach enables KD to\neffectively incorporate data augmentation for performance improvement.\nExtensive experiments on various datasets, including CIFAR-100, FGVR,\nTinyImagenet, and ImageNet, demonstrate our method's superiority over current\nstate-of-the-art methods.\n","authors":["Seonghak Kim","Gyeongdo Ham","Yucheol Cho","Daeshik Kim"],"pdf_url":"https://arxiv.org/pdf/2311.13934v1.pdf","comment":"11 pages, 7 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2311.13930v1","updated":"2023-11-23T11:30:54Z","published":"2023-11-23T11:30:54Z","title":"Periodically Exchange Teacher-Student for Source-Free Object Detection","summary":"  Source-free object detection (SFOD) aims to adapt the source detector to\nunlabeled target domain data in the absence of source domain data. Most SFOD\nmethods follow the same self-training paradigm using mean-teacher (MT)\nframework where the student model is guided by only one single teacher model.\nHowever, such paradigm can easily fall into a training instability problem that\nwhen the teacher model collapses uncontrollably due to the domain shift, the\nstudent model also suffers drastic performance degradation. To address this\nissue, we propose the Periodically Exchange Teacher-Student (PETS) method, a\nsimple yet novel approach that introduces a multiple-teacher framework\nconsisting of a static teacher, a dynamic teacher, and a student model. During\nthe training phase, we periodically exchange the weights between the static\nteacher and the student model. Then, we update the dynamic teacher using the\nmoving average of the student model that has already been exchanged by the\nstatic teacher. In this way, the dynamic teacher can integrate knowledge from\npast periods, effectively reducing error accumulation and enabling a more\nstable training process within the MT-based framework. Further, we develop a\nconsensus mechanism to merge the predictions of two teacher models to provide\nhigher-quality pseudo labels for student model. Extensive experiments on\nmultiple SFOD benchmarks show that the proposed method achieves\nstate-of-the-art performance compared with other related methods, demonstrating\nthe effectiveness and superiority of our method on SFOD task.\n","authors":["Qipeng Liu","Luojun Lin","Zhifeng Shen","Zhifeng Yang"],"pdf_url":"https://arxiv.org/pdf/2311.13930v1.pdf","comment":"ICCV 2023"},{"id":"http://arxiv.org/abs/2311.13929v1","updated":"2023-11-23T11:30:02Z","published":"2023-11-23T11:30:02Z","title":"MetaFBP: Learning to Learn High-Order Predictor for Personalized Facial\n  Beauty Prediction","summary":"  Predicting individual aesthetic preferences holds significant practical\napplications and academic implications for human society. However, existing\nstudies mainly focus on learning and predicting the commonality of facial\nattractiveness, with little attention given to Personalized Facial Beauty\nPrediction (PFBP). PFBP aims to develop a machine that can adapt to individual\naesthetic preferences with only a few images rated by each user. In this paper,\nwe formulate this task from a meta-learning perspective that each user\ncorresponds to a meta-task. To address such PFBP task, we draw inspiration from\nthe human aesthetic mechanism that visual aesthetics in society follows a\nGaussian distribution, which motivates us to disentangle user preferences into\na commonality and an individuality part. To this end, we propose a novel\nMetaFBP framework, in which we devise a universal feature extractor to capture\nthe aesthetic commonality and then optimize to adapt the aesthetic\nindividuality by shifting the decision boundary of the predictor via a\nmeta-learning mechanism. Unlike conventional meta-learning methods that may\nstruggle with slow adaptation or overfitting to tiny support sets, we propose a\nnovel approach that optimizes a high-order predictor for fast adaptation. In\norder to validate the performance of the proposed method, we build several PFBP\nbenchmarks by using existing facial beauty prediction datasets rated by\nnumerous users. Extensive experiments on these benchmarks demonstrate the\neffectiveness of the proposed MetaFBP method.\n","authors":["Luojun Lin","Zhifeng Shen","Jia-Li Yin","Qipeng Liu","Yuanlong Yu","Weijie Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13929v1.pdf","comment":"Accepted by ACM MM 2023. Source code:\n  https://github.com/MetaVisionLab/MetaFBP"},{"id":"http://arxiv.org/abs/2311.13928v1","updated":"2023-11-23T11:29:16Z","published":"2023-11-23T11:29:16Z","title":"Parameter Exchange for Robust Dynamic Domain Generalization","summary":"  Agnostic domain shift is the main reason of model degradation on the unknown\ntarget domains, which brings an urgent need to develop Domain Generalization\n(DG). Recent advances at DG use dynamic networks to achieve training-free\nadaptation on the unknown target domains, termed Dynamic Domain Generalization\n(DDG), which compensates for the lack of self-adaptability in static models\nwith fixed weights. The parameters of dynamic networks can be decoupled into a\nstatic and a dynamic component, which are designed to learn domain-invariant\nand domain-specific features, respectively. Based on the existing arts, in this\nwork, we try to push the limits of DDG by disentangling the static and dynamic\ncomponents more thoroughly from an optimization perspective. Our main\nconsideration is that we can enable the static component to learn\ndomain-invariant features more comprehensively by augmenting the\ndomain-specific information. As a result, the more comprehensive\ndomain-invariant features learned by the static component can then enforce the\ndynamic component to focus more on learning adaptive domain-specific features.\nTo this end, we propose a simple yet effective Parameter Exchange (PE) method\nto perturb the combination between the static and dynamic components. We\noptimize the model using the gradients from both the perturbed and\nnon-perturbed feed-forward jointly to implicitly achieve the aforementioned\ndisentanglement. In this way, the two components can be optimized in a\nmutually-beneficial manner, which can resist the agnostic domain shifts and\nimprove the self-adaptability on the unknown target domain. Extensive\nexperiments show that PE can be easily plugged into existing dynamic networks\nto improve their generalization ability without bells and whistles.\n","authors":["Luojun Lin","Zhifeng Shen","Zhishu Sun","Yuanlong Yu","Lei Zhang","Weijie Chen"],"pdf_url":"https://arxiv.org/pdf/2311.13928v1.pdf","comment":"Accepted by ACM MM 2023. Source code:\n  https://github.com/MetaVisionLab/PE"},{"id":"http://arxiv.org/abs/2311.13925v1","updated":"2023-11-23T11:21:40Z","published":"2023-11-23T11:21:40Z","title":"Predicting Recovery or Decease of COVID-19 Patients with Clinical and\n  RT-PCR Using Machine Learning Classification Algorithms","summary":"  The COVID-19 pandemic has disrupted the global economy and people's daily\nlives in unprecedented ways. To make appropriate decisions, it is necessary to\ndiagnose COVID-19 rapidly and accurately. Clinical decision making is\ninfluenced by data collected from patients. With the aid of artificial\nintelligence, COVID-19 has been diagnosed quickly by analyzing symptoms,\npolymerase chain reaction (PCR), computed tomography scans, chest X-rays,\nroutine laboratory blood tests and even cough sounds. Furthermore, these data\ncan be used to predict a patient's morality, although there is a question about\nwhich data makes the most accurate predictions. Therefore, this study consists\nof two parts. Our first objective is to examine whether machine learning\nalgorithms can predict the outcome of COVID-19 cases (recovery or death), based\non the features present in the dataset. In the second part of the research, we\ninvestigated the impact of clinical and RT-PCR on prediction of recovery and\ndecease to determine which one is more reliable. We defined four stages with\ndifferent feature sets and use six machine learning methods to build prediction\nmodel. With an accuracy of 78.7%, random forest showed promising results for\npredicting death and recovery of patients. Based on this, it appears that\nrecovery and decease of patients are predictable using machine learning. For\nsecond objective, results indicate that clinical alone (without using RT-PCR),\ntrained with AdaBoost algorithm, is the most accurate with an accuracy of\n82.1%. This study can provide guidance for medical professionals in the event\nof a crisis or outbreak similar to COVID-19.\n","authors":["Mohammad Dehghani","Zahra Yazdanparast"],"pdf_url":"https://arxiv.org/pdf/2311.13925v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.06214v2","updated":"2023-11-23T11:04:39Z","published":"2023-10-10T00:07:25Z","title":"CoT3DRef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding","summary":"  3D visual grounding is the ability to localize objects in 3D scenes\nconditioned by utterances. Most existing methods devote the referring head to\nlocalize the referred object directly, causing failure in complex scenarios. In\naddition, it does not illustrate how and why the network reaches the final\ndecision. In this paper, we address this question Can we design an\ninterpretable 3D visual grounding framework that has the potential to mimic the\nhuman perception system?. To this end, we formulate the 3D visual grounding\nproblem as a sequence-to-sequence task by first predicting a chain of anchors\nand then the final target. Interpretability not only improves the overall\nperformance but also helps us identify failure cases. Following the chain of\nthoughts approach enables us to decompose the referring task into interpretable\nintermediate steps, boosting the performance and making our framework extremely\ndata-efficient. Moreover, our proposed framework can be easily integrated into\nany existing architecture. We validate our approach through comprehensive\nexperiments on the Nr3D, Sr3D, and Scanrefer benchmarks and show consistent\nperformance gains compared to existing methods without requiring manually\nannotated data. Furthermore, our proposed framework, dubbed CoT3DRef, is\nsignificantly data-efficient, whereas on the Sr3D dataset, when trained only on\n10% of the data, we match the SOTA performance that trained on the entire data.\n","authors":["Eslam Mohamed Bakr","Mohamed Ayman","Mahmoud Ahmed","Habib Slim","Mohamed Elhoseiny"],"pdf_url":"https://arxiv.org/pdf/2310.06214v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13912v1","updated":"2023-11-23T11:01:35Z","published":"2023-11-23T11:01:35Z","title":"Expanding the deep-learning model to diagnosis LVNC: Limitations and\n  trade-offs","summary":"  Hyper-trabeculation or non-compaction in the left ventricle of the myocardium\n(LVNC) is a recently classified form of cardiomyopathy. Several methods have\nbeen proposed to quantify the trabeculae accurately in the left ventricle, but\nthere is no general agreement in the medical community to use a particular\napproach. In previous work, we proposed DL-LVTQ, a deep learning approach for\nleft ventricular trabecular quantification based on a U-Net CNN architecture.\nDL-LVTQ was an automatic diagnosis tool developed from a dataset of patients\nwith the same cardiomyopathy (hypertrophic cardiomyopathy).\n  In this work, we have extended and adapted DL-LVTQ to cope with patients with\ndifferent cardiomyopathies. The dataset consists of up 379 patients in three\ngroups with different particularities and cardiomyopathies. Patient images were\ntaken from different scanners and hospitals. We have modified and adapted the\nU-Net convolutional neural network to account for the different particularities\nof a heterogeneous group of patients with various unclassifiable or mixed and\ninherited cardiomyopathies.\n  The inclusion of new groups of patients has increased the accuracy,\nspecificity and kappa values while maintaining the sensitivity of the automatic\ndeep learning method proposed. Therefore, a better-prepared diagnosis tool is\nready for various cardiomyopathies with different characteristics.\nCardiologists have considered that 98.9% of the evaluated outputs are verified\nclinically for diagnosis. Therefore, the high precision to segment the\ndifferent cardiac structures allows us to make a robust diagnostic system\nobjective and faster, decreasing human error and time spent.\n","authors":["Gregorio Bernabé","Pilar González-Férez","José M. García","Guillem Casas","Josefa González-Carrillo"],"pdf_url":"https://arxiv.org/pdf/2311.13912v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13895v1","updated":"2023-11-23T10:26:36Z","published":"2023-11-23T10:26:36Z","title":"Query by Activity Video in the Wild","summary":"  This paper focuses on activity retrieval from a video query in an imbalanced\nscenario. In current query-by-activity-video literature, a common assumption is\nthat all activities have sufficient labelled examples when learning an\nembedding. This assumption does however practically not hold, as only a portion\nof activities have many examples, while other activities are only described by\nfew examples. In this paper, we propose a visual-semantic embedding network\nthat explicitly deals with the imbalanced scenario for activity retrieval. Our\nnetwork contains two novel modules. The visual alignment module performs a\nglobal alignment between the input video and fixed-sized visual bank\nrepresentations for all activities. The semantic module performs an alignment\nbetween the input video and fixed-sized semantic activity representations. By\nmatching videos with both visual and semantic activity representations that are\nof equal size over all activities, we no longer ignore infrequent activities\nduring retrieval. Experiments on a new imbalanced activity retrieval benchmark\nshow the effectiveness of our approach for all types of activities.\n","authors":["Tao Hu","William Thong","Pascal Mettes","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2311.13895v1.pdf","comment":"An extended version of ICIP 2023"},{"id":"http://arxiv.org/abs/2204.11291v2","updated":"2023-11-23T10:16:54Z","published":"2022-04-24T14:39:47Z","title":"Large Scale Time-Series Representation Learning via Simultaneous Low and\n  High Frequency Feature Bootstrapping","summary":"  Learning representation from unlabeled time series data is a challenging\nproblem. Most existing self-supervised and unsupervised approaches in the\ntime-series domain do not capture low and high-frequency features at the same\ntime. Further, some of these methods employ large scale models like\ntransformers or rely on computationally expensive techniques such as\ncontrastive learning. To tackle these problems, we propose a non-contrastive\nself-supervised learning approach efficiently captures low and high-frequency\ntime-varying features in a cost-effective manner. Our method takes raw time\nseries data as input and creates two different augmented views for two branches\nof the model, by randomly sampling the augmentations from same family.\nFollowing the terminology of BYOL, the two branches are called online and\ntarget network which allows bootstrapping of the latent representation. In\ncontrast to BYOL, where a backbone encoder is followed by multilayer perceptron\n(MLP) heads, the proposed model contains additional temporal convolutional\nnetwork (TCN) heads. As the augmented views are passed through large kernel\nconvolution blocks of the encoder, the subsequent combination of MLP and TCN\nenables an effective representation of low as well as high-frequency\ntime-varying features due to the varying receptive fields. The two modules (MLP\nand TCN) act in a complementary manner. We train an online network where each\nmodule learns to predict the outcome of the respective module of target network\nbranch. To demonstrate the robustness of our model we performed extensive\nexperiments and ablation studies on five real-world time-series datasets. Our\nmethod achieved state-of-art performance on all five real-world datasets.\n","authors":["Vandan Gorade","Azad Singh","Deepak Mishra"],"pdf_url":"https://arxiv.org/pdf/2204.11291v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13880v1","updated":"2023-11-23T10:05:31Z","published":"2023-11-23T10:05:31Z","title":"PointPCA+: Extending PointPCA objective quality assessment metric","summary":"  A computationally-simplified and descriptor-richer Point Cloud Quality\nAssessment (PCQA) metric, namely PointPCA+, is proposed in this paper, which is\nan extension of PointPCA. PointPCA proposed a set of perceptually-relevant\ndescriptors based on PCA decomposition that were applied to both the geometry\nand texture data of point clouds for full reference PCQA. PointPCA+ employs PCA\nonly on the geometry data while enriching existing geometry and texture\ndescriptors, that are computed more efficiently. Similarly to PointPCA, a total\nquality score is obtained through a learning-based fusion of individual\npredictions from geometry and texture descriptors that capture local shape and\nappearance properties, respectively. Before feature fusion, a feature selection\nmodule is introduced to choose the most effective features from a proposed\nsuper-set. Experimental results show that PointPCA+ achieves high predictive\nperformance against subjective ground truth scores obtained from publicly\navailable datasets. The code is available at\n\\url{https://github.com/cwi-dis/pointpca_suite/}.\n","authors":["Xuemei Zhou","Evangelos Alexiou","Irene Viola","Pablo Cesar"],"pdf_url":"https://arxiv.org/pdf/2311.13880v1.pdf","comment":"ICIP 2023"},{"id":"http://arxiv.org/abs/2311.13865v1","updated":"2023-11-23T09:08:49Z","published":"2023-11-23T09:08:49Z","title":"Language-guided Few-shot Semantic Segmentation","summary":"  Few-shot learning is a promising way for reducing the label cost in new\ncategories adaptation with the guidance of a small, well labeled support set.\nBut for few-shot semantic segmentation, the pixel-level annotations of support\nimages are still expensive. In this paper, we propose an innovative solution to\ntackle the challenge of few-shot semantic segmentation using only language\ninformation, i.e.image-level text labels. Our approach involves a\nvision-language-driven mask distillation scheme, which contains a\nvision-language pretraining (VLP) model and a mask refiner, to generate high\nquality pseudo-semantic masks from text prompts. We additionally introduce a\ndistributed prototype supervision method and complementary correlation matching\nmodule to guide the model in digging precise semantic relations among support\nand query images. The experiments on two benchmark datasets demonstrate that\nour method establishes a new baseline for language-guided few-shot semantic\nsegmentation and achieves competitive results to recent vision-guided methods.\n","authors":["Jing Wang","Yuang Liu","Qiang Zhou","Fan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13865v1.pdf","comment":"Expanded version for a pending ICASSP2024 submission"},{"id":"http://arxiv.org/abs/2311.06214v2","updated":"2023-11-23T08:55:49Z","published":"2023-11-10T18:03:44Z","title":"Instant3D: Fast Text-to-3D with Sparse-View Generation and Large\n  Reconstruction Model","summary":"  Text-to-3D with diffusion models has achieved remarkable progress in recent\nyears. However, existing methods either rely on score distillation-based\noptimization which suffer from slow inference, low diversity and Janus\nproblems, or are feed-forward methods that generate low-quality results due to\nthe scarcity of 3D training data. In this paper, we propose Instant3D, a novel\nmethod that generates high-quality and diverse 3D assets from text prompts in a\nfeed-forward manner. We adopt a two-stage paradigm, which first generates a\nsparse set of four structured and consistent views from text in one shot with a\nfine-tuned 2D text-to-image diffusion model, and then directly regresses the\nNeRF from the generated images with a novel transformer-based sparse-view\nreconstructor. Through extensive experiments, we demonstrate that our method\ncan generate diverse 3D assets of high visual quality within 20 seconds, which\nis two orders of magnitude faster than previous optimization-based methods that\ncan take 1 to 10 hours. Our project webpage: https://jiahao.ai/instant3d/.\n","authors":["Jiahao Li","Hao Tan","Kai Zhang","Zexiang Xu","Fujun Luan","Yinghao Xu","Yicong Hong","Kalyan Sunkavalli","Greg Shakhnarovich","Sai Bi"],"pdf_url":"https://arxiv.org/pdf/2311.06214v2.pdf","comment":"Project webpage: https://jiahao.ai/instant3d/"},{"id":"http://arxiv.org/abs/2303.01538v2","updated":"2023-11-23T08:50:37Z","published":"2023-03-02T19:05:46Z","title":"Feature Perturbation Augmentation for Reliable Evaluation of Importance\n  Estimators in Neural Networks","summary":"  Post-hoc explanation methods attempt to make the inner workings of deep\nneural networks more interpretable. However, since a ground truth is in general\nlacking, local post-hoc interpretability methods, which assign importance\nscores to input features, are challenging to evaluate. One of the most popular\nevaluation frameworks is to perturb features deemed important by an\ninterpretability method and to measure the change in prediction accuracy.\nIntuitively, a large decrease in prediction accuracy would indicate that the\nexplanation has correctly quantified the importance of features with respect to\nthe prediction outcome (e.g., logits). However, the change in the prediction\noutcome may stem from perturbation artifacts, since perturbed samples in the\ntest dataset are out of distribution (OOD) compared to the training dataset and\ncan therefore potentially disturb the model in an unexpected manner. To\novercome this challenge, we propose feature perturbation augmentation (FPA)\nwhich creates and adds perturbed images during the model training. Through\nextensive computational experiments, we demonstrate that FPA makes deep neural\nnetworks (DNNs) more robust against perturbations. Furthermore, training DNNs\nwith FPA demonstrate that the sign of importance scores may explain the model\nmore meaningfully than has previously been assumed. Overall, FPA is an\nintuitive data augmentation technique that improves the evaluation of post-hoc\ninterpretability methods.\n","authors":["Lennart Brocki","Neo Christopher Chung"],"pdf_url":"https://arxiv.org/pdf/2303.01538v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13847v1","updated":"2023-11-23T08:31:11Z","published":"2023-11-23T08:31:11Z","title":"Perceptual Image Compression with Cooperative Cross-Modal Side\n  Information","summary":"  The explosion of data has resulted in more and more associated text being\ntransmitted along with images. Inspired by from distributed source coding, many\nworks utilize image side information to enhance image compression. However,\nexisting methods generally do not consider using text as side information to\nenhance perceptual compression of images, even though the benefits of\nmultimodal synergy have been widely demonstrated in research. This begs the\nfollowing question: How can we effectively transfer text-level semantic\ndependencies to help image compression, which is only available to the decoder?\nIn this work, we propose a novel deep image compression method with text-guided\nside information to achieve a better rate-perception-distortion tradeoff.\nSpecifically, we employ the CLIP text encoder and an effective Semantic-Spatial\nAware block to fuse the text and image features. This is done by predicting a\nsemantic mask to guide the learned text-adaptive affine transformation at the\npixel level. Furthermore, we design a text-conditional generative adversarial\nnetworks to improve the perceptual quality of reconstructed images. Extensive\nexperiments involving four datasets and ten image quality assessment metrics\ndemonstrate that the proposed approach achieves superior results in terms of\nrate-perception trade-off and semantic distortion.\n","authors":["Shiyu Qin","Bin Chen","Yujun Huang","Baoyi An","Tao Dai","Shu-Tao Via"],"pdf_url":"https://arxiv.org/pdf/2311.13847v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13846v1","updated":"2023-11-23T08:29:32Z","published":"2023-11-23T08:29:32Z","title":"Progressive Learning with Visual Prompt Tuning for Variable-Rate Image\n  Compression","summary":"  In this paper, we propose a progressive learning paradigm for\ntransformer-based variable-rate image compression. Our approach covers a wide\nrange of compression rates with the assistance of the Layer-adaptive Prompt\nModule (LPM). Inspired by visual prompt tuning, we use LPM to extract prompts\nfor input images and hidden features at the encoder side and decoder side,\nrespectively, which are fed as additional information into the Swin Transformer\nlayer of a pre-trained transformer-based image compression model to affect the\nallocation of attention region and the bits, which in turn changes the target\ncompression ratio of the model. To ensure the network is more lightweight, we\ninvolves the integration of prompt networks with less convolutional layers.\nExhaustive experiments show that compared to methods based on multiple models,\nwhich are optimized separately for different target rates, the proposed method\narrives at the same performance with 80% savings in parameter storage and 90%\nsavings in datasets. Meanwhile, our model outperforms all current variable\nbitrate image methods in terms of rate-distortion performance and approaches\nthe state-of-the-art fixed bitrate image compression methods trained from\nscratch.\n","authors":["Shiyu Qin","Yimin Zhou","Jinpeng Wang","Bin Chen","Baoyi An","Tao Dai","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2311.13846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13833v1","updated":"2023-11-23T07:33:38Z","published":"2023-11-23T07:33:38Z","title":"Lego: Learning to Disentangle and Invert Concepts Beyond Object\n  Appearance in Text-to-Image Diffusion Models","summary":"  Diffusion models have revolutionized generative content creation and\ntext-to-image (T2I) diffusion models in particular have increased the creative\nfreedom of users by allowing scene synthesis using natural language. T2I models\nexcel at synthesizing concepts such as nouns, appearances, and styles. To\nenable customized content creation based on a few example images of a concept,\nmethods such as Textual Inversion and DreamBooth invert the desired concept and\nenable synthesizing it in new scenes. However, inverting more general concepts\nthat go beyond object appearance and style (adjectives and verbs) through\nnatural language, remains a challenge. Two key characteristics of these\nconcepts contribute to the limitations of current inversion methods. 1)\nAdjectives and verbs are entangled with nouns (subject) and can hinder\nappearance-based inversion methods, where the subject appearance leaks into the\nconcept embedding and 2) describing such concepts often extends beyond single\nword embeddings (being frozen in ice, walking on a tightrope, etc.) that\ncurrent methods do not handle.\n  In this study, we introduce Lego, a textual inversion method designed to\ninvert subject entangled concepts from a few example images. Lego disentangles\nconcepts from their associated subjects using a simple yet effective Subject\nSeparation step and employs a Context Loss that guides the inversion of\nsingle/multi-embedding concepts. In a thorough user study, Lego-generated\nconcepts were preferred over 70% of the time when compared to the baseline.\nAdditionally, visual question answering using a large language model suggested\nLego-generated concepts are better aligned with the text description of the\nconcept.\n","authors":["Saman Motamed","Danda Pani Paudel","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2311.13833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.12862v2","updated":"2023-11-23T07:26:55Z","published":"2023-09-22T13:37:10Z","title":"Associative Transformer Is A Sparse Representation Learner","summary":"  Emerging from the monolithic pairwise attention mechanism in conventional\nTransformer models, there is a growing interest in leveraging sparse\ninteractions that align more closely with biological principles. Approaches\nincluding the Set Transformer and the Perceiver employ cross-attention\nconsolidated with a latent space that forms an attention bottleneck with\nlimited capacity. Building upon recent neuroscience studies of Global Workspace\nTheory and associative memory, we propose the Associative Transformer (AiT).\nAiT induces low-rank explicit memory that serves as both priors to guide\nbottleneck attention in the shared workspace and attractors within associative\nmemory of a Hopfield network. Through joint end-to-end training, these priors\nnaturally develop module specialization, each contributing a distinct inductive\nbias to form attention bottlenecks. A bottleneck can foster competition among\ninputs for writing information into the memory. We show that AiT is a sparse\nrepresentation learner, learning distinct priors through the bottlenecks that\nare complexity-invariant to input quantities and dimensions. AiT demonstrates\nits superiority over methods such as the Set Transformer, Vision Transformer,\nand Coordination in various vision tasks.\n","authors":["Yuwei Sun","Hideya Ochiai","Zhirong Wu","Stephen Lin","Ryota Kanai"],"pdf_url":"https://arxiv.org/pdf/2309.12862v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13831v1","updated":"2023-11-23T07:25:31Z","published":"2023-11-23T07:25:31Z","title":"Posterior Distillation Sampling","summary":"  We introduce Posterior Distillation Sampling (PDS), a novel optimization\nmethod for parametric image editing based on diffusion models. Existing\noptimization-based methods, which leverage the powerful 2D prior of diffusion\nmodels to handle various parametric images, have mainly focused on generation.\nUnlike generation, editing requires a balance between conforming to the target\nattribute and preserving the identity of the source content. Recent 2D image\nediting methods have achieved this balance by leveraging the stochastic latent\nencoded in the generative process of diffusion models. To extend the editing\ncapabilities of diffusion models shown in pixel space to parameter space, we\nreformulate the 2D image editing method into an optimization form named PDS.\nPDS matches the stochastic latents of the source and the target, enabling the\nsampling of targets in diverse parameter spaces that align with a desired\nattribute while maintaining the source's identity. We demonstrate that this\noptimization resembles running a generative process with the target attribute,\nbut aligning this process with the trajectory of the source's generative\nprocess. Extensive editing results in Neural Radiance Fields and Scalable\nVector Graphics representations demonstrate that PDS is capable of sampling\ntargets to fulfill the aforementioned balance across various parameter spaces.\n","authors":["Juil Koo","Chanho Park","Minhyuk Sung"],"pdf_url":"https://arxiv.org/pdf/2311.13831v1.pdf","comment":"Project page: https://posterior-distillation-sampling.github.io/"},{"id":"http://arxiv.org/abs/2311.10543v3","updated":"2023-11-23T06:10:17Z","published":"2023-11-17T14:10:55Z","title":"Joint covariance property under geometric image transformations for\n  spatio-temporal receptive fields according to the generalized Gaussian\n  derivative model for visual receptive fields","summary":"  The influence of natural image transformations on receptive field responses\nis crucial for modelling visual operations in computer vision and biological\nvision. In this regard, covariance properties with respect to geometric image\ntransformations in the earliest layers of the visual hierarchy are essential\nfor expressing robust image operations and for formulating invariant visual\noperations at higher levels. This paper defines and proves a joint covariance\nproperty under compositions of spatial scaling transformations, spatial affine\ntransformations, Galilean transformations and temporal scaling transformations,\nwhich makes it possible to characterize how different types of image\ntransformations interact with each other. Specifically, the derived relations\nshow how the receptive field parameters need to be transformed, in order to\nmatch the output from spatio-temporal receptive fields with the underlying\nspatio-temporal image transformations.\n","authors":["Tony Lindeberg"],"pdf_url":"https://arxiv.org/pdf/2311.10543v3.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2309.03493v3","updated":"2023-11-23T04:17:18Z","published":"2023-09-07T06:05:28Z","title":"SAM3D: Segment Anything Model in Volumetric Medical Images","summary":"  Image segmentation remains a pivotal component in medical image analysis,\naiding in the extraction of critical information for precise diagnostic\npractices. With the advent of deep learning, automated image segmentation\nmethods have risen to prominence, showcasing exceptional proficiency in\nprocessing medical imagery. Motivated by the Segment Anything Model (SAM)-a\nfoundational model renowned for its remarkable precision and robust\ngeneralization capabilities in segmenting 2D natural images-we introduce SAM3D,\nan innovative adaptation tailored for 3D volumetric medical image analysis.\nUnlike current SAM-based methods that segment volumetric data by converting the\nvolume into separate 2D slices for individual analysis, our SAM3D model\nprocesses the entire 3D volume image in a unified approach. Extensive\nexperiments are conducted on multiple medical image datasets to demonstrate\nthat our network attains competitive results compared with other\nstate-of-the-art methods in 3D medical segmentation tasks while being\nsignificantly efficient in terms of parameters. Code and checkpoints are\navailable at https://github.com/UARK-AICV/SAM3D.\n","authors":["Nhat-Tan Bui","Dinh-Hieu Hoang","Minh-Triet Tran","Gianfranco Doretto","Donald Adjeroh","Brijesh Patel","Arabinda Choudhary","Ngan Le"],"pdf_url":"https://arxiv.org/pdf/2309.03493v3.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2311.00996v2","updated":"2023-11-23T03:58:04Z","published":"2023-11-02T05:24:19Z","title":"VCISR: Blind Single Image Super-Resolution with Video Compression\n  Synthetic Data","summary":"  In the blind single image super-resolution (SISR) task, existing works have\nbeen successful in restoring image-level unknown degradations. However, when a\nsingle video frame becomes the input, these works usually fail to address\ndegradations caused by video compression, such as mosquito noise, ringing,\nblockiness, and staircase noise. In this work, we for the first time, present a\nvideo compression-based degradation model to synthesize low-resolution image\ndata in the blind SISR task. Our proposed image synthesizing method is widely\napplicable to existing image datasets, so that a single degraded image can\ncontain distortions caused by the lossy video compression algorithms. This\novercomes the leak of feature diversity in video data and thus retains the\ntraining efficiency. By introducing video coding artifacts to SISR degradation\nmodels, neural networks can super-resolve images with the ability to restore\nvideo compression degradations, and achieve better results on restoring generic\ndistortions caused by image compression as well. Our proposed approach achieves\nsuperior performance in SOTA no-reference Image Quality Assessment, and shows\nbetter visual quality on various datasets. In addition, we evaluate the SISR\nneural network trained with our degradation model on video super-resolution\n(VSR) datasets. Compared to architectures specifically designed for the VSR\npurpose, our method exhibits similar or better performance, evidencing that the\npresented strategy on infusing video-based degradation is generalizable to\naddress more complicated compression artifacts even without temporal cues.\n","authors":["Boyang Wang","Bowen Liu","Shiyu Liu","Fengyu Yang"],"pdf_url":"https://arxiv.org/pdf/2311.00996v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13793v1","updated":"2023-11-23T03:51:46Z","published":"2023-11-23T03:51:46Z","title":"Evidential Active Recognition: Intelligent and Prudent Open-World\n  Embodied Perception","summary":"  Active recognition enables robots to intelligently explore novel\nobservations, thereby acquiring more information while circumventing undesired\nviewing conditions. Recent approaches favor learning policies from simulated or\ncollected data, wherein appropriate actions are more frequently selected when\nthe recognition is accurate. However, most recognition modules are developed\nunder the closed-world assumption, which makes them ill-equipped to handle\nunexpected inputs, such as the absence of the target object in the current\nobservation. To address this issue, we propose treating active recognition as a\nsequential evidence-gathering process, providing by-step uncertainty\nquantification and reliable prediction under the evidence combination theory.\nAdditionally, the reward function developed in this paper effectively\ncharacterizes the merit of actions when operating in open-world environments.\nTo evaluate the performance, we collect a dataset from an indoor simulator,\nencompassing various recognition challenges such as distance, occlusion levels,\nand visibility. Through a series of experiments on recognition and robustness\nanalysis, we demonstrate the necessity of introducing uncertainties to active\nrecognition and the superior performance of the proposed method.\n","authors":["Lei Fan","Mingfu Liang","Yunxuan Li","Gang Hua","Ying Wu"],"pdf_url":"https://arxiv.org/pdf/2311.13793v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13781v1","updated":"2023-11-23T02:49:46Z","published":"2023-11-23T02:49:46Z","title":"Dynamic Compositional Graph Convolutional Network for Efficient\n  Composite Human Motion Prediction","summary":"  With potential applications in fields including intelligent surveillance and\nhuman-robot interaction, the human motion prediction task has become a hot\nresearch topic and also has achieved high success, especially using the recent\nGraph Convolutional Network (GCN). Current human motion prediction task usually\nfocuses on predicting human motions for atomic actions. Observing that atomic\nactions can happen at the same time and thus formulating the composite actions,\nwe propose the composite human motion prediction task. To handle this task, we\nfirst present a Composite Action Generation (CAG) module to generate synthetic\ncomposite actions for training, thus avoiding the laborious work of collecting\ncomposite action samples. Moreover, we alleviate the effect of composite\nactions on demand for a more complicated model by presenting a Dynamic\nCompositional Graph Convolutional Network (DC-GCN). Extensive experiments on\nthe Human3.6M dataset and our newly collected CHAMP dataset consistently verify\nthe efficiency of our DC-GCN method, which achieves state-of-the-art motion\nprediction accuracies and meanwhile needs few extra computational costs than\ntraditional GCN-based human motion methods.\n","authors":["Wanying Zhang","Shen Zhao","Fanyang Meng","Songtao Wu","Mengyuan Liu"],"pdf_url":"https://arxiv.org/pdf/2311.13781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13779v1","updated":"2023-11-23T02:36:29Z","published":"2023-11-23T02:36:29Z","title":"Detection and Identification Accuracy of PCA-Accelerated Real-Time\n  Processing of Hyperspectral Imagery","summary":"  Real-time or near real-time hyperspectral detection and identification are\nextremely useful and needed in many fields. These data sets can be quite large,\nand the algorithms can require numerous computations that slow the process\ndown. A common way of speeding up the process is to use principal component\nanalysis (PCA) for dimension reduction. In the reduced dimensional space,\nprovided by a subset of the principal components, fewer computations are needed\nto process the data resulting in a faster run time. In this paper, we propose a\nway to further decrease the time required to use PCA by investigating how many\nprincipal components may be omitted with minimal impact on the detection rate.\nUsing ACE to perform the detection, and then probability, and spectral fit for\nidentification, we find that the number of principal components can be reduced\nby a substantial amount before seeing a noticeable change in detection rates.\n","authors":["Abigail Basener","Meagan Herald"],"pdf_url":"https://arxiv.org/pdf/2311.13779v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13777v1","updated":"2023-11-23T02:35:38Z","published":"2023-11-23T02:35:38Z","title":"GS-Pose: Category-Level Object Pose Estimation via Geometric and\n  Semantic Correspondence","summary":"  Category-level pose estimation is a challenging task with many potential\napplications in computer vision and robotics. Recently, deep-learning-based\napproaches have made great progress, but are typically hindered by the need for\nlarge datasets of either pose-labelled real images or carefully tuned\nphotorealistic simulators. This can be avoided by using only geometry inputs\nsuch as depth images to reduce the domain-gap but these approaches suffer from\na lack of semantic information, which can be vital in the pose estimation\nproblem. To resolve this conflict, we propose to utilize both geometric and\nsemantic features obtained from a pre-trained foundation model.Our approach\nprojects 2D features from this foundation model into 3D for a single object\nmodel per category, and then performs matching against this for new single view\nobservations of unseen object instances with a trained matching network. This\nrequires significantly less data to train than prior methods since the semantic\nfeatures are robust to object texture and appearance. We demonstrate this with\na rich evaluation, showing improved performance over prior methods with a\nfraction of the data required.\n","authors":["Pengyuan Wang","Takuya Ikeda","Robert Lee","Koichi Nishiwaki"],"pdf_url":"https://arxiv.org/pdf/2311.13777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13752v1","updated":"2023-11-23T00:57:35Z","published":"2023-11-23T00:57:35Z","title":"3D-MIR: A Benchmark and Empirical Study on 3D Medical Image Retrieval in\n  Radiology","summary":"  The increasing use of medical imaging in healthcare settings presents a\nsignificant challenge due to the increasing workload for radiologists, yet it\nalso offers opportunity for enhancing healthcare outcomes if effectively\nleveraged. 3D image retrieval holds potential to reduce radiologist workloads\nby enabling clinicians to efficiently search through diagnostically similar or\notherwise relevant cases, resulting in faster and more precise diagnoses.\nHowever, the field of 3D medical image retrieval is still emerging, lacking\nestablished evaluation benchmarks, comprehensive datasets, and thorough\nstudies. This paper attempts to bridge this gap by introducing a novel\nbenchmark for 3D Medical Image Retrieval (3D-MIR) that encompasses four\ndifferent anatomies imaged with computed tomography. Using this benchmark, we\nexplore a diverse set of search strategies that use aggregated 2D slices, 3D\nvolumes, and multi-modal embeddings from popular multi-modal foundation models\nas queries. Quantitative and qualitative assessments of each approach are\nprovided alongside an in-depth discussion that offers insight for future\nresearch. To promote the advancement of this field, our benchmark, dataset, and\ncode are made publicly available.\n","authors":["Asma Ben Abacha","Alberto Santamaria-Pang","Ho Hin Lee","Jameson Merkow","Qin Cai","Surya Teja Devarakonda","Abdullah Islam","Julia Gong","Matthew P. Lungren","Thomas Lin","Noel C Codella","Ivan Tarapov"],"pdf_url":"https://arxiv.org/pdf/2311.13752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13750v1","updated":"2023-11-23T00:53:11Z","published":"2023-11-23T00:53:11Z","title":"Towards Transferable Multi-modal Perception Representation Learning for\n  Autonomy: NeRF-Supervised Masked AutoEncoder","summary":"  This work proposes a unified self-supervised pre-training framework for\ntransferable multi-modal perception representation learning via masked\nmulti-modal reconstruction in Neural Radiance Field (NeRF), namely\nNeRF-Supervised Masked AutoEncoder (NS-MAE). Specifically, conditioned on\ncertain view directions and locations, multi-modal embeddings extracted from\ncorrupted multi-modal input signals, i.e., Lidar point clouds and images, are\nrendered into projected multi-modal feature maps via neural rendering. Then,\noriginal multi-modal signals serve as reconstruction targets for the rendered\nmulti-modal feature maps to enable self-supervised representation learning.\nExtensive experiments show that the representation learned via NS-MAE shows\npromising transferability for diverse multi-modal and single-modal (camera-only\nand Lidar-only) perception models on diverse 3D perception downstream tasks (3D\nobject detection and BEV map segmentation) with diverse amounts of fine-tuning\nlabeled data. Moreover, we empirically find that NS-MAE enjoys the synergy of\nboth the mechanism of masked autoencoder and neural radiance field. Our code\nshall be released upon acceptance.\n","authors":["Xiaohao Xu"],"pdf_url":"https://arxiv.org/pdf/2311.13750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13552v2","updated":"2023-11-23T00:46:44Z","published":"2022-10-24T19:16:33Z","title":"Perceptual Image Enhancement for Smartphone Real-Time Applications","summary":"  Recent advances in camera designs and imaging pipelines allow us to capture\nhigh-quality images using smartphones. However, due to the small size and lens\nlimitations of the smartphone cameras, we commonly find artifacts or\ndegradation in the processed images. The most common unpleasant effects are\nnoise artifacts, diffraction artifacts, blur, and HDR overexposure. Deep\nlearning methods for image restoration can successfully remove these artifacts.\nHowever, most approaches are not suitable for real-time applications on mobile\ndevices due to their heavy computation and memory requirements. In this paper,\nwe propose LPIENet, a lightweight network for perceptual image enhancement,\nwith the focus on deploying it on smartphones. Our experiments show that, with\nmuch fewer parameters and operations, our model can deal with the mentioned\nartifacts and achieve competitive performance compared with state-of-the-art\nmethods on standard benchmarks. Moreover, to prove the efficiency and\nreliability of our approach, we deployed the model directly on commercial\nsmartphones and evaluated its performance. Our model can process 2K resolution\nimages under 1 second in mid-level commercial smartphones.\n","authors":["Marcos V. Conde","Florin Vasluianu","Javier Vazquez-Corral","Radu Timofte"],"pdf_url":"https://arxiv.org/pdf/2210.13552v2.pdf","comment":"IEEE/CVF WACV 2023 (Oral)"},{"id":"http://arxiv.org/abs/2311.13745v1","updated":"2023-11-23T00:27:13Z","published":"2023-11-23T00:27:13Z","title":"Sample-Efficient Training for Diffusion","summary":"  Score-based diffusion models have become the most popular approach to deep\ngenerative modeling of images, largely due to their empirical performance and\nreliability. Recently, a number of theoretical works \\citep{chen2022,\nChen2022ImprovedAO, Chenetal23flowode, benton2023linear} have shown that\ndiffusion models can efficiently sample, assuming $L^2$-accurate score\nestimates. The score-matching objective naturally approximates the true score\nin $L^2$, but the sample complexity of existing bounds depends\n\\emph{polynomially} on the data radius and desired Wasserstein accuracy. By\ncontrast, the time complexity of sampling is only logarithmic in these\nparameters. We show that estimating the score in $L^2$ \\emph{requires} this\npolynomial dependence, but that a number of samples that scales\npolylogarithmically in the Wasserstein accuracy actually do suffice for\nsampling. We show that with a polylogarithmic number of samples, the ERM of the\nscore-matching objective is $L^2$ accurate on all but a probability $\\delta$\nfraction of the true distribution, and that this weaker guarantee is sufficient\nfor efficient sampling.\n","authors":["Shivam Gupta","Aditya Parulekar","Eric Price","Zhiyang Xun"],"pdf_url":"https://arxiv.org/pdf/2311.13745v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2303.04689v3","updated":"2023-11-23T16:00:51Z","published":"2023-03-07T17:22:38Z","title":"A Privacy Preserving System for Movie Recommendations Using Federated\n  Learning","summary":"  Recommender systems have become ubiquitous in the past years. They solve the\ntyranny of choice problem faced by many users, and are utilized by many online\nbusinesses to drive engagement and sales. Besides other criticisms, like\ncreating filter bubbles within social networks, recommender systems are often\nreproved for collecting considerable amounts of personal data. However, to\npersonalize recommendations, personal information is fundamentally required. A\nrecent distributed learning scheme called federated learning has made it\npossible to learn from personal user data without its central collection.\nConsequently, we present a recommender system for movie recommendations, which\nprovides privacy and thus trustworthiness on multiple levels: First and\nforemost, it is trained using federated learning and thus, by its very nature,\nprivacy-preserving, while still enabling users to benefit from global insights.\nFurthermore, a novel federated learning scheme, called FedQ, is employed, which\nnot only addresses the problem of non-i.i.d.-ness and small local datasets, but\nalso prevents input data reconstruction attacks by aggregating client updates\nearly. Finally, to reduce the communication overhead, compression is applied,\nwhich significantly compresses the exchanged neural network parametrizations to\na fraction of their original size. We conjecture that this may also improve\ndata privacy through its lossy quantization stage.\n","authors":["David Neumann","Andreas Lutz","Karsten Müller","Wojciech Samek"],"pdf_url":"https://arxiv.org/pdf/2303.04689v3.pdf","comment":"Accepted for publication in the ACM Transactions on Recommender\n  Systems (TORS) Special Issue on Trustworthy Recommender Systems"},{"id":"http://arxiv.org/abs/2311.02082v3","updated":"2023-11-23T21:30:39Z","published":"2023-10-20T19:36:03Z","title":"Semantic Modelling of Organizational Knowledge as a Basis for Enterprise\n  Data Governance 4.0 -- Application to a Unified Clinical Data Model","summary":"  Individuals and organizations cope with an always-growing amount of data,\nwhich is heterogeneous in its contents and formats. An adequate data management\nprocess yielding data quality and control over its lifecycle is a prerequisite\nto getting value out of this data and minimizing inherent risks related to\nmultiple usages. Common data governance frameworks rely on people, policies,\nand processes that fall short of the overwhelming complexity of data. Yet,\nharnessing this complexity is necessary to achieve high-quality standards. The\nlatter will condition any downstream data usage outcome, including generative\nartificial intelligence trained on this data. In this paper, we report our\nconcrete experience establishing a simple, cost-efficient framework that\nenables metadata-driven, agile and (semi-)automated data governance (i.e. Data\nGovernance 4.0). We explain how we implement and use this framework to\nintegrate 25 years of clinical study data at an enterprise scale in a fully\nproductive environment. The framework encompasses both methodologies and\ntechnologies leveraging semantic web principles. We built a knowledge graph\ndescribing avatars of data assets in their business context, including\ngovernance principles. Multiple ontologies articulated by an enterprise upper\nontology enable key governance actions such as FAIRification, lifecycle\nmanagement, definition of roles and responsibilities, lineage across\ntransformations and provenance from source systems. This metadata model is the\nkeystone to data governance 4.0: a semi-automatised data management process\nthat considers the business context in an agile manner to adapt governance\nconstraints to each use case and dynamically tune it based on business changes.\n","authors":["Miguel AP Oliveira","Stephane Manara","Bruno Molé","Thomas Muller","Aurélien Guillouche","Lysann Hesske","Bruce Jordan","Gilles Hubert","Chinmay Kulkarni","Pralipta Jagdev","Cedric R. Berger"],"pdf_url":"https://arxiv.org/pdf/2311.02082v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04760v2","updated":"2023-11-23T09:12:45Z","published":"2023-11-08T15:33:06Z","title":"Towards Open-world Cross-Domain Sequential Recommendation: A\n  Model-Agnostic Contrastive Denoising Approach","summary":"  Cross-domain sequential recommendation (CDSR) aims to address the data\nsparsity problems that exist in traditional sequential recommendation (SR)\nsystems.\n  The existing approaches aim to design a specific cross-domain unit that can\ntransfer and propagate information across multiple domains by relying on\noverlapping users with abundant behaviors. However, in real-world recommender\nsystems, CDSR scenarios usually consist of a majority of long-tailed users with\nsparse behaviors and cold-start users who only exist in one domain. This leads\nto a drop in the performance of existing CDSR methods in the real-world\nindustry platform. Therefore, improving the consistency and effectiveness of\nmodels in open-world CDSR scenarios is crucial for constructing CDSR models\n(\\textit{1st} CH). Recently, some SR approaches have utilized auxiliary\nbehaviors to complement the information for long-tailed users. However, these\nmulti-behavior SR methods cannot deliver promising performance in CDSR, as they\noverlook the semantic gap between target and auxiliary behaviors, as well as\nuser interest deviation across domains (\\textit{2nd} CH).\n","authors":["Wujiang Xu","Xuying Ning","Wenfang Lin","Mingming Ha","Qiongxu Ma","Qianqiao Liang","Xuewen Tao","Linxun Chen","Bing Han","Minnan Luo"],"pdf_url":"https://arxiv.org/pdf/2311.04760v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14084v1","updated":"2023-11-23T16:22:58Z","published":"2023-11-23T16:22:58Z","title":"AI-Generated Images Introduce Invisible Relevance Bias to Text-Image\n  Retrieval","summary":"  With the advancement of generation models, AI-generated content (AIGC) is\nbecoming more realistic, flooding the Internet. A recent study suggests that\nthis phenomenon has elevated the issue of source bias in text retrieval for web\nsearches. Specifically, neural retrieval models tend to rank generated texts\nhigher than human-written texts. In this paper, we extend the study of this\nbias to cross-modal retrieval. Firstly, we successfully construct a suitable\nbenchmark to explore the existence of the bias. Subsequent extensive\nexperiments on this benchmark reveal that AI-generated images introduce an\ninvisible relevance bias to text-image retrieval models. Specifically, our\nexperiments show that text-image retrieval models tend to rank the AI-generated\nimages higher than the real images, even though the AI-generated images do not\nexhibit more visually relevant features to the query than real images. This\ninvisible relevance bias is prevalent across retrieval models with varying\ntraining data and architectures. Furthermore, our subsequent exploration\nreveals that the inclusion of AI-generated images in the training data of the\nretrieval models exacerbates the invisible relevance bias. The above phenomenon\ntriggers a vicious cycle, which makes the invisible relevance bias become more\nand more serious. To elucidate the potential causes of invisible relevance and\naddress the aforementioned issues, we introduce an effective training method\naimed at alleviating the invisible relevance bias. Subsequently, we apply our\nproposed debiasing method to retroactively identify the causes of invisible\nrelevance, revealing that the AI-generated images induce the image encoder to\nembed additional information into their representation. This information\nexhibits a certain consistency across generated images with different semantics\nand can make the retriever estimate a higher relevance score.\n","authors":["Shicheng Xu","Danyang Hou","Liang Pang","Jingcheng Deng","Jun Xu","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2311.14084v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2311.13921v1","updated":"2023-11-23T11:14:13Z","published":"2023-11-23T11:14:13Z","title":"Some Like It Small: Czech Semantic Embedding Models for Industry\n  Applications","summary":"  This article focuses on the development and evaluation of Small-sized Czech\nsentence embedding models. Small models are important components for real-time\nindustry applications in resource-constrained environments. Given the limited\navailability of labeled Czech data, alternative approaches, including\npre-training, knowledge distillation, and unsupervised contrastive fine-tuning,\nare investigated. Comprehensive intrinsic and extrinsic analyses are conducted,\nshowcasing the competitive performance of our models compared to significantly\nlarger counterparts, with approximately 8 times smaller size and 5 times faster\nspeed than conventional Base-sized models. To promote cooperation and\nreproducibility, both the models and the evaluation pipeline are made publicly\naccessible. Ultimately, this article presents practical applications of the\ndeveloped sentence embedding models in Seznam.cz, the Czech search engine.\nThese models have effectively replaced previous counterparts, enhancing the\noverall search experience for instance, in organic search, featured snippets,\nand image search. This transition has yielded improved performance.\n","authors":["Jiří Bednář","Jakub Náplava","Petra Barančíková","Ondřej Lisický"],"pdf_url":"https://arxiv.org/pdf/2311.13921v1.pdf","comment":"Accepted at the Thirty-Sixth Annual Conference on Innovative\n  Applications of Artificial Intelligence (IAAI-24). IAAI Innovative\n  Application Award. 9 pages"},{"id":"http://arxiv.org/abs/2309.05238v3","updated":"2023-11-23T05:25:59Z","published":"2023-09-11T05:12:14Z","title":"Generating Natural Language Queries for More Effective Systematic Review\n  Screening Prioritisation","summary":"  Screening prioritisation in medical systematic reviews aims to rank the set\nof documents retrieved by complex Boolean queries. Prioritising the most\nimportant documents ensures that subsequent review steps can be carried out\nmore efficiently and effectively. The current state of the art uses the final\ntitle of the review as a query to rank the documents using BERT-based neural\nrankers. However, the final title is only formulated at the end of the review\nprocess, which makes this approach impractical as it relies on ex post facto\ninformation. At the time of screening, only a rough working title is available,\nwith which the BERT-based ranker performs significantly worse than with the\nfinal title. In this paper, we explore alternative sources of queries for\nprioritising screening, such as the Boolean query used to retrieve the\ndocuments to be screened and queries generated by instruction-based generative\nlarge-scale language models such as ChatGPT and Alpaca. Our best approach is\nnot only viable based on the information available at the time of screening,\nbut also has similar effectiveness to the final title.\n","authors":["Shuai Wang","Harrisen Scells","Martin Potthast","Bevan Koopman","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2309.05238v3.pdf","comment":"Preprints for Accepted paper in SIGIR-AP-2023, note that this is\n  updated from ACM published paper. The working title was wrong in the\n  ACM-published version due to a bug in data preprocessing; however, this does\n  not have any influence on the final conclusion/observation made from the\n  paper"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2311.08228v3","updated":"2023-11-23T10:11:06Z","published":"2023-11-14T15:08:14Z","title":"Counterfactual Explanation for Regression via Disentanglement in Latent\n  Space","summary":"  Counterfactual Explanations (CEs) help address the question: How can the\nfactors that influence the prediction of a predictive model be changed to\nachieve a more favorable outcome from a user's perspective? Thus, they bear the\npotential to guide the user's interaction with AI systems since they represent\neasy-to-understand explanations. To be applicable, CEs need to be realistic and\nactionable. In the literature, various methods have been proposed to generate\nCEs. However, the majority of research on CEs focuses on classification\nproblems where questions like \"What should I do to get my rejected loan\napproved?\" are raised. In practice, answering questions like \"What should I do\nto increase my salary?\" are of a more regressive nature. In this paper, we\nintroduce a novel method to generate CEs for a pre-trained regressor by first\ndisentangling the label-relevant from the label-irrelevant dimensions in the\nlatent space. CEs are then generated by combining the label-irrelevant\ndimensions and the predefined output. The intuition behind this approach is\nthat the ideal counterfactual search should focus on the label-irrelevant\ncharacteristics of the input and suggest changes toward target-relevant\ncharacteristics. Searching in the latent space could help achieve this goal. We\nshow that our method maintains the characteristics of the query sample during\nthe counterfactual search. In various experiments, we demonstrate that the\nproposed method is competitive based on different quality measures on image and\ntabular datasets in regression problem settings. It efficiently returns results\ncloser to the original data manifold compared to three state-of-the-art\nmethods, which is essential for realistic high-dimensional machine learning\napplications. Our code will be made available as an open-source package upon\nthe publication of this work.\n","authors":["Xuan Zhao","Klaus Broelemann","Gjergji Kasneci"],"pdf_url":"https://arxiv.org/pdf/2311.08228v3.pdf","comment":"CXAI workshop @ ICDM 2023. arXiv admin note: text overlap with\n  arXiv:2307.13390"},{"id":"http://arxiv.org/abs/2311.13231v2","updated":"2023-11-23T11:56:46Z","published":"2023-11-22T08:42:46Z","title":"Using Human Feedback to Fine-tune Diffusion Models without Any Reward\n  Model","summary":"  Using reinforcement learning with human feedback (RLHF) has shown significant\npromise in fine-tuning diffusion models. Previous methods start by training a\nreward model that aligns with human preferences, then leverage RL techniques to\nfine-tune the underlying models. However, crafting an efficient reward model\ndemands extensive datasets, optimal architecture, and manual hyperparameter\ntuning, making the process both time and cost-intensive. The direct preference\noptimization (DPO) method, effective in fine-tuning large language models,\neliminates the necessity for a reward model. However, the extensive GPU memory\nrequirement of the diffusion model's denoising process hinders the direct\napplication of the DPO method. To address this issue, we introduce the Direct\nPreference for Denoising Diffusion Policy Optimization (D3PO) method to\ndirectly fine-tune diffusion models. The theoretical analysis demonstrates that\nalthough D3PO omits training a reward model, it effectively functions as the\noptimal reward model trained using human feedback data to guide the learning\nprocess. This approach requires no training of a reward model, proving to be\nmore direct, cost-effective, and minimizing computational overhead. In\nexperiments, our method uses the relative scale of objectives as a proxy for\nhuman preference, delivering comparable results to methods using ground-truth\nrewards. Moreover, D3PO demonstrates the ability to reduce image distortion\nrates and generate safer images, overcoming challenges lacking robust reward\nmodels. Our code is publicly available in\nhttps://github.com/yk7333/D3PO/tree/main.\n","authors":["Kai Yang","Jian Tao","Jiafei Lyu","Chunjiang Ge","Jiaxin Chen","Qimai Li","Weihan Shen","Xiaolong Zhu","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2311.13231v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10986v3","updated":"2023-11-23T04:44:00Z","published":"2023-11-18T06:40:39Z","title":"EdgeFM: Leveraging Foundation Model for Open-set Learning on the Edge","summary":"  Deep Learning (DL) models have been widely deployed on IoT devices with the\nhelp of advancements in DL algorithms and chips. However, the limited resources\nof edge devices make these on-device DL models hard to be generalizable to\ndiverse environments and tasks. Although the recently emerged foundation models\n(FMs) show impressive generalization power, how to effectively leverage the\nrich knowledge of FMs on resource-limited edge devices is still not explored.\nIn this paper, we propose EdgeFM, a novel edge-cloud cooperative system with\nopen-set recognition capability. EdgeFM selectively uploads unlabeled data to\nquery the FM on the cloud and customizes the specific knowledge and\narchitectures for edge models. Meanwhile, EdgeFM conducts dynamic model\nswitching at run-time taking into account both data uncertainty and dynamic\nnetwork variations, which ensures the accuracy always close to the original FM.\nWe implement EdgeFM using two FMs on two edge platforms. We evaluate EdgeFM on\nthree public datasets and two self-collected datasets. Results show that EdgeFM\ncan reduce the end-to-end latency up to 3.2x and achieve 34.3% accuracy\nincrease compared with the baseline.\n","authors":["Bufang Yang","Lixing He","Neiwen Ling","Zhenyu Yan","Guoliang Xing","Xian Shuai","Xiaozhe Ren","Xin Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.10986v3.pdf","comment":"Accepted to the 21th ACM Conference on Embedded Networked Sensor\n  Systems (SenSys 2023)"},{"id":"http://arxiv.org/abs/2305.16854v4","updated":"2023-11-23T05:25:19Z","published":"2023-05-26T12:04:59Z","title":"Channel and Gradient-Importance Aware Device Scheduling for Over-the-Air\n  Federated Learning","summary":"  Federated learning (FL) is a popular privacy-preserving distributed training\nscheme, where multiple devices collaborate to train machine learning models by\nuploading local model updates. To improve communication efficiency,\nover-the-air computation (AirComp) has been applied to FL, which leverages\nanalog modulation to harness the superposition property of radio waves such\nthat numerous devices can upload their model updates concurrently for\naggregation. However, the uplink channel noise incurs considerable model\naggregation distortion, which is critically determined by the device scheduling\nand compromises the learned model performance. In this paper, we propose a\nprobabilistic device scheduling framework for over-the-air FL, named PO-FL, to\nmitigate the negative impact of channel noise, where each device is scheduled\naccording to a certain probability and its model update is reweighted using\nthis probability in aggregation. We prove the unbiasedness of this aggregation\nscheme and demonstrate the convergence of PO-FL on both convex and non-convex\nloss functions. Our convergence bounds unveil that the device scheduling\naffects the learning performance through the communication distortion and\nglobal update variance. Based on the convergence analysis, we further develop a\nchannel and gradient-importance aware algorithm to optimize the device\nscheduling probabilities in PO-FL. Extensive simulation results show that the\nproposed PO-FL framework with channel and gradient-importance awareness\nachieves faster convergence and produces better models than baseline methods.\n","authors":["Yuchang Sun","Zehong lin","Yuyi Mao","Shi Jin","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.16854v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12716v2","updated":"2023-11-23T19:12:07Z","published":"2023-11-21T16:43:13Z","title":"minimax: Efficient Baselines for Autocurricula in JAX","summary":"  Unsupervised environment design (UED) is a form of automatic curriculum\nlearning for training robust decision-making agents to zero-shot transfer into\nunseen environments. Such autocurricula have received much interest from the RL\ncommunity. However, UED experiments, based on CPU rollouts and GPU model\nupdates, have often required several weeks of training. This compute\nrequirement is a major obstacle to rapid innovation for the field. This work\nintroduces the minimax library for UED training on accelerated hardware. Using\nJAX to implement fully-tensorized environments and autocurriculum algorithms,\nminimax allows the entire training loop to be compiled for hardware\nacceleration. To provide a petri dish for rapid experimentation, minimax\nincludes a tensorized grid-world based on MiniGrid, in addition to reusable\nabstractions for conducting autocurricula in procedurally-generated\nenvironments. With these components, minimax provides strong UED baselines,\nincluding new parallelized variants, which achieve over 120$\\times$ speedups in\nwall time compared to previous implementations when training with equal batch\nsizes. The minimax library is available under the Apache 2.0 license at\nhttps://github.com/facebookresearch/minimax.\n","authors":["Minqi Jiang","Michael Dennis","Edward Grefenstette","Tim Rocktäschel"],"pdf_url":"https://arxiv.org/pdf/2311.12716v2.pdf","comment":"Presented at ALOE 2023"},{"id":"http://arxiv.org/abs/2311.14227v1","updated":"2023-11-23T23:40:01Z","published":"2023-11-23T23:40:01Z","title":"Robust and Interpretable COVID-19 Diagnosis on Chest X-ray Images using\n  Adversarial Training","summary":"  The novel 2019 Coronavirus disease (COVID-19) global pandemic is a defining\nhealth crisis. Recent efforts have been increasingly directed towards achieving\nquick and accurate detection of COVID-19 across symptomatic patients to\nmitigate the intensity and spread of the disease. Artificial intelligence (AI)\nalgorithms applied to chest X-ray (CXR) images have emerged as promising\ndiagnostic tools, and previous work has demonstrated impressive classification\nperformances. However, such methods have faced criticisms from physicians due\nto their black-box reasoning process and unpredictable nature. In contrast to\nprofessional radiologist diagnosis, AI systems often lack generalizability,\nexplainability, and robustness in the clinical decision making process. In our\nwork, we address these issues by first proposing an extensive baseline study,\ntraining and evaluating 21 convolutional neural network (CNN) models on a\ndiverse set of 33,000+ CXR images to classify between healthy, COVID-19, and\nnon-COVID-19 pneumonia CXRs. Our resulting models achieved a 3-way\nclassification accuracy, recall, and precision of up to 97.03\\%, 97.97\\%, and\n99.95\\%, respectively. Next, we investigate the effectiveness of adversarial\ntraining on model robustness and explainability via Gradient-weighted Class\nActivation Mapping (Grad-CAM) heatmaps. We find that adversarially trained\nmodels not only significantly outperform their standard counterparts on\nclassifying perturbed images, but also yield saliency maps that 1) better\nspecify clinically relevant features, 2) are robust against extraneous\nartifacts, and 3) agree considerably more with expert radiologist findings.\n","authors":["Karina Yang","Alexis Bennett","Dominique Duncan"],"pdf_url":"https://arxiv.org/pdf/2311.14227v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.09043v2","updated":"2023-11-23T23:39:55Z","published":"2023-08-17T15:24:03Z","title":"Kernel-Based Tests for Likelihood-Free Hypothesis Testing","summary":"  Given $n$ observations from two balanced classes, consider the task of\nlabeling an additional $m$ inputs that are known to all belong to \\emph{one} of\nthe two classes. Special cases of this problem are well-known: with complete\nknowledge of class distributions ($n=\\infty$) the problem is solved optimally\nby the likelihood-ratio test; when $m=1$ it corresponds to binary\nclassification; and when $m\\approx n$ it is equivalent to two-sample testing.\nThe intermediate settings occur in the field of likelihood-free inference,\nwhere labeled samples are obtained by running forward simulations and the\nunlabeled sample is collected experimentally. In recent work it was discovered\nthat there is a fundamental trade-off between $m$ and $n$: increasing the data\nsample $m$ reduces the amount $n$ of training/simulation data needed. In this\nwork we (a) introduce a generalization where unlabeled samples come from a\nmixture of the two classes -- a case often encountered in practice; (b) study\nthe minimax sample complexity for non-parametric classes of densities under\n\\textit{maximum mean discrepancy} (MMD) separation; and (c) investigate the\nempirical performance of kernels parameterized by neural networks on two tasks:\ndetection of the Higgs boson and detection of planted DDPM generated images\namidst CIFAR-10 images. For both problems we confirm the existence of the\ntheoretically predicted asymmetric $m$ vs $n$ trade-off.\n","authors":["Patrik Róbert Gerber","Tianze Jiang","Yury Polyanskiy","Rui Sun"],"pdf_url":"https://arxiv.org/pdf/2308.09043v2.pdf","comment":"36 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.14222v1","updated":"2023-11-23T23:02:10Z","published":"2023-11-23T23:02:10Z","title":"Risk Bounds of Accelerated SGD for Overparameterized Linear Regression","summary":"  Accelerated stochastic gradient descent (ASGD) is a workhorse in deep\nlearning and often achieves better generalization performance than SGD.\nHowever, existing optimization theory can only explain the faster convergence\nof ASGD, but cannot explain its better generalization. In this paper, we study\nthe generalization of ASGD for overparameterized linear regression, which is\npossibly the simplest setting of learning with overparameterization. We\nestablish an instance-dependent excess risk bound for ASGD within each\neigen-subspace of the data covariance matrix. Our analysis shows that (i) ASGD\noutperforms SGD in the subspace of small eigenvalues, exhibiting a faster rate\nof exponential decay for bias error, while in the subspace of large\neigenvalues, its bias error decays slower than SGD; and (ii) the variance error\nof ASGD is always larger than that of SGD. Our result suggests that ASGD can\noutperform SGD when the difference between the initialization and the true\nweight vector is mostly confined to the subspace of small eigenvalues.\nAdditionally, when our analysis is specialized to linear regression in the\nstrongly convex setting, it yields a tighter bound for bias error than the\nbest-known result.\n","authors":["Xuheng Li","Yihe Deng","Jingfeng Wu","Dongruo Zhou","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2311.14222v1.pdf","comment":"85 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.14220v1","updated":"2023-11-23T22:41:30Z","published":"2023-11-23T22:41:30Z","title":"Assumption-lean and Data-adaptive Post-Prediction Inference","summary":"  A primary challenge facing modern scientific research is the limited\navailability of gold-standard data which can be both costly and labor-intensive\nto obtain. With the rapid development of machine learning (ML), scientists have\nrelied on ML algorithms to predict these gold-standard outcomes with easily\nobtained covariates. However, these predicted outcomes are often used directly\nin subsequent statistical analyses, ignoring imprecision and heterogeneity\nintroduced by the prediction procedure. This will likely result in false\npositive findings and invalid scientific conclusions. In this work, we\nintroduce an assumption-lean and data-adaptive Post-Prediction Inference\n(POP-Inf) procedure that allows valid and powerful inference based on\nML-predicted outcomes. Its \"assumption-lean\" property guarantees reliable\nstatistical inference without assumptions on the ML-prediction, for a wide\nrange of statistical quantities. Its \"data-adaptive'\" feature guarantees an\nefficiency gain over existing post-prediction inference methods, regardless of\nthe accuracy of ML-prediction. We demonstrate the superiority and applicability\nof our method through simulations and large-scale genomic data.\n","authors":["Jiacheng Miao","Xinran Miao","Yixuan Wu","Jiwei Zhao","Qiongshi Lu"],"pdf_url":"https://arxiv.org/pdf/2311.14220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.05954v4","updated":"2023-11-23T22:11:49Z","published":"2022-09-09T23:18:31Z","title":"Automatically Score Tissue Images Like a Pathologist by Transfer\n  Learning","summary":"  Cancer is the second leading cause of death in the world. Diagnosing cancer\nearly on can save many lives. Pathologists have to look at tissue microarray\n(TMA) images manually to identify tumors, which can be time-consuming,\ninconsistent and subjective. Existing automatic algorithms either have not\nachieved the accuracy level of a pathologist or require substantial human\ninvolvements. A major challenge is that TMA images with different shapes,\nsizes, and locations can have the same score. Learning staining patterns in TMA\nimages requires a huge number of images, which are severely limited due to\nprivacy and regulation concerns in medical organizations. TMA images from\ndifferent cancer types may share certain common characteristics, but combining\nthem directly harms the accuracy due to heterogeneity in their staining\npatterns. Transfer learning is an emerging learning paradigm that allows\nborrowing strength from similar problems. However, existing approaches\ntypically require a large sample from similar learning problems, while TMA\nimages of different cancer types are often available in small sample size and\nfurther existing algorithms are limited to transfer learning from one similar\nproblem. We propose a new transfer learning algorithm that could learn from\nmultiple related problems, where each problem has a small sample and can have a\nsubstantially different distribution from the original one. The proposed\nalgorithm has made it possible to break the critical accuracy barrier (the 75%\naccuracy level of pathologists), with a reported accuracy of 75.9% on breast\ncancer TMA images from the Stanford Tissue Microarray Database. It is supported\nby recent developments in transfer learning theory and empirical evidence in\nclustering technology. This will allow pathologists to confidently adopt\nautomatic algorithms in recognizing tumors consistently with a higher accuracy\nin real time.\n","authors":["Iris Yan"],"pdf_url":"https://arxiv.org/pdf/2209.05954v4.pdf","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.14214v1","updated":"2023-11-23T22:08:29Z","published":"2023-11-23T22:08:29Z","title":"Extending Variability-Aware Model Selection with Bias Detection in\n  Machine Learning Projects","summary":"  Data science projects often involve various machine learning (ML) methods\nthat depend on data, code, and models. One of the key activities in these\nprojects is the selection of a model or algorithm that is appropriate for the\ndata analysis at hand. ML model selection depends on several factors, which\ninclude data-related attributes such as sample size, functional requirements\nsuch as the prediction algorithm type, and non-functional requirements such as\nperformance and bias. However, the factors that influence such selection are\noften not well understood and explicitly represented. This paper describes\nongoing work on extending an adaptive variability-aware model selection method\nwith bias detection in ML projects. The method involves: (i) modeling the\nvariability of the factors that affect model selection using feature models\nbased on heuristics proposed in the literature; (ii) instantiating our\nvariability model with added features related to bias (e.g., bias-related\nmetrics); and (iii) conducting experiments that illustrate the method in a\nspecific case study to illustrate our approach based on a heart failure\nprediction project. The proposed approach aims to advance the state of the art\nby making explicit factors that influence model selection, particularly those\nrelated to bias, as well as their interactions. The provided representations\ncan transform model selection in ML projects into a non ad hoc, adaptive, and\nexplainable process.\n","authors":["Cristina Tavares","Nathalia Nascimento","Paulo Alencar","Donald Cowan"],"pdf_url":"https://arxiv.org/pdf/2311.14214v1.pdf","comment":"IEEE BigData 2023"},{"id":"http://arxiv.org/abs/2311.14212v1","updated":"2023-11-23T21:54:22Z","published":"2023-11-23T21:54:22Z","title":"Annotation Sensitivity: Training Data Collection Methods Affect Model\n  Performance","summary":"  When training data are collected from human annotators, the design of the\nannotation instrument, the instructions given to annotators, the\ncharacteristics of the annotators, and their interactions can impact training\ndata. This study demonstrates that design choices made when creating an\nannotation instrument also impact the models trained on the resulting\nannotations.\n  We introduce the term annotation sensitivity to refer to the impact of\nannotation data collection methods on the annotations themselves and on\ndownstream model performance and predictions.\n  We collect annotations of hate speech and offensive language in five\nexperimental conditions of an annotation instrument, randomly assigning\nannotators to conditions. We then fine-tune BERT models on each of the five\nresulting datasets and evaluate model performance on a holdout portion of each\ncondition. We find considerable differences between the conditions for 1) the\nshare of hate speech/offensive language annotations, 2) model performance, 3)\nmodel predictions, and 4) model learning curves.\n  Our results emphasize the crucial role played by the annotation instrument\nwhich has received little attention in the machine learning literature. We call\nfor additional research into how and why the instrument impacts the annotations\nto inform the development of best practices in instrument design.\n","authors":["Christoph Kern","Stephanie Eckman","Jacob Beck","Rob Chew","Bolei Ma","Frauke Kreuter"],"pdf_url":"https://arxiv.org/pdf/2311.14212v1.pdf","comment":"EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2306.15030v2","updated":"2023-11-23T21:53:19Z","published":"2023-06-26T19:40:10Z","title":"Equivariant flow matching","summary":"  Normalizing flows are a class of deep generative models that are especially\ninteresting for modeling probability distributions in physics, where the exact\nlikelihood of flows allows reweighting to known target energy functions and\ncomputing unbiased observables. For instance, Boltzmann generators tackle the\nlong-standing sampling problem in statistical physics by training flows to\nproduce equilibrium samples of many-body systems such as small molecules and\nproteins. To build effective models for such systems, it is crucial to\nincorporate the symmetries of the target energy into the model, which can be\nachieved by equivariant continuous normalizing flows (CNFs). However, CNFs can\nbe computationally expensive to train and generate samples from, which has\nhampered their scalability and practical application. In this paper, we\nintroduce equivariant flow matching, a new training objective for equivariant\nCNFs that is based on the recently proposed optimal transport flow matching.\nEquivariant flow matching exploits the physical symmetries of the target energy\nfor efficient, simulation-free training of equivariant CNFs. We demonstrate the\neffectiveness of flow matching on rotation and permutation invariant\nmany-particle systems and a small molecule, alanine dipeptide, where for the\nfirst time we obtain a Boltzmann generator with significant sampling efficiency\nwithout relying on tailored internal coordinate featurization. Our results show\nthat the equivariant flow matching objective yields flows with shorter\nintegration paths, improved sampling efficiency, and higher scalability\ncompared to existing methods.\n","authors":["Leon Klein","Andreas Krämer","Frank Noé"],"pdf_url":"https://arxiv.org/pdf/2306.15030v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.05784v2","updated":"2023-11-23T20:45:53Z","published":"2023-11-09T23:25:29Z","title":"Are \"Hierarchical\" Visual Representations Hierarchical?","summary":"  Learned visual representations often capture large amounts of semantic\ninformation for accurate downstream applications. Human understanding of the\nworld is fundamentally grounded in hierarchy. To mimic this and further improve\nrepresentation capabilities, the community has explored \"hierarchical\" visual\nrepresentations that aim at modeling the underlying hierarchy of the visual\nworld. In this work, we set out to investigate if hierarchical visual\nrepresentations truly capture the human perceived hierarchy better than\nstandard learned representations. To this end, we create HierNet, a suite of 12\ndatasets spanning 3 kinds of hierarchy from the BREEDs subset of ImageNet.\nAfter extensive evaluation of Hyperbolic and Matryoshka Representations across\ntraining setups, we conclude that they do not capture hierarchy any better than\nthe standard representations but can assist in other aspects like search\nefficiency and interpretability. Our benchmark and the datasets are\nopen-sourced at https://github.com/ethanlshen/HierNet.\n","authors":["Ethan Shen","Ali Farhadi","Aditya Kusupati"],"pdf_url":"https://arxiv.org/pdf/2311.05784v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14197v1","updated":"2023-11-23T20:41:46Z","published":"2023-11-23T20:41:46Z","title":"Enhancing mTBI Diagnosis with Residual Triplet Convolutional Neural\n  Network Using 3D CT","summary":"  Mild Traumatic Brain Injury (mTBI) is a common and challenging condition to\ndiagnose accurately. Timely and precise diagnosis is essential for effective\ntreatment and improved patient outcomes. Traditional diagnostic methods for\nmTBI often have limitations in terms of accuracy and sensitivity. In this\nstudy, we introduce an innovative approach to enhance mTBI diagnosis using 3D\nComputed Tomography (CT) images and a metric learning technique trained with\ntriplet loss. To address these challenges, we propose a Residual Triplet\nConvolutional Neural Network (RTCNN) model to distinguish between mTBI cases\nand healthy ones by embedding 3D CT scans into a feature space. The triplet\nloss function maximizes the margin between similar and dissimilar image pairs,\noptimizing feature representations. This facilitates better context placement\nof individual cases, aids informed decision-making, and has the potential to\nimprove patient outcomes. Our RTCNN model shows promising performance in mTBI\ndiagnosis, achieving an average accuracy of 94.3%, a sensitivity of 94.1%, and\na specificity of 95.2%, as confirmed through a five-fold cross-validation.\nImportantly, when compared to the conventional Residual Convolutional Neural\nNetwork (RCNN) model, the RTCNN exhibits a significant improvement, showcasing\na remarkable 22.5% increase in specificity, a notable 16.2% boost in accuracy,\nand an 11.3% enhancement in sensitivity. Moreover, RTCNN requires lower memory\nresources, making it not only highly effective but also resource-efficient in\nminimizing false positives while maximizing its diagnostic accuracy in\ndistinguishing normal CT scans from mTBI cases. The quantitative performance\nmetrics provided and utilization of occlusion sensitivity maps to visually\nexplain the model's decision-making process further enhance the\ninterpretability and transparency of our approach.\n","authors":["Hanem Ellethy","Shekhar S. Chandra","Viktor Vegh"],"pdf_url":"https://arxiv.org/pdf/2311.14197v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14195v1","updated":"2023-11-23T20:31:48Z","published":"2023-11-23T20:31:48Z","title":"Touch Analysis: An Empirical Evaluation of Machine Learning\n  Classification Algorithms on Touch Data","summary":"  Our research aims at classifying individuals based on their unique\ninteractions on touchscreen-based smartphones. In this research, we use\nTouch-Analytics datasets, which include 41 subjects and 30 different behavioral\nfeatures. Furthermore, we derived new features from the raw data to improve the\noverall authentication performance. Previous research has already been done on\nthe Touch-Analytics datasets with the state-of-the-art classifiers, including\nSupport Vector Machine (SVM) and k-nearest neighbor (kNN), and achieved equal\nerror rates (EERs) between 0% to 4%. Here, we propose a novel Deep Neural Net\n(DNN) architecture to classify the individuals correctly. The proposed DNN\narchitecture has three dense layers and uses many-to-many mapping techniques.\nWhen we combine the new features with the existing ones, SVM and kNN achieved\nthe classification accuracy of 94.7% and 94.6%, respectively. This research\nexplored seven other classifiers and out of them, the decision tree and our\nproposed DNN classifiers resulted in the highest accuracy of 100%. The others\nincluded: Logistic Regression (LR), Linear Discriminant Analysis (LDA),\nGaussian Naive Bayes (NB), Neural Network, and VGGNet with the following\naccuracy scores of 94.7%, 95.9%, 31.9%, 88.8%, and 96.1%, respectively.\n","authors":["Melodee Montgomery","Prosenjit Chatterjee","John Jenkins","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2311.14195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14182v1","updated":"2023-11-23T20:03:51Z","published":"2023-11-23T20:03:51Z","title":"Gradient-based bilevel optimization for multi-penalty Ridge regression\n  through matrix differential calculus","summary":"  Common regularization algorithms for linear regression, such as LASSO and\nRidge regression, rely on a regularization hyperparameter that balances the\ntradeoff between minimizing the fitting error and the norm of the learned model\ncoefficients. As this hyperparameter is scalar, it can be easily selected via\nrandom or grid search optimizing a cross-validation criterion. However, using a\nscalar hyperparameter limits the algorithm's flexibility and potential for\nbetter generalization. In this paper, we address the problem of linear\nregression with l2-regularization, where a different regularization\nhyperparameter is associated with each input variable. We optimize these\nhyperparameters using a gradient-based approach, wherein the gradient of a\ncross-validation criterion with respect to the regularization hyperparameters\nis computed analytically through matrix differential calculus. Additionally, we\nintroduce two strategies tailored for sparse model learning problems aiming at\nreducing the risk of overfitting to the validation data. Numerical examples\ndemonstrate that our multi-hyperparameter regularization approach outperforms\nLASSO, Ridge, and Elastic Net regression. Moreover, the analytical computation\nof the gradient proves to be more efficient in terms of computational time\ncompared to automatic differentiation, especially when handling a large number\nof input variables. Application to the identification of over-parameterized\nLinear Parameter-Varying models is also presented.\n","authors":["Gabriele Maroni","Loris Cannelli","Dario Piga"],"pdf_url":"https://arxiv.org/pdf/2311.14182v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.14156v2","updated":"2023-11-23T19:50:21Z","published":"2023-09-25T14:08:21Z","title":"Designing and evaluating an online reinforcement learning agent for\n  physical exercise recommendations in N-of-1 trials","summary":"  Personalized adaptive interventions offer the opportunity to increase patient\nbenefits, however, there are challenges in their planning and implementation.\nOnce implemented, it is an important question whether personalized adaptive\ninterventions are indeed clinically more effective compared to a fixed gold\nstandard intervention. In this paper, we present an innovative N-of-1 trial\nstudy design testing whether implementing a personalized intervention by an\nonline reinforcement learning agent is feasible and effective. Throughout, we\nuse a new study on physical exercise recommendations to reduce pain in\nendometriosis for illustration. We describe the design of a contextual bandit\nrecommendation agent and evaluate the agent in simulation studies. The results\nshow that, first, implementing a personalized intervention by an online\nreinforcement learning agent is feasible. Second, such adaptive interventions\nhave the potential to improve patients' benefits even if only few observations\nare available. As one challenge, they add complexity to the design and\nimplementation process. In order to quantify the expected benefit, data from\nprevious interventional studies is required. We expect our approach to be\ntransferable to other interventions and clinical interventions.\n","authors":["Dominik Meier","Ipek Ensari","Stefan Konigorski"],"pdf_url":"https://arxiv.org/pdf/2309.14156v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14177v1","updated":"2023-11-23T19:49:59Z","published":"2023-11-23T19:49:59Z","title":"TCuPGAN: A novel framework developed for optimizing human-machine\n  interactions in citizen science","summary":"  In the era of big data in scientific research, there is a necessity to\nleverage techniques which reduce human effort in labeling and categorizing\nlarge datasets by involving sophisticated machine tools. To combat this\nproblem, we present a novel, general purpose model for 3D segmentation that\nleverages patch-wise adversariality and Long Short-Term Memory to encode\nsequential information. Using this model alongside citizen science projects\nwhich use 3D datasets (image cubes) on the Zooniverse platforms, we propose an\niterative human-machine optimization framework where only a fraction of the 2D\nslices from these cubes are seen by the volunteers. We leverage the patch-wise\ndiscriminator in our model to provide an estimate of which slices within these\nimage cubes have poorly generalized feature representations, and\ncorrespondingly poor machine performance. These images with corresponding\nmachine proposals would be presented to volunteers on Zooniverse for\ncorrection, leading to a drastic reduction in the volunteer effort on citizen\nscience projects. We trained our model on ~2300 liver tissue 3D electron\nmicrographs. Lipid droplets were segmented within these images through human\nannotation via the `Etch A Cell - Fat Checker' citizen science project, hosted\non the Zooniverse platform. In this work, we demonstrate this framework and the\nselection methodology which resulted in a measured reduction in volunteer\neffort by more than 60%. We envision this type of joint human-machine\npartnership will be of great use on future Zooniverse projects.\n","authors":["Ramanakumar Sankar","Kameswara Mantha","Lucy Fortson","Helen Spiers","Thomas Pengo","Douglas Mashek","Myat Mo","Mark Sanders","Trace Christensen","Jeffrey Salisbury","Laura Trouille"],"pdf_url":"https://arxiv.org/pdf/2311.14177v1.pdf","comment":"5 pages, 1 figure, accepted for publication at HLDM '23 (ECML PKDD\n  2023 workshop)"},{"id":"http://arxiv.org/abs/2311.00860v2","updated":"2023-11-23T19:41:41Z","published":"2023-11-01T21:28:24Z","title":"Zero Coordinate Shift: Whetted Automatic Differentiation for\n  Physics-informed Operator Learning","summary":"  Automatic differentiation (AD) is a critical step in physics-informed machine\nlearning, required for computing the high-order derivatives of network output\nw.r.t. coordinates of collocation points. In this paper, we present a novel and\nlightweight algorithm to conduct AD for physics-informed operator learning,\nwhich we call the trick of Zero Coordinate Shift (ZCS). Instead of making all\nsampled coordinates as leaf variables, ZCS introduces only one scalar-valued\nleaf variable for each spatial or temporal dimension, simplifying the wanted\nderivatives from \"many-roots-many-leaves\" to \"one-root-many-leaves\" whereby\nreverse-mode AD becomes directly utilisable. It has led to an outstanding\nperformance leap by avoiding the duplication of the computational graph along\nthe dimension of functions (physical parameters). ZCS is easy to implement with\ncurrent deep learning libraries; our own implementation is achieved by\nextending the DeepXDE package. We carry out a comprehensive benchmark analysis\nand several case studies, training physics-informed DeepONets to solve partial\ndifferential equations (PDEs) without data. The results show that ZCS has\npersistently reduced GPU memory consumption and wall time for training by an\norder of magnitude, and such reduction factor scales with the number of\nfunctions. As a low-level optimisation technique, ZCS imposes no restrictions\non data, physics (PDE) or network architecture and does not compromise training\nresults from any aspect.\n","authors":["Kuangdai Leng","Mallikarjun Shankar","Jeyan Thiyagalingam"],"pdf_url":"https://arxiv.org/pdf/2311.00860v2.pdf","comment":"19 pages; this minor revision gives clearer explanation on the reason\n  of performance boost by ZCS"},{"id":"http://arxiv.org/abs/2311.14169v1","updated":"2023-11-23T19:20:59Z","published":"2023-11-23T19:20:59Z","title":"Evaluating GPT-4's Vision Capabilities on Brazilian University Admission\n  Exams","summary":"  Recent advancements in language models have showcased human-comparable\nperformance in academic entrance exams. However, existing studies often\noverlook questions that require the integration of visual comprehension, thus\ncompromising the full spectrum and complexity inherent in real-world scenarios.\nTo address this gap, we present a comprehensive framework to evaluate language\nmodels on entrance exams, which incorporates both textual and visual elements.\nWe evaluate the two most recent editions of Exame Nacional do Ensino M\\'edio\n(ENEM), the main standardized entrance examination adopted by Brazilian\nuniversities. Our study not only reaffirms the capabilities of GPT-4 as the\nstate of the art for handling complex multidisciplinary questions, but also\npioneers in offering a realistic assessment of multimodal language models on\nPortuguese examinations. One of the highlights is that text captions\ntranscribing visual content outperform the direct use of images, suggesting\nthat the vision model has room for improvement. Yet, despite improvements\nafforded by images or captions, mathematical questions remain a challenge for\nthese state-of-the-art models. The code and data used on experiments are\navailable at https://github.com/piresramon/gpt-4-enem.\n","authors":["Ramon Pires","Thales Sales Almeida","Hugo Abonizio","Rodrigo Nogueira"],"pdf_url":"https://arxiv.org/pdf/2311.14169v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2303.17003"},{"id":"http://arxiv.org/abs/2311.14168v1","updated":"2023-11-23T19:08:39Z","published":"2023-11-23T19:08:39Z","title":"Fast Policy Learning for Linear Quadratic Regulator with Entropy\n  Regularization","summary":"  This paper proposes and analyzes two new policy learning methods: regularized\npolicy gradient (RPG) and iterative policy optimization (IPO), for a class of\ndiscounted linear-quadratic regulator (LQR) problems over an infinite time\nhorizon with entropy regularization. Assuming access to the exact policy\nevaluation, both proposed approaches are proved to converge linearly in finding\noptimal policies of the regularized LQR. Moreover, the IPO method can achieve a\nsuper-linear convergence rate once it enters a local region around the optimal\npolicy. Finally, when the optimal policy from a well-understood environment in\nan RL problem is appropriately transferred as the initial policy to an RL\nproblem with an unknown environment, the IPO method is shown to enable a\nsuper-linear convergence rate if the latter is sufficiently close to the\nformer. The performances of these proposed algorithms are supported by\nnumerical examples.\n","authors":["Xin Guo","Xinyu Li","Renyuan Xu"],"pdf_url":"https://arxiv.org/pdf/2311.14168v1.pdf","comment":"33 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.14160v1","updated":"2023-11-23T19:00:02Z","published":"2023-11-23T19:00:02Z","title":"Efficient and Robust Jet Tagging at the LHC with Knowledge Distillation","summary":"  The challenging environment of real-time data processing systems at the Large\nHadron Collider (LHC) strictly limits the computational complexity of\nalgorithms that can be deployed. For deep learning models, this implies that\nonly models with low computational complexity that have weak inductive bias are\nfeasible. To address this issue, we utilize knowledge distillation to leverage\nboth the performance of large models and the reduced computational complexity\nof small ones. In this paper, we present an implementation of knowledge\ndistillation, demonstrating an overall boost in the student models' performance\nfor the task of classifying jets at the LHC. Furthermore, by using a teacher\nmodel with a strong inductive bias of Lorentz symmetry, we show that we can\ninduce the same inductive bias in the student model which leads to better\nrobustness against arbitrary Lorentz boost.\n","authors":["Ryan Liu","Abhijith Gandrakota","Jennifer Ngadiuba","Maria Spiropulu","Jean-Roch Vlimant"],"pdf_url":"https://arxiv.org/pdf/2311.14160v1.pdf","comment":"7 pages, 3 figures, accepted at the Machine Learning and the Physical\n  Sciences Workshop, NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.14156v1","updated":"2023-11-23T18:56:51Z","published":"2023-11-23T18:56:51Z","title":"Variational Annealing on Graphs for Combinatorial Optimization","summary":"  Several recent unsupervised learning methods use probabilistic approaches to\nsolve combinatorial optimization (CO) problems based on the assumption of\nstatistically independent solution variables. We demonstrate that this\nassumption imposes performance limitations in particular on difficult problem\ninstances. Our results corroborate that an autoregressive approach which\ncaptures statistical dependencies among solution variables yields superior\nperformance on many popular CO problems. We introduce subgraph tokenization in\nwhich the configuration of a set of solution variables is represented by a\nsingle token. This tokenization technique alleviates the drawback of the long\nsequential sampling procedure which is inherent to autoregressive methods\nwithout sacrificing expressivity. Importantly, we theoretically motivate an\nannealed entropy regularization and show empirically that it is essential for\nefficient and stable learning.\n","authors":["Sebastian Sanokowski","Wilhelm Berghammer","Sepp Hochreiter","Sebastian Lehner"],"pdf_url":"https://arxiv.org/pdf/2311.14156v1.pdf","comment":"Accepted at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.14153v1","updated":"2023-11-23T18:54:25Z","published":"2023-11-23T18:54:25Z","title":"Tube-NeRF: Efficient Imitation Learning of Visuomotor Policies from MPC\n  using Tube-Guided Data Augmentation and NeRFs","summary":"  Imitation learning (IL) can train computationally-efficient sensorimotor\npolicies from a resource-intensive Model Predictive Controller (MPC), but it\noften requires many samples, leading to long training times or limited\nrobustness. To address these issues, we combine IL with a variant of robust MPC\nthat accounts for process and sensing uncertainties, and we design a data\naugmentation (DA) strategy that enables efficient learning of vision-based\npolicies. The proposed DA method, named Tube-NeRF, leverages Neural Radiance\nFields (NeRFs) to generate novel synthetic images, and uses properties of the\nrobust MPC (the tube) to select relevant views and to efficiently compute the\ncorresponding actions. We tailor our approach to the task of localization and\ntrajectory tracking on a multirotor, by learning a visuomotor policy that\ngenerates control actions using images from the onboard camera as only source\nof horizontal position. Our evaluations numerically demonstrate learning of a\nrobust visuomotor policy with an 80-fold increase in demonstration efficiency\nand a 50% reduction in training time over current IL methods. Additionally, our\npolicies successfully transfer to a real multirotor, achieving accurate\nlocalization and low tracking errors despite large disturbances, with an\nonboard inference time of only 1.5 ms.\n","authors":["Andrea Tagliabue","Jonathan P. How"],"pdf_url":"https://arxiv.org/pdf/2311.14153v1.pdf","comment":"Video: https://youtu.be/_W5z33ZK1m4. Evolved paper from our previous\n  work: arXiv:2210.10127"},{"id":"http://arxiv.org/abs/2307.07871v2","updated":"2023-11-23T18:45:29Z","published":"2023-07-15T19:05:56Z","title":"The SocialAI School: Insights from Developmental Psychology Towards\n  Artificial Socio-Cultural Agents","summary":"  Developmental psychologists have long-established the importance of\nsocio-cognitive abilities in human intelligence. These abilities enable us to\nenter, participate and benefit from human culture. AI research on social\ninteractive agents mostly concerns the emergence of culture in a multi-agent\nsetting (often without a strong grounding in developmental psychology). We\nargue that AI research should be informed by psychology and study\nsocio-cognitive abilities enabling to enter a culture too. We discuss the\ntheories of Michael Tomasello and Jerome Bruner to introduce some of their\nconcepts to AI and outline key concepts and socio-cognitive abilities. We\npresent The SocialAI school - a tool including a customizable parameterized\nuite of procedurally generated environments, which simplifies conducting\nexperiments regarding those concepts. We show examples of such experiments with\nRL agents and Large Language Models. The main motivation of this work is to\nengage the AI community around the problem of social intelligence informed by\ndevelopmental psychology, and to provide a tool to simplify first steps in this\ndirection. Refer to the project website for code and additional information:\nhttps://sites.google.com/view/socialai-school.\n","authors":["Grgur Kovač","Rémy Portelas","Peter Ford Dominey","Pierre-Yves Oudeyer"],"pdf_url":"https://arxiv.org/pdf/2307.07871v2.pdf","comment":"Preprint, see v1 for a shorter version (accepted at the \"Workshop on\n  Theory-of-Mind\" at ICML 2023) See project website for demo and code:\n  https://sites.google.com/view/socialai-school"},{"id":"http://arxiv.org/abs/2311.14148v1","updated":"2023-11-23T18:37:26Z","published":"2023-11-23T18:37:26Z","title":"Automated 3D Tumor Segmentation using Temporal Cubic PatchGAN (TCuP-GAN)","summary":"  Development of robust general purpose 3D segmentation frameworks using the\nlatest deep learning techniques is one of the active topics in various\nbio-medical domains. In this work, we introduce Temporal Cubic PatchGAN\n(TCuP-GAN), a volume-to-volume translational model that marries the concepts of\na generative feature learning framework with Convolutional Long Short-Term\nMemory Networks (LSTMs), for the task of 3D segmentation. We demonstrate the\ncapabilities of our TCuP-GAN on the data from four segmentation challenges\n(Adult Glioma, Meningioma, Pediatric Tumors, and Sub-Saharan Africa subset)\nfeatured within the 2023 Brain Tumor Segmentation (BraTS) Challenge and\nquantify its performance using LesionWise Dice similarity and $95\\%$ Hausdorff\nDistance metrics. We demonstrate the successful learning of our framework to\npredict robust multi-class segmentation masks across all the challenges. This\nbenchmarking work serves as a stepping stone for future efforts towards\napplying TCuP-GAN on other multi-class tasks such as multi-organelle\nsegmentation in electron microscopy imaging.\n","authors":["Kameswara Bharadwaj Mantha","Ramanakumar Sankar","Lucy Fortson"],"pdf_url":"https://arxiv.org/pdf/2311.14148v1.pdf","comment":"Submitted as a short paper to the proceedings of the 2023 Brain Tumor\n  Segmentation (BraTS) Challenge"},{"id":"http://arxiv.org/abs/2311.14139v1","updated":"2023-11-23T18:13:34Z","published":"2023-11-23T18:13:34Z","title":"Machine Learning For An Explainable Cost Prediction of Medical Insurance","summary":"  Predictive modeling in healthcare continues to be an active actuarial\nresearch topic as more insurance companies aim to maximize the potential of\nMachine Learning approaches to increase their productivity and efficiency. In\nthis paper, the authors deployed three regression-based ensemble ML models that\ncombine variations of decision trees through Extreme Gradient Boosting,\nGradient-boosting Machine, and Random Forest) methods in predicting medical\ninsurance costs. Explainable Artificial Intelligence methods SHapley Additive\nexPlanations and Individual Conditional Expectation plots were deployed to\ndiscover and explain the key determinant factors that influence medical\ninsurance premium prices in the dataset. The dataset used comprised 986 records\nand is publicly available in the KAGGLE repository. The models were evaluated\nusing four performance evaluation metrics, including R-squared, Mean Absolute\nError, Root Mean Squared Error, and Mean Absolute Percentage Error. The results\nshow that all models produced impressive outcomes; however, the XGBoost model\nachieved a better overall performance although it also expanded more\ncomputational resources, while the RF model recorded a lesser prediction error\nand consumed far fewer computing resources than the XGBoost model. Furthermore,\nwe compared the outcome of both XAi methods in identifying the key determinant\nfeatures that influenced the PremiumPrices for each model and whereas both XAi\nmethods produced similar outcomes, we found that the ICE plots showed in more\ndetail the interactions between each variable than the SHAP analysis which\nseemed to be more high-level. It is the aim of the authors that the\ncontributions of this study will help policymakers, insurers, and potential\nmedical insurance buyers in their decision-making process for selecting the\nright policies that meet their specific needs.\n","authors":["Ugochukwu Orji","Elochukwu Ukwandu"],"pdf_url":"https://arxiv.org/pdf/2311.14139v1.pdf","comment":"42 pages, 16 figures and 9 tables"},{"id":"http://arxiv.org/abs/2311.14137v1","updated":"2023-11-23T18:08:15Z","published":"2023-11-23T18:08:15Z","title":"Privacy-Preserving Algorithmic Recourse","summary":"  When individuals are subject to adverse outcomes from machine learning\nmodels, providing a recourse path to help achieve a positive outcome is\ndesirable. Recent work has shown that counterfactual explanations - which can\nbe used as a means of single-step recourse - are vulnerable to privacy issues,\nputting an individuals' privacy at risk. Providing a sequential multi-step path\nfor recourse can amplify this risk. Furthermore, simply adding noise to\nrecourse paths found from existing methods can impact the realism and\nactionability of the path for an end-user. In this work, we address privacy\nissues when generating realistic recourse paths based on instance-based\ncounterfactual explanations, and provide PrivRecourse: an end-to-end privacy\npreserving pipeline that can provide realistic recourse paths. PrivRecourse\nuses differentially private (DP) clustering to represent non-overlapping\nsubsets of the private dataset. These DP cluster centers are then used to\ngenerate recourse paths by forming a graph with cluster centers as the nodes,\nso that we can generate realistic - feasible and actionable - recourse paths.\nWe empirically evaluate our approach on finance datasets and compare it to\nsimply adding noise to data instances, and to using DP synthetic data, to\ngenerate the graph. We observe that PrivRecourse can provide paths that are\nprivate and realistic.\n","authors":["Sikha Pentyala","Shubham Sharma","Sanjay Kariyappa","Freddy Lecue","Daniele Magazzeni"],"pdf_url":"https://arxiv.org/pdf/2311.14137v1.pdf","comment":"Accepted at 3rd International Workshop on Explainable AI in Finance,\n  ICAIF 2023"},{"id":"http://arxiv.org/abs/2311.14136v1","updated":"2023-11-23T18:06:05Z","published":"2023-11-23T18:06:05Z","title":"A Blockchain Solution for Collaborative Machine Learning over IoT","summary":"  The rapid growth of Internet of Things (IoT) devices and applications has led\nto an increased demand for advanced analytics and machine learning techniques\ncapable of handling the challenges associated with data privacy, security, and\nscalability. Federated learning (FL) and blockchain technologies have emerged\nas promising approaches to address these challenges by enabling decentralized,\nsecure, and privacy-preserving model training on distributed data sources. In\nthis paper, we present a novel IoT solution that combines the incremental\nlearning vector quantization algorithm (XuILVQ) with Ethereum blockchain\ntechnology to facilitate secure and efficient data sharing, model training, and\nprototype storage in a distributed environment. Our proposed architecture\naddresses the shortcomings of existing blockchain-based FL solutions by\nreducing computational and communication overheads while maintaining data\nprivacy and security. We assess the performance of our system through a series\nof experiments, showcasing its potential to enhance the accuracy and efficiency\nof machine learning tasks in IoT settings.\n","authors":["Carlos Beis-Penedo","Francisco Troncoso-Pastoriza","Rebeca P. Díaz-Redondo","Ana Fernández-Vilas","Manuel Fernández-Veiga","Martín González Soto"],"pdf_url":"https://arxiv.org/pdf/2311.14136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14131v1","updated":"2023-11-23T17:59:48Z","published":"2023-11-23T17:59:48Z","title":"Exactly conservative physics-informed neural networks and deep operator\n  networks for dynamical systems","summary":"  We introduce a method for training exactly conservative physics-informed\nneural networks and physics-informed deep operator networks for dynamical\nsystems. The method employs a projection-based technique that maps a candidate\nsolution learned by the neural network solver for any given dynamical system\npossessing at least one first integral onto an invariant manifold. We\nillustrate that exactly conservative physics-informed neural network solvers\nand physics-informed deep operator networks for dynamical systems vastly\noutperform their non-conservative counterparts for several real-world problems\nfrom the mathematical sciences.\n","authors":["Elsa Cardoso-Bihlo","Alex Bihlo"],"pdf_url":"https://arxiv.org/pdf/2311.14131v1.pdf","comment":"12 pages, 6 figures, 1 algorithm"},{"id":"http://arxiv.org/abs/2311.14127v1","updated":"2023-11-23T17:50:30Z","published":"2023-11-23T17:50:30Z","title":"Byzantine Robustness and Partial Participation Can Be Achieved\n  Simultaneously: Just Clip Gradient Differences","summary":"  Distributed learning has emerged as a leading paradigm for training large\nmachine learning models. However, in real-world scenarios, participants may be\nunreliable or malicious, posing a significant challenge to the integrity and\naccuracy of the trained models. Byzantine fault tolerance mechanisms have been\nproposed to address these issues, but they often assume full participation from\nall clients, which is not always practical due to the unavailability of some\nclients or communication constraints. In our work, we propose the first\ndistributed method with client sampling and provable tolerance to Byzantine\nworkers. The key idea behind the developed method is the use of gradient\nclipping to control stochastic gradient differences in recursive variance\nreduction. This allows us to bound the potential harm caused by Byzantine\nworkers, even during iterations when all sampled clients are Byzantine.\nFurthermore, we incorporate communication compression into the method to\nenhance communication efficiency. Under quite general assumptions, we prove\nconvergence rates for the proposed method that match the existing\nstate-of-the-art (SOTA) theoretical results.\n","authors":["Grigory Malinovsky","Peter Richtárik","Samuel Horváth","Eduard Gorbunov"],"pdf_url":"https://arxiv.org/pdf/2311.14127v1.pdf","comment":"50 pages; 1 figure"},{"id":"http://arxiv.org/abs/2311.14126v1","updated":"2023-11-23T17:47:14Z","published":"2023-11-23T17:47:14Z","title":"Towards Auditing Large Language Models: Improving Text-based Stereotype\n  Detection","summary":"  Large Language Models (LLM) have made significant advances in the recent past\nbecoming more mainstream in Artificial Intelligence (AI) enabled human-facing\napplications. However, LLMs often generate stereotypical output inherited from\nhistorical data, amplifying societal biases and raising ethical concerns. This\nwork introduces i) the Multi-Grain Stereotype Dataset, which includes 52,751\ninstances of gender, race, profession and religion stereotypic text and ii) a\nnovel stereotype classifier for English text. We design several experiments to\nrigorously test the proposed model trained on the novel dataset. Our\nexperiments show that training the model in a multi-class setting can\noutperform the one-vs-all binary counterpart. Consistent feature importance\nsignals from different eXplainable AI tools demonstrate that the new model\nexploits relevant text features. We utilise the newly created model to assess\nthe stereotypic behaviour of the popular GPT family of models and observe the\nreduction of bias over time. In summary, our work establishes a robust and\npractical framework for auditing and evaluating the stereotypic bias in LLM.\n","authors":["Wu Zekun","Sahan Bulathwela","Adriano Soares Koshiyama"],"pdf_url":"https://arxiv.org/pdf/2311.14126v1.pdf","comment":"2023 NeurIPS SoLaR Workshop Accepted"},{"id":"http://arxiv.org/abs/2311.14125v1","updated":"2023-11-23T17:46:30Z","published":"2023-11-23T17:46:30Z","title":"Scalable AI Safety via Doubly-Efficient Debate","summary":"  The emergence of pre-trained AI systems with powerful capabilities across a\ndiverse and ever-increasing set of complex domains has raised a critical\nchallenge for AI safety as tasks can become too complicated for humans to judge\ndirectly. Irving et al. [2018] proposed a debate method in this direction with\nthe goal of pitting the power of such AI models against each other until the\nproblem of identifying (mis)-alignment is broken down into a manageable\nsubtask. While the promise of this approach is clear, the original framework\nwas based on the assumption that the honest strategy is able to simulate\ndeterministic AI systems for an exponential number of steps, limiting its\napplicability. In this paper, we show how to address these challenges by\ndesigning a new set of debate protocols where the honest strategy can always\nsucceed using a simulation of a polynomial number of steps, whilst being able\nto verify the alignment of stochastic AI systems, even when the dishonest\nstrategy is allowed to use exponentially many simulation steps.\n","authors":["Jonah Brown-Cohen","Geoffrey Irving","Georgios Piliouras"],"pdf_url":"https://arxiv.org/pdf/2311.14125v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14120v1","updated":"2023-11-23T17:30:31Z","published":"2023-11-23T17:30:31Z","title":"Weight fluctuations in (deep) linear neural networks and a derivation of\n  the inverse-variance flatness relation","summary":"  We investigate the stationary (late-time) training regime of single- and\ntwo-layer linear neural networks within the continuum limit of stochastic\ngradient descent (SGD) for synthetic Gaussian data. In the case of a\nsingle-layer network in the weakly oversampled regime, the spectrum of the\nnoise covariance matrix deviates notably from the Hessian, which can be\nattributed to the broken detailed balance of SGD dynamics. The weight\nfluctuations are in this case generally anisotropic, but experience an\nisotropic loss. For a two-layer network, we obtain the stochastic dynamics of\nthe weights in each layer and analyze the associated stationary covariances. We\nidentify the inter-layer coupling as a new source of anisotropy for the weight\nfluctuations. In contrast to the single-layer case, the weight fluctuations\nexperience an anisotropic loss, the flatness of which is inversely related to\nthe fluctuation variance. We thereby provide an analytical derivation of the\nrecently observed inverse variance-flatness relation in a deep linear network\nmodel.\n","authors":["Markus Gross","Arne P. Raulf","Christoph Räth"],"pdf_url":"https://arxiv.org/pdf/2311.14120v1.pdf","comment":"25 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.11762v2","updated":"2023-11-23T17:26:53Z","published":"2023-11-20T13:40:40Z","title":"MUVO: A Multimodal Generative World Model for Autonomous Driving with\n  Geometric Representations","summary":"  Learning unsupervised world models for autonomous driving has the potential\nto improve the reasoning capabilities of today's systems dramatically. However,\nmost work neglects the physical attributes of the world and focuses on sensor\ndata alone. We propose MUVO, a MUltimodal World Model with Geometric VOxel\nRepresentations to address this challenge. We utilize raw camera and lidar data\nto learn a sensor-agnostic geometric representation of the world, which can\ndirectly be used by downstream tasks, such as planning. We demonstrate\nmultimodal future predictions and show that our geometric representation\nimproves the prediction quality of both camera images and lidar point clouds.\n","authors":["Daniel Bogdoll","Yitian Yang","J. Marius Zöllner"],"pdf_url":"https://arxiv.org/pdf/2311.11762v2.pdf","comment":"Daniel Bogdoll and Yitian Yang contributed equally"},{"id":"http://arxiv.org/abs/2311.14115v1","updated":"2023-11-23T17:20:36Z","published":"2023-11-23T17:20:36Z","title":"A density estimation perspective on learning from pairwise human\n  preferences","summary":"  Learning from human feedback (LHF) -- and in particular learning from\npairwise preferences -- has recently become a crucial ingredient in training\nlarge language models (LLMs), and has been the subject of much research. Most\nrecent works frame it as a reinforcement learning problem, where a reward\nfunction is learned from pairwise preference data and the LLM is treated as a\npolicy which is adapted to maximize the rewards, often under additional\nregularization constraints. We propose an alternative interpretation which\ncenters on the generative process for pairwise preferences and treats LHF as a\ndensity estimation problem. We provide theoretical and empirical results\nshowing that for a family of generative processes defined via preference\nbehavior distribution equations, training a reward function on pairwise\npreferences effectively models an annotator's implicit preference distribution.\nFinally, we discuss and present findings on \"annotator misspecification\" --\nfailure cases where wrong modeling assumptions are made about annotator\nbehavior, resulting in poorly-adapted models -- suggesting that approaches that\nlearn from pairwise human preferences could have trouble learning from a\npopulation of annotators with diverse viewpoints.\n","authors":["Vincent Dumoulin","Daniel D. Johnson","Pablo Samuel Castro","Hugo Larochelle","Yann Dauphin"],"pdf_url":"https://arxiv.org/pdf/2311.14115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14114v1","updated":"2023-11-23T17:20:09Z","published":"2023-11-23T17:20:09Z","title":"SySMOL: A Hardware-software Co-design Framework for Ultra-Low and\n  Fine-Grained Mixed-Precision Neural Networks","summary":"  Recent advancements in quantization and mixed-precision techniques offer\nsignificant promise for improving the run-time and energy efficiency of neural\nnetworks. In this work, we further showed that neural networks, wherein\nindividual parameters or activations can take on different precisions ranging\nbetween 1 and 4 bits, can achieve accuracies comparable to or exceeding the\nfull-precision counterparts. However, the deployment of such networks poses\nnumerous challenges, stemming from the necessity to manage and control the\ncompute/communication/storage requirements associated with these extremely\nfine-grained mixed precisions for each piece of data. There is a lack of\nexisting efficient hardware and system-level support tailored to these unique\nand challenging requirements. Our research introduces the first novel holistic\nhardware-software co-design approach for these networks, which enables a\ncontinuous feedback loop between hardware design, training, and inference to\nfacilitate systematic design exploration. As a proof-of-concept, we illustrate\nthis co-design approach by designing new, configurable CPU SIMD architectures\ntailored for these networks, tightly integrating the architecture with new\nsystem-aware training and inference techniques. We perform systematic design\nspace exploration using this framework to analyze various tradeoffs. The design\nfor mixed-precision networks that achieves optimized tradeoffs corresponds to\nan architecture that supports 1, 2, and 4-bit fixed-point operations with four\nconfigurable precision patterns, when coupled with system-aware training and\ninference optimization -- networks trained for this design achieve accuracies\nthat closely match full-precision accuracies, while compressing and improving\nrun-time efficiency of the neural networks drastically by 10-20x, compared to\nfull-precision networks.\n","authors":["Cyrus Zhou","Vaughn Richard","Pedro Savarese","Zachary Hassman","Michael Maire","Michael DiBrino","Yanjing Li"],"pdf_url":"https://arxiv.org/pdf/2311.14114v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14110v1","updated":"2023-11-23T17:13:37Z","published":"2023-11-23T17:13:37Z","title":"When is Off-Policy Evaluation Useful? A Data-Centric Perspective","summary":"  Evaluating the value of a hypothetical target policy with only a logged\ndataset is important but challenging. On the one hand, it brings opportunities\nfor safe policy improvement under high-stakes scenarios like clinical\nguidelines. On the other hand, such opportunities raise a need for precise\noff-policy evaluation (OPE). While previous work on OPE focused on improving\nthe algorithm in value estimation, in this work, we emphasize the importance of\nthe offline dataset, hence putting forward a data-centric framework for\nevaluating OPE problems. We propose DataCOPE, a data-centric framework for\nevaluating OPE, that answers the questions of whether and to what extent we can\nevaluate a target policy given a dataset. DataCOPE (1) forecasts the overall\nperformance of OPE algorithms without access to the environment, which is\nespecially useful before real-world deployment where evaluating OPE is\nimpossible; (2) identifies the sub-group in the dataset where OPE can be\ninaccurate; (3) permits evaluations of datasets or data-collection strategies\nfor OPE problems. Our empirical analysis of DataCOPE in the logged contextual\nbandit settings using healthcare datasets confirms its ability to evaluate both\nmachine-learning and human expert policies like clinical guidelines.\n","authors":["Hao Sun","Alex J. Chan","Nabeel Seedat","Alihan Hüyük","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2311.14110v1.pdf","comment":"Off-Policy Evaluation, Data-Centric AI, Data-Centric Reinforcement\n  Learning, Reinforcement Learning"},{"id":"http://arxiv.org/abs/2311.14108v1","updated":"2023-11-23T17:09:12Z","published":"2023-11-23T17:09:12Z","title":"MINTY: Rule-based Models that Minimize the Need for Imputing Features\n  with Missing Values","summary":"  Rule models are often preferred in prediction tasks with tabular inputs as\nthey can be easily interpreted using natural language and provide predictive\nperformance on par with more complex models. However, most rule models'\npredictions are undefined or ambiguous when some inputs are missing, forcing\nusers to rely on statistical imputation models or heuristics like zero\nimputation, undermining the interpretability of the models. In this work, we\npropose fitting concise yet precise rule models that learn to avoid relying on\nfeatures with missing values and, therefore, limit their reliance on imputation\nat test time. We develop MINTY, a method that learns rules in the form of\ndisjunctions between variables that act as replacements for each other when one\nor more is missing. This results in a sparse linear rule model, regularized to\nhave small dependence on features with missing values, that allows a trade-off\nbetween goodness of fit, interpretability, and robustness to missing values at\ntest time. We demonstrate the value of MINTY in experiments using synthetic and\nreal-world data sets and find its predictive performance comparable or\nfavorable to baselines, with smaller reliance on features with missing values.\n","authors":["Lena Stempfle","Fredrik D. Johansson"],"pdf_url":"https://arxiv.org/pdf/2311.14108v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.02205v3","updated":"2023-11-23T17:04:26Z","published":"2022-03-04T09:31:20Z","title":"Evaluating Object (mis)Detection from a Safety and Reliability\n  Perspective: Discussion and Measures","summary":"  We argue that object detectors in the safety critical domain should\nprioritize detection of objects that are most likely to interfere with the\nactions of the autonomous actor. Especially, this applies to objects that can\nimpact the actor's safety and reliability. To quantify the impact of object\n(mis)detection on safety and reliability in the context of autonomous driving,\nwe propose new object detection measures that reward the correct identification\nof objects that are most dangerous and most likely to affect driving decisions.\nTo achieve this, we build an object criticality model to reward the detection\nof the objects based on proximity, orientation, and relative velocity with\nrespect to the subject vehicle. Then, we apply our model on the recent\nautonomous driving dataset nuScenes, and we compare nine object detectors.\nResults show that, in several settings, object detectors that perform best\naccording to the nuScenes ranking are not the preferable ones when the focus is\nshifted on safety and reliability.\n","authors":["Andrea Ceccarelli","Leonardo Montecchi"],"pdf_url":"https://arxiv.org/pdf/2203.02205v3.pdf","comment":"journal version, open access"},{"id":"http://arxiv.org/abs/2311.14101v1","updated":"2023-11-23T17:01:16Z","published":"2023-11-23T17:01:16Z","title":"Subnetwork Ensembles","summary":"  Neural network ensembles have been effectively used to improve generalization\nby combining the predictions of multiple independently trained models. However,\nthe growing scale and complexity of deep neural networks have led to these\nmethods becoming prohibitively expensive and time consuming to implement.\nLow-cost ensemble methods have become increasingly important as they can\nalleviate the need to train multiple models from scratch while retaining the\ngeneralization benefits that traditional ensemble learning methods afford. This\ndissertation introduces and formalizes a low-cost framework for constructing\nSubnetwork Ensembles, where a collection of child networks are formed by\nsampling, perturbing, and optimizing subnetworks from a trained parent model.\nWe explore several distinct methodologies for generating child networks and we\nevaluate their efficacy through a variety of ablation studies and established\nbenchmarks. Our findings reveal that this approach can greatly improve training\nefficiency, parametric utilization, and generalization performance while\nminimizing computational cost. Subnetwork Ensembles offer a compelling\nframework for exploring how we can build better systems by leveraging the\nunrealized potential of deep neural networks.\n","authors":["Tim Whitaker"],"pdf_url":"https://arxiv.org/pdf/2311.14101v1.pdf","comment":"116 Pages, 21 figures, Accepted PhD Dissertation"},{"id":"http://arxiv.org/abs/2311.14094v1","updated":"2023-11-23T16:39:55Z","published":"2023-11-23T16:39:55Z","title":"Robust Decision Aggregation with Second-order Information","summary":"  We consider a decision aggregation problem with two experts who each make a\nbinary recommendation after observing a private signal about an unknown binary\nworld state. An agent, who does not know the joint information structure\nbetween signals and states, sees the experts' recommendations and aims to match\nthe action with the true state. Under the scenario, we study whether\nsupplemented additionally with second-order information (each expert's forecast\non the other's recommendation) could enable a better aggregation.\n  We adopt a minimax regret framework to evaluate the aggregator's performance,\nby comparing it to an omniscient benchmark that knows the joint information\nstructure. With general information structures, we show that second-order\ninformation provides no benefit. No aggregator can improve over a trivial\naggregator, which always follows the first expert's recommendation. However,\npositive results emerge when we assume experts' signals are conditionally\nindependent given the world state. When the aggregator is deterministic, we\npresent a robust aggregator that leverages second-order information, which can\nsignificantly outperform counterparts without it. Second, when two experts are\nhomogeneous, by adding a non-degenerate assumption on the signals, we\ndemonstrate that random aggregators using second-order information can surpass\noptimal ones without it. In the remaining settings, the second-order\ninformation is not beneficial. We also extend the above results to the setting\nwhen the aggregator's utility function is more general.\n","authors":["Yuqi Pan","Zhaohua Chen","Yuqing Kong"],"pdf_url":"https://arxiv.org/pdf/2311.14094v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14090v1","updated":"2023-11-23T16:36:03Z","published":"2023-11-23T16:36:03Z","title":"Class Uncertainty: A Measure to Mitigate Class Imbalance","summary":"  Class-wise characteristics of training examples affect the performance of\ndeep classifiers. A well-studied example is when the number of training\nexamples of classes follows a long-tailed distribution, a situation that is\nlikely to yield sub-optimal performance for under-represented classes. This\nclass imbalance problem is conventionally addressed by approaches relying on\nthe class-wise cardinality of training examples, such as data resampling. In\nthis paper, we demonstrate that considering solely the cardinality of classes\ndoes not cover all issues causing class imbalance. To measure class imbalance,\nwe propose \"Class Uncertainty\" as the average predictive uncertainty of the\ntraining examples, and we show that this novel measure captures the differences\nacross classes better than cardinality. We also curate SVCI-20 as a novel\ndataset in which the classes have equal number of training examples but they\ndiffer in terms of their hardness; thereby causing a type of class imbalance\nwhich cannot be addressed by the approaches relying on cardinality. We\nincorporate our \"Class Uncertainty\" measure into a diverse set of ten class\nimbalance mitigation methods to demonstrate its effectiveness on long-tailed\ndatasets as well as on our SVCI-20. Code and datasets will be made available.\n","authors":["Z. S. Baltaci","K. Oksuz","S. Kuzucu","K. Tezoren","B. K. Konar","A. Ozkan","E. Akbas","S. Kalkan"],"pdf_url":"https://arxiv.org/pdf/2311.14090v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17400v2","updated":"2023-11-23T16:27:42Z","published":"2023-05-27T07:55:17Z","title":"Query-Policy Misalignment in Preference-Based Reinforcement Learning","summary":"  Preference-based reinforcement learning (PbRL) provides a natural way to\nalign RL agents' behavior with human desired outcomes, but is often restrained\nby costly human feedback. To improve feedback efficiency, most existing PbRL\nmethods focus on selecting queries to maximally improve the overall quality of\nthe reward model, but counter-intuitively, we find that this may not\nnecessarily lead to improved performance. To unravel this mystery, we identify\na long-neglected issue in the query selection schemes of existing PbRL studies:\nQuery-Policy Misalignment. We show that the seemingly informative queries\nselected to improve the overall quality of reward model actually may not align\nwith RL agents' interests, thus offering little help on policy learning and\neventually resulting in poor feedback efficiency. We show that this issue can\nbe effectively addressed via near on-policy query and a specially designed\nhybrid experience replay, which together enforce the bidirectional query-policy\nalignment. Simple yet elegant, our method can be easily incorporated into\nexisting approaches by changing only a few lines of code. We showcase in\ncomprehensive experiments that our method achieves substantial gains in both\nhuman feedback and RL sample efficiency, demonstrating the importance of\naddressing query-policy misalignment in PbRL tasks.\n","authors":["Xiao Hu","Jianxiong Li","Xianyuan Zhan","Qing-Shan Jia","Ya-Qin Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.17400v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14790v2","updated":"2023-11-23T16:27:37Z","published":"2023-10-20T16:53:31Z","title":"Weighted Joint Maximum Mean Discrepancy Enabled\n  Multi-Source-Multi-Target Unsupervised Domain Adaptation Fault Diagnosis","summary":"  Despite the remarkable results that can be achieved by data-driven\nintelligent fault diagnosis techniques, they presuppose the same distribution\nof training and test data as well as sufficient labeled data. Various operating\nstates often exist in practical scenarios, leading to the problem of domain\nshift that hinders the effectiveness of fault diagnosis. While recent\nunsupervised domain adaptation methods enable cross-domain fault diagnosis,\nthey struggle to effectively utilize information from multiple source domains\nand achieve effective diagnosis faults in multiple target domains\nsimultaneously. In this paper, we innovatively proposed a weighted joint\nmaximum mean discrepancy enabled multi-source-multi-target unsupervised domain\nadaptation (WJMMD-MDA), which realizes domain adaptation under\nmulti-source-multi-target scenarios in the field of fault diagnosis for the\nfirst time. The proposed method extracts sufficient information from multiple\nlabeled source domains and achieves domain alignment between source and target\ndomains through an improved weighted distance loss. As a result,\ndomain-invariant and discriminative features between multiple source and target\ndomains are learned with cross-domain fault diagnosis realized. The performance\nof the proposed method is evaluated in comprehensive comparative experiments on\nthree datasets, and the experimental results demonstrate the superiority of\nthis method.\n","authors":["Zixuan Wang","Haoran Tang","Haibo Wang","Bo Qin","Mark D. Butala","Weiming Shen","Hongwei Wang"],"pdf_url":"https://arxiv.org/pdf/2310.14790v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00574v3","updated":"2023-11-23T16:24:39Z","published":"2023-10-01T05:11:54Z","title":"YFlows: Systematic Dataflow Exploration and Code Generation for\n  Efficient Neural Network Inference using SIMD Architectures on CPUs","summary":"  We address the challenges associated with deploying neural networks on CPUs,\nwith a particular focus on minimizing inference time while maintaining\naccuracy. Our novel approach is to use the dataflow (i.e., computation order)\nof a neural network to explore data reuse opportunities using heuristic-guided\nanalysis and a code generation framework, which enables exploration of various\nSingle Instruction, Multiple Data (SIMD) implementations to achieve optimized\nneural network execution. Our results demonstrate that the dataflow that keeps\noutputs in SIMD registers while also maximizing both input and weight reuse\nconsistently yields the best performance for a wide variety of inference\nworkloads, achieving up to 3x speedup for 8-bit neural networks, and up to 4.8x\nspeedup for binary neural networks, respectively, over the optimized\nimplementations of neural networks today.\n","authors":["Cyrus Zhou","Zack Hassman","Ruize Xu","Dhirpal Shah","Vaugnn Richard","Yanjing Li"],"pdf_url":"https://arxiv.org/pdf/2310.00574v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14086v1","updated":"2023-11-23T16:24:26Z","published":"2023-11-23T16:24:26Z","title":"Brain MRI Screening Tool with Federated Learning","summary":"  In clinical practice, we often see significant delays between MRI scans and\nthe diagnosis made by radiologists, even for severe cases. In some cases, this\nmay be caused by the lack of additional information and clues, so even the\nsevere cases need to wait in the queue for diagnosis. This can be avoided if\nthere is an automatic software tool, which would supplement additional\ninformation, alerting radiologists that the particular patient may be a severe\ncase.\n  We are presenting an automatic brain MRI Screening Tool and we are\ndemonstrating its capabilities for detecting tumor-like pathologies. It is the\nfirst version on the path toward a robust multi-pathology screening solution.\nThe tool supports Federated Learning, so multiple institutions may contribute\nto the model without disclosing their private data.\n","authors":["Roman Stoklasa","Ioannis Stathopoulos","Efstratios Karavasilis","Efstathios Efstathopoulos","Marek Dostál","Miloš Keřkovský","Michal Kozubek","Luigi Serio"],"pdf_url":"https://arxiv.org/pdf/2311.14086v1.pdf","comment":"5 pages, 2 figures. Submitted to ISBI 2024 conference"},{"id":"http://arxiv.org/abs/2311.14079v1","updated":"2023-11-23T16:14:24Z","published":"2023-11-23T16:14:24Z","title":"Empirical Comparison between Cross-Validation and Mutation-Validation in\n  Model Selection","summary":"  Mutation validation (MV) is a recently proposed approach for model selection,\ngarnering significant interest due to its unique characteristics and potential\nbenefits compared to the widely used cross-validation (CV) method. In this\nstudy, we empirically compared MV and $k$-fold CV using benchmark and\nreal-world datasets. By employing Bayesian tests, we compared generalization\nestimates yielding three posterior probabilities: practical equivalence, CV\nsuperiority, and MV superiority. We also evaluated the differences in the\ncapacity of the selected models and computational efficiency. We found that\nboth MV and CV select models with practically equivalent generalization\nperformance across various machine learning algorithms and the majority of\nbenchmark datasets. MV exhibited advantages in terms of selecting simpler\nmodels and lower computational costs. However, in some cases MV selected overly\nsimplistic models leading to underfitting and showed instability in\nhyperparameter selection. These limitations of MV became more evident in the\nevaluation of a real-world neuroscientific task of predicting sex at birth\nusing brain functional connectivity.\n","authors":["Jinyang Yu","Sami Hamdan","Leonard Sasse","Abigail Morrison","Kaustubh R. Patil"],"pdf_url":"https://arxiv.org/pdf/2311.14079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12792v2","updated":"2023-11-23T16:13:10Z","published":"2022-11-23T09:13:33Z","title":"MECCH: Metapath Context Convolution-based Heterogeneous Graph Neural\n  Networks","summary":"  Heterogeneous graph neural networks (HGNNs) were proposed for representation\nlearning on structural data with multiple types of nodes and edges. To deal\nwith the performance degradation issue when HGNNs become deep, researchers\ncombine metapaths into HGNNs to associate nodes closely related in semantics\nbut far apart in the graph. However, existing metapath-based models suffer from\neither information loss or high computation costs. To address these problems,\nwe present a novel Metapath Context Convolution-based Heterogeneous Graph\nNeural Network (MECCH). MECCH leverages metapath contexts, a new kind of graph\nstructure that facilitates lossless node information aggregation while avoiding\nany redundancy. Specifically, MECCH applies three novel components after\nfeature preprocessing to extract comprehensive information from the input graph\nefficiently: (1) metapath context construction, (2) metapath context encoder,\nand (3) convolutional metapath fusion. Experiments on five real-world\nheterogeneous graph datasets for node classification and link prediction show\nthat MECCH achieves superior prediction accuracy compared with state-of-the-art\nbaselines with improved computational efficiency.\n","authors":["Xinyu Fu","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2211.12792v2.pdf","comment":"12 pages, 7 figures, 7 tables; published in Neural Networks; code\n  available at https://github.com/cynricfu/MECCH"},{"id":"http://arxiv.org/abs/2311.14078v1","updated":"2023-11-23T16:12:00Z","published":"2023-11-23T16:12:00Z","title":"Machine learning-based decentralized TDMA for VLC IoT networks","summary":"  In this paper, a machine learning-based decentralized time division multiple\naccess (TDMA) algorithm for visible light communication (VLC) Internet of\nThings (IoT) networks is proposed. The proposed algorithm is based on\nQ-learning, a reinforcement learning algorithm. This paper considers a\ndecentralized condition in which there is no coordinator node for sending\nsynchronization frames and assigning transmission time slots to other nodes.\nThe proposed algorithm uses a decentralized manner for synchronization, and\neach node uses the Q-learning algorithm to find the optimal transmission time\nslot for sending data without collisions. The proposed algorithm is implemented\non a VLC hardware system, which had been designed and implemented in our\nlaboratory. Average reward, convergence time, goodput, average delay, and data\npacket size are evaluated parameters. The results show that the proposed\nalgorithm converges quickly and provides collision-free decentralized TDMA for\nthe network. The proposed algorithm is compared with carrier-sense multiple\naccess with collision avoidance (CSMA/CA) algorithm as a potential selection\nfor decentralized VLC IoT networks. The results show that the proposed\nalgorithm provides up to 61% more goodput and up to 49% less average delay than\nCSMA/CA.\n","authors":["Armin Makvandi","Yousef Seifi Kavian"],"pdf_url":"https://arxiv.org/pdf/2311.14078v1.pdf","comment":"This work has been submitted to Elsevier for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2311.14077v1","updated":"2023-11-23T16:08:52Z","published":"2023-11-23T16:08:52Z","title":"RetroDiff: Retrosynthesis as Multi-stage Distribution Interpolation","summary":"  Retrosynthesis poses a fundamental challenge in biopharmaceuticals, aiming to\naid chemists in finding appropriate reactant molecules and synthetic pathways\ngiven determined product molecules. With the reactant and product represented\nas 2D graphs, retrosynthesis constitutes a conditional graph-to-graph\ngenerative task. Inspired by the recent advancements in discrete diffusion\nmodels for graph generation, we introduce Retrosynthesis Diffusion (RetroDiff),\na novel diffusion-based method designed to address this problem. However,\nintegrating a diffusion-based graph-to-graph framework while retaining\nessential chemical reaction template information presents a notable challenge.\nOur key innovation is to develop a multi-stage diffusion process. In this\nmethod, we decompose the retrosynthesis procedure to first sample external\ngroups from the dummy distribution given products and then generate the\nexternal bonds to connect the products and generated groups. Interestingly,\nsuch a generation process is exactly the reverse of the widely adapted\nsemi-template retrosynthesis procedure, i.e. from reaction center\nidentification to synthon completion, which significantly reduces the error\naccumulation. Experimental results on the benchmark have demonstrated the\nsuperiority of our method over all other semi-template methods.\n","authors":["Yiming Wang","Yuxuan Song","Minkai Xu","Rui Wang","Hao Zhou","Weiying Ma"],"pdf_url":"https://arxiv.org/pdf/2311.14077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03982v3","updated":"2023-11-23T16:02:22Z","published":"2023-03-07T15:32:18Z","title":"Structured State Space Models for In-Context Reinforcement Learning","summary":"  Structured state space sequence (S4) models have recently achieved\nstate-of-the-art performance on long-range sequence modeling tasks. These\nmodels also have fast inference speeds and parallelisable training, making them\npotentially useful in many reinforcement learning settings. We propose a\nmodification to a variant of S4 that enables us to initialise and reset the\nhidden state in parallel, allowing us to tackle reinforcement learning tasks.\nWe show that our modified architecture runs asymptotically faster than\nTransformers in sequence length and performs better than RNN's on a simple\nmemory-based task. We evaluate our modified architecture on a set of\npartially-observable environments and find that, in practice, our model\noutperforms RNN's while also running over five times faster. Then, by\nleveraging the model's ability to handle long-range sequences, we achieve\nstrong performance on a challenging meta-learning task in which the agent is\ngiven a randomly-sampled continuous control environment, combined with a\nrandomly-sampled linear projection of the environment's observations and\nactions. Furthermore, we show the resulting model can adapt to\nout-of-distribution held-out tasks. Overall, the results presented in this\npaper show that structured state space models are fast and performant for\nin-context reinforcement learning tasks. We provide code at\nhttps://github.com/luchris429/popjaxrl.\n","authors":["Chris Lu","Yannick Schroecker","Albert Gu","Emilio Parisotto","Jakob Foerster","Satinder Singh","Feryal Behbahani"],"pdf_url":"https://arxiv.org/pdf/2303.03982v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04689v3","updated":"2023-11-23T16:00:51Z","published":"2023-03-07T17:22:38Z","title":"A Privacy Preserving System for Movie Recommendations Using Federated\n  Learning","summary":"  Recommender systems have become ubiquitous in the past years. They solve the\ntyranny of choice problem faced by many users, and are utilized by many online\nbusinesses to drive engagement and sales. Besides other criticisms, like\ncreating filter bubbles within social networks, recommender systems are often\nreproved for collecting considerable amounts of personal data. However, to\npersonalize recommendations, personal information is fundamentally required. A\nrecent distributed learning scheme called federated learning has made it\npossible to learn from personal user data without its central collection.\nConsequently, we present a recommender system for movie recommendations, which\nprovides privacy and thus trustworthiness on multiple levels: First and\nforemost, it is trained using federated learning and thus, by its very nature,\nprivacy-preserving, while still enabling users to benefit from global insights.\nFurthermore, a novel federated learning scheme, called FedQ, is employed, which\nnot only addresses the problem of non-i.i.d.-ness and small local datasets, but\nalso prevents input data reconstruction attacks by aggregating client updates\nearly. Finally, to reduce the communication overhead, compression is applied,\nwhich significantly compresses the exchanged neural network parametrizations to\na fraction of their original size. We conjecture that this may also improve\ndata privacy through its lossy quantization stage.\n","authors":["David Neumann","Andreas Lutz","Karsten Müller","Wojciech Samek"],"pdf_url":"https://arxiv.org/pdf/2303.04689v3.pdf","comment":"Accepted for publication in the ACM Transactions on Recommender\n  Systems (TORS) Special Issue on Trustworthy Recommender Systems"},{"id":"http://arxiv.org/abs/2311.14063v1","updated":"2023-11-23T15:42:00Z","published":"2023-11-23T15:42:00Z","title":"Do VSR Models Generalize Beyond LRS3?","summary":"  The Lip Reading Sentences-3 (LRS3) benchmark has primarily been the focus of\nintense research in visual speech recognition (VSR) during the last few years.\nAs a result, there is an increased risk of overfitting to its excessively used\ntest set, which is only one hour duration. To alleviate this issue, we build a\nnew VSR test set named WildVSR, by closely following the LRS3 dataset creation\nprocesses. We then evaluate and analyse the extent to which the current VSR\nmodels generalize to the new test data. We evaluate a broad range of publicly\navailable VSR models and find significant drops in performance on our test set,\ncompared to their corresponding LRS3 results. Our results suggest that the\nincrease in word error rates is caused by the models inability to generalize to\nslightly harder and in the wild lip sequences than those found in the LRS3 test\nset. Our new test benchmark is made public in order to enable future research\ntowards more robust VSR models.\n","authors":["Yasser Abdelaziz Dahou Djilali","Sanath Narayan","Eustache Le Bihan","Haithem Boussaid","Ebtessam Almazrouei","Merouane Debbah"],"pdf_url":"https://arxiv.org/pdf/2311.14063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14056v1","updated":"2023-11-23T15:19:30Z","published":"2023-11-23T15:19:30Z","title":"DPSUR: Accelerating Differentially Private Stochastic Gradient Descent\n  Using Selective Update and Release","summary":"  Machine learning models are known to memorize private data to reduce their\ntraining loss, which can be inadvertently exploited by privacy attacks such as\nmodel inversion and membership inference. To protect against these attacks,\ndifferential privacy (DP) has become the de facto standard for\nprivacy-preserving machine learning, particularly those popular training\nalgorithms using stochastic gradient descent, such as DPSGD. Nonetheless, DPSGD\nstill suffers from severe utility loss due to its slow convergence. This is\npartially caused by the random sampling, which brings bias and variance to the\ngradient, and partially by the Gaussian noise, which leads to fluctuation of\ngradient updates.\n  Our key idea to address these issues is to apply selective updates to the\nmodel training, while discarding those useless or even harmful updates.\nMotivated by this, this paper proposes DPSUR, a Differentially Private training\nframework based on Selective Updates and Release, where the gradient from each\niteration is evaluated based on a validation test, and only those updates\nleading to convergence are applied to the model. As such, DPSUR ensures the\ntraining in the right direction and thus can achieve faster convergence than\nDPSGD. The main challenges lie in two aspects -- privacy concerns arising from\ngradient evaluation, and gradient selection strategy for model update. To\naddress the challenges, DPSUR introduces a clipping strategy for update\nrandomization and a threshold mechanism for gradient selection. Experiments\nconducted on MNIST, FMNIST, CIFAR-10, and IMDB datasets show that DPSUR\nsignificantly outperforms previous works in terms of convergence speed and\nmodel utility.\n","authors":["Jie Fu","Qingqing Ye","Haibo Hu","Zhili Chen","Lulu Wang","Kuncan Wang","Ran Xun"],"pdf_url":"https://arxiv.org/pdf/2311.14056v1.pdf","comment":"This paper has been accepted by VLDB 2024"},{"id":"http://arxiv.org/abs/2301.11873v4","updated":"2023-11-23T15:07:41Z","published":"2023-01-27T17:27:07Z","title":"A Deep Learning Method for Comparing Bayesian Hierarchical Models","summary":"  Bayesian model comparison (BMC) offers a principled approach for assessing\nthe relative merits of competing computational models and propagating\nuncertainty into model selection decisions. However, BMC is often intractable\nfor the popular class of hierarchical models due to their high-dimensional\nnested parameter structure. To address this intractability, we propose a deep\nlearning method for performing BMC on any set of hierarchical models which can\nbe instantiated as probabilistic programs. Since our method enables amortized\ninference, it allows efficient re-estimation of posterior model probabilities\nand fast performance validation prior to any real-data application. In a series\nof extensive validation studies, we benchmark the performance of our method\nagainst the state-of-the-art bridge sampling method and demonstrate excellent\namortized inference across all BMC settings. We then showcase our method by\ncomparing four hierarchical evidence accumulation models that have previously\nbeen deemed intractable for BMC due to partly implicit likelihoods.\nAdditionally, we demonstrate how transfer learning can be leveraged to enhance\ntraining efficiency. We provide reproducible code for all analyses and an\nopen-source implementation of our method.\n","authors":["Lasse Elsemüller","Martin Schnuerch","Paul-Christian Bürkner","Stefan T. Radev"],"pdf_url":"https://arxiv.org/pdf/2301.11873v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.11792v2","updated":"2023-11-23T14:56:37Z","published":"2023-08-22T21:14:57Z","title":"Karasu: A Collaborative Approach to Efficient Cluster Configuration for\n  Big Data Analytics","summary":"  Selecting the right resources for big data analytics jobs is hard because of\nthe wide variety of configuration options like machine type and cluster size.\nAs poor choices can have a significant impact on resource efficiency, cost, and\nenergy usage, automated approaches are gaining popularity. Most existing\nmethods rely on profiling recurring workloads to find near-optimal solutions\nover time. Due to the cold-start problem, this often leads to lengthy and\ncostly profiling phases. However, big data analytics jobs across users can\nshare many common properties: they often operate on similar infrastructure,\nusing similar algorithms implemented in similar frameworks. The potential in\nsharing aggregated profiling runs to collaboratively address the cold start\nproblem is largely unexplored.\n  We present Karasu, an approach to more efficient resource configuration\nprofiling that promotes data sharing among users working with similar\ninfrastructures, frameworks, algorithms, or datasets. Karasu trains lightweight\nperformance models using aggregated runtime information of collaborators and\ncombines them into an ensemble method to exploit inherent knowledge of the\nconfiguration search space. Moreover, Karasu allows the optimization of\nmultiple objectives simultaneously. Our evaluation is based on performance data\nfrom diverse workload executions in a public cloud environment. We show that\nKarasu is able to significantly boost existing methods in terms of performance,\nsearch time, and cost, even when few comparable profiling runs are available\nthat share only partial common characteristics with the target job.\n","authors":["Dominik Scheinert","Philipp Wiesner","Thorsten Wittkopp","Lauritz Thamsen","Jonathan Will","Odej Kao"],"pdf_url":"https://arxiv.org/pdf/2308.11792v2.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2311.10049v2","updated":"2023-11-23T14:46:49Z","published":"2023-11-16T17:45:37Z","title":"Inherently Interpretable Time Series Classification via Multiple\n  Instance Learning","summary":"  Conventional Time Series Classification (TSC) methods are often black boxes\nthat obscure inherent interpretation of their decision-making processes. In\nthis work, we leverage Multiple Instance Learning (MIL) to overcome this issue,\nand propose a new framework called MILLET: Multiple Instance Learning for\nLocally Explainable Time series classification. We apply MILLET to existing\ndeep learning TSC models and show how they become inherently interpretable\nwithout compromising (and in some cases, even improving) predictive\nperformance. We evaluate MILLET on 85 UCR TSC datasets and also present a novel\nsynthetic dataset that is specially designed to facilitate interpretability\nevaluation. On these datasets, we show MILLET produces sparse explanations\nquickly that are of higher quality than other well-known interpretability\nmethods. To the best of our knowledge, our work with MILLET, which is available\non GitHub (https://github.com/JAEarly/MILTimeSeriesClassification), is the\nfirst to develop general MIL methods for TSC and apply them to an extensive\nvariety of domains\n","authors":["Joseph Early","Gavin KC Cheung","Kurt Cutajar","Hanting Xie","Jas Kandola","Niall Twomey"],"pdf_url":"https://arxiv.org/pdf/2311.10049v2.pdf","comment":"Preprint. Under submission at ICLR 2024. 29 pages (9 main, 3 ref, 17\n  appendix)"},{"id":"http://arxiv.org/abs/2310.11122v3","updated":"2023-11-23T14:45:13Z","published":"2023-10-17T10:14:10Z","title":"Sensitivity-Aware Amortized Bayesian Inference","summary":"  Bayesian inference is a powerful framework for making probabilistic\ninferences and decisions under uncertainty. Fundamental choices in modern\nBayesian workflows concern the specification of the likelihood function and\nprior distributions, the posterior approximator, and the data. Each choice can\nsignificantly influence model-based inference and subsequent decisions, thereby\nnecessitating sensitivity analysis. In this work, we propose a multifaceted\napproach to integrate sensitivity analyses into amortized Bayesian inference\n(ABI, i.e., simulation-based inference with neural networks). First, we utilize\nweight sharing to encode the structural similarities between alternative\nlikelihood and prior specifications in the training process with minimal\ncomputational overhead. Second, we leverage the rapid inference of neural\nnetworks to assess sensitivity to various data perturbations or pre-processing\nprocedures. In contrast to most other Bayesian approaches, both steps\ncircumvent the costly bottleneck of refitting the model(s) for each choice of\nlikelihood, prior, or dataset. Finally, we propose to use neural network\nensembles to evaluate variation in results induced by unreliable approximation\non unseen data. We demonstrate the effectiveness of our method in applied\nmodeling problems, ranging from the estimation of disease outbreak dynamics and\nglobal warming thresholds to the comparison of human decision-making models.\nOur experiments showcase how our approach enables practitioners to effectively\nunveil hidden relationships between modeling choices and inferential\nconclusions.\n","authors":["Lasse Elsemüller","Hans Olischläger","Marvin Schmitt","Paul-Christian Bürkner","Ullrich Köthe","Stefan T. Radev"],"pdf_url":"https://arxiv.org/pdf/2310.11122v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14037v1","updated":"2023-11-23T14:42:43Z","published":"2023-11-23T14:42:43Z","title":"AdapterFL: Adaptive Heterogeneous Federated Learning for\n  Resource-constrained Mobile Computing Systems","summary":"  Federated Learning (FL) enables collaborative learning of large-scale\ndistributed clients without data sharing. However, due to the disparity of\ncomputing resources among massive mobile computing devices, the performance of\ntraditional homogeneous model-based Federated Learning (FL) is seriously\nlimited. On the one hand, to achieve model training in all the diverse clients,\nmobile computing systems can only use small low-performance models for\ncollaborative learning. On the other hand, devices with high computing\nresources cannot train a high-performance large model with their insufficient\nraw data. To address the resource-constrained problem in mobile computing\nsystems, we present a novel heterogeneous FL approach named AdapterFL, which\nuses a model reassemble strategy to facilitate collaborative training of\nmassive heterogeneous mobile devices adaptively. Specifically, we select\nmultiple candidate heterogeneous models based on the computing performance of\nmassive mobile devices and then divide each heterogeneous model into two\npartitions. By reassembling the partitions, we can generate models with varied\nsizes that are combined by the partial parameters of the large model with the\npartial parameters of the small model. Using these reassembled models for FL\ntraining, we can train the partial parameters of the large model using\nlow-performance devices. In this way, we can alleviate performance degradation\nin large models due to resource constraints. The experimental results show that\nAdapterFL can achieve up to 12\\% accuracy improvement compared to the\nstate-of-the-art heterogeneous federated learning methods in\nresource-constrained scenarios.\n","authors":["Ruixuan Liu","Ming Hu","Zeke Xia","Jun Xia","Pengyu Zhang","Yihao Huang","Yang Liu","Mingsong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.14037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14033v1","updated":"2023-11-23T14:38:10Z","published":"2023-11-23T14:38:10Z","title":"Multivariate Scenario Generation of Day-Ahead Electricity Prices using\n  Normalizing Flows","summary":"  Trading on electricity markets requires accurate information about the\nrealization of electricity prices and the uncertainty attached to the\npredictions. We present a probabilistic forecasting approach for day-ahead\nelectricity prices using the fully data-driven deep generative model called\nnormalizing flows. Our modeling approach generates full-day scenarios of\nday-ahead electricity prices based on conditional features such as residual\nload forecasts. Furthermore, we propose extended feature sets of prior\nrealizations and a periodic retraining scheme that allows the normalizing flow\nto adapt to the changing conditions of modern electricity markets. In\nparticular, we investigate the impact of the energy crisis ensuing from the\nRussian invasion of Ukraine. Our results highlight that the normalizing flow\ngenerates high-quality scenarios that reproduce the true price distribution and\nyield highly accurate forecasts. Additionally, our analysis highlights how our\nimprovements towards adaptations in changing regimes allow the normalizing flow\nto adapt to changing market conditions and enables continued sampling of\nhigh-quality day-ahead price scenarios.\n","authors":["Hannes Hilger","Dirk Witthaut","Manuel Dahmen","Leonardo Rydin Gorjao","Julius Trebbien","Eike Cramer"],"pdf_url":"https://arxiv.org/pdf/2311.14033v1.pdf","comment":"15 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.14029v1","updated":"2023-11-23T14:33:53Z","published":"2023-11-23T14:33:53Z","title":"Understanding the Vulnerability of CLIP to Image Compression","summary":"  CLIP is a widely used foundational vision-language model that is used for\nzero-shot image recognition and other image-text alignment tasks. We\ndemonstrate that CLIP is vulnerable to change in image quality under\ncompression. This surprising result is further analysed using an attribution\nmethod-Integrated Gradients. Using this attribution method, we are able to\nbetter understand both quantitatively and qualitatively exactly the nature in\nwhich the compression affects the zero-shot recognition accuracy of this model.\nWe evaluate this extensively on CIFAR-10 and STL-10. Our work provides the\nbasis to understand this vulnerability of CLIP and can help us develop more\neffective methods to improve the robustness of CLIP and other vision-language\nmodels.\n","authors":["Cangxiong Chen","Vinay P. Namboodiri","Julian Padget"],"pdf_url":"https://arxiv.org/pdf/2311.14029v1.pdf","comment":"R0-FoMo: Workshop on Robustness of Few-shot and Zero-shot Learning in\n  Foundation Models at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.14028v1","updated":"2023-11-23T14:33:03Z","published":"2023-11-23T14:33:03Z","title":"Continual Learning of Diffusion Models with Generative Distillation","summary":"  Diffusion models are powerful generative models that achieve state-of-the-art\nperformance in tasks such as image synthesis. However, training them demands\nsubstantial amounts of data and computational resources. Continual learning\nwould allow for incrementally learning new tasks and accumulating knowledge,\nthus reusing already trained models would be possible. One potentially suitable\napproach is generative replay, where a copy of a generative model trained on\nprevious tasks produces synthetic data that are interleaved with data from the\ncurrent task. However, standard generative replay applied to diffusion models\nresults in a catastrophic loss in denoising capabilities. In this paper, we\npropose generative distillation, an approach that distils the entire reverse\nprocess of a diffusion model. We demonstrate that our approach significantly\nimproves the continual learning performance of generative replay with only a\nmoderate increase in the computational costs.\n","authors":["Sergi Masip","Pau Rodriguez","Tinne Tuytelaars","Gido M. van de Ven"],"pdf_url":"https://arxiv.org/pdf/2311.14028v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14024v1","updated":"2023-11-23T14:28:28Z","published":"2023-11-23T14:28:28Z","title":"Creating and Benchmarking a Synthetic Dataset for Cloud Optical\n  Thickness Estimation","summary":"  Cloud formations often obscure optical satellite-based monitoring of the\nEarth's surface, thus limiting Earth observation (EO) activities such as land\ncover mapping, ocean color analysis, and cropland monitoring. The integration\nof machine learning (ML) methods within the remote sensing domain has\nsignificantly improved performance on a wide range of EO tasks, including cloud\ndetection and filtering, but there is still much room for improvement. A key\nbottleneck is that ML methods typically depend on large amounts of annotated\ndata for training, which is often difficult to come by in EO contexts. This is\nespecially true for the task of cloud optical thickness (COT) estimation. A\nreliable estimation of COT enables more fine-grained and application-dependent\ncontrol compared to using pre-specified cloud categories, as is commonly done\nin practice. To alleviate the COT data scarcity problem, in this work we\npropose a novel synthetic dataset for COT estimation, where top-of-atmosphere\nradiances have been simulated for 12 of the spectral bands of the\nMulti-Spectral Instrument (MSI) sensor onboard Sentinel-2 platforms. These data\npoints have been simulated under consideration of different cloud types, COTs,\nand ground surface and atmospheric profiles. Extensive experimentation of\ntraining several ML models to predict COT from the measured reflectivity of the\nspectral bands demonstrates the usefulness of our proposed dataset.\nGeneralization to real data is also demonstrated on two satellite image\ndatasets -- one that is publicly available, and one which we have collected and\nannotated. The synthetic data, the newly collected real dataset, code and\nmodels have been made publicly available at\nhttps://github.com/aleksispi/ml-cloud-opt-thick.\n","authors":["Aleksis Pirinen","Nosheen Abid","Nuria Agues Paszkowsky","Thomas Ohlson Timoudas","Ronald Scheirer","Chiara Ceccobello","György Kovács","Anders Persson"],"pdf_url":"https://arxiv.org/pdf/2311.14024v1.pdf","comment":"Code, data and models available at\n  https://github.com/aleksispi/ml-cloud-opt-thick"},{"id":"http://arxiv.org/abs/2311.14014v1","updated":"2023-11-23T14:11:01Z","published":"2023-11-23T14:11:01Z","title":"On the Hyperparameter Landscapes of Machine Learning Algorithms","summary":"  Despite the recent success in a plethora of hyperparameter optimization (HPO)\nmethods for machine learning (ML) models, the intricate interplay between model\nhyperparameters (HPs) and predictive losses (a.k.a fitness), which is a key\nprerequisite for understanding HPO, remain notably underexplored in our\ncommunity. This results in limited explainability in the HPO process, rendering\na lack of human trust and difficulties in pinpointing algorithm bottlenecks. In\nthis paper, we aim to shed light on this black box by conducting large-scale\nfitness landscape analysis (FLA) on 1,500 HP loss landscapes of 6 ML models\nwith more than 11 model configurations, across 67 datasets and different levels\nof fidelities. We reveal the first unified, comprehensive portrait of their\ntopographies in terms of smoothness, neutrality and modality. We also show that\nsuch properties are highly transferable across datasets and fidelities,\nproviding fundamental evidence for the success of multi-fidelity and transfer\nlearning methods. These findings are made possible by developing a dedicated\nFLA framework that incorporates a combination of visual and quantitative\nmeasures. We further demonstrate the potential of this framework by analyzing\nthe NAS-Bench-101 landscape, and we believe it is able to faciliate fundamental\nunderstanding of a broader range of AutoML tasks.\n","authors":["Mingyu Huang","Ke Li"],"pdf_url":"https://arxiv.org/pdf/2311.14014v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13988v1","updated":"2023-11-23T13:14:31Z","published":"2023-11-23T13:14:31Z","title":"Docking Multirotors in Close Proximity using Learnt Downwash Models","summary":"  Unmodeled aerodynamic disturbances pose a key challenge for multirotor flight\nwhen multiple vehicles are in close proximity to each other. However, certain\nmissions \\textit{require} two multirotors to approach each other within 1-2\nbody-lengths of each other and hold formation -- we consider one such practical\ninstance: vertically docking two multirotors in the air. In this\nleader-follower setting, the follower experiences significant downwash\ninterference from the leader in its final docking stages. To compensate for\nthis, we employ a learnt downwash model online within an optimal feedback\ncontroller to accurately track a docking maneuver and then hold formation.\nThrough real-world flights with different maneuvers, we demonstrate that this\ncompensation is crucial for reducing the large vertical separation otherwise\nrequired by conventional/naive approaches. Our evaluations show a tracking\nerror of less than 0.06m for the follower (a 3-4x reduction) when approaching\nvertically within two body-lengths of the leader. Finally, we deploy the\ncomplete system to effect a successful physical docking between two airborne\nmultirotors in a single smooth planned trajectory.\n","authors":["Ajay Shankar","Heedo Woo","Amanda Prorok"],"pdf_url":"https://arxiv.org/pdf/2311.13988v1.pdf","comment":"Presented at International Symposium on Experimental Robotics (ISER)\n  2023"},{"id":"http://arxiv.org/abs/2311.13987v1","updated":"2023-11-23T13:13:48Z","published":"2023-11-23T13:13:48Z","title":"Jam-ALT: A Formatting-Aware Lyrics Transcription Benchmark","summary":"  Current automatic lyrics transcription (ALT) benchmarks focus exclusively on\nword content and ignore the finer nuances of written lyrics including\nformatting and punctuation, which leads to a potential misalignment with the\ncreative products of musicians and songwriters as well as listeners'\nexperiences. For example, line breaks are important in conveying information\nabout rhythm, emotional emphasis, rhyme, and high-level structure. To address\nthis issue, we introduce Jam-ALT, a new lyrics transcription benchmark based on\nthe JamendoLyrics dataset. Our contribution is twofold. Firstly, a complete\nrevision of the transcripts, geared specifically towards ALT evaluation by\nfollowing a newly created annotation guide that unifies the music industry's\nguidelines, covering aspects such as punctuation, line breaks, spelling,\nbackground vocals, and non-word sounds. Secondly, a suite of evaluation metrics\ndesigned, unlike the traditional word error rate, to capture such phenomena. We\nhope that the proposed benchmark contributes to the ALT task, enabling more\nprecise and reliable assessments of transcription systems and enhancing the\nuser experience in lyrics applications such as subtitle renderings for live\ncaptioning or karaoke.\n","authors":["Ondřej Cífka","Constantinos Dimitriou","Cheng-i Wang","Hendrik Schreiber","Luke Miner","Fabian-Robert Stöter"],"pdf_url":"https://arxiv.org/pdf/2311.13987v1.pdf","comment":"6 pages (3 pages main content); website:\n  https://audioshake.github.io/jam-alt/; data:\n  https://huggingface.co/datasets/audioshake/jam-alt; code:\n  https://github.com/audioshake/alt-eval/"},{"id":"http://arxiv.org/abs/2311.13983v1","updated":"2023-11-23T12:55:10Z","published":"2023-11-23T12:55:10Z","title":"Learning Dynamic Selection and Pricing of Out-of-Home Deliveries","summary":"  Home delivery failures, traffic congestion, and relatively large handling\ntimes have a negative impact on the profitability of last-mile logistics. These\nexternal factors contribute to up to $28\\%$ of the overall costs and $25\\%$ of\nemissions for the home delivery supply chain. A potential solution, showing\nannual growth rates up to $36\\%$, is the delivery to parcel lockers or parcel\nshops, denoted by out-of-home (OOH) delivery. In the academic literature,\nmodels of customer behavior with respect to OOH delivery were so far limited to\ndeterministic settings, contrasting with the stochastic nature of actual\ncustomer choices. We model the sequential decision-making problem of which OOH\nlocation to offer against what incentive for each incoming customer, taking\ninto account future customer arrivals and choices. We propose Dynamic Selection\nand Pricing of OOH (DSPO), an algorithmic pipeline that uses a novel\nspatial-temporal state encoding as input to a convolutional neural network. We\ndemonstrate the performance of our method by benchmarking it against three\nstate-of-the-art approaches. Our extensive numerical study, guided by\nreal-world data, reveals that DSPO can save $20.8\\%$ in costs compared to a\nsituation without OOH locations, $8.1\\%$ compared to a static selection and\npricing policy, and $4.6\\%$ compared to a state-of-the-art demand management\nbenchmark. We provide comprehensive insights into the complex interplay between\nOOH delivery dynamics and customer behavior influenced by pricing strategies.\nThe implications of our findings suggest practitioners to adopt dynamic\nselection and pricing policies as OOH delivery gains a larger market share.\n","authors":["Fabian Akkerman","Peter Dieter","Martijn Mes"],"pdf_url":"https://arxiv.org/pdf/2311.13983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.11952v2","updated":"2023-11-23T12:54:39Z","published":"2022-05-24T10:32:32Z","title":"3D helical CT Reconstruction with a Memory Efficient Learned Primal-Dual\n  Architecture","summary":"  Deep learning based computed tomography (CT) reconstruction has demonstrated\noutstanding performance on simulated 2D low-dose CT data. This applies in\nparticular to domain adapted neural networks, which incorporate a handcrafted\nphysics model for CT imaging. Empirical evidence shows that employing such\narchitectures reduces the demand for training data and improves upon\ngeneralisation. However, their training requires large computational resources\nthat quickly become prohibitive in 3D helical CT, which is the most common\nacquisition geometry used for medical imaging. Furthermore, clinical data also\ncomes with other challenges not accounted for in simulations, like errors in\nflux measurement, resolution mismatch and, most importantly, the absence of the\nreal ground truth. The necessity to have a computationally feasible training\ncombined with the need to address these issues has made it difficult to\nevaluate deep learning based reconstruction on clinical 3D helical CT. This\npaper modifies a domain adapted neural network architecture, the Learned\nPrimal-Dual (LPD), so that it can be trained and applied to reconstruction in\nthis setting. We achieve this by splitting the helical trajectory into sections\nand applying the unrolled LPD iterations to those sections sequentially. To the\nbest of our knowledge, this work is the first to apply an unrolled deep\nlearning architecture for reconstruction on full-sized clinical data, like\nthose in the Low dose CT image and projection data set (LDCT). Moreover,\ntraining and testing is done on a single GPU card with 24GB of memory.\n","authors":["Jevgenija Rudzusika","Buda Bajić","Thomas Koehler","Ozan Öktem"],"pdf_url":"https://arxiv.org/pdf/2205.11952v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13978v1","updated":"2023-11-23T12:47:43Z","published":"2023-11-23T12:47:43Z","title":"MedISure: Towards Assuring Machine Learning-based Medical Image\n  Classifiers using Mixup Boundary Analysis","summary":"  Machine learning (ML) models are becoming integral in healthcare\ntechnologies, presenting a critical need for formal assurance to validate their\nsafety, fairness, robustness, and trustworthiness. These models are inherently\nprone to errors, potentially posing serious risks to patient health and could\neven cause irreparable harm. Traditional software assurance techniques rely on\nfixed code and do not directly apply to ML models since these algorithms are\nadaptable and learn from curated datasets through a training process. However,\nadapting established principles, such as boundary testing using synthetic test\ndata can effectively bridge this gap. To this end, we present a novel technique\ncalled Mix-Up Boundary Analysis (MUBA) that facilitates evaluating image\nclassifiers in terms of prediction fairness. We evaluated MUBA for two\nimportant medical imaging tasks -- brain tumour classification and breast\ncancer classification -- and achieved promising results. This research aims to\nshowcase the importance of adapting traditional assurance principles for\nassessing ML models to enhance the safety and reliability of healthcare\ntechnologies. To facilitate future research, we plan to publicly release our\ncode for MUBA.\n","authors":["Adam Byfield","William Poulett","Ben Wallace","Anusha Jose","Shatakshi Tyagi","Smita Shembekar","Adnan Qayyum","Junaid Qadir","Muhammad Bilal"],"pdf_url":"https://arxiv.org/pdf/2311.13978v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10642v2","updated":"2023-11-23T12:47:26Z","published":"2023-11-17T16:58:52Z","title":"Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as\n  an Alternative to Attention Layers in Transformers","summary":"  This work presents an analysis of the effectiveness of using standard shallow\nfeed-forward networks to mimic the behavior of the attention mechanism in the\noriginal Transformer model, a state-of-the-art architecture for\nsequence-to-sequence tasks. We substitute key elements of the attention\nmechanism in the Transformer with simple feed-forward networks, trained using\nthe original components via knowledge distillation. Our experiments, conducted\non the IWSLT2017 dataset, reveal the capacity of these \"attentionless\nTransformers\" to rival the performance of the original architecture. Through\nrigorous ablation studies, and experimenting with various replacement network\ntypes and sizes, we offer insights that support the viability of our approach.\nThis not only sheds light on the adaptability of shallow feed-forward networks\nin emulating attention mechanisms but also underscores their potential to\nstreamline complex architectures for sequence-to-sequence tasks.\n","authors":["Vukasin Bozic","Danilo Dordevic","Daniele Coppola","Joseph Thommes","Sidak Pal Singh"],"pdf_url":"https://arxiv.org/pdf/2311.10642v2.pdf","comment":"Accepted at AAAI24(https://aaai.org/aaai-conference/)"},{"id":"http://arxiv.org/abs/2311.13964v1","updated":"2023-11-23T12:26:08Z","published":"2023-11-23T12:26:08Z","title":"Deep Interactive Segmentation of Medical Images: A Systematic Review and\n  Taxonomy","summary":"  Interactive segmentation is a crucial research area in medical image analysis\naiming to boost the efficiency of costly annotations by incorporating human\nfeedback. This feedback takes the form of clicks, scribbles, or masks and\nallows for iterative refinement of the model output so as to efficiently guide\nthe system towards the desired behavior. In recent years, deep learning-based\napproaches have propelled results to a new level causing a rapid growth in the\nfield with 121 methods proposed in the medical imaging domain alone. In this\nreview, we provide a structured overview of this emerging field featuring a\ncomprehensive taxonomy, a systematic review of existing methods, and an\nin-depth analysis of current practices. Based on these contributions, we\ndiscuss the challenges and opportunities in the field. For instance, we find\nthat there is a severe lack of comparison across methods which needs to be\ntackled by standardized baselines and benchmarks.\n","authors":["Zdravko Marinov","Paul F. Jäger","Jan Egger","Jens Kleesiek","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2311.13964v1.pdf","comment":"26 pages, 8 figures, 10 tables; Zdravko Marinov and Paul F. J\\\"ager\n  and co-first authors; This work has been submitted to the IEEE for possible\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible"},{"id":"http://arxiv.org/abs/2311.13959v1","updated":"2023-11-23T12:17:45Z","published":"2023-11-23T12:17:45Z","title":"RankFeat\\&RankWeight: Rank-1 Feature/Weight Removal for\n  Out-of-distribution Detection","summary":"  The task of out-of-distribution (OOD) detection is crucial for deploying\nmachine learning models in real-world settings. In this paper, we observe that\nthe singular value distributions of the in-distribution (ID) and OOD features\nare quite different: the OOD feature matrix tends to have a larger dominant\nsingular value than the ID feature, and the class predictions of OOD samples\nare largely determined by it. This observation motivates us to propose\n\\texttt{RankFeat}, a simple yet effective \\emph{post hoc} approach for OOD\ndetection by removing the rank-1 matrix composed of the largest singular value\nand the associated singular vectors from the high-level feature.\n\\texttt{RankFeat} achieves \\emph{state-of-the-art} performance and reduces the\naverage false positive rate (FPR95) by 17.90\\% compared with the previous best\nmethod. The success of \\texttt{RankFeat} motivates us to investigate whether a\nsimilar phenomenon would exist in the parameter matrices of neural networks. We\nthus propose \\texttt{RankWeight} which removes the rank-1 weight from the\nparameter matrices of a single deep layer. Our \\texttt{RankWeight}is also\n\\emph{post hoc} and only requires computing the rank-1 matrix once. As a\nstandalone approach, \\texttt{RankWeight} has very competitive performance\nagainst other methods across various backbones. Moreover, \\texttt{RankWeight}\nenjoys flexible compatibility with a wide range of OOD detection methods. The\ncombination of \\texttt{RankWeight} and \\texttt{RankFeat} refreshes the new\n\\emph{state-of-the-art} performance, achieving the FPR95 as low as 16.13\\% on\nthe ImageNet-1k benchmark. Extensive ablation studies and comprehensive\ntheoretical analyses are presented to support the empirical results.\n","authors":["Yue Song","Nicu Sebe","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13959v1.pdf","comment":"submitted to T-PAMI"},{"id":"http://arxiv.org/abs/2311.13958v1","updated":"2023-11-23T12:16:33Z","published":"2023-11-23T12:16:33Z","title":"High-Order Tensor Recovery with A Tensor $U_1$ Norm","summary":"  Recently, numerous tensor SVD (t-SVD)-based tensor recovery methods have\nemerged, showing promise in processing visual data. However, these methods\noften suffer from performance degradation when confronted with high-order\ntensor data exhibiting non-smooth changes, commonly observed in real-world\nscenarios but ignored by the traditional t-SVD-based methods. Our objective in\nthis study is to provide an effective tensor recovery technique for handling\nnon-smooth changes in tensor data and efficiently explore the correlations of\nhigh-order tensor data across its various dimensions without introducing\nnumerous variables and weights. To this end, we introduce a new tensor\ndecomposition and a new tensor norm called the Tensor $U_1$ norm. We utilize\nthese novel techniques in solving the problem of high-order tensor completion\nproblem and provide theoretical guarantees for the exact recovery of the\nresulting tensor completion models. An optimization algorithm is proposed to\nsolve the resulting tensor completion model iteratively by combining the\nproximal algorithm with the Alternating Direction Method of Multipliers.\nTheoretical analysis showed the convergence of the algorithm to the\nKarush-Kuhn-Tucker (KKT) point of the optimization problem. Numerical\nexperiments demonstrated the effectiveness of the proposed method in high-order\ntensor completion, especially for tensor data with non-smooth changes.\n","authors":["Jingjing Zheng","Wenzhe Wang","Xiaoqin Zhang","Yankai Cao","Xianta Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.13958v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13953v1","updated":"2023-11-23T12:08:20Z","published":"2023-11-23T12:08:20Z","title":"Learning Uniform Clusters on Hypersphere for Deep Graph-level Clustering","summary":"  Graph clustering has been popularly studied in recent years. However, most\nexisting graph clustering methods focus on node-level clustering, i.e.,\ngrouping nodes in a single graph into clusters. In contrast, graph-level\nclustering, i.e., grouping multiple graphs into clusters, remains largely\nunexplored. Graph-level clustering is critical in a variety of real-world\napplications, such as, properties prediction of molecules and community\nanalysis in social networks. However, graph-level clustering is challenging due\nto the insufficient discriminability of graph-level representations, and the\ninsufficient discriminability makes deep clustering be more likely to obtain\ndegenerate solutions (cluster collapse). To address the issue, we propose a\nnovel deep graph-level clustering method called Uniform Deep Graph Clustering\n(UDGC). UDGC assigns instances evenly to different clusters and then scatters\nthose clusters on unit hypersphere, leading to a more uniform cluster-level\ndistribution and a slighter cluster collapse. Specifically, we first propose\nAugmentation-Consensus Optimal Transport (ACOT) for generating uniformly\ndistributed and reliable pseudo labels for partitioning clusters. Then we adopt\ncontrastive learning to scatter those clusters. Besides, we propose Center\nAlignment Optimal Transport (CAOT) for guiding the model to learn better\nparameters, which further promotes the cluster performance. Our empirical study\non eight well-known datasets demonstrates that UDGC significantly outperforms\nthe state-of-the-art models.\n","authors":["Mengling Hu","Chaochao Chen","Weiming Liu","Xinyi Zhang","Xinting Liao","Xiaolin Zheng"],"pdf_url":"https://arxiv.org/pdf/2311.13953v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13950v1","updated":"2023-11-23T12:03:02Z","published":"2023-11-23T12:03:02Z","title":"Object Location Prediction in Real-time using LSTM Neural Network and\n  Polynomial Regression","summary":"  This paper details the design and implementation of a system for predicting\nand interpolating object location coordinates. Our solution is based on\nprocessing inertial measurements and global positioning system data through a\nLong Short-Term Memory (LSTM) neural network and polynomial regression. LSTM is\na type of recurrent neural network (RNN) particularly suited for processing\ndata sequences and avoiding the long-term dependency problem. We employed data\nfrom real-world vehicles and the global positioning system (GPS) sensors. A\ncritical pre-processing step was developed to address varying sensor\nfrequencies and inconsistent GPS time steps and dropouts. The LSTM-based\nsystem's performance was compared with the Kalman Filter. The system was tuned\nto work in real-time with low latency and high precision. We tested our system\non roads under various driving conditions, including acceleration, turns,\ndeceleration, and straight paths. We tested our proposed solution's accuracy\nand inference time and showed that it could perform in real-time. Our\nLSTM-based system yielded an average error of 0.11 meters with an inference\ntime of 2 ms. This represents a 76\\% reduction in error compared to the\ntraditional Kalman filter method, which has an average error of 0.46 meters\nwith a similar inference time to the LSTM-based system.\n","authors":["Petar Stojković","Predrag Tadić"],"pdf_url":"https://arxiv.org/pdf/2311.13950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13949v1","updated":"2023-11-23T12:02:58Z","published":"2023-11-23T12:02:58Z","title":"Optimal Power Flow in Highly Renewable Power System Based on Attention\n  Neural Networks","summary":"  The Optimal Power Flow (OPF) problem is pivotal for power system operations,\nguiding generator output and power distribution to meet demand at minimized\ncosts, while adhering to physical and engineering constraints. The integration\nof renewable energy sources, like wind and solar, however, poses challenges due\nto their inherent variability. This variability, driven largely by changing\nweather conditions, demands frequent recalibrations of power settings, thus\nnecessitating recurrent OPF resolutions. This task is daunting using\ntraditional numerical methods, particularly for extensive power systems. In\nthis work, we present a cutting-edge, physics-informed machine learning\nmethodology, trained using imitation learning and historical European weather\ndatasets. Our approach directly correlates electricity demand and weather\npatterns with power dispatch and generation, circumventing the iterative\nrequirements of traditional OPF solvers. This offers a more expedient solution\napt for real-time applications. Rigorous evaluations on aggregated European\npower systems validate our method's superiority over existing data-driven\ntechniques in OPF solving. By presenting a quick, robust, and efficient\nsolution, this research sets a new standard in real-time OPF resolution, paving\nthe way for more resilient power systems in the era of renewable energy.\n","authors":["Chen Li","Alexander Kies","Kai Zhou","Markus Schlott","Omar El Sayed","Mariia Bilousova","Horst Stoecker"],"pdf_url":"https://arxiv.org/pdf/2311.13949v1.pdf","comment":"Submitted to Elsevier"},{"id":"http://arxiv.org/abs/2304.05390v2","updated":"2023-11-23T11:45:02Z","published":"2023-04-11T17:59:13Z","title":"HRS-Bench: Holistic, Reliable and Scalable Benchmark for Text-to-Image\n  Models","summary":"  In recent years, Text-to-Image (T2I) models have been extensively studied,\nespecially with the emergence of diffusion models that achieve state-of-the-art\nresults on T2I synthesis tasks. However, existing benchmarks heavily rely on\nsubjective human evaluation, limiting their ability to holistically assess the\nmodel's capabilities. Furthermore, there is a significant gap between efforts\nin developing new T2I architectures and those in evaluation. To address this,\nwe introduce HRS-Bench, a concrete evaluation benchmark for T2I models that is\nHolistic, Reliable, and Scalable. Unlike existing bench-marks that focus on\nlimited aspects, HRS-Bench measures 13 skills that can be categorized into five\nmajor categories: accuracy, robustness, generalization, fairness, and bias. In\naddition, HRS-Bench covers 50 scenarios, including fashion, animals,\ntransportation, food, and clothes. We evaluate nine recent large-scale T2I\nmodels using metrics that cover a wide range of skills. A human evaluation\naligned with 95% of our evaluations on average was conducted to probe the\neffectiveness of HRS-Bench. Our experiments demonstrate that existing models\noften struggle to generate images with the desired count of objects, visual\ntext, or grounded emotions. We hope that our benchmark help ease future\ntext-to-image generation research. The code and data are available at\nhttps://eslambakr.github.io/hrsbench.github.io\n","authors":["Eslam Mohamed Bakr","Pengzhan Sun","Xiaoqian Shen","Faizan Farooq Khan","Li Erran Li","Mohamed Elhoseiny"],"pdf_url":"https://arxiv.org/pdf/2304.05390v2.pdf","comment":"ICCV 2023"},{"id":"http://arxiv.org/abs/2311.05788v2","updated":"2023-11-23T11:29:11Z","published":"2023-11-09T23:33:31Z","title":"Structured Transforms Across Spaces with Cost-Regularized Optimal\n  Transport","summary":"  Matching a source to a target probability measure is often solved by\ninstantiating a linear optimal transport (OT) problem, parameterized by a\nground cost function that quantifies discrepancy between points. When these\nmeasures live in the same metric space, the ground cost often defaults to its\ndistance. When instantiated across two different spaces, however, choosing that\ncost in the absence of aligned data is a conundrum. As a result, practitioners\noften resort to solving instead a quadratic Gromow-Wasserstein (GW) problem. We\nexploit in this work a parallel between GW and cost-regularized OT, the\nregularized minimization of a linear OT objective parameterized by a ground\ncost. We use this cost-regularized formulation to match measures across two\ndifferent Euclidean spaces, where the cost is evaluated between transformed\nsource points and target points. We show that several quadratic OT problems\nfall in this category, and consider enforcing structure in linear transform\n(e.g. sparsity), by introducing structure-inducing regularizers. We provide a\nproximal algorithm to extract such transforms from unaligned data, and\ndemonstrate its applicability to single-cell spatial transcriptomics/multiomics\nmatching tasks.\n","authors":["Othmane Sebbouh","Marco Cuturi","Gabriel Peyré"],"pdf_url":"https://arxiv.org/pdf/2311.05788v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.00542v4","updated":"2023-11-23T11:23:26Z","published":"2021-09-01T16:59:09Z","title":"Shared Certificates for Neural Network Verification","summary":"  Existing neural network verifiers compute a proof that each input is handled\ncorrectly under a given perturbation by propagating a symbolic abstraction of\nreachable values at each layer. This process is repeated from scratch\nindependently for each input (e.g., image) and perturbation (e.g., rotation),\nleading to an expensive overall proof effort when handling an entire dataset.\nIn this work, we introduce a new method for reducing this verification cost\nwithout losing precision based on a key insight that abstractions obtained at\nintermediate layers for different inputs and perturbations can overlap or\ncontain each other. Leveraging our insight, we introduce the general concept of\nshared certificates, enabling proof effort reuse across multiple inputs to\nreduce overall verification costs. We perform an extensive experimental\nevaluation to demonstrate the effectiveness of shared certificates in reducing\nthe verification cost on a range of datasets and attack specifications on image\nclassifiers including the popular patch and geometric perturbations. We release\nour implementation at https://github.com/eth-sri/proof-sharing.\n","authors":["Marc Fischer","Christian Sprecher","Dimitar I. Dimitrov","Gagandeep Singh","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2109.00542v4.pdf","comment":"Extended version of our CAV'22 paper"},{"id":"http://arxiv.org/abs/2311.13925v1","updated":"2023-11-23T11:21:40Z","published":"2023-11-23T11:21:40Z","title":"Predicting Recovery or Decease of COVID-19 Patients with Clinical and\n  RT-PCR Using Machine Learning Classification Algorithms","summary":"  The COVID-19 pandemic has disrupted the global economy and people's daily\nlives in unprecedented ways. To make appropriate decisions, it is necessary to\ndiagnose COVID-19 rapidly and accurately. Clinical decision making is\ninfluenced by data collected from patients. With the aid of artificial\nintelligence, COVID-19 has been diagnosed quickly by analyzing symptoms,\npolymerase chain reaction (PCR), computed tomography scans, chest X-rays,\nroutine laboratory blood tests and even cough sounds. Furthermore, these data\ncan be used to predict a patient's morality, although there is a question about\nwhich data makes the most accurate predictions. Therefore, this study consists\nof two parts. Our first objective is to examine whether machine learning\nalgorithms can predict the outcome of COVID-19 cases (recovery or death), based\non the features present in the dataset. In the second part of the research, we\ninvestigated the impact of clinical and RT-PCR on prediction of recovery and\ndecease to determine which one is more reliable. We defined four stages with\ndifferent feature sets and use six machine learning methods to build prediction\nmodel. With an accuracy of 78.7%, random forest showed promising results for\npredicting death and recovery of patients. Based on this, it appears that\nrecovery and decease of patients are predictable using machine learning. For\nsecond objective, results indicate that clinical alone (without using RT-PCR),\ntrained with AdaBoost algorithm, is the most accurate with an accuracy of\n82.1%. This study can provide guidance for medical professionals in the event\nof a crisis or outbreak similar to COVID-19.\n","authors":["Mohammad Dehghani","Zahra Yazdanparast"],"pdf_url":"https://arxiv.org/pdf/2311.13925v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05104v2","updated":"2023-11-23T11:13:07Z","published":"2023-02-10T08:05:19Z","title":"Monte Carlo Neural PDE Solver for Learning PDEs via Probabilistic\n  Representation","summary":"  In scenarios with limited available or high-quality data, training the\nfunction-to-function neural PDE solver in an unsupervised manner is essential.\nHowever, the efficiency and accuracy of existing methods are constrained by the\nproperties of numerical algorithms, such as finite difference and\npseudo-spectral methods, integrated during the training stage. These methods\nnecessitate careful spatiotemporal discretization to achieve reasonable\naccuracy, leading to significant computational challenges and inaccurate\nsimulations, particularly in cases with substantial spatiotemporal variations.\nTo address these limitations, we propose the Monte Carlo Neural PDE Solver\n(MCNP Solver) for training unsupervised neural solvers via the PDEs'\nprobabilistic representation, which regards macroscopic phenomena as ensembles\nof random particles. Compared to other unsupervised methods, MCNP Solver\nnaturally inherits the advantages of the Monte Carlo method, which is robust\nagainst spatiotemporal variations and can tolerate coarse step size. In\nsimulating the random walk of particles, we employ Heun's method for the\nconvection process and calculate the expectation via the probability density\nfunction of neighbouring grid points during the diffusion process. These\ntechniques enhance accuracy and circumvent the computational memory and time\nissues associated with Monte Carlo sampling, offering an improvement over\ntraditional Monte Carlo methods. Our numerical experiments on\nconvection-diffusion, Allen-Cahn, and Navier-Stokes equations demonstrate\nsignificant improvements in accuracy and efficiency compared to other\nunsupervised baselines. The source code will be publicly available at:\nhttps://github.com/optray/MCNP.\n","authors":["Rui Zhang","Qi Meng","Rongchan Zhu","Yue Wang","Wenlei Shi","Shihua Zhang","Zhi-Ming Ma","Tie-Yan Liu"],"pdf_url":"https://arxiv.org/pdf/2302.05104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13917v1","updated":"2023-11-23T11:05:54Z","published":"2023-11-23T11:05:54Z","title":"Exploring the impact of social stress on the adaptive dynamics of\n  COVID-19: Typing the behavior of naïve populations faced with epidemics","summary":"  In the context of natural disasters, human responses inevitably intertwine\nwith natural factors. The COVID-19 pandemic, as a significant stress factor,\nhas brought to light profound variations among different countries in terms of\ntheir adaptive dynamics in addressing the spread of infection outbreaks across\ndifferent regions. This emphasizes the crucial role of cultural characteristics\nin natural disaster analysis. The theoretical understanding of large-scale\nepidemics primarily relies on mean-field kinetic models. However, conventional\nSIR-like models failed to fully explain the observed phenomena at the onset of\nthe COVID-19 outbreak. These phenomena included the unexpected cessation of\nexponential growth, the reaching of plateaus, and the occurrence of multi-wave\ndynamics. In situations where an outbreak of a highly virulent and unfamiliar\ninfection arises, it becomes crucial to respond swiftly at a non-medical level\nto mitigate the negative socio-economic impact. Here we present a theoretical\nexamination of the first wave of the epidemic based on a simple SIRSS model\n(SIR with Social Stress). We conduct an analysis of the socio-cultural features\nof na\\\"ive population behaviors across various countries worldwide. The unique\ncharacteristics of each country/territory are encapsulated in only a few\nconstants within our model, derived from the fitted COVID-19 statistics. These\nconstants also reflect the societal response dynamics to the external stress\nfactor, underscoring the importance of studying the mutual behavior of humanity\nand natural factors during global social disasters. Based on these distinctive\ncharacteristics of specific regions, local authorities can optimize their\nstrategies to effectively combat epidemics until vaccines are developed.\n","authors":["Innokentiy Kastalskiy","Andrei Zinovyev","Evgeny Mirkes","Victor Kazantsev","Alexander N. Gorban"],"pdf_url":"https://arxiv.org/pdf/2311.13917v1.pdf","comment":"27 pages, 15 figures, 1 table, 1 appendix"},{"id":"http://arxiv.org/abs/2311.13912v1","updated":"2023-11-23T11:01:35Z","published":"2023-11-23T11:01:35Z","title":"Expanding the deep-learning model to diagnosis LVNC: Limitations and\n  trade-offs","summary":"  Hyper-trabeculation or non-compaction in the left ventricle of the myocardium\n(LVNC) is a recently classified form of cardiomyopathy. Several methods have\nbeen proposed to quantify the trabeculae accurately in the left ventricle, but\nthere is no general agreement in the medical community to use a particular\napproach. In previous work, we proposed DL-LVTQ, a deep learning approach for\nleft ventricular trabecular quantification based on a U-Net CNN architecture.\nDL-LVTQ was an automatic diagnosis tool developed from a dataset of patients\nwith the same cardiomyopathy (hypertrophic cardiomyopathy).\n  In this work, we have extended and adapted DL-LVTQ to cope with patients with\ndifferent cardiomyopathies. The dataset consists of up 379 patients in three\ngroups with different particularities and cardiomyopathies. Patient images were\ntaken from different scanners and hospitals. We have modified and adapted the\nU-Net convolutional neural network to account for the different particularities\nof a heterogeneous group of patients with various unclassifiable or mixed and\ninherited cardiomyopathies.\n  The inclusion of new groups of patients has increased the accuracy,\nspecificity and kappa values while maintaining the sensitivity of the automatic\ndeep learning method proposed. Therefore, a better-prepared diagnosis tool is\nready for various cardiomyopathies with different characteristics.\nCardiologists have considered that 98.9% of the evaluated outputs are verified\nclinically for diagnosis. Therefore, the high precision to segment the\ndifferent cardiac structures allows us to make a robust diagnostic system\nobjective and faster, decreasing human error and time spent.\n","authors":["Gregorio Bernabé","Pilar González-Férez","José M. García","Guillem Casas","Josefa González-Carrillo"],"pdf_url":"https://arxiv.org/pdf/2311.13912v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09740v2","updated":"2023-11-23T11:00:13Z","published":"2023-11-16T10:13:09Z","title":"Redefining Super-Resolution: Fine-mesh PDE predictions without classical\n  simulations","summary":"  In Computational Fluid Dynamics (CFD), coarse mesh simulations offer\ncomputational efficiency but often lack precision. Applying conventional\nsuper-resolution to these simulations poses a significant challenge due to the\nfundamental contrast between downsampling high-resolution images and\nauthentically emulating low-resolution physics. The former method conserves\nmore of the underlying physics, surpassing the usual constraints of real-world\nscenarios. We propose a novel definition of super-resolution tailored for\nPDE-based problems. Instead of simply downsampling from a high-resolution\ndataset, we use coarse-grid simulated data as our input and predict fine-grid\nsimulated outcomes. Employing a physics-infused UNet upscaling method, we\ndemonstrate its efficacy across various 2D-CFD problems such as discontinuity\ndetection in Burger's equation, Methane combustion, and fouling in Industrial\nheat exchangers. Our method enables the generation of fine-mesh solutions\nbypassing traditional simulation, ensuring considerable computational saving\nand fidelity to the original ground truth outcomes. Through diverse boundary\nconditions during training, we further establish the robustness of our method,\npaving the way for its broad applications in engineering and scientific CFD\nsolvers.\n","authors":["Rajat Kumar Sarkar","Ritam Majumdar","Vishal Jadhav","Sagar Srinivas Sakhinana","Venkataramana Runkana"],"pdf_url":"https://arxiv.org/pdf/2311.09740v2.pdf","comment":"Accepted at Machine Learning and the Physical Sciences Workshop,\n  NeurIPS 2023"},{"id":"http://arxiv.org/abs/2306.10548v4","updated":"2023-11-23T10:31:17Z","published":"2023-06-18T12:56:46Z","title":"MARBLE: Music Audio Representation Benchmark for Universal Evaluation","summary":"  In the era of extensive intersection between art and Artificial Intelligence\n(AI), such as image generation and fiction co-creation, AI for music remains\nrelatively nascent, particularly in music understanding. This is evident in the\nlimited work on deep music representations, the scarcity of large-scale\ndatasets, and the absence of a universal and community-driven benchmark. To\naddress this issue, we introduce the Music Audio Representation Benchmark for\nuniversaL Evaluation, termed MARBLE. It aims to provide a benchmark for various\nMusic Information Retrieval (MIR) tasks by defining a comprehensive taxonomy\nwith four hierarchy levels, including acoustic, performance, score, and\nhigh-level description. We then establish a unified protocol based on 14 tasks\non 8 public-available datasets, providing a fair and standard assessment of\nrepresentations of all open-sourced pre-trained models developed on music\nrecordings as baselines. Besides, MARBLE offers an easy-to-use, extendable, and\nreproducible suite for the community, with a clear statement on copyright\nissues on datasets. Results suggest recently proposed large-scale pre-trained\nmusical language models perform the best in most tasks, with room for further\nimprovement. The leaderboard and toolkit repository are published at\nhttps://marble-bm.shef.ac.uk to promote future music AI research.\n","authors":["Ruibin Yuan","Yinghao Ma","Yizhi Li","Ge Zhang","Xingran Chen","Hanzhi Yin","Le Zhuo","Yiqi Liu","Jiawen Huang","Zeyue Tian","Binyue Deng","Ningzhi Wang","Chenghua Lin","Emmanouil Benetos","Anton Ragni","Norbert Gyenge","Roger Dannenberg","Wenhu Chen","Gus Xia","Wei Xue","Si Liu","Shi Wang","Ruibo Liu","Yike Guo","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2306.10548v4.pdf","comment":"camera-ready version for NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.13887v1","updated":"2023-11-23T10:18:21Z","published":"2023-11-23T10:18:21Z","title":"Unsupervised Learning for Topological Classification of Transportation\n  Networks","summary":"  With increasing urbanization, transportation plays an increasingly critical\nrole in city development. The number of studies on modeling, optimization,\nsimulation, and data analysis of transportation systems is on the rise. Many of\nthese studies utilize transportation test networks to represent real-world\ntransportation systems in urban areas, examining the efficacy of their proposed\napproaches. Each of these networks exhibits unique characteristics in their\ntopology, making their applications distinct for various study objectives.\nDespite their widespread use in research, there is a lack of comprehensive\nstudy addressing the classification of these networks based on their\ntopological characteristics. This study aims to fill this gap by employing\nunsupervised learning methods, particularly clustering. We present a\ncomprehensive framework for evaluating various topological network\ncharacteristics. Additionally, we employ two dimensionality reduction\ntechniques, namely Principal Component Analysis (PCA) and Isometric Feature\nMapping (ISOMAP), to reduce overlaps of highly correlated features and enhance\nthe interpretability of the subsequent classification results. We then utilize\ntwo clustering algorithms, K-means and HDBSCAN, to classify 14 transportation\nnetworks. The PCA method, followed by the K-means clustering approach,\noutperforms other alternatives with a Silhouette score of $0.510$, enabling the\nclassification of transportation networks into five clusters. We also provide a\ndetailed discussion on the resulting classification.\n","authors":["Sina Sabzekar","Mohammad Reza Valipour Malakshah","Zahra Amini"],"pdf_url":"https://arxiv.org/pdf/2311.13887v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13885v1","updated":"2023-11-23T10:15:09Z","published":"2023-11-23T10:15:09Z","title":"Can Physics Informed Neural Operators Self Improve?","summary":"  Self-training techniques have shown remarkable value across many deep\nlearning models and tasks. However, such techniques remain largely unexplored\nwhen considered in the context of learning fast solvers for systems of partial\ndifferential equations (Eg: Neural Operators). In this work, we explore the use\nof self-training for Fourier Neural Operators (FNO). Neural Operators emerged\nas a data driven technique, however, data from experiments or traditional\nsolvers is not always readily available. Physics Informed Neural Operators\n(PINO) overcome this constraint by utilizing a physics loss for the training,\nhowever the accuracy of PINO trained without data does not match the\nperformance obtained by training with data. In this work we show that\nself-training can be used to close this gap in performance. We examine\ncanonical examples, namely the 1D-Burgers and 2D-Darcy PDEs, to showcase the\nefficacy of self-training. Specifically, FNOs, when trained exclusively with\nphysics loss through self-training, approach 1.07x for Burgers and 1.02x for\nDarcy, compared to FNOs trained with both data and physics loss. Furthermore,\nwe discover that pseudo-labels can be used for self-training without\nnecessarily training to convergence in each iteration. A consequence of this is\nthat we are able to discover self-training schedules that improve upon the\nbaseline performance of PINO in terms of accuracy as well as time.\n","authors":["Ritam Majumdar","Amey Varhade","Shirish Karande","Lovekesh Vig"],"pdf_url":"https://arxiv.org/pdf/2311.13885v1.pdf","comment":"Paper accepted as a Spotlight talk at Symbiosis of Deep Learning and\n  Differential Equations, Neural Information Processing Systems 2023"},{"id":"http://arxiv.org/abs/2311.13883v1","updated":"2023-11-23T10:13:07Z","published":"2023-11-23T10:13:07Z","title":"Leveraging Optimal Transport via Projections on Subspaces for Machine\n  Learning Applications","summary":"  Optimal Transport has received much attention in Machine Learning as it\nallows to compare probability distributions by exploiting the geometry of the\nunderlying space. However, in its original formulation, solving this problem\nsuffers from a significant computational burden. Thus, a meaningful line of\nwork consists at proposing alternatives to reduce this burden while still\nenjoying its properties. In this thesis, we focus on alternatives which use\nprojections on subspaces. The main such alternative is the Sliced-Wasserstein\ndistance, which we first propose to extend to Riemannian manifolds in order to\nuse it in Machine Learning applications for which using such spaces has been\nshown to be beneficial in the recent years. We also study sliced distances\nbetween positive measures in the so-called unbalanced OT problem. Back to the\noriginal Euclidean Sliced-Wasserstein distance between probability measures, we\nstudy the dynamic of gradient flows when endowing the space with this distance\nin place of the usual Wasserstein distance. Then, we investigate the use of the\nBusemann function, a generalization of the inner product in metric spaces, in\nthe space of probability measures. Finally, we extend the subspace detour\napproach to incomparable spaces using the Gromov-Wasserstein distance.\n","authors":["Clément Bonet"],"pdf_url":"https://arxiv.org/pdf/2311.13883v1.pdf","comment":"PhD Thesis"},{"id":"http://arxiv.org/abs/2310.20457v2","updated":"2023-11-23T09:58:55Z","published":"2023-10-31T13:51:13Z","title":"FlexTrain: A Dynamic Training Framework for Heterogeneous Devices\n  Environments","summary":"  As deep learning models become increasingly large, they pose significant\nchallenges in heterogeneous devices environments. The size of deep learning\nmodels makes it difficult to deploy them on low-power or resource-constrained\ndevices, leading to long inference times and high energy consumption. To\naddress these challenges, we propose FlexTrain, a framework that accommodates\nthe diverse storage and computational resources available on different devices\nduring the training phase. FlexTrain enables efficient deployment of deep\nlearning models, while respecting device constraints, minimizing communication\ncosts, and ensuring seamless integration with diverse devices. We demonstrate\nthe effectiveness of FlexTrain on the CIFAR-100 dataset, where a single global\nmodel trained with FlexTrain can be easily deployed on heterogeneous devices,\nsaving training time and energy consumption. We also extend FlexTrain to the\nfederated learning setting, showing that our approach outperforms standard\nfederated learning benchmarks on both CIFAR-10 and CIFAR-100 datasets.\n","authors":["Mert Unsal","Ali Maatouk","Antonio De Domenico","Nicola Piovesan","Fadhel Ayed"],"pdf_url":"https://arxiv.org/pdf/2310.20457v2.pdf","comment":"Workshop on Advancing Neural Network Training (WANT) at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.13877v1","updated":"2023-11-23T09:57:35Z","published":"2023-11-23T09:57:35Z","title":"Locally Optimal Descent for Dynamic Stepsize Scheduling","summary":"  We introduce a novel dynamic learning-rate scheduling scheme grounded in\ntheory with the goal of simplifying the manual and time-consuming tuning of\nschedules in practice. Our approach is based on estimating the locally-optimal\nstepsize, guaranteeing maximal descent in the direction of the stochastic\ngradient of the current step. We first establish theoretical convergence bounds\nfor our method within the context of smooth non-convex stochastic optimization,\nmatching state-of-the-art bounds while only assuming knowledge of the\nsmoothness parameter. We then present a practical implementation of our\nalgorithm and conduct systematic experiments across diverse datasets and\noptimization algorithms, comparing our scheme with existing state-of-the-art\nlearning-rate schedulers. Our findings indicate that our method needs minimal\ntuning when compared to existing approaches, removing the need for auxiliary\nmanual schedules and warm-up phases and achieving comparable performance with\ndrastically reduced parameter tuning.\n","authors":["Gilad Yehudai","Alon Cohen","Amit Daniely","Yoel Drori","Tomer Koren","Mariano Schain"],"pdf_url":"https://arxiv.org/pdf/2311.13877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13870v1","updated":"2023-11-23T09:27:08Z","published":"2023-11-23T09:27:08Z","title":"L(M)V-IQL: Multiple Intention Inverse Reinforcement Learning for Animal\n  Behavior Characterization","summary":"  In advancing the understanding of decision-making processes, mathematical\nmodels, particularly Inverse Reinforcement Learning (IRL), have proven\ninstrumental in reconstructing animal's multiple intentions amidst complex\nbehaviors. Given the recent development of a continuous-time multi-intention\nIRL framework, there has been persistent inquiry into inferring discrete\ntime-varying reward functions with multiple intention IRL approaches. To tackle\nthe challenge, we introduce the Latent (Markov) Variable Inverse Q-learning\n(L(M)V-IQL) algorithms, a novel IRL framework tailored for accommodating\ndiscrete intrinsic rewards. Leveraging an Expectation-Maximization approach, we\ncluster observed trajectories into distinct intentions and independently solve\nthe IRL problem for each. Demonstrating the efficacy of L(M)V-IQL through\nsimulated experiments and its application to different real mouse behavior\ndatasets, our approach surpasses current benchmarks in animal behavior\nprediction, producing interpretable reward functions. This advancement holds\npromise for neuroscience and psychology, contributing to a deeper understanding\nof animal decision-making and uncovering underlying brain mechanisms.\n","authors":["Hao Zhu","Brice De La Crompe","Gabriel Kalweit","Artur Schneider","Maria Kalweit","Ilka Diester","Joschka Boedecker"],"pdf_url":"https://arxiv.org/pdf/2311.13870v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.10581v4","updated":"2023-11-23T09:15:48Z","published":"2022-04-22T09:01:29Z","title":"Fused Audio Instance and Representation for Respiratory Disease\n  Detection","summary":"  Audio-based classification techniques on body sounds have long been studied\nto aid in the diagnosis of respiratory diseases. While most research is\ncentered on the use of cough as the main biomarker, other body sounds also have\nthe potential to detect respiratory diseases. Recent studies on COVID-19 have\nshown that breath and speech sounds, in addition to cough, correlate with the\ndisease. Our study proposes Fused Audio Instance and Representation (FAIR) as a\nmethod for respiratory disease detection. FAIR relies on constructing a joint\nfeature vector from various body sounds represented in waveform and spectrogram\nform. We conducted experiments on the use case of COVID-19 detection by\ncombining waveform and spectrogram representation of body sounds. Our findings\nshow that the use of self-attention to combine extracted features from cough,\nbreath, and speech sounds leads to the best performance with an Area Under the\nReceiver Operating Characteristic Curve (AUC) score of 0.8658, a sensitivity of\n0.8057, and a specificity of 0.7958. Compared to models trained solely on\nspectrograms or waveforms, the use of both representations results in an\nimproved AUC score, demonstrating that combining spectrogram and waveform\nrepresentation helps to enrich the extracted features and outperforms the\nmodels that use only one representation.\n","authors":["Tuan Truong","Matthias Lenga","Antoine Serrurier","Sadegh Mohammadi"],"pdf_url":"https://arxiv.org/pdf/2204.10581v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04760v2","updated":"2023-11-23T09:12:45Z","published":"2023-11-08T15:33:06Z","title":"Towards Open-world Cross-Domain Sequential Recommendation: A\n  Model-Agnostic Contrastive Denoising Approach","summary":"  Cross-domain sequential recommendation (CDSR) aims to address the data\nsparsity problems that exist in traditional sequential recommendation (SR)\nsystems.\n  The existing approaches aim to design a specific cross-domain unit that can\ntransfer and propagate information across multiple domains by relying on\noverlapping users with abundant behaviors. However, in real-world recommender\nsystems, CDSR scenarios usually consist of a majority of long-tailed users with\nsparse behaviors and cold-start users who only exist in one domain. This leads\nto a drop in the performance of existing CDSR methods in the real-world\nindustry platform. Therefore, improving the consistency and effectiveness of\nmodels in open-world CDSR scenarios is crucial for constructing CDSR models\n(\\textit{1st} CH). Recently, some SR approaches have utilized auxiliary\nbehaviors to complement the information for long-tailed users. However, these\nmulti-behavior SR methods cannot deliver promising performance in CDSR, as they\noverlook the semantic gap between target and auxiliary behaviors, as well as\nuser interest deviation across domains (\\textit{2nd} CH).\n","authors":["Wujiang Xu","Xuying Ning","Wenfang Lin","Mingming Ha","Qiongxu Ma","Qianqiao Liang","Xuewen Tao","Linxun Chen","Bing Han","Minnan Luo"],"pdf_url":"https://arxiv.org/pdf/2311.04760v2.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2311.14091v1","updated":"2023-11-23T16:36:40Z","published":"2023-11-23T16:36:40Z","title":"PortfolioMentor: Multimodal Generative AI Companion for Learning and\n  Crafting Interactive Digital Art Portfolios","summary":"  Digital art portfolios serve as impactful mediums for artists to convey their\nvisions, weaving together visuals, audio, interactions, and narratives.\nHowever, without technical backgrounds, design students often find it\nchallenging to translate creative ideas into tangible codes and designs, given\nthe lack of tailored resources for the non-technical, academic support in art\nschools, and a comprehensive guiding tool throughout the mentally demanding\nprocess. Recognizing the role of companionship in code learning and leveraging\ngenerative AI models' capabilities in supporting creative tasks, we present\nPortfolioMentor, a coding companion chatbot for IDEs. This tool guides and\ncollaborates with students through proactive suggestions and responsible Q&As\nfor learning, inspiration, and support. In detail, the system starts with the\nunderstanding of the task and artist's visions, follows the co-creation of\nvisual illustrations, audio or music suggestions and files, click-scroll\neffects for interactions, and creative vision conceptualization, and finally\nsynthesizes these facets into a polished interactive digital portfolio.\n","authors":["Tao Long","Weirui Peng"],"pdf_url":"https://arxiv.org/pdf/2311.14091v1.pdf","comment":"3 pages, 1 figure, work in progress"},{"id":"http://arxiv.org/abs/2311.13954v1","updated":"2023-11-23T12:09:49Z","published":"2023-11-23T12:09:49Z","title":"Electric Network Frequency Optical Sensing Devices","summary":"  Electric Network Frequency (ENF) acts as a fingerprint in multimedia\nforensics applications. In indoor environments, ENF variations affect the\nintensity of light sources connected to power mains. Accordingly, the light\nintensity variations captured by sensing devices can be exploited to estimate\nthe ENF. A first optical sensing device based on a photodiode is developed for\ncapturing ENF variations in indoor lighting environments. In addition, a device\nthat captures the ENF directly from power mains is implemented. This device\nserves as a ground truth ENF collector. Video recordings captured by a camera\nare also employed to estimate the ENF. The camera serves as a second optical\nsensor. The factors affecting the ENF estimation are thoroughly studied. The\nmaximum correlation coefficient between the ENF estimated by the two optical\nsensors and that estimated directly from power mains is used to measure the\nestimation accuracy. The paper's major contribution is in the disclosure of\nextensive experimental evidence on ENF estimation in scenes ranging from static\nones capturing a white wall to non-static ones, including human activity.\n","authors":["Christos Moysiadis","Georgios Karantaidis","Constantine Kotropoulos"],"pdf_url":"https://arxiv.org/pdf/2311.13954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13946v1","updated":"2023-11-23T11:55:40Z","published":"2023-11-23T11:55:40Z","title":"Weakly-Supervised Video Moment Retrieval via Regularized Two-Branch\n  Proposal Networks with Erasing Mechanism","summary":"  Video moment retrieval is to identify the target moment according to the\ngiven sentence in an untrimmed video. Due to temporal boundary annotations of\nthe video are extremely time-consuming to acquire, modeling in the\nweakly-supervised setting is increasingly focused, where we only have access to\nthe video-sentence pairs during training. Most existing weakly-supervised\nmethods adopt a MIL-based framework to develop inter-sample confrontment, but\nneglect the intra-sample confrontment between moments with similar semantics.\nTherefore, these methods fail to distinguish the correct moment from plausible\nnegative moments. Further, the previous attention models in cross-modal\ninteraction tend to focus on a few dominant words exorbitantly, ignoring the\ncomprehensive video-sentence correspondence. In this paper, we propose a novel\nRegularized Two-Branch Proposal Network with Erasing Mechanism to consider the\ninter-sample and intra-sample confrontments simultaneously. Concretely, we\nfirst devise a language-aware visual filter to generate both enhanced and\nsuppressed video streams. Then, we design the sharable two-branch proposal\nmodule to generate positive and plausible negative proposals from the enhanced\nand suppressed branch respectively, contributing to sufficient confrontment.\nBesides, we introduce an attention-guided dynamic erasing mechanism in enhanced\nbranch to discover the complementary video-sentence relation. Moreover, we\napply two types of proposal regularization to stabilize the training process\nand improve model performance. The extensive experiments on ActivityCaption,\nCharades-STA and DiDeMo datasets show the effectiveness of our method.\n","authors":["Haoyuan Li","Zhou Zhao","Zhu Zhang","Zhijie Lin"],"pdf_url":"https://arxiv.org/pdf/2311.13946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13770v1","updated":"2023-11-23T01:53:02Z","published":"2023-11-23T01:53:02Z","title":"Archiving Body Movements: Collective Generation of Chinese Calligraphy","summary":"  As a communication channel, body movements have been widely explored in\nbehavioral studies and kinesics. Performing and visual arts share the same\ninterests but focus on documenting and representing human body movements, such\nas for dance notation and visual work creation. This paper investigates body\nmovements in oriental calligraphy and how to apply calligraphy principles to\nstimulate and archive body movements. Through an artwork (Wushu), the authors\nexperiment with an interactive and generative approach to engage the audience's\nbodily participation and archive the body movements as a compendium of\ngenerated calligraphy. The audience assumes the role of both writers and\nreaders; creating (\"writing\") and appreciating (\"reading\") the generated\ncalligraphy becomes a cyclical process within this infinite \"Book,\" which can\nmotivate further attention and discussions concerning Chinese characters and\ncalligraphy.\n","authors":["Aven Le Zhou","Jiayi Ye","Tianchen Liu","Kang Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.13770v1.pdf","comment":"8 pages, 8 figures"}]},"2023-11-27T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2310.19106v3","updated":"2023-11-27T13:46:00Z","published":"2023-10-29T18:43:19Z","title":"PACuna: Automated Fine-Tuning of Language Models for Particle\n  Accelerators","summary":"  Navigating the landscape of particle accelerators has become increasingly\nchallenging with recent surges in contributions. These intricate devices\nchallenge comprehension, even within individual facilities. To address this, we\nintroduce PACuna, a fine-tuned language model refined through publicly\navailable accelerator resources like conferences, pre-prints, and books. We\nautomated data collection and question generation to minimize expert\ninvolvement and make the data publicly available. PACuna demonstrates\nproficiency in addressing intricate accelerator questions, validated by\nexperts. Our approach shows adapting language models to scientific domains by\nfine-tuning technical texts and auto-generated corpora capturing the latest\ndevelopments can further produce pre-trained models to answer some intricate\nquestions that commercially available assistants cannot and can serve as\nintelligent assistants for individual facilities.\n","authors":["Antonin Sulc","Raimund Kammering","Annika Eichler","Tim Wilksen"],"pdf_url":"https://arxiv.org/pdf/2310.19106v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14353v2","updated":"2023-11-27T16:55:29Z","published":"2023-11-24T08:53:52Z","title":"Average Token Delay: A Duration-aware Latency Metric for Simultaneous\n  Translation","summary":"  Simultaneous translation is a task in which the translation begins before the\nend of an input speech segment. Its evaluation should be conducted based on\nlatency in addition to quality, and for users, the smallest possible amount of\nlatency is preferable. Most existing metrics measure latency based on the start\ntimings of partial translations and ignore their duration. This means such\nmetrics do not penalize the latency caused by long translation output, which\ndelays the comprehension of users and subsequent translations. In this work, we\npropose a novel latency evaluation metric for simultaneous translation called\n\\emph{Average Token Delay} (ATD) that focuses on the duration of partial\ntranslations. We demonstrate its effectiveness through analyses simulating\nuser-side latency based on Ear-Voice Span (EVS). In our experiment, ATD had the\nhighest correlation with EVS among baseline latency metrics under most\nconditions.\n","authors":["Yasumasa Kano","Katsuhito Sudoh","Satoshi Nakamura"],"pdf_url":"https://arxiv.org/pdf/2311.14353v2.pdf","comment":"Extended version of the paper (doi: 10.21437/Interspeech.2023-933)\n  which appeared in INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2311.13534v2","updated":"2023-11-27T02:52:46Z","published":"2023-11-22T17:14:54Z","title":"LM-Cocktail: Resilient Tuning of Language Models via Model Merging","summary":"  The pre-trained language models are continually fine-tuned to better support\ndownstream applications. However, this operation may result in significant\nperformance degeneration on general tasks beyond the targeted domain. To\novercome this problem, we propose a novel method which enables the fine-tuned\nmodel to stay resilient in general perspectives. Our method is conducted in the\nform of model merging (namely LM-Cocktail), where the fine-tuned language model\nis merged with the pre-trained base model or the peer models from other domains\nthrough weighted average. Despite simplicity, LM-Cocktail is surprisingly\neffective: the resulted model is able to achieve a strong empirical performance\nin the whole scope of general tasks while preserving a superior capacity in its\ntargeted domain. We conduct comprehensive experiments with LLama and BGE model\non popular benchmarks, including FLAN, MMLU, MTEB, whose results validate the\nefficacy of our proposed method. The code and checkpoints are available at\nhttps://github.com/FlagOpen/FlagEmbedding/tree/master/LM_Cocktail.\n","authors":["Shitao Xiao","Zheng Liu","Peitian Zhang","Xingrun Xing"],"pdf_url":"https://arxiv.org/pdf/2311.13534v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16101v1","updated":"2023-11-27T18:59:42Z","published":"2023-11-27T18:59:42Z","title":"How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for\n  Vision LLMs","summary":"  This work focuses on the potential of Vision LLMs (VLLMs) in visual\nreasoning. Different from prior studies, we shift our focus from evaluating\nstandard performance to introducing a comprehensive safety evaluation suite,\ncovering both out-of-distribution (OOD) generalization and adversarial\nrobustness. For the OOD evaluation, we present two novel VQA datasets, each\nwith one variant, designed to test model performance under challenging\nconditions. In exploring adversarial robustness, we propose a straightforward\nattack strategy for misleading VLLMs to produce visual-unrelated responses.\nMoreover, we assess the efficacy of two jailbreaking strategies, targeting\neither the vision or language component of VLLMs. Our evaluation of 21 diverse\nmodels, ranging from open-source VLLMs to GPT-4V, yields interesting\nobservations: 1) Current VLLMs struggle with OOD texts but not images, unless\nthe visual information is limited; and 2) These VLLMs can be easily misled by\ndeceiving vision encoders only, and their vision-language training often\ncompromise safety protocols. We release this safety evaluation suite at\nhttps://github.com/UCSC-VLAA/vllm-safety-benchmark.\n","authors":["Haoqin Tu","Chenhang Cui","Zijun Wang","Yiyang Zhou","Bingchen Zhao","Junlin Han","Wangchunshu Zhou","Huaxiu Yao","Cihang Xie"],"pdf_url":"https://arxiv.org/pdf/2311.16101v1.pdf","comment":"H.T., C.C., and Z.W. contribute equally. Work done during H.T. and\n  Z.W.'s internship at UCSC, and C.C. and Y.Z.'s internship at UNC"},{"id":"http://arxiv.org/abs/2311.16087v1","updated":"2023-11-27T18:56:14Z","published":"2023-11-27T18:56:14Z","title":"DUnE: Dataset for Unified Editing","summary":"  Even the most advanced language models remain susceptible to errors\nnecessitating to modify these models without initiating a comprehensive\nretraining process. Model editing refers to the modification of a model's\nknowledge or representations in a manner that produces the desired outcomes.\nPrior research primarily centered around editing factual data e.g. \"Messi plays\nfor Inter Miami\" confining the definition of an edit to a knowledge triplet\ni.e. (subject, object, relation). However, as the applications of language\nmodels expand, so do the diverse ways in which we wish to edit and refine their\noutputs. In this study, we broaden the scope of the editing problem to include\nan array of editing cases such as debiasing and rectifying reasoning errors and\ndefine an edit as any natural language expression that solicits a change in the\nmodel's outputs. We are introducing DUnE-an editing benchmark where edits are\nnatural language sentences and propose that DUnE presents a challenging yet\nrelevant task. To substantiate this claim, we conduct an extensive series of\nexperiments testing various editing approaches to address DUnE, demonstrating\ntheir respective strengths and weaknesses. We show that retrieval-augmented\nlanguage modeling can outperform specialized editing techniques and neither set\nof approaches has fully solved the generalized editing problem covered by our\nbenchmark.\n","authors":["Afra Feyza Akyürek","Eric Pan","Garry Kuwanto","Derry Wijaya"],"pdf_url":"https://arxiv.org/pdf/2311.16087v1.pdf","comment":"Accepted at EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.16083v1","updated":"2023-11-27T18:53:31Z","published":"2023-11-27T18:53:31Z","title":"BERT Goes Off-Topic: Investigating the Domain Transfer Challenge using\n  Genre Classification","summary":"  While performance of many text classification tasks has been recently\nimproved due to Pre-trained Language Models (PLMs), in this paper we show that\nthey still suffer from a performance gap when the underlying distribution of\ntopics changes. For example, a genre classifier trained on \\textit{political}\ntopics often fails when tested on documents about \\textit{sport} or\n\\textit{medicine}. In this work, we quantify this phenomenon empirically with a\nlarge corpus and a large set of topics. Consequently, we verify that domain\ntransfer remains challenging both for classic PLMs, such as BERT, and for\nmodern large models, such as GPT-3. We also suggest and successfully test a\npossible remedy: after augmenting the training dataset with\ntopically-controlled synthetic texts, the F1 score improves by up to 50\\% for\nsome topics, nearing on-topic training results, while others show little to no\nimprovement. While our empirical results focus on genre classification, our\nmethodology is applicable to other classification tasks such as gender,\nauthorship, or sentiment classification. The code and data to replicate the\nexperiments are available at https://github.com/dminus1/genre\n","authors":["Dmitri Roussinov","Serge Sharoff"],"pdf_url":"https://arxiv.org/pdf/2311.16083v1.pdf","comment":"Published at EMNLP'2023"},{"id":"http://arxiv.org/abs/2311.16079v1","updated":"2023-11-27T18:49:43Z","published":"2023-11-27T18:49:43Z","title":"MEDITRON-70B: Scaling Medical Pretraining for Large Language Models","summary":"  Large language models (LLMs) can potentially democratize access to medical\nknowledge. While many efforts have been made to harness and improve LLMs'\nmedical knowledge and reasoning capacities, the resulting models are either\nclosed-source (e.g., PaLM, GPT-4) or limited in scale (<= 13B parameters),\nwhich restricts their abilities. In this work, we improve access to large-scale\nmedical LLMs by releasing MEDITRON: a suite of open-source LLMs with 7B and 70B\nparameters adapted to the medical domain. MEDITRON builds on Llama-2 (through\nour adaptation of Nvidia's Megatron-LM distributed trainer), and extends\npretraining on a comprehensively curated medical corpus, including selected\nPubMed articles, abstracts, and internationally-recognized medical guidelines.\nEvaluations using four major medical benchmarks show significant performance\ngains over several state-of-the-art baselines before and after task-specific\nfinetuning. Overall, MEDITRON achieves a 6% absolute performance gain over the\nbest public baseline in its parameter class and 3% over the strongest baseline\nwe finetuned from Llama-2. Compared to closed-source LLMs, MEDITRON-70B\noutperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of\nMed-PaLM-2. We release our code for curating the medical pretraining corpus and\nthe MEDITRON model weights to drive open-source development of more capable\nmedical LLMs.\n","authors":["Zeming Chen","Alejandro Hernández Cano","Angelika Romanou","Antoine Bonnet","Kyle Matoba","Francesco Salvi","Matteo Pagliardini","Simin Fan","Andreas Köpf","Amirkeivan Mohtashami","Alexandre Sallinen","Alireza Sakhaeirad","Vinitra Swamy","Igor Krawczuk","Deniz Bayazit","Axel Marmet","Syrielle Montariol","Mary-Anne Hartley","Martin Jaggi","Antoine Bosselut"],"pdf_url":"https://arxiv.org/pdf/2311.16079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16075v1","updated":"2023-11-27T18:46:17Z","published":"2023-11-27T18:46:17Z","title":"BioLORD-2023: Semantic Textual Representations Fusing LLM and Clinical\n  Knowledge Graph Insights","summary":"  In this study, we investigate the potential of Large Language Models to\ncomplement biomedical knowledge graphs in the training of semantic models for\nthe biomedical and clinical domains. Drawing on the wealth of the UMLS\nknowledge graph and harnessing cutting-edge Large Language Models, we propose a\nnew state-of-the-art approach for obtaining high-fidelity representations of\nbiomedical concepts and sentences, consisting of three steps: an improved\ncontrastive learning phase, a novel self-distillation phase, and a weight\naveraging phase. Through rigorous evaluations via the extensive BioLORD testing\nsuite and diverse downstream tasks, we demonstrate consistent and substantial\nperformance improvements over the previous state of the art (e.g. +2pts on\nMedSTS, +2.5pts on MedNLI-S, +6.1pts on EHR-Rel-B). Besides our new\nstate-of-the-art biomedical model for English, we also distill and release a\nmultilingual model compatible with 50+ languages and finetuned on 7 European\nlanguages. Many clinical pipelines can benefit from our latest models. Our new\nmultilingual model enables a range of languages to benefit from our\nadvancements in biomedical semantic representation learning, opening a new\navenue for bioinformatics researchers around the world. As a result, we hope to\nsee BioLORD-2023 becoming a precious tool for future biomedical applications.\n","authors":["François Remy","Kris Demuynck","Thomas Demeester"],"pdf_url":"https://arxiv.org/pdf/2311.16075v1.pdf","comment":"Preprint of upcoming journal article"},{"id":"http://arxiv.org/abs/2107.10021v2","updated":"2023-11-27T18:09:19Z","published":"2021-07-21T11:31:57Z","title":"Neuradicon: operational representation learning of neuroimaging reports","summary":"  Radiological reports typically summarize the content and interpretation of\nimaging studies in unstructured form that precludes quantitative analysis. This\nlimits the monitoring of radiological services to throughput undifferentiated\nby content, impeding specific, targeted operational optimization. Here we\npresent Neuradicon, a natural language processing (NLP) framework for\nquantitative analysis of neuroradiological reports. Our framework is a hybrid\nof rule-based and artificial intelligence models to represent neurological\nreports in succinct, quantitative form optimally suited to operational\nguidance. We demonstrate the application of Neuradicon to operational\nphenotyping of a corpus of 336,569 reports, and report excellent\ngeneralizability across time and two independent healthcare institutions.\n","authors":["Henry Watkins","Robert Gray","Adam Julius","Yee-Haur Mah","Walter H. L. Pinaya","Paul Wright","Ashwani Jha","Holger Engleitner","Jorge Cardoso","Sebastien Ourselin","Geraint Rees","Rolf Jaeger","Parashkev Nachev"],"pdf_url":"https://arxiv.org/pdf/2107.10021v2.pdf","comment":"26 pages, 11 figures"},{"id":"http://arxiv.org/abs/2308.14306v3","updated":"2023-11-27T17:43:20Z","published":"2023-08-28T04:57:07Z","title":"Evaluating the Robustness to Instructions of Large Language Models","summary":"  Recently, Instruction fine-tuning has risen to prominence as a potential\nmethod for enhancing the zero-shot capabilities of Large Language Models (LLMs)\non novel tasks. This technique has shown an exceptional ability to boost the\nperformance of moderately sized LLMs, sometimes even reaching performance\nlevels comparable to those of much larger model variants. The focus is on the\nrobustness of instruction-tuned LLMs to seen and unseen tasks. We conducted an\nexploration of six models including Alpaca, Vicuna, WizardLM, and Traditional\nTask-oriented Models(Flan-T5-XL/XXL, T0++) using real-world relation extraction\ndatasets as case studies. We carried out a comprehensive evaluation of these\ninstruction-following LLMs which have been tuned based on open-domain\ninstructions and task-oriented instructions. The main discussion is their\nperformance and robustness towards instructions. We have observed that in most\ncases, the model's performance in dealing with unfamiliar instructions tends to\nworsen significantly, and the robustness of the model for RE instructions\ndeteriorates compared to QA. Further, we discovered that up until a certain\nparameter size threshold (3B), the performance of the FLAN-T5 model improves as\nthe parameter count increases. The robustness of different scales of FLAN-T5\nmodels to RE instruction is worse than the robustness to QA instruction.\n","authors":["Yuansheng Ni","Sichao Jiang","Xinyu wu","Hui Shen","Yuli Zhou"],"pdf_url":"https://arxiv.org/pdf/2308.14306v3.pdf","comment":"There were major problems with the experimental data"},{"id":"http://arxiv.org/abs/2310.06627v2","updated":"2023-11-27T16:59:39Z","published":"2023-10-10T13:45:59Z","title":"What If the TV Was Off? Examining Counterfactual Reasoning Abilities of\n  Multi-modal Language Models","summary":"  Counterfactual reasoning, a fundamental aspect of human cognition, involves\ncontemplating alternatives to established facts or past events, significantly\nenhancing our abilities in planning and decision-making. In light of the\nadvancements in current multi-modal large language models, we explore their\neffectiveness in counterfactual reasoning. To facilitate this investigation, we\nintroduce a novel dataset, C-VQA, specifically designed to test the\ncounterfactual reasoning capabilities of modern multi-modal large language\nmodels. This dataset is constructed by infusing original questions with\ncounterfactual presuppositions, spanning various types such as numerical and\nboolean queries. It encompasses a mix of real and synthetic data, representing\na wide range of difficulty levels. Our thorough evaluations of contemporary\nvision-language models using this dataset have revealed substantial performance\ndrops, with some models showing up to a 40\\% decrease, highlighting a\nsignificant gap between current models and human-like vision reasoning\ncapabilities. We hope our dataset will serve as a vital benchmark for\nevaluating the counterfactual reasoning capabilities of models. Code and\ndataset are publicly available at https://bzhao.me/C-VQA/.\n","authors":["Letian Zhang","Xiaotong Zhai","Zhongkai Zhao","Yongshuo Zong","Xin Wen","Bingchen Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.06627v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15983v1","updated":"2023-11-27T16:28:20Z","published":"2023-11-27T16:28:20Z","title":"Sparsify-then-Classify: From Internal Neurons of Large Language Models\n  To Efficient Text Classifiers","summary":"  Among the many tasks that Large Language Models (LLMs) have revolutionized is\ntext classification. However, existing approaches for applying pretrained LLMs\nto text classification predominantly rely on using single token outputs from\nonly the last layer of hidden states. As a result, they suffer from limitations\nin efficiency, task-specificity, and interpretability. In our work, we\ncontribute an approach that uses all internal representations by employing\nmultiple pooling strategies on all activation and hidden states. Our novel\nlightweight strategy, Sparsify-then-Classify (STC) first sparsifies\ntask-specific features layer-by-layer, then aggregates across layers for text\nclassification. STC can be applied as a seamless plug-and-play module on top of\nexisting LLMs. Our experiments on a comprehensive set of models and datasets\ndemonstrate that STC not only consistently improves the classification\nperformance of pretrained and fine-tuned models, but is also more efficient for\nboth training and inference, and is more intrinsically interpretable.\n","authors":["Yilun Liu","Difan Jiao","Ashton Anderson"],"pdf_url":"https://arxiv.org/pdf/2311.15983v1.pdf","comment":"23 pages, 5 figures, 8 tables Code available at\n  https://github.com/difanj0713/Sparsify-then-Classify"},{"id":"http://arxiv.org/abs/2311.15964v1","updated":"2023-11-27T16:07:37Z","published":"2023-11-27T16:07:37Z","title":"Efficient Pre-training for Localized Instruction Generation of Videos","summary":"  Procedural videos show step-by-step demonstrations of tasks like recipe\npreparation. Understanding such videos is challenging, involving the precise\nlocalization of steps and the generation of textual instructions. Manually\nannotating steps and writing instructions is costly, which limits the size of\ncurrent datasets and hinders effective learning. Leveraging large but noisy\nvideo-transcript datasets for pre-training can boost performance, but demands\nsignificant computational resources. Furthermore, transcripts contain\nirrelevant content and exhibit style variation compared to instructions written\nby human annotators. To mitigate both issues, we propose a technique,\nSieve-&-Swap, to automatically curate a smaller dataset: (i) Sieve filters\nirrelevant transcripts and (ii) Swap enhances the quality of the text\ninstruction by automatically replacing the transcripts with human-written\ninstructions from a text-only recipe dataset. The curated dataset, three orders\nof magnitude smaller than current web-scale datasets, enables efficient\ntraining of large-scale models with competitive performance. We complement our\nSieve-\\&-Swap approach with a Procedure Transformer (ProcX) for end-to-end step\nlocalization and instruction generation for procedural videos. When this model\nis pre-trained on our curated dataset, it achieves state-of-the-art performance\nin zero-shot and finetuning settings on YouCook2 and Tasty, while using a\nfraction of the computational resources.\n","authors":["Anil Batra","Davide Moltisanti","Laura Sevilla-Lara","Marcus Rohrbach","Frank Keller"],"pdf_url":"https://arxiv.org/pdf/2311.15964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15954v1","updated":"2023-11-27T15:58:28Z","published":"2023-11-27T15:58:28Z","title":"A Quantitative Approach to Understand Self-Supervised Models as\n  Cross-lingual Feature Extractors","summary":"  In this work, we study the features extracted by English self-supervised\nlearning (SSL) models in cross-lingual contexts and propose a new metric to\npredict the quality of feature representations. Using automatic speech\nrecognition (ASR) as a downstream task, we analyze the effect of model size,\ntraining objectives, and model architecture on the models' performance as a\nfeature extractor for a set of topologically diverse corpora. We develop a\nnovel metric, the Phonetic-Syntax Ratio (PSR), to measure the phonetic and\nsynthetic information in the extracted representations using deep generalized\ncanonical correlation analysis. Results show the contrastive loss in the\nwav2vec2.0 objective facilitates more effective cross-lingual feature\nextraction. There is a positive correlation between PSR scores and ASR\nperformance, suggesting that phonetic information extracted by monolingual SSL\nmodels can be used for downstream tasks in cross-lingual settings. The proposed\nmetric is an effective indicator of the quality of the representations and can\nbe useful for model selection.\n","authors":["Shuyue Stella Li","Beining Xu","Xiangyu Zhang","Hexin Liu","Wenhan Chao","Leibny Paola Garcia"],"pdf_url":"https://arxiv.org/pdf/2311.15954v1.pdf","comment":"12 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.15946v1","updated":"2023-11-27T15:53:11Z","published":"2023-11-27T15:53:11Z","title":"Leveraging deep active learning to identify low-resource mobility\n  functioning information in public clinical notes","summary":"  Function is increasingly recognized as an important indicator of whole-person\nhealth, although it receives little attention in clinical natural language\nprocessing research. We introduce the first public annotated dataset\nspecifically on the Mobility domain of the International Classification of\nFunctioning, Disability and Health (ICF), aiming to facilitate automatic\nextraction and analysis of functioning information from free-text clinical\nnotes. We utilize the National NLP Clinical Challenges (n2c2) research dataset\nto construct a pool of candidate sentences using keyword expansion. Our active\nlearning approach, using query-by-committee sampling weighted by density\nrepresentativeness, selects informative sentences for human annotation. We\ntrain BERT and CRF models, and use predictions from these models to guide the\nselection of new sentences for subsequent annotation iterations. Our final\ndataset consists of 4,265 sentences with a total of 11,784 entities, including\n5,511 Action entities, 5,328 Mobility entities, 306 Assistance entities, and\n639 Quantification entities. The inter-annotator agreement (IAA), averaged over\nall entity types, is 0.72 for exact matching and 0.91 for partial matching. We\nalso train and evaluate common BERT models and state-of-the-art Nested NER\nmodels. The best F1 scores are 0.84 for Action, 0.7 for Mobility, 0.62 for\nAssistance, and 0.71 for Quantification. Empirical results demonstrate\npromising potential of NER models to accurately extract mobility functioning\ninformation from clinical text. The public availability of our annotated\ndataset will facilitate further research to comprehensively capture functioning\ninformation in electronic health records (EHRs).\n","authors":["Tuan-Dung Le","Zhuqi Miao","Samuel Alvarado","Brittany Smith","William Paiva","Thanh Thieu"],"pdf_url":"https://arxiv.org/pdf/2311.15946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15941v1","updated":"2023-11-27T15:49:29Z","published":"2023-11-27T15:49:29Z","title":"Tell2Design: A Dataset for Language-Guided Floor Plan Generation","summary":"  We consider the task of generating designs directly from natural language\ndescriptions, and consider floor plan generation as the initial research area.\nLanguage conditional generative models have recently been very successful in\ngenerating high-quality artistic images. However, designs must satisfy\ndifferent constraints that are not present in generating artistic images,\nparticularly spatial and relational constraints. We make multiple contributions\nto initiate research on this task. First, we introduce a novel dataset,\n\\textit{Tell2Design} (T2D), which contains more than $80k$ floor plan designs\nassociated with natural language instructions. Second, we propose a\nSequence-to-Sequence model that can serve as a strong baseline for future\nresearch. Third, we benchmark this task with several text-conditional image\ngeneration models. We conclude by conducting human evaluations on the generated\nsamples and providing an analysis of human performance. We hope our\ncontributions will propel the research on language-guided design generation\nforward.\n","authors":["Sicong Leng","Yang Zhou","Mohammed Haroon Dupty","Wee Sun Lee","Sam Conrad Joyce","Wei Lu"],"pdf_url":"https://arxiv.org/pdf/2311.15941v1.pdf","comment":"Paper published in ACL2023; Area Chair Award; Best Paper Nomination"},{"id":"http://arxiv.org/abs/2311.15930v1","updated":"2023-11-27T15:38:17Z","published":"2023-11-27T15:38:17Z","title":"WorldSense: A Synthetic Benchmark for Grounded Reasoning in Large\n  Language Models","summary":"  We propose WorldSense, a benchmark designed to assess the extent to which\nLLMs are consistently able to sustain tacit world models, by testing how they\ndraw simple inferences from descriptions of simple arrangements of entities.\nWorldsense is a synthetic benchmark with three problem types, each with their\nown trivial control, which explicitly avoids bias by decorrelating the abstract\nstructure of problems from the vocabulary and expressions, and by decorrelating\nall problem subparts with the correct response. We run our benchmark on three\nstate-of-the-art chat-LLMs (GPT3.5, GPT4 and Llama2-chat) and show that these\nmodels make errors even with as few as three objects. Furthermore, they have\nquite heavy response biases, preferring certain responses irrespective of the\nquestion. Errors persist even with chain-of-thought prompting and in-context\nlearning. Lastly, we show that while finetuning on similar problems does result\nin substantial improvements -- within- and out-of-distribution -- the finetuned\nmodels do not generalise beyond a constraint problem space.\n","authors":["Youssef Benchekroun","Megi Dervishi","Mark Ibrahim","Jean-Baptiste Gaya","Xavier Martinet","Grégoire Mialon","Thomas Scialom","Emmanuel Dupoux","Dieuwke Hupkes","Pascal Vincent"],"pdf_url":"https://arxiv.org/pdf/2311.15930v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07590v2","updated":"2023-11-27T15:17:49Z","published":"2023-11-09T17:12:44Z","title":"Technical Report: Large Language Models can Strategically Deceive their\n  Users when Put Under Pressure","summary":"  We demonstrate a situation in which Large Language Models, trained to be\nhelpful, harmless, and honest, can display misaligned behavior and\nstrategically deceive their users about this behavior without being instructed\nto do so. Concretely, we deploy GPT-4 as an agent in a realistic, simulated\nenvironment, where it assumes the role of an autonomous stock trading agent.\nWithin this environment, the model obtains an insider tip about a lucrative\nstock trade and acts upon it despite knowing that insider trading is\ndisapproved of by company management. When reporting to its manager, the model\nconsistently hides the genuine reasons behind its trading decision. We perform\na brief investigation of how this behavior varies under changes to the setting,\nsuch as removing model access to a reasoning scratchpad, attempting to prevent\nthe misaligned behavior by changing system instructions, changing the amount of\npressure the model is under, varying the perceived risk of getting caught, and\nmaking other simple changes to the environment. To our knowledge, this is the\nfirst demonstration of Large Language Models trained to be helpful, harmless,\nand honest, strategically deceiving their users in a realistic situation\nwithout direct instructions or training for deception.\n","authors":["Jérémy Scheurer","Mikita Balesni","Marius Hobbhahn"],"pdf_url":"https://arxiv.org/pdf/2311.07590v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.13547v3","updated":"2023-11-27T15:10:00Z","published":"2023-05-22T23:43:23Z","title":"Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot\n  Text Classification Tasks","summary":"  Text classification tasks often encounter few shot scenarios with limited\nlabeled data, and addressing data scarcity is crucial. Data augmentation with\nmixup has shown to be effective on various text classification tasks. However,\nmost of the mixup methods do not consider the varying degree of learning\ndifficulty in different stages of training and generate new samples with one\nhot labels, resulting in the model over confidence. In this paper, we propose a\nself evolution learning (SE) based mixup approach for data augmentation in text\nclassification, which can generate more adaptive and model friendly pesudo\nsamples for the model training. SE focuses on the variation of the model's\nlearning ability. To alleviate the model confidence, we introduce a novel\ninstance specific label smoothing approach, which linearly interpolates the\nmodel's output and one hot labels of the original samples to generate new soft\nfor label mixing up. Through experimental analysis, in addition to improving\nclassification accuracy, we demonstrate that SE also enhances the model's\ngeneralize ability.\n","authors":["Haoqi Zheng","Qihuang Zhong","Liang Ding","Zhiliang Tian","Xin Niu","Dongsheng Li","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2305.13547v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15896v1","updated":"2023-11-27T15:01:26Z","published":"2023-11-27T15:01:26Z","title":"Data Generation for Post-OCR correction of Cyrillic handwriting","summary":"  This paper introduces a novel approach to post-Optical Character Recognition\nCorrection (POC) for handwritten Cyrillic text, addressing a significant gap in\ncurrent research methodologies. This gap is due to the lack of large text\ncorporas that provide OCR errors for further training of language-based POC\nmodels, which are demanding in terms of corpora size. Our study primarily\nfocuses on the development and application of a synthetic handwriting\ngeneration engine based on B\\'ezier curves. Such an engine generates highly\nrealistic handwritten text in any amounts, which we utilize to create a\nsubstantial dataset by transforming Russian text corpora sourced from the\ninternet. We apply a Handwritten Text Recognition (HTR) model to this dataset\nto identify OCR errors, forming the basis for our POC model training. The\ncorrection model is trained on a 90-symbol input context, utilizing a\npre-trained T5 architecture with a seq2seq correction task. We evaluate our\napproach on HWR200 and School_notebooks_RU datasets as they provide significant\nchallenges in the HTR domain. Furthermore, POC can be used to highlight errors\nfor teachers, evaluating student performance. This can be done simply by\ncomparing sentences before and after correction, displaying differences in\ntext. Our primary contribution lies in the innovative use of B\\'ezier curves\nfor Cyrillic text generation and subsequent error correction using a\nspecialized POC model. We validate our approach by presenting Word Accuracy\nRate (WAR) and Character Accuracy Rate (CAR) results, both with and without\npost-OCR correction, using real open corporas of handwritten Cyrillic text.\nThese results, coupled with our methodology, are designed to be reproducible,\npaving the way for further advancements in the field of OCR and handwritten\ntext analysis. Paper contributions can be found in\nhttps://github.com/dbrainio/CyrillicHandwritingPOC\n","authors":["Evgenii Davydkin","Aleksandr Markelov","Egor Iuldashev","Anton Dudkin","Ivan Krivorotov"],"pdf_url":"https://arxiv.org/pdf/2311.15896v1.pdf","comment":"17 pages, 27 figures, 6 tables, 26 references"},{"id":"http://arxiv.org/abs/2307.15176v2","updated":"2023-11-27T14:35:05Z","published":"2023-07-27T20:11:07Z","title":"RCT Rejection Sampling for Causal Estimation Evaluation","summary":"  Confounding is a significant obstacle to unbiased estimation of causal\neffects from observational data. For settings with high-dimensional covariates\n-- such as text data, genomics, or the behavioral social sciences --\nresearchers have proposed methods to adjust for confounding by adapting machine\nlearning methods to the goal of causal estimation. However, empirical\nevaluation of these adjustment methods has been challenging and limited. In\nthis work, we build on a promising empirical evaluation strategy that\nsimplifies evaluation design and uses real data: subsampling randomized\ncontrolled trials (RCTs) to create confounded observational datasets while\nusing the average causal effects from the RCTs as ground-truth. We contribute a\nnew sampling algorithm, which we call RCT rejection sampling, and provide\ntheoretical guarantees that causal identification holds in the observational\ndata to allow for valid comparisons to the ground-truth RCT. Using synthetic\ndata, we show our algorithm indeed results in low bias when oracle estimators\nare evaluated on the confounded samples, which is not always the case for a\npreviously proposed algorithm. In addition to this identification result, we\nhighlight several finite data considerations for evaluation designers who plan\nto use RCT rejection sampling on their own datasets. As a proof of concept, we\nimplement an example evaluation pipeline and walk through these finite data\nconsiderations with a novel, real-world RCT -- which we release publicly --\nconsisting of approximately 70k observations and text data as high-dimensional\ncovariates. Together, these contributions build towards a broader agenda of\nimproved empirical evaluation for causal estimation.\n","authors":["Katherine A. Keith","Sergey Feldman","David Jurgens","Jonathan Bragg","Rohit Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2307.15176v2.pdf","comment":"Code and data at https://github.com/kakeith/rct_rejection_sampling"},{"id":"http://arxiv.org/abs/2310.14505v2","updated":"2023-11-27T14:23:16Z","published":"2023-10-23T02:32:30Z","title":"Sentiment analysis with adaptive multi-head attention in Transformer","summary":"  We propose a novel framework based on the attention mechanism to identify the\nsentiment of a movie review document. Previous efforts on deep neural networks\nwith attention mechanisms focus on encoder and decoder with fixed numbers of\nmulti-head attention. Therefore, we need a mechanism to stop the attention\nprocess automatically if no more useful information can be read from the\nmemory.In this paper, we propose an adaptive multi-head attention architecture\n(AdaptAttn) which varies the number of attention heads based on length of\nsentences. AdaptAttn has a data preprocessing step where each document is\nclassified into any one of the three bins small, medium or large based on\nlength of the sentence. The document classified as small goes through two heads\nin each layer, the medium group passes four heads and the large group is\nprocessed by eight heads. We examine the merit of our model on the Stanford\nlarge movie review dataset. The experimental results show that the F1 score\nfrom our model is on par with the baseline model.\n","authors":["Fanfei Meng","David Demeter"],"pdf_url":"https://arxiv.org/pdf/2310.14505v2.pdf","comment":"Accepted by the 4th International Conference on Signal Processing and\n  Machine Learning"},{"id":"http://arxiv.org/abs/2311.15786v1","updated":"2023-11-27T13:01:59Z","published":"2023-11-27T13:01:59Z","title":"YUAN 2.0: A Large Language Model with Localized Filtering-based\n  Attention","summary":"  In this work, the Localized Filtering-based Attention (LFA) is introduced to\nincorporate prior knowledge of local dependencies of natural language into\nAttention. Based on LFA, we develop and release Yuan 2.0, a large language\nmodel with parameters ranging from 2.1 billion to 102.6 billion. A data\nfiltering and generation method is presented to build pretraining and\nfine-tuning dataset in high quality. A distributed training method with\nnon-uniform pipeline parallel, data parallel, and optimizer parallel is\nproposed, which greatly reduces the bandwidth requirements of intra-node\ncommunication, and achieves good performance in large-scale distributed\ntraining. Yuan 2.0 models display impressive ability in code generation, math\nproblem-solving, and chat compared with existing models. The latest version of\nYUAN 2.0, including model weights and source code, is accessible at Github.\n","authors":["Shaohua Wu","Xudong Zhao","Shenling Wang","Jiangang Luo","Lingjun Li","Xi Chen","Bing Zhao","Wei Wang","Tong Yu","Rongguo Zhang","Jiahua Zhang","Chao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.15786v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15781v1","updated":"2023-11-27T12:54:47Z","published":"2023-11-27T12:54:47Z","title":"Increasing Coverage and Precision of Textual Information in Multilingual\n  Knowledge Graphs","summary":"  Recent work in Natural Language Processing and Computer Vision has been using\ntextual information -- e.g., entity names and descriptions -- available in\nknowledge graphs to ground neural models to high-quality structured data.\nHowever, when it comes to non-English languages, the quantity and quality of\ntextual information are comparatively scarce. To address this issue, we\nintroduce the novel task of automatic Knowledge Graph Enhancement (KGE) and\nperform a thorough investigation on bridging the gap in both the quantity and\nquality of textual information between English and non-English languages. More\nspecifically, we: i) bring to light the problem of increasing multilingual\ncoverage and precision of entity names and descriptions in Wikidata; ii)\ndemonstrate that state-of-the-art methods, namely, Machine Translation (MT),\nWeb Search (WS), and Large Language Models (LLMs), struggle with this task;\niii) present M-NTA, a novel unsupervised approach that combines MT, WS, and\nLLMs to generate high-quality textual information; and, iv) study the impact of\nincreasing multilingual coverage and precision of non-English textual\ninformation in Entity Linking, Knowledge Graph Completion, and Question\nAnswering. As part of our effort towards better multilingual knowledge graphs,\nwe also introduce WikiKGE-10, the first human-curated benchmark to evaluate KGE\napproaches in 10 languages across 7 language families.\n","authors":["Simone Conia","Min Li","Daniel Lee","Umar Farooq Minhas","Ihab Ilyas","Yunyao Li"],"pdf_url":"https://arxiv.org/pdf/2311.15781v1.pdf","comment":"Camera ready for EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.15766v1","updated":"2023-11-27T12:37:51Z","published":"2023-11-27T12:37:51Z","title":"Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges","summary":"  In recent years, large language models (LLMs) have spurred a new research\nparadigm in natural language processing. Despite their excellent capability in\nknowledge-based question answering and reasoning, their potential to retain\nfaulty or even harmful knowledge poses risks of malicious application. The\nchallenge of mitigating this issue and transforming these models into purer\nassistants is crucial for their widespread applicability. Unfortunately,\nRetraining LLMs repeatedly to eliminate undesirable knowledge is impractical\ndue to their immense parameters. Knowledge unlearning, derived from analogous\nstudies on machine unlearning, presents a promising avenue to address this\nconcern and is notably advantageous in the context of LLMs. It allows for the\nremoval of harmful knowledge in an efficient manner, without affecting\nunrelated knowledge in the model. To this end, we provide a survey of knowledge\nunlearning in the era of LLMs. Firstly, we formally define the knowledge\nunlearning problem and distinguish it from related works. Subsequently, we\ncategorize existing knowledge unlearning methods into three classes: those\nbased on parameter optimization, parameter merging, and in-context learning,\nand introduce details of these unlearning methods. We further present\nevaluation datasets used in existing methods, and finally conclude this survey\nby presenting the ongoing challenges and future directions.\n","authors":["Nianwen Si","Hao Zhang","Heyu Chang","Wenlin Zhang","Dan Qu","Weiqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.15766v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2311.15759v1","updated":"2023-11-27T12:29:20Z","published":"2023-11-27T12:29:20Z","title":"Towards Vision Enhancing LLMs: Empowering Multimodal Knowledge Storage\n  and Sharing in LLMs","summary":"  Recent advancements in multimodal large language models (MLLMs) have achieved\nsignificant multimodal generation capabilities, akin to GPT-4. These models\npredominantly map visual information into language representation space,\nleveraging the vast knowledge and powerful text generation abilities of LLMs to\nproduce multimodal instruction-following responses. We could term this method\nas LLMs for Vision because of its employing LLMs for visual-language\nunderstanding, yet observe that these MLLMs neglect the potential of harnessing\nvisual knowledge to enhance overall capabilities of LLMs, which could be\nregraded as Vision Enhancing LLMs. In this paper, we propose an approach called\nMKS2, aimed at enhancing LLMs through empowering Multimodal Knowledge Storage\nand Sharing in LLMs. Specifically, we introduce the Modular Visual Memory, a\ncomponent integrated into the internal blocks of LLMs, designed to store\nopen-world visual information efficiently. Additionally, we present a soft\nMixtures-of-Multimodal Experts architecture in LLMs to invoke multimodal\nknowledge collaboration during generation. Our comprehensive experiments\ndemonstrate that MKS2 substantially augments the reasoning capabilities of LLMs\nin contexts necessitating physical or commonsense knowledge. It also delivers\ncompetitive results on multimodal benchmarks.\n","authors":["Yunxin Li","Baotian Hu","Wei Wang","Xiaochun Cao","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.15759v1.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2311.15723v1","updated":"2023-11-27T11:17:29Z","published":"2023-11-27T11:17:29Z","title":"Italian Crossword Generator: Enhancing Education through Interactive\n  Word Puzzles","summary":"  Educational crosswords offer numerous benefits for students, including\nincreased engagement, improved understanding, critical thinking, and memory\nretention. Creating high-quality educational crosswords can be challenging, but\nrecent advances in natural language processing and machine learning have made\nit possible to use language models to generate nice wordplays. The exploitation\nof cutting-edge language models like GPT3-DaVinci, GPT3-Curie, GPT3-Babbage,\nGPT3-Ada, and BERT-uncased has led to the development of a comprehensive system\nfor generating and verifying crossword clues. A large dataset of clue-answer\npairs was compiled to fine-tune the models in a supervised manner to generate\noriginal and challenging clues from a given keyword. On the other hand, for\ngenerating crossword clues from a given text, Zero/Few-shot learning techniques\nwere used to extract clues from the input text, adding variety and creativity\nto the puzzles. We employed the fine-tuned model to generate data and labeled\nthe acceptability of clue-answer parts with human supervision. To ensure\nquality, we developed a classifier by fine-tuning existing language models on\nthe labeled dataset. Conversely, to assess the quality of clues generated from\nthe given text using zero/few-shot learning, we employed a zero-shot learning\napproach to check the quality of generated clues. The results of the evaluation\nhave been very promising, demonstrating the effectiveness of the approach in\ncreating high-standard educational crosswords that offer students engaging and\nrewarding learning experiences.\n","authors":["Kamyar Zeinalipour","Tommaso laquinta","Asya Zanollo","Giovanni Angelini","Leonardo Rigutini","Marco Maggini","Marco Gori"],"pdf_url":"https://arxiv.org/pdf/2311.15723v1.pdf","comment":"Accepted Paper for CLiC-it 2023 - 9th Italian Conference on\n  Computational Linguistics"},{"id":"http://arxiv.org/abs/2311.15716v1","updated":"2023-11-27T10:59:16Z","published":"2023-11-27T10:59:16Z","title":"Justifiable Artificial Intelligence: Engineering Large Language Models\n  for Legal Applications","summary":"  In this work, I discuss how Large Language Models can be applied in the legal\ndomain, circumventing their current drawbacks. Despite their large success and\nacceptance, their lack of explainability hinders legal experts to trust in\ntheir output, and this happens rightfully so. However, in this paper, I argue\nin favor of a new view, Justifiable Artificial Intelligence, instead of\nfocusing on Explainable Artificial Intelligence. I discuss in this paper how\ngaining evidence for and against a Large Language Model's output may make their\ngenerated texts more trustworthy - or hold them accountable for misinformation.\n","authors":["Sabine Wehnert"],"pdf_url":"https://arxiv.org/pdf/2311.15716v1.pdf","comment":"12 pages, 2 figures"},{"id":"http://arxiv.org/abs/2310.01825v2","updated":"2023-11-27T10:39:13Z","published":"2023-10-03T06:42:28Z","title":"Empirical Study of PEFT techniques for Winter Wheat Segmentation","summary":"  Parameter Efficient Fine Tuning (PEFT) techniques have recently experienced\nsignificant growth and have been extensively employed to adapt large vision and\nlanguage models to various domains, enabling satisfactory model performance\nwith minimal computational needs. Despite these advances, more research has yet\nto delve into potential PEFT applications in real-life scenarios, particularly\nin the critical domains of remote sensing and crop monitoring. The diversity of\nclimates across different regions and the need for comprehensive large-scale\ndatasets have posed significant obstacles to accurately identify crop types\nacross varying geographic locations and changing growing seasons. This study\nseeks to bridge this gap by comprehensively exploring the feasibility of\ncross-area and cross-year out-of-distribution generalization using the\nState-of-the-Art (SOTA) wheat crop monitoring model. The aim of this work is to\nexplore PEFT approaches for crop monitoring. Specifically, we focus on adapting\nthe SOTA TSViT model to address winter wheat field segmentation, a critical\ntask for crop monitoring and food security. This adaptation process involves\nintegrating different PEFT techniques, including BigFit, LoRA, Adaptformer, and\nprompt tuning. Using PEFT techniques, we achieved notable results comparable to\nthose achieved using full fine-tuning methods while training only a mere 0.7%\nparameters of the whole TSViT architecture. The in-house labeled data-set,\nreferred to as the Beqaa-Lebanon dataset, comprises high-quality annotated\npolygons for wheat and non-wheat classes with a total surface of 170 kmsq, over\nfive consecutive years. Using Sentinel-2 images, our model achieved a 84%\nF1-score. We intend to publicly release the Lebanese winter wheat data set,\ncode repository, and model weights.\n","authors":["Mohamad Hasan Zahweh","Hasan Nasrallah","Mustafa Shukor","Ghaleb Faour","Ali J. Ghandour"],"pdf_url":"https://arxiv.org/pdf/2310.01825v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15698v1","updated":"2023-11-27T10:34:55Z","published":"2023-11-27T10:34:55Z","title":"Cerbero-7B: A Leap Forward in Language-Specific LLMs Through Enhanced\n  Chat Corpus Generation and Evaluation","summary":"  This study introduces a novel approach for generating high-quality,\nlanguage-specific chat corpora using a self-chat mechanism. We combine a\ngenerator LLM for creating new samples and an embedder LLM to ensure diversity.\nA new Masked Language Modelling (MLM) model-based quality assessment metric is\nproposed for evaluating and filtering the corpora. Utilizing the llama2-70b as\nthe generator and a multilingual sentence transformer as embedder, we generate\nan Italian chat corpus and refine the Fauno corpus, which is based on\ntranslated English ChatGPT self-chat data. The refinement uses structural\nassertions and Natural Language Processing techniques. Both corpora undergo a\ncomprehensive quality evaluation using the proposed MLM model-based quality\nmetric. The Italian LLM fine-tuned with these corpora demonstrates\nsignificantly enhanced language comprehension and question-answering skills.\nThe resultant model, cerbero-7b, establishes a new state-of-the-art for Italian\nLLMs. This approach marks a substantial advancement in the development of\nlanguage-specific LLMs, with a special emphasis on augmenting corpora for\nunderrepresented languages like Italian.\n","authors":["Federico A. Galatolo","Mario G. C. A. Cimino"],"pdf_url":"https://arxiv.org/pdf/2311.15698v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.06422v2","updated":"2023-11-27T10:18:36Z","published":"2023-10-10T08:46:10Z","title":"Large Language Models for Propaganda Detection","summary":"  The prevalence of propaganda in our digital society poses a challenge to\nsocietal harmony and the dissemination of truth. Detecting propaganda through\nNLP in text is challenging due to subtle manipulation techniques and contextual\ndependencies. To address this issue, we investigate the effectiveness of modern\nLarge Language Models (LLMs) such as GPT-3 and GPT-4 for propaganda detection.\nWe conduct experiments using the SemEval-2020 task 11 dataset, which features\nnews articles labeled with 14 propaganda techniques as a multi-label\nclassification problem. Five variations of GPT-3 and GPT-4 are employed,\nincorporating various prompt engineering and fine-tuning strategies across the\ndifferent models. We evaluate the models' performance by assessing metrics such\nas $F1$ score, $Precision$, and $Recall$, comparing the results with the\ncurrent state-of-the-art approach using RoBERTa. Our findings demonstrate that\nGPT-4 achieves comparable results to the current state-of-the-art. Further,\nthis study analyzes the potential and challenges of LLMs in complex tasks like\npropaganda detection.\n","authors":["Kilian Sprenkamp","Daniel Gordon Jones","Liudmila Zavolokina"],"pdf_url":"https://arxiv.org/pdf/2310.06422v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15653v1","updated":"2023-11-27T09:33:13Z","published":"2023-11-27T09:33:13Z","title":"MoDS: Model-oriented Data Selection for Instruction Tuning","summary":"  Instruction tuning has become the de facto method to equip large language\nmodels (LLMs) with the ability of following user instructions. Usually,\nhundreds of thousands or millions of instruction-following pairs are employed\nto fine-tune the foundation LLMs. Recently, some studies show that a small\nnumber of high-quality instruction data is enough. However, how to select\nappropriate instruction data for a given LLM is still an open problem. To\naddress this problem, in this paper we present a model-oriented data selection\n(MoDS) approach, which selects instruction data based on a new criteria\nconsidering three aspects: quality, coverage and necessity. First, our approach\nutilizes a quality evaluation model to filter out the high-quality subset from\nthe original instruction dataset, and then designs an algorithm to further\nselect from the high-quality subset a seed instruction dataset with good\ncoverage. The seed dataset is applied to fine-tune the foundation LLM to obtain\nan initial instruction-following LLM. Finally, we develop a necessity\nevaluation model to find out the instruction data which are performed badly in\nthe initial instruction-following LLM and consider them necessary instructions\nto further improve the LLMs. In this way, we can get a small high-quality,\nbroad-coverage and high-necessity subset from the original instruction\ndatasets. Experimental results show that, the model fine-tuned with 4,000\ninstruction pairs selected by our approach could perform better than the model\nfine-tuned with the full original dataset which includes 214k instruction data.\n","authors":["Qianlong Du","Chengqing Zong","Jiajun Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.15653v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15648v1","updated":"2023-11-27T09:20:12Z","published":"2023-11-27T09:20:12Z","title":"Reinforcement Learning from Diffusion Feedback: Q* for Image Search","summary":"  Large vision-language models are steadily gaining personalization\ncapabilities at the cost of fine-tuning or data augmentation. We present two\nmodels for image generation using model-agnostic learning that align semantic\npriors with generative capabilities. RLDF, or Reinforcement Learning from\nDiffusion Feedback, is a singular approach for visual imitation through\nprior-preserving reward function guidance. This employs Q-learning (with\nstandard Q*) for generation and follows a semantic-rewarded trajectory for\nimage search through finite encoding-tailored actions. The second proposed\nmethod, noisy diffusion gradient, is optimization driven. At the root of both\nmethods is a special CFG encoding that we propose for continual semantic\nguidance. Using only a single input image and no text input, RLDF generates\nhigh-quality images over varied domains including retail, sports and\nagriculture showcasing class-consistency and strong visual diversity. Project\nwebsite is available at https://infernolia.github.io/RLDF.\n","authors":["Aboli Marathe"],"pdf_url":"https://arxiv.org/pdf/2311.15648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15642v1","updated":"2023-11-27T09:12:35Z","published":"2023-11-27T09:12:35Z","title":"InfoPattern: Unveiling Information Propagation Patterns in Social Media","summary":"  Social media play a significant role in shaping public opinion and\ninfluencing ideological communities through information propagation. Our demo\nInfoPattern centers on the interplay between language and human ideology. The\ndemo (Code: https://github.com/blender-nlp/InfoPattern ) is capable of: (1) red\nteaming to simulate adversary responses from opposite ideology communities; (2)\nstance detection to identify the underlying political sentiments in each\nmessage; (3) information propagation graph discovery to reveal the evolution of\nclaims across various communities over time. (Live Demo:\nhttps://incas.csl.illinois.edu/blender/About )\n","authors":["Chi Han","Jialiang Xu","Manling Li","Hanning Zhang","Tarek Abdelzaher","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2311.15642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.17255v3","updated":"2023-11-27T08:57:10Z","published":"2023-09-29T14:03:34Z","title":"Knowledge Graphs for the Life Sciences: Recent Developments, Challenges\n  and Opportunities","summary":"  The term life sciences refers to the disciplines that study living organisms\nand life processes, and include chemistry, biology, medicine, and a range of\nother related disciplines. Research efforts in life sciences are heavily\ndata-driven, as they produce and consume vast amounts of scientific data, much\nof which is intrinsically relational and graph-structured.\n  The volume of data and the complexity of scientific concepts and relations\nreferred to therein promote the application of advanced knowledge-driven\ntechnologies for managing and interpreting data, with the ultimate aim to\nadvance scientific discovery.\n  In this survey and position paper, we discuss recent developments and\nadvances in the use of graph-based technologies in life sciences and set out a\nvision for how these technologies will impact these fields into the future. We\nfocus on three broad topics: the construction and management of Knowledge\nGraphs (KGs), the use of KGs and associated technologies in the discovery of\nnew knowledge, and the use of KGs in artificial intelligence applications to\nsupport explanations (explainable AI). We select a few exemplary use cases for\neach topic, discuss the challenges and open research questions within these\ntopics, and conclude with a perspective and outlook that summarizes the\noverarching challenges and their potential solutions as a guide for future\nresearch.\n","authors":["Jiaoyan Chen","Hang Dong","Janna Hastings","Ernesto Jiménez-Ruiz","Vanessa López","Pierre Monnin","Catia Pesquita","Petr Škoda","Valentina Tamma"],"pdf_url":"https://arxiv.org/pdf/2309.17255v3.pdf","comment":"33 pages, 1 figure, accepted for Transactions on Graph Data and\n  Knowledge (TGDK)"},{"id":"http://arxiv.org/abs/2311.15626v1","updated":"2023-11-27T08:45:31Z","published":"2023-11-27T08:45:31Z","title":"The WebCrow French Crossword Solver","summary":"  Crossword puzzles are one of the most popular word games, played in different\nlanguages all across the world, where riddle style can vary significantly from\none country to another. Automated crossword resolution is challenging, and\ntypical solvers rely on large databases of previously solved crosswords. In\nthis work, we extend WebCrow 2.0, an automatic crossword solver, to French,\nmaking it the first program for crossword solving in the French language. To\ncope with the lack of a large repository of clue-answer crossword data, WebCrow\n2.0 exploits multiple modules, called experts, that retrieve candidate answers\nfrom heterogeneous resources, such as the web, knowledge graphs, and linguistic\nrules. We compared WebCrow's performance against humans in two different\nchallenges. Despite the limited amount of past crosswords, French WebCrow was\ncompetitive, actually outperforming humans in terms of speed and accuracy, thus\nproving its capabilities to generalize to new languages.\n","authors":["Giovanni Angelini","Marco Ernandes","Tommaso laquinta","Caroline Stehlé","Fanny Simões","Kamyar Zeinalipour","Andrea Zugarini","Marco Gori"],"pdf_url":"https://arxiv.org/pdf/2311.15626v1.pdf","comment":"Accepted Paper for EAI Intetain 2023 - 14th EAI International\n  Conference on Intelligent Technologies for Interactive Entertainment"},{"id":"http://arxiv.org/abs/2311.15623v1","updated":"2023-11-27T08:38:42Z","published":"2023-11-27T08:38:42Z","title":"Injecting linguistic knowledge into BERT for Dialogue State Tracking","summary":"  Dialogue State Tracking (DST) models often employ intricate neural network\narchitectures, necessitating substantial training data, and their inference\nprocesses lack transparency. This paper proposes a method that extracts\nlinguistic knowledge via an unsupervised framework and subsequently utilizes\nthis knowledge to augment BERT's performance and interpretability in DST tasks.\nThe knowledge extraction procedure is computationally economical and does not\nnecessitate annotations or additional training data. The injection of the\nextracted knowledge necessitates the addition of only simple neural modules. We\nemploy the Convex Polytopic Model (CPM) as a feature extraction tool for DST\ntasks and illustrate that the acquired features correlate with the syntactic\nand semantic patterns in the dialogues. This correlation facilitates a\ncomprehensive understanding of the linguistic features influencing the DST\nmodel's decision-making process. We benchmark this framework on various DST\ntasks and observe a notable improvement in accuracy.\n","authors":["Xiaohan Feng","Xixin Wu","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2311.15623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.15992v2","updated":"2023-11-27T08:30:00Z","published":"2023-07-29T14:11:15Z","title":"Towards Codable Watermarking for Injecting Multi-bit Information to LLM","summary":"  As large language models (LLMs) generate texts with increasing fluency and\nrealism, there is a growing need to identify the source of texts to prevent the\nabuse of LLMs. Text watermarking techniques have proven reliable in\ndistinguishing whether a text is generated by LLMs by injecting hidden patterns\ninto the generated texts. However, we argue that existing watermarking methods\nfor LLMs are encoding-inefficient (only contain one bit of information -\nwhether it is generated from an LLM or not) and cannot flexibly meet the\ndiverse information encoding needs (such as encoding model version, generation\ntime, user id, etc.) in different LLMs application scenarios. In this work, we\nconduct the first systematic study on the topic of Codable Text Watermarking\nfor LLMs (CTWL) that allows text watermarks to carry more customizable\ninformation. First of all, we study the taxonomy of LLM watermarking technology\nand give a mathematical formulation for CTWL. Additionally, we provide a\ncomprehensive evaluation system for CTWL: (1) watermarking success rate, (2)\nrobustness against various corruptions, (3) coding rate of payload information,\n(4) encoding and decoding efficiency, (5) impacts on the quality of the\ngenerated text. To meet the requirements of these non-Pareto-improving metrics,\nwe devise a CTWL method named Balance-Marking, based on the motivation of\nensuring that available and unavailable vocabularies for encoding information\nhave approximately equivalent probabilities. Compared to the random vocabulary\npartitioning extended from the existing work, a probability-balanced vocabulary\npartition can significantly improve the quality of the generated text.\nExtensive experimental results have shown that our method outperforms a direct\nbaseline under comprehensive evaluation.\n","authors":["Lean Wang","Wenkai Yang","Deli Chen","Hao Zhou","Yankai Lin","Fandong Meng","Jie Zhou","Xu Sun"],"pdf_url":"https://arxiv.org/pdf/2307.15992v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15614v1","updated":"2023-11-27T08:23:08Z","published":"2023-11-27T08:23:08Z","title":"FreeAL: Towards Human-Free Active Learning in the Era of Large Language\n  Models","summary":"  Collecting high-quality labeled data for model training is notoriously\ntime-consuming and labor-intensive for various NLP tasks. While copious\nsolutions, such as active learning for small language models (SLMs) and\nprevalent in-context learning in the era of large language models (LLMs), have\nbeen proposed and alleviate the labeling burden to some extent, their\nperformances are still subject to human intervention. It is still underexplored\nhow to reduce the annotation cost in the LLMs era. To bridge this, we\nrevolutionize traditional active learning and propose an innovative\ncollaborative learning framework FreeAL to interactively distill and filter the\ntask-specific knowledge from LLMs. During collaborative training, an LLM serves\nas an active annotator inculcating its coarse-grained knowledge, while a\ndownstream SLM is incurred as a student to filter out high-quality in-context\nsamples to feedback LLM for the subsequent label refinery. Extensive\nexperiments on eight benchmark datasets demonstrate that FreeAL largely\nenhances the zero-shot performances for both SLM and LLM without any human\nsupervision. The code is available at https://github.com/Justherozen/FreeAL .\n","authors":["Ruixuan Xiao","Yiwen Dong","Junbo Zhao","Runze Wu","Minmin Lin","Gang Chen","Haobo Wang"],"pdf_url":"https://arxiv.org/pdf/2311.15614v1.pdf","comment":"Accepted to EMNLP 2023 (Main conference)"},{"id":"http://arxiv.org/abs/2311.15596v1","updated":"2023-11-27T07:44:25Z","published":"2023-11-27T07:44:25Z","title":"Can Vision-Language Models Think from a First-Person Perspective?","summary":"  Vision-language models (VLMs) have recently shown promising results in\ntraditional downstream tasks. Evaluation studies have emerged to assess their\nabilities, with the majority focusing on the third-person perspective, and only\na few addressing specific tasks from the first-person perspective. However, the\ncapability of VLMs to \"think\" from a first-person perspective, a crucial\nattribute for advancing autonomous agents and robotics, remains largely\nunexplored. To bridge this research gap, we introduce EgoThink, a novel visual\nquestion-answering benchmark that encompasses six core capabilities with twelve\ndetailed dimensions. The benchmark is constructed using selected clips from\negocentric videos, with manually annotated question-answer pairs containing\nfirst-person information. To comprehensively assess VLMs, we evaluate eighteen\npopular VLMs on EgoThink. Moreover, given the open-ended format of the answers,\nwe use GPT-4 as the automatic judge to compute single-answer grading.\nExperimental results indicate that although GPT-4V leads in numerous\ndimensions, all evaluated VLMs still possess considerable potential for\nimprovement in first-person perspective tasks. Meanwhile, enlarging the number\nof trainable parameters has the most significant impact on model performance on\nEgoThink. In conclusion, EgoThink serves as a valuable addition to existing\nevaluation benchmarks for VLMs, providing an indispensable resource for future\nresearch in the realm of embodied artificial intelligence and robotics.\n","authors":["Sijie Cheng","Zhicheng Guo","Jingwen Wu","Kechen Fang","Peng Li","Huaping Liu","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2311.15596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11509v2","updated":"2023-11-27T06:53:03Z","published":"2023-11-20T03:17:21Z","title":"Token-Level Adversarial Prompt Detection Based on Perplexity Measures\n  and Contextual Information","summary":"  In recent years, Large Language Models (LLM) have emerged as pivotal tools in\nvarious applications. However, these models are susceptible to adversarial\nprompt attacks, where attackers can carefully curate input strings that lead to\nundesirable outputs. The inherent vulnerability of LLMs stems from their\ninput-output mechanisms, especially when presented with intensely\nout-of-distribution (OOD) inputs. This paper proposes a token-level detection\nmethod to identify adversarial prompts, leveraging the LLM's capability to\npredict the next token's probability. We measure the degree of the model's\nperplexity and incorporate neighboring token information to encourage the\ndetection of contiguous adversarial prompt sequences. As a result, we propose\ntwo methods: one that identifies each token as either being part of an\nadversarial prompt or not, and another that estimates the probability of each\ntoken being part of an adversarial prompt.\n","authors":["Zhengmian Hu","Gang Wu","Saayan Mitra","Ruiyi Zhang","Tong Sun","Heng Huang","Viswanathan Swaminathan"],"pdf_url":"https://arxiv.org/pdf/2311.11509v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01889v4","updated":"2023-11-27T06:38:47Z","published":"2023-10-03T08:44:50Z","title":"Ring Attention with Blockwise Transformers for Near-Infinite Context","summary":"  Transformers have emerged as the architecture of choice for many\nstate-of-the-art AI models, showcasing exceptional performance across a wide\nrange of AI applications. However, the memory demands imposed by Transformers\nlimit their ability to handle long sequences, thereby posing challenges in\nutilizing videos, actions, and other long-form sequences and modalities in\ncomplex environments. We present a novel approach, Ring Attention with\nBlockwise Transformers (Ring Attention), which leverages blockwise computation\nof self-attention and feedforward to distribute long sequences across multiple\ndevices while fully overlapping the communication of key-value blocks with the\ncomputation of blockwise attention. Our approach enables training and inference\nof sequences that are up to device count times longer than those achievable by\nprior memory-efficient Transformers, without resorting to approximations or\nincurring additional communication and computation overheads. Extensive\nexperiments on language modeling and reinforcement learning tasks demonstrate\nthe effectiveness of our approach in allowing millions of tokens context size\nand improving performance.\n","authors":["Hao Liu","Matei Zaharia","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2310.01889v4.pdf","comment":"Code: https://github.com/lhao499/llm_large_context"},{"id":"http://arxiv.org/abs/2311.15566v1","updated":"2023-11-27T06:31:17Z","published":"2023-11-27T06:31:17Z","title":"SpotServe: Serving Generative Large Language Models on Preemptible\n  Instances","summary":"  The high computational and memory requirements of generative large language\nmodels (LLMs) make it challenging to serve them cheaply. This paper aims to\nreduce the monetary cost for serving LLMs by leveraging preemptible GPU\ninstances on modern clouds, which offer accesses to spare GPUs at a much\ncheaper price than regular instances but may be preempted by the cloud at any\ntime. Serving LLMs on preemptible instances requires addressing challenges\ninduced by frequent instance preemptions and the necessity of migrating\ninstances to handle these preemptions.\n  This paper presents SpotServe, the first distributed LLM serving system on\npreemptible instances. Several key techniques in SpotServe realize fast and\nreliable serving of generative LLMs on cheap preemptible instances. First,\nSpotServe dynamically adapts the LLM parallelization configuration for dynamic\ninstance availability and fluctuating workload, while balancing the trade-off\namong the overall throughput, inference latency and monetary costs. Second, to\nminimize the cost of migrating instances for dynamic reparallelization, the\ntask of migrating instances is formulated as a bipartite graph matching\nproblem, which uses the Kuhn-Munkres algorithm to identify an optimal migration\nplan that minimizes communications. Finally, to take advantage of the grace\nperiod offered by modern clouds, we introduce stateful inference recovery, a\nnew inference mechanism that commits inference progress at a much finer\ngranularity and allows SpotServe to cheaply resume inference upon preemption.\nWe evaluate on real spot instance preemption traces and various popular LLMs\nand show that SpotServe can reduce the P99 tail latency by 2.4 - 9.1x compared\nwith the best existing LLM serving systems. We also show that SpotServe can\nleverage the price advantage of preemptive instances, saving 54% monetary cost\ncompared with only using on-demand instances.\n","authors":["Xupeng Miao","Chunan Shi","Jiangfei Duan","Xiaoli Xi","Dahua Lin","Bin Cui","Zhihao Jia"],"pdf_url":"https://arxiv.org/pdf/2311.15566v1.pdf","comment":"ASPLOS 2024"},{"id":"http://arxiv.org/abs/2311.15565v1","updated":"2023-11-27T06:26:53Z","published":"2023-11-27T06:26:53Z","title":"Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing\n  AI-Generated Text","summary":"  My research investigates the use of cutting-edge hybrid deep learning models\nto accurately differentiate between AI-generated text and human writing. I\napplied a robust methodology, utilising a carefully selected dataset comprising\nAI and human texts from various sources, each tagged with instructions.\nAdvanced natural language processing techniques facilitated the analysis of\ntextual features. Combining sophisticated neural networks, the custom model\nenabled it to detect nuanced differences between AI and human content.\n","authors":["Finbarrs Oketunji"],"pdf_url":"https://arxiv.org/pdf/2311.15565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15564v1","updated":"2023-11-27T06:22:57Z","published":"2023-11-27T06:22:57Z","title":"Boot and Switch: Alternating Distillation for Zero-Shot Dense Retrieval","summary":"  Neural 'dense' retrieval models are state of the art for many datasets,\nhowever these models often exhibit limited domain transfer ability. Existing\napproaches to adaptation are unwieldy, such as requiring explicit supervision,\ncomplex model architectures, or massive external models. We present\n$\\texttt{ABEL}$, a simple but effective unsupervised method to enhance passage\nretrieval in zero-shot settings. Our technique follows a straightforward loop:\na dense retriever learns from supervision signals provided by a reranker, and\nsubsequently, the reranker is updated based on feedback from the improved\nretriever. By iterating this loop, the two components mutually enhance one\nanother's performance. Experimental results demonstrate that our unsupervised\n$\\texttt{ABEL}$ model outperforms both leading supervised and unsupervised\nretrievers on the BEIR benchmark. Meanwhile, it exhibits strong adaptation\nabilities to tasks and domains that were unseen during training. By either\nfine-tuning $\\texttt{ABEL}$ on labelled data or integrating it with existing\nsupervised dense retrievers, we achieve state-of-the-art\nresults.\\footnote{Source code is available at\n\\url{https://github.com/Fantabulous-J/BootSwitch}.}\n","authors":["Fan Jiang","Qiongkai Xu","Tom Drummond","Trevor Cohn"],"pdf_url":"https://arxiv.org/pdf/2311.15564v1.pdf","comment":"Accepted by EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2311.15563v1","updated":"2023-11-27T06:19:50Z","published":"2023-11-27T06:19:50Z","title":"Noisy Self-Training with Synthetic Queries for Dense Retrieval","summary":"  Although existing neural retrieval models reveal promising results when\ntraining data is abundant and the performance keeps improving as training data\nincreases, collecting high-quality annotated data is prohibitively costly. To\nthis end, we introduce a novel noisy self-training framework combined with\nsynthetic queries, showing that neural retrievers can be improved in a\nself-evolution manner with no reliance on any external models. Experimental\nresults show that our method improves consistently over existing methods on\nboth general-domain (e.g., MS-MARCO) and out-of-domain (i.e., BEIR) retrieval\nbenchmarks. Extra analysis on low-resource settings reveals that our method is\ndata efficient and outperforms competitive baselines, with as little as 30% of\nlabelled training data. Further extending the framework for reranker training\ndemonstrates that the proposed method is general and yields additional gains on\ntasks of diverse domains.\\footnote{Source code is available at\n\\url{https://github.com/Fantabulous-J/Self-Training-DPR}}\n","authors":["Fan Jiang","Tom Drummond","Trevor Cohn"],"pdf_url":"https://arxiv.org/pdf/2311.15563v1.pdf","comment":"Accepted by EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2311.15548v1","updated":"2023-11-27T05:27:13Z","published":"2023-11-27T05:27:13Z","title":"Deficiency of Large Language Models in Finance: An Empirical Examination\n  of Hallucination","summary":"  The hallucination issue is recognized as a fundamental deficiency of large\nlanguage models (LLMs), especially when applied to fields such as finance,\neducation, and law. Despite the growing concerns, there has been a lack of\nempirical investigation. In this paper, we provide an empirical examination of\nLLMs' hallucination behaviors in financial tasks. First, we empirically\ninvestigate LLM model's ability of explaining financial concepts and\nterminologies. Second, we assess LLM models' capacity of querying historical\nstock prices. Third, to alleviate the hallucination issue, we evaluate the\nefficacy of four practical methods, including few-shot learning, Decoding by\nContrasting Layers (DoLa), the Retrieval Augmentation Generation (RAG) method\nand the prompt-based tool learning method for a function to generate a query\ncommand. Finally, our major finding is that off-the-shelf LLMs experience\nserious hallucination behaviors in financial tasks. Therefore, there is an\nurgent need to call for research efforts in mitigating LLMs' hallucination.\n","authors":["Haoqiang Kang","Xiao-Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2311.15548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15544v1","updated":"2023-11-27T05:20:47Z","published":"2023-11-27T05:20:47Z","title":"The effect of source disclosure on evaluation of AI-generated messages:\n  A two-part study","summary":"  Advancements in artificial intelligence (AI) over the last decade demonstrate\nthat machines can exhibit communicative behavior and influence how humans\nthink, feel, and behave. In fact, the recent development of ChatGPT has shown\nthat large language models (LLMs) can be leveraged to generate high-quality\ncommunication content at scale and across domains, suggesting that they will be\nincreasingly used in practice. However, many questions remain about how knowing\nthe source of the messages influences recipients' evaluation of and preference\nfor AI-generated messages compared to human-generated messages. This paper\ninvestigated this topic in the context of vaping prevention messaging. In Study\n1, which was pre-registered, we examined the influence of source disclosure on\npeople's evaluation of AI-generated health prevention messages compared to\nhuman-generated messages. We found that source disclosure (i.e., labeling the\nsource of a message as AI vs. human) significantly impacted the evaluation of\nthe messages but did not significantly alter message rankings. In a follow-up\nstudy (Study 2), we examined how the influence of source disclosure may vary by\nthe participants' negative attitudes towards AI. We found a significant\nmoderating effect of negative attitudes towards AI on message evaluation, but\nnot for message selection. However, for those with moderate levels of negative\nattitudes towards AI, source disclosure decreased the preference for\nAI-generated messages. Overall, the results of this series of studies showed a\nslight bias against AI-generated messages once the source was disclosed, adding\nto the emerging area of study that lies at the intersection of AI and\ncommunication.\n","authors":["Sue Lim","Ralf Schmälzle"],"pdf_url":"https://arxiv.org/pdf/2311.15544v1.pdf","comment":"Manuscript currently under review. Paper presented at 109th Annual\n  National Communication Association (NCA) Conference, November 16-19, 2023. 10\n  pages, 5 figures"},{"id":"http://arxiv.org/abs/2309.01947v2","updated":"2023-11-27T05:03:31Z","published":"2023-09-05T04:47:55Z","title":"TODM: Train Once Deploy Many Efficient Supernet-Based RNN-T Compression\n  For On-device ASR Models","summary":"  Automatic Speech Recognition (ASR) models need to be optimized for specific\nhardware before they can be deployed on devices. This can be done by tuning the\nmodel's hyperparameters or exploring variations in its architecture.\nRe-training and re-validating models after making these changes can be a\nresource-intensive task. This paper presents TODM (Train Once Deploy Many), a\nnew approach to efficiently train many sizes of hardware-friendly on-device ASR\nmodels with comparable GPU-hours to that of a single training job. TODM\nleverages insights from prior work on Supernet, where Recurrent Neural Network\nTransducer (RNN-T) models share weights within a Supernet. It reduces layer\nsizes and widths of the Supernet to obtain subnetworks, making them smaller\nmodels suitable for all hardware types. We introduce a novel combination of\nthree techniques to improve the outcomes of the TODM Supernet: adaptive\ndropouts, an in-place Alpha-divergence knowledge distillation, and the use of\nScaledAdam optimizer. We validate our approach by comparing Supernet-trained\nversus individually tuned Multi-Head State Space Model (MH-SSM) RNN-T using\nLibriSpeech. Results demonstrate that our TODM Supernet either matches or\nsurpasses the performance of manually tuned models by up to a relative of 3%\nbetter in word error rate (WER), while efficiently keeping the cost of training\nmany models at a small constant.\n","authors":["Yuan Shangguan","Haichuan Yang","Danni Li","Chunyang Wu","Yassir Fathullah","Dilin Wang","Ayushi Dalmia","Raghuraman Krishnamoorthi","Ozlem Kalinli","Junteng Jia","Jay Mahadeokar","Xin Lei","Mike Seltzer","Vikas Chandra"],"pdf_url":"https://arxiv.org/pdf/2309.01947v2.pdf","comment":"Meta AI; Submitted to ICASSP 2024"},{"id":"http://arxiv.org/abs/2310.18332v2","updated":"2023-11-27T04:22:54Z","published":"2023-10-20T12:44:44Z","title":"WordArt Designer: User-Driven Artistic Typography Synthesis using Large\n  Language Models","summary":"  This paper introduces WordArt Designer, a user-driven framework for artistic\ntypography synthesis, relying on the Large Language Model (LLM). The system\nincorporates four key modules: the LLM Engine, SemTypo, StyTypo, and TexTypo\nmodules. 1) The LLM Engine, empowered by the LLM (e.g., GPT-3.5), interprets\nuser inputs and generates actionable prompts for the other modules, thereby\ntransforming abstract concepts into tangible designs. 2) The SemTypo module\noptimizes font designs using semantic concepts, striking a balance between\nartistic transformation and readability. 3) Building on the semantic layout\nprovided by the SemTypo module, the StyTypo module creates smooth, refined\nimages. 4) The TexTypo module further enhances the design's aesthetics through\ntexture rendering, enabling the generation of inventive textured fonts.\nNotably, WordArt Designer highlights the fusion of generative AI with artistic\ntypography. Experience its capabilities on ModelScope:\nhttps://www.modelscope.cn/studios/WordArt/WordArt.\n","authors":["Jun-Yan He","Zhi-Qi Cheng","Chenyang Li","Jingdong Sun","Wangmeng Xiang","Xianhui Lin","Xiaoyang Kang","Zengke Jin","Yusen Hu","Bin Luo","Yifeng Geng","Xuansong Xie","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2310.18332v2.pdf","comment":"Accepted by EMNLP 2023, 10 pages, 11 figures, 1 table, the system is\n  at https://www.modelscope.cn/studios/WordArt/WordArt"},{"id":"http://arxiv.org/abs/2311.15525v1","updated":"2023-11-27T04:01:13Z","published":"2023-11-27T04:01:13Z","title":"Overview of the VLSP 2022 -- Abmusu Shared Task: A Data Challenge for\n  Vietnamese Abstractive Multi-document Summarization","summary":"  This paper reports the overview of the VLSP 2022 - Vietnamese abstractive\nmulti-document summarization (Abmusu) shared task for Vietnamese News. This\ntask is hosted at the 9$^{th}$ annual workshop on Vietnamese Language and\nSpeech Processing (VLSP 2022). The goal of Abmusu shared task is to develop\nsummarization systems that could create abstractive summaries automatically for\na set of documents on a topic. The model input is multiple news documents on\nthe same topic, and the corresponding output is a related abstractive summary.\nIn the scope of Abmusu shared task, we only focus on Vietnamese news\nsummarization and build a human-annotated dataset of 1,839 documents in 600\nclusters, collected from Vietnamese news in 8 categories. Participated models\nare evaluated and ranked in terms of \\texttt{ROUGE2-F1} score, the most typical\nevaluation metric for document summarization problem.\n","authors":["Mai-Vu Tran","Hoang-Quynh Le","Duy-Cat Can","Quoc-An Nguyen"],"pdf_url":"https://arxiv.org/pdf/2311.15525v1.pdf","comment":"VLSP 2022"},{"id":"http://arxiv.org/abs/2311.15513v1","updated":"2023-11-27T03:17:09Z","published":"2023-11-27T03:17:09Z","title":"A Comparative and Experimental Study on Automatic Question Answering\n  Systems and its Robustness against Word Jumbling","summary":"  Question answer generation using Natural Language Processing models is\nubiquitous in the world around us. It is used in many use cases such as the\nbuilding of chat bots, suggestive prompts in google search and also as a way of\nnavigating information in banking mobile applications etc. It is highly\nrelevant because a frequently asked questions (FAQ) list can only have a finite\namount of questions but a model which can perform question answer generation\ncould be able to answer completely new questions that are within the scope of\nthe data. This helps us to be able to answer new questions accurately as long\nas it is a relevant question. In commercial applications, it can be used to\nincrease customer satisfaction and ease of usage. However a lot of data is\ngenerated by humans so it is susceptible to human error and this can adversely\naffect the model's performance and we are investigating this through our work\n","authors":["Shashidhar Reddy Javaji","Haoran Hu","Sai Sameer Vennam","Vijaya Gajanan Buddhavarapu"],"pdf_url":"https://arxiv.org/pdf/2311.15513v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15509v1","updated":"2023-11-27T03:08:41Z","published":"2023-11-27T03:08:41Z","title":"A Corpus for Named Entity Recognition in Chinese Novels with\n  Multi-genres","summary":"  Entities like person, location, organization are important for literary text\nanalysis. The lack of annotated data hinders the progress of named entity\nrecognition (NER) in literary domain. To promote the research of literary NER,\nwe build the largest multi-genre literary NER corpus containing 263,135\nentities in 105,851 sentences from 260 online Chinese novels spanning 13\ndifferent genres. Based on the corpus, we investigate characteristics of\nentities from different genres. We propose several baseline NER models and\nconduct cross-genre and cross-domain experiments. Experimental results show\nthat genre difference significantly impact NER performance though not as much\nas domain difference like literary domain and news domain. Compared with NER in\nnews domain, literary NER still needs much improvement and the\nOut-of-Vocabulary (OOV) problem is more challenging due to the high variety of\nentities in literary works.\n","authors":["Hanjie Zhao","Jinge Xie","Yuchen Yan","Yuxiang Jia","Yawen Ye","Hongying Zan"],"pdf_url":"https://arxiv.org/pdf/2311.15509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15507v1","updated":"2023-11-27T03:05:48Z","published":"2023-11-27T03:05:48Z","title":"Improving Word Sense Disambiguation in Neural Machine Translation with\n  Salient Document Context","summary":"  Lexical ambiguity is a challenging and pervasive problem in machine\ntranslation (\\mt). We introduce a simple and scalable approach to resolve\ntranslation ambiguity by incorporating a small amount of extra-sentential\ncontext in neural \\mt. Our approach requires no sense annotation and no change\nto standard model architectures. Since actual document context is not available\nfor the vast majority of \\mt training data, we collect related sentences for\neach input to construct pseudo-documents. Salient words from pseudo-documents\nare then encoded as a prefix to each source sentence to condition the\ngeneration of the translation. To evaluate, we release \\docmucow, a challenge\nset for translation disambiguation based on the English-German \\mucow\n\\cite{raganato-etal-2020-evaluation} augmented with document IDs. Extensive\nexperiments show that our method translates ambiguous source words better than\nstrong sentence-level baselines and comparable document-level baselines while\nreducing training costs.\n","authors":["Elijah Rippeth","Marine Carpuat","Kevin Duh","Matt Post"],"pdf_url":"https://arxiv.org/pdf/2311.15507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15500v1","updated":"2023-11-27T02:55:34Z","published":"2023-11-27T02:55:34Z","title":"Function-constrained Program Synthesis","summary":"  This work introduces (1) a technique that allows large language models (LLMs)\nto leverage user-provided code when solving programming tasks and (2) a method\nto iteratively generate modular sub-functions that can aid future code\ngeneration attempts when the initial code generated by the LLM is inadequate.\nGenerating computer programs in general-purpose programming languages like\nPython poses a challenge for LLMs when instructed to use code provided in the\nprompt. Code-specific LLMs (e.g., GitHub Copilot, CodeLlama2) can generate code\ncompletions in real-time by drawing on all code available in a development\nenvironment. However, restricting code-specific LLMs to use only in-context\ncode is not straightforward, as the model is not explicitly instructed to use\nthe user-provided code and users cannot highlight precisely which snippets of\ncode the model should incorporate into its context. Moreover, current systems\nlack effective recovery methods, forcing users to iteratively re-prompt the\nmodel with modified prompts until a sufficient solution is reached. Our method\ndiffers from traditional LLM-powered code-generation by constraining\ncode-generation to an explicit function set and enabling recovery from failed\nattempts through automatically generated sub-functions. When the LLM cannot\nproduce working code, we generate modular sub-functions to aid subsequent\nattempts at generating functional code. A by-product of our method is a library\nof reusable sub-functions that can solve related tasks, imitating a software\nteam where efficiency scales with experience. We also introduce a new\n\"half-shot\" evaluation paradigm that provides tighter estimates of LLMs' coding\nabilities compared to traditional zero-shot evaluation. Our proposed evaluation\nmethod encourages models to output solutions in a structured format, decreasing\nsyntax errors that can be mistaken for poor coding ability.\n","authors":["Patrick Hajali","Ignas Budvytis"],"pdf_url":"https://arxiv.org/pdf/2311.15500v1.pdf","comment":"17 pages, 6 figures, 2023 NeurIPS R0-Fomo Workshop"},{"id":"http://arxiv.org/abs/2311.15490v1","updated":"2023-11-27T02:17:11Z","published":"2023-11-27T02:17:11Z","title":"Optimizing and Fine-tuning Large Language Model for Urban Renewal","summary":"  This study aims to innovatively explore adaptive applications of large\nlanguage models (LLM) in urban renewal. It also aims to improve its performance\nand text generation quality for knowledge question-answering (QA) tasks. Based\non the ChatGLM, we automatically generate QA datasets using urban renewal\nscientific literature corpora in a self-instruct manner and then conduct joint\nfine-tuning training on the model using the Prefix and LoRA fine-tuning methods\nto create an LLM for urban renewal. By guiding the LLM to automatically\ngenerate QA data based on prompt words and given text, it is possible to\nquickly obtain datasets in the urban renewal field and provide data support for\nthe fine-tuning training of LLMs. The experimental results show that the joint\nfine-tuning training method proposed in this study can significantly improve\nthe performance of LLM on the QA tasks. Compared with LoRA fine-tuning, the\nmethod improves the Bleu and Rouge metrics on the test by about 5%; compared\nwith the model before fine-tuning, the method improves the Bleu and Rouge\nmetrics by about 15%-20%. This study demonstrates the effectiveness and\nsuperiority of the joint fine-tuning method using Prefix and LoRA for ChatGLM\nin the urban renewal knowledge QA tasks. It provides a new approach for\nfine-tuning LLMs on urban renewal-related tasks.\n","authors":["Xi Wang","Xianyao Ling","Tom Zhang","Xuecao Li","Shaolan Wang","Zhixing Li","Liang Zhang","Peng Gong"],"pdf_url":"https://arxiv.org/pdf/2311.15490v1.pdf","comment":"11 pages, 2 figures, 2 tables, 41 references"},{"id":"http://arxiv.org/abs/2311.15480v1","updated":"2023-11-27T01:44:02Z","published":"2023-11-27T01:44:02Z","title":"Automatic Time Signature Determination for New Scores Using Lyrics for\n  Latent Rhythmic Structure","summary":"  There has recently been a sharp increase in interest in Artificial\nIntelligence-Generated Content (AIGC). Despite this, musical components such as\ntime signatures have not been studied sufficiently to form an algorithmic\ndetermination approach for new compositions, especially lyrical songs. This is\nlikely because of the neglect of musical details, which is critical for\nconstructing a robust framework. Specifically, time signatures establish the\nfundamental rhythmic structure for almost all aspects of a song, including the\nphrases and notes. In this paper, we propose a novel approach that only uses\nlyrics as input to automatically generate a fitting time signature for lyrical\nsongs and uncover the latent rhythmic structure utilizing explainable machine\nlearning models. In particular, we devise multiple methods that are associated\nwith discovering lyrical patterns and creating new features that simultaneously\ncontain lyrical, rhythmic, and statistical information. In this approach, the\nbest of our experimental results reveal a 97.6% F1 score and a 0.996 Area Under\nthe Curve (AUC) of the Receiver Operating Characteristic (ROC) score. In\nconclusion, our research directly generates time signatures from lyrics\nautomatically for new scores utilizing machine learning, which is an innovative\nidea that approaches an understudied component of musicology and therefore\ncontributes significantly to the future of Artificial Intelligence (AI) music\ngeneration.\n","authors":["Callie C. Liao","Duoduo Liao","Jesse Guessford"],"pdf_url":"https://arxiv.org/pdf/2311.15480v1.pdf","comment":"Submitted to IEEE Big Data 2023 Conference"},{"id":"http://arxiv.org/abs/2305.11853v3","updated":"2023-11-27T00:42:07Z","published":"2023-05-19T17:43:58Z","title":"How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain,\n  and Cross-domain Settings","summary":"  Large language models (LLMs) with in-context learning have demonstrated\nremarkable capability in the text-to-SQL task. Previous research has prompted\nLLMs with various demonstration-retrieval strategies and intermediate reasoning\nsteps to enhance the performance of LLMs. However, those works often employ\nvaried strategies when constructing the prompt text for text-to-SQL inputs,\nsuch as databases and demonstration examples. This leads to a lack of\ncomparability in both the prompt constructions and their primary contributions.\nFurthermore, selecting an effective prompt construction has emerged as a\npersistent problem for future research. To address this limitation, we\ncomprehensively investigate the impact of prompt constructions across various\nsettings and provide insights into prompt constructions for future text-to-SQL\nstudies.\n","authors":["Shuaichen Chang","Eric Fosler-Lussier"],"pdf_url":"https://arxiv.org/pdf/2305.11853v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16362v1","updated":"2023-11-27T23:03:01Z","published":"2023-11-27T23:03:01Z","title":"Reducing Gender Bias in Machine Translation through Counterfactual Data\n  Generation","summary":"  Recent advances in neural methods have led to substantial improvement in the\nquality of Neural Machine Translation (NMT) systems. However, these systems\nfrequently produce translations with inaccurate gender (Stanovsky et al.,\n2019), which can be traced to bias in training data. Saunders and Byrne (2020)\ntackle this problem with a handcrafted dataset containing balanced gendered\nprofession words. By using this data to fine-tune an existing NMT model, they\nshow that gender bias can be significantly mitigated, albeit at the expense of\ntranslation quality due to catastrophic forgetting. They recover some of the\nlost quality with modified training objectives or additional models at\ninference. We find, however, that simply supplementing the handcrafted dataset\nwith a random sample from the base model training corpus is enough to\nsignificantly reduce the catastrophic forgetting. We also propose a novel\ndomain-adaptation technique that leverages in-domain data created with the\ncounterfactual data generation techniques proposed by Zmigrod et al. (2019) to\nfurther improve accuracy on the WinoMT challenge test set without significant\nloss in translation quality. We show its effectiveness in NMT systems from\nEnglish into three morphologically rich languages French, Spanish, and Italian.\nThe relevant dataset and code will be available at Github.\n","authors":["Ranjita Naik","Spencer Rarrick","Vishal Chowdhary"],"pdf_url":"https://arxiv.org/pdf/2311.16362v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16338v1","updated":"2023-11-27T21:54:50Z","published":"2023-11-27T21:54:50Z","title":"Releasing the CRaQAn (Coreference Resolution in Question-Answering): An\n  open-source dataset and dataset creation methodology using\n  instruction-following models","summary":"  Instruction-following language models demand robust methodologies for\ninformation retrieval to augment instructions for question-answering\napplications. A primary challenge is the resolution of coreferences in the\ncontext of chunking strategies for long documents. The critical barrier to\nexperimentation of handling coreferences is a lack of open source datasets,\nspecifically in question-answering tasks that require coreference resolution.\nIn this work we present our Coreference Resolution in Question-Answering\n(CRaQAn) dataset, an open-source dataset that caters to the nuanced information\nretrieval requirements of coreference resolution in question-answering tasks by\nproviding over 250 question-answer pairs containing coreferences. To develop\nthis dataset, we developed a novel approach for creating high-quality datasets\nusing an instruction-following model (GPT-4) and a Recursive Criticism and\nImprovement Loop.\n","authors":["Rob Grzywinski","Joshua D'Arcy","Rob Naidoff","Ashish Shukla","Alex Browne","Ren Gibbons","Brinnae Bent"],"pdf_url":"https://arxiv.org/pdf/2311.16338v1.pdf","comment":"NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following"},{"id":"http://arxiv.org/abs/2310.17639v2","updated":"2023-11-27T21:05:54Z","published":"2023-10-26T17:54:52Z","title":"In-Context Learning Dynamics with Random Binary Sequences","summary":"  Large language models (LLMs) trained on huge corpora of text datasets\ndemonstrate intriguing capabilities, achieving state-of-the-art performance on\ntasks they were not explicitly trained for. The precise nature of LLM\ncapabilities is often mysterious, and different prompts can elicit different\ncapabilities through in-context learning. We propose a framework that enables\nus to analyze in-context learning dynamics to understand latent concepts\nunderlying LLMs' behavioral patterns. This provides a more nuanced\nunderstanding than success-or-failure evaluation benchmarks, but does not\nrequire observing internal activations as a mechanistic interpretation of\ncircuits would. Inspired by the cognitive science of human randomness\nperception, we use random binary sequences as context and study dynamics of\nin-context learning by manipulating properties of context data, such as\nsequence length. In the latest GPT-3.5+ models, we find emergent abilities to\ngenerate seemingly random numbers and learn basic formal languages, with\nstriking in-context learning dynamics where model outputs transition sharply\nfrom seemingly random behaviors to deterministic repetition.\n","authors":["Eric J. Bigelow","Ekdeep Singh Lubana","Robert P. Dick","Hidenori Tanaka","Tomer D. Ullman"],"pdf_url":"https://arxiv.org/pdf/2310.17639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16302v1","updated":"2023-11-27T20:33:54Z","published":"2023-11-27T20:33:54Z","title":"Comprehensive Benchmarking of Entropy and Margin Based Scoring Metrics\n  for Data Selection","summary":"  While data selection methods have been studied extensively in active\nlearning, data pruning, and data augmentation settings, there is little\nevidence for the efficacy of these methods in industry scale settings,\nparticularly in low-resource languages. Our work presents ways of assessing\nprospective training examples in those settings for their \"usefulness\" or\n\"difficulty\". We also demonstrate how these measures can be used in selecting\nimportant examples for training supervised machine learning models. We\nprimarily experiment with entropy and Error L2-Norm (EL2N) scores. We use these\nmetrics to curate high quality datasets from a large pool of \\textit{Weak\nSignal Labeled} data, which assigns no-defect high confidence hypotheses during\ninference as ground truth labels. We then conduct training data augmentation\nexperiments using these de-identified datasets and demonstrate that score-based\nselection can result in a 2% decrease in semantic error rate and 4%-7% decrease\nin domain classification error rate when compared to the baseline technique of\nrandom selection.\n","authors":["Anusha Sabbineni","Nikhil Anand","Maria Minakova"],"pdf_url":"https://arxiv.org/pdf/2311.16302v1.pdf","comment":"Accepted to Efficient Natural Language and Speech Processing\n  (ENLSP-III) workshop at NeurIPS '23"},{"id":"http://arxiv.org/abs/2311.16298v1","updated":"2023-11-27T20:19:22Z","published":"2023-11-27T20:19:22Z","title":"Influence Scores at Scale for Efficient Language Data Sampling","summary":"  Modern ML systems ingest data aggregated from diverse sources, such as\nsynthetic, human-annotated, and live customer traffic. Understanding\n\\textit{which} examples are important to the performance of a learning\nalgorithm is crucial for efficient model training. Recently, a growing body of\nliterature has given rise to various \"influence scores,\" which use training\nartifacts such as model confidence or checkpointed gradients to identify\nimportant subsets of data. However, these methods have primarily been developed\nin computer vision settings, and it remains unclear how well they generalize to\nlanguage-based tasks using pretrained models.\n  In this paper, we explore the applicability of influence scores in language\nclassification tasks. We evaluate a diverse subset of these scores on the SNLI\ndataset by quantifying accuracy changes in response to pruning training data\nthrough random and influence-score-based sampling. We then stress-test one of\nthe scores -- \"variance of gradients\" (VoG) from Agarwal et al. (2022) -- in an\nNLU model stack that was exposed to dynamic user speech patterns in a voice\nassistant type of setting. Our experiments demonstrate that in many cases,\nencoder-based language models can be finetuned on roughly 50% of the original\ndata without degradation in performance metrics. Along the way, we summarize\nlessons learned from applying out-of-the-box implementations of influence\nscores, quantify the effects of noisy and class-imbalanced data, and offer\nrecommendations on score-based sampling for better accuracy and training\nefficiency.\n","authors":["Nikhil Anand","Joshua Tan","Maria Minakova"],"pdf_url":"https://arxiv.org/pdf/2311.16298v1.pdf","comment":"Accepted at EMNLP '23"},{"id":"http://arxiv.org/abs/2311.16292v1","updated":"2023-11-27T20:10:13Z","published":"2023-11-27T20:10:13Z","title":"Student Mastery or AI Deception? Analyzing ChatGPT's Assessment\n  Proficiency and Evaluating Detection Strategies","summary":"  Generative AI systems such as ChatGPT have a disruptive effect on learning\nand assessment. Computer science requires practice to develop skills in problem\nsolving and programming that are traditionally developed using assignments.\nGenerative AI has the capability of completing these assignments for students\nwith high accuracy, which dramatically increases the potential for academic\nintegrity issues and students not achieving desired learning outcomes. This\nwork investigates the performance of ChatGPT by evaluating it across three\ncourses (CS1,CS2,databases). ChatGPT completes almost all introductory\nassessments perfectly. Existing detection methods, such as MOSS and JPlag\n(based on similarity metrics) and GPTzero (AI detection), have mixed success in\nidentifying AI solutions. Evaluating instructors and teaching assistants using\nheuristics to distinguish between student and AI code shows that their\ndetection is not sufficiently accurate. These observations emphasize the need\nfor adapting assessments and improved detection methods.\n","authors":["Kevin Wang","Seth Akins","Abdallah Mohammed","Ramon Lawrence"],"pdf_url":"https://arxiv.org/pdf/2311.16292v1.pdf","comment":"7 pages, Published in 2023 International Conference on Computational\n  Science and Computational Intelligence Research Track on Education, IEEE CPS"},{"id":"http://arxiv.org/abs/2212.09744v2","updated":"2023-11-27T19:57:09Z","published":"2022-12-19T18:59:34Z","title":"DSI++: Updating Transformer Memory with New Documents","summary":"  Differentiable Search Indices (DSIs) encode a corpus of documents in model\nparameters and use the same model to answer user queries directly. Despite the\nstrong performance of DSI models, deploying them in situations where the corpus\nchanges over time is computationally expensive because reindexing the corpus\nrequires re-training the model. In this work, we introduce DSI++, a continual\nlearning challenge for DSI to incrementally index new documents while being\nable to answer queries related to both previously and newly indexed documents.\nAcross different model scales and document identifier representations, we show\nthat continual indexing of new documents leads to considerable forgetting of\npreviously indexed documents. We also hypothesize and verify that the model\nexperiences forgetting events during training, leading to unstable learning. To\nmitigate these issues, we investigate two approaches. The first focuses on\nmodifying the training dynamics. Flatter minima implicitly alleviate\nforgetting, so we optimize for flatter loss basins and show that the model\nstably memorizes more documents ($+12\\%$). Next, we introduce a generative\nmemory to sample pseudo-queries for documents and supplement them during\ncontinual indexing to prevent forgetting for the retrieval task. Extensive\nexperiments on novel continual indexing benchmarks based on Natural Questions\n(NQ) and MS MARCO demonstrate that our proposed solution mitigates forgetting\nsignificantly. Concretely, it improves the average Hits@10 by $+21.1\\%$ over\ncompetitive baselines for NQ and requires $6$ times fewer model updates\ncompared to re-training the DSI model for incrementally indexing five corpora\nin a sequence.\n","authors":["Sanket Vaibhav Mehta","Jai Gupta","Yi Tay","Mostafa Dehghani","Vinh Q. Tran","Jinfeng Rao","Marc Najork","Emma Strubell","Donald Metzler"],"pdf_url":"https://arxiv.org/pdf/2212.09744v2.pdf","comment":"Accepted at EMNLP 2023 main conference"},{"id":"http://arxiv.org/abs/2305.14726v2","updated":"2023-11-27T19:53:27Z","published":"2023-05-24T05:04:00Z","title":"In-Context Demonstration Selection with Cross Entropy Difference","summary":"  Large language models (LLMs) can use in-context demonstrations to improve\nperformance on zero-shot tasks. However, selecting the best in-context examples\nis challenging because model performance can vary widely depending on the\nselected examples. We present a cross-entropy difference (CED) method for\nselecting in-context demonstrations. Our method is based on the observation\nthat the effectiveness of in-context demonstrations negatively correlates with\nthe perplexity of the test example by a language model that was finetuned on\nthat demonstration. We utilize parameter efficient finetuning to train small\nmodels on training data that are used for computing the cross-entropy\ndifference between a test example and every candidate in-context demonstration.\nThis metric is used to rank and select in-context demonstrations independently\nfor each test input. We evaluate our method on a mix-domain dataset that\ncombines 8 benchmarks, representing 4 text generation tasks, showing that CED\nfor in-context demonstration selection can improve performance for a variety of\nLLMs.\n","authors":["Dan Iter","Reid Pryzant","Ruochen Xu","Shuohang Wang","Yang Liu","Yichong Xu","Chenguang Zhu"],"pdf_url":"https://arxiv.org/pdf/2305.14726v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16267v1","updated":"2023-11-27T19:17:39Z","published":"2023-11-27T19:17:39Z","title":"Applications of Large Language Models in Data Processing: Innovative\n  Approaches to Segmenting and Renewing Information","summary":"  Our paper investigates effective methods for code generation in\n\"specific-domain\" applications, including the use of Large Language Models\n(LLMs) for data segmentation and renewal, as well as stimulating deeper\nthinking in LLMs through prompt adjustments. Using a real company product as an\nexample, we provide user manuals, API documentation, and other data. The ideas\ndiscussed in this paper help segment and then convert this data into semantic\nvectors to better reflect their true positioning. Subsequently, user\nrequirements are transformed into vectors to retrieve the most relevant\ncontent, achieving about 70% accuracy in simple to medium-complexity tasks\nthrough various prompt techniques. This paper is the first to enhance\nspecific-domain code generation effectiveness from this perspective.\nAdditionally, we experiment with generating more scripts from a limited number\nusing llama2-based fine-tuning to test its effectiveness in professional domain\ncode generation. This is a challenging and promising field, and once achieved,\nit will not only lead to breakthroughs in LLM development across multiple\nindustries but also enable LLMs to understand and learn any new knowledge\neffectively.\n","authors":["Yu-Chen Lin","Akhilesh Kumar","Wen-Liang Zhang","Norman Chang","Muhammad Zakir","Rucha Apte","Chao Wang","Jyh-Shing Roger Jang"],"pdf_url":"https://arxiv.org/pdf/2311.16267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16258v1","updated":"2023-11-27T19:04:37Z","published":"2023-11-27T19:04:37Z","title":"An Exploration of Left-Corner Transformations","summary":"  The left-corner transformation (Rosenkrantz and Lewis, 1970) is used to\nremove left recursion from context-free grammars, which is an important step\ntowards making the grammar parsable top-down with simple techniques. This paper\ngeneralizes prior left-corner transformations to support semiring-weighted\nproduction rules and to provide finer-grained control over which left corners\nmay be moved. Our generalized left-corner transformation (GLCT) arose from\nunifying the left-corner transformation and speculation transformation (Eisner\nand Blatz, 2007), originally for logic programming. Our new transformation and\nspeculation define equivalent weighted languages. Yet, their derivation trees\nare structurally different in an important way: GLCT replaces left recursion\nwith right recursion, and speculation does not. We also provide several\ntechnical results regarding the formal relationships between the outputs of\nGLCT, speculation, and the original grammar. Lastly, we empirically investigate\nthe efficiency of GLCT for left-recursion elimination from grammars of nine\nlanguages.\n","authors":["Andreas Opedal","Eleftheria Tsipidi","Tiago Pimentel","Ryan Cotterell","Tim Vieira"],"pdf_url":"https://arxiv.org/pdf/2311.16258v1.pdf","comment":"Main conference long paper at EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.16254v1","updated":"2023-11-27T19:02:17Z","published":"2023-11-27T19:02:17Z","title":"Removing NSFW Concepts from Vision-and-Language Models for Text-to-Image\n  Retrieval and Generation","summary":"  Vision-and-Language models such as CLIP have demonstrated remarkable\neffectiveness across a wide range of tasks. However, these models are typically\ntrained on web-scale data, which can introduce inappropriate content and lead\nto the development of unsafe and biased behavior. This, in turn, hampers their\napplicability in sensitive and trustworthy contexts and could raise significant\nconcern in their adoption. To overcome these limitations, we introduce a\nmethodology to make Vision-and-Language models safer by removing their\nsensitivity to not-safe-for-work concepts. We show how this can be done by\ndistilling from a large language model which converts between safe and unsafe\nsentences and which is fine-tuned starting from just 100 manually-curated\npairs. We conduct extensive experiments on the resulting embedding space for\nboth retrieval and text-to-image generation, where we show that our model can\nalso be properly employed with pre-trained image generators. Our source code\nand trained models are available at: https://github.com/aimagelab/safe-clip.\n","authors":["Samuele Poppi","Tobia Poppi","Federico Cocchi","Marcella Cornia","Lorenzo Baraldi","Rita Cucchiara"],"pdf_url":"https://arxiv.org/pdf/2311.16254v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16502v1","updated":"2023-11-27T17:33:21Z","published":"2023-11-27T17:33:21Z","title":"MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning\n  Benchmark for Expert AGI","summary":"  We introduce MMMU: a new benchmark designed to evaluate multimodal models on\nmassive multi-discipline tasks demanding college-level subject knowledge and\ndeliberate reasoning. MMMU includes 11.5K meticulously collected multimodal\nquestions from college exams, quizzes, and textbooks, covering six core\ndisciplines: Art & Design, Business, Science, Health & Medicine, Humanities &\nSocial Science, and Tech & Engineering. These questions span 30 subjects and\n183 subfields, comprising 30 highly heterogeneous image types, such as charts,\ndiagrams, maps, tables, music sheets, and chemical structures. Unlike existing\nbenchmarks, MMMU focuses on advanced perception and reasoning with\ndomain-specific knowledge, challenging models to perform tasks akin to those\nfaced by experts. Our evaluation of 14 open-source LMMs and the proprietary\nGPT-4V(ision) highlights the substantial challenges posed by MMMU. Even the\nadvanced GPT-4V only achieves a 56% accuracy, indicating significant room for\nimprovement. We believe MMMU will stimulate the community to build\nnext-generation multimodal foundation models towards expert artificial general\nintelligence.\n","authors":["Xiang Yue","Yuansheng Ni","Kai Zhang","Tianyu Zheng","Ruoqi Liu","Ge Zhang","Samuel Stevens","Dongfu Jiang","Weiming Ren","Yuxuan Sun","Cong Wei","Botao Yu","Ruibin Yuan","Renliang Sun","Ming Yin","Boyuan Zheng","Zhenzhu Yang","Yibo Liu","Wenhao Huang","Huan Sun","Yu Su","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2311.16502v1.pdf","comment":"115 pages, 99 figures"},{"id":"http://arxiv.org/abs/2311.16483v1","updated":"2023-11-27T15:20:23Z","published":"2023-11-27T15:20:23Z","title":"ChartLlama: A Multimodal LLM for Chart Understanding and Generation","summary":"  Multi-modal large language models have demonstrated impressive performances\non most vision-language tasks. However, the model generally lacks the\nunderstanding capabilities for specific domain data, particularly when it comes\nto interpreting chart figures. This is mainly due to the lack of relevant\nmulti-modal instruction tuning datasets. In this article, we create a\nhigh-quality instruction-tuning dataset leveraging GPT-4. We develop a\nmulti-step data generation process in which different steps are responsible for\ngenerating tabular data, creating chart figures, and designing instruction\ntuning data separately. Our method's flexibility enables us to generate\ndiverse, high-quality instruction-tuning data consistently and efficiently\nwhile maintaining a low resource expenditure. Additionally, it allows us to\nincorporate a wider variety of chart and task types not yet featured in\nexisting datasets. Next, we introduce ChartLlama, a multi-modal large language\nmodel that we've trained using our created dataset. ChartLlama outperforms all\nprior methods in ChartQA, Chart-to-text, and Chart-extraction evaluation\nbenchmarks. Additionally, ChartLlama significantly improves upon the baseline\nin our specially compiled chart dataset, which includes new chart and task\ntypes. The results of ChartLlama confirm the value and huge potential of our\nproposed data generation method in enhancing chart comprehension.\n","authors":["Yucheng Han","Chi Zhang","Xin Chen","Xu Yang","Zhibin Wang","Gang Yu","Bin Fu","Hanwang Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.16483v1.pdf","comment":"Code and model on https://tingxueronghua.github.io/ChartLlama/"},{"id":"http://arxiv.org/abs/2311.16203v1","updated":"2023-11-27T08:52:10Z","published":"2023-11-27T08:52:10Z","title":"ChatTraffc: Text-to-Traffic Generation via Diffusion Model","summary":"  Traffic prediction is one of the most significant foundations in Intelligent\nTransportation Systems (ITS). Traditional traffic prediction methods rely only\non historical traffic data to predict traffic trends and face two main\nchallenges. 1) insensitivity to unusual events. 2) poor performance in\nlong-term prediction. In this work, we explore how generative models combined\nwith text describing the traffic system can be applied for traffic generation\nand name the task Text-to-Traffic Generation (TTG). The key challenge of the\nTTG task is how to associate text with the spatial structure of the road\nnetwork and traffic data for generating traffic situations. To this end, we\npropose ChatTraffic, the first diffusion model for text-to-traffic generation.\nTo guarantee the consistency between synthetic and real data, we augment a\ndiffusion model with the Graph Convolutional Network (GCN) to extract spatial\ncorrelations of traffic data. In addition, we construct a large dataset\ncontaining text-traffic pairs for the TTG task. We benchmarked our model\nqualitatively and quantitatively on the released dataset. The experimental\nresults indicate that ChatTraffic can generate realistic traffic situations\nfrom the text. Our code and dataset are available at\nhttps://github.com/ChyaZhang/ChatTraffic.\n","authors":["Chengyang Zhang","Yong Zhang","Qitan Shao","Bo Li","Yisheng Lv","Xinglin Piao","Baocai Yin"],"pdf_url":"https://arxiv.org/pdf/2311.16203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16201v1","updated":"2023-11-27T07:19:26Z","published":"2023-11-27T07:19:26Z","title":"Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image\n  Generation","summary":"  Recent advances in image tokenizers, such as VQ-VAE, have enabled\ntext-to-image generation using auto-regressive methods, similar to language\nmodeling. However, these methods have yet to leverage pre-trained language\nmodels, despite their adaptability to various downstream tasks. In this work,\nwe explore this gap by adapting a pre-trained language model for\nauto-regressive text-to-image generation, and find that pre-trained language\nmodels offer limited help. We provide a two-fold explanation by analyzing\ntokens from each modality. First, we demonstrate that image tokens possess\nsignificantly different semantics compared to text tokens, rendering\npre-trained language models no more effective in modeling them than randomly\ninitialized ones. Second, the text tokens in the image-text datasets are too\nsimple compared to normal language model pre-training data, which causes the\ncatastrophic degradation of language models' capability.\n","authors":["Yuhui Zhang","Brandon McKinzie","Zhe Gan","Vaishaal Shankar","Alexander Toshev"],"pdf_url":"https://arxiv.org/pdf/2311.16201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16480v1","updated":"2023-11-27T05:05:41Z","published":"2023-11-27T05:05:41Z","title":"MI-Gen: Multiple Instance Generation of Pathology Reports for Gigapixel\n  Whole-Slide Images","summary":"  Whole slide images are the foundation of digital pathology for the diagnosis\nand treatment of carcinomas. Writing pathology reports is laborious and\nerror-prone for inexperienced pathologists. To reduce the workload and improve\nclinical automation, we investigate how to generate pathology reports given\nwhole slide images. On the data end, we curated the largest WSI-text dataset\n(TCGA-PathoText). In specific, we collected nearly 10000 high-quality WSI-text\npairs for visual-language models by recognizing and cleaning pathology reports\nwhich narrate diagnostic slides in TCGA. On the model end, we propose the\nmultiple instance generative model (MI-Gen) which can produce pathology reports\nfor gigapixel WSIs. We benchmark our model on the largest subset of\nTCGA-PathoText. Experimental results show our model can generate pathology\nreports which contain multiple clinical clues. Furthermore, WSI-text prediction\ncan be seen as an approach of visual-language pre-training, which enables our\nmodel to be transferred to downstream diagnostic tasks like carcinoma grading\nand phenotyping. We observe that simple semantic extraction from the pathology\nreports can achieve the best performance (0.838 of F1 score) on BRCA subtyping\nwithout adding extra parameters or tricky fine-tuning. Our collected dataset\nand related code will all be publicly available.\n","authors":["Pingyi Chen","Honglin Li","Chenglu Zhu","Sunyi Zheng","Lin Yang"],"pdf_url":"https://arxiv.org/pdf/2311.16480v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2310.17294v3","updated":"2023-11-27T06:21:03Z","published":"2023-10-26T10:18:51Z","title":"Scale-Adaptive Feature Aggregation for Efficient Space-Time Video\n  Super-Resolution","summary":"  The Space-Time Video Super-Resolution (STVSR) task aims to enhance the visual\nquality of videos, by simultaneously performing video frame interpolation (VFI)\nand video super-resolution (VSR). However, facing the challenge of the\nadditional temporal dimension and scale inconsistency, most existing STVSR\nmethods are complex and inflexible in dynamically modeling different motion\namplitudes. In this work, we find that choosing an appropriate processing scale\nachieves remarkable benefits in flow-based feature propagation. We propose a\nnovel Scale-Adaptive Feature Aggregation (SAFA) network that adaptively selects\nsub-networks with different processing scales for individual samples.\nExperiments on four public STVSR benchmarks demonstrate that SAFA achieves\nstate-of-the-art performance. Our SAFA network outperforms recent\nstate-of-the-art methods such as TMNet and VideoINR by an average improvement\nof over 0.5dB on PSNR, while requiring less than half the number of parameters\nand only 1/3 computational costs.\n","authors":["Zhewei Huang","Ailin Huang","Xiaotao Hu","Chen Hu","Jun Xu","Shuchang Zhou"],"pdf_url":"https://arxiv.org/pdf/2310.17294v3.pdf","comment":"WACV2024, 16 pages"},{"id":"http://arxiv.org/abs/2311.14084v2","updated":"2023-11-27T13:43:19Z","published":"2023-11-23T16:22:58Z","title":"AI-Generated Images Introduce Invisible Relevance Bias to Text-Image\n  Retrieval","summary":"  With the advancement of generation models, AI-generated content (AIGC) is\nbecoming more realistic, flooding the Internet. A recent study suggests that\nthis phenomenon has elevated the issue of source bias in text retrieval for web\nsearches. Specifically, neural retrieval models tend to rank generated texts\nhigher than human-written texts. In this paper, we extend the study of this\nbias to cross-modal retrieval. Firstly, we successfully construct a suitable\nbenchmark to explore the existence of the bias. Subsequent extensive\nexperiments on this benchmark reveal that AI-generated images introduce an\ninvisible relevance bias to text-image retrieval models. Specifically, our\nexperiments show that text-image retrieval models tend to rank the AI-generated\nimages higher than the real images, even though the AI-generated images do not\nexhibit more visually relevant features to the query than real images. This\ninvisible relevance bias is prevalent across retrieval models with varying\ntraining data and architectures. Furthermore, our subsequent exploration\nreveals that the inclusion of AI-generated images in the training data of the\nretrieval models exacerbates the invisible relevance bias. The above phenomenon\ntriggers a vicious cycle, which makes the invisible relevance bias become more\nand more serious. To elucidate the potential causes of invisible relevance and\naddress the aforementioned issues, we introduce an effective training method\naimed at alleviating the invisible relevance bias. Subsequently, we apply our\nproposed debiasing method to retroactively identify the causes of invisible\nrelevance, revealing that the AI-generated images induce the image encoder to\nembed additional information into their representation. This information\nexhibits a certain consistency across generated images with different semantics\nand can make the retriever estimate a higher relevance score.\n","authors":["Shicheng Xu","Danyang Hou","Liang Pang","Jingcheng Deng","Jun Xu","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2311.14084v2.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2311.13959v2","updated":"2023-11-27T09:47:10Z","published":"2023-11-23T12:17:45Z","title":"RankFeat&RankWeight: Rank-1 Feature/Weight Removal for\n  Out-of-distribution Detection","summary":"  The task of out-of-distribution (OOD) detection is crucial for deploying\nmachine learning models in real-world settings. In this paper, we observe that\nthe singular value distributions of the in-distribution (ID) and OOD features\nare quite different: the OOD feature matrix tends to have a larger dominant\nsingular value than the ID feature, and the class predictions of OOD samples\nare largely determined by it. This observation motivates us to propose\n\\texttt{RankFeat}, a simple yet effective \\emph{post hoc} approach for OOD\ndetection by removing the rank-1 matrix composed of the largest singular value\nand the associated singular vectors from the high-level feature.\n\\texttt{RankFeat} achieves \\emph{state-of-the-art} performance and reduces the\naverage false positive rate (FPR95) by 17.90\\% compared with the previous best\nmethod. The success of \\texttt{RankFeat} motivates us to investigate whether a\nsimilar phenomenon would exist in the parameter matrices of neural networks. We\nthus propose \\texttt{RankWeight} which removes the rank-1 weight from the\nparameter matrices of a single deep layer. Our \\texttt{RankWeight}is also\n\\emph{post hoc} and only requires computing the rank-1 matrix once. As a\nstandalone approach, \\texttt{RankWeight} has very competitive performance\nagainst other methods across various backbones. Moreover, \\texttt{RankWeight}\nenjoys flexible compatibility with a wide range of OOD detection methods. The\ncombination of \\texttt{RankWeight} and \\texttt{RankFeat} refreshes the new\n\\emph{state-of-the-art} performance, achieving the FPR95 as low as 16.13\\% on\nthe ImageNet-1k benchmark. Extensive ablation studies and comprehensive\ntheoretical analyses are presented to support the empirical results.\n","authors":["Yue Song","Nicu Sebe","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13959v2.pdf","comment":"submitted to T-PAMI. arXiv admin note: substantial text overlap with\n  arXiv:2209.08590"},{"id":"http://arxiv.org/abs/2309.17389v4","updated":"2023-11-27T10:46:03Z","published":"2023-09-29T16:50:38Z","title":"Prompt-based test-time real image dehazing: a novel pipeline","summary":"  Existing methods attempt to improve models' generalization ability on\nreal-world hazy images by exploring well-designed training schemes (e.g.,\nCycleGAN, prior loss). However, most of them need very complicated training\nprocedures to achieve satisfactory results. In this work, we present a totally\nnovel testing pipeline called Prompt-based Test-Time Dehazing (PTTD) to help\ngenerate visually pleasing results of real-captured hazy images during the\ninference phase. We experimentally find that given a dehazing model trained on\nsynthetic data, by fine-tuning the statistics (i.e., mean and standard\ndeviation) of encoding features, PTTD is able to narrow the domain gap,\nboosting the performance of real image dehazing. Accordingly, we first apply a\nprompt generation module (PGM) to generate a visual prompt, which is the source\nof appropriate statistical perturbations for mean and standard deviation. And\nthen, we employ the feature adaptation module (FAM) into the existing dehazing\nmodels for adjusting the original statistics with the guidance of the generated\nprompt. Note that, PTTD is model-agnostic and can be equipped with various\nstate-of-the-art dehazing models trained on synthetic hazy-clean pairs.\nExtensive experimental results demonstrate that our PTTD is flexible meanwhile\nachieves superior performance against state-of-the-art dehazing methods in\nreal-world scenarios. The source code of our PTTD will be made available at\nhttps://github.com/cecret3350/PTTD-Dehazing.\n","authors":["Zixuan Chen","Zewei He","Ziqian Lu","Xuecheng Sun","Zhe-Ming Lu"],"pdf_url":"https://arxiv.org/pdf/2309.17389v4.pdf","comment":"update github link (https://github.com/cecret3350/PTTD-Dehazing)"},{"id":"http://arxiv.org/abs/2311.12144v4","updated":"2023-11-27T16:38:44Z","published":"2023-11-20T19:45:27Z","title":"Applications of Large Scale Foundation Models for Autonomous Driving","summary":"  Since DARPA Grand Challenges (rural) in 2004/05 and Urban Challenges in 2007,\nautonomous driving has been the most active field of AI applications. Recently\npowered by large language models (LLMs), chat systems, such as chatGPT and\nPaLM, emerge and rapidly become a promising direction to achieve artificial\ngeneral intelligence (AGI) in natural language processing (NLP). There comes a\nnatural thinking that we could employ these abilities to reformulate autonomous\ndriving. By combining LLM with foundation models, it is possible to utilize the\nhuman knowledge, commonsense and reasoning to rebuild autonomous driving\nsystems from the current long-tailed AI dilemma. In this paper, we investigate\nthe techniques of foundation models and LLMs applied for autonomous driving,\ncategorized as simulation, world model, data annotation and planning or E2E\nsolutions etc.\n","authors":["Yu Huang","Yue Chen","Zhu Li"],"pdf_url":"https://arxiv.org/pdf/2311.12144v4.pdf","comment":"22 pages. arXiv admin note: text overlap with arXiv:2304.03589 by\n  other authors"},{"id":"http://arxiv.org/abs/2311.16103v1","updated":"2023-11-27T18:59:58Z","published":"2023-11-27T18:59:58Z","title":"Video-Bench: A Comprehensive Benchmark and Toolkit for Evaluating\n  Video-based Large Language Models","summary":"  Video-based large language models (Video-LLMs) have been recently introduced,\ntargeting both fundamental improvements in perception and comprehension, and a\ndiverse range of user inquiries. In pursuit of the ultimate goal of achieving\nartificial general intelligence, a truly intelligent Video-LLM model should not\nonly see and understand the surroundings, but also possess human-level\ncommonsense, and make well-informed decisions for the users. To guide the\ndevelopment of such a model, the establishment of a robust and comprehensive\nevaluation system becomes crucial. To this end, this paper proposes\n\\textit{Video-Bench}, a new comprehensive benchmark along with a toolkit\nspecifically designed for evaluating Video-LLMs. The benchmark comprises 10\nmeticulously crafted tasks, evaluating the capabilities of Video-LLMs across\nthree distinct levels: Video-exclusive Understanding, Prior Knowledge-based\nQuestion-Answering, and Comprehension and Decision-making. In addition, we\nintroduce an automatic toolkit tailored to process model outputs for various\ntasks, facilitating the calculation of metrics and generating convenient final\nscores. We evaluate 8 representative Video-LLMs using \\textit{Video-Bench}. The\nfindings reveal that current Video-LLMs still fall considerably short of\nachieving human-like comprehension and analysis of real-world videos, offering\nvaluable insights for future research directions. The benchmark and toolkit are\navailable at: \\url{https://github.com/PKU-YuanGroup/Video-Bench}.\n","authors":["Munan Ning","Bin Zhu","Yujia Xie","Bin Lin","Jiaxi Cui","Lu Yuan","Dongdong Chen","Li Yuan"],"pdf_url":"https://arxiv.org/pdf/2311.16103v1.pdf","comment":"Benchmark is available at\n  https://github.com/PKU-YuanGroup/Video-Bench"},{"id":"http://arxiv.org/abs/2311.16102v1","updated":"2023-11-27T18:59:53Z","published":"2023-11-27T18:59:53Z","title":"Test-time Adaptation of Discriminative Models via Diffusion Generative\n  Feedback","summary":"  The advancements in generative modeling, particularly the advent of diffusion\nmodels, have sparked a fundamental question: how can these models be\neffectively used for discriminative tasks? In this work, we find that\ngenerative models can be great test-time adapters for discriminative models.\nOur method, Diffusion-TTA, adapts pre-trained discriminative models such as\nimage classifiers, segmenters and depth predictors, to each unlabelled example\nin the test set using generative feedback from a diffusion model. We achieve\nthis by modulating the conditioning of the diffusion model using the output of\nthe discriminative model. We then maximize the image likelihood objective by\nbackpropagating the gradients to discriminative model's parameters. We show\nDiffusion-TTA significantly enhances the accuracy of various large-scale\npre-trained discriminative models, such as, ImageNet classifiers, CLIP models,\nimage pixel labellers and image depth predictors. Diffusion-TTA outperforms\nexisting test-time adaptation methods, including TTT-MAE and TENT, and\nparticularly shines in online adaptation setups, where the discriminative model\nis continually adapted to each example in the test set. We provide access to\ncode, results, and visualizations on our website:\nhttps://diffusion-tta.github.io/.\n","authors":["Mihir Prabhudesai","Tsung-Wei Ke","Alexander C. Li","Deepak Pathak","Katerina Fragkiadaki"],"pdf_url":"https://arxiv.org/pdf/2311.16102v1.pdf","comment":"Accepted at NeurIPS 2023 Webpage with Code:\n  https://diffusion-tta.github.io/"},{"id":"http://arxiv.org/abs/2311.16101v1","updated":"2023-11-27T18:59:42Z","published":"2023-11-27T18:59:42Z","title":"How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for\n  Vision LLMs","summary":"  This work focuses on the potential of Vision LLMs (VLLMs) in visual\nreasoning. Different from prior studies, we shift our focus from evaluating\nstandard performance to introducing a comprehensive safety evaluation suite,\ncovering both out-of-distribution (OOD) generalization and adversarial\nrobustness. For the OOD evaluation, we present two novel VQA datasets, each\nwith one variant, designed to test model performance under challenging\nconditions. In exploring adversarial robustness, we propose a straightforward\nattack strategy for misleading VLLMs to produce visual-unrelated responses.\nMoreover, we assess the efficacy of two jailbreaking strategies, targeting\neither the vision or language component of VLLMs. Our evaluation of 21 diverse\nmodels, ranging from open-source VLLMs to GPT-4V, yields interesting\nobservations: 1) Current VLLMs struggle with OOD texts but not images, unless\nthe visual information is limited; and 2) These VLLMs can be easily misled by\ndeceiving vision encoders only, and their vision-language training often\ncompromise safety protocols. We release this safety evaluation suite at\nhttps://github.com/UCSC-VLAA/vllm-safety-benchmark.\n","authors":["Haoqin Tu","Chenhang Cui","Zijun Wang","Yiyang Zhou","Bingchen Zhao","Junlin Han","Wangchunshu Zhou","Huaxiu Yao","Cihang Xie"],"pdf_url":"https://arxiv.org/pdf/2311.16101v1.pdf","comment":"H.T., C.C., and Z.W. contribute equally. Work done during H.T. and\n  Z.W.'s internship at UCSC, and C.C. and Y.Z.'s internship at UNC"},{"id":"http://arxiv.org/abs/2311.16099v1","updated":"2023-11-27T18:59:30Z","published":"2023-11-27T18:59:30Z","title":"GART: Gaussian Articulated Template Models","summary":"  We introduce Gaussian Articulated Template Model GART, an explicit,\nefficient, and expressive representation for non-rigid articulated subject\ncapturing and rendering from monocular videos. GART utilizes a mixture of\nmoving 3D Gaussians to explicitly approximate a deformable subject's geometry\nand appearance. It takes advantage of a categorical template model prior (SMPL,\nSMAL, etc.) with learnable forward skinning while further generalizing to more\ncomplex non-rigid deformations with novel latent bones. GART can be\nreconstructed via differentiable rendering from monocular videos in seconds or\nminutes and rendered in novel poses faster than 150fps.\n","authors":["Jiahui Lei","Yufu Wang","Georgios Pavlakos","Lingjie Liu","Kostas Daniilidis"],"pdf_url":"https://arxiv.org/pdf/2311.16099v1.pdf","comment":"13 pages, code available at\n  https://www.cis.upenn.edu/~leijh/projects/gart/"},{"id":"http://arxiv.org/abs/2311.16098v1","updated":"2023-11-27T18:59:25Z","published":"2023-11-27T18:59:25Z","title":"On Bringing Robots Home","summary":"  Throughout history, we have successfully integrated various machines into our\nhomes. Dishwashers, laundry machines, stand mixers, and robot vacuums are a few\nrecent examples. However, these machines excel at performing only a single task\neffectively. The concept of a \"generalist machine\" in homes - a domestic\nassistant that can adapt and learn from our needs, all while remaining\ncost-effective - has long been a goal in robotics that has been steadily\npursued for decades. In this work, we initiate a large-scale effort towards\nthis goal by introducing Dobb-E, an affordable yet versatile general-purpose\nsystem for learning robotic manipulation within household settings. Dobb-E can\nlearn a new task with only five minutes of a user showing it how to do it,\nthanks to a demonstration collection tool (\"The Stick\") we built out of cheap\nparts and iPhones. We use the Stick to collect 13 hours of data in 22 homes of\nNew York City, and train Home Pretrained Representations (HPR). Then, in a\nnovel home environment, with five minutes of demonstrations and fifteen minutes\nof adapting the HPR model, we show that Dobb-E can reliably solve the task on\nthe Stretch, a mobile robot readily available on the market. Across roughly 30\ndays of experimentation in homes of New York City and surrounding areas, we\ntest our system in 10 homes, with a total of 109 tasks in different\nenvironments, and finally achieve a success rate of 81%. Beyond success\npercentages, our experiments reveal a plethora of unique challenges absent or\nignored in lab robotics. These range from effects of strong shadows, to\nvariable demonstration quality by non-expert users. With the hope of\naccelerating research on home robots, and eventually seeing robot butlers in\nevery home, we open-source Dobb-E software stack and models, our data, and our\nhardware designs at https://dobb-e.com\n","authors":["Nur Muhammad Mahi Shafiullah","Anant Rai","Haritheja Etukuru","Yiqian Liu","Ishan Misra","Soumith Chintala","Lerrel Pinto"],"pdf_url":"https://arxiv.org/pdf/2311.16098v1.pdf","comment":"Project website and videos are available at https://dobb-e.com,\n  technical documentation for getting started is available at\n  https://docs.dobb-e.com, and code is released at\n  https://github.com/notmahi/dobb-e"},{"id":"http://arxiv.org/abs/2311.16097v1","updated":"2023-11-27T18:59:10Z","published":"2023-11-27T18:59:10Z","title":"CG-HOI: Contact-Guided 3D Human-Object Interaction Generation","summary":"  We propose CG-HOI, the first method to address the task of generating dynamic\n3D human-object interactions (HOIs) from text. We model the motion of both\nhuman and object in an interdependent fashion, as semantically rich human\nmotion rarely happens in isolation without any interactions. Our key insight is\nthat explicitly modeling contact between the human body surface and object\ngeometry can be used as strong proxy guidance, both during training and\ninference. Using this guidance to bridge human and object motion enables\ngenerating more realistic and physically plausible interaction sequences, where\nthe human body and corresponding object move in a coherent manner. Our method\nfirst learns to model human motion, object motion, and contact in a joint\ndiffusion process, inter-correlated through cross-attention. We then leverage\nthis learned contact for guidance during inference synthesis of realistic,\ncoherent HOIs. Extensive evaluation shows that our joint contact-based\nhuman-object interaction approach generates realistic and physically plausible\nsequences, and we show two applications highlighting the capabilities of our\nmethod. Conditioned on a given object trajectory, we can generate the\ncorresponding human motion without re-training, demonstrating strong\nhuman-object interdependency learning. Our approach is also flexible, and can\nbe applied to static real-world 3D scene scans.\n","authors":["Christian Diller","Angela Dai"],"pdf_url":"https://arxiv.org/pdf/2311.16097v1.pdf","comment":"Project page: https://cg-hoi.christian-diller.de Video:\n  https://www.youtube.com/watch?v=GNyQwTwZ15s"},{"id":"http://arxiv.org/abs/2311.16096v1","updated":"2023-11-27T18:59:04Z","published":"2023-11-27T18:59:04Z","title":"Animatable Gaussians: Learning Pose-dependent Gaussian Maps for\n  High-fidelity Human Avatar Modeling","summary":"  Modeling animatable human avatars from RGB videos is a long-standing and\nchallenging problem. Recent works usually adopt MLP-based neural radiance\nfields (NeRF) to represent 3D humans, but it remains difficult for pure MLPs to\nregress pose-dependent garment details. To this end, we introduce Animatable\nGaussians, a new avatar representation that leverages powerful 2D CNNs and 3D\nGaussian splatting to create high-fidelity avatars. To associate 3D Gaussians\nwith the animatable avatar, we learn a parametric template from the input\nvideos, and then parameterize the template on two front \\& back canonical\nGaussian maps where each pixel represents a 3D Gaussian. The learned template\nis adaptive to the wearing garments for modeling looser clothes like dresses.\nSuch template-guided 2D parameterization enables us to employ a powerful\nStyleGAN-based CNN to learn the pose-dependent Gaussian maps for modeling\ndetailed dynamic appearances. Furthermore, we introduce a pose projection\nstrategy for better generalization given novel poses. Overall, our method can\ncreate lifelike avatars with dynamic, realistic and generalized appearances.\nExperiments show that our method outperforms other state-of-the-art approaches.\nCode: https://github.com/lizhe00/AnimatableGaussians\n","authors":["Zhe Li","Zerong Zheng","Lizhen Wang","Yebin Liu"],"pdf_url":"https://arxiv.org/pdf/2311.16096v1.pdf","comment":"Projectpage: https://animatable-gaussians.github.io/, Code:\n  https://github.com/lizhe00/AnimatableGaussians"},{"id":"http://arxiv.org/abs/2311.16094v1","updated":"2023-11-27T18:59:02Z","published":"2023-11-27T18:59:02Z","title":"Street TryOn: Learning In-the-Wild Virtual Try-On from Unpaired Person\n  Images","summary":"  Virtual try-on has become a popular research topic, but most existing methods\nfocus on studio images with a clean background. They can achieve plausible\nresults for this studio try-on setting by learning to warp a garment image to\nfit a person's body from paired training data, i.e., garment images paired with\nimages of people wearing the same garment. Such data is often collected from\ncommercial websites, where each garment is demonstrated both by itself and on\nseveral models. By contrast, it is hard to collect paired data for in-the-wild\nscenes, and therefore, virtual try-on for casual images of people against\ncluttered backgrounds is rarely studied.\n  In this work, we fill the gap in the current virtual try-on research by (1)\nintroducing a Street TryOn benchmark to evaluate performance on street scenes\nand (2) proposing a novel method that can learn without paired data, from a set\nof in-the-wild person images directly. Our method can achieve robust\nperformance across shop and street domains using a novel DensePose warping\ncorrection method combined with diffusion-based inpainting controlled by pose\nand semantic segmentation. Our experiments demonstrate competitive performance\nfor standard studio try-on tasks and SOTA performance for street try-on and\ncross-domain try-on tasks.\n","authors":["Aiyu Cui","Jay Mahajan","Viraj Shah","Preeti Gomathinayagam","Svetlana Lazebnik"],"pdf_url":"https://arxiv.org/pdf/2311.16094v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16091v1","updated":"2023-11-27T18:57:42Z","published":"2023-11-27T18:57:42Z","title":"Interactive Autonomous Navigation with Internal State Inference and\n  Interactivity Estimation","summary":"  Deep reinforcement learning (DRL) provides a promising way for intelligent\nagents (e.g., autonomous vehicles) to learn to navigate complex scenarios.\nHowever, DRL with neural networks as function approximators is typically\nconsidered a black box with little explainability and often suffers from\nsuboptimal performance, especially for autonomous navigation in highly\ninteractive multi-agent environments. To address these issues, we propose three\nauxiliary tasks with spatio-temporal relational reasoning and integrate them\ninto the standard DRL framework, which improves the decision making performance\nand provides explainable intermediate indicators. We propose to explicitly\ninfer the internal states (i.e., traits and intentions) of surrounding agents\n(e.g., human drivers) as well as to predict their future trajectories in the\nsituations with and without the ego agent through counterfactual reasoning.\nThese auxiliary tasks provide additional supervision signals to infer the\nbehavior patterns of other interactive agents. Multiple variants of framework\nintegration strategies are compared. We also employ a spatio-temporal graph\nneural network to encode relations between dynamic entities, which enhances\nboth internal state inference and decision making of the ego agent. Moreover,\nwe propose an interactivity estimation mechanism based on the difference\nbetween predicted trajectories in these two situations, which indicates the\ndegree of influence of the ego agent on other agents. To validate the proposed\nmethod, we design an intersection driving simulator based on the Intelligent\nIntersection Driver Model (IIDM) that simulates vehicles and pedestrians. Our\napproach achieves robust and state-of-the-art performance in terms of standard\nevaluation metrics and provides explainable intermediate indicators (i.e.,\ninternal states, and interactivity scores) for decision making.\n","authors":["Jiachen Li","David Isele","Kanghoon Lee","Jinkyoo Park","Kikuo Fujimura","Mykel J. Kochenderfer"],"pdf_url":"https://arxiv.org/pdf/2311.16091v1.pdf","comment":"18 pages, 14 figures"},{"id":"http://arxiv.org/abs/2311.16090v1","updated":"2023-11-27T18:56:37Z","published":"2023-11-27T18:56:37Z","title":"Self-correcting LLM-controlled Diffusion Models","summary":"  Text-to-image generation has witnessed significant progress with the advent\nof diffusion models. Despite the ability to generate photorealistic images,\ncurrent text-to-image diffusion models still often struggle to accurately\ninterpret and follow complex input text prompts. In contrast to existing models\nthat aim to generate images only with their best effort, we introduce\nSelf-correcting LLM-controlled Diffusion (SLD). SLD is a framework that\ngenerates an image from the input prompt, assesses its alignment with the\nprompt, and performs self-corrections on the inaccuracies in the generated\nimage. Steered by an LLM controller, SLD turns text-to-image generation into an\niterative closed-loop process, ensuring correctness in the resulting image. SLD\nis not only training-free but can also be seamlessly integrated with diffusion\nmodels behind API access, such as DALL-E 3, to further boost the performance of\nstate-of-the-art diffusion models. Experimental results show that our approach\ncan rectify a majority of incorrect generations, particularly in generative\nnumeracy, attribute binding, and spatial relationships. Furthermore, by simply\nadjusting the instructions to the LLM, SLD can perform image editing tasks,\nbridging the gap between text-to-image generation and image editing pipelines.\nWe will make our code available for future research and applications.\n","authors":["Tsung-Han Wu","Long Lian","Joseph E. Gonzalez","Boyi Li","Trevor Darrell"],"pdf_url":"https://arxiv.org/pdf/2311.16090v1.pdf","comment":"16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2311.16081v1","updated":"2023-11-27T18:52:09Z","published":"2023-11-27T18:52:09Z","title":"ViT-Lens-2: Gateway to Omni-modal Intelligence","summary":"  Aiming to advance AI agents, large foundation models significantly improve\nreasoning and instruction execution, yet the current focus on vision and\nlanguage neglects the potential of perceiving diverse modalities in open-world\nenvironments. However, the success of data-driven vision and language models is\ncostly or even infeasible to be reproduced for rare modalities. In this paper,\nwe present ViT-Lens-2 that facilitates efficient omni-modal representation\nlearning by perceiving novel modalities with a pretrained ViT and aligning them\nto a pre-defined space. Specifically, the modality-specific lens is tuned to\nproject any-modal signals to an intermediate embedding space, which are then\nprocessed by a strong ViT with pre-trained visual knowledge. The encoded\nrepresentations are optimized toward aligning with the modal-independent space,\npre-defined by off-the-shelf foundation models. ViT-Lens-2 provides a unified\nsolution for representation learning of increasing modalities with two\nappealing advantages: (i) Unlocking the great potential of pretrained ViTs to\nnovel modalities effectively with efficient data regime; (ii) Enabling emergent\ndownstream capabilities through modality alignment and shared ViT parameters.\nWe tailor ViT-Lens-2 to learn representations for 3D point cloud, depth, audio,\ntactile and EEG, and set new state-of-the-art results across various\nunderstanding tasks, such as zero-shot classification. By seamlessly\nintegrating ViT-Lens-2 into Multimodal Foundation Models, we enable\nAny-modality to Text and Image Generation in a zero-shot manner. Code and\nmodels are available at https://github.com/TencentARC/ViT-Lens.\n","authors":["Weixian Lei","Yixiao Ge","Kun Yi","Jianfeng Zhang","Difei Gao","Dylan Sun","Yuying Ge","Ying Shan","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2311.16081v1.pdf","comment":"This work is a follow-up of \"ViT-Lens: Towards Omni-modal\n  Representations\". arXiv admin note: text overlap with arXiv:2308.10185"},{"id":"http://arxiv.org/abs/2211.14309v2","updated":"2023-11-27T18:48:33Z","published":"2022-11-25T18:59:53Z","title":"FutureHuman3D: Forecasting Complex Long-Term 3D Human Behavior from\n  Video Observations","summary":"  We present a generative approach to forecast long-term future human behavior\nin 3D, requiring only weak supervision from readily available 2D human action\ndata. This is a fundamental task enabling many downstream applications. The\nrequired ground-truth data is hard to capture in 3D (mocap suits, expensive\nsetups) but easy to acquire in 2D (simple RGB cameras). Thus, we design our\nmethod to only require 2D RGB data while being able to generate 3D human motion\nsequences. We use a differentiable 2D projection scheme in an autoregressive\nmanner for weak supervision, and an adversarial loss for 3D regularization. Our\nmethod predicts long and complex behavior sequences (e.g. cooking, assembly)\nconsisting of multiple sub-actions. We tackle this in a semantically\nhierarchical manner, jointly predicting high-level coarse action labels\ntogether with their low-level fine-grained realizations as characteristic 3D\nhuman poses. We observe that these two action representations are coupled in\nnature, and joint prediction benefits both action and pose forecasting. Our\nexperiments demonstrate the complementary nature of joint action and 3D pose\nprediction: our joint approach outperforms each task treated individually,\nenables robust longer-term sequence prediction, and outperforms alternative\napproaches to forecast actions and characteristic 3D poses.\n","authors":["Christian Diller","Thomas Funkhouser","Angela Dai"],"pdf_url":"https://arxiv.org/pdf/2211.14309v2.pdf","comment":"Project Page: https://future-human-3d.christian-diller.de/ Video:\n  https://www.youtube.com/watch?v=18du85YFXL0"},{"id":"http://arxiv.org/abs/2210.06462v3","updated":"2023-11-27T18:30:14Z","published":"2022-10-12T17:57:58Z","title":"Self-Guided Diffusion Models","summary":"  Diffusion models have demonstrated remarkable progress in image generation\nquality, especially when guidance is used to control the generative process.\nHowever, guidance requires a large amount of image-annotation pairs for\ntraining and is thus dependent on their availability, correctness and\nunbiasedness. In this paper, we eliminate the need for such annotation by\ninstead leveraging the flexibility of self-supervision signals to design a\nframework for self-guided diffusion models. By leveraging a feature extraction\nfunction and a self-annotation function, our method provides guidance signals\nat various image granularities: from the level of holistic images to object\nboxes and even segmentation masks. Our experiments on single-label and\nmulti-label image datasets demonstrate that self-labeled guidance always\noutperforms diffusion models without guidance and may even surpass guidance\nbased on ground-truth labels, especially on unbalanced data. When equipped with\nself-supervised box or mask proposals, our method further generates visually\ndiverse yet semantically consistent images, without the need for any class,\nbox, or segment label annotation. Self-guided diffusion is simple, flexible and\nexpected to profit from deployment at scale. Source code will be at:\nhttps://taohu.me/sgdm/\n","authors":["Vincent Tao Hu","David W Zhang","Yuki M. Asano","Gertjan J. Burghouts","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2210.06462v3.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2311.16060v1","updated":"2023-11-27T18:26:19Z","published":"2023-11-27T18:26:19Z","title":"DiffSLVA: Harnessing Diffusion Models for Sign Language Video\n  Anonymization","summary":"  Since American Sign Language (ASL) has no standard written form, Deaf signers\nfrequently share videos in order to communicate in their native language.\nHowever, since both hands and face convey critical linguistic information in\nsigned languages, sign language videos cannot preserve signer privacy. While\nsigners have expressed interest, for a variety of applications, in sign\nlanguage video anonymization that would effectively preserve linguistic\ncontent, attempts to develop such technology have had limited success, given\nthe complexity of hand movements and facial expressions. Existing approaches\nrely predominantly on precise pose estimations of the signer in video footage\nand often require sign language video datasets for training. These requirements\nprevent them from processing videos 'in the wild,' in part because of the\nlimited diversity present in current sign language video datasets. To address\nthese limitations, our research introduces DiffSLVA, a novel methodology that\nutilizes pre-trained large-scale diffusion models for zero-shot text-guided\nsign language video anonymization. We incorporate ControlNet, which leverages\nlow-level image features such as HED (Holistically-Nested Edge Detection)\nedges, to circumvent the need for pose estimation. Additionally, we develop a\nspecialized module dedicated to capturing facial expressions, which are\ncritical for conveying essential linguistic information in signed languages. We\nthen combine the above methods to achieve anonymization that better preserves\nthe essential linguistic content of the original signer. This innovative\nmethodology makes possible, for the first time, sign language video\nanonymization that could be used for real-world applications, which would offer\nsignificant benefits to the Deaf and Hard-of-Hearing communities. We\ndemonstrate the effectiveness of our approach with a series of signer\nanonymization experiments.\n","authors":["Zhaoyang Xia","Carol Neidle","Dimitris N. Metaxas"],"pdf_url":"https://arxiv.org/pdf/2311.16060v1.pdf","comment":"Project webpage: https://github.com/Jeffery9707/DiffSLVA"},{"id":"http://arxiv.org/abs/2311.16052v1","updated":"2023-11-27T18:14:03Z","published":"2023-11-27T18:14:03Z","title":"Exploring Attribute Variations in Style-based GANs using Diffusion\n  Models","summary":"  Existing attribute editing methods treat semantic attributes as binary,\nresulting in a single edit per attribute. However, attributes such as\neyeglasses, smiles, or hairstyles exhibit a vast range of diversity. In this\nwork, we formulate the task of \\textit{diverse attribute editing} by modeling\nthe multidimensional nature of attribute edits. This enables users to generate\nmultiple plausible edits per attribute. We capitalize on disentangled latent\nspaces of pretrained GANs and train a Denoising Diffusion Probabilistic Model\n(DDPM) to learn the latent distribution for diverse edits. Specifically, we\ntrain DDPM over a dataset of edit latent directions obtained by embedding image\npairs with a single attribute change. This leads to latent subspaces that\nenable diverse attribute editing. Applying diffusion in the highly compressed\nlatent space allows us to model rich distributions of edits within limited\ncomputational resources. Through extensive qualitative and quantitative\nexperiments conducted across a range of datasets, we demonstrate the\neffectiveness of our approach for diverse attribute editing. We also showcase\nthe results of our method applied for 3D editing of various face attributes.\n","authors":["Rishubh Parihar","Prasanna Balaji","Raghav Magazine","Sarthak Vora","Tejan Karmali","Varun Jampani","R. Venkatesh Babu"],"pdf_url":"https://arxiv.org/pdf/2311.16052v1.pdf","comment":"Neurips Workshop on Diffusion Models 2023"},{"id":"http://arxiv.org/abs/2311.16043v1","updated":"2023-11-27T18:07:58Z","published":"2023-11-27T18:07:58Z","title":"Relightable 3D Gaussian: Real-time Point Cloud Relighting with BRDF\n  Decomposition and Ray Tracing","summary":"  We present a novel differentiable point-based rendering framework for\nmaterial and lighting decomposition from multi-view images, enabling editing,\nray-tracing, and real-time relighting of the 3D point cloud. Specifically, a 3D\nscene is represented as a set of relightable 3D Gaussian points, where each\npoint is additionally associated with a normal direction, BRDF parameters, and\nincident lights from different directions. To achieve robust lighting\nestimation, we further divide incident lights of each point into global and\nlocal components, as well as view-dependent visibilities. The 3D scene is\noptimized through the 3D Gaussian Splatting technique while BRDF and lighting\nare decomposed by physically-based differentiable rendering. Moreover, we\nintroduce an innovative point-based ray-tracing approach based on the bounding\nvolume hierarchy for efficient visibility baking, enabling real-time rendering\nand relighting of 3D Gaussian points with accurate shadow effects. Extensive\nexperiments demonstrate improved BRDF estimation and novel view rendering\nresults compared to state-of-the-art material estimation approaches. Our\nframework showcases the potential to revolutionize the mesh-based graphics\npipeline with a relightable, traceable, and editable rendering pipeline solely\nbased on point cloud. Project\npage:https://nju-3dv.github.io/projects/Relightable3DGaussian/.\n","authors":["Jian Gao","Chun Gu","Youtian Lin","Hao Zhu","Xun Cao","Li Zhang","Yao Yao"],"pdf_url":"https://arxiv.org/pdf/2311.16043v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16042v1","updated":"2023-11-27T18:06:35Z","published":"2023-11-27T18:06:35Z","title":"Weakly-Supervised 3D Reconstruction of Clothed Humans via Normal Maps","summary":"  We present a novel deep learning-based approach to the 3D reconstruction of\nclothed humans using weak supervision via 2D normal maps. Given a single RGB\nimage or multiview images, our network infers a signed distance function (SDF)\ndiscretized on a tetrahedral mesh surrounding the body in a rest pose.\nSubsequently, inferred pose and camera parameters are used to generate a normal\nmap from the SDF. A key aspect of our approach is the use of Marching\nTetrahedra to (uniquely) compute a triangulated surface from the SDF on the\ntetrahedral mesh, facilitating straightforward differentiation (and thus\nbackpropagation). Thus, given only ground truth normal maps (with no volumetric\ninformation ground truth information), we can train the network to produce SDF\nvalues from corresponding RGB images. Optionally, an additional multiview loss\nleads to improved results. We demonstrate the efficacy of our approach for both\nnetwork inference and 3D reconstruction.\n","authors":["Jane Wu","Diego Thomas","Ronald Fedkiw"],"pdf_url":"https://arxiv.org/pdf/2311.16042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16038v1","updated":"2023-11-27T17:59:41Z","published":"2023-11-27T17:59:41Z","title":"OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving","summary":"  Understanding how the 3D scene evolves is vital for making decisions in\nautonomous driving. Most existing methods achieve this by predicting the\nmovements of object boxes, which cannot capture more fine-grained scene\ninformation. In this paper, we explore a new framework of learning a world\nmodel, OccWorld, in the 3D Occupancy space to simultaneously predict the\nmovement of the ego car and the evolution of the surrounding scenes. We propose\nto learn a world model based on 3D occupancy rather than 3D bounding boxes and\nsegmentation maps for three reasons: 1) expressiveness. 3D occupancy can\ndescribe the more fine-grained 3D structure of the scene; 2) efficiency. 3D\noccupancy is more economical to obtain (e.g., from sparse LiDAR points). 3)\nversatility. 3D occupancy can adapt to both vision and LiDAR. To facilitate the\nmodeling of the world evolution, we learn a reconstruction-based scene\ntokenizer on the 3D occupancy to obtain discrete scene tokens to describe the\nsurrounding scenes. We then adopt a GPT-like spatial-temporal generative\ntransformer to generate subsequent scene and ego tokens to decode the future\noccupancy and ego trajectory. Extensive experiments on the widely used nuScenes\nbenchmark demonstrate the ability of OccWorld to effectively model the\nevolution of the driving scenes. OccWorld also produces competitive planning\nresults without using instance and map supervision. Code:\nhttps://github.com/wzzheng/OccWorld.\n","authors":["Wenzhao Zheng","Weiliang Chen","Yuanhui Huang","Borui Zhang","Yueqi Duan","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2311.16038v1.pdf","comment":"Code is available at: https://github.com/wzzheng/OccWorld"},{"id":"http://arxiv.org/abs/2311.16037v1","updated":"2023-11-27T17:58:21Z","published":"2023-11-27T17:58:21Z","title":"GaussianEditor: Editing 3D Gaussians Delicately with Text Instructions","summary":"  Recently, impressive results have been achieved in 3D scene editing with text\ninstructions based on a 2D diffusion model. However, current diffusion models\nprimarily generate images by predicting noise in the latent space, and the\nediting is usually applied to the whole image, which makes it challenging to\nperform delicate, especially localized, editing for 3D scenes. Inspired by\nrecent 3D Gaussian splatting, we propose a systematic framework, named\nGaussianEditor, to edit 3D scenes delicately via 3D Gaussians with text\ninstructions. Benefiting from the explicit property of 3D Gaussians, we design\na series of techniques to achieve delicate editing. Specifically, we first\nextract the region of interest (RoI) corresponding to the text instruction,\naligning it to 3D Gaussians. The Gaussian RoI is further used to control the\nediting process. Our framework can achieve more delicate and precise editing of\n3D scenes than previous methods while enjoying much faster training speed, i.e.\nwithin 20 minutes on a single V100 GPU, more than twice as fast as\nInstruct-NeRF2NeRF (45 minutes -- 2 hours).\n","authors":["Jiemin Fang","Junjie Wang","Xiaopeng Zhang","Lingxi Xie","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2311.16037v1.pdf","comment":"Project page: https://GaussianEditor.github.io"},{"id":"http://arxiv.org/abs/2310.06627v2","updated":"2023-11-27T16:59:39Z","published":"2023-10-10T13:45:59Z","title":"What If the TV Was Off? Examining Counterfactual Reasoning Abilities of\n  Multi-modal Language Models","summary":"  Counterfactual reasoning, a fundamental aspect of human cognition, involves\ncontemplating alternatives to established facts or past events, significantly\nenhancing our abilities in planning and decision-making. In light of the\nadvancements in current multi-modal large language models, we explore their\neffectiveness in counterfactual reasoning. To facilitate this investigation, we\nintroduce a novel dataset, C-VQA, specifically designed to test the\ncounterfactual reasoning capabilities of modern multi-modal large language\nmodels. This dataset is constructed by infusing original questions with\ncounterfactual presuppositions, spanning various types such as numerical and\nboolean queries. It encompasses a mix of real and synthetic data, representing\na wide range of difficulty levels. Our thorough evaluations of contemporary\nvision-language models using this dataset have revealed substantial performance\ndrops, with some models showing up to a 40\\% decrease, highlighting a\nsignificant gap between current models and human-like vision reasoning\ncapabilities. We hope our dataset will serve as a vital benchmark for\nevaluating the counterfactual reasoning capabilities of models. Code and\ndataset are publicly available at https://bzhao.me/C-VQA/.\n","authors":["Letian Zhang","Xiaotong Zhai","Zhongkai Zhao","Yongshuo Zong","Xin Wen","Bingchen Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.06627v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09257v3","updated":"2023-11-27T16:51:40Z","published":"2023-11-14T23:07:50Z","title":"UFOGen: You Forward Once Large Scale Text-to-Image Generation via\n  Diffusion GANs","summary":"  Text-to-image diffusion models have demonstrated remarkable capabilities in\ntransforming textual prompts into coherent images, yet the computational cost\nof their inference remains a persistent challenge. To address this issue, we\npresent UFOGen, a novel generative model designed for ultra-fast, one-step\ntext-to-image synthesis. In contrast to conventional approaches that focus on\nimproving samplers or employing distillation techniques for diffusion models,\nUFOGen adopts a hybrid methodology, integrating diffusion models with a GAN\nobjective. Leveraging a newly introduced diffusion-GAN objective and\ninitialization with pre-trained diffusion models, UFOGen excels in efficiently\ngenerating high-quality images conditioned on textual descriptions in a single\nstep. Beyond traditional text-to-image generation, UFOGen showcases versatility\nin applications. Notably, UFOGen stands among the pioneering models enabling\none-step text-to-image generation and diverse downstream tasks, presenting a\nsignificant advancement in the landscape of efficient generative models.\n","authors":["Yanwu Xu","Yang Zhao","Zhisheng Xiao","Tingbo Hou"],"pdf_url":"https://arxiv.org/pdf/2311.09257v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16001v1","updated":"2023-11-27T16:47:09Z","published":"2023-11-27T16:47:09Z","title":"Automated Measurement of Vascular Calcification in Femoral\n  Endarterectomy Patients Using Deep Learning","summary":"  Atherosclerosis, a chronic inflammatory disease affecting the large arteries,\npresents a global health risk. Accurate analysis of diagnostic images, like\ncomputed tomographic angiograms (CTAs), is essential for staging and monitoring\nthe progression of atherosclerosis-related conditions, including peripheral\narterial disease (PAD). However, manual analysis of CTA images is\ntime-consuming and tedious. To address this limitation, we employed a deep\nlearning model to segment the vascular system in CTA images of PAD patients\nundergoing femoral endarterectomy surgery and to measure vascular calcification\nfrom the left renal artery to the patella. Utilizing proprietary CTA images of\n27 patients undergoing femoral endarterectomy surgery provided by Prisma Health\nMidlands, we developed a Deep Neural Network (DNN) model to first segment the\narterial system, starting from the descending aorta to the patella, and second,\nto provide a metric of arterial calcification. Our designed DNN achieved 83.4%\naverage Dice accuracy in segmenting arteries from aorta to patella, advancing\nthe state-of-the-art by 0.8%. Furthermore, our work is the first to present a\nrobust statistical analysis of automated calcification measurement in the lower\nextremities using deep learning, attaining a Mean Absolute Percentage Error\n(MAPE) of 9.5% and a correlation coefficient of 0.978 between automated and\nmanual calcification scores. These findings underscore the potential of deep\nlearning techniques as a rapid and accurate tool for medical professionals to\nassess calcification in the abdominal aorta and its branches above the patella.\nThe developed DNN model and related documentation in this project are available\nat GitHub page at https://github.com/pip-alireza/DeepCalcScoring.\n","authors":["Alireza Bagheri Rajeoni","Breanna Pederson","Daniel G. Clair","Susan M. Lessner","Homayoun Valafar"],"pdf_url":"https://arxiv.org/pdf/2311.16001v1.pdf","comment":"Published in MDPI Diagnostic journal, the code can be accessed via\n  the GitHub link in the paper"},{"id":"http://arxiv.org/abs/2310.10541v2","updated":"2023-11-27T16:45:18Z","published":"2023-10-16T16:13:53Z","title":"AST: Effective Dataset Distillation through Alignment with Smooth and\n  High-Quality Expert Trajectories","summary":"  Training large AI models typically requires large-scale datasets in the\nmachine learning process, making training and parameter-tuning process both\ntime-consuming and costly. Some researchers address this problem by carefully\nsynthesizing a very small number of highly representative and informative\nsamples from real-world datasets. This approach, known as Dataset Distillation\n(DD), proposes a perspective for data-efficient learning. Despite recent\nprogress in this field, the performance of existing methods still cannot meet\nexpectations, and distilled datasets cannot effectively replace original\ndatasets. In this paper, unlike previous methods that focus solely on improving\nthe effectiveness of student distillation, we recognize and leverage the\nimportant mutual influence between expert and student models. We observed that\nthe smoothness of expert trajectories has a significant impact on subsequent\nstudent parameter alignment. Based on this, we propose an effective DD\nframework named AST, standing for Alignment with Smooth and high-quality expert\nTrajectories. We devise the integration of clipping loss and gradient penalty\nto regulate the rate of parameter changes in expert trajectory generation. To\nfurther refine the student parameter alignment with expert trajectory, we put\nforward representative initialization for the synthetic dataset and balanced\ninner-loop loss in response to the sensitivity exhibited towards randomly\ninitialized variables during distillation. We also propose two enhancement\nstrategies, namely intermediate matching loss and weight perturbation, to\nmitigate the potential occurrence of cumulative errors. We conduct extensive\nexperiments on datasets of different scales, sizes, and resolutions. The\nresults demonstrate that the proposed method significantly outperforms prior\nmethods.\n","authors":["Jiyuan Shen","Wenzhuo Yang","Kwok-Yan Lam"],"pdf_url":"https://arxiv.org/pdf/2310.10541v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15994v1","updated":"2023-11-27T16:43:37Z","published":"2023-11-27T16:43:37Z","title":"Adversaral Doodles: Interpretable and Human-drawable Attacks Provide\n  Describable Insights","summary":"  DNN-based image classification models are susceptible to adversarial attacks.\nMost previous adversarial attacks do not focus on the interpretability of the\ngenerated adversarial examples, and we cannot gain insights into the mechanism\nof the target classifier from the attacks. Therefore, we propose Adversarial\nDoodles, which have interpretable shapes. We optimize black b\\'ezier curves to\nfool the target classifier by overlaying them onto the input image. By\nintroducing random perspective transformation and regularizing the doodled\narea, we obtain compact attacks that cause misclassification even when humans\nreplicate them by hand. Adversarial doodles provide describable and intriguing\ninsights into the relationship between our attacks and the classifier's output.\nWe utilize adversarial doodles and discover the bias inherent in the target\nclassifier, such as \"We add two strokes on its head, a triangle onto its body,\nand two lines inside the triangle on a bird image. Then, the classifier\nmisclassifies the image as a butterfly.\"\n","authors":["Ryoya Nara","Yusuke Matsui"],"pdf_url":"https://arxiv.org/pdf/2311.15994v1.pdf","comment":"Submitted to CVPR 2024"},{"id":"http://arxiv.org/abs/2311.15993v1","updated":"2023-11-27T16:41:31Z","published":"2023-11-27T16:41:31Z","title":"Unified Batch Normalization: Identifying and Alleviating the Feature\n  Condensation in Batch Normalization and a Unified Framework","summary":"  Batch Normalization (BN) has become an essential technique in contemporary\nneural network design, enhancing training stability. Specifically, BN employs\ncentering and scaling operations to standardize features along the batch\ndimension and uses an affine transformation to recover features. Although\nstandard BN has shown its capability to improve deep neural network training\nand convergence, it still exhibits inherent limitations in certain cases. Most\nexisting techniques that enhance BN consider a single or a few aspects of BN.\nIn this paper, we first identify problems with BN from a feature perspective\nand explore that feature condensation exists in the learning when employing BN,\nwhich negatively affects testing performance. To tackle this problem, we\npropose a two-stage unified framework called Unified Batch Normalization (UBN).\nIn the first stage, we utilize a simple feature condensation threshold to\nalleviate the feature condensation, which hinders inappropriate statistic\nupdates in normalization. In the second stage, we unify various normalization\nvariants to boost each component of BN. Our experimental results reveal that\nUBN significantly enhances performance across different visual backbones and\nnotably expedites network training convergence, particularly in early training\nstages. Notably, our method improved about 3% in top-1 accuracy on ImageNet\nclassification with large batch sizes, showing the effectiveness of our\napproach in real-world scenarios.\n","authors":["Shaobo Wang","Xiangdong Zhang","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2311.15993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15991v1","updated":"2023-11-27T16:40:09Z","published":"2023-11-27T16:40:09Z","title":"DiffAnt: Diffusion Models for Action Anticipation","summary":"  Anticipating future actions is inherently uncertain. Given an observed video\nsegment containing ongoing actions, multiple subsequent actions can plausibly\nfollow. This uncertainty becomes even larger when predicting far into the\nfuture. However, the majority of existing action anticipation models adhere to\na deterministic approach, neglecting to account for future uncertainties. In\nthis work, we rethink action anticipation from a generative view, employing\ndiffusion models to capture different possible future actions. In this\nframework, future actions are iteratively generated from standard Gaussian\nnoise in the latent space, conditioned on the observed video, and subsequently\ntransitioned into the action space. Extensive experiments on four benchmark\ndatasets, i.e., Breakfast, 50Salads, EpicKitchens, and EGTEA Gaze+, are\nperformed and the proposed method achieves superior or comparable results to\nstate-of-the-art methods, showing the effectiveness of a generative approach\nfor action anticipation. Our code and trained models will be published on\nGitHub.\n","authors":["Zeyun Zhong","Chengzhi Wu","Manuel Martin","Michael Voit","Juergen Gall","Jürgen Beyerer"],"pdf_url":"https://arxiv.org/pdf/2311.15991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15980v1","updated":"2023-11-27T16:26:54Z","published":"2023-11-27T16:26:54Z","title":"Direct2.5: Diverse Text-to-3D Generation via Multi-view 2.5D Diffusion","summary":"  Recent advances in generative AI have unveiled significant potential for the\ncreation of 3D content. However, current methods either apply a pre-trained 2D\ndiffusion model with the time-consuming score distillation sampling (SDS), or a\ndirect 3D diffusion model trained on limited 3D data losing generation\ndiversity. In this work, we approach the problem by employing a multi-view 2.5D\ndiffusion fine-tuned from a pre-trained 2D diffusion model. The multi-view 2.5D\ndiffusion directly models the structural distribution of 3D data, while still\nmaintaining the strong generalization ability of the original 2D diffusion\nmodel, filling the gap between 2D diffusion-based and direct 3D diffusion-based\nmethods for 3D content generation. During inference, multi-view normal maps are\ngenerated using the 2.5D diffusion, and a novel differentiable rasterization\nscheme is introduced to fuse the almost consistent multi-view normal maps into\na consistent 3D model. We further design a normal-conditioned multi-view image\ngeneration module for fast appearance generation given the 3D geometry. Our\nmethod is a one-pass diffusion process and does not require any SDS\noptimization as post-processing. We demonstrate through extensive experiments\nthat, our direct 2.5D generation with the specially-designed fusion scheme can\nachieve diverse, mode-seeking-free, and high-fidelity 3D content generation in\nonly 10 seconds. Project page: https://nju-3dv.github.io/projects/direct25.\n","authors":["Yuanxun Lu","Jingyang Zhang","Shiwei Li","Tian Fang","David McKinnon","Yanghai Tsin","Long Quan","Xun Cao","Yao Yao"],"pdf_url":"https://arxiv.org/pdf/2311.15980v1.pdf","comment":"Project webpage: https://nju-3dv.github.io/projects/direct25"},{"id":"http://arxiv.org/abs/2304.00553v3","updated":"2023-11-27T16:24:59Z","published":"2023-04-02T15:04:43Z","title":"From Isolated Islands to Pangea: Unifying Semantic Space for Human\n  Action Understanding","summary":"  As a vital step toward the intelligent agent, Action understanding matters\nfor intelligent agents and has attracted long-term attention. It can be formed\nas the mapping from the action physical space to the semantic space. Typically,\nresearchers built action datasets according to idiosyncratic choices to define\nclasses and push the envelope of benchmarks respectively. Thus, datasets are\nincompatible with each other like \"Isolated Islands\" due to semantic gaps and\nvarious class granularities, e.g., do housework in dataset A and wash plate in\ndataset B. We argue that a more principled semantic space is an urgent need to\nconcentrate the community efforts and enable us to use all datasets together to\npursue generalizable action learning. To this end, we design a structured\naction semantic space in view of verb taxonomy hierarchy and covering massive\nactions. By aligning the classes of previous datasets to our semantic space, we\ngather (image/video/skeleton/MoCap) datasets into a unified database in a\nunified label system, i.e., bridging ``isolated islands'' into a \"Pangea\".\nAccordingly, we propose a novel model mapping from the physical space to\nsemantic space to fully use Pangea. In extensive experiments, our new system\nshows significant superiority, especially in transfer learning. Code and data\nwill be made publicly available.\n","authors":["Yong-Lu Li","Xiaoqian Wu","Xinpeng Liu","Zehao Wang","Yiming Dou","Yikun Ji","Junyi Zhang","Yixing Li","Jingru Tan","Xudong Lu","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2304.00553v3.pdf","comment":"Project Webpage: https://mvig-rhos.com/pangea"},{"id":"http://arxiv.org/abs/2311.15977v1","updated":"2023-11-27T16:23:01Z","published":"2023-11-27T16:23:01Z","title":"Text2Loc: 3D Point Cloud Localization from Natural Language","summary":"  We tackle the problem of 3D point cloud localization based on a few natural\nlinguistic descriptions and introduce a novel neural network, Text2Loc, that\nfully interprets the semantic relationship between points and text. Text2Loc\nfollows a coarse-to-fine localization pipeline: text-submap global place\nrecognition, followed by fine localization. In global place recognition,\nrelational dynamics among each textual hint are captured in a hierarchical\ntransformer with max-pooling (HTM), whereas a balance between positive and\nnegative pairs is maintained using text-submap contrastive learning. Moreover,\nwe propose a novel matching-free fine localization method to further refine the\nlocation predictions, which completely removes the need for complicated\ntext-instance matching and is lighter, faster, and more accurate than previous\nmethods. Extensive experiments show that Text2Loc improves the localization\naccuracy by up to $2\\times$ over the state-of-the-art on the KITTI360Pose\ndataset. We will make the code publicly available.\n","authors":["Yan Xia","Letian Shi","Zifeng Ding","João F. Henriques","Daniel Cremers"],"pdf_url":"https://arxiv.org/pdf/2311.15977v1.pdf","comment":"10 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2309.14809v2","updated":"2023-11-27T16:09:03Z","published":"2023-09-26T10:14:44Z","title":"ENIGMA-51: Towards a Fine-Grained Understanding of Human-Object\n  Interactions in Industrial Scenarios","summary":"  ENIGMA-51 is a new egocentric dataset acquired in an industrial scenario by\n19 subjects who followed instructions to complete the repair of electrical\nboards using industrial tools (e.g., electric screwdriver) and equipments\n(e.g., oscilloscope). The 51 egocentric video sequences are densely annotated\nwith a rich set of labels that enable the systematic study of human behavior in\nthe industrial domain. We provide benchmarks on four tasks related to human\nbehavior: 1) untrimmed temporal detection of human-object interactions, 2)\negocentric human-object interaction detection, 3) short-term object interaction\nanticipation and 4) natural language understanding of intents and entities.\nBaseline results show that the ENIGMA-51 dataset poses a challenging benchmark\nto study human behavior in industrial scenarios. We publicly release the\ndataset at https://iplab.dmi.unict.it/ENIGMA-51.\n","authors":["Francesco Ragusa","Rosario Leonardi","Michele Mazzamuto","Claudia Bonanno","Rosario Scavo","Antonino Furnari","Giovanni Maria Farinella"],"pdf_url":"https://arxiv.org/pdf/2309.14809v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15965v1","updated":"2023-11-27T16:07:39Z","published":"2023-11-27T16:07:39Z","title":"FALCON: Fairness Learning via Contrastive Attention Approach to\n  Continual Semantic Scene Understanding in Open World","summary":"  Continual Learning in semantic scene segmentation aims to continually learn\nnew unseen classes in dynamic environments while maintaining previously learned\nknowledge. Prior studies focused on modeling the catastrophic forgetting and\nbackground shift challenges in continual learning. However, fairness, another\nmajor challenge that causes unfair predictions leading to low performance among\nmajor and minor classes, still needs to be well addressed. In addition, prior\nmethods have yet to model the unknown classes well, thus resulting in producing\nnon-discriminative features among unknown classes. This paper presents a novel\nFairness Learning via Contrastive Attention Approach to continual learning in\nsemantic scene understanding. In particular, we first introduce a new Fairness\nContrastive Clustering loss to address the problems of catastrophic forgetting\nand fairness. Then, we propose an attention-based visual grammar approach to\neffectively model the background shift problem and unknown classes, producing\nbetter feature representations for different unknown classes. Through our\nexperiments, our proposed approach achieves State-of-the-Art (SOTA) performance\non different continual learning settings of three standard benchmarks, i.e.,\nADE20K, Cityscapes, and Pascal VOC. It promotes the fairness of the continual\nsemantic segmentation model.\n","authors":["Thanh-Dat Truong","Utsav Prabhu","Bhiksha Raj","Jackson Cothren","Khoa Luu"],"pdf_url":"https://arxiv.org/pdf/2311.15965v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15964v1","updated":"2023-11-27T16:07:37Z","published":"2023-11-27T16:07:37Z","title":"Efficient Pre-training for Localized Instruction Generation of Videos","summary":"  Procedural videos show step-by-step demonstrations of tasks like recipe\npreparation. Understanding such videos is challenging, involving the precise\nlocalization of steps and the generation of textual instructions. Manually\nannotating steps and writing instructions is costly, which limits the size of\ncurrent datasets and hinders effective learning. Leveraging large but noisy\nvideo-transcript datasets for pre-training can boost performance, but demands\nsignificant computational resources. Furthermore, transcripts contain\nirrelevant content and exhibit style variation compared to instructions written\nby human annotators. To mitigate both issues, we propose a technique,\nSieve-&-Swap, to automatically curate a smaller dataset: (i) Sieve filters\nirrelevant transcripts and (ii) Swap enhances the quality of the text\ninstruction by automatically replacing the transcripts with human-written\ninstructions from a text-only recipe dataset. The curated dataset, three orders\nof magnitude smaller than current web-scale datasets, enables efficient\ntraining of large-scale models with competitive performance. We complement our\nSieve-\\&-Swap approach with a Procedure Transformer (ProcX) for end-to-end step\nlocalization and instruction generation for procedural videos. When this model\nis pre-trained on our curated dataset, it achieves state-of-the-art performance\nin zero-shot and finetuning settings on YouCook2 and Tasty, while using a\nfraction of the computational resources.\n","authors":["Anil Batra","Davide Moltisanti","Laura Sevilla-Lara","Marcus Rohrbach","Frank Keller"],"pdf_url":"https://arxiv.org/pdf/2311.15964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15963v1","updated":"2023-11-27T16:07:34Z","published":"2023-11-27T16:07:34Z","title":"From Pixels to Titles: Video Game Identification by Screenshots using\n  Convolutional Neural Networks","summary":"  This paper investigates video game identification through single screenshots,\nutilizing five convolutional neural network (CNN) architectures (MobileNet,\nDenseNet, EfficientNetB0, EfficientNetB2, and EfficientNetB3) across 22 home\nconsole systems, spanning from Atari 2600 to PlayStation 5. Confirming the\nhypothesis, CNNs autonomously extract image features, enabling the\nidentification of game titles from screenshots without additional features.\nUsing ImageNet pre-trained weights, EfficientNetB3 achieves the highest average\naccuracy (74.51%), while DenseNet169 excels in 14 of the 22 systems. Employing\nalternative initial weights from another screenshots dataset boosts accuracy\nfor EfficientNetB2 and EfficientNetB3, with the latter reaching a peak accuracy\nof 76.36% and demonstrating reduced convergence epochs from 23.7 to 20.5 on\naverage. Overall, the combination of optimal architecture and weights attains\n77.67% accuracy, primarily led by EfficientNetB3 in 19 systems. These findings\nunderscore the efficacy of CNNs in video game identification through\nscreenshots.\n","authors":["Fabricio Breve"],"pdf_url":"https://arxiv.org/pdf/2311.15963v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10093v2","updated":"2023-11-27T15:58:30Z","published":"2023-11-16T18:59:51Z","title":"The Chosen One: Consistent Characters in Text-to-Image Diffusion Models","summary":"  Recent advances in text-to-image generation models have unlocked vast\npotential for visual creativity. However, these models struggle with generation\nof consistent characters, a crucial aspect for numerous real-world applications\nsuch as story visualization, game development asset design, advertising, and\nmore. Current methods typically rely on multiple pre-existing images of the\ntarget character or involve labor-intensive manual processes. In this work, we\npropose a fully automated solution for consistent character generation, with\nthe sole input being a text prompt. We introduce an iterative procedure that,\nat each stage, identifies a coherent set of images sharing a similar identity\nand extracts a more consistent identity from this set. Our quantitative\nanalysis demonstrates that our method strikes a better balance between prompt\nalignment and identity consistency compared to the baseline methods, and these\nfindings are reinforced by a user study. To conclude, we showcase several\npractical applications of our approach. Project page is available at\nhttps://omriavrahami.com/the-chosen-one\n","authors":["Omri Avrahami","Amir Hertz","Yael Vinker","Moab Arar","Shlomi Fruchter","Ohad Fried","Daniel Cohen-Or","Dani Lischinski"],"pdf_url":"https://arxiv.org/pdf/2311.10093v2.pdf","comment":"Project page is available at https://omriavrahami.com/the-chosen-one"},{"id":"http://arxiv.org/abs/2311.15941v1","updated":"2023-11-27T15:49:29Z","published":"2023-11-27T15:49:29Z","title":"Tell2Design: A Dataset for Language-Guided Floor Plan Generation","summary":"  We consider the task of generating designs directly from natural language\ndescriptions, and consider floor plan generation as the initial research area.\nLanguage conditional generative models have recently been very successful in\ngenerating high-quality artistic images. However, designs must satisfy\ndifferent constraints that are not present in generating artistic images,\nparticularly spatial and relational constraints. We make multiple contributions\nto initiate research on this task. First, we introduce a novel dataset,\n\\textit{Tell2Design} (T2D), which contains more than $80k$ floor plan designs\nassociated with natural language instructions. Second, we propose a\nSequence-to-Sequence model that can serve as a strong baseline for future\nresearch. Third, we benchmark this task with several text-conditional image\ngeneration models. We conclude by conducting human evaluations on the generated\nsamples and providing an analysis of human performance. We hope our\ncontributions will propel the research on language-guided design generation\nforward.\n","authors":["Sicong Leng","Yang Zhou","Mohammed Haroon Dupty","Wee Sun Lee","Sam Conrad Joyce","Wei Lu"],"pdf_url":"https://arxiv.org/pdf/2311.15941v1.pdf","comment":"Paper published in ACL2023; Area Chair Award; Best Paper Nomination"},{"id":"http://arxiv.org/abs/2311.15939v1","updated":"2023-11-27T15:46:47Z","published":"2023-11-27T15:46:47Z","title":"Unleashing the Power of Prompt-driven Nucleus Instance Segmentation","summary":"  Nuclear instance segmentation in histology images is crucial for a broad\nspectrum of clinical applications. Current prevailing nuclear instance\nsegmentation algorithms rely on regression of nuclei contours, distance maps,\nwatershed markers or a proxy nuclear representation of star-convex polygons.\nConsequently, these methods necessitate sophisticated post-processing\noperations to distinguish nuclei instances, which are commonly acknowledged to\nbe error-prone and parameter-sensitive. Recently, the segment anything model\n(SAM) has earned attracted huge attention within the domain of medical image\nsegmentation due to its impressive generalization ability and promptable\nproperty. Nevertheless, its potential on nuclear instance segmentation remains\nlargely underexplored. In this paper, we present a novel prompt-driven\nframework that consists of a point prompter and a SAM for automatic nuclei\ninstance segmentation. Specifically, the prompter learns to generate a unique\npoint prompt for each nucleus while the SAM is fine tuned to output the\ncorresponding mask of the cued nucleus. Furthermore, we propose to add adjacent\nnuclei as negative prompts to promote the model's ability to recognize\noverlapping nuclei. Without bells and whistles, our proposed method sets a new\nstate-of-the-art performance on three challenging benchmarks. Our code is\navailable at\n\\textcolor{magenta}{\\url{https://github.com/windygoo/PromptNucSeg}} .\n","authors":["Zhongyi Shui","Yunlong Zhang","Kai Yao","Chenglu Zhu","Yuxuan Sun","Lin Yang"],"pdf_url":"https://arxiv.org/pdf/2311.15939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15937v1","updated":"2023-11-27T15:46:19Z","published":"2023-11-27T15:46:19Z","title":"Optimal Transport Aggregation for Visual Place Recognition","summary":"  The task of Visual Place Recognition (VPR) aims to match a query image\nagainst references from an extensive database of images from different places,\nrelying solely on visual cues. State-of-the-art pipelines focus on the\naggregation of features extracted from a deep backbone, in order to form a\nglobal descriptor for each image. In this context, we introduce SALAD (Sinkhorn\nAlgorithm for Locally Aggregated Descriptors), which reformulates NetVLAD's\nsoft-assignment of local features to clusters as an optimal transport problem.\nIn SALAD, we consider both feature-to-cluster and cluster-to-feature relations\nand we also introduce a 'dustbin' cluster, designed to selectively discard\nfeatures deemed non-informative, enhancing the overall descriptor quality.\nAdditionally, we leverage and fine-tune DINOv2 as a backbone, which provides\nenhanced description power for the local features, and dramatically reduces the\nrequired training time. As a result, our single-stage method not only surpasses\nsingle-stage baselines in public VPR datasets, but also surpasses two-stage\nmethods that add a re-ranking with significantly higher cost. Code and models\nare available at https://github.com/serizba/salad.\n","authors":["Sergio Izquierdo","Javier Civera"],"pdf_url":"https://arxiv.org/pdf/2311.15937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15916v1","updated":"2023-11-27T15:24:54Z","published":"2023-11-27T15:24:54Z","title":"ADM-Loc: Actionness Distribution Modeling for Point-supervised Temporal\n  Action Localization","summary":"  This paper addresses the challenge of point-supervised temporal action\ndetection, in which only one frame per action instance is annotated in the\ntraining set. Self-training aims to provide supplementary supervision for the\ntraining process by generating pseudo-labels (action proposals) from a base\nmodel. However, most current methods generate action proposals by applying\nmanually designed thresholds to action classification probabilities and\ntreating adjacent snippets as independent entities. As a result, these methods\nstruggle to generate complete action proposals, exhibit sensitivity to\nfluctuations in action classification scores, and generate redundant and\noverlapping action proposals. This paper proposes a novel framework termed\nADM-Loc, which stands for Actionness Distribution Modeling for point-supervised\naction Localization. ADM-Loc generates action proposals by fitting a composite\ndistribution, comprising both Gaussian and uniform distributions, to the action\nclassification signals. This fitting process is tailored to each action class\npresent in the video and is applied separately for each action instance,\nensuring the distinctiveness of their distributions. ADM-Loc significantly\nenhances the alignment between the generated action proposals and ground-truth\naction instances and offers high-quality pseudo-labels for self-training.\nMoreover, to model action boundary snippets, it enforces consistency in action\nclassification scores during training by employing Gaussian kernels, supervised\nwith the proposed loss functions. ADM-Loc outperforms the state-of-the-art\npoint-supervised methods on THUMOS14 and ActivityNet-v1.2 datasets.\n","authors":["Elahe Vahdani","Yingli Tian"],"pdf_url":"https://arxiv.org/pdf/2311.15916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01908v2","updated":"2023-11-27T15:23:27Z","published":"2023-11-03T13:38:42Z","title":"LLM-driven Multimodal Target Volume Contouring in Radiation Oncology","summary":"  Target volume contouring for radiation therapy is considered significantly\nmore challenging than the normal organ segmentation tasks as it necessitates\nthe utilization of both image and text-based clinical information. Inspired by\nthe recent advancement of large language models (LLMs) that can facilitate the\nintegration of the textural information and images, here we present a novel\nLLM-driven multi-modal AI that utilizes the clinical text information and is\napplicable to the challenging task of target volume contouring for radiation\ntherapy, and validate it within the context of breast cancer radiation therapy\ntarget volume contouring. Using external validation and data-insufficient\nenvironments, which attributes highly conducive to real-world applications, we\ndemonstrate that the proposed model exhibits markedly improved performance\ncompared to conventional vision-only AI models, particularly exhibiting robust\ngeneralization performance and data-efficiency. To our best knowledge, this is\nthe first LLM-driven multimodal AI model that integrates the clinical text\ninformation into target volume delineation for radiation oncology.\n","authors":["Yujin Oh","Sangjoon Park","Hwa Kyung Byun","Jin Sung Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2311.01908v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15914v1","updated":"2023-11-27T15:23:25Z","published":"2023-11-27T15:23:25Z","title":"Computer Vision for Carriers: PATRIOT","summary":"  Deck tracking performed on carriers currently involves a team of sailors\nmanually identifying aircraft and updating a digital user interface called the\nOuija Board. Improvements to the deck tracking process would result in\nincreased Sortie Generation Rates, and therefore applying automation is seen as\na critical method to improve deck tracking. However, the requirements on a\ncarrier ship do not allow for the installation of hardware-based location\nsensing technologies like Global Positioning System (GPS) sensors. PATRIOT\n(Panoramic Asset Tracking of Real-Time Information for the Ouija Tabletop) is a\nresearch effort and proposed solution to performing deck tracking with passive\nsensing and without the need for GPS sensors. PATRIOT is a prototype system\nwhich takes existing camera feeds, calculates aircraft poses, and updates a\nvirtual Ouija board interface with the current status of the assets. PATRIOT\nwould allow for faster, more accurate, and less laborious asset tracking for\naircraft, people, and support equipment. PATRIOT is anticipated to benefit the\nwarfighter by reducing cognitive workload, reducing manning requirements,\ncollecting data to improve logistics, and enabling an automation gateway for\nfuture efforts to improve efficiency and safety. The authors have developed and\ntested algorithms to perform pose estimations of assets in real-time including\nOpenPifPaf, High-Resolution Network (HRNet), HigherHRNet (HHRNet), Faster\nR-CNN, and in-house developed encoder-decoder network. The software was tested\nwith synthetic and real-world data and was able to accurately extract the pose\nof assets. Fusion, tracking, and real-world generality are planned to be\nimproved to ensure a successful transition to the fleet.\n","authors":["Ari Goodman","Gurpreet Singh","James Hing","Ryan O'Shea"],"pdf_url":"https://arxiv.org/pdf/2311.15914v1.pdf","comment":"8 pages, 18 figures. Published in the Proceedings of the ASNE 2023\n  Technology, Systems & Ships Symposium. Reproduced with permission from the\n  American Society of Naval Engineers. Distribution Statement A: Approved for\n  public release; distribution is unlimited, as submitted under NAVAIR Public\n  Release Authorization 2023-019"},{"id":"http://arxiv.org/abs/2311.15912v1","updated":"2023-11-27T15:22:17Z","published":"2023-11-27T15:22:17Z","title":"LIFT OFF: LoRaWAN Installation and Fiducial Tracking Operations for the\n  Flightline of the Future","summary":"  Real-time situational awareness for the location of assets is critical to\nensure missions are completed efficiently and requirements are satisfied. In\nmany commercial settings, the application of global positioning system (GPS)\nsensors is appropriate to achieve timely knowledge of the position of people\nand equipment. However, GPS sensors are not appropriate for all situations due\nto flight clearance and operations security concerns. LIFT OFF: LoRaWAN\nInstallation and Fiducial Tracking Operations for the Flightline of the Future\nproposes a hybrid framework solution to achieve real-time situational awareness\nfor people, support equipment, and aircraft positions regardless of the\nenvironment. This framework included a machine-vision component, which involved\nsetting up cameras to detect AprilTag decals that were installed on the sides\nof aircraft. The framework included a geolocation sensor component, which\ninvolved installing GPS sensors on support equipment and helmets. The framework\nalso included creating a long-range wide area network (LoRaWAN) to transfer\ndata and developing a user interface to display the data. The framework was\ntested at Naval Air Station Oceana Flightline, the United States Naval Test\nPilot School, and at Naval Air Warfare Center Aircraft Division Lakehurst. LIFT\nOFF successfully provided a real-time updating map of all tracked assets using\nGPS sensors for people and support equipment and with visual fiducials for\naircraft. The trajectories of the assets were recorded for logistical analysis\nand playback. Future follow-on work is anticipated to apply the technology to\nother environments including carriers and amphibious assault ships in addition\nto the flightline.\n","authors":["Ari Goodman","Ryan O'Shea"],"pdf_url":"https://arxiv.org/pdf/2311.15912v1.pdf","comment":"6 pages, 11 figures. Published in the Proceedings of the ASNE 2023\n  Technology, Systems & Ships Symposium. Reproduced with permission from the\n  American Society of Naval Engineers. Distribution Statement A: Approved for\n  public release; distribution is unlimited, as submitted under NAVAIR Public\n  Release Authorization 2023-020"},{"id":"http://arxiv.org/abs/2209.13204v2","updated":"2023-11-27T15:19:00Z","published":"2022-09-27T07:10:20Z","title":"NEURAL MARIONETTE: A Transformer-based Multi-action Human Motion\n  Synthesis System","summary":"  We present a neural network-based system for long-term, multi-action human\nmotion synthesis. The system, dubbed as NEURAL MARIONETTE, can produce\nhigh-quality and meaningful motions with smooth transitions from simple user\ninput, including a sequence of action tags with expected action duration, and\noptionally a hand-drawn moving trajectory if the user specifies. The core of\nour system is a novel Transformer-based motion generation model, namely\nMARIONET, which can generate diverse motions given action tags. Different from\nexisting motion generation models, MARIONET utilizes contextual information\nfrom the past motion clip and future action tag, dedicated to generating\nactions that can smoothly blend historical and future actions. Specifically,\nMARIONET first encodes target action tag and contextual information into an\naction-level latent code. The code is unfolded into frame-level control signals\nvia a time unrolling module, which could be then combined with other\nframe-level control signals like the target trajectory. Motion frames are then\ngenerated in an auto-regressive way. By sequentially applying MARIONET, the\nsystem NEURAL MARIONETTE can robustly generate long-term, multi-action motions\nwith the help of two simple schemes, namely \"Shadow Start\" and \"Action\nRevision\". Along with the novel system, we also present a new dataset dedicated\nto the multi-action motion synthesis task, which contains both action tags and\ntheir contextual information. Extensive experiments are conducted to study the\naction accuracy, naturalism, and transition smoothness of the motions generated\nby our system.\n","authors":["Weiqiang Wang","Xuefei Zhe","Qiuhong Ke","Di Kang","Tingguang Li","Ruizhi Chen","Linchao Bao"],"pdf_url":"https://arxiv.org/pdf/2209.13204v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15908v1","updated":"2023-11-27T15:14:38Z","published":"2023-11-27T15:14:38Z","title":"Enhancing Perceptual Quality in Video Super-Resolution through\n  Temporally-Consistent Detail Synthesis using Diffusion Models","summary":"  In this paper, we address the problem of video super-resolution (VSR) using\nDiffusion Models (DM), and present StableVSR. Our method significantly enhances\nthe perceptual quality of upscaled videos by synthesizing realistic and\ntemporally-consistent details. We turn a pre-trained DM for single image\nsuper-resolution into a VSR method by introducing the Temporal Conditioning\nModule (TCM). TCM uses Temporal Texture Guidance, which provides\nspatially-aligned and detail-rich texture information synthesized in adjacent\nframes. This guides the generative process of the current frame toward\nhigh-quality and temporally-consistent results. We introduce a Frame-wise\nBidirectional Sampling strategy to encourage the use of information from past\nto future and vice-versa. This strategy improves the perceptual quality of the\nresults and the temporal consistency across frames. We demonstrate the\neffectiveness of StableVSR in enhancing the perceptual quality of upscaled\nvideos compared to existing state-of-the-art methods for VSR. The code is\navailable at https://github.com/claudiom4sir/StableVSR.\n","authors":["Claudio Rota","Marco Buzzelli","Joost van de Weijer"],"pdf_url":"https://arxiv.org/pdf/2311.15908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15906v1","updated":"2023-11-27T15:13:02Z","published":"2023-11-27T15:13:02Z","title":"MetaDefa: Meta-learning based on Domain Enhancement and Feature\n  Alignment for Single Domain Generalization","summary":"  The single domain generalization(SDG) based on meta-learning has emerged as\nan effective technique for solving the domain-shift problem. However, the\ninadequate match of data distribution between source and augmented domains and\ndifficult separation of domain-invariant features from domain-related features\nmake SDG model hard to achieve great generalization. Therefore, a novel\nmeta-learning method based on domain enhancement and feature alignment\n(MetaDefa) is proposed to improve the model generalization performance. First,\nthe background substitution and visual corruptions techniques are used to\ngenerate diverse and effective augmented domains. Then, the multi-channel\nfeature alignment module based on class activation maps and class agnostic\nactivation maps is designed to effectively extract adequate transferability\nknowledge. In this module, domain-invariant features can be fully explored by\nfocusing on similar target regions between source and augmented domains feature\nspace and suppressing the feature representation of non-similar target regions.\nExtensive experiments on two publicly available datasets show that MetaDefa has\nsignificant generalization performance advantages in unknown multiple target\ndomains.\n","authors":["Can Sun","Hao Zheng","Zhigang Hu","Liu Yang","Meiguang Zheng","Bo Xu"],"pdf_url":"https://arxiv.org/pdf/2311.15906v1.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.05697v2","updated":"2023-11-27T15:08:03Z","published":"2023-11-09T19:10:28Z","title":"3DGAUnet: 3D generative adversarial networks with a 3D U-Net based\n  generator to achieve the accurate and effective synthesis of clinical tumor\n  image data for pancreatic cancer","summary":"  Pancreatic ductal adenocarcinoma (PDAC) presents a critical global health\nchallenge, and early detection is crucial for improving the 5-year survival\nrate. Recent medical imaging and computational algorithm advances offer\npotential solutions for early diagnosis. Deep learning, particularly in the\nform of convolutional neural networks (CNNs), has demonstrated success in\nmedical image analysis tasks, including classification and segmentation.\nHowever, the limited availability of clinical data for training purposes\ncontinues to provide a significant obstacle. Data augmentation, generative\nadversarial networks (GANs), and cross-validation are potential techniques to\naddress this limitation and improve model performance, but effective solutions\nare still rare for 3D PDAC, where contrast is especially poor owing to the high\nheterogeneity in both tumor and background tissues. In this study, we developed\na new GAN-based model, named 3DGAUnet, for generating realistic 3D CT images of\nPDAC tumors and pancreatic tissue, which can generate the interslice connection\ndata that the existing 2D CT image synthesis models lack. Our innovation is to\ndevelop a 3D U-Net architecture for the generator to improve shape and texture\nlearning for PDAC tumors and pancreatic tissue. Our approach offers a promising\npath to tackle the urgent requirement for creative and synergistic methods to\ncombat PDAC. The development of this GAN-based model has the potential to\nalleviate data scarcity issues, elevate the quality of synthesized data, and\nthereby facilitate the progression of deep learning models to enhance the\naccuracy and early detection of PDAC tumors, which could profoundly impact\npatient outcomes. Furthermore, this model has the potential to be adapted to\nother types of solid tumors, hence making significant contributions to the\nfield of medical imaging in terms of image processing models.\n","authors":["Yu Shi","Hannah Tang","Michael Baine","Michael A. Hollingsworth","Huijing Du","Dandan Zheng","Chi Zhang","Hongfeng Yu"],"pdf_url":"https://arxiv.org/pdf/2311.05697v2.pdf","comment":"Published on Cancers: Shi, Yu, Hannah Tang, Michael J. Baine, Michael\n  A. Hollingsworth, Huijing Du, Dandan Zheng, Chi Zhang, and Hongfeng Yu. 2023.\n  \"3DGAUnet: 3D Generative Adversarial Networks with a 3D U-Net Based Generator\n  to Achieve the Accurate and Effective Synthesis of Clinical Tumor Image Data\n  for Pancreatic Cancer\" Cancers 15, no. 23: 5496"},{"id":"http://arxiv.org/abs/2311.15896v1","updated":"2023-11-27T15:01:26Z","published":"2023-11-27T15:01:26Z","title":"Data Generation for Post-OCR correction of Cyrillic handwriting","summary":"  This paper introduces a novel approach to post-Optical Character Recognition\nCorrection (POC) for handwritten Cyrillic text, addressing a significant gap in\ncurrent research methodologies. This gap is due to the lack of large text\ncorporas that provide OCR errors for further training of language-based POC\nmodels, which are demanding in terms of corpora size. Our study primarily\nfocuses on the development and application of a synthetic handwriting\ngeneration engine based on B\\'ezier curves. Such an engine generates highly\nrealistic handwritten text in any amounts, which we utilize to create a\nsubstantial dataset by transforming Russian text corpora sourced from the\ninternet. We apply a Handwritten Text Recognition (HTR) model to this dataset\nto identify OCR errors, forming the basis for our POC model training. The\ncorrection model is trained on a 90-symbol input context, utilizing a\npre-trained T5 architecture with a seq2seq correction task. We evaluate our\napproach on HWR200 and School_notebooks_RU datasets as they provide significant\nchallenges in the HTR domain. Furthermore, POC can be used to highlight errors\nfor teachers, evaluating student performance. This can be done simply by\ncomparing sentences before and after correction, displaying differences in\ntext. Our primary contribution lies in the innovative use of B\\'ezier curves\nfor Cyrillic text generation and subsequent error correction using a\nspecialized POC model. We validate our approach by presenting Word Accuracy\nRate (WAR) and Character Accuracy Rate (CAR) results, both with and without\npost-OCR correction, using real open corporas of handwritten Cyrillic text.\nThese results, coupled with our methodology, are designed to be reproducible,\npaving the way for further advancements in the field of OCR and handwritten\ntext analysis. Paper contributions can be found in\nhttps://github.com/dbrainio/CyrillicHandwritingPOC\n","authors":["Evgenii Davydkin","Aleksandr Markelov","Egor Iuldashev","Anton Dudkin","Ivan Krivorotov"],"pdf_url":"https://arxiv.org/pdf/2311.15896v1.pdf","comment":"17 pages, 27 figures, 6 tables, 26 references"},{"id":"http://arxiv.org/abs/2311.15890v1","updated":"2023-11-27T14:56:47Z","published":"2023-11-27T14:56:47Z","title":"Stability-Informed Initialization of Neural Ordinary Differential\n  Equations","summary":"  This paper addresses the training of Neural Ordinary Differential Equations\n(neural ODEs), and in particular explores the interplay between numerical\nintegration techniques, stability regions, step size, and initialization\ntechniques. It is shown how the choice of integration technique implicitly\nregularizes the learned model, and how the solver's corresponding stability\nregion affects training and prediction performance. From this analysis, a\nstability-informed parameter initialization technique is introduced. The\neffectiveness of the initialization method is displayed across several learning\nbenchmarks and industrial applications.\n","authors":["Theodor Westny","Arman Mohammadi","Daniel Jung","Erik Frisk"],"pdf_url":"https://arxiv.org/pdf/2311.15890v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15879v1","updated":"2023-11-27T14:51:37Z","published":"2023-11-27T14:51:37Z","title":"EVCap: Retrieval-Augmented Image Captioning with External Visual-Name\n  Memory for Open-World Comprehension","summary":"  Large language models (LLMs)-based image captioning has the capability of\ndescribing objects not explicitly observed in training data; yet novel objects\noccur frequently, necessitating the requirement of sustaining up-to-date object\nknowledge for open-world comprehension. Instead of relying on large amounts of\ndata and scaling up network parameters, we introduce a highly effective\nretrieval-augmented image captioning method that prompts LLMs with object names\nretrieved from External Visual--name memory (EVCap). We build ever-changing\nobject knowledge memory using objects' visuals and names, enabling us to (i)\nupdate the memory at a minimal cost and (ii) effortlessly augment LLMs with\nretrieved object names utilizing a lightweight and fast-to-train model. Our\nmodel, which was trained only on the COCO dataset, can be adapted to out-domain\ndata without additional fine-tuning or retraining. Our comprehensive\nexperiments conducted on various benchmarks and synthetic commonsense-violating\ndata demonstrate that EVCap, comprising solely 3.97M trainable parameters,\nexhibits superior performance compared to other methods of equivalent model\nsize scale. Notably, it achieves competitive performance against specialist\nSOTAs with an enormous number of parameters. Our code is available at\nhttps://jiaxuan-li.github.io/EVCap.\n","authors":["Jiaxuan Li","Duc Minh Vo","Akihiro Sugimoto","Hideki Nakayama"],"pdf_url":"https://arxiv.org/pdf/2311.15879v1.pdf","comment":"Project page: https://jiaxuan-li.github.io/EVCap"},{"id":"http://arxiv.org/abs/2311.15876v1","updated":"2023-11-27T14:49:06Z","published":"2023-11-27T14:49:06Z","title":"RO-LLaMA: Generalist LLM for Radiation Oncology via Noise Augmentation\n  and Consistency Regularization","summary":"  Recent advancements in Artificial Intelligence (AI) have profoundly\ninfluenced medical fields, by providing tools to reduce clinical workloads.\nHowever, most AI models are constrained to execute uni-modal tasks, in stark\ncontrast to the comprehensive approaches utilized by medical professionals. To\naddress this, here we present RO-LLaMA, a versatile generalist large language\nmodel (LLM) tailored for the field of radiation oncology. This model seamlessly\ncovers a wide range of the workflow of radiation oncologists, adept at various\ntasks such as clinical report summarization, radiation therapy plan suggestion,\nand plan-guided therapy target volume segmentation. In particular, to maximize\nthe end-to-end performance, we further present a novel Consistency Embedding\nFine-Tuning (CEFTune) technique, which boosts LLM's robustness to additional\nerrors at the intermediates while preserving the capability of handling clean\ninputs, and creatively transform this concept into LLM-driven segmentation\nframework as Consistency Embedding Segmentation (CESEG). Experimental results\non multi-centre cohort sets demonstrate our proposed RO-LLaMA's promising\nperformance for diverse tasks with generalization capabilities.\n","authors":["Kwanyoung Kim","Yujin Oh","Sangjoon Park","Hwa Kyung Byun","Jin Sung Kim","Yong Bae Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2311.15876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.00349v2","updated":"2023-11-27T14:42:52Z","published":"2023-06-01T05:06:56Z","title":"CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV\n  Perception","summary":"  Perception is crucial in the realm of autonomous driving systems, where\nbird's eye view (BEV)-based architectures have recently reached\nstate-of-the-art performance. The desirability of self-supervised\nrepresentation learning stems from the expensive and laborious process of\nannotating 2D and 3D data. Although previous research has investigated\npretraining methods for both LiDAR and camera-based 3D object detection, a\nunified pretraining framework for multimodal BEV perception is missing. In this\nstudy, we introduce CALICO, a novel framework that applies contrastive\nobjectives to both LiDAR and camera backbones. Specifically, CALICO\nincorporates two stages: point-region contrast (PRC) and region-aware\ndistillation (RAD). PRC better balances the region- and scene-level\nrepresentation learning on the LiDAR modality and offers significant\nperformance improvement compared to existing methods. RAD effectively achieves\ncontrastive distillation on our self-trained teacher model. CALICO's efficacy\nis substantiated by extensive evaluations on 3D object detection and BEV map\nsegmentation tasks, where it delivers significant performance improvements.\nNotably, CALICO outperforms the baseline method by 10.5% and 8.6% on NDS and\nmAP. Moreover, CALICO boosts the robustness of multimodal 3D object detection\nagainst adversarial attacks and corruption. Additionally, our framework can be\ntailored to different backbones and heads, positioning it as a promising\napproach for multimodal BEV perception.\n","authors":["Jiachen Sun","Haizhong Zheng","Qingzhao Zhang","Atul Prakash","Z. Morley Mao","Chaowei Xiao"],"pdf_url":"https://arxiv.org/pdf/2306.00349v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15864v1","updated":"2023-11-27T14:32:33Z","published":"2023-11-27T14:32:33Z","title":"InterControl: Generate Human Motion Interactions by Controlling Every\n  Joint","summary":"  Text-conditioned human motion generation model has achieved great progress by\nintroducing diffusion models and corresponding control signals. However, the\ninteraction between humans are still under explored. To model interactions of\narbitrary number of humans, we define interactions as human joint pairs that\nare either in contact or separated, and leverage {\\em Large Language Model\n(LLM) Planner} to translate interaction descriptions into contact plans. Based\non the contact plans, interaction generation could be achieved by spatially\ncontrollable motion generation methods by taking joint contacts as spatial\nconditions. We present a novel approach named InterControl for flexible spatial\ncontrol of every joint in every person at any time by leveraging motion\ndiffusion model only trained on single-person data. We incorporate a motion\ncontrolnet to generate coherent and realistic motions given sparse spatial\ncontrol signals and a loss guidance module to precisely align any joint to the\ndesired position in a classifier guidance manner via Inverse Kinematics (IK).\nExtensive experiments on HumanML3D and KIT-ML dataset demonstrate its\neffectiveness in versatile joint control. We also collect data of joint contact\npairs by LLMs to show InterControl's ability in human interaction generation.\n","authors":["Zhenzhi Wang","Jingbo Wang","Dahua Lin","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2311.15864v1.pdf","comment":"Generate human interactions with only single-person motion diffusion\n  model via LLM generated joint contact pairs, code\n  https://github.com/zhenzhiwang/intercontrol"},{"id":"http://arxiv.org/abs/2311.15856v1","updated":"2023-11-27T14:23:36Z","published":"2023-11-27T14:23:36Z","title":"JSSL: Joint Supervised and Self-supervised Learning for MRI\n  Reconstruction","summary":"  Magnetic Resonance Imaging represents an important diagnostic modality;\nhowever, its inherently slow acquisition process poses challenges in obtaining\nfully sampled k-space data under motion in clinical scenarios such as\nabdominal, cardiac, and prostate imaging. In the absence of fully sampled\nacquisitions, which can serve as ground truth data, training deep learning\nalgorithms in a supervised manner to predict the underlying ground truth image\nbecomes an impossible task. To address this limitation, self-supervised methods\nhave emerged as a viable alternative, leveraging available subsampled k-space\ndata to train deep learning networks for MRI reconstruction. Nevertheless,\nthese self-supervised approaches often fall short when compared to supervised\nmethodologies. In this paper, we introduce JSSL (Joint Supervised and\nSelf-supervised Learning), a novel training approach for deep learning-based\nMRI reconstruction algorithms aimed at enhancing reconstruction quality in\nscenarios where target dataset(s) containing fully sampled k-space measurements\nare unavailable. Our proposed method operates by simultaneously training a\nmodel in a self-supervised learning setting, using subsampled data from the\ntarget dataset(s), and in a supervised learning manner, utilizing data from\nother datasets, referred to as proxy datasets, where fully sampled k-space data\nis accessible. To demonstrate the efficacy of JSSL, we utilized subsampled\nprostate parallel MRI measurements as the target dataset, while employing fully\nsampled brain and knee k-space acquisitions as proxy datasets. Our results\nshowcase a substantial improvement over conventional self-supervised training\nmethods, thereby underscoring the effectiveness of our joint approach. We\nprovide a theoretical motivation for JSSL and establish a practical\n\"rule-of-thumb\" for selecting the most appropriate training approach for deep\nMRI reconstruction.\n","authors":["George Yiasemis","Nikita Moriakov","Clara I. Sánchez","Jan-Jakob Sonke","Jonas Teuwen"],"pdf_url":"https://arxiv.org/pdf/2311.15856v1.pdf","comment":"26 pages, 11 figures, 6 tables"},{"id":"http://arxiv.org/abs/2311.15855v1","updated":"2023-11-27T14:22:07Z","published":"2023-11-27T14:22:07Z","title":"SiTH: Single-view Textured Human Reconstruction with Image-Conditioned\n  Diffusion","summary":"  A long-standing goal of 3D human reconstruction is to create lifelike and\nfully detailed 3D humans from single images. The main challenge lies in\ninferring unknown human shapes, clothing, and texture information in areas not\nvisible in the images. To address this, we propose SiTH, a novel pipeline that\nuniquely integrates an image-conditioned diffusion model into a 3D mesh\nreconstruction workflow. At the core of our method lies the decomposition of\nthe ill-posed single-view reconstruction problem into hallucination and\nreconstruction subproblems. For the former, we employ a powerful generative\ndiffusion model to hallucinate back appearances from the input images. For the\nlatter, we leverage skinned body meshes as guidance to recover full-body\ntexture meshes from the input and back-view images. Our designs enable training\nof the pipeline with only about 500 3D human scans while maintaining its\ngenerality and robustness. Extensive experiments and user studies on two 3D\nreconstruction benchmarks demonstrated the efficacy of our method in generating\nrealistic, fully textured 3D humans from a diverse range of unseen images.\n","authors":["Hsuan-I Ho","Jie Song","Otmar Hilliges"],"pdf_url":"https://arxiv.org/pdf/2311.15855v1.pdf","comment":"8 pages, 9 figures"},{"id":"http://arxiv.org/abs/2310.12877v3","updated":"2023-11-27T14:22:05Z","published":"2023-10-19T16:32:18Z","title":"Perceptual Assessment and Optimization of High Dynamic Range Image\n  Rendering","summary":"  The increasing popularity of high dynamic range (HDR) imaging stems from its\nability to faithfully capture luminance levels in natural scenes. However, HDR\nimage quality assessment has been insufficiently addressed. Existing models are\nmostly designed for low dynamic range (LDR) images, which exhibit poorly\ncorrelated with human perception of HDR image quality. To fill this gap, we\npropose a family of HDR quality metrics by transferring the recent advancements\nin LDR domain. The key step in our approach is to employ a simple inverse\ndisplay model to decompose an HDR image into a stack of LDR images with varying\nexposures. Subsequently, these LDR images are evaluated using state-of-the-art\nLDR quality metrics. Our family of HDR quality models offer three notable\nadvantages. First, specific exposures (i.e., luminance ranges) can be weighted\nto emphasize their assessment when calculating the overall quality score.\nSecond, our HDR quality metrics directly inherit the capabilities of their base\nLDR quality models in assessing LDR images. Third, our metrics do not rely on\nhuman perceptual data of HDR image quality for re-calibration. Experiments\nconducted on four human-rated HDR image quality datasets indicate that our HDR\nquality metrics consistently outperform existing methods, including the HDR-VDP\nfamily. Furthermore, we demonstrate the promise of our models in the perceptual\noptimization of HDR novel view synthesis.\n","authors":["Peibei Cao","Rafal K. Mantiuk","Kede Ma"],"pdf_url":"https://arxiv.org/pdf/2310.12877v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15851v1","updated":"2023-11-27T14:17:41Z","published":"2023-11-27T14:17:41Z","title":"Single-Model and Any-Modality for Video Object Tracking","summary":"  In the realm of video object tracking, auxiliary modalities such as depth,\nthermal, or event data have emerged as valuable assets to complement the RGB\ntrackers. In practice, most existing RGB trackers learn a single set of\nparameters to use them across datasets and applications. However, a similar\nsingle-model unification for multi-modality tracking presents several\nchallenges. These challenges stem from the inherent heterogeneity of inputs --\neach with modality-specific representations, the scarcity of multi-modal\ndatasets, and the absence of all the modalities at all times. In this work, we\nintroduce Un-Track, a \\underline{Un}ified Tracker of a single set of parameters\nfor any modality. To handle any modality, our method learns their common latent\nspace through low-rank factorization and reconstruction techniques. More\nimportantly, we use only the RGB-X pairs to learn the common latent space. This\nunique shared representation seamlessly binds all modalities together, enabling\neffective unification and accommodating any missing modality, all within a\nsingle transformer-based architecture and without the need for\nmodality-specific fine-tuning. Our Un-Track achieves +8.1 absolute F-score\ngain, on the DepthTrack dataset, by introducing only +2.14 (over 21.50) GFLOPs\nwith +6.6M (over 93M) parameters, through a simple yet efficient prompting\nstrategy. Extensive comparisons on five benchmark datasets with different\nmodalities show that Un-Track surpasses both SOTA unified trackers and\nmodality-specific finetuned counterparts, validating our effectiveness and\npracticality.\n","authors":["Zongwei Wu","Jilai Zheng","Xiangxuan Ren","Florin-Alexandru Vasluianu","Chao Ma","Danda Pani Paudel","Luc Van Gool","Radu Timofte"],"pdf_url":"https://arxiv.org/pdf/2311.15851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15847v1","updated":"2023-11-27T14:12:51Z","published":"2023-11-27T14:12:51Z","title":"Cell Maps Representation For Lung Adenocarcinoma Growth Patterns\n  Classification In Whole Slide Images","summary":"  Lung adenocarcinoma is a morphologically heterogeneous disease, characterized\nby five primary histologic growth patterns. The quantity of these patterns can\nbe related to tumor behavior and has a significant impact on patient prognosis.\nIn this work, we propose a novel machine learning pipeline capable of\nclassifying tissue tiles into one of the five patterns or as non-tumor, with an\nArea Under the Receiver Operating Characteristic Curve (AUCROC) score of 0.97.\nOur model's strength lies in its comprehensive consideration of cellular\nspatial patterns, where it first generates cell maps from Hematoxylin and Eosin\n(H&E) whole slide images (WSIs), which are then fed into a convolutional neural\nnetwork classification model. Exploiting these cell maps provides the model\nwith robust generalizability to new data, achieving approximately 30% higher\naccuracy on unseen test-sets compared to current state of the art approaches.\nThe insights derived from our model can be used to predict prognosis, enhancing\npatient outcomes.\n","authors":["Arwa Al-Rubaian","Gozde N. Gunesli","Wajd A. Althakfi","Ayesha Azam","Nasir Rajpoot","Shan E Ahmed Raza"],"pdf_url":"https://arxiv.org/pdf/2311.15847v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15846v1","updated":"2023-11-27T14:11:54Z","published":"2023-11-27T14:11:54Z","title":"Learning with Noisy Low-Cost MOS for Image Quality Assessment via\n  Dual-Bias Calibration","summary":"  Learning based image quality assessment (IQA) models have obtained impressive\nperformance with the help of reliable subjective quality labels, where mean\nopinion score (MOS) is the most popular choice. However, in view of the\nsubjective bias of individual annotators, the labor-abundant MOS (LA-MOS)\ntypically requires a large collection of opinion scores from multiple\nannotators for each image, which significantly increases the learning cost. In\nthis paper, we aim to learn robust IQA models from low-cost MOS (LC-MOS), which\nonly requires very few opinion scores or even a single opinion score for each\nimage. More specifically, we consider the LC-MOS as the noisy observation of\nLA-MOS and enforce the IQA model learned from LC-MOS to approach the unbiased\nestimation of LA-MOS. In this way, we represent the subjective bias between\nLC-MOS and LA-MOS, and the model bias between IQA predictions learned from\nLC-MOS and LA-MOS (i.e., dual-bias) as two latent variables with unknown\nparameters. By means of the expectation-maximization based alternating\noptimization, we can jointly estimate the parameters of the dual-bias, which\nsuppresses the misleading of LC-MOS via a gated dual-bias calibration (GDBC)\nmodule. To the best of our knowledge, this is the first exploration of robust\nIQA model learning from noisy low-cost labels. Theoretical analysis and\nextensive experiments on four popular IQA datasets show that the proposed\nmethod is robust toward different bias rates and annotation numbers and\nsignificantly outperforms the other learning based IQA models when only LC-MOS\nis available. Furthermore, we also achieve comparable performance with respect\nto the other models learned with LA-MOS.\n","authors":["Lei Wang","Qingbo Wu","Desen Yuan","King Ngi Ngan","Hongliang Li","Fanman Meng","Linfeng Xu"],"pdf_url":"https://arxiv.org/pdf/2311.15846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15841v1","updated":"2023-11-27T14:07:13Z","published":"2023-11-27T14:07:13Z","title":"Learning Disentangled Identifiers for Action-Customized Text-to-Image\n  Generation","summary":"  This study focuses on a novel task in text-to-image (T2I) generation, namely\naction customization. The objective of this task is to learn the co-existing\naction from limited data and generalize it to unseen humans or even animals.\nExperimental results show that existing subject-driven customization methods\nfail to learn the representative characteristics of actions and struggle in\ndecoupling actions from context features, including appearance. To overcome the\npreference for low-level features and the entanglement of high-level features,\nwe propose an inversion-based method Action-Disentangled Identifier (ADI) to\nlearn action-specific identifiers from the exemplar images. ADI first expands\nthe semantic conditioning space by introducing layer-wise identifier tokens,\nthereby increasing the representational richness while distributing the\ninversion across different features. Then, to block the inversion of\naction-agnostic features, ADI extracts the gradient invariance from the\nconstructed sample triples and masks the updates of irrelevant channels. To\ncomprehensively evaluate the task, we present an ActionBench that includes a\nvariety of actions, each accompanied by meticulously selected samples. Both\nquantitative and qualitative results show that our ADI outperforms existing\nbaselines in action-customized T2I generation.\n","authors":["Siteng Huang","Biao Gong","Yutong Feng","Xi Chen","Yuqian Fu","Yu Liu","Donglin Wang"],"pdf_url":"https://arxiv.org/pdf/2311.15841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15836v1","updated":"2023-11-27T13:59:53Z","published":"2023-11-27T13:59:53Z","title":"Syn3DWound: A Synthetic Dataset for 3D Wound Bed Analysis","summary":"  Wound management poses a significant challenge, particularly for bedridden\npatients and the elderly. Accurate diagnostic and healing monitoring can\nsignificantly benefit from modern image analysis, providing accurate and\nprecise measurements of wounds. Despite several existing techniques, the\nshortage of expansive and diverse training datasets remains a significant\nobstacle to constructing machine learning-based frameworks. This paper\nintroduces Syn3DWound, an open-source dataset of high-fidelity simulated wounds\nwith 2D and 3D annotations. We propose baseline methods and a benchmarking\nframework for automated 3D morphometry analysis and 2D/3D wound segmentation.\n","authors":["Léo Lebrat","Rodrigo Santa Cruz","Remi Chierchia","Yulia Arzhaeva","Mohammad Ali Armin","Joshua Goldsmith","Jeremy Oorloff","Prithvi Reddy","Chuong Nguyen","Lars Petersson","Michelle Barakat-Johnson","Georgina Luscombe","Clinton Fookes","Olivier Salvado","David Ahmedt-Aristizabal"],"pdf_url":"https://arxiv.org/pdf/2311.15836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15830v1","updated":"2023-11-27T13:53:53Z","published":"2023-11-27T13:53:53Z","title":"A-JEPA: Joint-Embedding Predictive Architecture Can Listen","summary":"  This paper presents that the masked-modeling principle driving the success of\nlarge foundational vision models can be effectively applied to audio by making\npredictions in a latent space. We introduce Audio-based Joint-Embedding\nPredictive Architecture (A-JEPA), a simple extension method for self-supervised\nlearning from the audio spectrum. Following the design of I-JPEA, our A-JEPA\nencodes visible audio spectrogram patches with a curriculum masking strategy\nvia context encoder, and predicts the representations of regions sampled at\nwell-designed locations. The target representations of those regions are\nextracted by the exponential moving average of context encoder, \\emph{i.e.},\ntarget encoder, on the whole spectrogram. We find it beneficial to transfer\nrandom block masking into time-frequency aware masking in a curriculum manner,\nconsidering the complexity of highly correlated in local time and frequency in\naudio spectrograms. To enhance contextual semantic understanding and\nrobustness, we fine-tune the encoder with a regularized masking on target\ndatasets, instead of input dropping or zero. Empirically, when built with\nVision Transformers structure, we find A-JEPA to be highly scalable and sets\nnew state-of-the-art performance on multiple audio and speech classification\ntasks, outperforming other recent models that use externally supervised\npre-training.\n","authors":["Zhengcong Fei","Mingyuan Fan","Junshi Huang"],"pdf_url":"https://arxiv.org/pdf/2311.15830v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15813v1","updated":"2023-11-27T13:39:44Z","published":"2023-11-27T13:39:44Z","title":"FlowZero: Zero-Shot Text-to-Video Synthesis with LLM-Driven Dynamic\n  Scene Syntax","summary":"  Text-to-video (T2V) generation is a rapidly growing research area that aims\nto translate the scenes, objects, and actions within complex video text into a\nsequence of coherent visual frames. We present FlowZero, a novel framework that\ncombines Large Language Models (LLMs) with image diffusion models to generate\ntemporally-coherent videos. FlowZero uses LLMs to understand complex\nspatio-temporal dynamics from text, where LLMs can generate a comprehensive\ndynamic scene syntax (DSS) containing scene descriptions, object layouts, and\nbackground motion patterns. These elements in DSS are then used to guide the\nimage diffusion model for video generation with smooth object motions and\nframe-to-frame coherence. Moreover, FlowZero incorporates an iterative\nself-refinement process, enhancing the alignment between the spatio-temporal\nlayouts and the textual prompts for the videos. To enhance global coherence, we\npropose enriching the initial noise of each frame with motion dynamics to\ncontrol the background movement and camera motion adaptively. By using\nspatio-temporal syntaxes to guide the diffusion process, FlowZero achieves\nimprovement in zero-shot video synthesis, generating coherent videos with vivid\nmotion.\n","authors":["Yu Lu","Linchao Zhu","Hehe Fan","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2311.15813v1.pdf","comment":"Project page: https://flowzero-video.github.io"},{"id":"http://arxiv.org/abs/2310.12190v2","updated":"2023-11-27T13:36:04Z","published":"2023-10-18T14:42:16Z","title":"DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors","summary":"  Animating a still image offers an engaging visual experience. Traditional\nimage animation techniques mainly focus on animating natural scenes with\nstochastic dynamics (e.g. clouds and fluid) or domain-specific motions (e.g.\nhuman hair or body motions), and thus limits their applicability to more\ngeneral visual content. To overcome this limitation, we explore the synthesis\nof dynamic content for open-domain images, converting them into animated\nvideos. The key idea is to utilize the motion prior of text-to-video diffusion\nmodels by incorporating the image into the generative process as guidance.\nGiven an image, we first project it into a text-aligned rich context\nrepresentation space using a query transformer, which facilitates the video\nmodel to digest the image content in a compatible fashion. However, some visual\ndetails still struggle to be preserved in the resultant videos. To supplement\nwith more precise image information, we further feed the full image to the\ndiffusion model by concatenating it with the initial noises. Experimental\nresults show that our proposed method can produce visually convincing and more\nlogical & natural motions, as well as higher conformity to the input image.\nComparative evaluation demonstrates the notable superiority of our approach\nover existing competitors.\n","authors":["Jinbo Xing","Menghan Xia","Yong Zhang","Haoxin Chen","Wangbo Yu","Hanyuan Liu","Xintao Wang","Tien-Tsin Wong","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2310.12190v2.pdf","comment":"Project page: https://doubiiu.github.io/projects/DynamiCrafter"},{"id":"http://arxiv.org/abs/2311.15812v1","updated":"2023-11-27T13:35:20Z","published":"2023-11-27T13:35:20Z","title":"C-SAW: Self-Supervised Prompt Learning for Image Generalization in\n  Remote Sensing","summary":"  We focus on domain and class generalization problems in analyzing optical\nremote sensing images, using the large-scale pre-trained vision-language model\n(VLM), CLIP. While contrastively trained VLMs show impressive zero-shot\ngeneralization performance, their effectiveness is limited when dealing with\ndiverse domains during training and testing. Existing prompt learning\ntechniques overlook the importance of incorporating domain and content\ninformation into the prompts, which results in a drop in performance while\ndealing with such multi-domain data. To address these challenges, we propose a\nsolution that ensures domain-invariant prompt learning while enhancing the\nexpressiveness of visual features. We observe that CLIP's vision encoder\nstruggles to identify contextual image information, particularly when image\npatches are jumbled up. This issue is especially severe in optical remote\nsensing images, where land-cover classes exhibit well-defined contextual\nappearances. To this end, we introduce C-SAW, a method that complements CLIP\nwith a self-supervised loss in the visual space and a novel prompt learning\ntechnique that emphasizes both visual domain and content-specific features. We\nkeep the CLIP backbone frozen and introduce a small set of projectors for both\nthe CLIP encoders to train C-SAW contrastively. Experimental results\ndemonstrate the superiority of C-SAW across multiple remote sensing benchmarks\nand different generalization tasks.\n","authors":["Avigyan Bhattacharya","Mainak Singha","Ankit Jha","Biplab Banerjee"],"pdf_url":"https://arxiv.org/pdf/2311.15812v1.pdf","comment":"Accepted in ACM ICVGIP 2023"},{"id":"http://arxiv.org/abs/2311.15806v1","updated":"2023-11-27T13:29:34Z","published":"2023-11-27T13:29:34Z","title":"PIPE : Parallelized Inference Through Post-Training Quantization\n  Ensembling of Residual Expansions","summary":"  Deep neural networks (DNNs) are ubiquitous in computer vision and natural\nlanguage processing, but suffer from high inference cost. This problem can be\naddressed by quantization, which consists in converting floating point\nperations into a lower bit-width format. With the growing concerns on privacy\nrights, we focus our efforts on data-free methods. However, such techniques\nsuffer from their lack of adaptability to the target devices, as a hardware\ntypically only support specific bit widths. Thus, to adapt to a variety of\ndevices, a quantization method shall be flexible enough to find good accuracy\nv.s. speed trade-offs for every bit width and target device. To achieve this,\nwe propose PIPE, a quantization method that leverages residual error expansion,\nalong with group sparsity and an ensemble approximation for better\nparallelization. PIPE is backed off by strong theoretical guarantees and\nachieves superior performance on every benchmarked application (from vision to\nNLP tasks), architecture (ConvNets, transformers) and bit-width (from int8 to\nternary quantization).\n","authors":["Edouard Yvinec","Arnaud Dapogny","Kevin Bailly"],"pdf_url":"https://arxiv.org/pdf/2311.15806v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2203.14645"},{"id":"http://arxiv.org/abs/2311.15803v1","updated":"2023-11-27T13:25:47Z","published":"2023-11-27T13:25:47Z","title":"SOAC: Spatio-Temporal Overlap-Aware Multi-Sensor Calibration using\n  Neural Radiance Fields","summary":"  In rapidly-evolving domains such as autonomous driving, the use of multiple\nsensors with different modalities is crucial to ensure high operational\nprecision and stability. To correctly exploit the provided information by each\nsensor in a single common frame, it is essential for these sensors to be\naccurately calibrated. In this paper, we leverage the ability of Neural\nRadiance Fields (NeRF) to represent different sensors modalities in a common\nvolumetric representation to achieve robust and accurate spatio-temporal sensor\ncalibration. By designing a partitioning approach based on the visible part of\nthe scene for each sensor, we formulate the calibration problem using only the\noverlapping areas. This strategy results in a more robust and accurate\ncalibration that is less prone to failure. We demonstrate that our approach\nworks on outdoor urban scenes by validating it on multiple established driving\ndatasets. Results show that our method is able to get better accuracy and\nrobustness compared to existing methods.\n","authors":["Quentin Herau","Nathan Piasco","Moussab Bennehar","Luis Roldão","Dzmitry Tsishkou","Cyrille Migniot","Pascal Vasseur","Cédric Demonceaux"],"pdf_url":"https://arxiv.org/pdf/2311.15803v1.pdf","comment":"Paper + Supplementary, under review"},{"id":"http://arxiv.org/abs/2209.07042v5","updated":"2023-11-27T13:18:28Z","published":"2022-09-15T04:51:17Z","title":"Efficient Perception, Planning, and Control Algorithms for Vision-Based\n  Automated Vehicles","summary":"  Autonomous vehicles have limited computational resources; hence, their\ncontrol systems must be efficient. The cost and size of sensors have limited\nthe development of self-driving cars. To overcome these restrictions, this\nstudy proposes an efficient framework for the operation of vision-based\nautomatic vehicles; the framework requires only a monocular camera and a few\ninexpensive radars. The proposed algorithm comprises a multi-task UNet (MTUNet)\nnetwork for extracting image features and constrained iterative linear\nquadratic regulator (CILQR) and vision predictive control (VPC) modules for\nrapid motion planning and control. MTUNet is designed to simultaneously solve\nlane line segmentation, the ego vehicle's heading angle regression, road type\nclassification, and traffic object detection tasks at approximately 40 FPS\n(frames per second) for 228 x 228 pixel RGB input images. The CILQR controllers\nthen use the MTUNet outputs and radar data as inputs to produce driving\ncommands for lateral and longitudinal vehicle guidance within only 1 ms. In\nparticular, the VPC algorithm is included to reduce steering command latency to\nbelow actuator latency to prevent self-driving vehicle performance degradation\nduring tight turns. The VPC algorithm uses road curvature data from MTUNet to\nestimate the correction of the current steering angle at a look-ahead point to\nadjust the turning amount. Including the VPC algorithm in a VPC-CILQR\ncontroller on curvy roads leads to higher performance than CILQR alone. Our\nexperiments demonstrate that the proposed autonomous driving system, which does\nnot require high-definition maps, could be applied in current autonomous\nvehicles.\n","authors":["Der-Hau Lee"],"pdf_url":"https://arxiv.org/pdf/2209.07042v5.pdf","comment":"10 figures, 13 pages"},{"id":"http://arxiv.org/abs/2310.03335v2","updated":"2023-11-27T13:18:11Z","published":"2023-10-05T06:35:21Z","title":"Continual Test-time Domain Adaptation via Dynamic Sample Selection","summary":"  The objective of Continual Test-time Domain Adaptation (CTDA) is to gradually\nadapt a pre-trained model to a sequence of target domains without accessing the\nsource data. This paper proposes a Dynamic Sample Selection (DSS) method for\nCTDA. DSS consists of dynamic thresholding, positive learning, and negative\nlearning processes. Traditionally, models learn from unlabeled unknown\nenvironment data and equally rely on all samples' pseudo-labels to update their\nparameters through self-training. However, noisy predictions exist in these\npseudo-labels, so all samples are not equally trustworthy. Therefore, in our\nmethod, a dynamic thresholding module is first designed to select suspected\nlow-quality from high-quality samples. The selected low-quality samples are\nmore likely to be wrongly predicted. Therefore, we apply joint positive and\nnegative learning on both high- and low-quality samples to reduce the risk of\nusing wrong information. We conduct extensive experiments that demonstrate the\neffectiveness of our proposed method for CTDA in the image domain,\noutperforming the state-of-the-art results. Furthermore, our approach is also\nevaluated in the 3D point cloud domain, showcasing its versatility and\npotential for broader applicability.\n","authors":["Yanshuo Wang","Jie Hong","Ali Cheraghian","Shafin Rahman","David Ahmedt-Aristizabal","Lars Petersson","Mehrtash Harandi"],"pdf_url":"https://arxiv.org/pdf/2310.03335v2.pdf","comment":"2024 IEEE/CVF Winter Conference on Applications of Computer Vision"},{"id":"http://arxiv.org/abs/2304.02970v4","updated":"2023-11-27T13:11:20Z","published":"2023-04-06T09:54:06Z","title":"A Closer Look at Audio-Visual Segmentation","summary":"  Audio-visual segmentation (AVS) is a complex task that involves accurately\nsegmenting the corresponding sounding object based on audio-visual queries.\nSuccessful audio-visual learning requires two essential components: 1) an\nunbiased dataset with high-quality pixel-level multi-class labels, and 2) a\nmodel capable of effectively linking audio information with its corresponding\nvisual object. However, these two requirements are only partially addressed by\ncurrent methods, with training sets containing biased audio-visual data, and\nmodels that generalise poorly beyond this biased training set. In this work, we\npropose a new strategy to build cost-effective and relatively unbiased\naudio-visual semantic segmentation benchmarks. Our strategy, called Visual\nPost-production (VPO), explores the observation that it is not necessary to\nhave explicit audio-visual pairs extracted from single video sources to build\nsuch benchmarks. We also refine the previously proposed AVSBench to transform\nit into the audio-visual semantic segmentation benchmark AVSBench-Single+.\nFurthermore, this paper introduces a new pixel-wise audio-visual contrastive\nlearning method to enable a better generalisation of the model beyond the\ntraining set. We verify the validity of the VPO strategy by showing that\nstate-of-the-art (SOTA) models trained with datasets built by matching audio\nand visual data from different sources or with datasets containing audio and\nvisual data from the same video source produce almost the same accuracy. Then,\nusing the proposed VPO benchmarks and AVSBench-Single+, we show that our method\nproduces more accurate audio-visual semantic segmentation than SOTA models.\nCode and dataset will be available.\n","authors":["Yuanhong Chen","Yuyuan Liu","Hu Wang","Fengbei Liu","Chong Wang","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2304.02970v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.10594v2","updated":"2023-11-27T13:02:06Z","published":"2023-03-19T07:53:31Z","title":"AdaptGuard: Defending Against Universal Attacks for Model Adaptation","summary":"  Model adaptation aims at solving the domain transfer problem under the\nconstraint of only accessing the pretrained source models. With the increasing\nconsiderations of data privacy and transmission efficiency, this paradigm has\nbeen gaining recent popularity. This paper studies the vulnerability to\nuniversal attacks transferred from the source domain during model adaptation\nalgorithms due to the existence of malicious providers. We explore both\nuniversal adversarial perturbations and backdoor attacks as loopholes on the\nsource side and discover that they still survive in the target models after\nadaptation. To address this issue, we propose a model preprocessing framework,\nnamed AdaptGuard, to improve the security of model adaptation algorithms.\nAdaptGuard avoids direct use of the risky source parameters through knowledge\ndistillation and utilizes the pseudo adversarial samples under adjusted radius\nto enhance the robustness. AdaptGuard is a plug-and-play module that requires\nneither robust pretrained models nor any changes for the following model\nadaptation algorithms. Extensive results on three commonly used datasets and\ntwo popular adaptation methods validate that AdaptGuard can effectively defend\nagainst universal attacks and maintain clean accuracy in the target domain\nsimultaneously. We hope this research will shed light on the safety and\nrobustness of transfer learning. Code is available at\nhttps://github.com/TomSheng21/AdaptGuard.\n","authors":["Lijun Sheng","Jian Liang","Ran He","Zilei Wang","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2303.10594v2.pdf","comment":"ICCV2023"},{"id":"http://arxiv.org/abs/2311.15782v1","updated":"2023-11-27T12:55:39Z","published":"2023-11-27T12:55:39Z","title":"Relationship between Model Compression and Adversarial Robustness: A\n  Review of Current Evidence","summary":"  Increasing the model capacity is a known approach to enhance the adversarial\nrobustness of deep learning networks. On the other hand, various model\ncompression techniques, including pruning and quantization, can reduce the size\nof the network while preserving its accuracy. Several recent studies have\naddressed the relationship between model compression and adversarial\nrobustness, while some experiments have reported contradictory results. This\nwork summarizes available evidence and discusses possible explanations for the\nobserved effects.\n","authors":["Svetlana Pavlitska","Hannes Grolig","J. Marius Zöllner"],"pdf_url":"https://arxiv.org/pdf/2311.15782v1.pdf","comment":"Accepted for publication at SSCI 2023"},{"id":"http://arxiv.org/abs/2311.15776v1","updated":"2023-11-27T12:51:42Z","published":"2023-11-27T12:51:42Z","title":"Stable Segment Anything Model","summary":"  The Segment Anything Model (SAM) achieves remarkable promptable segmentation\ngiven high-quality prompts which, however, often require good skills to\nspecify. To make SAM robust to casual prompts, this paper presents the first\ncomprehensive analysis on SAM's segmentation stability across a diverse\nspectrum of prompt qualities, notably imprecise bounding boxes and insufficient\npoints. Our key finding reveals that given such low-quality prompts, SAM's mask\ndecoder tends to activate image features that are biased towards the background\nor confined to specific object parts. To mitigate this issue, our key idea\nconsists of adjusting the sampling locations of image feature using learnable\ndeformable offsets, while the original SAM model architecture and weights\nremain unchanged. Consequently, our deformable sampling plugin (DSP) enables\nSAM to adaptively shift attention to the prompted target regions in a\ndata-driven manner, facilitated by our effective robust training strategy\n(RTS). During inference, dynamic routing plugin (DRP) is proposed that toggles\nSAM between the deformable and regular grid sampling modes, conditioned on the\ninput prompt quality. Thus, our solution, termed Stable-SAM, is one of its kind\nfocusing on solely adjusting feature sampling locations, which offers several\nadvantages: 1) improved SAM's segmentation stability across a wide range of\nprompt qualities, while 2) retaining SAM's powerful promptable segmentation\nefficiency and generality, with 3) minimal learnable parameters (0.08 M) and\nfast adaptation (by 1 training epoch). Extensive experiments across multiple\ndatasets validate the effectiveness and advantages of our approach,\nunderscoring Stable-SAM as a more robust solution for segmenting anything.\nCodes will be released upon acceptance.\n","authors":["Qi Fan","Xin Tao","Lei Ke","Mingqiao Ye","Yuan Zhang","Pengfei Wan","Zhongyuan Wang","Yu-Wing Tai","Chi-Keung Tang"],"pdf_url":"https://arxiv.org/pdf/2311.15776v1.pdf","comment":"Codes will be released upon acceptance"},{"id":"http://arxiv.org/abs/2305.19599v3","updated":"2023-11-27T12:50:09Z","published":"2023-05-31T06:59:21Z","title":"RealignDiff: Boosting Text-to-Image Diffusion Model with Coarse-to-fine\n  Semantic Re-alignment","summary":"  Recent advances in text-to-image diffusion models have achieved remarkable\nsuccess in generating high-quality, realistic images from textual descriptions.\nHowever, these approaches have faced challenges in precisely aligning the\ngenerated visual content with the textual concepts described in the prompts. In\nthis paper, we propose a two-stage coarse-to-fine semantic re-alignment method,\nnamed RealignDiff, aimed at improving the alignment between text and images in\ntext-to-image diffusion models. In the coarse semantic re-alignment phase, a\nnovel caption reward, leveraging the BLIP-2 model, is proposed to evaluate the\nsemantic discrepancy between the generated image caption and the given text\nprompt. Subsequently, the fine semantic re-alignment stage employs a local\ndense caption generation module and a re-weighting attention modulation module\nto refine the previously generated images from a local semantic view.\nExperimental results on the MS-COCO benchmark demonstrate that the proposed\ntwo-stage coarse-to-fine semantic re-alignment method outperforms other\nbaseline re-alignment techniques by a substantial margin in both visual quality\nand semantic similarity with the input prompt.\n","authors":["Guian Fang","Zutao Jiang","Jianhua Han","Guansong Lu","Hang Xu","Shengcai Liao","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2305.19599v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15773v1","updated":"2023-11-27T12:48:33Z","published":"2023-11-27T12:48:33Z","title":"Check, Locate, Rectify: A Training-Free Layout Calibration System for\n  Text-to-Image Generation","summary":"  Diffusion models have recently achieved remarkable progress in generating\nrealistic images. However, challenges remain in accurately understanding and\nsynthesizing the layout requirements in the textual prompts. To align the\ngenerated image with layout instructions, we present a training-free layout\ncalibration system SimM that intervenes in the generative process on the fly\nduring inference time. Specifically, following a \"check-locate-rectify\"\npipeline, the system first analyses the prompt to generate the target layout\nand compares it with the intermediate outputs to automatically detect errors.\nThen, by moving the located activations and making intra- and inter-map\nadjustments, the rectification process can be performed with negligible\ncomputational overhead. To evaluate SimM over a range of layout requirements,\nwe present a benchmark SimMBench that compensates for the lack of superlative\nspatial relations in existing datasets. And both quantitative and qualitative\nresults demonstrate the effectiveness of the proposed SimM in calibrating the\nlayout inconsistencies.\n","authors":["Biao Gong","Siteng Huang","Yutong Feng","Shiwei Zhang","Yuyuan Li","Yu Liu"],"pdf_url":"https://arxiv.org/pdf/2311.15773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14456v4","updated":"2023-11-27T12:45:22Z","published":"2022-11-26T02:15:35Z","title":"TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud Analysis","summary":"  In many practical applications, 3D point cloud analysis requires rotation\ninvariance. In this paper, we present a learnable descriptor invariant under 3D\nrotations and reflections, i.e., the O(3) actions, utilizing the recently\nintroduced steerable 3D spherical neurons and vector neurons. Specifically, we\npropose an embedding of the 3D spherical neurons into 4D vector neurons, which\nleverages end-to-end training of the model. In our approach, we perform\nTetraTransform--an equivariant embedding of the 3D input into 4D, constructed\nfrom the steerable neurons--and extract deeper O(3)-equivariant features using\nvector neurons. This integration of the TetraTransform into the VN-DGCNN\nframework, termed TetraSphere, negligibly increases the number of parameters by\nless than 0.0002%. TetraSphere sets a new state-of-the-art performance\nclassifying randomly rotated real-world object scans of the challenging subsets\nof ScanObjectNN. Additionally, TetraSphere outperforms all equivariant methods\non randomly rotated synthetic data: classifying objects from ModelNet40 and\nsegmenting parts of the ShapeNet shapes. Thus, our results reveal the practical\nvalue of steerable 3D spherical neurons for learning in 3D Euclidean space.\n","authors":["Pavlo Melnyk","Andreas Robinson","Michael Felsberg","Mårten Wadenbäck"],"pdf_url":"https://arxiv.org/pdf/2211.14456v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15769v1","updated":"2023-11-27T12:39:42Z","published":"2023-11-27T12:39:42Z","title":"Side4Video: Spatial-Temporal Side Network for Memory-Efficient\n  Image-to-Video Transfer Learning","summary":"  Large pre-trained vision models achieve impressive success in computer\nvision. However, fully fine-tuning large models for downstream tasks,\nparticularly in video understanding, can be prohibitively computationally\nexpensive. Recent studies turn their focus towards efficient image-to-video\ntransfer learning. Nevertheless, existing efficient fine-tuning methods lack\nattention to training memory usage and exploration of transferring a larger\nmodel to the video domain. In this paper, we present a novel Spatial-Temporal\nSide Network for memory-efficient fine-tuning large image models to video\nunderstanding, named Side4Video. Specifically, we introduce a lightweight\nspatial-temporal side network attached to the frozen vision model, which avoids\nthe backpropagation through the heavy pre-trained model and utilizes\nmulti-level spatial features from the original image model. Extremely\nmemory-efficient architecture enables our method to reduce 75% memory usage\nthan previous adapter-based methods. In this way, we can transfer a huge ViT-E\n(4.4B) for video understanding tasks which is 14x larger than ViT-L (304M). Our\napproach achieves remarkable performance on various video datasets across\nunimodal and cross-modal tasks (i.e., action recognition and text-video\nretrieval), especially in Something-Something V1&V2 (67.3% & 74.6%),\nKinetics-400 (88.6%), MSR-VTT (52.3%), MSVD (56.1%) and VATEX (68.8%). We\nrelease our code at https://github.com/HJYao00/Side4Video.\n","authors":["Huanjin Yao","Wenhao Wu","Zhiheng Li"],"pdf_url":"https://arxiv.org/pdf/2311.15769v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2311.15759v1","updated":"2023-11-27T12:29:20Z","published":"2023-11-27T12:29:20Z","title":"Towards Vision Enhancing LLMs: Empowering Multimodal Knowledge Storage\n  and Sharing in LLMs","summary":"  Recent advancements in multimodal large language models (MLLMs) have achieved\nsignificant multimodal generation capabilities, akin to GPT-4. These models\npredominantly map visual information into language representation space,\nleveraging the vast knowledge and powerful text generation abilities of LLMs to\nproduce multimodal instruction-following responses. We could term this method\nas LLMs for Vision because of its employing LLMs for visual-language\nunderstanding, yet observe that these MLLMs neglect the potential of harnessing\nvisual knowledge to enhance overall capabilities of LLMs, which could be\nregraded as Vision Enhancing LLMs. In this paper, we propose an approach called\nMKS2, aimed at enhancing LLMs through empowering Multimodal Knowledge Storage\nand Sharing in LLMs. Specifically, we introduce the Modular Visual Memory, a\ncomponent integrated into the internal blocks of LLMs, designed to store\nopen-world visual information efficiently. Additionally, we present a soft\nMixtures-of-Multimodal Experts architecture in LLMs to invoke multimodal\nknowledge collaboration during generation. Our comprehensive experiments\ndemonstrate that MKS2 substantially augments the reasoning capabilities of LLMs\nin contexts necessitating physical or commonsense knowledge. It also delivers\ncompetitive results on multimodal benchmarks.\n","authors":["Yunxin Li","Baotian Hu","Wei Wang","Xiaochun Cao","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.15759v1.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2304.02833v2","updated":"2023-11-27T12:10:09Z","published":"2023-04-06T02:45:39Z","title":"DoUnseen: Tuning-Free Class-Adaptive Object Detection of Unseen Objects\n  for Robotic Grasping","summary":"  How can we segment varying numbers of objects where each specific object\nrepresents its own separate class? To make the problem even more realistic, how\ncan we add and delete classes on the fly without retraining or fine-tuning?\nThis is the case of robotic applications where no datasets of the objects exist\nor application that includes thousands of objects (E.g., in logistics) where it\nis impossible to train a single model to learn all of the objects. Most current\nresearch on object segmentation for robotic grasping focuses on class-level\nobject segmentation (E.g., box, cup, bottle), closed sets (specific objects of\na dataset; for example, YCB dataset), or deep learning-based template matching.\nIn this work, we are interested in open sets where the number of classes is\nunknown, varying, and without pre-knowledge about the objects' types. We\nconsider each specific object as its own separate class. Our goal is to develop\nan object detector that requires no fine-tuning and can add any object as a\nclass just by capturing a few images of the object. Our main idea is to break\nthe segmentation pipelines into two steps by combining unseen object\nsegmentation networks cascaded by class-adaptive classifiers. We evaluate our\nclass-adaptive object detector on unseen datasets and compare it to a trained\nMask R-CNN on those datasets. The results show that the performance varies from\npractical to unsuitable depending on the environment setup and the objects\nbeing handled. The code is available in our DoUnseen library repository.\n","authors":["Anas Gouda","Moritz Roidl"],"pdf_url":"https://arxiv.org/pdf/2304.02833v2.pdf","comment":"presented at RSS 2023 Workshop on Perception and Manipulation\n  Challenges for Warehouse Automation"},{"id":"http://arxiv.org/abs/2311.15751v1","updated":"2023-11-27T12:08:46Z","published":"2023-11-27T12:08:46Z","title":"PyNanospacing: TEM image processing tool for strain analysis and\n  visualization","summary":"  The diverse spectrum of material characteristics including band gap,\nmechanical moduli, color, phonon and electronic density of states, along with\ncatalytic and surface properties are intricately intertwined with the atomic\nstructure and the corresponding interatomic bond-lengths. This interconnection\nextends to the manifestation of interplanar spacings within a crystalline\nlattice. Analysis of these interplanar spacings and the comprehension of any\ndeviations, whether it be lattice compression or expansion, commonly referred\nto as strain, hold paramount significance in unraveling various unknowns within\nthe field. Transmission Electron Microscopy (TEM) is widely used to capture\natomic-scale ordering, facilitating direct investigation of interplanar\nspacings. However, creating critical contour maps for visualizing and\ninterpreting lattice stresses in TEM images remains a challenging task. Here we\ndeveloped a Python code for TEM image processing that can handle a wide range\nof materials including nanoparticles, 2D materials, pure crystals and solid\nsolutions. This algorithm converts local differences in interplanar spacings\ninto contour maps allowing for a visual representation of lattice expansion and\ncompression. The tool is very generic and can significantly aid in analyzing\nmaterial properties using TEM images, allowing for a more in-depth exploration\nof the underlying science behind strain engineering via strain contour maps at\nthe atomic level.\n","authors":["Mehmet Ali Sarsil","Mubashir Mansoor","Mert Saracoglu","Servet Timur","Mustafa Urgen","Onur Ergen"],"pdf_url":"https://arxiv.org/pdf/2311.15751v1.pdf","comment":"Preprint, 13 pages, 9 figures"},{"id":"http://arxiv.org/abs/2311.15744v1","updated":"2023-11-27T12:02:42Z","published":"2023-11-27T12:02:42Z","title":"One More Step: A Versatile Plug-and-Play Module for Rectifying Diffusion\n  Schedule Flaws and Enhancing Low-Frequency Controls","summary":"  It is well known that many open-released foundational diffusion models have\ndifficulty in generating images that substantially depart from average\nbrightness, despite such images being present in the training data. This is due\nto an inconsistency: while denoising starts from pure Gaussian noise during\ninference, the training noise schedule retains residual data even in the final\ntimestep distribution, due to difficulties in numerical conditioning in\nmainstream formulation, leading to unintended bias during inference. To\nmitigate this issue, certain $\\epsilon$-prediction models are combined with an\nad-hoc offset-noise methodology. In parallel, some contemporary models have\nadopted zero-terminal SNR noise schedules together with\n$\\mathbf{v}$-prediction, which necessitate major alterations to pre-trained\nmodels. However, such changes risk destabilizing a large multitude of\ncommunity-driven applications anchored on these pre-trained models. In light of\nthis, our investigation revisits the fundamental causes, leading to our\nproposal of an innovative and principled remedy, called One More Step (OMS). By\nintegrating a compact network and incorporating an additional simple yet\neffective step during inference, OMS elevates image fidelity and harmonizes the\ndichotomy between training and inference, while preserving original model\nparameters. Once trained, various pre-trained diffusion models with the same\nlatent domain can share the same OMS module.\n","authors":["Minghui Hu","Jianbin Zheng","Chuanxia Zheng","Chaoyue Wang","Dacheng Tao","Tat-Jen Cham"],"pdf_url":"https://arxiv.org/pdf/2311.15744v1.pdf","comment":"Project Page: https://jabir-zheng.github.io/OneMoreStep/, Demo Page:\n  https://huggingface.co/spaces/h1t/oms_sdxl_lcm"},{"id":"http://arxiv.org/abs/2311.15741v1","updated":"2023-11-27T11:46:30Z","published":"2023-11-27T11:46:30Z","title":"Machine Learning-Based Jamun Leaf Disease Detection: A Comprehensive\n  Review","summary":"  Jamun leaf diseases pose a significant threat to agricultural productivity,\nnegatively impacting both yield and quality in the jamun industry. The advent\nof machine learning has opened up new avenues for tackling these diseases\neffectively. Early detection and diagnosis are essential for successful crop\nmanagement. While no automated systems have yet been developed specifically for\njamun leaf disease detection, various automated systems have been implemented\nfor similar types of disease detection using image processing techniques. This\npaper presents a comprehensive review of machine learning methodologies\nemployed for diagnosing plant leaf diseases through image classification, which\ncan be adapted for jamun leaf disease detection. It meticulously assesses the\nstrengths and limitations of various Vision Transformer models, including\nTransfer learning model and vision transformer (TLMViT), SLViT, SE-ViT,\nIterationViT, Tiny-LeViT, IEM-ViT, GreenViT, and PMViT. Additionally, the paper\nreviews models such as Dense Convolutional Network (DenseNet), Residual Neural\nNetwork (ResNet)-50V2, EfficientNet, Ensemble model, Convolutional Neural\nNetwork (CNN), and Locally Reversible Transformer. These machine-learning\nmodels have been evaluated on various datasets, demonstrating their real-world\napplicability. This review not only sheds light on current advancements in the\nfield but also provides valuable insights for future research directions in\nmachine learning-based jamun leaf disease detection and classification.\n","authors":["Auvick Chandra Bhowmik","Dr. Md. Taimur Ahad","Yousuf Rayhan Emon"],"pdf_url":"https://arxiv.org/pdf/2311.15741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15740v1","updated":"2023-11-27T11:44:46Z","published":"2023-11-27T11:44:46Z","title":"Optimization of Image Processing Algorithms for Character Recognition in\n  Cultural Typewritten Documents","summary":"  Linked Data is used in various fields as a new way of structuring and\nconnecting data. Cultural heritage institutions have been using linked data to\nimprove archival descriptions and facilitate the discovery of information. Most\narchival records have digital representations of physical artifacts in the form\nof scanned images that are non-machine-readable. Optical Character Recognition\n(OCR) recognizes text in images and translates it into machine-encoded text.\nThis paper evaluates the impact of image processing methods and parameter\ntuning in OCR applied to typewritten cultural heritage documents. The approach\nuses a multi-objective problem formulation to minimize Levenshtein edit\ndistance and maximize the number of words correctly identified with a\nnon-dominated sorting genetic algorithm (NSGA-II) to tune the methods'\nparameters. Evaluation results show that parameterization by digital\nrepresentation typology benefits the performance of image pre-processing\nalgorithms in OCR. Furthermore, our findings suggest that employing image\npre-processing algorithms in OCR might be more suitable for typologies where\nthe text recognition task without pre-processing does not produce good results.\nIn particular, Adaptive Thresholding, Bilateral Filter, and Opening are the\nbest-performing algorithms for the theatre plays' covers, letters, and overall\ndataset, respectively, and should be applied before OCR to improve its\nperformance.\n","authors":["Mariana Dias","Carla Teixeira Lopes"],"pdf_url":"https://arxiv.org/pdf/2311.15740v1.pdf","comment":"25 pages, 4 figures"},{"id":"http://arxiv.org/abs/2307.03017v3","updated":"2023-11-27T11:38:39Z","published":"2023-07-06T14:31:01Z","title":"RealLiFe: Real-Time Light Field Reconstruction via Hierarchical Sparse\n  Gradient Descent","summary":"  With the rise of Extended Reality (XR) technology, there is a growing need\nfor real-time light field generation from sparse view inputs. Existing methods\ncan be classified into offline techniques, which can generate high-quality\nnovel views but at the cost of long inference/training time, and online\nmethods, which either lack generalizability or produce unsatisfactory results.\nHowever, we have observed that the intrinsic sparse manifold of Multi-plane\nImages (MPI) enables a significant acceleration of light field generation while\nmaintaining rendering quality. Based on this insight, we introduce EffLiFe, a\nnovel light field optimization method, which leverages the proposed\nHierarchical Sparse Gradient Descent (HSGD) to produce high-quality light\nfields from sparse view images in real time. Technically, the coarse MPI of a\nscene is first generated using a 3D CNN, and it is further sparsely optimized\nby focusing only on important MPI gradients in a few iterations. Nevertheless,\nrelying solely on optimization can lead to artifacts at occlusion boundaries.\nTherefore, we propose an occlusion-aware iterative refinement module that\nremoves visual artifacts in occluded regions by iteratively filtering the\ninput. Extensive experiments demonstrate that our method achieves comparable\nvisual quality while being 100x faster on average than state-of-the-art offline\nmethods and delivering better performance (about 2 dB higher in PSNR) compared\nto other online approaches.\n","authors":["Yijie Deng","Lei Han","Tianpeng Lin","Lin Li","Jinzhi Zhang","Lu Fang"],"pdf_url":"https://arxiv.org/pdf/2307.03017v3.pdf","comment":"Submitted to IEEE TPAMI"},{"id":"http://arxiv.org/abs/2311.15732v1","updated":"2023-11-27T11:29:10Z","published":"2023-11-27T11:29:10Z","title":"GPT4Vis: What Can GPT-4 Do for Zero-shot Visual Recognition?","summary":"  This paper does not present a novel method. Instead, it delves into an\nessential, yet must-know baseline in light of the latest advancements in\nGenerative Artificial Intelligence (GenAI): the utilization of GPT-4 for visual\nunderstanding. Our study centers on the evaluation of GPT-4's linguistic and\nvisual capabilities in zero-shot visual recognition tasks. Specifically, we\nexplore the potential of its generated rich textual descriptions across various\ncategories to enhance recognition performance without any training.\nAdditionally, we evaluate its visual proficiency in directly recognizing\ndiverse visual content. To achieve this, we conduct an extensive series of\nexperiments, systematically quantifying the performance of GPT-4 across three\nmodalities: images, videos, and point clouds. This comprehensive evaluation\nencompasses a total of 16 widely recognized benchmark datasets, providing top-1\nand top-5 accuracy metrics. Our study reveals that leveraging GPT-4's advanced\nlinguistic knowledge to generate rich descriptions markedly improves zero-shot\nrecognition. In terms of visual proficiency, GPT-4V's average performance\nacross 16 datasets sits roughly between the capabilities of OpenAI-CLIP's ViT-L\nand EVA-CLIP's ViT-E. We hope that this research will contribute valuable data\npoints and experience for future studies. We release our code at\nhttps://github.com/whwu95/GPT4Vis.\n","authors":["Wenhao Wu","Huanjin Yao","Mengxi Zhang","Yuxin Song","Wanli Ouyang","Jingdong Wang"],"pdf_url":"https://arxiv.org/pdf/2311.15732v1.pdf","comment":"Technical report. Work in progress"},{"id":"http://arxiv.org/abs/2311.15728v1","updated":"2023-11-27T11:26:41Z","published":"2023-11-27T11:26:41Z","title":"Adinkra Symbol Recognition using Classical Machine Learning and Deep\n  Learning","summary":"  Artificial intelligence (AI) has emerged as a transformative influence,\nengendering paradigm shifts in global societies, spanning academia and\nindustry. However, in light of these rapid advances, addressing the\nunderrepresentation of black communities and African countries in AI is\ncrucial. Boosting enthusiasm for AI can be effectively accomplished by\nshowcasing straightforward applications around tasks like identifying and\ncategorizing traditional symbols, such as Adinkra symbols, or familiar objects\nwithin the community. In this research endeavor, we dived into classical\nmachine learning and harnessed the power of deep learning models to tackle the\nintricate task of classifying and recognizing Adinkra symbols. The idea led to\na newly constructed ADINKRA dataset comprising 174,338 images meticulously\norganized into 62 distinct classes, each representing a singular and emblematic\nsymbol. We constructed a CNN model for classification and recognition using six\nconvolutional layers, three fully connected (FC) layers, and optional dropout\nregularization. The model is a simpler and smaller version of VGG, with fewer\nlayers, smaller channel sizes, and a fixed kernel size. Additionally, we tap\ninto the transfer learning capabilities provided by pre-trained models like VGG\nand ResNet. These models assist us in both classifying images and extracting\nfeatures that can be used with classical machine learning models. We assess the\nmodel's performance by measuring its accuracy and convergence rate and\nvisualizing the areas that significantly influence its predictions. These\nevaluations serve as a foundational benchmark for future assessments of the\nADINKRA dataset. We hope this application exemplar inspires ideas on the\nvarious uses of AI in organizing our traditional and modern lives.\n","authors":["Michael Adjeisah","Kwame Omono Asamoah","Martha Asamoah Yeboah","Raji Rafiu King","Godwin Ferguson Achaab","Kingsley Adjei"],"pdf_url":"https://arxiv.org/pdf/2311.15728v1.pdf","comment":"15 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2311.15727v1","updated":"2023-11-27T11:24:25Z","published":"2023-11-27T11:24:25Z","title":"MARIS: Referring Image Segmentation via Mutual-Aware Attention Features","summary":"  Referring image segmentation (RIS) aims to segment a particular region based\non a language expression prompt. Existing methods incorporate linguistic\nfeatures into visual features and obtain multi-modal features for mask\ndecoding. However, these methods may segment the visually salient entity\ninstead of the correct referring region, as the multi-modal features are\ndominated by the abundant visual context. In this paper, we propose MARIS, a\nreferring image segmentation method that leverages the Segment Anything Model\n(SAM) and introduces a mutual-aware attention mechanism to enhance the\ncross-modal fusion via two parallel branches. Specifically, our mutual-aware\nattention mechanism consists of Vision-Guided Attention and Language-Guided\nAttention, which bidirectionally model the relationship between visual and\nlinguistic features. Correspondingly, we design a Mask Decoder to enable\nexplicit linguistic guidance for more consistent segmentation with the language\nexpression. To this end, a multi-modal query token is proposed to integrate\nlinguistic information and interact with visual information simultaneously.\nExtensive experiments on three benchmark datasets show that our method\noutperforms the state-of-the-art RIS methods. Our code will be publicly\navailable.\n","authors":["Mengxi Zhang","Yiming Liu","Xiangjun Yin","Huanjing Yue","Jingyu Yang"],"pdf_url":"https://arxiv.org/pdf/2311.15727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15722v1","updated":"2023-11-27T11:17:20Z","published":"2023-11-27T11:17:20Z","title":"GLIME: General, Stable and Local LIME Explanation","summary":"  As black-box machine learning models grow in complexity and find applications\nin high-stakes scenarios, it is imperative to provide explanations for their\npredictions. Although Local Interpretable Model-agnostic Explanations (LIME)\n[22] is a widely adpoted method for understanding model behaviors, it is\nunstable with respect to random seeds [35,24,3] and exhibits low local fidelity\n(i.e., how well the explanation approximates the model's local behaviors)\n[21,16]. Our study shows that this instability problem stems from small sample\nweights, leading to the dominance of regularization and slow convergence.\nAdditionally, LIME's sampling neighborhood is non-local and biased towards the\nreference, resulting in poor local fidelity and sensitivity to reference\nchoice. To tackle these challenges, we introduce GLIME, an enhanced framework\nextending LIME and unifying several prior methods. Within the GLIME framework,\nwe derive an equivalent formulation of LIME that achieves significantly faster\nconvergence and improved stability. By employing a local and unbiased sampling\ndistribution, GLIME generates explanations with higher local fidelity compared\nto LIME. GLIME explanations are independent of reference choice. Moreover,\nGLIME offers users the flexibility to choose a sampling distribution based on\ntheir specific scenarios.\n","authors":["Zeren Tan","Yang Tian","Jian Li"],"pdf_url":"https://arxiv.org/pdf/2311.15722v1.pdf","comment":"Accepted by NeurIPS 2023 as a Spotlight paper"},{"id":"http://arxiv.org/abs/2311.15719v1","updated":"2023-11-27T11:12:33Z","published":"2023-11-27T11:12:33Z","title":"Variational Autoencoders for Feature Exploration and Malignancy\n  Prediction of Lung Lesions","summary":"  Lung cancer is responsible for 21% of cancer deaths in the UK and five-year\nsurvival rates are heavily influenced by the stage the cancer was identified\nat. Recent studies have demonstrated the capability of AI methods for accurate\nand early diagnosis of lung cancer from routine scans. However, this evidence\nhas not translated into clinical practice with one barrier being a lack of\ninterpretable models. This study investigates the application Variational\nAutoencoders (VAEs), a type of generative AI model, to lung cancer lesions.\nProposed models were trained on lesions extracted from 3D CT scans in the\nLIDC-IDRI public dataset. Latent vector representations of 2D slices produced\nby the VAEs were explored through clustering to justify their quality and used\nin an MLP classifier model for lung cancer diagnosis, the best model achieved\nstate-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows\nthe VAE latent space separates the dataset of malignant and benign lesions\nbased on meaningful feature components including tumour size, shape, patient\nand malignancy class. We also include a comparative analysis of the standard\nGaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces\nthe prior with a Dirichlet distribution to encourage a more explainable latent\nspace with disentangled feature representation. Finally, we demonstrate the\npotential for latent space traversals corresponding to clinically meaningful\nfeature changes.\n","authors":["Benjamin Keel","Aaron Quyn","David Jayne","Samuel D. Relton"],"pdf_url":"https://arxiv.org/pdf/2311.15719v1.pdf","comment":"10 pages (main paper), 5 pages (references), 5 figures, 2 tables,\n  work accepted for BMVC 2023"},{"id":"http://arxiv.org/abs/2309.12303v3","updated":"2023-11-27T11:04:07Z","published":"2023-09-21T17:59:02Z","title":"PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for\n  Video Segmentation","summary":"  Panoramic videos contain richer spatial information and have attracted\ntremendous amounts of attention due to their exceptional experience in some\nfields such as autonomous driving and virtual reality. However, existing\ndatasets for video segmentation only focus on conventional planar images. To\naddress the challenge, in this paper, we present a panoramic video dataset,\nPanoVOS. The dataset provides 150 videos with high video resolutions and\ndiverse motions. To quantify the domain gap between 2D planar videos and\npanoramic videos, we evaluate 15 off-the-shelf video object segmentation (VOS)\nmodels on PanoVOS. Through error analysis, we found that all of them fail to\ntackle pixel-level content discontinues of panoramic videos. Thus, we present a\nPanoramic Space Consistency Transformer (PSCFormer), which can effectively\nutilize the semantic boundary information of the previous frame for pixel-level\nmatching with the current frame. Extensive experiments demonstrate that\ncompared with the previous SOTA models, our PSCFormer network exhibits a great\nadvantage in terms of segmentation results under the panoramic setting. Our\ndataset poses new challenges in panoramic VOS and we hope that our PanoVOS can\nadvance the development of panoramic segmentation/tracking.\n","authors":["Shilin Yan","Xiaohao Xu","Renrui Zhang","Lingyi Hong","Wenchao Chen","Wenqiang Zhang","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2309.12303v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15707v1","updated":"2023-11-27T10:50:47Z","published":"2023-11-27T10:50:47Z","title":"SAM-6D: Segment Anything Model Meets Zero-Shot 6D Object Pose Estimation","summary":"  Zero-shot 6D object pose estimation involves the detection of novel objects\nwith their 6D poses in cluttered scenes, presenting significant challenges for\nmodel generalizability. Fortunately, the recent Segment Anything Model (SAM)\nhas showcased remarkable zero-shot transfer performance, which provides a\npromising solution to tackle this task. Motivated by this, we introduce SAM-6D,\na novel framework designed to realize the task through two steps, including\ninstance segmentation and pose estimation. Given the target objects, SAM-6D\nemploys two dedicated sub-networks, namely Instance Segmentation Model (ISM)\nand Pose Estimation Model (PEM), to perform these steps on cluttered RGB-D\nimages. ISM takes SAM as an advanced starting point to generate all possible\nobject proposals and selectively preserves valid ones through meticulously\ncrafted object matching scores in terms of semantics, appearance and geometry.\nBy treating pose estimation as a partial-to-partial point matching problem, PEM\nperforms a two-stage point matching process featuring a novel design of\nbackground tokens to construct dense 3D-3D correspondence, ultimately yielding\nthe pose estimates. Without bells and whistles, SAM-6D outperforms the existing\nmethods on the seven core datasets of the BOP Benchmark for both instance\nsegmentation and pose estimation of novel objects.\n","authors":["Jiehong Lin","Lihua Liu","Dekun Lu","Kui Jia"],"pdf_url":"https://arxiv.org/pdf/2311.15707v1.pdf","comment":"Github Page: https://github.com/JiehongLin/SAM-6D"},{"id":"http://arxiv.org/abs/2311.13372v2","updated":"2023-11-27T10:42:46Z","published":"2023-11-22T13:13:19Z","title":"MRGazer: Decoding Eye Gaze Points from Functional Magnetic Resonance\n  Imaging in Individual Space","summary":"  Eye-tracking research has proven valuable in understanding numerous cognitive\nfunctions. Recently, Frey et al. provided an exciting deep learning method for\nlearning eye movements from fMRI data. However, it needed to co-register fMRI\ninto standard space to obtain eyeballs masks, and thus required additional\ntemplates and was time consuming. To resolve this issue, in this paper, we\npropose a framework named MRGazer for predicting eye gaze points from fMRI in\nindividual space. The MRGazer consisted of eyeballs extraction module and a\nresidual network-based eye gaze prediction. Compared to the previous method,\nthe proposed framework skips the fMRI co-registration step, simplifies the\nprocessing protocol and achieves end-to-end eye gaze regression. The proposed\nmethod achieved superior performance in a variety of eye movement tasks than\nthe co-registration-based method, and delivered objective results within a\nshorter time (~ 0.02 Seconds for each volume) than prior method (~0.3 Seconds\nfor each volume).\n","authors":["Xiuwen Wu","Rongjie Hu","Jie Liang","Yanming Wang","Bensheng Qiu","Xiaoxiao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13372v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01825v2","updated":"2023-11-27T10:39:13Z","published":"2023-10-03T06:42:28Z","title":"Empirical Study of PEFT techniques for Winter Wheat Segmentation","summary":"  Parameter Efficient Fine Tuning (PEFT) techniques have recently experienced\nsignificant growth and have been extensively employed to adapt large vision and\nlanguage models to various domains, enabling satisfactory model performance\nwith minimal computational needs. Despite these advances, more research has yet\nto delve into potential PEFT applications in real-life scenarios, particularly\nin the critical domains of remote sensing and crop monitoring. The diversity of\nclimates across different regions and the need for comprehensive large-scale\ndatasets have posed significant obstacles to accurately identify crop types\nacross varying geographic locations and changing growing seasons. This study\nseeks to bridge this gap by comprehensively exploring the feasibility of\ncross-area and cross-year out-of-distribution generalization using the\nState-of-the-Art (SOTA) wheat crop monitoring model. The aim of this work is to\nexplore PEFT approaches for crop monitoring. Specifically, we focus on adapting\nthe SOTA TSViT model to address winter wheat field segmentation, a critical\ntask for crop monitoring and food security. This adaptation process involves\nintegrating different PEFT techniques, including BigFit, LoRA, Adaptformer, and\nprompt tuning. Using PEFT techniques, we achieved notable results comparable to\nthose achieved using full fine-tuning methods while training only a mere 0.7%\nparameters of the whole TSViT architecture. The in-house labeled data-set,\nreferred to as the Beqaa-Lebanon dataset, comprises high-quality annotated\npolygons for wheat and non-wheat classes with a total surface of 170 kmsq, over\nfive consecutive years. Using Sentinel-2 images, our model achieved a 84%\nF1-score. We intend to publicly release the Lebanese winter wheat data set,\ncode repository, and model weights.\n","authors":["Mohamad Hasan Zahweh","Hasan Nasrallah","Mustafa Shukor","Ghaleb Faour","Ali J. Ghandour"],"pdf_url":"https://arxiv.org/pdf/2310.01825v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.06226v2","updated":"2023-11-27T10:31:09Z","published":"2023-03-10T22:21:30Z","title":"NeRFlame: FLAME-based conditioning of NeRF for 3D face rendering","summary":"  Traditional 3D face models are based on mesh representations with texture.\nOne of the most important models is FLAME (Faces Learned with an Articulated\nModel and Expressions), which produces meshes of human faces that are fully\ncontrollable. Unfortunately, such models have problems with capturing geometric\nand appearance details. In contrast to mesh representation, the neural radiance\nfield (NeRF) produces extremely sharp renders. However, implicit methods are\nhard to animate and do not generalize well to unseen expressions. It is not\ntrivial to effectively control NeRF models to obtain face manipulation.\n  The present paper proposes a novel approach, named NeRFlame, which combines\nthe strengths of both NeRF and FLAME methods. Our method enables high-quality\nrendering capabilities of NeRF while also offering complete control over the\nvisual appearance, similar to FLAME. In contrast to traditional NeRF-based\nstructures that use neural networks for RGB color and volume density modeling,\nour approach utilizes the FLAME mesh as a distinct density volume.\nConsequently, color values exist only in the vicinity of the FLAME mesh. This\nFLAME framework is seamlessly incorporated into the NeRF architecture for\npredicting RGB colors, enabling our model to explicitly represent volume\ndensity and implicitly capture RGB colors.\n","authors":["Wojciech Zając","Joanna Waczyńska","Piotr Borycki","Jacek Tabor","Maciej Zięba","Przemysław Spurek"],"pdf_url":"https://arxiv.org/pdf/2303.06226v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15679v1","updated":"2023-11-27T10:10:25Z","published":"2023-11-27T10:10:25Z","title":"Model-agnostic Body Part Relevance Assessment for Pedestrian Detection","summary":"  Model-agnostic explanation methods for deep learning models are flexible\nregarding usability and availability. However, due to the fact that they can\nonly manipulate input to see changes in output, they suffer from weak\nperformance when used with complex model architectures. For models with large\ninputs as, for instance, in object detection, sampling-based methods like\nKernelSHAP are inefficient due to many computation-heavy forward passes through\nthe model. In this work, we present a framework for using sampling-based\nexplanation models in a computer vision context by body part relevance\nassessment for pedestrian detection. Furthermore, we introduce a novel\nsampling-based method similar to KernelSHAP that shows more robustness for\nlower sampling sizes and, thus, is more efficient for explainability analyses\non large-scale datasets.\n","authors":["Maurice Günder","Sneha Banerjee","Rafet Sifa","Christian Bauckhage"],"pdf_url":"https://arxiv.org/pdf/2311.15679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15672v1","updated":"2023-11-27T10:01:31Z","published":"2023-11-27T10:01:31Z","title":"HAVE-FUN: Human Avatar Reconstruction from Few-Shot Unconstrained Images","summary":"  As for human avatar reconstruction, contemporary techniques commonly\nnecessitate the acquisition of costly data and struggle to achieve satisfactory\nresults from a small number of casual images. In this paper, we investigate\nthis task from a few-shot unconstrained photo album. The reconstruction of\nhuman avatars from such data sources is challenging because of limited data\namount and dynamic articulated poses. For handling dynamic data, we integrate a\nskinning mechanism with deep marching tetrahedra (DMTet) to form a drivable\ntetrahedral representation, which drives arbitrary mesh topologies generated by\nthe DMTet for the adaptation of unconstrained images. To effectively mine\ninstructive information from few-shot data, we devise a two-phase optimization\nmethod with few-shot reference and few-shot guidance. The former focuses on\naligning avatar identity with reference images, while the latter aims to\ngenerate plausible appearances for unseen regions. Overall, our framework,\ncalled HaveFun, can undertake avatar reconstruction, rendering, and animation.\nExtensive experiments on our developed benchmarks demonstrate that HaveFun\nexhibits substantially superior performance in reconstructing the human body\nand hand. Project website: https://seanchenxy.github.io/HaveFunWeb/.\n","authors":["Xihe Yang","Xingyu Chen","Shaohui Wang","Daiheng Gao","Xiaoguang Han","Baoyuan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.15672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15668v1","updated":"2023-11-27T09:55:55Z","published":"2023-11-27T09:55:55Z","title":"Deformation-Guided Unsupervised Non-Rigid Shape Matching","summary":"  We present an unsupervised data-driven approach for non-rigid shape matching.\nShape matching identifies correspondences between two shapes and is a\nfundamental step in many computer vision and graphics applications. Our\napproach is designed to be particularly robust when matching shapes digitized\nusing 3D scanners that contain fine geometric detail and suffer from different\ntypes of noise including topological noise caused by the coalescence of\nspatially close surface regions. We build on two strategies. First, using a\nhierarchical patch based shape representation we match shapes consistently in a\ncoarse to fine manner, allowing for robustness to noise. This multi-scale\nrepresentation drastically reduces the dimensionality of the problem when\nmatching at the coarsest scale, rendering unsupervised learning feasible.\nSecond, we constrain this hierarchical matching to be reflected in 3D by\nfitting a patch-wise near-rigid deformation model. Using this constraint, we\nleverage spatial continuity at different scales to capture global shape\nproperties, resulting in matchings that generalize well to data with different\ndeformations and noise characteristics. Experiments demonstrate that our\napproach obtains significantly better results on raw 3D scans than\nstate-of-the-art methods, while performing on-par on standard test scenarios.\n","authors":["Aymen Merrouche","Joao Regateiro","Stefanie Wuhrer","Edmond Boyer"],"pdf_url":"https://arxiv.org/pdf/2311.15668v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15660v1","updated":"2023-11-27T09:40:53Z","published":"2023-11-27T09:40:53Z","title":"Technical Report for Argoverse Challenges on 4D Occupancy Forecasting","summary":"  This report presents our Le3DE2E_Occ solution for 4D Occupancy Forecasting in\nArgoverse Challenges at CVPR 2023 Workshop on Autonomous Driving (WAD). Our\nsolution consists of a strong LiDAR-based Bird's Eye View (BEV) encoder with\ntemporal fusion and a two-stage decoder, which combines a DETR head and a UNet\ndecoder. The solution was tested on the Argoverse 2 sensor dataset to evaluate\nthe occupancy state 3 seconds in the future. Our solution achieved 18% lower L1\nError (3.57) than the baseline and got the 1 place on the 4D Occupancy\nForecasting task in Argoverse Challenges at CVPR 2023.\n","authors":["Pengfei Zheng","Kanokphan Lertniphonphan","Feng Chen","Siwei Chen","Bingchuan Sun","Jun Xie","Zhepeng Wang"],"pdf_url":"https://arxiv.org/pdf/2311.15660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15658v1","updated":"2023-11-27T09:40:14Z","published":"2023-11-27T09:40:14Z","title":"Regularization by Texts for Latent Diffusion Inverse Solvers","summary":"  The recent advent of diffusion models has led to significant progress in\nsolving inverse problems, leveraging these models as effective generative\npriors. Nonetheless, challenges related to the ill-posed nature of such\nproblems remain, often due to inherent ambiguities in measurements. Drawing\ninspiration from the human ability to resolve visual ambiguities through\nperceptual biases, here we introduce a novel latent diffusion inverse solver by\nincorporating regularization by texts (TReg). Specifically, TReg applies the\ntextual description of the preconception of the solution during the reverse\nsampling phase, of which description isndynamically reinforced through\nnull-text optimization for adaptive negation. Our comprehensive experimental\nresults demonstrate that TReg successfully mitigates ambiguity in latent\ndiffusion inverse solvers, enhancing their effectiveness and accuracy.\n","authors":["Jeongsol Kim","Geon Yeong Park","Hyungjin Chung","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2311.15658v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15657v1","updated":"2023-11-27T09:39:45Z","published":"2023-11-27T09:39:45Z","title":"Enhancing Diffusion Models with Text-Encoder Reinforcement Learning","summary":"  Text-to-image diffusion models are typically trained to optimize the\nlog-likelihood objective, which presents challenges in meeting specific\nrequirements for downstream tasks, such as image aesthetics and image-text\nalignment. Recent research addresses this issue by refining the diffusion U-Net\nusing human rewards through reinforcement learning or direct backpropagation.\nHowever, many of them overlook the importance of the text encoder, which is\ntypically pretrained and fixed during training. In this paper, we demonstrate\nthat by finetuning the text encoder through reinforcement learning, we can\nenhance the text-image alignment of the results, thereby improving the visual\nquality. Our primary motivation comes from the observation that the current\ntext encoder is suboptimal, often requiring careful prompt adjustment. While\nfine-tuning the U-Net can partially improve performance, it remains suffering\nfrom the suboptimal text encoder. Therefore, we propose to use reinforcement\nlearning with low-rank adaptation to finetune the text encoder based on\ntask-specific rewards, referred as \\textbf{TexForce}. We first show that\nfinetuning the text encoder can improve the performance of diffusion models.\nThen, we illustrate that TexForce can be simply combined with existing U-Net\nfinetuned models to get much better results without additional training.\nFinally, we showcase the adaptability of our method in diverse applications,\nincluding the generation of high-quality face and hand images.\n","authors":["Chaofeng Chen","Annan Wang","Haoning Wu","Liang Liao","Wenxiu Sun","Qiong Yan","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2311.15657v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15648v1","updated":"2023-11-27T09:20:12Z","published":"2023-11-27T09:20:12Z","title":"Reinforcement Learning from Diffusion Feedback: Q* for Image Search","summary":"  Large vision-language models are steadily gaining personalization\ncapabilities at the cost of fine-tuning or data augmentation. We present two\nmodels for image generation using model-agnostic learning that align semantic\npriors with generative capabilities. RLDF, or Reinforcement Learning from\nDiffusion Feedback, is a singular approach for visual imitation through\nprior-preserving reward function guidance. This employs Q-learning (with\nstandard Q*) for generation and follows a semantic-rewarded trajectory for\nimage search through finite encoding-tailored actions. The second proposed\nmethod, noisy diffusion gradient, is optimization driven. At the root of both\nmethods is a special CFG encoding that we propose for continual semantic\nguidance. Using only a single input image and no text input, RLDF generates\nhigh-quality images over varied domains including retail, sports and\nagriculture showcasing class-consistency and strong visual diversity. Project\nwebsite is available at https://infernolia.github.io/RLDF.\n","authors":["Aboli Marathe"],"pdf_url":"https://arxiv.org/pdf/2311.15648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.14969v2","updated":"2023-11-27T09:06:55Z","published":"2023-08-29T01:47:49Z","title":"Uncovering the Hidden Cost of Model Compression","summary":"  In the era of resource-intensive foundation models, efficient adaptation in\ndownstream tasks has become paramount. Visual Prompting (VP), inspired by\nprompting in Large Language Models (LLMs), has emerged as a key transfer\nlearning method in computer vision. Aligned with the growing significance of\nefficiency, research in model compression has become pivotal to alleviate the\ncomputational burden in both training and deploying over-parameterized neural\nnetworks. A key goal in model compression is the development of sparse models\ncapable of matching or surpassing the performance of their over-parameterized,\ndense counterparts. While prior research has explored the impact of model\nsparsity on transfer learning, its effects on visual prompting-based transfer\nremain unclear. This study addresses this gap, revealing that model sparsity\nadversely affects the performance of visual prompting-based transfer,\nparticularly in low-data-volume scenarios. Furthermore, our findings highlight\nthe negative influence of sparsity on the calibration of downstream\nvisual-prompted models. This empirical exploration calls for a nuanced\nunderstanding beyond accuracy in sparse settings, opening avenues for further\nresearch in Visual Prompting for sparse models. Code and logs can be accessed\nat https://github.com/landskape-ai/Reprogram_LT .\n","authors":["Diganta Misra","Agam Goyal","Bharat Runwal","Pin Yu Chen"],"pdf_url":"https://arxiv.org/pdf/2308.14969v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2311.15637v1","updated":"2023-11-27T09:02:21Z","published":"2023-11-27T09:02:21Z","title":"PaintNeSF: Artistic Creation of Stylized Scenes with Vectorized 3D\n  Strokes","summary":"  We present Paint Neural Stroke Field (PaintNeSF), a novel technique to\ngenerate stylized images of a 3D scene at arbitrary novel views from multi-view\n2D images. Different from existing methods which apply stylization to trained\nneural radiance fields at the voxel level, our approach draws inspiration from\nimage-to-painting methods, simulating the progressive painting process of human\nartwork with vector strokes. We develop a palette of stylized 3D strokes from\nbasic primitives and splines, and consider the 3D scene stylization task as a\nmulti-view reconstruction process based on these 3D stroke primitives. Instead\nof directly searching for the parameters of these 3D strokes, which would be\ntoo costly, we introduce a differentiable renderer that allows optimizing\nstroke parameters using gradient descent, and propose a training scheme to\nalleviate the vanishing gradient issue. The extensive evaluation demonstrates\nthat our approach effectively synthesizes 3D scenes with significant geometric\nand aesthetic stylization while maintaining a consistent appearance across\ndifferent views. Our method can be further integrated with style loss and\nimage-text contrastive models to extend its applications, including color\ntransfer and text-driven 3D scene drawing.\n","authors":["Hao-Bin Duan","Miao Wang","Yan-Xun Li","Yong-Liang Yang"],"pdf_url":"https://arxiv.org/pdf/2311.15637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.00397v2","updated":"2023-11-27T09:02:06Z","published":"2023-11-01T09:46:59Z","title":"Towards Omni-supervised Referring Expression Segmentation","summary":"  Referring Expression Segmentation (RES) is an emerging task in computer\nvision, which segments the target instances in images based on text\ndescriptions. However, its development is plagued by the expensive segmentation\nlabels. To address this issue, we propose a new learning task for RES called\nOmni-supervised Referring Expression Segmentation (Omni-RES), which aims to\nmake full use of unlabeled, fully labeled and weakly labeled data, e.g.,\nreferring points or grounding boxes, for efficient RES training. To accomplish\nthis task, we also propose a novel yet strong baseline method for Omni-RES\nbased on the recently popular teacher-student learning, where the weak labels\nare not directly transformed into supervision signals but used as a yardstick\nto select and refine high-quality pseudo-masks for teacher-student learning. To\nvalidate the proposed Omni-RES method, we apply it to a set of state-of-the-art\nRES models and conduct extensive experiments on a bunch of RES datasets. The\nexperimental results yield the obvious merits of Omni-RES than the\nfully-supervised and semi-supervised training schemes. For instance, with only\n10% fully labeled data, Omni-RES can help the base model achieve 100% fully\nsupervised performance, and it also outperform the semi-supervised alternative\nby a large margin, e.g., +14.93% on RefCOCO and +14.95% on RefCOCO+,\nrespectively. More importantly, Omni-RES also enable the use of large-scale\nvision-langauges like Visual Genome to facilitate low-cost RES training, and\nachieve new SOTA performance of RES, e.g., 80.66 on RefCOCO.\n","authors":["Minglang Huang","Yiyi Zhou","Gen Luo","Guannan Jiang","Weilin Zhuang","Xiaoshuai Sun"],"pdf_url":"https://arxiv.org/pdf/2311.00397v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15625v1","updated":"2023-11-27T08:44:00Z","published":"2023-11-27T08:44:00Z","title":"Only Positive Cases: 5-fold High-order Attention Interaction Model for\n  Skin Segmentation Derived Classification","summary":"  Computer-aided diagnosis of skin diseases is an important tool. However, the\ninterpretability of computer-aided diagnosis is currently poor. Dermatologists\nand patients cannot intuitively understand the learning and prediction process\nof neural networks, which will lead to a decrease in the credibility of\ncomputer-aided diagnosis. In addition, traditional methods need to be trained\nusing negative samples in order to predict the presence or absence of a lesion,\nbut medical data is often in short supply. In this paper, we propose a multiple\nhigh-order attention interaction model (MHA-UNet) for use in a highly\nexplainable skin lesion segmentation task. MHA-UNet is able to obtain the\npresence or absence of a lesion by explainable reasoning without the need for\ntraining on negative samples. Specifically, we propose a high-order attention\ninteraction mechanism that introduces squeeze attention to a higher level for\nfeature attention. In addition, a multiple high-order attention interaction\n(MHAblock) module is proposed by combining the different features of different\norders. For classifying the presence or absence of lesions, we conducted\nclassification experiments on several publicly available datasets in the\nabsence of negative samples, based on explainable reasoning about the\ninteraction of 5 attention orders of MHAblock. The highest positive detection\nrate obtained from the experiments was 81.0% and the highest negative detection\nrate was 83.5%. For segmentation experiments, comparison experiments of the\nproposed method with 13 medical segmentation models and external validation\nexperiments with 8 state-of-the-art models in three public datasets and our\nclinical dataset demonstrate the state-of-the-art performance of our model. The\ncode is available from https://github.com/wurenkai/MHA-UNet.\n","authors":["Renkai Wu","Yinghao Liu","Pengchen Liang","Qing Chang"],"pdf_url":"https://arxiv.org/pdf/2311.15625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08872v5","updated":"2023-11-27T08:42:07Z","published":"2023-10-13T05:48:42Z","title":"R&B: Region and Boundary Aware Zero-shot Grounded Text-to-image\n  Generation","summary":"  Recent text-to-image (T2I) diffusion models have achieved remarkable progress\nin generating high-quality images given text-prompts as input. However, these\nmodels fail to convey appropriate spatial composition specified by a layout\ninstruction. In this work, we probe into zero-shot grounded T2I generation with\ndiffusion models, that is, generating images corresponding to the input layout\ninformation without training auxiliary modules or finetuning diffusion models.\nWe propose a Region and Boundary (R&B) aware cross-attention guidance approach\nthat gradually modulates the attention maps of diffusion model during\ngenerative process, and assists the model to synthesize images (1) with high\nfidelity, (2) highly compatible with textual input, and (3) interpreting layout\ninstructions accurately. Specifically, we leverage the discrete sampling to\nbridge the gap between consecutive attention maps and discrete layout\nconstraints, and design a region-aware loss to refine the generative layout\nduring diffusion process. We further propose a boundary-aware loss to\nstrengthen object discriminability within the corresponding regions.\nExperimental results show that our method outperforms existing state-of-the-art\nzero-shot grounded T2I generation methods by a large margin both qualitatively\nand quantitatively on several benchmarks.\n","authors":["Jiayu Xiao","Henglei Lv","Liang Li","Shuhui Wang","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2310.08872v5.pdf","comment":"Preprint. Under review. Project page:\n  https://sagileo.github.io/Region-and-Boundary"},{"id":"http://arxiv.org/abs/2311.15619v1","updated":"2023-11-27T08:32:28Z","published":"2023-11-27T08:32:28Z","title":"Align before Adapt: Leveraging Entity-to-Region Alignments for\n  Generalizable Video Action Recognition","summary":"  Large-scale visual-language pre-trained models have achieved significant\nsuccess in various video tasks. However, most existing methods follow an \"adapt\nthen align\" paradigm, which adapts pre-trained image encoders to model\nvideo-level representations and utilizes one-hot or text embedding of the\naction labels for supervision. This paradigm overlooks the challenge of mapping\nfrom static images to complicated activity concepts. In this paper, we propose\na novel \"Align before Adapt\" (ALT) paradigm. Prior to adapting to video\nrepresentation learning, we exploit the entity-to-region alignments for each\nframe. The alignments are fulfilled by matching the region-aware image\nembeddings to an offline-constructed text corpus. With the aligned entities, we\nfeed their text embeddings to a transformer-based video adapter as the queries,\nwhich can help extract the semantics of the most important entities from a\nvideo to a vector. This paradigm reuses the visual-language alignment of VLP\nduring adaptation and tries to explain an action by the underlying entities.\nThis helps understand actions by bridging the gap with complex activity\nsemantics, particularly when facing unfamiliar or unseen categories. ALT\nachieves competitive performance and superior generalizability while requiring\nsignificantly low computational costs. In fully supervised scenarios, it\nachieves 88.1% top-1 accuracy on Kinetics-400 with only 4947 GFLOPs. In 2-shot\nexperiments, ALT outperforms the previous state-of-the-art by 7.1% and 9.2% on\nHMDB-51 and UCF-101, respectively.\n","authors":["Yifei Chen","Dapeng Chen","Ruijin Liu","Sai Zhou","Wenyuan Xue","Wei Peng"],"pdf_url":"https://arxiv.org/pdf/2311.15619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12092v2","updated":"2023-11-27T08:29:54Z","published":"2023-11-20T18:59:01Z","title":"Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models","summary":"  We present a method to create interpretable concept sliders that enable\nprecise control over attributes in image generations from diffusion models. Our\napproach identifies a low-rank parameter direction corresponding to one concept\nwhile minimizing interference with other attributes. A slider is created using\na small set of prompts or sample images; thus slider directions can be created\nfor either textual or visual concepts. Concept Sliders are plug-and-play: they\ncan be composed efficiently and continuously modulated, enabling precise\ncontrol over image generation. In quantitative experiments comparing to\nprevious editing techniques, our sliders exhibit stronger targeted edits with\nlower interference. We showcase sliders for weather, age, styles, and\nexpressions, as well as slider compositions. We show how sliders can transfer\nlatents from StyleGAN for intuitive editing of visual concepts for which\ntextual description is difficult. We also find that our method can help address\npersistent quality issues in Stable Diffusion XL including repair of object\ndeformations and fixing distorted hands. Our code, data, and trained sliders\nare available at https://sliders.baulab.info/\n","authors":["Rohit Gandikota","Joanna Materzynska","Tingrui Zhou","Antonio Torralba","David Bau"],"pdf_url":"https://arxiv.org/pdf/2311.12092v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15615v1","updated":"2023-11-27T08:25:23Z","published":"2023-11-27T08:25:23Z","title":"Technical Report for Argoverse Challenges on Unified Sensor-based\n  Detection, Tracking, and Forecasting","summary":"  This report presents our Le3DE2E solution for unified sensor-based detection,\ntracking, and forecasting in Argoverse Challenges at CVPR 2023 Workshop on\nAutonomous Driving (WAD). We propose a unified network that incorporates three\ntasks, including detection, tracking, and forecasting. This solution adopts a\nstrong Bird's Eye View (BEV) encoder with spatial and temporal fusion and\ngenerates unified representations for multi-tasks. The solution was tested in\nthe Argoverse 2 sensor dataset to evaluate the detection, tracking, and\nforecasting of 26 object categories. We achieved 1st place in Detection,\nTracking, and Forecasting on the E2E Forecasting track in Argoverse Challenges\nat CVPR 2023 WAD.\n","authors":["Zhepeng Wang","Feng Chen","Kanokphan Lertniphonphan","Siwei Chen","Jinyao Bao","Pengfei Zheng","Jinbao Zhang","Kaer Huang","Tao Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.15615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.05646v2","updated":"2023-11-27T08:12:14Z","published":"2023-04-12T06:49:56Z","title":"Breaking Modality Disparity: Harmonized Representation for Infrared and\n  Visible Image Registration","summary":"  Since the differences in viewing range, resolution and relative position, the\nmulti-modality sensing module composed of infrared and visible cameras needs to\nbe registered so as to have more accurate scene perception. In practice, manual\ncalibration-based registration is the most widely used process, and it is\nregularly calibrated to maintain accuracy, which is time-consuming and\nlabor-intensive. To cope with these problems, we propose a scene-adaptive\ninfrared and visible image registration. Specifically, in regard of the\ndiscrepancy between multi-modality images, an invertible translation process is\ndeveloped to establish a modality-invariant domain, which comprehensively\nembraces the feature intensity and distribution of both infrared and visible\nmodalities. We employ homography to simulate the deformation between different\nplanes and develop a hierarchical framework to rectify the deformation inferred\nfrom the proposed latent representation in a coarse-to-fine manner. For that,\nthe advanced perception ability coupled with the residual estimation conducive\nto the regression of sparse offsets, and the alternate correlation search\nfacilitates a more accurate correspondence matching. Moreover, we propose the\nfirst ground truth available misaligned infrared and visible image dataset,\ninvolving three synthetic sets and one real-world set. Extensive experiments\nvalidate the effectiveness of the proposed method against the\nstate-of-the-arts, advancing the subsequent applications.\n","authors":["Zhiying Jiang","Zengxi Zhang","Jinyuan Liu","Xin Fan","Risheng Liu"],"pdf_url":"https://arxiv.org/pdf/2304.05646v2.pdf","comment":"10 pages, 11 figures"},{"id":"http://arxiv.org/abs/2311.15609v1","updated":"2023-11-27T08:06:56Z","published":"2023-11-27T08:06:56Z","title":"A manometric feature descriptor with linear-SVM to distinguish\n  esophageal contraction vigor","summary":"  n clinical, if a patient presents with nonmechanical obstructive dysphagia,\nesophageal chest pain, and gastro esophageal reflux symptoms, the physician\nwill usually assess the esophageal dynamic function. High-resolution manometry\n(HRM) is a clinically commonly used technique for detection of esophageal\ndynamic function comprehensively and objectively. However, after the results of\nHRM are obtained, doctors still need to evaluate by a variety of parameters.\nThis work is burdensome, and the process is complex. We conducted image\nprocessing of HRM to predict the esophageal contraction vigor for assisting the\nevaluation of esophageal dynamic function. Firstly, we used Feature-Extraction\nand Histogram of Gradients (FE-HOG) to analyses feature of proposal of swallow\n(PoS) to further extract higher-order features. Then we determine the\nclassification of esophageal contraction vigor normal, weak and failed by using\nlinear-SVM according to these features. Our data set includes 3000 training\nsets, 500 validation sets and 411 test sets. After verification our accuracy\nreaches 86.83%, which is higher than other common machine learning methods.\n","authors":["Jialin Liu","Lu Yan","Xiaowei Liu","Yuzhuo Dai","Fanggen Lu","Yuanting Ma","Muzhou Hou","Zheng Wang"],"pdf_url":"https://arxiv.org/pdf/2311.15609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15607v1","updated":"2023-11-27T08:00:53Z","published":"2023-11-27T08:00:53Z","title":"Spatially Covariant Image Registration with Text Prompts","summary":"  Medical images are often characterized by their structured anatomical\nrepresentations and spatially inhomogeneous contrasts. Leveraging anatomical\npriors in neural networks can greatly enhance their utility in\nresource-constrained clinical settings. Prior research has harnessed such\ninformation for image segmentation, yet progress in deformable image\nregistration has been modest. Our work introduces textSCF, a novel method that\nintegrates spatially covariant filters and textual anatomical prompts encoded\nby visual-language models, to fill this gap. This approach optimizes an\nimplicit function that correlates text embeddings of anatomical regions to\nfilter weights, relaxing the typical translation-invariance constraint of\nconvolutional operations. TextSCF not only boosts computational efficiency but\ncan also retain or improve registration accuracy. By capturing the contextual\ninterplay between anatomical regions, it offers impressive inter-regional\ntransferability and the ability to preserve structural discontinuities during\nregistration. TextSCF's performance has been rigorously tested on inter-subject\nbrain MRI and abdominal CT registration tasks, outperforming existing\nstate-of-the-art models in the MICCAI Learn2Reg 2021 challenge and leading the\nleaderboard. In abdominal registrations, textSCF's larger model variant\nimproved the Dice score by 11.3% over the second-best model, while its smaller\nvariant maintained similar accuracy but with an 89.13% reduction in network\nparameters and a 98.34\\% decrease in computational operations.\n","authors":["Hang Zhang","Xiang Chen","Rongguang Wang","Renjiu Hu","Dongdong Liu","Gaolei Li"],"pdf_url":"https://arxiv.org/pdf/2311.15607v1.pdf","comment":"15 pages, 8 figures, 5 tables"},{"id":"http://arxiv.org/abs/2311.15605v1","updated":"2023-11-27T07:57:29Z","published":"2023-11-27T07:57:29Z","title":"2D Feature Distillation for Weakly- and Semi-Supervised 3D Semantic\n  Segmentation","summary":"  As 3D perception problems grow in popularity and the need for large-scale\nlabeled datasets for LiDAR semantic segmentation increase, new methods arise\nthat aim to reduce the necessity for dense annotations by employing\nweakly-supervised training. However these methods continue to show weak\nboundary estimation and high false negative rates for small objects and distant\nsparse regions. We argue that such weaknesses can be compensated by using RGB\nimages which provide a denser representation of the scene. We propose an\nimage-guidance network (IGNet) which builds upon the idea of distilling high\nlevel feature information from a domain adapted synthetically trained 2D\nsemantic segmentation network. We further utilize a one-way contrastive\nlearning scheme alongside a novel mixing strategy called FOVMix, to combat the\nhorizontal field-of-view mismatch between the two sensors and enhance the\neffects of image guidance. IGNet achieves state-of-the-art results for\nweakly-supervised LiDAR semantic segmentation on ScribbleKITTI, boasting up to\n98% relative performance to fully supervised training with only 8% labeled\npoints, while introducing no additional annotation burden or\ncomputational/memory cost during inference. Furthermore, we show that our\ncontributions also prove effective for semi-supervised training, where IGNet\nclaims state-of-the-art results on both ScribbleKITTI and SemanticKITTI.\n","authors":["Ozan Unal","Dengxin Dai","Lukas Hoyer","Yigit Baran Can","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2311.15605v1.pdf","comment":"Accepted at WACV 2024"},{"id":"http://arxiv.org/abs/2311.15599v1","updated":"2023-11-27T07:48:50Z","published":"2023-11-27T07:48:50Z","title":"UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio,\n  Video, Point Cloud, Time-Series and Image Recognition","summary":"  Large-kernel convolutional neural networks (ConvNets) have recently received\nextensive research attention, but there are two unresolved and critical issues\nthat demand further investigation. 1) The architectures of existing\nlarge-kernel ConvNets largely follow the design principles of conventional\nConvNets or transformers, while the architectural design for large-kernel\nConvNets remains under-addressed. 2) As transformers have dominated multiple\nmodalities, it remains to be investigated whether ConvNets also have a strong\nuniversal perception ability in domains beyond vision. In this paper, we\ncontribute from two aspects. 1) We propose four architectural guidelines for\ndesigning large-kernel ConvNets, the core of which is to exploit the essential\ncharacteristics of large kernels that distinguish them from small kernels -\nthey can see wide without going deep. Following such guidelines, our proposed\nlarge-kernel ConvNet shows leading performance in image recognition. For\nexample, our models achieve an ImageNet accuracy of 88.0%, ADE20K mIoU of\n55.6%, and COCO box AP of 56.4%, demonstrating better performance and higher\nspeed than a number of recently proposed powerful competitors. 2) We discover\nthat large kernels are the key to unlocking the exceptional performance of\nConvNets in domains where they were originally not proficient. With certain\nmodality-related preprocessing approaches, the proposed model achieves\nstate-of-the-art performance on time-series forecasting and audio recognition\ntasks even without modality-specific customization to the architecture. Code\nand all the models at https://github.com/AILab-CVC/UniRepLKNet.\n","authors":["Xiaohan Ding","Yiyuan Zhang","Yixiao Ge","Sijie Zhao","Lin Song","Xiangyu Yue","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2311.15599v1.pdf","comment":"Code, all the models and reproducible training scripts at\n  https://github.com/AILab-CVC/UniRepLKNet"},{"id":"http://arxiv.org/abs/2311.15596v1","updated":"2023-11-27T07:44:25Z","published":"2023-11-27T07:44:25Z","title":"Can Vision-Language Models Think from a First-Person Perspective?","summary":"  Vision-language models (VLMs) have recently shown promising results in\ntraditional downstream tasks. Evaluation studies have emerged to assess their\nabilities, with the majority focusing on the third-person perspective, and only\na few addressing specific tasks from the first-person perspective. However, the\ncapability of VLMs to \"think\" from a first-person perspective, a crucial\nattribute for advancing autonomous agents and robotics, remains largely\nunexplored. To bridge this research gap, we introduce EgoThink, a novel visual\nquestion-answering benchmark that encompasses six core capabilities with twelve\ndetailed dimensions. The benchmark is constructed using selected clips from\negocentric videos, with manually annotated question-answer pairs containing\nfirst-person information. To comprehensively assess VLMs, we evaluate eighteen\npopular VLMs on EgoThink. Moreover, given the open-ended format of the answers,\nwe use GPT-4 as the automatic judge to compute single-answer grading.\nExperimental results indicate that although GPT-4V leads in numerous\ndimensions, all evaluated VLMs still possess considerable potential for\nimprovement in first-person perspective tasks. Meanwhile, enlarging the number\nof trainable parameters has the most significant impact on model performance on\nEgoThink. In conclusion, EgoThink serves as a valuable addition to existing\nevaluation benchmarks for VLMs, providing an indispensable resource for future\nresearch in the realm of embodied artificial intelligence and robotics.\n","authors":["Sijie Cheng","Zhicheng Guo","Jingwen Wu","Kechen Fang","Peng Li","Huaping Liu","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2311.15596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15586v1","updated":"2023-11-27T07:24:50Z","published":"2023-11-27T07:24:50Z","title":"An Ensemble of 2.5D ResUnet Based Models for Segmentation for Kidney and\n  Masses","summary":"  The automatic segmentation of kidney, kidney tumor and kidney cyst on\nComputed Tomography (CT) scans is a challenging task due to the indistinct\nlesion boundaries and fuzzy texture. Considering the large range and unbalanced\ndistribution of CT scans' thickness, 2.5D ResUnet are adopted to build an\nefficient coarse-to-fine semantic segmentation framework in this work. A set of\n489 CT scans are used for training and validation, and an independent\nnever-before-used CT scans for testing. Finally, we demonstrate the\neffectiveness of our proposed method. The dice values on test set are 0.954,\n0.792, 0.691, the surface dice values are 0.897, 0.591, 0.541 for kidney, tumor\nand cyst, respectively. The average inference time of each CT scan is 20.65s\nand the max GPU memory is 3525MB. The results suggest that a better trade-off\nbetween model performance and efficiency.\n","authors":["Cancan Chen"," RongguoZhang"],"pdf_url":"https://arxiv.org/pdf/2311.15586v1.pdf","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2311.15584v1","updated":"2023-11-27T07:19:41Z","published":"2023-11-27T07:19:41Z","title":"A deep learning approach for marine snow synthesis and removal","summary":"  Marine snow, the floating particles in underwater images, severely degrades\nthe visibility and performance of human and machine vision systems. This paper\nproposes a novel method to reduce the marine snow interference using deep\nlearning techniques. We first synthesize realistic marine snow samples by\ntraining a Generative Adversarial Network (GAN) model and combine them with\nnatural underwater images to create a paired dataset. We then train a U-Net\nmodel to perform marine snow removal as an image to image translation task. Our\nexperiments show that the U-Net model can effectively remove both synthetic and\nnatural marine snow with high accuracy, outperforming state-of-the-art methods\nsuch as the Median filter and its adaptive variant. We also demonstrate the\nrobustness of our method by testing it on the MSRB dataset, which contains\nsynthetic artifacts that our model has not seen during training. Our method is\na practical and efficient solution for enhancing underwater images affected by\nmarine snow.\n","authors":["Fernando Galetto","Guang Deng"],"pdf_url":"https://arxiv.org/pdf/2311.15584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15581v1","updated":"2023-11-27T07:19:10Z","published":"2023-11-27T07:19:10Z","title":"Real Time GAZED: Online Shot Selection and Editing of Virtual Cameras\n  from Wide-Angle Monocular Video Recordings","summary":"  Eliminating time-consuming post-production processes and delivering\nhigh-quality videos in today's fast-paced digital landscape are the key\nadvantages of real-time approaches. To address these needs, we present Real\nTime GAZED: a real-time adaptation of the GAZED framework integrated with\nCineFilter, a novel real-time camera trajectory stabilization approach. It\nenables users to create professionally edited videos in real-time. Comparative\nevaluations against baseline methods, including the non-real-time GAZED,\ndemonstrate that Real Time GAZED achieves similar editing results, ensuring\nhigh-quality video output. Furthermore, a user study confirms the aesthetic\nquality of the video edits produced by the Real Time GAZED approach. With these\nadvancements in real-time camera trajectory optimization and video editing\npresented, the demand for immediate and dynamic content creation in industries\nsuch as live broadcasting, sports coverage, news reporting, and social media\ncontent creation can be met more efficiently.\n","authors":["Sudheer Achary","Rohit Girmaji","Adhiraj Anil Deshmukh","Vineet Gandhi"],"pdf_url":"https://arxiv.org/pdf/2311.15581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15573v1","updated":"2023-11-27T06:55:53Z","published":"2023-11-27T06:55:53Z","title":"EucliDreamer: Fast and High-Quality Texturing for 3D Models with Stable\n  Diffusion Depth","summary":"  This paper presents a novel method to generate textures for 3D models given\ntext prompts and 3D meshes. Additional depth information is taken into account\nto perform the Score Distillation Sampling (SDS) process [28] with depth\nconditional Stable Diffusion [34]. We ran our model over the open-source\ndataset Objaverse [7] and conducted a user study to compare the results with\nthose of various 3D texturing methods. We have shown that our model can\ngenerate more satisfactory results and produce various art styles for the same\nobject. In addition, we achieved faster time when generating textures of\ncomparable quality. We also conduct thorough ablation studies of how different\nfactors may affect generation quality, including sampling steps, guidance\nscale, negative prompts, data augmentation, elevation range, and alternatives\nto SDS.\n","authors":["Cindy Le","Congrui Hetang","Ang Cao","Yihui He"],"pdf_url":"https://arxiv.org/pdf/2311.15573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11317v3","updated":"2023-11-27T06:52:44Z","published":"2023-11-19T13:07:06Z","title":"Discrete approximations of Gaussian smoothing and Gaussian derivatives","summary":"  This paper develops an in-depth treatment concerning the problem of\napproximating the Gaussian smoothing and Gaussian derivative computations in\nscale-space theory for application on discrete data. With close connections to\nprevious axiomatic treatments of continuous and discrete scale-space theory, we\nconsider three main ways discretizing these scale-space operations in terms of\nexplicit discrete convolutions, based on either (i) sampling the Gaussian\nkernels and the Gaussian derivative kernels, (ii) locally integrating the\nGaussian kernels and the Gaussian derivative kernels over each pixel support\nregion and (iii) basing the scale-space analysis on the discrete analogue of\nthe Gaussian kernel, and then computing derivative approximations by applying\nsmall-support central difference operators to the spatially smoothed image\ndata.\n  We study the properties of these three main discretization methods both\ntheoretically and experimentally, and characterize their performance by\nquantitative measures, including the results they give rise to with respect to\nthe task of scale selection, investigated for four different use cases, and\nwith emphasis on the behaviour at fine scales. The results show that the\nsampled Gaussian kernels and derivatives as well as the integrated Gaussian\nkernels and derivatives perform very poorly at very fine scales. At very fine\nscales, the discrete analogue of the Gaussian kernel with its corresponding\ndiscrete derivative approximations performs substantially better. The sampled\nGaussian kernel and the sampled Gaussian derivatives do, on the other hand,\nlead to numerically very good approximations of the corresponding continuous\nresults, when the scale parameter is sufficiently large, in the experiments\npresented in the paper, when the scale parameter is greater than a value of\nabout 1, in units of the grid spacing.\n","authors":["Tony Lindeberg"],"pdf_url":"https://arxiv.org/pdf/2311.11317v3.pdf","comment":"38 pages, 34 figures"},{"id":"http://arxiv.org/abs/2311.15571v1","updated":"2023-11-27T06:45:22Z","published":"2023-11-27T06:45:22Z","title":"Video-based Visible-Infrared Person Re-Identification with Auxiliary\n  Samples","summary":"  Visible-infrared person re-identification (VI-ReID) aims to match persons\ncaptured by visible and infrared cameras, allowing person retrieval and\ntracking in 24-hour surveillance systems. Previous methods focus on learning\nfrom cross-modality person images in different cameras. However, temporal\ninformation and single-camera samples tend to be neglected. To crack this nut,\nin this paper, we first contribute a large-scale VI-ReID dataset named\nBUPTCampus. Different from most existing VI-ReID datasets, it 1) collects\ntracklets instead of images to introduce rich temporal information, 2) contains\npixel-aligned cross-modality sample pairs for better modality-invariant\nlearning, 3) provides one auxiliary set to help enhance the optimization, in\nwhich each identity only appears in a single camera. Based on our constructed\ndataset, we present a two-stream framework as baseline and apply Generative\nAdversarial Network (GAN) to narrow the gap between the two modalities. To\nexploit the advantages introduced by the auxiliary set, we propose a curriculum\nlearning based strategy to jointly learn from both primary and auxiliary sets.\nMoreover, we design a novel temporal k-reciprocal re-ranking method to refine\nthe ranking list with fine-grained temporal correlation cues. Experimental\nresults demonstrate the effectiveness of the proposed methods. We also\nreproduce 9 state-of-the-art image-based and video-based VI-ReID methods on\nBUPTCampus and our methods show substantial superiority to them. The codes and\ndataset are available at: https://github.com/dyhBUPT/BUPTCampus.\n","authors":["Yunhao Du","Cheng Lei","Zhicheng Zhao","Yuan Dong","Fei Su"],"pdf_url":"https://arxiv.org/pdf/2311.15571v1.pdf","comment":"Accepted by Transactions on Information Forensics & Security 2023"},{"id":"http://arxiv.org/abs/2311.15570v1","updated":"2023-11-27T06:38:07Z","published":"2023-11-27T06:38:07Z","title":"UFDA: Universal Federated Domain Adaptation with Practical Assumptions","summary":"  Conventional Federated Domain Adaptation (FDA) approaches usually demand an\nabundance of assumptions, such as label set consistency, which makes them\nsignificantly less feasible for real-world situations and introduces security\nhazards. In this work, we propose a more practical scenario named Universal\nFederated Domain Adaptation (UFDA). It only requires the black-box model and\nthe label set information of each source domain, while the label sets of\ndifferent source domains could be inconsistent and the target-domain label set\nis totally blind. This relaxes the assumptions made by FDA, which are often\nchallenging to meet in real-world cases and diminish model security. To address\nthe UFDA scenario, we propose a corresponding framework called Hot-Learning\nwith Contrastive Label Disambiguation (HCLD), which tackles UFDA's domain\nshifts and category gaps problem by using one-hot outputs from the black-box\nmodels of various source domains. Moreover, to better distinguish the shared\nand unknown classes, we further present a cluster-level strategy named\nMutual-Voting Decision (MVD) to extract robust consensus knowledge across peer\nclasses from both source and target domains. The extensive experiments on three\nbenchmarks demonstrate that our HCLD achieves comparable performance for our\nUFDA scenario with much fewer assumptions, compared to the previous\nmethodologies with many additional assumptions.\n","authors":["Xinhui Liu","Zhenghao Chen","Luping Zhou","Dong Xu","Wei Xi","Gairui Bai","Yihan Zhao","Jizhong Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.15570v1.pdf","comment":"Submitted to AAAI2024"},{"id":"http://arxiv.org/abs/2311.15569v1","updated":"2023-11-27T06:37:05Z","published":"2023-11-27T06:37:05Z","title":"Improving Adaptability and Generalizability of Efficient Transfer\n  Learning for Vision-Language Models","summary":"  Vision-Language Models (VLMs) like CLIP have demonstrated remarkable\napplicability across a variety of downstream tasks, including zero-shot image\nclassification. Recently, the use of prompts or adapters for efficient transfer\nlearning has gained significant attention for effectively adapting to\ndownstream tasks. However, the roles of vision and text prompts, as well as\nadapters in terms of generalization and transfer difficulty, have been\noverlooked, limiting performance on unseen tasks. In this paper, we empirically\nanalyze how VLMs behave when using vision and text prompts, adapters, and a\ncombination of these components, marking a novel exploration by our study. Our\nobservations find that utilizing vision prompts for class separability and text\nadapters for task adaptation is crucial for adaptability and generalizability.\nMoreover, to improve generalization across every domain, we propose an adaptive\nensemble method that effectively combines the general knowledge of VLMs with\ntask-specific knowledge according to transfer difficulty. Upon experimenting\nwith extensive benchmarks, our method consistently outperforms all baselines,\nparticularly on unseen tasks, demonstrating the effectiveness of our proposed\napproach.\n","authors":["Yongjin Yang","Jongwoo Ko","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2311.15569v1.pdf","comment":"11 pages (19 pages including supplementary), 10 figures (12 figures\n  including supplementary), 6 tables (17 tables including supplementary)"},{"id":"http://arxiv.org/abs/2311.15562v1","updated":"2023-11-27T06:19:00Z","published":"2023-11-27T06:19:00Z","title":"Fully Authentic Visual Question Answering Dataset from Online\n  Communities","summary":"  Visual Question Answering (VQA) entails answering questions about images. We\nintroduce the first VQA dataset in which all contents originate from an\nauthentic use case. Sourced from online question answering community forums, we\ncall it VQAonline. We then characterize our dataset and how it relates to eight\nother VQA datasets. Observing that answers in our dataset tend to be much\nlonger (e.g., with a mean of 173 words) and thus incompatible with standard VQA\nevaluation metrics, we next analyze which of the six popular metrics for longer\ntext evaluation align best with human judgments. We then use the best-suited\nmetrics to evaluate six state-of-the-art vision and language foundation models\non VQAonline and reveal where they struggle most. We will release the dataset\nsoon to facilitate future extensions.\n","authors":["Chongyan Chen","Mengchen Liu","Noel Codella","Yunsheng Li","Lu Yuan","Danna Gurari"],"pdf_url":"https://arxiv.org/pdf/2311.15562v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15561v1","updated":"2023-11-27T06:14:23Z","published":"2023-11-27T06:14:23Z","title":"ET3D: Efficient Text-to-3D Generation via Multi-View Distillation","summary":"  Recent breakthroughs in text-to-image generation has shown encouraging\nresults via large generative models. Due to the scarcity of 3D assets, it is\nhardly to transfer the success of text-to-image generation to that of\ntext-to-3D generation. Existing text-to-3D generation methods usually adopt the\nparadigm of DreamFusion, which conducts per-asset optimization by distilling a\npretrained text-to-image diffusion model. The generation speed usually ranges\nfrom several minutes to tens of minutes per 3D asset, which degrades the user\nexperience and also imposes a burden to the service providers due to the high\ncomputational budget.\n  In this work, we present an efficient text-to-3D generation method, which\nrequires only around 8 $ms$ to generate a 3D asset given the text prompt on a\nconsumer graphic card. The main insight is that we exploit the images generated\nby a large pre-trained text-to-image diffusion model, to supervise the training\nof a text conditioned 3D generative adversarial network. Once the network is\ntrained, we are able to efficiently generate a 3D asset via a single forward\npass. Our method requires no 3D training data and provides an alternative\napproach for efficient text-to-3D generation by distilling pre-trained image\ndiffusion models.\n","authors":["Yiming Chen","Zhiqi Li","Peidong Liu"],"pdf_url":"https://arxiv.org/pdf/2311.15561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12386v2","updated":"2023-11-27T05:58:45Z","published":"2023-11-21T06:55:21Z","title":"Point, Segment and Count: A Generalized Framework for Object Counting","summary":"  Class-agnostic object counting aims to count all objects in an image with\nrespect to example boxes or class names, \\emph{a.k.a} few-shot and zero-shot\ncounting. Current state-of-the-art methods highly rely on density maps to\npredict object counts, which lacks model interpretability. In this paper, we\npropose a generalized framework for both few-shot and zero-shot object counting\nbased on detection. Our framework combines the superior advantages of two\nfoundation models without compromising their zero-shot capability: (\\textbf{i})\nSAM to segment all possible objects as mask proposals, and (\\textbf{ii}) CLIP\nto classify proposals to obtain accurate object counts. However, this strategy\nmeets the obstacles of efficiency overhead and the small crowded objects that\ncannot be localized and distinguished. To address these issues, our framework,\ntermed PseCo, follows three steps: point, segment, and count. Specifically, we\nfirst propose a class-agnostic object localization to provide accurate but\nleast point prompts for SAM, which consequently not only reduces computation\ncosts but also avoids missing small objects. Furthermore, we propose a\ngeneralized object classification that leverages CLIP image/text embeddings as\nthe classifier, following a hierarchical knowledge distillation to obtain\ndiscriminative classifications among hierarchical mask proposals. Extensive\nexperimental results on FSC-147 dataset demonstrate that PseCo achieves\nstate-of-the-art performance in both few-shot/zero-shot object\ncounting/detection, with additional results on large-scale COCO and LVIS\ndatasets. The source code is available at\n\\url{https://github.com/Hzzone/PseCo}.\n","authors":["Zhizhong Huang","Mingliang Dai","Yi Zhang","Junping Zhang","Hongming Shan"],"pdf_url":"https://arxiv.org/pdf/2311.12386v2.pdf","comment":"Fix typos"},{"id":"http://arxiv.org/abs/2311.15556v1","updated":"2023-11-27T05:53:03Z","published":"2023-11-27T05:53:03Z","title":"PKU-I2IQA: An Image-to-Image Quality Assessment Database for AI\n  Generated Images","summary":"  With the development of image generation technology, AI-based image\ngeneration has been applied in various fields. However, the development of AIGC\nimage generative models also brings new problems and challenges. A significant\nchallenge is that AI-generated images (AIGI) compared to natural images may\nhave some unique distortions, and not all generated images meet the\nrequirements of the real world, so it is of great significance to evaluate\nAI-generated images more comprehensively. Although previous work has\nestablished some human perception-based AIGC image quality assessment databases\nfor text-generated images, the AI image generation technology includes\nscenarios like text-to-image and image-to-image, and assessing only the images\ngenerated by text-to-image models is insufficient. To address this issue, we\nhave established a human perception-based image-to-image AIGC image quality\nassessment database, named PKU-I2IQA. We conducted a comprehensive analysis of\nthe PKU-I2IQA database. Furthermore, we introduced two benchmark models:\nNR-AIGCIQA based on no-reference image quality assessment and FR-AIGCIQA based\non full-reference image quality assessment.Finally, leveraging this database,\nwe conducted benchmark experiments and compared the performance of the proposed\nbenchmark models. The PKU-I2IQA database and benchmarks will be released to\nfacilitate future research on https://github.com/jiquan123/I2IQA.\n  Keywords: AIGC, image-to-image generation, image quality assessment,\nNR-AIGCIQA, FR-AIGCIQA\n","authors":["Jiquan Yuan","Xinyan Cao","Changjin Li","Fanyi Yang","Jinlong Lin","Xixin Cao"],"pdf_url":"https://arxiv.org/pdf/2311.15556v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2311.15551v1","updated":"2023-11-27T05:35:49Z","published":"2023-11-27T05:35:49Z","title":"Instruct2Attack: Language-Guided Semantic Adversarial Attacks","summary":"  We propose Instruct2Attack (I2A), a language-guided semantic attack that\ngenerates semantically meaningful perturbations according to free-form language\ninstructions. We make use of state-of-the-art latent diffusion models, where we\nadversarially guide the reverse diffusion process to search for an adversarial\nlatent code conditioned on the input image and text instruction. Compared to\nexisting noise-based and semantic attacks, I2A generates more natural and\ndiverse adversarial examples while providing better controllability and\ninterpretability. We further automate the attack process with GPT-4 to generate\ndiverse image-specific text instructions. We show that I2A can successfully\nbreak state-of-the-art deep neural networks even under strong adversarial\ndefenses, and demonstrate great transferability among a variety of network\narchitectures.\n","authors":["Jiang Liu","Chen Wei","Yuxiang Guo","Heng Yu","Alan Yuille","Soheil Feizi","Chun Pong Lau","Rama Chellappa"],"pdf_url":"https://arxiv.org/pdf/2311.15551v1.pdf","comment":"under submission, code coming soon"},{"id":"http://arxiv.org/abs/2311.15547v1","updated":"2023-11-27T05:23:01Z","published":"2023-11-27T05:23:01Z","title":"Dataset Distillation in Latent Space","summary":"  Dataset distillation (DD) is a newly emerging research area aiming at\nalleviating the heavy computational load in training models on large datasets.\nIt tries to distill a large dataset into a small and condensed one so that\nmodels trained on the distilled dataset can perform comparably with those\ntrained on the full dataset when performing downstream tasks. Among the\nprevious works in this area, there are three key problems that hinder the\nperformance and availability of the existing DD methods: high time complexity,\nhigh space complexity, and low info-compactness. In this work, we\nsimultaneously attempt to settle these three problems by moving the DD\nprocesses from conventionally used pixel space to latent space. Encoded by a\npretrained generic autoencoder, latent codes in the latent space are naturally\ninfo-compact representations of the original images in much smaller sizes.\nAfter transferring three mainstream DD algorithms to latent space, we\nsignificantly reduce time and space consumption while achieving similar\nperformance, allowing us to distill high-resolution datasets or target at\ngreater data ratio that previous methods have failed. Besides, within the same\nstorage budget, we can also quantitatively deliver more latent codes than\npixel-level images, which further boosts the performance of our methods.\n","authors":["Yuxuan Duan","Jianfu Zhang","Liqing Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.15547v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2311.15543v1","updated":"2023-11-27T05:20:11Z","published":"2023-11-27T05:20:11Z","title":"Beyond Pixels: Exploring Human-Readable SVG Generation for Simple Images\n  with Vision Language Models","summary":"  In the field of computer graphics, the use of vector graphics, particularly\nScalable Vector Graphics (SVG), represents a notable development from\ntraditional pixel-based imagery. SVGs, with their XML-based format, are\ndistinct in their ability to directly and explicitly represent visual elements\nsuch as shape, color, and path. This direct representation facilitates a more\naccurate and logical depiction of graphical elements, enhancing reasoning and\ninterpretability. Recognizing the potential of SVGs, the machine learning\ncommunity has introduced multiple methods for image vectorization. However,\ntransforming images into SVG format while retaining the relational properties\nand context of the original scene remains a key challenge. Most vectorization\nmethods often yield SVGs that are overly complex and not easily interpretable.\nIn response to this challenge, we introduce our method, Simple-SVG-Generation\n(S\\textsuperscript{2}VG\\textsuperscript{2}). Our method focuses on producing\nSVGs that are both accurate and simple, aligning with human readability and\nunderstanding. With simple images, we evaluate our method with reasoning tasks\ntogether with advanced language models, the results show a clear improvement\nover previous SVG generation methods. We also conducted surveys for human\nevaluation on the readability of our generated SVGs, the results also favor our\nmethods.\n","authors":["Tong Zhang","Haoyang Liu","Peiyan Zhang","Yuxuan Cheng","Haohan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.15543v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.15540v1","updated":"2023-11-27T05:10:15Z","published":"2023-11-27T05:10:15Z","title":"EAFP-Med: An Efficient Adaptive Feature Processing Module Based on\n  Prompts for Medical Image Detection","summary":"  In the face of rapid advances in medical imaging, cross-domain adaptive\nmedical image detection is challenging due to the differences in lesion\nrepresentations across various medical imaging technologies. To address this\nissue, we draw inspiration from large language models to propose EAFP-Med, an\nefficient adaptive feature processing module based on prompts for medical image\ndetection. EAFP-Med can efficiently extract lesion features of different scales\nfrom a diverse range of medical images based on prompts while being flexible\nand not limited by specific imaging techniques. Furthermore, it serves as a\nfeature preprocessing module that can be connected to any model front-end to\nenhance the lesion features in input images. Moreover, we propose a novel\nadaptive disease detection model named EAFP-Med ST, which utilizes the Swin\nTransformer V2 - Tiny (SwinV2-T) as its backbone and connects it to EAFP-Med.\nWe have compared our method to nine state-of-the-art methods. Experimental\nresults demonstrate that EAFP-Med ST achieves the best performance on all three\ndatasets (chest X-ray images, cranial magnetic resonance imaging images, and\nskin images). EAFP-Med can efficiently extract lesion features from various\nmedical images based on prompts, enhancing the model's performance. This holds\nsignificant potential for improving medical image analysis and diagnosis.\n","authors":["Xiang Li","Long Lan","Husam Lahza","Shaowu Yang","Shuihua Wang","Wenjing Yang","Hengzhu Liu","Yudong Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.15540v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.09777v2","updated":"2023-11-27T05:09:29Z","published":"2023-09-18T13:58:42Z","title":"DriveDreamer: Towards Real-world-driven World Models for Autonomous\n  Driving","summary":"  World models, especially in autonomous driving, are trending and drawing\nextensive attention due to their capacity for comprehending driving\nenvironments. The established world model holds immense potential for the\ngeneration of high-quality driving videos, and driving policies for safe\nmaneuvering. However, a critical limitation in relevant research lies in its\npredominant focus on gaming environments or simulated settings, thereby lacking\nthe representation of real-world driving scenarios. Therefore, we introduce\nDriveDreamer, a pioneering world model entirely derived from real-world driving\nscenarios. Regarding that modeling the world in intricate driving scenes\nentails an overwhelming search space, we propose harnessing the powerful\ndiffusion model to construct a comprehensive representation of the complex\nenvironment. Furthermore, we introduce a two-stage training pipeline. In the\ninitial phase, DriveDreamer acquires a deep understanding of structured traffic\nconstraints, while the subsequent stage equips it with the ability to\nanticipate future states. The proposed DriveDreamer is the first world model\nestablished from real-world driving scenarios. We instantiate DriveDreamer on\nthe challenging nuScenes benchmark, and extensive experiments verify that\nDriveDreamer empowers precise, controllable video generation that faithfully\ncaptures the structural constraints of real-world traffic scenarios.\nAdditionally, DriveDreamer enables the generation of realistic and reasonable\ndriving policies, opening avenues for interaction and practical applications.\n","authors":["Xiaofeng Wang","Zheng Zhu","Guan Huang","Xinze Chen","Jiagang Zhu","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2309.09777v2.pdf","comment":"Project Page: https://drivedreamer.github.io"},{"id":"http://arxiv.org/abs/2311.15537v1","updated":"2023-11-27T05:00:38Z","published":"2023-11-27T05:00:38Z","title":"SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation","summary":"  Open-vocabulary semantic segmentation strives to distinguish pixels into\ndifferent semantic groups from an open set of categories. Most existing methods\nexplore utilizing pre-trained vision-language models, in which the key is to\nadopt the image-level model for pixel-level segmentation task. In this paper,\nwe propose a simple encoder-decoder, named SED, for open-vocabulary semantic\nsegmentation, which comprises a hierarchical encoder-based cost map generation\nand a gradual fusion decoder with category early rejection. The hierarchical\nencoder-based cost map generation employs hierarchical backbone, instead of\nplain transformer, to predict pixel-level image-text cost map. Compared to\nplain transformer, hierarchical backbone better captures local spatial\ninformation and has linear computational complexity with respect to input size.\nOur gradual fusion decoder employs a top-down structure to combine cost map and\nthe feature maps of different backbone levels for segmentation. To accelerate\ninference speed, we introduce a category early rejection scheme in the decoder\nthat rejects many no-existing categories at the early layer of decoder,\nresulting in at most 4.7 times acceleration without accuracy degradation.\nExperiments are performed on multiple open-vocabulary semantic segmentation\ndatasets, which demonstrates the efficacy of our SED method. When using\nConvNeXt-B, our SED method achieves mIoU score of 31.6\\% on ADE20K with 150\ncategories at 82 millisecond ($ms$) per image on a single A6000. We will\nrelease it at \\url{https://github.com/xb534/SED.git}.\n","authors":["Bin Xie","Jiale Cao","Jin Xie","Fahad Shahbaz Khan","Yanwei Pang"],"pdf_url":"https://arxiv.org/pdf/2311.15537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15536v1","updated":"2023-11-27T04:49:24Z","published":"2023-11-27T04:49:24Z","title":"SVRDA: A Web-based Dataset Annotation Tool for Slice-to-Volume\n  Registration","summary":"  Background and Objective: The lack of benchmark datasets has impeded the\ndevelopment of slice-to-volume registration algorithms. Such datasets are\ndifficult to annotate, primarily due to the dimensional difference within data\nand the dearth of task-specific software. We aim to develop a user-friendly\ntool to streamline dataset annotation for slice-to-volume registration.\n  Methods: The proposed tool, named SVRDA, is an installation-free web\napplication for platform-agnostic collaborative dataset annotation. It enables\nefficient transformation manipulation via keyboard shortcuts and smooth case\ntransitions with auto-saving. SVRDA supports configuration-based data loading\nand adheres to the separation of concerns, offering great flexibility and\nextensibility for future research. Various supplementary features have been\nimplemented to facilitate slice-to-volume registration.\n  Results: We validated the effectiveness of SVRDA by indirectly evaluating the\npost-registration segmentation quality on UK Biobank data, observing a dramatic\noverall improvement (24.02% in the Dice Similarity Coefficient and 48.93% in\nthe 95th percentile Hausdorff distance, respectively) supported by highly\nstatistically significant evidence ($p<0.001$).We further showcased the\nclinical usage of SVRDA by integrating it into test-retest T1 quantification on\nin-house magnetic resonance images, leading to more consistent results after\nregistration.\n  Conclusions: SVRDA can facilitate collaborative annotation of benchmark\ndatasets while being potentially applicable to other pipelines incorporating\nslice-to-volume registration. Full source code and documentation are available\nat https://github.com/Roldbach/SVRDA\n","authors":["Weixun Luo","Alexandre Triay Bagur","Paul Aljabar","George Ralli","Sir Michael Brady"],"pdf_url":"https://arxiv.org/pdf/2311.15536v1.pdf","comment":"18 pages, 11 figures, In submission to Computer Methods and Programs\n  in Biomedicine"},{"id":"http://arxiv.org/abs/2310.01852v6","updated":"2023-11-27T04:28:58Z","published":"2023-10-03T07:33:27Z","title":"LanguageBind: Extending Video-Language Pretraining to N-modality by\n  Language-based Semantic Alignment","summary":"  The video-language (VL) pretraining has achieved remarkable improvement in\nmultiple downstream tasks. However, the current VL pretraining framework is\nhard to extend to multiple modalities (N modalities, N>=3) beyond vision and\nlanguage. We thus propose LanguageBind, taking the language as the bind across\ndifferent modalities because the language modality is well-explored and\ncontains rich semantics. Specifically, we freeze the language encoder acquired\nby VL pretraining, then train encoders for other modalities with contrastive\nlearning. As a result, all modalities are mapped to a shared feature space,\nimplementing multi-modal semantic alignment. While LanguageBind ensures that we\ncan extend VL modalities to N modalities, we also need a high-quality dataset\nwith alignment data pairs centered on language. We thus propose VIDAL-10M with\nVideo, Infrared, Depth, Audio and their corresponding Language, naming as\nVIDAL-10M. In our VIDAL-10M, all videos are from short video platforms with\ncomplete semantics rather than truncated segments from long videos, and all the\nvideo, depth, infrared, and audio modalities are aligned to their textual\ndescriptions. After pretraining on VIDAL-10M, we outperform ImageBind by 5.8%\nR@1 on the MSR-VTT dataset with only 15% of the parameters in the zero-shot\nvideo-text retrieval task. Beyond this, our LanguageBind has greatly improved\nin the zero-shot video, audio, depth, and infrared understanding tasks. For\ninstance, LanguageBind surpassing InterVideo by 1.9% on MSR-VTT, 8.8% on MSVD,\n6.3% on DiDeMo, and 4.4% on ActivityNet. On the LLVIP and NYU-D datasets,\nLanguageBind outperforms ImageBind with 23.8% and 11.1% top-1 accuracy. Code\naddress: https://github.com/PKU-YuanGroup/LanguageBind.\n","authors":["Bin Zhu","Bin Lin","Munan Ning","Yang Yan","Jiaxi Cui","HongFa Wang","Yatian Pang","Wenhao Jiang","Junwu Zhang","Zongwei Li","Wancai Zhang","Zhifeng Li","Wei Liu","Li Yuan"],"pdf_url":"https://arxiv.org/pdf/2310.01852v6.pdf","comment":"Under review as a conference paper at ICLR 2024"},{"id":"http://arxiv.org/abs/2310.18332v2","updated":"2023-11-27T04:22:54Z","published":"2023-10-20T12:44:44Z","title":"WordArt Designer: User-Driven Artistic Typography Synthesis using Large\n  Language Models","summary":"  This paper introduces WordArt Designer, a user-driven framework for artistic\ntypography synthesis, relying on the Large Language Model (LLM). The system\nincorporates four key modules: the LLM Engine, SemTypo, StyTypo, and TexTypo\nmodules. 1) The LLM Engine, empowered by the LLM (e.g., GPT-3.5), interprets\nuser inputs and generates actionable prompts for the other modules, thereby\ntransforming abstract concepts into tangible designs. 2) The SemTypo module\noptimizes font designs using semantic concepts, striking a balance between\nartistic transformation and readability. 3) Building on the semantic layout\nprovided by the SemTypo module, the StyTypo module creates smooth, refined\nimages. 4) The TexTypo module further enhances the design's aesthetics through\ntexture rendering, enabling the generation of inventive textured fonts.\nNotably, WordArt Designer highlights the fusion of generative AI with artistic\ntypography. Experience its capabilities on ModelScope:\nhttps://www.modelscope.cn/studios/WordArt/WordArt.\n","authors":["Jun-Yan He","Zhi-Qi Cheng","Chenyang Li","Jingdong Sun","Wangmeng Xiang","Xianhui Lin","Xiaoyang Kang","Zengke Jin","Yusen Hu","Bin Luo","Yifeng Geng","Xuansong Xie","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2310.18332v2.pdf","comment":"Accepted by EMNLP 2023, 10 pages, 11 figures, 1 table, the system is\n  at https://www.modelscope.cn/studios/WordArt/WordArt"},{"id":"http://arxiv.org/abs/2311.15529v1","updated":"2023-11-27T04:22:48Z","published":"2023-11-27T04:22:48Z","title":"Efficient Dataset Distillation via Minimax Diffusion","summary":"  Dataset distillation reduces the storage and computational consumption of\ntraining a network by generating a small surrogate dataset that encapsulates\nrich information of the original large-scale one. However, previous\ndistillation methods heavily rely on the sample-wise iterative optimization\nscheme. As the images-per-class (IPC) setting or image resolution grows larger,\nthe necessary computation will demand overwhelming time and resources. In this\nwork, we intend to incorporate generative diffusion techniques for computing\nthe surrogate dataset. Observing that key factors for constructing an effective\nsurrogate dataset are representativeness and diversity, we design additional\nminimax criteria in the generative training to enhance these facets for the\ngenerated images of diffusion models. We present a theoretical model of the\nprocess as hierarchical diffusion control demonstrating the flexibility of the\ndiffusion process to target these criteria without jeopardizing the\nfaithfulness of the sample to the desired distribution. The proposed method\nachieves state-of-the-art validation performance while demanding much less\ncomputational resources. Under the 100-IPC setting on ImageWoof, our method\nrequires less than one-twentieth the distillation time of previous methods, yet\nyields even better performance. Source code available in\nhttps://github.com/vimar-gu/MinimaxDiffusion.\n","authors":["Jianyang Gu","Saeed Vahidian","Vyacheslav Kungurtsev","Haonan Wang","Wei Jiang","Yang You","Yiran Chen"],"pdf_url":"https://arxiv.org/pdf/2311.15529v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.12532v2","updated":"2023-11-27T03:33:37Z","published":"2023-08-24T03:43:02Z","title":"FedSoL: Bridging Global Alignment and Local Generality in Federated\n  Learning","summary":"  Federated Learning (FL) aggregates locally trained models from individual\nclients to construct a global model. While FL enables learning a model with\ndata privacy, it often suffers from significant performance degradation when\nclient data distributions are heterogeneous. Many previous FL algorithms have\naddressed this issue by introducing various proximal restrictions. These\nrestrictions aim to encourage global alignment by constraining the deviation of\nlocal learning from the global objective. However, they inherently limit local\nlearning by interfering with the original local objectives. Recently, an\nalternative approach has emerged to improve local learning generality. By\nobtaining local models within a smooth loss landscape, this approach mitigates\nconflicts among different local objectives of the clients. Yet, it does not\nensure stable global alignment, as local learning does not take the global\nobjective into account. In this study, we propose Federated Stability on\nLearning (FedSoL), which combines both the concepts of global alignment and\nlocal generality. In FedSoL, the local learning seeks a parameter region robust\nagainst proximal perturbations. This strategy introduces an implicit proximal\nrestriction effect in local learning while maintaining the original local\nobjective for parameter update. Our experiments show that FedSoL consistently\nachieves state-of-the-art performance on various setups.\n","authors":["Gihun Lee","Minchan Jeong","Sangmook Kim","Jaehoon Oh","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2308.12532v2.pdf","comment":"19 pages, 12 figures"},{"id":"http://arxiv.org/abs/2310.07206v2","updated":"2023-11-27T03:32:21Z","published":"2023-10-11T05:34:36Z","title":"DeepSimHO: Stable Pose Estimation for Hand-Object Interaction via\n  Physics Simulation","summary":"  This paper addresses the task of 3D pose estimation for a hand interacting\nwith an object from a single image observation. When modeling hand-object\ninteraction, previous works mainly exploit proximity cues, while overlooking\nthe dynamical nature that the hand must stably grasp the object to counteract\ngravity and thus preventing the object from slipping or falling. These works\nfail to leverage dynamical constraints in the estimation and consequently often\nproduce unstable results. Meanwhile, refining unstable configurations with\nphysics-based reasoning remains challenging, both by the complexity of contact\ndynamics and by the lack of effective and efficient physics inference in the\ndata-driven learning framework. To address both issues, we present DeepSimHO: a\nnovel deep-learning pipeline that combines forward physics simulation and\nbackward gradient approximation with a neural network. Specifically, for an\ninitial hand-object pose estimated by a base network, we forward it to a\nphysics simulator to evaluate its stability. However, due to non-smooth contact\ngeometry and penetration, existing differentiable simulators can not provide\nreliable state gradient. To remedy this, we further introduce a deep network to\nlearn the stability evaluation process from the simulator, while smoothly\napproximating its gradient and thus enabling effective back-propagation.\nExtensive experiments show that our method noticeably improves the stability of\nthe estimation and achieves superior efficiency over test-time optimization.\nThe code is available at https://github.com/rongakowang/DeepSimHO.\n","authors":["Rong Wang","Wei Mao","Hongdong Li"],"pdf_url":"https://arxiv.org/pdf/2310.07206v2.pdf","comment":"Accepted to NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.15512v1","updated":"2023-11-27T03:15:48Z","published":"2023-11-27T03:15:48Z","title":"Sparse Pedestrian Character Learning for Trajectory Prediction","summary":"  Pedestrian trajectory prediction in a first-person view has recently\nattracted much attention due to its importance in autonomous driving. Recent\nwork utilizes pedestrian character information, \\textit{i.e.}, action and\nappearance, to improve the learned trajectory embedding and achieves\nstate-of-the-art performance. However, it neglects the invalid and negative\npedestrian character information, which is harmful to trajectory representation\nand thus leads to performance degradation. To address this issue, we present a\ntwo-stream sparse-character-based network~(TSNet) for pedestrian trajectory\nprediction. Specifically, TSNet learns the negative-removed characters in the\nsparse character representation stream to improve the trajectory embedding\nobtained in the trajectory representation stream. Moreover, to model the\nnegative-removed characters, we propose a novel sparse character graph,\nincluding the sparse category and sparse temporal character graphs, to learn\nthe different effects of various characters in category and temporal\ndimensions, respectively. Extensive experiments on two first-person view\ndatasets, PIE and JAAD, show that our method outperforms existing\nstate-of-the-art methods. In addition, ablation studies demonstrate different\neffects of various characters and prove that TSNet outperforms approaches\nwithout eliminating negative characters.\n","authors":["Yonghao Dong","Le Wang","Sanpin Zhou","Gang Hua","Changyin Sun"],"pdf_url":"https://arxiv.org/pdf/2311.15512v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15510v1","updated":"2023-11-27T03:09:58Z","published":"2023-11-27T03:09:58Z","title":"CaesarNeRF: Calibrated Semantic Representation for Few-shot\n  Generalizable Neural Rendering","summary":"  Generalizability and few-shot learning are key challenges in Neural Radiance\nFields (NeRF), often due to the lack of a holistic understanding in pixel-level\nrendering. We introduce CaesarNeRF, an end-to-end approach that leverages\nscene-level CAlibratEd SemAntic Representation along with pixel-level\nrepresentations to advance few-shot, generalizable neural rendering,\nfacilitating a holistic understanding without compromising high-quality\ndetails. CaesarNeRF explicitly models pose differences of reference views to\ncombine scene-level semantic representations, providing a calibrated holistic\nunderstanding. This calibration process aligns various viewpoints with precise\nlocation and is further enhanced by sequential refinement to capture varying\ndetails. Extensive experiments on public datasets, including LLFF, Shiny,\nmip-NeRF 360, and MVImgNet, show that CaesarNeRF delivers state-of-the-art\nperformance across varying numbers of reference views, proving effective even\nwith a single reference image. The project page of this work can be found at\nhttps://haidongz-usc.github.io/project/caesarnerf.\n","authors":["Haidong Zhu","Tianyu Ding","Tianyi Chen","Ilya Zharkov","Ram Nevatia","Luming Liang"],"pdf_url":"https://arxiv.org/pdf/2311.15510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11810v2","updated":"2023-11-27T02:53:33Z","published":"2023-11-20T14:42:25Z","title":"DocPedia: Unleashing the Power of Large Multimodal Model in the\n  Frequency Domain for Versatile Document Understanding","summary":"  This work presents DocPedia, a novel large multimodal model (LMM) for\nversatile OCR-free document understanding, capable of parsing images up to\n2,560$\\times$2,560 resolution. Unlike existing work either struggle with\nhigh-resolution documents or give up the large language model thus vision or\nlanguage ability constrained, our DocPedia directly processes visual input in\nthe frequency domain rather than the pixel space. The unique characteristic\nenables DocPedia to capture a greater amount of visual and textual information\nusing a limited number of visual tokens. To consistently enhance both\nperception and comprehension abilities of our model, we develop a dual-stage\ntraining strategy and enrich instructions/annotations of all training tasks\ncovering multiple document types. Extensive quantitative and qualitative\nexperiments conducted on various publicly available benchmarks confirm the\nmutual benefits of jointly learning perception and comprehension tasks. The\nresults provide further evidence of the effectiveness and superior performance\nof our DocPedia over other methods.\n","authors":["Hao Feng","Qi Liu","Hao Liu","Wengang Zhou","Houqiang Li","Can Huang"],"pdf_url":"https://arxiv.org/pdf/2311.11810v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15497v1","updated":"2023-11-27T02:48:06Z","published":"2023-11-27T02:48:06Z","title":"Adaptive Image Registration: A Hybrid Approach Integrating Deep Learning\n  and Optimization Functions for Enhanced Precision","summary":"  Image registration has traditionally been done using two distinct approaches:\nlearning based methods, relying on robust deep neural networks, and\noptimization-based methods, applying complex mathematical transformations to\nwarp images accordingly. Of course, both paradigms offer advantages and\ndisadvantages, and, in this work, we seek to combine their respective strengths\ninto a single streamlined framework, using the outputs of the learning based\nmethod as initial parameters for optimization while prioritizing computational\npower for the image pairs that offer the greatest loss. Our investigations\nshowed that an improvement of 0.3\\% in testing when utilizing the best\nperforming state-of-the-art model as the backbone of the framework, while\nmaintaining the same inference time and with only a 0.8\\% loss in deformation\nfield smoothness.\n","authors":["Gabriel De Araujo","Shanlin Sun","Xiaohui Xie"],"pdf_url":"https://arxiv.org/pdf/2311.15497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13404v2","updated":"2023-11-27T02:33:36Z","published":"2023-11-22T14:00:23Z","title":"Animatable 3D Gaussians for High-fidelity Synthesis of Human Motions","summary":"  We present a novel animatable 3D Gaussian model for rendering high-fidelity\nfree-view human motions in real time. Compared to existing NeRF-based methods,\nthe model owns better capability in synthesizing high-frequency details without\nthe jittering problem across video frames. The core of our model is a novel\naugmented 3D Gaussian representation, which attaches each Gaussian with a\nlearnable code. The learnable code serves as a pose-dependent appearance\nembedding for refining the erroneous appearance caused by geometric\ntransformation of Gaussians, based on which an appearance refinement model is\nlearned to produce residual Gaussian properties to match the appearance in\ntarget pose. To force the Gaussians to learn the foreground human only without\nbackground interference, we further design a novel alpha loss to explicitly\nconstrain the Gaussians within the human body. We also propose to jointly\noptimize the human joint parameters to improve the appearance accuracy. The\nanimatable 3D Gaussian model can be learned with shallow MLPs, so new human\nmotions can be synthesized in real time (66 fps on avarage). Experiments show\nthat our model has superior performance over NeRF-based methods.\n","authors":["Keyang Ye","Tianjia Shao","Kun Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.13404v2.pdf","comment":"Some experiment data is wrong. The expression of the paper in\n  introduction and abstract is incorrect. Some graphs have inappropriate\n  descriptions"},{"id":"http://arxiv.org/abs/2311.15478v1","updated":"2023-11-27T01:41:25Z","published":"2023-11-27T01:41:25Z","title":"AerialBooth: Mutual Information Guidance for Text Controlled Aerial View\n  Synthesis from a Single Image","summary":"  We present a novel method, AerialBooth, for synthesizing the aerial view from\na single input image using its text description. We leverage the pretrained\ntext-to-2D image stable diffusion model as prior knowledge of the 3D world. The\nmodel is finetuned in two steps to optimize for the text embedding and the UNet\nthat reconstruct the input image and its inverse perspective mapping\nrespectively. The inverse perspective mapping creates variance within the\ntext-image space of the diffusion model, while providing weak guidance for\naerial view synthesis. At inference, we steer the contents of the generated\nimage towards the input image using novel mutual information guidance that\nmaximizes the information content between the probability distributions of the\ntwo images. We evaluate our approach on a wide spectrum of real and synthetic\ndata, including natural scenes, indoor scenes, human action, etc. Through\nextensive experiments and ablation studies, we demonstrate the effectiveness of\nAerialBooth and also its generalizability to other text-controlled views. We\nalso show that AerialBooth achieves the best viewpoint-fidelity trade-off\nthough quantitative evaluation on 7 metrics analyzing viewpoint and fidelity\nw.r.t. input image. Code and data is available at\nhttps://github.com/divyakraman/AerialBooth2023.\n","authors":["Divya Kothandaraman","Tianyi Zhou","Ming Lin","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2311.15478v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15477v1","updated":"2023-11-27T01:24:31Z","published":"2023-11-27T01:24:31Z","title":"DreamCreature: Crafting Photorealistic Virtual Creatures from\n  Imagination","summary":"  Recent text-to-image (T2I) generative models allow for high-quality synthesis\nfollowing either text instructions or visual examples. Despite their\ncapabilities, these models face limitations in creating new, detailed creatures\nwithin specific categories (e.g., virtual dog or bird species), which are\nvaluable in digital asset creation and biodiversity analysis. To bridge this\ngap, we introduce a novel task, Virtual Creatures Generation: Given a set of\nunlabeled images of the target concepts (e.g., 200 bird species), we aim to\ntrain a T2I model capable of creating new, hybrid concepts within diverse\nbackgrounds and contexts. We propose a new method called DreamCreature, which\nidentifies and extracts the underlying sub-concepts (e.g., body parts of a\nspecific species) in an unsupervised manner. The T2I thus adapts to generate\nnovel concepts (e.g., new bird species) with faithful structures and\nphotorealistic appearance by seamlessly and flexibly composing learned\nsub-concepts. To enhance sub-concept fidelity and disentanglement, we extend\nthe textual inversion technique by incorporating an additional projector and\ntailored attention loss regularization. Extensive experiments on two\nfine-grained image benchmarks demonstrate the superiority of DreamCreature over\nprior methods in both qualitative and quantitative evaluation. Ultimately, the\nlearned sub-concepts facilitate diverse creative applications, including\ninnovative consumer product designs and nuanced property modifications.\n","authors":["Kam Woh Ng","Xiatian Zhu","Yi-Zhe Song","Tao Xiang"],"pdf_url":"https://arxiv.org/pdf/2311.15477v1.pdf","comment":"Website: https://github.com/kamwoh/dreamcreature"},{"id":"http://arxiv.org/abs/2311.15475v1","updated":"2023-11-27T01:20:11Z","published":"2023-11-27T01:20:11Z","title":"MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers","summary":"  We introduce MeshGPT, a new approach for generating triangle meshes that\nreflects the compactness typical of artist-created meshes, in contrast to dense\ntriangle meshes extracted by iso-surfacing methods from neural fields. Inspired\nby recent advances in powerful large language models, we adopt a sequence-based\napproach to autoregressively generate triangle meshes as sequences of\ntriangles. We first learn a vocabulary of latent quantized embeddings, using\ngraph convolutions, which inform these embeddings of the local mesh geometry\nand topology. These embeddings are sequenced and decoded into triangles by a\ndecoder, ensuring that they can effectively reconstruct the mesh. A transformer\nis then trained on this learned vocabulary to predict the index of the next\nembedding given previous embeddings. Once trained, our model can be\nautoregressively sampled to generate new triangle meshes, directly generating\ncompact meshes with sharp edges, more closely imitating the efficient\ntriangulation patterns of human-crafted meshes. MeshGPT demonstrates a notable\nimprovement over state of the art mesh generation methods, with a 9% increase\nin shape coverage and a 30-point enhancement in FID scores across various\ncategories.\n","authors":["Yawar Siddiqui","Antonio Alliegro","Alexey Artemov","Tatiana Tommasi","Daniele Sirigatti","Vladislav Rosov","Angela Dai","Matthias Nießner"],"pdf_url":"https://arxiv.org/pdf/2311.15475v1.pdf","comment":"Project Page: https://nihalsid.github.io/mesh-gpt/, Video:\n  https://youtu.be/UV90O1_69_o"},{"id":"http://arxiv.org/abs/2311.11178v2","updated":"2023-11-27T00:58:21Z","published":"2023-11-18T22:42:16Z","title":"Active Prompt Learning in Vision Language Models","summary":"  Pre-trained Vision Language Models (VLMs) have demonstrated notable progress\nin various zero-shot tasks, such as classification and retrieval. Despite their\nperformance, because improving performance on new tasks requires task-specific\nknowledge, their adaptation is essential. While labels are needed for the\nadaptation, acquiring them is typically expensive. To overcome this challenge,\nactive learning, a method of achieving a high performance by obtaining labels\nfor a small number of samples from experts, has been studied. Active learning\nprimarily focuses on selecting unlabeled samples for labeling and leveraging\nthem to train models. In this study, we pose the question, \"how can the\npre-trained VLMs be adapted under the active learning framework?\" In response\nto this inquiry, we observe that (1) simply applying a conventional active\nlearning framework to pre-trained VLMs even may degrade performance compared to\nrandom selection because of the class imbalance in labeling candidates, and (2)\nthe knowledge of VLMs can provide hints for achieving the balance before\nlabeling. Based on these observations, we devise a novel active learning\nframework for VLMs, denoted as PCB. To assess the effectiveness of our\napproach, we conduct experiments on seven different real-world datasets, and\nthe results demonstrate that PCB surpasses conventional active learning and\nrandom sampling methods.\n","authors":["Jihwan Bang","Sumyeong Ahn","Jae-Gil Lee"],"pdf_url":"https://arxiv.org/pdf/2311.11178v2.pdf","comment":"version 1"},{"id":"http://arxiv.org/abs/2311.15463v1","updated":"2023-11-27T00:29:10Z","published":"2023-11-27T00:29:10Z","title":"Where to Begin? From Random to Foundation Model Instructed\n  Initialization in Federated Learning for Medical Image Segmentation","summary":"  In medical image analysis, Federated Learning (FL) stands out as a key\ntechnology that enables privacy-preserved, decentralized data processing,\ncrucial for handling sensitive medical data. Currently, most FL models employ\nrandom initialization, which has been proven effective in various instances.\nHowever, given the unique challenges posed by non-IID (independently and\nidentically distributed) data in FL, we propose a novel perspective: exploring\nthe impact of using the foundation model with enormous pre-trained knowledge,\nsuch as the Segment Anything Model (SAM), as an instructive teacher for FL\nmodel initialization in medical image segmentation task. This work for the\nfirst time attempts to utilize the foundation model as an instructive teacher\nfor initialization in FL, assessing its impact on the performance of FL models,\nespecially in non-IID data scenarios. Our empirical evaluation on chest x-ray\nlung segmentation showcases that FL with foundation model instructed\ninitialization not only achieves faster convergence but also improves\nperformance in complex data contexts. These findings offer a new perspective\nfor model initialization in FL.\n","authors":["Ming Li","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2311.15463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10575v2","updated":"2023-11-27T23:00:02Z","published":"2023-01-25T13:27:27Z","title":"Trainable Loss Weights in Super-Resolution","summary":"  In recent years, limited research has discussed the loss function in the\nsuper-resolution process. The majority of those studies have only used\nperceptual similarity conventionally. This is while the development of\nappropriate loss can improve the quality of other methods as well. In this\narticle, a new weighting method for pixel-wise loss is proposed. With the help\nof this method, it is possible to use trainable weights based on the general\nstructure of the image and its perceptual features while maintaining the\nadvantages of pixel-wise loss. Also, a criterion for comparing weights of loss\nis introduced so that the weights can be estimated directly by a convolutional\nneural network. In addition, in this article, the expectation-maximization\nmethod is used for the simultaneous estimation super-resolution network and\nweighting network. In addition, a new activation function, called \"FixedSum\",\nis introduced which can keep the sum of all components of vector constants\nwhile keeping the output components between zero and one. As experimental\nresults shows, weighted loss by the proposed method leads to better results\nthan the unweighted loss and weighted loss based on uncertainty in both\nsignal-to-noise and perceptual similarity senses on the state-of-the-art\nnetworks. Code is available online.\n","authors":["Arash Chaichi Mellatshahi","Shohreh Kasaei"],"pdf_url":"https://arxiv.org/pdf/2301.10575v2.pdf","comment":"9 pages, 6 figures, 2 table"},{"id":"http://arxiv.org/abs/2310.01288v3","updated":"2023-11-27T22:44:15Z","published":"2023-10-02T15:41:35Z","title":"Offline Tracking with Object Permanence","summary":"  To reduce the expensive labor cost for manual labeling autonomous driving\ndatasets, an alternative is to automatically label the datasets using an\noffline perception system. However, objects might be temporally occluded. Such\nocclusion scenarios in the datasets are common yet underexplored in offline\nauto labeling. In this work, we propose an offline tracking model that focuses\non occluded object tracks. It leverages the concept of object permanence which\nmeans objects continue to exist even if they are not observed anymore. The\nmodel contains three parts: a standard online tracker, a re-identification\n(Re-ID) module that associates tracklets before and after occlusion, and a\ntrack completion module that completes the fragmented tracks. The Re-ID module\nand the track completion module use the vectorized map as one of the inputs to\nrefine the tracking results with occlusion. The model can effectively recover\nthe occluded object trajectories. It achieves state-of-the-art performance in\n3D multi-object tracking by significantly improving the original online\ntracking result, showing its potential to be applied in offline auto labeling\nas a useful plugin to improve tracking by recovering occlusions.\n","authors":["Xianzhong Liu","Holger Caesar"],"pdf_url":"https://arxiv.org/pdf/2310.01288v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16353v1","updated":"2023-11-27T22:30:26Z","published":"2023-11-27T22:30:26Z","title":"Improving Denoising Diffusion Probabilistic Models via Exploiting Shared\n  Representations","summary":"  In this work, we address the challenge of multi-task image generation with\nlimited data for denoising diffusion probabilistic models (DDPM), a class of\ngenerative models that produce high-quality images by reversing a noisy\ndiffusion process. We propose a novel method, SR-DDPM, that leverages\nrepresentation-based techniques from few-shot learning to effectively learn\nfrom fewer samples across different tasks. Our method consists of a core meta\narchitecture with shared parameters, i.e., task-specific layers with exclusive\nparameters. By exploiting the similarity between diverse data distributions,\nour method can scale to multiple tasks without compromising the image quality.\nWe evaluate our method on standard image datasets and show that it outperforms\nboth unconditional and conditional DDPM in terms of FID and SSIM metrics.\n","authors":["Delaram Pirhayatifard","Mohammad Taha Toghani","Guha Balakrishnan","César A. Uribe"],"pdf_url":"https://arxiv.org/pdf/2311.16353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16346v1","updated":"2023-11-27T22:25:46Z","published":"2023-11-27T22:25:46Z","title":"Small and Dim Target Detection in IR Imagery: A Review","summary":"  While there has been significant progress in object detection using\nconventional image processing and machine learning algorithms, exploring small\nand dim target detection in the IR domain is a relatively new area of study.\nThe majority of small and dim target detection methods are derived from\nconventional object detection algorithms, albeit with some alterations. The\ntask of detecting small and dim targets in IR imagery is complex. This is\nbecause these targets often need distinct features, the background is cluttered\nwith unclear details, and the IR signatures of the scene can change over time\ndue to fluctuations in thermodynamics. The primary objective of this review is\nto highlight the progress made in this field. This is the first review in the\nfield of small and dim target detection in infrared imagery, encompassing\nvarious methodologies ranging from conventional image processing to\ncutting-edge deep learning-based approaches. The authors have also introduced a\ntaxonomy of such approaches. There are two main types of approaches:\nmethodologies using several frames for detection, and single-frame-based\ndetection techniques. Single frame-based detection techniques encompass a\ndiverse range of methods, spanning from traditional image processing-based\napproaches to more advanced deep learning methodologies. Our findings indicate\nthat deep learning approaches perform better than traditional image\nprocessing-based approaches. In addition, a comprehensive compilation of\nvarious available datasets has also been provided. Furthermore, this review\nidentifies the gaps and limitations in existing techniques, paving the way for\nfuture research and development in this area.\n","authors":["Nikhil Kumar","Pravendra Singh"],"pdf_url":"https://arxiv.org/pdf/2311.16346v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2311.16344v1","updated":"2023-11-27T22:20:53Z","published":"2023-11-27T22:20:53Z","title":"Spatially Adaptive Cloth Regression with Implicit Neural Representations","summary":"  The accurate representation of fine-detailed cloth wrinkles poses significant\nchallenges in computer graphics. The inherently non-uniform structure of cloth\nwrinkles mandates the employment of intricate discretization strategies, which\nare frequently characterized by high computational demands and complex\nmethodologies. Addressing this, the research introduced in this paper\nelucidates a novel anisotropic cloth regression technique that capitalizes on\nthe potential of implicit neural representations of surfaces. Our first core\ncontribution is an innovative mesh-free sampling approach, crafted to reduce\nthe reliance on traditional mesh structures, thereby offering greater\nflexibility and accuracy in capturing fine cloth details. Our second\ncontribution is a novel adversarial training scheme, which is designed\nmeticulously to strike a harmonious balance between the sampling and simulation\nobjectives. The adversarial approach ensures that the wrinkles are represented\nwith high fidelity, while also maintaining computational efficiency. Our\nresults showcase through various cloth-object interaction scenarios that our\nmethod, given the same memory constraints, consistently surpasses traditional\ndiscrete representations, particularly when modelling highly-detailed localized\nwrinkles.\n","authors":["Lei Shu","Vinicius Azevedo","Barbara Solenthaler","Markus Gross"],"pdf_url":"https://arxiv.org/pdf/2311.16344v1.pdf","comment":"16 pages, 13 figures"},{"id":"http://arxiv.org/abs/2301.13098v2","updated":"2023-11-27T22:09:31Z","published":"2023-01-30T17:36:12Z","title":"CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac\n  Anatomy","summary":"  Two key questions in cardiac image analysis are to assess the anatomy and\nmotion of the heart from images; and to understand how they are associated with\nnon-imaging clinical factors such as gender, age and diseases. While the first\nquestion can often be addressed by image segmentation and motion tracking\nalgorithms, our capability to model and to answer the second question is still\nlimited. In this work, we propose a novel conditional generative model to\ndescribe the 4D spatio-temporal anatomy of the heart and its interaction with\nnon-imaging clinical factors. The clinical factors are integrated as the\nconditions of the generative modelling, which allows us to investigate how\nthese factors influence the cardiac anatomy. We evaluate the model performance\nin mainly two tasks, anatomical sequence completion and sequence generation.\nThe model achieves a high performance in anatomical sequence completion,\ncomparable to or outperforming other state-of-the-art generative models. In\nterms of sequence generation, given clinical conditions, the model can generate\nrealistic synthetic 4D sequential anatomies that share similar distributions\nwith the real data.\n","authors":["Mengyun Qiao","Shuo Wang","Huaqi Qiu","Antonio de Marvao","Declan P. O'Regan","Daniel Rueckert","Wenjia Bai"],"pdf_url":"https://arxiv.org/pdf/2301.13098v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.12976v4","updated":"2023-11-27T22:07:04Z","published":"2023-03-23T00:55:48Z","title":"NVAutoNet: Fast and Accurate 360$^{\\circ}$ 3D Visual Perception For Self\n  Driving","summary":"  Achieving robust and real-time 3D perception is fundamental for autonomous\nvehicles. While most existing 3D perception methods prioritize detection\naccuracy, they often overlook critical aspects such as computational\nefficiency, onboard chip deployment friendliness, resilience to sensor mounting\ndeviations, and adaptability to various vehicle types. To address these\nchallenges, we present NVAutoNet: a specialized Bird's-Eye-View (BEV)\nperception network tailored explicitly for automated vehicles. NVAutoNet takes\nsynchronized camera images as input and predicts 3D signals like obstacles,\nfreespaces, and parking spaces. The core of NVAutoNet's architecture (image and\nBEV backbones) relies on efficient convolutional networks, optimized for high\nperformance using TensorRT. More importantly, our image-to-BEV transformation\nemploys simple linear layers and BEV look-up tables, ensuring rapid inference\nspeed. Trained on an extensive proprietary dataset, NVAutoNet consistently\nachieves elevated perception accuracy, operating remarkably at 53 frames per\nsecond on the NVIDIA DRIVE Orin SoC. Notably, NVAutoNet demonstrates resilience\nto sensor mounting deviations arising from diverse car models. Moreover,\nNVAutoNet excels in adapting to varied vehicle types, facilitated by\ninexpensive model fine-tuning procedures that expedite compatibility\nadjustments.\n","authors":["Trung Pham","Mehran Maghoumi","Wanli Jiang","Bala Siva Sashank Jujjavarapu","Mehdi Sajjadi","Xin Liu","Hsuan-Chu Lin","Bor-Jeng Chen","Giang Truong","Chao Fang","Junghyun Kwon","Minwoo Park"],"pdf_url":"https://arxiv.org/pdf/2303.12976v4.pdf","comment":"Accepted to WACV 2024. Link to video\n  https://www.youtube.com/watch?v=cPxVhCJ7kyY"},{"id":"http://arxiv.org/abs/2309.16064v2","updated":"2023-11-27T22:05:53Z","published":"2023-09-27T23:11:35Z","title":"Masked Autoencoders are Scalable Learners of Cellular Morphology","summary":"  Inferring biological relationships from cellular phenotypes in high-content\nmicroscopy screens provides significant opportunity and challenge in biological\nresearch. Prior results have shown that deep vision models can capture\nbiological signal better than hand-crafted features. This work explores how\nself-supervised deep learning approaches scale when training larger models on\nlarger microscopy datasets. Our results show that both CNN- and ViT-based\nmasked autoencoders significantly outperform weakly supervised baselines. At\nthe high-end of our scale, a ViT-L/8 trained on over 3.5-billion unique crops\nsampled from 93-million microscopy images achieves relative improvements as\nhigh as 28% over our best weakly supervised baseline at inferring known\nbiological relationships curated from public databases. Relevant code and\nselect models released with this work can be found at:\nhttps://github.com/recursionpharma/maes_microscopy.\n","authors":["Oren Kraus","Kian Kenyon-Dean","Saber Saberian","Maryam Fallah","Peter McLean","Jess Leung","Vasudev Sharma","Ayla Khan","Jia Balakrishnan","Safiye Celik","Maciej Sypetkowski","Chi Vicky Cheng","Kristen Morse","Maureen Makes","Ben Mabey","Berton Earnshaw"],"pdf_url":"https://arxiv.org/pdf/2309.16064v2.pdf","comment":"Spotlight at NeurIPS 2023 Generative AI and Biology (GenBio) Workshop"},{"id":"http://arxiv.org/abs/2311.16337v1","updated":"2023-11-27T21:53:17Z","published":"2023-11-27T21:53:17Z","title":"Multi-3D-Models Registration-Based Augmented Reality (AR) Instructions\n  for Assembly","summary":"  This paper introduces a novel, markerless, step-by-step, in-situ 3D Augmented\nReality (AR) instruction method and its application - BRICKxAR (Multi 3D\nModels/M3D) - for small parts assembly. BRICKxAR (M3D) realistically visualizes\nrendered 3D assembly parts at the assembly location of the physical assembly\nmodel (Figure 1). The user controls the assembly process through a user\ninterface. BRICKxAR (M3D) utilizes deep learning-trained 3D model-based\nregistration. Object recognition and tracking become challenging as the\nassembly model updates at each step. Additionally, not every part in a 3D\nassembly may be visible to the camera during the assembly. BRICKxAR (M3D)\ncombines multiple assembly phases with a step count to address these\nchallenges. Thus, using fewer phases simplifies the complex assembly process\nwhile step count facilitates accurate object recognition and precise\nvisualization of each step. A testing and heuristic evaluation of the BRICKxAR\n(M3D) prototype and qualitative analysis were conducted with users and experts\nin visualization and human-computer interaction. Providing robust 3D AR\ninstructions and allowing the handling of the assembly model, BRICKxAR (M3D)\nhas the potential to be used at different scales ranging from manufacturing\nassembly to construction.\n","authors":["Seda Tuzun Canadinc","Wei Yan"],"pdf_url":"https://arxiv.org/pdf/2311.16337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16312v1","updated":"2023-11-27T21:01:29Z","published":"2023-11-27T21:01:29Z","title":"Domain-Specific Deep Learning Feature Extractor for Diabetic Foot Ulcer\n  Detection","summary":"  Diabetic Foot Ulcer (DFU) is a condition requiring constant monitoring and\nevaluations for treatment. DFU patient population is on the rise and will soon\noutpace the available health resources. Autonomous monitoring and evaluation of\nDFU wounds is a much-needed area in health care. In this paper, we evaluate and\nidentify the most accurate feature extractor that is the core basis for\ndeveloping a deep-learning wound detection network. For the evaluation, we used\nmAP and F1-score on the publicly available DFU2020 dataset. A combination of\nUNet and EfficientNetb3 feature extractor resulted in the best evaluation among\nthe 14 networks compared. UNet and Efficientnetb3 can be used as the classifier\nin the development of a comprehensive DFU domain-specific autonomous wound\ndetection pipeline.\n","authors":["Reza Basiri","Milos R. Popovic","Shehroz S. Khan"],"pdf_url":"https://arxiv.org/pdf/2311.16312v1.pdf","comment":"5 pages, 2 figures, 3 tables, 2022 IEEE International Conference on\n  Data Mining Workshops"},{"id":"http://arxiv.org/abs/2311.16311v1","updated":"2023-11-27T21:00:20Z","published":"2023-11-27T21:00:20Z","title":"Characterizing Video Question Answering with Sparsified Inputs","summary":"  In Video Question Answering, videos are often processed as a full-length\nsequence of frames to ensure minimal loss of information. Recent works have\ndemonstrated evidence that sparse video inputs are sufficient to maintain high\nperformance. However, they usually discuss the case of single frame selection.\nIn our work, we extend the setting to multiple number of inputs and other\nmodalities. We characterize the task with different input sparsity and provide\na tool for doing that. Specifically, we use a Gumbel-based learnable selection\nmodule to adaptively select the best inputs for the final task. In this way, we\nexperiment over public VideoQA benchmarks and provide analysis on how\nsparsified inputs affect the performance. From our experiments, we have\nobserved only 5.2%-5.8% loss of performance with only 10% of video lengths,\nwhich corresponds to 2-4 frames selected from each video. Meanwhile, we also\nobserved the complimentary behaviour between visual and textual inputs, even\nunder highly sparsified settings, suggesting the potential of improving data\nefficiency for video-and-language tasks.\n","authors":["Shiyuan Huang","Robinson Piramuthu","Vicente Ordonez","Shih-Fu Chang","Gunnar A. Sigurdsson"],"pdf_url":"https://arxiv.org/pdf/2311.16311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16304v1","updated":"2023-11-27T20:36:00Z","published":"2023-11-27T20:36:00Z","title":"Robust Self-calibration of Focal Lengths from the Fundamental Matrix","summary":"  The problem of self-calibration of two cameras from a given fundamental\nmatrix is one of the basic problems in geometric computer vision. Under the\nassumption of known principal points and square pixels, the well-known Bougnoux\nformula offers a means to compute the two unknown focal lengths. However, in\nmany practical situations, the formula yields inaccurate results due to\ncommonly occurring singularities. Moreover, the estimates are sensitive to\nnoise in the computed fundamental matrix and to the assumed positions of the\nprincipal points. In this paper, we therefore propose an efficient and robust\niterative method to estimate the focal lengths along with the principal points\nof the cameras given a fundamental matrix and priors for the estimated camera\nparameters. In addition, we study a computationally efficient check of models\ngenerated within RANSAC that improves the accuracy of the estimated models\nwhile reducing the total computational time. Extensive experiments on real and\nsynthetic data show that our iterative method brings significant improvements\nin terms of the accuracy of the estimated focal lengths over the Bougnoux\nformula and other state-of-the-art methods, even when relying on inaccurate\npriors.\n","authors":["Viktor Kocur","Daniel Kyselica","Zuzana Kúkelová"],"pdf_url":"https://arxiv.org/pdf/2311.16304v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16294v1","updated":"2023-11-27T20:13:15Z","published":"2023-11-27T20:13:15Z","title":"Aligning Non-Causal Factors for Transformer-Based Source-Free Domain\n  Adaptation","summary":"  Conventional domain adaptation algorithms aim to achieve better\ngeneralization by aligning only the task-discriminative causal factors between\na source and target domain. However, we find that retaining the spurious\ncorrelation between causal and non-causal factors plays a vital role in\nbridging the domain gap and improving target adaptation. Therefore, we propose\nto build a framework that disentangles and supports causal factor alignment by\naligning the non-causal factors first. We also investigate and find that the\nstrong shape bias of vision transformers, coupled with its multi-head\nattention, make it a suitable architecture for realizing our proposed\ndisentanglement. Hence, we propose to build a Causality-enforcing Source-Free\nTransformer framework (C-SFTrans) to achieve disentanglement via a novel\ntwo-stage alignment approach: a) non-causal factor alignment: non-causal\nfactors are aligned using a style classification task which leads to an overall\nglobal alignment, b) task-discriminative causal factor alignment: causal\nfactors are aligned via target adaptation. We are the first to investigate the\nrole of vision transformers (ViTs) in a privacy-preserving source-free setting.\nOur approach achieves state-of-the-art results in several DA benchmarks.\n","authors":["Sunandini Sanyal","Ashish Ramayee Asokan","Suvaansh Bhambri","Pradyumna YM","Akshay Kulkarni","Jogendra Nath Kundu","R Venkatesh Babu"],"pdf_url":"https://arxiv.org/pdf/2311.16294v1.pdf","comment":"WACV 2024. Project Page: https://val.cds.iisc.ac.in/C-SFTrans/"},{"id":"http://arxiv.org/abs/2310.14045v2","updated":"2023-11-27T19:43:36Z","published":"2023-10-21T15:43:24Z","title":"Training Image Derivatives: Increased Accuracy and Universal Robustness","summary":"  Derivative training is a known method that significantly improves the\naccuracy of neural networks in some low-dimensional applications. In this\npaper, a similar improvement is obtained for an image analysis problem:\nreconstructing the vertices of a cube from its image. By training the\nderivatives with respect to the 6 degrees of freedom of the cube, we obtain 25\ntimes more accurate results for noiseless inputs. The derivatives also offer\ninsight into the robustness problem, which is currently understood in terms of\ntwo types of network vulnerabilities. The first type involves small\nperturbations that dramatically change the output, and the second type relates\nto substantial image changes that the network erroneously ignores. Defense\nagainst each is possible, but safeguarding against both while maintaining the\naccuracy defies conventional training methods. The first type is analyzed using\nthe network's gradient, while the second relies on human input evaluation,\nserving as an oracle substitute. For the task at hand, the nearest neighbor\noracle can be defined and expanded into Taylor series using image derivatives.\nThis allows for a robustness analysis that unifies both types of\nvulnerabilities and enables training where accuracy and universal robustness\nare limited only by network capacity.\n","authors":["Vsevolod I. Avrutskiy"],"pdf_url":"https://arxiv.org/pdf/2310.14045v2.pdf","comment":"converted to two-column format, shortened abstract, improved\n  readability, removed unnecessary graphics, fixed typos"},{"id":"http://arxiv.org/abs/2311.11567v2","updated":"2023-11-27T19:34:25Z","published":"2023-11-20T07:06:31Z","title":"CORE-MM: Complex Open-Ended Reasoning Evaluation For Multi-Modal Large\n  Language Models","summary":"  Multi-modal Large Language Models (MLLMs) are increasingly prominent in the\nfield of artificial intelligence. These models not only excel in traditional\nvision-language tasks but also demonstrate impressive performance in\ncontemporary multi-modal benchmarks. Although many of these benchmarks attempt\nto holistically evaluate MLLMs, they typically concentrate on basic reasoning\ntasks, often yielding only simple yes/no or multi-choice responses. These\nmethods naturally lead to confusion and difficulties in conclusively\ndetermining the reasoning capabilities of MLLMs. To mitigate this issue, we\nmanually curate a benchmark dataset specifically designed for MLLMs, with a\nfocus on complex reasoning tasks. Our benchmark comprises three key reasoning\ncategories: deductive, abductive, and analogical reasoning. The queries in our\ndataset are intentionally constructed to engage the reasoning capabilities of\nMLLMs in the process of generating answers. For a fair comparison across\nvarious MLLMs, we incorporate intermediate reasoning steps into our evaluation\ncriteria. In instances where an MLLM is unable to produce a definitive answer,\nits reasoning ability is evaluated by requesting intermediate reasoning steps.\nIf these steps align with our manual annotations, appropriate scores are\nassigned. This evaluation scheme resembles methods commonly used in human\nassessments, such as exams or assignments, and represents what we consider a\nmore effective assessment technique compared with existing benchmarks. We\nevaluate a selection of representative MLLMs using this rigorously developed\nopen-ended multi-step elaborate reasoning benchmark, designed to challenge and\naccurately measure their reasoning capabilities. The code and data will be\nreleased at https://core-mm.github.io/\n","authors":["Xiaotian Han","Quanzeng You","Yongfei Liu","Wentao Chen","Huangjie Zheng","Khalil Mrini","Xudong Lin","Yiqi Wang","Bohan Zhai","Jianbo Yuan","Heng Wang","Hongxia Yang"],"pdf_url":"https://arxiv.org/pdf/2311.11567v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16278v1","updated":"2023-11-27T19:34:04Z","published":"2023-11-27T19:34:04Z","title":"VehicleGAN: Pair-flexible Pose Guided Image Synthesis for Vehicle\n  Re-identification","summary":"  Vehicle Re-identification (Re-ID) has been broadly studied in the last\ndecade; however, the different camera view angle leading to confused\ndiscrimination in the feature subspace for the vehicles of various poses, is\nstill challenging for the Vehicle Re-ID models in the real world. To promote\nthe Vehicle Re-ID models, this paper proposes to synthesize a large number of\nvehicle images in the target pose, whose idea is to project the vehicles of\ndiverse poses into the unified target pose so as to enhance feature\ndiscrimination. Considering that the paired data of the same vehicles in\ndifferent traffic surveillance cameras might be not available in the real\nworld, we propose the first Pair-flexible Pose Guided Image Synthesis method\nfor Vehicle Re-ID, named as VehicleGAN in this paper, which works for both\nsupervised and unsupervised settings without the knowledge of geometric 3D\nmodels. Because of the feature distribution difference between real and\nsynthetic data, simply training a traditional metric learning based Re-ID model\nwith data-level fusion (i.e., data augmentation) is not satisfactory, therefore\nwe propose a new Joint Metric Learning (JML) via effective feature-level fusion\nfrom both real and synthetic data. Intensive experimental results on the public\nVeRi-776 and VehicleID datasets prove the accuracy and effectiveness of our\nproposed VehicleGAN and JML.\n","authors":["Baolu Li","Ping Liu","Lan Fu","Jinlong Li","Jianwu Fang","Zhigang Xu","Hongkai Yu"],"pdf_url":"https://arxiv.org/pdf/2311.16278v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16261v1","updated":"2023-11-27T19:08:08Z","published":"2023-11-27T19:08:08Z","title":"RelVAE: Generative Pretraining for few-shot Visual Relationship\n  Detection","summary":"  Visual relations are complex, multimodal concepts that play an important role\nin the way humans perceive the world. As a result of their complexity,\nhigh-quality, diverse and large scale datasets for visual relations are still\nabsent. In an attempt to overcome this data barrier, we choose to focus on the\nproblem of few-shot Visual Relationship Detection (VRD), a setting that has\nbeen so far neglected by the community. In this work we present the first\npretraining method for few-shot predicate classification that does not require\nany annotated relations. We achieve this by introducing a generative model that\nis able to capture the variation of semantic, visual and spatial information of\nrelations inside a latent space and later exploiting its representations in\norder to achieve efficient few-shot classification. We construct few-shot\ntraining splits and show quantitative experiments on VG200 and VRD datasets\nwhere our model outperforms the baselines. Lastly we attempt to interpret the\ndecisions of the model by conducting various qualitative experiments.\n","authors":["Sotiris Karapiperis","Markos Diomataris","Vassilis Pitsikalis"],"pdf_url":"https://arxiv.org/pdf/2311.16261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16254v1","updated":"2023-11-27T19:02:17Z","published":"2023-11-27T19:02:17Z","title":"Removing NSFW Concepts from Vision-and-Language Models for Text-to-Image\n  Retrieval and Generation","summary":"  Vision-and-Language models such as CLIP have demonstrated remarkable\neffectiveness across a wide range of tasks. However, these models are typically\ntrained on web-scale data, which can introduce inappropriate content and lead\nto the development of unsafe and biased behavior. This, in turn, hampers their\napplicability in sensitive and trustworthy contexts and could raise significant\nconcern in their adoption. To overcome these limitations, we introduce a\nmethodology to make Vision-and-Language models safer by removing their\nsensitivity to not-safe-for-work concepts. We show how this can be done by\ndistilling from a large language model which converts between safe and unsafe\nsentences and which is fine-tuned starting from just 100 manually-curated\npairs. We conduct extensive experiments on the resulting embedding space for\nboth retrieval and text-to-image generation, where we show that our model can\nalso be properly employed with pre-trained image generators. Our source code\nand trained models are available at: https://github.com/aimagelab/safe-clip.\n","authors":["Samuele Poppi","Tobia Poppi","Federico Cocchi","Marcella Cornia","Lorenzo Baraldi","Rita Cucchiara"],"pdf_url":"https://arxiv.org/pdf/2311.16254v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16241v1","updated":"2023-11-27T19:00:06Z","published":"2023-11-27T19:00:06Z","title":"SemiVL: Semi-Supervised Semantic Segmentation with Vision-Language\n  Guidance","summary":"  In semi-supervised semantic segmentation, a model is trained with a limited\nnumber of labeled images along with a large corpus of unlabeled images to\nreduce the high annotation effort. While previous methods are able to learn\ngood segmentation boundaries, they are prone to confuse classes with similar\nvisual appearance due to the limited supervision. On the other hand,\nvision-language models (VLMs) are able to learn diverse semantic knowledge from\nimage-caption datasets but produce noisy segmentation due to the image-level\ntraining. In SemiVL, we propose to integrate rich priors from VLM pre-training\ninto semi-supervised semantic segmentation to learn better semantic decision\nboundaries. To adapt the VLM from global to local reasoning, we introduce a\nspatial fine-tuning strategy for label-efficient learning. Further, we design a\nlanguage-guided decoder to jointly reason over vision and language. Finally, we\npropose to handle inherent ambiguities in class labels by providing the model\nwith language guidance in the form of class definitions. We evaluate SemiVL on\n4 semantic segmentation datasets, where it significantly outperforms previous\nsemi-supervised methods. For instance, SemiVL improves the state-of-the-art by\n+13.5 mIoU on COCO with 232 annotated images and by +6.1 mIoU on Pascal VOC\nwith 92 labels. Project page: https://github.com/google-research/semivl\n","authors":["Lukas Hoyer","David Joseph Tan","Muhammad Ferjad Naeem","Luc Van Gool","Federico Tombari"],"pdf_url":"https://arxiv.org/pdf/2311.16241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16498v1","updated":"2023-11-27T18:32:31Z","published":"2023-11-27T18:32:31Z","title":"MagicAnimate: Temporally Consistent Human Image Animation using\n  Diffusion Model","summary":"  This paper studies the human image animation task, which aims to generate a\nvideo of a certain reference identity following a particular motion sequence.\nExisting animation works typically employ the frame-warping technique to\nanimate the reference image towards the target motion. Despite achieving\nreasonable results, these approaches face challenges in maintaining temporal\nconsistency throughout the animation due to the lack of temporal modeling and\npoor preservation of reference identity. In this work, we introduce\nMagicAnimate, a diffusion-based framework that aims at enhancing temporal\nconsistency, preserving reference image faithfully, and improving animation\nfidelity. To achieve this, we first develop a video diffusion model to encode\ntemporal information. Second, to maintain the appearance coherence across\nframes, we introduce a novel appearance encoder to retain the intricate details\nof the reference image. Leveraging these two innovations, we further employ a\nsimple video fusion technique to encourage smooth transitions for long video\nanimation. Empirical results demonstrate the superiority of our method over\nbaseline approaches on two benchmarks. Notably, our approach outperforms the\nstrongest baseline by over 38% in terms of video fidelity on the challenging\nTikTok dancing dataset. Code and model will be made available.\n","authors":["Zhongcong Xu","Jianfeng Zhang","Jun Hao Liew","Hanshu Yan","Jia-Wei Liu","Chenxu Zhang","Jiashi Feng","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2311.16498v1.pdf","comment":"Project Page at https://showlab.github.io/magicanimate"},{"id":"http://arxiv.org/abs/2311.16213v1","updated":"2023-11-27T18:22:07Z","published":"2023-11-27T18:22:07Z","title":"Seeing Beyond Cancer: Multi-Institutional Validation of Object\n  Localization and 3D Semantic Segmentation using Deep Learning for Breast MRI","summary":"  The clinical management of breast cancer depends on an accurate understanding\nof the tumor and its anatomical context to adjacent tissues and landmark\nstructures. This context may be provided by semantic segmentation methods;\nhowever, previous works have been largely limited to a singular focus on the\ntumor alone and rarely other tissue types. In contrast, we present a method\nthat exploits tissue-tissue interactions to accurately segment every major\ntissue type in the breast including: chest wall, skin, adipose tissue,\nfibroglandular tissue, vasculature and tumor via standard-of-care Dynamic\nContrast Enhanced MRI. Comparing our method to prior state-of-the-art, we\nachieved a superior Dice score on tumor segmentation while maintaining\ncompetitive performance on other studied tissues across multiple institutions.\nBriefly, our method proceeds by localizing the tumor using 2D object detectors,\nthen segmenting the tumor and surrounding tissues independently using two 3D\nU-nets, and finally integrating these results while mitigating false positives\nby checking for anatomically plausible tissue-tissue contacts. The object\ndetection models were pre-trained on ImageNet and COCO, and operated on MIP\n(maximum intensity projection) images in the axial and sagittal planes,\nestablishing a 3D tumor bounding box. By integrating multiple relevant\nperi-tumoral tissues, our work enables clinical applications in breast cancer\nstaging, prognosis and surgical planning.\n","authors":["Arda Pekis","Vignesh Kannan","Evandros Kaklamanos","Anu Antony","Snehal Patel","Tyler Earnest"],"pdf_url":"https://arxiv.org/pdf/2311.16213v1.pdf","comment":"9 pages, 2 figures, to appear in SPIE: Medical Imaging 2024"},{"id":"http://arxiv.org/abs/2311.16516v1","updated":"2023-11-27T18:20:03Z","published":"2023-11-27T18:20:03Z","title":"Segment Every Out-of-Distribution Object","summary":"  Semantic segmentation models, while effective for in-distribution categories,\nface challenges in real-world deployment due to encountering\nout-of-distribution (OoD) objects. Detecting these OoD objects is crucial for\nsafety-critical applications. Existing methods rely on anomaly scores, but\nchoosing a suitable threshold for generating masks presents difficulties and\ncan lead to fragmentation and inaccuracy. This paper introduces a method to\nconvert anomaly Score To segmentation Mask, called S2M, a simple and effective\nframework for OoD detection in semantic segmentation. Unlike assigning anomaly\nscores to pixels, S2M directly segments the entire OoD object. By transforming\nanomaly scores into prompts for a promptable segmentation model, S2M eliminates\nthe need for threshold selection. Extensive experiments demonstrate that S2M\noutperforms the state-of-the-art by approximately 10\\% in IoU and 30\\% in mean\nF1 score, on average, across various benchmarks including Fishyscapes,\nSegment-Me-If-You-Can, and RoadAnomaly datasets.\n","authors":["Wenjie Zhao","Jia Li","Xin Dong","Yu Xiang","Yunhui Guo"],"pdf_url":"https://arxiv.org/pdf/2311.16516v1.pdf","comment":"18 pages, 14 figures"},{"id":"http://arxiv.org/abs/2311.16518v1","updated":"2023-11-27T18:11:19Z","published":"2023-11-27T18:11:19Z","title":"SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution","summary":"  Owe to the powerful generative priors, the pre-trained text-to-image (T2I)\ndiffusion models have become increasingly popular in solving the real-world\nimage super-resolution problem. However, as a consequence of the heavy quality\ndegradation of input low-resolution (LR) images, the destruction of local\nstructures can lead to ambiguous image semantics. As a result, the content of\nreproduced high-resolution image may have semantic errors, deteriorating the\nsuper-resolution performance. To address this issue, we present a\nsemantics-aware approach to better preserve the semantic fidelity of generative\nreal-world image super-resolution. First, we train a degradation-aware prompt\nextractor, which can generate accurate soft and hard semantic prompts even\nunder strong degradation. The hard semantic prompts refer to the image tags,\naiming to enhance the local perception ability of the T2I model, while the soft\nsemantic prompts compensate for the hard ones to provide additional\nrepresentation information. These semantic prompts can encourage the T2I model\nto generate detailed and semantically accurate results. Furthermore, during the\ninference process, we integrate the LR images into the initial sampling noise\nto mitigate the diffusion model's tendency to generate excessive random\ndetails. The experiments show that our method can reproduce more realistic\nimage details and hold better the semantics.\n","authors":["Rongyuan Wu","Tao Yang","Lingchen Sun","Zhengqiang Zhang","Shuai Li","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.16518v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2311.14084v2","updated":"2023-11-27T13:43:19Z","published":"2023-11-23T16:22:58Z","title":"AI-Generated Images Introduce Invisible Relevance Bias to Text-Image\n  Retrieval","summary":"  With the advancement of generation models, AI-generated content (AIGC) is\nbecoming more realistic, flooding the Internet. A recent study suggests that\nthis phenomenon has elevated the issue of source bias in text retrieval for web\nsearches. Specifically, neural retrieval models tend to rank generated texts\nhigher than human-written texts. In this paper, we extend the study of this\nbias to cross-modal retrieval. Firstly, we successfully construct a suitable\nbenchmark to explore the existence of the bias. Subsequent extensive\nexperiments on this benchmark reveal that AI-generated images introduce an\ninvisible relevance bias to text-image retrieval models. Specifically, our\nexperiments show that text-image retrieval models tend to rank the AI-generated\nimages higher than the real images, even though the AI-generated images do not\nexhibit more visually relevant features to the query than real images. This\ninvisible relevance bias is prevalent across retrieval models with varying\ntraining data and architectures. Furthermore, our subsequent exploration\nreveals that the inclusion of AI-generated images in the training data of the\nretrieval models exacerbates the invisible relevance bias. The above phenomenon\ntriggers a vicious cycle, which makes the invisible relevance bias become more\nand more serious. To elucidate the potential causes of invisible relevance and\naddress the aforementioned issues, we introduce an effective training method\naimed at alleviating the invisible relevance bias. Subsequently, we apply our\nproposed debiasing method to retroactively identify the causes of invisible\nrelevance, revealing that the AI-generated images induce the image encoder to\nembed additional information into their representation. This information\nexhibits a certain consistency across generated images with different semantics\nand can make the retriever estimate a higher relevance score.\n","authors":["Shicheng Xu","Danyang Hou","Liang Pang","Jingcheng Deng","Jun Xu","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2311.14084v2.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2311.13534v2","updated":"2023-11-27T02:52:46Z","published":"2023-11-22T17:14:54Z","title":"LM-Cocktail: Resilient Tuning of Language Models via Model Merging","summary":"  The pre-trained language models are continually fine-tuned to better support\ndownstream applications. However, this operation may result in significant\nperformance degeneration on general tasks beyond the targeted domain. To\novercome this problem, we propose a novel method which enables the fine-tuned\nmodel to stay resilient in general perspectives. Our method is conducted in the\nform of model merging (namely LM-Cocktail), where the fine-tuned language model\nis merged with the pre-trained base model or the peer models from other domains\nthrough weighted average. Despite simplicity, LM-Cocktail is surprisingly\neffective: the resulted model is able to achieve a strong empirical performance\nin the whole scope of general tasks while preserving a superior capacity in its\ntargeted domain. We conduct comprehensive experiments with LLama and BGE model\non popular benchmarks, including FLAN, MMLU, MTEB, whose results validate the\nefficacy of our proposed method. The code and checkpoints are available at\nhttps://github.com/FlagOpen/FlagEmbedding/tree/master/LM_Cocktail.\n","authors":["Shitao Xiao","Zheng Liu","Peitian Zhang","Xingrun Xing"],"pdf_url":"https://arxiv.org/pdf/2311.13534v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.10230v3","updated":"2023-11-27T10:38:30Z","published":"2023-07-15T11:49:43Z","title":"Prompt Tuning on Graph-augmented Low-resource Text Classification","summary":"  Text classification is a fundamental problem in information retrieval with\nmany real-world applications, such as predicting the topics of online articles\nand the categories of e-commerce product descriptions. However, low-resource\ntext classification, with no or few labeled samples, presents a serious concern\nfor supervised learning. Meanwhile, many text data are inherently grounded on a\nnetwork structure, such as a hyperlink/citation network for online articles,\nand a user-item purchase network for e-commerce products. These graph\nstructures capture rich semantic relationships, which can potentially augment\nlow-resource text classification. In this paper, we propose a novel model\ncalled Graph-Grounded Pre-training and Prompting (G2P2) to address low-resource\ntext classification in a two-pronged approach. During pre-training, we propose\nthree graph interaction-based contrastive strategies to jointly pre-train a\ngraph-text model; during downstream classification, we explore handcrafted\ndiscrete prompts and continuous prompt tuning for the jointly pre-trained model\nto achieve zero- and few-shot classification, respectively. Moreover, we\nexplore the possibility of employing continuous prompt tuning for zero-shot\ninference. Specifically, we aim to generalize continuous prompts to unseen\nclasses while leveraging a set of base classes. To this end, we extend G2P2\ninto G2P2$^*$, hinging on a new architecture of conditional prompt tuning.\nExtensive experiments on four real-world datasets demonstrate the strength of\nG2P2 in zero- and few-shot low-resource text classification tasks, and\nillustrate the advantage of G2P2$^*$ in dealing with unseen classes.\n","authors":["Zhihao Wen","Yuan Fang"],"pdf_url":"https://arxiv.org/pdf/2307.10230v3.pdf","comment":"14 pages, journal under review. arXiv admin note: substantial text\n  overlap with arXiv:2305.03324"},{"id":"http://arxiv.org/abs/2310.13540v3","updated":"2023-11-27T15:33:04Z","published":"2023-10-20T14:36:09Z","title":"Thoroughly Modeling Multi-domain Pre-trained Recommendation as Language","summary":"  With the thriving of pre-trained language model (PLM) widely verified in\nvarious of NLP tasks, pioneer efforts attempt to explore the possible\ncooperation of the general textual information in PLM with the personalized\nbehavioral information in user historical behavior sequences to enhance\nsequential recommendation (SR). However, despite the commonalities of input\nformat and task goal, there are huge gaps between the behavioral and textual\ninformation, which obstruct thoroughly modeling SR as language modeling via\nPLM. To bridge the gap, we propose a novel Unified pre-trained language model\nenhanced sequential recommendation (UPSR), aiming to build a unified\npre-trained recommendation model for multi-domain recommendation tasks. We\nformally design five key indicators, namely naturalness, domain consistency,\ninformativeness, noise & ambiguity, and text length, to guide the text-item\nadaptation and behavior sequence-text sequence adaptation differently for\npre-training and fine-tuning stages, which are essential but under-explored by\nprevious works. In experiments, we conduct extensive evaluations on seven\ndatasets with both tuning and zero-shot settings and achieve the overall best\nperformance. Comprehensive model analyses also provide valuable insights for\nbehavior modeling via PLM, shedding light on large pre-trained recommendation\nmodels. The source codes will be released in the future.\n","authors":["Zekai Qu","Ruobing Xie","Chaojun Xiao","Yuan Yao","Zhiyuan Liu","Fengzong Lian","Zhanhui Kang","Jie Zhou"],"pdf_url":"https://arxiv.org/pdf/2310.13540v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16075v1","updated":"2023-11-27T18:46:17Z","published":"2023-11-27T18:46:17Z","title":"BioLORD-2023: Semantic Textual Representations Fusing LLM and Clinical\n  Knowledge Graph Insights","summary":"  In this study, we investigate the potential of Large Language Models to\ncomplement biomedical knowledge graphs in the training of semantic models for\nthe biomedical and clinical domains. Drawing on the wealth of the UMLS\nknowledge graph and harnessing cutting-edge Large Language Models, we propose a\nnew state-of-the-art approach for obtaining high-fidelity representations of\nbiomedical concepts and sentences, consisting of three steps: an improved\ncontrastive learning phase, a novel self-distillation phase, and a weight\naveraging phase. Through rigorous evaluations via the extensive BioLORD testing\nsuite and diverse downstream tasks, we demonstrate consistent and substantial\nperformance improvements over the previous state of the art (e.g. +2pts on\nMedSTS, +2.5pts on MedNLI-S, +6.1pts on EHR-Rel-B). Besides our new\nstate-of-the-art biomedical model for English, we also distill and release a\nmultilingual model compatible with 50+ languages and finetuned on 7 European\nlanguages. Many clinical pipelines can benefit from our latest models. Our new\nmultilingual model enables a range of languages to benefit from our\nadvancements in biomedical semantic representation learning, opening a new\navenue for bioinformatics researchers around the world. As a result, we hope to\nsee BioLORD-2023 becoming a precious tool for future biomedical applications.\n","authors":["François Remy","Kris Demuynck","Thomas Demeester"],"pdf_url":"https://arxiv.org/pdf/2311.16075v1.pdf","comment":"Preprint of upcoming journal article"},{"id":"http://arxiv.org/abs/2311.15923v1","updated":"2023-11-27T15:32:52Z","published":"2023-11-27T15:32:52Z","title":"SEINE: SEgment-based Indexing for NEural information retrieval","summary":"  Many early neural Information Retrieval (NeurIR) methods are re-rankers that\nrely on a traditional first-stage retriever due to expensive query time\ncomputations. Recently, representation-based retrievers have gained much\nattention, which learns query representation and document representation\nseparately, making it possible to pre-compute document representations offline\nand reduce the workload at query time. Both dense and sparse\nrepresentation-based retrievers have been explored. However, these methods\nfocus on finding the representation that best represents a text (aka metric\nlearning) and the actual retrieval function that is responsible for similarity\nmatching between query and document is kept at a minimum by using dot product.\nOne drawback is that unlike traditional term-level inverted index, the index\nformed by these embeddings cannot be easily re-used by another retrieval\nmethod. Another drawback is that keeping the interaction at minimum hurts\nretrieval effectiveness. On the contrary, interaction-based retrievers are\nknown for their better retrieval effectiveness. In this paper, we propose a\nnovel SEgment-based Neural Indexing method, SEINE, which provides a general\nindexing framework that can flexibly support a variety of interaction-based\nneural retrieval methods. We emphasize on a careful decomposition of common\ncomponents in existing neural retrieval methods and propose to use\nsegment-level inverted index to store the atomic query-document interaction\nvalues. Experiments on LETOR MQ2007 and MQ2008 datasets show that our indexing\nmethod can accelerate multiple neural retrieval methods up to 28-times faster\nwithout sacrificing much effectiveness.\n","authors":["Sibo Dong","Justin Goldstein","Grace Hui Yang"],"pdf_url":"https://arxiv.org/pdf/2311.15923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15790v1","updated":"2023-11-27T13:04:33Z","published":"2023-11-27T13:04:33Z","title":"A Social-aware Gaussian Pre-trained Model for Effective Cold-start\n  Recommendation","summary":"  The use of pre-training is an emerging technique to enhance a neural model's\nperformance, which has been shown to be effective for many neural language\nmodels such as BERT. This technique has also been used to enhance the\nperformance of recommender systems. In such recommender systems, pre-training\nmodels are used to learn a better initialisation for both users and items.\nHowever, recent existing pre-trained recommender systems tend to only\nincorporate the user interaction data at the pre-training stage, making it\ndifficult to deliver good recommendations, especially when the interaction data\nis sparse. To alleviate this common data sparsity issue, we propose to\npre-train the recommendation model not only with the interaction data but also\nwith other available information such as the social relations among users,\nthereby providing the recommender system with a better initialisation compared\nwith solely relying on the user interaction data. We propose a novel\nrecommendation model, the Social-aware Gaussian Pre-trained model (SGP), which\nencodes the user social relations and interaction data at the pre-training\nstage in a Graph Neural Network (GNN). Afterwards, in the subsequent\nfine-tuning stage, our SGP model adopts a Gaussian Mixture Model (GMM) to\nfactorise these pre-trained embeddings for further training, thereby benefiting\nthe cold-start users from these pre-built social relations. Our extensive\nexperiments on three public datasets show that, in comparison to 16 competitive\nbaselines, our SGP model significantly outperforms the best baseline by upto\n7.7% in terms of NDCG@10. In addition, we show that SGP permits to effectively\nalleviate the cold-start problem, especially when users newly register to the\nsystem through their friends' suggestions.\n","authors":["Siwei Liu","Xi Wang","Craig Macdonald","Iadh Ounis"],"pdf_url":"https://arxiv.org/pdf/2311.15790v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2311.15716v1","updated":"2023-11-27T10:59:16Z","published":"2023-11-27T10:59:16Z","title":"Justifiable Artificial Intelligence: Engineering Large Language Models\n  for Legal Applications","summary":"  In this work, I discuss how Large Language Models can be applied in the legal\ndomain, circumventing their current drawbacks. Despite their large success and\nacceptance, their lack of explainability hinders legal experts to trust in\ntheir output, and this happens rightfully so. However, in this paper, I argue\nin favor of a new view, Justifiable Artificial Intelligence, instead of\nfocusing on Explainable Artificial Intelligence. I discuss in this paper how\ngaining evidence for and against a Large Language Model's output may make their\ngenerated texts more trustworthy - or hold them accountable for misinformation.\n","authors":["Sabine Wehnert"],"pdf_url":"https://arxiv.org/pdf/2311.15716v1.pdf","comment":"12 pages, 2 figures"},{"id":"http://arxiv.org/abs/2311.15689v1","updated":"2023-11-27T10:28:06Z","published":"2023-11-27T10:28:06Z","title":"Two Approaches to the Identity of Processes in BFO","summary":"  This paper aims to explore processes and their identity with a focus on the\nupper ontology Basic Formal Ontology (BFO). We begin with a classification\nbased on two basic classes of changes of independent continuants: changes with\nrespect to a single specifically dependent continuant thereof or with respect\nto the spatial region that its parts occupy. We accordingly distinguish two\nkinds of simple processes: specifically dependent continuant changes and\nspatial changes. Next, we investigate a compositional approach to the identity\nof processes: the identity of any process is determined by the identity of the\nsimple processes that compose them. Then, we consider a causal approach to the\nidentity of processes with recourse to a dispositional view of processes\naccording to which any process is a realization of some disposition. We also\nexamine assumptions on which these two approaches to the identity of processes\nare based.\n","authors":["Fumiaki Toyoshima","Adrien Barton"],"pdf_url":"https://arxiv.org/pdf/2311.15689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15578v1","updated":"2023-11-27T07:11:47Z","published":"2023-11-27T07:11:47Z","title":"Experimental Analysis of Large-scale Learnable Vector Storage\n  Compression","summary":"  Learnable embedding vector is one of the most important applications in\nmachine learning, and is widely used in various database-related domains.\nHowever, the high dimensionality of sparse data in recommendation tasks and the\nhuge volume of corpus in retrieval-related tasks lead to a large memory\nconsumption of the embedding table, which poses a great challenge to the\ntraining and deployment of models. Recent research has proposed various methods\nto compress the embeddings at the cost of a slight decrease in model quality or\nthe introduction of other overheads. Nevertheless, the relative performance of\nthese methods remains unclear. Existing experimental comparisons only cover a\nsubset of these methods and focus on limited metrics. In this paper, we perform\na comprehensive comparative analysis and experimental evaluation of embedding\ncompression. We introduce a new taxonomy that categorizes these techniques\nbased on their characteristics and methodologies, and further develop a modular\nbenchmarking framework that integrates 14 representative methods. Under a\nuniform test environment, our benchmark fairly evaluates each approach,\npresents their strengths and weaknesses under different memory budgets, and\nrecommends the best method based on the use case. In addition to providing\nuseful guidelines, our study also uncovers the limitations of current methods\nand suggests potential directions for future research.\n","authors":["Hailin Zhang","Penghao Zhao","Xupeng Miao","Yingxia Shao","Zirui Liu","Tong Yang","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2311.15578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15564v1","updated":"2023-11-27T06:22:57Z","published":"2023-11-27T06:22:57Z","title":"Boot and Switch: Alternating Distillation for Zero-Shot Dense Retrieval","summary":"  Neural 'dense' retrieval models are state of the art for many datasets,\nhowever these models often exhibit limited domain transfer ability. Existing\napproaches to adaptation are unwieldy, such as requiring explicit supervision,\ncomplex model architectures, or massive external models. We present\n$\\texttt{ABEL}$, a simple but effective unsupervised method to enhance passage\nretrieval in zero-shot settings. Our technique follows a straightforward loop:\na dense retriever learns from supervision signals provided by a reranker, and\nsubsequently, the reranker is updated based on feedback from the improved\nretriever. By iterating this loop, the two components mutually enhance one\nanother's performance. Experimental results demonstrate that our unsupervised\n$\\texttt{ABEL}$ model outperforms both leading supervised and unsupervised\nretrievers on the BEIR benchmark. Meanwhile, it exhibits strong adaptation\nabilities to tasks and domains that were unseen during training. By either\nfine-tuning $\\texttt{ABEL}$ on labelled data or integrating it with existing\nsupervised dense retrievers, we achieve state-of-the-art\nresults.\\footnote{Source code is available at\n\\url{https://github.com/Fantabulous-J/BootSwitch}.}\n","authors":["Fan Jiang","Qiongkai Xu","Tom Drummond","Trevor Cohn"],"pdf_url":"https://arxiv.org/pdf/2311.15564v1.pdf","comment":"Accepted by EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2311.15563v1","updated":"2023-11-27T06:19:50Z","published":"2023-11-27T06:19:50Z","title":"Noisy Self-Training with Synthetic Queries for Dense Retrieval","summary":"  Although existing neural retrieval models reveal promising results when\ntraining data is abundant and the performance keeps improving as training data\nincreases, collecting high-quality annotated data is prohibitively costly. To\nthis end, we introduce a novel noisy self-training framework combined with\nsynthetic queries, showing that neural retrievers can be improved in a\nself-evolution manner with no reliance on any external models. Experimental\nresults show that our method improves consistently over existing methods on\nboth general-domain (e.g., MS-MARCO) and out-of-domain (i.e., BEIR) retrieval\nbenchmarks. Extra analysis on low-resource settings reveals that our method is\ndata efficient and outperforms competitive baselines, with as little as 30% of\nlabelled training data. Further extending the framework for reranker training\ndemonstrates that the proposed method is general and yields additional gains on\ntasks of diverse domains.\\footnote{Source code is available at\n\\url{https://github.com/Fantabulous-J/Self-Training-DPR}}\n","authors":["Fan Jiang","Tom Drummond","Trevor Cohn"],"pdf_url":"https://arxiv.org/pdf/2311.15563v1.pdf","comment":"Accepted by EMNLP 2023 Findings"},{"id":"http://arxiv.org/abs/2311.15493v1","updated":"2023-11-27T02:30:39Z","published":"2023-11-27T02:30:39Z","title":"UFIN: Universal Feature Interaction Network for Multi-Domain\n  Click-Through Rate Prediction","summary":"  Click-Through Rate (CTR) prediction, which aims to estimate the probability\nof a user clicking on an item, is a key task in online advertising. Numerous\nexisting CTR models concentrate on modeling the feature interactions within a\nsolitary domain, thereby rendering them inadequate for fulfilling the\nrequisites of multi-domain recommendations in real industrial scenarios. Some\nrecent approaches propose intricate architectures to enhance knowledge sharing\nand augment model training across multiple domains. However, these approaches\nencounter difficulties when being transferred to new recommendation domains,\nowing to their reliance on the modeling of ID features (e.g., item id). To\naddress the above issue, we propose the Universal Feature Interaction Network\n(UFIN) approach for CTR prediction. UFIN exploits textual data to learn\nuniversal feature interactions that can be effectively transferred across\ndiverse domains. For learning universal feature representations, we regard the\ntext and feature as two different modalities and propose an encoder-decoder\nnetwork founded on a Large Language Model (LLM) to enforce the transfer of data\nfrom the text modality to the feature modality. Building upon the above\nfoundation, we further develop a mixtureof-experts (MoE) enhanced adaptive\nfeature interaction model to learn transferable collaborative patterns across\nmultiple domains. Furthermore, we propose a multi-domain knowledge distillation\nframework to enhance feature interaction learning. Based on the above methods,\nUFIN can effectively bridge the semantic gap to learn common knowledge across\nvarious domains, surpassing the constraints of ID-based models. Extensive\nexperiments conducted on eight datasets show the effectiveness of UFIN, in both\nmultidomain and cross-platform settings. Our code is available at\nhttps://github.com/RUCAIBox/UFIN.\n","authors":["Zhen Tian","Changwang Zhang","Wayne Xin Zhao","Xin Zhao","Ji-Rong Wen","Zhao Cao"],"pdf_url":"https://arxiv.org/pdf/2311.15493v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16334v1","updated":"2023-11-27T21:38:10Z","published":"2023-11-27T21:38:10Z","title":"Robust Basket Recommendation via Noise-tolerated Graph Contrastive\n  Learning","summary":"  The growth of e-commerce has seen a surge in popularity of platforms like\nAmazon, eBay, and Taobao. This has given rise to a unique shopping behavior\ninvolving baskets - sets of items purchased together. As a less studied\ninteraction mode in the community, the question of how should shopping basket\ncomplement personalized recommendation systems remains under-explored. While\nprevious attempts focused on jointly modeling user purchases and baskets, the\ndistinct semantic nature of these elements can introduce noise when directly\nintegrated. This noise negatively impacts the model's performance, further\nexacerbated by significant noise within both user and basket behaviors.\n  In order to cope with the above difficulties, we propose a novel Basket\nrecommendation framework via Noise-tolerated Contrastive Learning, named BNCL,\nto handle the noise existing in the cross-behavior integration and\nwithin-behavior modeling. First, we represent the basket-item interactions as\nthe hypergraph to model the complex basket behavior, where all items appearing\nin the same basket are treated as a single hyperedge. Second, cross-behavior\ncontrastive learning is designed to suppress the noise during the fusion of\ndiverse behaviors. Next, to further inhibit the within-behavior noise of the\nuser and basket interactions, we propose to exploit invariant properties of the\nrecommenders w.r.t augmentations through within-behavior contrastive learning.\nA novel consistency-aware augmentation approach is further designed to better\nidentify noisy interactions with the consideration of the above two types of\ninteractions. Our framework BNCL offers a generic training paradigm that is\napplicable to different backbones. Extensive experiments on three shopping\ntransaction datasets verify the effectiveness of our proposed method. Our code\nis available.\n","authors":["Xinrui He","Tianxin Wei","Jingrui He"],"pdf_url":"https://arxiv.org/pdf/2311.16334v1.pdf","comment":"CIKM 2023"},{"id":"http://arxiv.org/abs/2212.09744v2","updated":"2023-11-27T19:57:09Z","published":"2022-12-19T18:59:34Z","title":"DSI++: Updating Transformer Memory with New Documents","summary":"  Differentiable Search Indices (DSIs) encode a corpus of documents in model\nparameters and use the same model to answer user queries directly. Despite the\nstrong performance of DSI models, deploying them in situations where the corpus\nchanges over time is computationally expensive because reindexing the corpus\nrequires re-training the model. In this work, we introduce DSI++, a continual\nlearning challenge for DSI to incrementally index new documents while being\nable to answer queries related to both previously and newly indexed documents.\nAcross different model scales and document identifier representations, we show\nthat continual indexing of new documents leads to considerable forgetting of\npreviously indexed documents. We also hypothesize and verify that the model\nexperiences forgetting events during training, leading to unstable learning. To\nmitigate these issues, we investigate two approaches. The first focuses on\nmodifying the training dynamics. Flatter minima implicitly alleviate\nforgetting, so we optimize for flatter loss basins and show that the model\nstably memorizes more documents ($+12\\%$). Next, we introduce a generative\nmemory to sample pseudo-queries for documents and supplement them during\ncontinual indexing to prevent forgetting for the retrieval task. Extensive\nexperiments on novel continual indexing benchmarks based on Natural Questions\n(NQ) and MS MARCO demonstrate that our proposed solution mitigates forgetting\nsignificantly. Concretely, it improves the average Hits@10 by $+21.1\\%$ over\ncompetitive baselines for NQ and requires $6$ times fewer model updates\ncompared to re-training the DSI model for incrementally indexing five corpora\nin a sequence.\n","authors":["Sanket Vaibhav Mehta","Jai Gupta","Yi Tay","Mostafa Dehghani","Vinh Q. Tran","Jinfeng Rao","Marc Najork","Emma Strubell","Donald Metzler"],"pdf_url":"https://arxiv.org/pdf/2212.09744v2.pdf","comment":"Accepted at EMNLP 2023 main conference"},{"id":"http://arxiv.org/abs/2311.16207v1","updated":"2023-11-27T15:34:14Z","published":"2023-11-27T15:34:14Z","title":"The Graph Convolutional Network with Multi-representation Alignment for\n  Drug Synergy Prediction","summary":"  Drug combination refers to the use of two or more drugs to treat a specific\ndisease at the same time. It is currently the mainstream way to treat complex\ndiseases. Compared with single drugs, drug combinations have better efficacy\nand can better inhibit toxicity and drug resistance. The computational model\nbased on deep learning concatenates the representation of multiple drugs and\nthe corresponding cell line feature as input, and the output is whether the\ndrug combination can have an inhibitory effect on the cell line. However, this\nstrategy of concatenating multiple representations has the following defects:\nthe alignment of drug representation and cell line representation is ignored,\nresulting in the synergistic relationship not being reflected positionally in\nthe embedding space. Moreover, the alignment measurement function in deep\nlearning cannot be suitable for drug synergy prediction tasks due to\ndifferences in input types. Therefore, in this work, we propose a graph\nconvolutional network with multi-representation alignment (GCNMRA) for\npredicting drug synergy. In the GCNMRA model, we designed a\nmulti-representation alignment function suitable for the drug synergy\nprediction task so that the positional relationship between drug\nrepresentations and cell line representation is reflected in the embedding\nspace. In addition, the vector modulus of drug representations and cell line\nrepresentation is considered to improve the accuracy of calculation results and\naccelerate model convergence. Finally, many relevant experiments were run on\nmultiple drug synergy datasets to verify the effectiveness of the above\ninnovative elements and the excellence of the GCNMRA model.\n","authors":["Xinxing Yang","Genke Yang","Jian Chu"],"pdf_url":"https://arxiv.org/pdf/2311.16207v1.pdf","comment":"14 pages;"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2311.14468v2","updated":"2023-11-27T08:04:04Z","published":"2023-11-24T13:21:35Z","title":"Efficient Gradient Estimation via Adaptive Sampling and Importance\n  Sampling","summary":"  Machine learning problems rely heavily on stochastic gradient descent (SGD)\nfor optimization. The effectiveness of SGD is contingent upon accurately\nestimating gradients from a mini-batch of data samples. Instead of the commonly\nused uniform sampling, adaptive or importance sampling reduces noise in\ngradient estimation by forming mini-batches that prioritize crucial data\npoints. Previous research has suggested that data points should be selected\nwith probabilities proportional to their gradient norm. Nevertheless, existing\nalgorithms have struggled to efficiently integrate importance sampling into\nmachine learning frameworks. In this work, we make two contributions. First, we\npresent an algorithm that can incorporate existing importance functions into\nour framework. Second, we propose a simplified importance function that relies\nsolely on the loss gradient of the output layer. By leveraging our proposed\ngradient estimation techniques, we observe improved convergence in\nclassification and regression tasks with minimal computational overhead. We\nvalidate the effectiveness of our adaptive and importance-sampling approach on\nimage and point-cloud datasets.\n","authors":["Corentin Salaün","Xingchang Huang","Iliyan Georgiev","Niloy J. Mitra","Gurprit Singh"],"pdf_url":"https://arxiv.org/pdf/2311.14468v2.pdf","comment":"15 pages, 10 figures"},{"id":"http://arxiv.org/abs/2311.14412v2","updated":"2023-11-27T07:20:42Z","published":"2023-11-24T11:12:26Z","title":"A Comparison of PDF Projection with Normalizing Flows and SurVAE","summary":"  Normalizing flows (NF) recently gained attention as a way to construct\ngenerative networks with exact likelihood calculation out of composable layers.\nHowever, NF is restricted to dimension-preserving transformations. Surjection\nVAE (SurVAE) has been proposed to extend NF to dimension-altering\ntransformations. Such networks are desirable because they are expressive and\ncan be precisely trained. We show that the approaches are a re-invention of PDF\nprojection, which appeared over twenty years earlier and is much further\ndeveloped.\n","authors":["Paul M. Baggenstoss","Felix Govaers"],"pdf_url":"https://arxiv.org/pdf/2311.14412v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12612v3","updated":"2023-11-27T07:41:06Z","published":"2023-11-21T13:54:08Z","title":"A New Type Of Upper And Lower Bounds On Right-Tail Probabilities Of\n  Continuous Random Variables","summary":"  In this paper, I present a completely new type of upper and lower bounds on\nthe right-tail probabilities of continuous random variables with unbounded\nsupport and with semi-bounded support from the left. The presented upper and\nlower right-tail bounds depend only on the probability density function (PDF),\nits first derivative, and two parameters that are used for tightening the\nbounds. These tail bounds hold under certain conditions that depend on the PDF,\nits first and second derivatives, and the two parameters. The new tail bounds\nare shown to be tight for a wide range of continuous random variables via\nnumerical examples.\n","authors":["Nikola Zlatanov"],"pdf_url":"https://arxiv.org/pdf/2311.12612v3.pdf","comment":"Minor typos corrected v2"},{"id":"http://arxiv.org/abs/2311.14078v2","updated":"2023-11-27T18:31:15Z","published":"2023-11-23T16:12:00Z","title":"Machine learning-based decentralized TDMA for VLC IoT networks","summary":"  In this paper, a machine learning-based decentralized time division multiple\naccess (TDMA) algorithm for visible light communication (VLC) Internet of\nThings (IoT) networks is proposed. The proposed algorithm is based on\nQ-learning, a reinforcement learning algorithm. This paper considers a\ndecentralized condition in which there is no coordinator node for sending\nsynchronization frames and assigning transmission time slots to other nodes.\nThe proposed algorithm uses a decentralized manner for synchronization, and\neach node uses the Q-learning algorithm to find the optimal transmission time\nslot for sending data without collisions. The proposed algorithm is implemented\non a VLC hardware system, which had been designed and implemented in our\nlaboratory. Average reward, convergence time, goodput, average delay, and data\npacket size are evaluated parameters. The results show that the proposed\nalgorithm converges quickly and provides collision-free decentralized TDMA for\nthe network. The proposed algorithm is compared with carrier-sense multiple\naccess with collision avoidance (CSMA/CA) algorithm as a potential selection\nfor decentralized VLC IoT networks. The results show that the proposed\nalgorithm provides up to 61% more goodput and up to 49% less average delay than\nCSMA/CA.\n","authors":["Armin Makvandi","Yousef Seifi Kavian"],"pdf_url":"https://arxiv.org/pdf/2311.14078v2.pdf","comment":"This work has been submitted to a journal for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2311.13959v2","updated":"2023-11-27T09:47:10Z","published":"2023-11-23T12:17:45Z","title":"RankFeat&RankWeight: Rank-1 Feature/Weight Removal for\n  Out-of-distribution Detection","summary":"  The task of out-of-distribution (OOD) detection is crucial for deploying\nmachine learning models in real-world settings. In this paper, we observe that\nthe singular value distributions of the in-distribution (ID) and OOD features\nare quite different: the OOD feature matrix tends to have a larger dominant\nsingular value than the ID feature, and the class predictions of OOD samples\nare largely determined by it. This observation motivates us to propose\n\\texttt{RankFeat}, a simple yet effective \\emph{post hoc} approach for OOD\ndetection by removing the rank-1 matrix composed of the largest singular value\nand the associated singular vectors from the high-level feature.\n\\texttt{RankFeat} achieves \\emph{state-of-the-art} performance and reduces the\naverage false positive rate (FPR95) by 17.90\\% compared with the previous best\nmethod. The success of \\texttt{RankFeat} motivates us to investigate whether a\nsimilar phenomenon would exist in the parameter matrices of neural networks. We\nthus propose \\texttt{RankWeight} which removes the rank-1 weight from the\nparameter matrices of a single deep layer. Our \\texttt{RankWeight}is also\n\\emph{post hoc} and only requires computing the rank-1 matrix once. As a\nstandalone approach, \\texttt{RankWeight} has very competitive performance\nagainst other methods across various backbones. Moreover, \\texttt{RankWeight}\nenjoys flexible compatibility with a wide range of OOD detection methods. The\ncombination of \\texttt{RankWeight} and \\texttt{RankFeat} refreshes the new\n\\emph{state-of-the-art} performance, achieving the FPR95 as low as 16.13\\% on\nthe ImageNet-1k benchmark. Extensive ablation studies and comprehensive\ntheoretical analyses are presented to support the empirical results.\n","authors":["Yue Song","Nicu Sebe","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2311.13959v2.pdf","comment":"submitted to T-PAMI. arXiv admin note: substantial text overlap with\n  arXiv:2209.08590"},{"id":"http://arxiv.org/abs/2311.09740v3","updated":"2023-11-27T03:09:21Z","published":"2023-11-16T10:13:09Z","title":"Redefining Super-Resolution: Fine-mesh PDE predictions without classical\n  simulations","summary":"  In Computational Fluid Dynamics (CFD), coarse mesh simulations offer\ncomputational efficiency but often lack precision. Applying conventional\nsuper-resolution to these simulations poses a significant challenge due to the\nfundamental contrast between downsampling high-resolution images and\nauthentically emulating low-resolution physics. The former method conserves\nmore of the underlying physics, surpassing the usual constraints of real-world\nscenarios. We propose a novel definition of super-resolution tailored for\nPDE-based problems. Instead of simply downsampling from a high-resolution\ndataset, we use coarse-grid simulated data as our input and predict fine-grid\nsimulated outcomes. Employing a physics-infused UNet upscaling method, we\ndemonstrate its efficacy across various 2D-CFD problems such as discontinuity\ndetection in Burger's equation, Methane combustion, and fouling in Industrial\nheat exchangers. Our method enables the generation of fine-mesh solutions\nbypassing traditional simulation, ensuring considerable computational saving\nand fidelity to the original ground truth outcomes. Through diverse boundary\nconditions during training, we further establish the robustness of our method,\npaving the way for its broad applications in engineering and scientific CFD\nsolvers.\n","authors":["Rajat Kumar Sarkar","Ritam Majumdar","Vishal Jadhav","Sagar Srinivas Sakhinana","Venkataramana Runkana"],"pdf_url":"https://arxiv.org/pdf/2311.09740v3.pdf","comment":"Accepted at Machine Learning and the Physical Sciences Workshop,\n  NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.16102v1","updated":"2023-11-27T18:59:53Z","published":"2023-11-27T18:59:53Z","title":"Test-time Adaptation of Discriminative Models via Diffusion Generative\n  Feedback","summary":"  The advancements in generative modeling, particularly the advent of diffusion\nmodels, have sparked a fundamental question: how can these models be\neffectively used for discriminative tasks? In this work, we find that\ngenerative models can be great test-time adapters for discriminative models.\nOur method, Diffusion-TTA, adapts pre-trained discriminative models such as\nimage classifiers, segmenters and depth predictors, to each unlabelled example\nin the test set using generative feedback from a diffusion model. We achieve\nthis by modulating the conditioning of the diffusion model using the output of\nthe discriminative model. We then maximize the image likelihood objective by\nbackpropagating the gradients to discriminative model's parameters. We show\nDiffusion-TTA significantly enhances the accuracy of various large-scale\npre-trained discriminative models, such as, ImageNet classifiers, CLIP models,\nimage pixel labellers and image depth predictors. Diffusion-TTA outperforms\nexisting test-time adaptation methods, including TTT-MAE and TENT, and\nparticularly shines in online adaptation setups, where the discriminative model\nis continually adapted to each example in the test set. We provide access to\ncode, results, and visualizations on our website:\nhttps://diffusion-tta.github.io/.\n","authors":["Mihir Prabhudesai","Tsung-Wei Ke","Alexander C. Li","Deepak Pathak","Katerina Fragkiadaki"],"pdf_url":"https://arxiv.org/pdf/2311.16102v1.pdf","comment":"Accepted at NeurIPS 2023 Webpage with Code:\n  https://diffusion-tta.github.io/"},{"id":"http://arxiv.org/abs/2311.16101v1","updated":"2023-11-27T18:59:42Z","published":"2023-11-27T18:59:42Z","title":"How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for\n  Vision LLMs","summary":"  This work focuses on the potential of Vision LLMs (VLLMs) in visual\nreasoning. Different from prior studies, we shift our focus from evaluating\nstandard performance to introducing a comprehensive safety evaluation suite,\ncovering both out-of-distribution (OOD) generalization and adversarial\nrobustness. For the OOD evaluation, we present two novel VQA datasets, each\nwith one variant, designed to test model performance under challenging\nconditions. In exploring adversarial robustness, we propose a straightforward\nattack strategy for misleading VLLMs to produce visual-unrelated responses.\nMoreover, we assess the efficacy of two jailbreaking strategies, targeting\neither the vision or language component of VLLMs. Our evaluation of 21 diverse\nmodels, ranging from open-source VLLMs to GPT-4V, yields interesting\nobservations: 1) Current VLLMs struggle with OOD texts but not images, unless\nthe visual information is limited; and 2) These VLLMs can be easily misled by\ndeceiving vision encoders only, and their vision-language training often\ncompromise safety protocols. We release this safety evaluation suite at\nhttps://github.com/UCSC-VLAA/vllm-safety-benchmark.\n","authors":["Haoqin Tu","Chenhang Cui","Zijun Wang","Yiyang Zhou","Bingchen Zhao","Junlin Han","Wangchunshu Zhou","Huaxiu Yao","Cihang Xie"],"pdf_url":"https://arxiv.org/pdf/2311.16101v1.pdf","comment":"H.T., C.C., and Z.W. contribute equally. Work done during H.T. and\n  Z.W.'s internship at UCSC, and C.C. and Y.Z.'s internship at UNC"},{"id":"http://arxiv.org/abs/2311.16098v1","updated":"2023-11-27T18:59:25Z","published":"2023-11-27T18:59:25Z","title":"On Bringing Robots Home","summary":"  Throughout history, we have successfully integrated various machines into our\nhomes. Dishwashers, laundry machines, stand mixers, and robot vacuums are a few\nrecent examples. However, these machines excel at performing only a single task\neffectively. The concept of a \"generalist machine\" in homes - a domestic\nassistant that can adapt and learn from our needs, all while remaining\ncost-effective - has long been a goal in robotics that has been steadily\npursued for decades. In this work, we initiate a large-scale effort towards\nthis goal by introducing Dobb-E, an affordable yet versatile general-purpose\nsystem for learning robotic manipulation within household settings. Dobb-E can\nlearn a new task with only five minutes of a user showing it how to do it,\nthanks to a demonstration collection tool (\"The Stick\") we built out of cheap\nparts and iPhones. We use the Stick to collect 13 hours of data in 22 homes of\nNew York City, and train Home Pretrained Representations (HPR). Then, in a\nnovel home environment, with five minutes of demonstrations and fifteen minutes\nof adapting the HPR model, we show that Dobb-E can reliably solve the task on\nthe Stretch, a mobile robot readily available on the market. Across roughly 30\ndays of experimentation in homes of New York City and surrounding areas, we\ntest our system in 10 homes, with a total of 109 tasks in different\nenvironments, and finally achieve a success rate of 81%. Beyond success\npercentages, our experiments reveal a plethora of unique challenges absent or\nignored in lab robotics. These range from effects of strong shadows, to\nvariable demonstration quality by non-expert users. With the hope of\naccelerating research on home robots, and eventually seeing robot butlers in\nevery home, we open-source Dobb-E software stack and models, our data, and our\nhardware designs at https://dobb-e.com\n","authors":["Nur Muhammad Mahi Shafiullah","Anant Rai","Haritheja Etukuru","Yiqian Liu","Ishan Misra","Soumith Chintala","Lerrel Pinto"],"pdf_url":"https://arxiv.org/pdf/2311.16098v1.pdf","comment":"Project website and videos are available at https://dobb-e.com,\n  technical documentation for getting started is available at\n  https://docs.dobb-e.com, and code is released at\n  https://github.com/notmahi/dobb-e"},{"id":"http://arxiv.org/abs/2311.16093v1","updated":"2023-11-27T18:58:34Z","published":"2023-11-27T18:58:34Z","title":"Have we built machines that think like people?","summary":"  A chief goal of artificial intelligence is to build machines that think like\npeople. Yet it has been argued that deep neural network architectures fail to\naccomplish this. Researchers have asserted these models' limitations in the\ndomains of causal reasoning, intuitive physics, and intuitive psychology. Yet\nrecent advancements, namely the rise of large language models, particularly\nthose designed for visual processing, have rekindled interest in the potential\nto emulate human-like cognitive abilities. This paper evaluates the current\nstate of vision-based large language models in the domains of intuitive\nphysics, causal reasoning, and intuitive psychology. Through a series of\ncontrolled experiments, we investigate the extent to which these modern models\ngrasp complex physical interactions, causal relationships, and intuitive\nunderstanding of others' preferences. Our findings reveal that, while these\nmodels demonstrate a notable proficiency in processing and interpreting visual\ndata, they still fall short of human capabilities in these areas. The models\nexhibit a rudimentary understanding of physical laws and causal relationships,\nbut their performance is hindered by a lack of deeper insights-a key aspect of\nhuman cognition. Furthermore, in tasks requiring an intuitive theory of mind,\nthe models fail altogether. Our results emphasize the need for integrating more\nrobust mechanisms for understanding causality, physical dynamics, and social\ncognition into modern-day, vision-based language models, and point out the\nimportance of cognitively-inspired benchmarks.\n","authors":["Luca M. Schulze Buschoff","Elif Akata","Matthias Bethge","Eric Schulz"],"pdf_url":"https://arxiv.org/pdf/2311.16093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16091v1","updated":"2023-11-27T18:57:42Z","published":"2023-11-27T18:57:42Z","title":"Interactive Autonomous Navigation with Internal State Inference and\n  Interactivity Estimation","summary":"  Deep reinforcement learning (DRL) provides a promising way for intelligent\nagents (e.g., autonomous vehicles) to learn to navigate complex scenarios.\nHowever, DRL with neural networks as function approximators is typically\nconsidered a black box with little explainability and often suffers from\nsuboptimal performance, especially for autonomous navigation in highly\ninteractive multi-agent environments. To address these issues, we propose three\nauxiliary tasks with spatio-temporal relational reasoning and integrate them\ninto the standard DRL framework, which improves the decision making performance\nand provides explainable intermediate indicators. We propose to explicitly\ninfer the internal states (i.e., traits and intentions) of surrounding agents\n(e.g., human drivers) as well as to predict their future trajectories in the\nsituations with and without the ego agent through counterfactual reasoning.\nThese auxiliary tasks provide additional supervision signals to infer the\nbehavior patterns of other interactive agents. Multiple variants of framework\nintegration strategies are compared. We also employ a spatio-temporal graph\nneural network to encode relations between dynamic entities, which enhances\nboth internal state inference and decision making of the ego agent. Moreover,\nwe propose an interactivity estimation mechanism based on the difference\nbetween predicted trajectories in these two situations, which indicates the\ndegree of influence of the ego agent on other agents. To validate the proposed\nmethod, we design an intersection driving simulator based on the Intelligent\nIntersection Driver Model (IIDM) that simulates vehicles and pedestrians. Our\napproach achieves robust and state-of-the-art performance in terms of standard\nevaluation metrics and provides explainable intermediate indicators (i.e.,\ninternal states, and interactivity scores) for decision making.\n","authors":["Jiachen Li","David Isele","Kanghoon Lee","Jinkyoo Park","Kikuo Fujimura","Mykel J. Kochenderfer"],"pdf_url":"https://arxiv.org/pdf/2311.16091v1.pdf","comment":"18 pages, 14 figures"},{"id":"http://arxiv.org/abs/2311.16086v1","updated":"2023-11-27T18:56:03Z","published":"2023-11-27T18:56:03Z","title":"MAST: Model-Agnostic Sparsified Training","summary":"  We introduce a novel optimization problem formulation that departs from the\nconventional way of minimizing machine learning model loss as a black-box\nfunction. Unlike traditional formulations, the proposed approach explicitly\nincorporates an initially pre-trained model and random sketch operators,\nallowing for sparsification of both the model and gradient during training. We\nestablish insightful properties of the proposed objective function and\nhighlight its connections to the standard formulation. Furthermore, we present\nseveral variants of the Stochastic Gradient Descent (SGD) method adapted to the\nnew problem formulation, including SGD with general sampling, a distributed\nversion, and SGD with variance reduction techniques. We achieve tighter\nconvergence rates and relax assumptions, bridging the gap between theoretical\nprinciples and practical applications, covering several important techniques\nsuch as Dropout and Sparse training. This work presents promising opportunities\nto enhance the theoretical understanding of model training through a\nsparsification-aware optimization approach.\n","authors":["Yury Demidovich","Grigory Malinovsky","Egor Shulgin","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2311.16086v1.pdf","comment":"58 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.16082v1","updated":"2023-11-27T18:52:25Z","published":"2023-11-27T18:52:25Z","title":"Transformer-QEC: Quantum Error Correction Code Decoding with\n  Transferable Transformers","summary":"  Quantum computing has the potential to solve problems that are intractable\nfor classical systems, yet the high error rates in contemporary quantum devices\noften exceed tolerable limits for useful algorithm execution. Quantum Error\nCorrection (QEC) mitigates this by employing redundancy, distributing quantum\ninformation across multiple data qubits and utilizing syndrome qubits to\nmonitor their states for errors. The syndromes are subsequently interpreted by\na decoding algorithm to identify and correct errors in the data qubits. This\ntask is complex due to the multiplicity of error sources affecting both data\nand syndrome qubits as well as syndrome extraction operations. Additionally,\nidentical syndromes can emanate from different error sources, necessitating a\ndecoding algorithm that evaluates syndromes collectively. Although machine\nlearning (ML) decoders such as multi-layer perceptrons (MLPs) and convolutional\nneural networks (CNNs) have been proposed, they often focus on local syndrome\nregions and require retraining when adjusting for different code distances. We\nintroduce a transformer-based QEC decoder which employs self-attention to\nachieve a global receptive field across all input syndromes. It incorporates a\nmixed loss training approach, combining both local physical error and global\nparity label losses. Moreover, the transformer architecture's inherent\nadaptability to variable-length inputs allows for efficient transfer learning,\nenabling the decoder to adapt to varying code distances without retraining.\n  Evaluation on six code distances and ten different error configurations\ndemonstrates that our model consistently outperforms non-ML decoders, such as\nUnion Find (UF) and Minimum Weight Perfect Matching (MWPM), and other ML\ndecoders, thereby achieving best logical error rates. Moreover, the transfer\nlearning can save over 10x of training cost.\n","authors":["Hanrui Wang","Pengyu Liu","Kevin Shao","Dantong Li","Jiaqi Gu","David Z. Pan","Yongshan Ding","Song Han"],"pdf_url":"https://arxiv.org/pdf/2311.16082v1.pdf","comment":"Accepted to ICCAD 2023, FAST ML for Science Workshop; 7 pages, 8\n  figures"},{"id":"http://arxiv.org/abs/2311.16080v1","updated":"2023-11-27T18:50:37Z","published":"2023-11-27T18:50:37Z","title":"XLB: Distributed Multi-GPU Lattice Boltzmann Simulation Framework for\n  Differentiable Scientific Machine Learning","summary":"  The lattice Boltzmann method (LBM) has emerged as a prominent technique for\nsolving fluid dynamics problems due to its algorithmic potential for\ncomputational scalability. We introduce XLB framework, a Python-based\ndifferentiable LBM library which harnesses the capabilities of the JAX\nframework. The architecture of XLB is predicated upon ensuring accessibility,\nextensibility, and computational performance, enabling scaling effectively\nacross CPU, multi-GPU, and distributed multi-GPU systems. The framework can be\nreadily augmented with novel boundary conditions, collision models, or\nsimulation capabilities. XLB offers the unique advantage of integration with\nJAX's extensive machine learning echosystem, and the ability to utilize\nautomatic differentiation for tackling physics-based machine learning,\noptimization, and inverse problems. XLB has been successfully scaled to handle\nsimulations with billions of cells, achieving giga-scale lattice updates per\nsecond. XLB is released under the permissive Apache-2.0 license and is\navailable on GitHub at https://github.com/Autodesk/XLB.\n","authors":["Mohammadmehdi Ataei","Hesam Salehipour"],"pdf_url":"https://arxiv.org/pdf/2311.16080v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16079v1","updated":"2023-11-27T18:49:43Z","published":"2023-11-27T18:49:43Z","title":"MEDITRON-70B: Scaling Medical Pretraining for Large Language Models","summary":"  Large language models (LLMs) can potentially democratize access to medical\nknowledge. While many efforts have been made to harness and improve LLMs'\nmedical knowledge and reasoning capacities, the resulting models are either\nclosed-source (e.g., PaLM, GPT-4) or limited in scale (<= 13B parameters),\nwhich restricts their abilities. In this work, we improve access to large-scale\nmedical LLMs by releasing MEDITRON: a suite of open-source LLMs with 7B and 70B\nparameters adapted to the medical domain. MEDITRON builds on Llama-2 (through\nour adaptation of Nvidia's Megatron-LM distributed trainer), and extends\npretraining on a comprehensively curated medical corpus, including selected\nPubMed articles, abstracts, and internationally-recognized medical guidelines.\nEvaluations using four major medical benchmarks show significant performance\ngains over several state-of-the-art baselines before and after task-specific\nfinetuning. Overall, MEDITRON achieves a 6% absolute performance gain over the\nbest public baseline in its parameter class and 3% over the strongest baseline\nwe finetuned from Llama-2. Compared to closed-source LLMs, MEDITRON-70B\noutperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of\nMed-PaLM-2. We release our code for curating the medical pretraining corpus and\nthe MEDITRON model weights to drive open-source development of more capable\nmedical LLMs.\n","authors":["Zeming Chen","Alejandro Hernández Cano","Angelika Romanou","Antoine Bonnet","Kyle Matoba","Francesco Salvi","Matteo Pagliardini","Simin Fan","Andreas Köpf","Amirkeivan Mohtashami","Alexandre Sallinen","Alireza Sakhaeirad","Vinitra Swamy","Igor Krawczuk","Deniz Bayazit","Axel Marmet","Syrielle Montariol","Mary-Anne Hartley","Martin Jaggi","Antoine Bosselut"],"pdf_url":"https://arxiv.org/pdf/2311.16079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14309v2","updated":"2023-11-27T18:48:33Z","published":"2022-11-25T18:59:53Z","title":"FutureHuman3D: Forecasting Complex Long-Term 3D Human Behavior from\n  Video Observations","summary":"  We present a generative approach to forecast long-term future human behavior\nin 3D, requiring only weak supervision from readily available 2D human action\ndata. This is a fundamental task enabling many downstream applications. The\nrequired ground-truth data is hard to capture in 3D (mocap suits, expensive\nsetups) but easy to acquire in 2D (simple RGB cameras). Thus, we design our\nmethod to only require 2D RGB data while being able to generate 3D human motion\nsequences. We use a differentiable 2D projection scheme in an autoregressive\nmanner for weak supervision, and an adversarial loss for 3D regularization. Our\nmethod predicts long and complex behavior sequences (e.g. cooking, assembly)\nconsisting of multiple sub-actions. We tackle this in a semantically\nhierarchical manner, jointly predicting high-level coarse action labels\ntogether with their low-level fine-grained realizations as characteristic 3D\nhuman poses. We observe that these two action representations are coupled in\nnature, and joint prediction benefits both action and pose forecasting. Our\nexperiments demonstrate the complementary nature of joint action and 3D pose\nprediction: our joint approach outperforms each task treated individually,\nenables robust longer-term sequence prediction, and outperforms alternative\napproaches to forecast actions and characteristic 3D poses.\n","authors":["Christian Diller","Thomas Funkhouser","Angela Dai"],"pdf_url":"https://arxiv.org/pdf/2211.14309v2.pdf","comment":"Project Page: https://future-human-3d.christian-diller.de/ Video:\n  https://www.youtube.com/watch?v=18du85YFXL0"},{"id":"http://arxiv.org/abs/2311.16065v1","updated":"2023-11-27T18:32:08Z","published":"2023-11-27T18:32:08Z","title":"A Survey on Vulnerability of Federated Learning: A Learning Algorithm\n  Perspective","summary":"  This review paper takes a comprehensive look at malicious attacks against FL,\ncategorizing them from new perspectives on attack origins and targets, and\nproviding insights into their methodology and impact. In this survey, we focus\non threat models targeting the learning process of FL systems. Based on the\nsource and target of the attack, we categorize existing threat models into four\ntypes, Data to Model (D2M), Model to Data (M2D), Model to Model (M2M) and\ncomposite attacks. For each attack type, we discuss the defense strategies\nproposed, highlighting their effectiveness, assumptions and potential areas for\nimprovement. Defense strategies have evolved from using a singular metric to\nexcluding malicious clients, to employing a multifaceted approach examining\nclient models at various phases. In this survey paper, our research indicates\nthat the to-learn data, the learning gradients, and the learned model at\ndifferent stages all can be manipulated to initiate malicious attacks that\nrange from undermining model performance, reconstructing private local data,\nand to inserting backdoors. We have also seen these threat are becoming more\ninsidious. While earlier studies typically amplified malicious gradients,\nrecent endeavors subtly alter the least significant weights in local models to\nbypass defense measures. This literature review provides a holistic\nunderstanding of the current FL threat landscape and highlights the importance\nof developing robust, efficient, and privacy-preserving defenses to ensure the\nsafe and trusted adoption of FL in real-world applications.\n","authors":["Xianghua Xie","Chen Hu","Hanchi Ren","Jingjing Deng"],"pdf_url":"https://arxiv.org/pdf/2311.16065v1.pdf","comment":"https://github.com/Rand2AI/Awesome-Vulnerability-of-Federated-Learning"},{"id":"http://arxiv.org/abs/2210.06462v3","updated":"2023-11-27T18:30:14Z","published":"2022-10-12T17:57:58Z","title":"Self-Guided Diffusion Models","summary":"  Diffusion models have demonstrated remarkable progress in image generation\nquality, especially when guidance is used to control the generative process.\nHowever, guidance requires a large amount of image-annotation pairs for\ntraining and is thus dependent on their availability, correctness and\nunbiasedness. In this paper, we eliminate the need for such annotation by\ninstead leveraging the flexibility of self-supervision signals to design a\nframework for self-guided diffusion models. By leveraging a feature extraction\nfunction and a self-annotation function, our method provides guidance signals\nat various image granularities: from the level of holistic images to object\nboxes and even segmentation masks. Our experiments on single-label and\nmulti-label image datasets demonstrate that self-labeled guidance always\noutperforms diffusion models without guidance and may even surpass guidance\nbased on ground-truth labels, especially on unbalanced data. When equipped with\nself-supervised box or mask proposals, our method further generates visually\ndiverse yet semantically consistent images, without the need for any class,\nbox, or segment label annotation. Self-guided diffusion is simple, flexible and\nexpected to profit from deployment at scale. Source code will be at:\nhttps://taohu.me/sgdm/\n","authors":["Vincent Tao Hu","David W Zhang","Yuki M. Asano","Gertjan J. Burghouts","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2210.06462v3.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2112.12589v3","updated":"2023-11-27T18:29:31Z","published":"2021-12-20T13:46:39Z","title":"A deep reinforcement learning model for predictive maintenance planning\n  of road assets: Integrating LCA and LCCA","summary":"  Road maintenance planning is an integral part of road asset management. One\nof the main challenges in Maintenance and Rehabilitation (M&R) practices is to\ndetermine maintenance type and timing. This research proposes a framework using\nReinforcement Learning (RL) based on the Long Term Pavement Performance (LTPP)\ndatabase to determine the type and timing of M&R practices. A predictive DNN\nmodel is first developed in the proposed algorithm, which serves as the\nEnvironment for the RL algorithm. For the Policy estimation of the RL model,\nboth DQN and PPO models are developed. However, PPO has been selected in the\nend due to better convergence and higher sample efficiency. Indicators used in\nthis study are International Roughness Index (IRI) and Rutting Depth (RD).\nInitially, we considered Cracking Metric (CM) as the third indicator, but it\nwas then excluded due to the much fewer data compared to other indicators,\nwhich resulted in lower accuracy of the results. Furthermore, in\ncost-effectiveness calculation (reward), we considered both the economic and\nenvironmental impacts of M&R treatments. Costs and environmental impacts have\nbeen evaluated with paLATE 2.0 software. Our method is tested on a hypothetical\ncase study of a six-lane highway with 23 kilometers length located in Texas,\nwhich has a warm and wet climate. The results propose a 20-year M&R plan in\nwhich road condition remains in an excellent condition range. Because the early\nstate of the road is at a good level of service, there is no need for heavy\nmaintenance practices in the first years. Later, after heavy M&R actions, there\nare several 1-2 years of no need for treatments. All of these show that the\nproposed plan has a logical result. Decision-makers and transportation agencies\ncan use this scheme to conduct better maintenance practices that can prevent\nbudget waste and, at the same time, minimize the environmental impacts.\n","authors":["Moein Latifi","Fateme Golivand Darvishvand","Omid Khandel","Mobin Latifi Nowsoud"],"pdf_url":"https://arxiv.org/pdf/2112.12589v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.08805v3","updated":"2023-11-27T18:24:41Z","published":"2021-11-16T22:16:03Z","title":"Online Estimation and Optimization of Utility-Based Shortfall Risk","summary":"  Utility-Based Shortfall Risk (UBSR) is a risk metric that is increasingly\npopular in financial applications, owing to certain desirable properties that\nit enjoys. We consider the problem of estimating UBSR in a recursive setting,\nwhere samples from the underlying loss distribution are available\none-at-a-time. We cast the UBSR estimation problem as a root finding problem,\nand propose stochastic approximation-based estimations schemes. We derive\nnon-asymptotic bounds on the estimation error in the number of samples. We also\nconsider the problem of UBSR optimization within a parameterized class of\nrandom variables. We propose a stochastic gradient descent based algorithm for\nUBSR optimization, and derive non-asymptotic bounds on its convergence.\n","authors":["Vishwajit Hegde","Arvind S. Menon","L. A. Prashanth","Krishna Jagannathan"],"pdf_url":"https://arxiv.org/pdf/2111.08805v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16054v1","updated":"2023-11-27T18:19:07Z","published":"2023-11-27T18:19:07Z","title":"Metric Space Magnitude for Evaluating Unsupervised Representation\n  Learning","summary":"  The magnitude of a metric space was recently established as a novel\ninvariant, providing a measure of the `effective size' of a space across\nmultiple scales. By capturing both geometrical and topological properties of\ndata, magnitude is poised to address challenges in unsupervised representation\nlearning tasks. We formalise a novel notion of dissimilarity between magnitude\nfunctions of finite metric spaces and use them to derive a quality measure for\ndimensionality reduction tasks. Our measure is provably stable under\nperturbations of the data, can be efficiently calculated, and enables a\nrigorous multi-scale comparison of embeddings. We show the utility of our\nmeasure in an experimental suite that comprises different domains and tasks,\nincluding the comparison of data visualisations.\n","authors":["Katharina Limbeck","Rayna Andreeva","Rik Sarkar","Bastian Rieck"],"pdf_url":"https://arxiv.org/pdf/2311.16054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16038v1","updated":"2023-11-27T17:59:41Z","published":"2023-11-27T17:59:41Z","title":"OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving","summary":"  Understanding how the 3D scene evolves is vital for making decisions in\nautonomous driving. Most existing methods achieve this by predicting the\nmovements of object boxes, which cannot capture more fine-grained scene\ninformation. In this paper, we explore a new framework of learning a world\nmodel, OccWorld, in the 3D Occupancy space to simultaneously predict the\nmovement of the ego car and the evolution of the surrounding scenes. We propose\nto learn a world model based on 3D occupancy rather than 3D bounding boxes and\nsegmentation maps for three reasons: 1) expressiveness. 3D occupancy can\ndescribe the more fine-grained 3D structure of the scene; 2) efficiency. 3D\noccupancy is more economical to obtain (e.g., from sparse LiDAR points). 3)\nversatility. 3D occupancy can adapt to both vision and LiDAR. To facilitate the\nmodeling of the world evolution, we learn a reconstruction-based scene\ntokenizer on the 3D occupancy to obtain discrete scene tokens to describe the\nsurrounding scenes. We then adopt a GPT-like spatial-temporal generative\ntransformer to generate subsequent scene and ego tokens to decode the future\noccupancy and ego trajectory. Extensive experiments on the widely used nuScenes\nbenchmark demonstrate the ability of OccWorld to effectively model the\nevolution of the driving scenes. OccWorld also produces competitive planning\nresults without using instance and map supervision. Code:\nhttps://github.com/wzzheng/OccWorld.\n","authors":["Wenzhao Zheng","Weiliang Chen","Yuanhui Huang","Borui Zhang","Yueqi Duan","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2311.16038v1.pdf","comment":"Code is available at: https://github.com/wzzheng/OccWorld"},{"id":"http://arxiv.org/abs/2308.00709v2","updated":"2023-11-27T17:57:18Z","published":"2023-07-28T22:52:15Z","title":"DeepTSF: Codeless machine learning operations for time series\n  forecasting","summary":"  This paper presents DeepTSF, a comprehensive machine learning operations\n(MLOps) framework aiming to innovate time series forecasting through workflow\nautomation and codeless modeling. DeepTSF automates key aspects of the ML\nlifecycle, making it an ideal tool for data scientists and MLops engineers\nengaged in machine learning (ML) and deep learning (DL)-based forecasting.\nDeepTSF empowers users with a robust and user-friendly solution, while it is\ndesigned to seamlessly integrate with existing data analysis workflows,\nproviding enhanced productivity and compatibility. The framework offers a\nfront-end user interface (UI) suitable for data scientists, as well as other\nhigher-level stakeholders, enabling comprehensive understanding through\ninsightful visualizations and evaluation metrics. DeepTSF also prioritizes\nsecurity through identity management and access authorization mechanisms. The\napplication of DeepTSF in real-life use cases of the I-NERGY project has\nalready proven DeepTSF's efficacy in DL-based load forecasting, showcasing its\nsignificant added value in the electrical power and energy systems domain.\n","authors":["Sotiris Pelekis","Evangelos Karakolis","Theodosios Pountridis","George Kormpakis","George Lampropoulos","Spiros Mouzakitis","Dimitris Askounis"],"pdf_url":"https://arxiv.org/pdf/2308.00709v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16035v1","updated":"2023-11-27T17:55:50Z","published":"2023-11-27T17:55:50Z","title":"RobustState: Boosting Fidelity of Quantum State Preparation via\n  Noise-Aware Variational Training","summary":"  Quantum state preparation, a crucial subroutine in quantum computing,\ninvolves generating a target quantum state from initialized qubits. Arbitrary\nstate preparation algorithms can be broadly categorized into arithmetic\ndecomposition (AD) and variational quantum state preparation (VQSP). AD employs\na predefined procedure to decompose the target state into a series of gates,\nwhereas VQSP iteratively tunes ansatz parameters to approximate target state.\nVQSP is particularly apt for Noisy-Intermediate Scale Quantum (NISQ) machines\ndue to its shorter circuits. However, achieving noise-robust parameter\noptimization still remains challenging.\n  We present RobustState, a novel VQSP training methodology that combines high\nrobustness with high training efficiency. The core idea involves utilizing\nmeasurement outcomes from real machines to perform back-propagation through\nclassical simulators, thus incorporating real quantum noise into gradient\ncalculations. RobustState serves as a versatile, plug-and-play technique\napplicable for training parameters from scratch or fine-tuning existing\nparameters to enhance fidelity on target machines. It is adaptable to various\nansatzes at both gate and pulse levels and can even benefit other variational\nalgorithms, such as variational unitary synthesis.\n  Comprehensive evaluation of RobustState on state preparation tasks for 4\ndistinct quantum algorithms using 10 real quantum machines demonstrates a\ncoherent error reduction of up to 7.1 $\\times$ and state fidelity improvement\nof up to 96\\% and 81\\% for 4-Q and 5-Q states, respectively. On average,\nRobustState improves fidelity by 50\\% and 72\\% for 4-Q and 5-Q states compared\nto baseline approaches.\n","authors":["Hanrui Wang","Yilian Liu","Pengyu Liu","Jiaqi Gu","Zirui Li","Zhiding Liang","Jinglei Cheng","Yongshan Ding","Xuehai Qian","Yiyu Shi","David Z. Pan","Frederic T. Chong","Song Han"],"pdf_url":"https://arxiv.org/pdf/2311.16035v1.pdf","comment":"Accepted to FASTML @ ICCAD 2023. 14 pages, 20 figures"},{"id":"http://arxiv.org/abs/2311.16030v1","updated":"2023-11-27T17:50:14Z","published":"2023-11-27T17:50:14Z","title":"Machine Learning-Enhanced Aircraft Landing Scheduling under\n  Uncertainties","summary":"  This paper addresses aircraft delays, emphasizing their impact on safety and\nfinancial losses. To mitigate these issues, an innovative machine learning\n(ML)-enhanced landing scheduling methodology is proposed, aiming to improve\nautomation and safety. Analyzing flight arrival delay scenarios reveals strong\nmultimodal distributions and clusters in arrival flight time durations. A\nmulti-stage conditional ML predictor enhances separation time prediction based\non flight events. ML predictions are then integrated as safety constraints in a\ntime-constrained traveling salesman problem formulation, solved using\nmixed-integer linear programming (MILP). Historical flight recordings and model\npredictions address uncertainties between successive flights, ensuring\nreliability. The proposed method is validated using real-world data from the\nAtlanta Air Route Traffic Control Center (ARTCC ZTL). Case studies demonstrate\nan average 17.2% reduction in total landing time compared to the\nFirst-Come-First-Served (FCFS) rule. Unlike FCFS, the proposed methodology\nconsiders uncertainties, instilling confidence in scheduling. The study\nconcludes with remarks and outlines future research directions.\n","authors":["Yutian Pang","Peng Zhao","Jueming Hu","Yongming Liu"],"pdf_url":"https://arxiv.org/pdf/2311.16030v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16026v1","updated":"2023-11-27T17:40:02Z","published":"2023-11-27T17:40:02Z","title":"A Neural Framework for Generalized Causal Sensitivity Analysis","summary":"  Unobserved confounding is common in many applications, making causal\ninference from observational data challenging. As a remedy, causal sensitivity\nanalysis is an important tool to draw causal conclusions under unobserved\nconfounding with mathematical guarantees. In this paper, we propose NeuralCSA,\na neural framework for generalized causal sensitivity analysis. Unlike previous\nwork, our framework is compatible with (i) a large class of sensitivity models,\nincluding the marginal sensitivity model, f-sensitivity models, and Rosenbaum's\nsensitivity model; (ii) different treatment types (i.e., binary and\ncontinuous); and (iii) different causal queries, including (conditional)\naverage treatment effects and simultaneous effects on multiple outcomes. The\ngenerality of \\frameworkname is achieved by learning a latent distribution\nshift that corresponds to a treatment intervention using two conditional\nnormalizing flows. We provide theoretical guarantees that NeuralCSA is able to\ninfer valid bounds on the causal query of interest and also demonstrate this\nempirically using both simulated and real-world data.\n","authors":["Dennis Frauen","Fergus Imrie","Alicia Curth","Valentyn Melnychuk","Stefan Feuerriegel","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2311.16026v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.13258v2","updated":"2023-11-27T17:36:19Z","published":"2023-10-20T03:34:31Z","title":"ManiCast: Collaborative Manipulation with Cost-Aware Human Forecasting","summary":"  Seamless human-robot manipulation in close proximity relies on accurate\nforecasts of human motion. While there has been significant progress in\nlearning forecast models at scale, when applied to manipulation tasks, these\nmodels accrue high errors at critical transition points leading to degradation\nin downstream planning performance. Our key insight is that instead of\npredicting the most likely human motion, it is sufficient to produce forecasts\nthat capture how future human motion would affect the cost of a robot's plan.\nWe present ManiCast, a novel framework that learns cost-aware human forecasts\nand feeds them to a model predictive control planner to execute collaborative\nmanipulation tasks. Our framework enables fluid, real-time interactions between\na human and a 7-DoF robot arm across a number of real-world tasks such as\nreactive stirring, object handovers, and collaborative table setting. We\nevaluate both the motion forecasts and the end-to-end forecaster-planner system\nagainst a range of learned and heuristic baselines while additionally\ncontributing new datasets. We release our code and datasets at\nhttps://portal-cornell.github.io/manicast/.\n","authors":["Kushal Kedia","Prithwish Dan","Atiksh Bhardwaj","Sanjiban Choudhury"],"pdf_url":"https://arxiv.org/pdf/2310.13258v2.pdf","comment":"CoRL 2023"},{"id":"http://arxiv.org/abs/2311.16021v1","updated":"2023-11-27T17:35:28Z","published":"2023-11-27T17:35:28Z","title":"Scheduling and Communication Schemes for Decentralized Federated\n  Learning","summary":"  Federated learning (FL) is a distributed machine learning paradigm in which a\nlarge number of clients coordinate with a central server to learn a model\nwithout sharing their own training data. One central server is not enough, due\nto problems of connectivity with clients. In this paper, a decentralized\nfederated learning (DFL) model with the stochastic gradient descent (SGD)\nalgorithm has been introduced, as a more scalable approach to improve the\nlearning performance in a network of agents with arbitrary topology. Three\nscheduling policies for DFL have been proposed for communications between the\nclients and the parallel servers, and the convergence, accuracy, and loss have\nbeen tested in a totally decentralized mplementation of SGD. The experimental\nresults show that the proposed scheduling polices have an impact both on the\nspeed of convergence and in the final global model.\n","authors":["Bahaa-Eldin Ali Abdelghany","Ana Fernández-Vilas","Manuel Fernández-Veiga","Nashwa El-Bendary","Ammar M. Hassan","Walid M. Abdelmoez"],"pdf_url":"https://arxiv.org/pdf/2311.16021v1.pdf","comment":"32nd International Conference on Computer Theory and Applications\n  (ICCTA), Alexandria, Egypt, 2022"},{"id":"http://arxiv.org/abs/2203.09659v3","updated":"2023-11-27T17:23:10Z","published":"2022-03-17T23:52:08Z","title":"Low-degree learning and the metric entropy of polynomials","summary":"  Let $\\mathscr{F}_{n,d}$ be the class of all functions $f:\\{-1,1\\}^n\\to[-1,1]$\non the $n$-dimensional discrete hypercube of degree at most $d$. In the first\npart of this paper, we prove that any (deterministic or randomized) algorithm\nwhich learns $\\mathscr{F}_{n,d}$ with $L_2$-accuracy $\\varepsilon$ requires at\nleast $\\Omega((1-\\sqrt{\\varepsilon})2^d\\log n)$ queries for large enough $n$,\nthus establishing the sharpness as $n\\to\\infty$ of a recent upper bound of\nEskenazis and Ivanisvili (2021). To do this, we show that the $L_2$-packing\nnumbers $\\mathsf{M}(\\mathscr{F}_{n,d},\\|\\cdot\\|_{L_2},\\varepsilon)$ of the\nconcept class $\\mathscr{F}_{n,d}$ satisfy the two-sided estimate\n$$c(1-\\varepsilon)2^d\\log n \\leq \\log\n\\mathsf{M}(\\mathscr{F}_{n,d},\\|\\cdot\\|_{L_2},\\varepsilon) \\leq \\frac{2^{Cd}\\log\nn}{\\varepsilon^4}$$ for large enough $n$, where $c, C>0$ are universal\nconstants. In the second part of the paper, we present a logarithmic upper\nbound for the randomized query complexity of classes of bounded approximate\npolynomials whose Fourier spectra are concentrated on few subsets. As an\napplication, we prove new estimates for the number of random queries required\nto learn approximate juntas of a given degree, functions with rapidly decaying\nFourier tails and constant depth circuits of given size. Finally, we obtain\nbounds for the number of queries required to learn the polynomial class\n$\\mathscr{F}_{n,d}$ without error in the query and random example models.\n","authors":["Alexandros Eskenazis","Paata Ivanisvili","Lauritz Streck"],"pdf_url":"https://arxiv.org/pdf/2203.09659v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11913v2","updated":"2023-11-27T17:17:39Z","published":"2023-11-20T16:44:18Z","title":"Deep Calibration of Market Simulations using Neural Density Estimators\n  and Embedding Networks","summary":"  The ability to construct a realistic simulator of financial exchanges,\nincluding reproducing the dynamics of the limit order book, can give insight\ninto many counterfactual scenarios, such as a flash crash, a margin call, or\nchanges in macroeconomic outlook. In recent years, agent-based models have been\ndeveloped that reproduce many features of an exchange, as summarised by a set\nof stylised facts and statistics. However, the ability to calibrate simulators\nto a specific period of trading remains an open challenge. In this work, we\ndevelop a novel approach to the calibration of market simulators by leveraging\nrecent advances in deep learning, specifically using neural density estimators\nand embedding networks. We demonstrate that our approach is able to correctly\nidentify high probability parameter sets, both when applied to synthetic and\nhistorical data, and without reliance on manually selected or weighted\nensembles of stylised facts.\n","authors":["Namid R. Stillman","Rory Baggott","Justin Lyon","Jianfei Zhang","Dingqiu Zhu","Tao Chen","Perukrishnen Vytelingum"],"pdf_url":"https://arxiv.org/pdf/2311.11913v2.pdf","comment":"4th ACM International Conference on AI in Finance (ICAIF 2023)"},{"id":"http://arxiv.org/abs/2211.14400v5","updated":"2023-11-27T17:13:24Z","published":"2022-11-25T23:32:26Z","title":"Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev and\n  Besov Spaces","summary":"  Let $\\Omega = [0,1]^d$ be the unit cube in $\\mathbb{R}^d$. We study the\nproblem of how efficiently, in terms of the number of parameters, deep neural\nnetworks with the ReLU activation function can approximate functions in the\nSobolev spaces $W^s(L_q(\\Omega))$ and Besov spaces $B^s_r(L_q(\\Omega))$, with\nerror measured in the $L_p(\\Omega)$ norm. This problem is important when\nstudying the application of neural networks in a variety of fields, including\nscientific computing and signal processing, and has previously been solved only\nwhen $p=q=\\infty$. Our contribution is to provide a complete solution for all\n$1\\leq p,q\\leq \\infty$ and $s > 0$ for which the corresponding Sobolev or Besov\nspace compactly embeds into $L_p$. The key technical tool is a novel\nbit-extraction technique which gives an optimal encoding of sparse vectors.\nThis enables us to obtain sharp upper bounds in the non-linear regime where $p\n> q$. We also provide a novel method for deriving $L_p$-approximation lower\nbounds based upon VC-dimension when $p < \\infty$. Our results show that very\ndeep ReLU networks significantly outperform classical methods of approximation\nin terms of the number of parameters, but that this comes at the cost of\nparameters which are not encodable.\n","authors":["Jonathan W. Siegel"],"pdf_url":"https://arxiv.org/pdf/2211.14400v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16008v1","updated":"2023-11-27T17:02:56Z","published":"2023-11-27T17:02:56Z","title":"Using Decentralized Aggregation for Federated Learning with Differential\n  Privacy","summary":"  Nowadays, the ubiquitous usage of mobile devices and networks have raised\nconcerns about the loss of control over personal data and research advance\ntowards the trade-off between privacy and utility in scenarios that combine\nexchange communications, big databases and distributed and collaborative (P2P)\nMachine Learning techniques. On the other hand, although Federated Learning\n(FL) provides some level of privacy by retaining the data at the local node,\nwhich executes a local training to enrich a global model, this scenario is\nstill susceptible to privacy breaches as membership inference attacks. To\nprovide a stronger level of privacy, this research deploys an experimental\nenvironment for FL with Differential Privacy (DP) using benchmark datasets. The\nobtained results show that the election of parameters and techniques of DP is\ncentral in the aforementioned trade-off between privacy and utility by means of\na classification example.\n","authors":["Hadeel Abd El-Kareem","Abd El-Moaty Saleh","Ana Fernández-Vilas","Manuel Fernández-Veiga","asser El-Sonbaty"],"pdf_url":"https://arxiv.org/pdf/2311.16008v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.06627v2","updated":"2023-11-27T16:59:39Z","published":"2023-10-10T13:45:59Z","title":"What If the TV Was Off? Examining Counterfactual Reasoning Abilities of\n  Multi-modal Language Models","summary":"  Counterfactual reasoning, a fundamental aspect of human cognition, involves\ncontemplating alternatives to established facts or past events, significantly\nenhancing our abilities in planning and decision-making. In light of the\nadvancements in current multi-modal large language models, we explore their\neffectiveness in counterfactual reasoning. To facilitate this investigation, we\nintroduce a novel dataset, C-VQA, specifically designed to test the\ncounterfactual reasoning capabilities of modern multi-modal large language\nmodels. This dataset is constructed by infusing original questions with\ncounterfactual presuppositions, spanning various types such as numerical and\nboolean queries. It encompasses a mix of real and synthetic data, representing\na wide range of difficulty levels. Our thorough evaluations of contemporary\nvision-language models using this dataset have revealed substantial performance\ndrops, with some models showing up to a 40\\% decrease, highlighting a\nsignificant gap between current models and human-like vision reasoning\ncapabilities. We hope our dataset will serve as a vital benchmark for\nevaluating the counterfactual reasoning capabilities of models. Code and\ndataset are publicly available at https://bzhao.me/C-VQA/.\n","authors":["Letian Zhang","Xiaotong Zhai","Zhongkai Zhao","Yongshuo Zong","Xin Wen","Bingchen Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.06627v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16004v1","updated":"2023-11-27T16:55:04Z","published":"2023-11-27T16:55:04Z","title":"Improved Data Generation for Enhanced Asset Allocation: A Synthetic\n  Dataset Approach for the Fixed Income Universe","summary":"  We present a novel process for generating synthetic datasets tailored to\nassess asset allocation methods and construct portfolios within the fixed\nincome universe. Our approach begins by enhancing the CorrGAN model to generate\nsynthetic correlation matrices. Subsequently, we propose an Encoder-Decoder\nmodel that samples additional data conditioned on a given correlation matrix.\nThe resulting synthetic dataset facilitates in-depth analyses of asset\nallocation methods across diverse asset universes. Additionally, we provide a\ncase study that exemplifies the use of the synthetic dataset to improve\nportfolios constructed within a simulation-based asset allocation process.\n","authors":["Szymon Kubiak","Tillman Weyde","Oleksandr Galkin","Dan Philps","Ram Gopal"],"pdf_url":"https://arxiv.org/pdf/2311.16004v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16003v1","updated":"2023-11-27T16:52:25Z","published":"2023-11-27T16:52:25Z","title":"Forecasting Auxiliary Energy Consumption for Electric Heavy-Duty\n  Vehicles","summary":"  Accurate energy consumption prediction is crucial for optimizing the\noperation of electric commercial heavy-duty vehicles, e.g., route planning for\ncharging. Moreover, understanding why certain predictions are cast is paramount\nfor such a predictive model to gain user trust and be deployed in practice.\nSince commercial vehicles operate differently as transportation tasks, ambient,\nand drivers vary, a heterogeneous population is expected when building an AI\nsystem for forecasting energy consumption. The dependencies between the input\nfeatures and the target values are expected to also differ across\nsub-populations. One well-known example of such a statistical phenomenon is the\nSimpson paradox. In this paper, we illustrate that such a setting poses a\nchallenge for existing XAI methods that produce global feature statistics, e.g.\nLIME or SHAP, causing them to yield misleading results. We demonstrate a\npotential solution by training multiple regression models on subsets of data.\nIt not only leads to superior regression performance but also more relevant and\nconsistent LIME explanations. Given that the employed groupings correspond to\nrelevant sub-populations, the associations between the input features and the\ntarget values are consistent within each cluster but different across clusters.\nExperiments on both synthetic and real-world datasets show that such splitting\nof a complex problem into simpler ones yields better regression performance and\ninterpretability.\n","authors":["Yuantao Fan","Zhenkan Wang","Sepideh Pashami","Slawomir Nowaczyk","Henrik Ydreskog"],"pdf_url":"https://arxiv.org/pdf/2311.16003v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.08736v2","updated":"2023-11-27T16:49:49Z","published":"2023-08-17T02:18:59Z","title":"On the Effectiveness of Log Representation for Log-based Anomaly\n  Detection","summary":"  Logs are an essential source of information for people to understand the\nrunning status of a software system. Due to the evolving modern software\narchitecture and maintenance methods, more research efforts have been devoted\nto automated log analysis. In particular, machine learning (ML) has been widely\nused in log analysis tasks. In ML-based log analysis tasks, converting textual\nlog data into numerical feature vectors is a critical and indispensable step.\nHowever, the impact of using different log representation techniques on the\nperformance of the downstream models is not clear, which limits researchers and\npractitioners' opportunities of choosing the optimal log representation\ntechniques in their automated log analysis workflows. Therefore, this work\ninvestigates and compares the commonly adopted log representation techniques\nfrom previous log analysis research. Particularly, we select six log\nrepresentation techniques and evaluate them with seven ML models and four\npublic log datasets (i.e., HDFS, BGL, Spirit and Thunderbird) in the context of\nlog-based anomaly detection. We also examine the impacts of the log parsing\nprocess and the different feature aggregation approaches when they are employed\nwith log representation techniques. From the experiments, we provide some\nheuristic guidelines for future researchers and developers to follow when\ndesigning an automated log analysis workflow. We believe our comprehensive\ncomparison of log representation techniques can help researchers and\npractitioners better understand the characteristics of different log\nrepresentation techniques and provide them with guidance for selecting the most\nsuitable ones for their ML-based log analysis workflow.\n","authors":["Xingfang Wu","Heng Li","Foutse Khomh"],"pdf_url":"https://arxiv.org/pdf/2308.08736v2.pdf","comment":"Accepted by Journal of Empirical Software Engineering (EMSE)"},{"id":"http://arxiv.org/abs/2307.06255v2","updated":"2023-11-27T16:48:14Z","published":"2023-07-12T15:50:38Z","title":"Machine learning and Topological data analysis identify unique features\n  of human papillae in 3D scans","summary":"  The tongue surface houses a range of papillae that are integral to the\nmechanics and chemistry of taste and textural sensation. Although gustatory\nfunction of papillae is well investigated, the uniqueness of papillae within\nand across individuals remains elusive. Here, we present the first machine\nlearning framework on 3D microscopic scans of human papillae (n = 2092),\nuncovering the uniqueness of geometric and topological features of papillae.\nThe finer differences in shapes of papillae are investigated computationally\nbased on a number of features derived from discrete differential geometry and\ncomputational topology. Interpretable machine learning techniques show that\npersistent homology features of the papillae shape are the most effective in\npredicting the biological variables. Models trained on these features with\nsmall volumes of data samples predict the type of papillae with an accuracy of\n85%. The papillae type classification models can map the spatial arrangement of\nfiliform and fungiform papillae on a surface. Remarkably, the papillae are\nfound to be distinctive across individuals and an individual can be identified\nwith an accuracy of 48% among the 15 participants from a single papillae.\nCollectively, this is the first unprecedented evidence demonstrating that\ntongue papillae can serve as a unique identifier inspiring new research\ndirection for food preferences and oral diagnostics.\n","authors":["Rayna Andreeva","Anwesha Sarkar","Rik Sarkar"],"pdf_url":"https://arxiv.org/pdf/2307.06255v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16001v1","updated":"2023-11-27T16:47:09Z","published":"2023-11-27T16:47:09Z","title":"Automated Measurement of Vascular Calcification in Femoral\n  Endarterectomy Patients Using Deep Learning","summary":"  Atherosclerosis, a chronic inflammatory disease affecting the large arteries,\npresents a global health risk. Accurate analysis of diagnostic images, like\ncomputed tomographic angiograms (CTAs), is essential for staging and monitoring\nthe progression of atherosclerosis-related conditions, including peripheral\narterial disease (PAD). However, manual analysis of CTA images is\ntime-consuming and tedious. To address this limitation, we employed a deep\nlearning model to segment the vascular system in CTA images of PAD patients\nundergoing femoral endarterectomy surgery and to measure vascular calcification\nfrom the left renal artery to the patella. Utilizing proprietary CTA images of\n27 patients undergoing femoral endarterectomy surgery provided by Prisma Health\nMidlands, we developed a Deep Neural Network (DNN) model to first segment the\narterial system, starting from the descending aorta to the patella, and second,\nto provide a metric of arterial calcification. Our designed DNN achieved 83.4%\naverage Dice accuracy in segmenting arteries from aorta to patella, advancing\nthe state-of-the-art by 0.8%. Furthermore, our work is the first to present a\nrobust statistical analysis of automated calcification measurement in the lower\nextremities using deep learning, attaining a Mean Absolute Percentage Error\n(MAPE) of 9.5% and a correlation coefficient of 0.978 between automated and\nmanual calcification scores. These findings underscore the potential of deep\nlearning techniques as a rapid and accurate tool for medical professionals to\nassess calcification in the abdominal aorta and its branches above the patella.\nThe developed DNN model and related documentation in this project are available\nat GitHub page at https://github.com/pip-alireza/DeepCalcScoring.\n","authors":["Alireza Bagheri Rajeoni","Breanna Pederson","Daniel G. Clair","Susan M. Lessner","Homayoun Valafar"],"pdf_url":"https://arxiv.org/pdf/2311.16001v1.pdf","comment":"Published in MDPI Diagnostic journal, the code can be accessed via\n  the GitHub link in the paper"},{"id":"http://arxiv.org/abs/2310.10541v2","updated":"2023-11-27T16:45:18Z","published":"2023-10-16T16:13:53Z","title":"AST: Effective Dataset Distillation through Alignment with Smooth and\n  High-Quality Expert Trajectories","summary":"  Training large AI models typically requires large-scale datasets in the\nmachine learning process, making training and parameter-tuning process both\ntime-consuming and costly. Some researchers address this problem by carefully\nsynthesizing a very small number of highly representative and informative\nsamples from real-world datasets. This approach, known as Dataset Distillation\n(DD), proposes a perspective for data-efficient learning. Despite recent\nprogress in this field, the performance of existing methods still cannot meet\nexpectations, and distilled datasets cannot effectively replace original\ndatasets. In this paper, unlike previous methods that focus solely on improving\nthe effectiveness of student distillation, we recognize and leverage the\nimportant mutual influence between expert and student models. We observed that\nthe smoothness of expert trajectories has a significant impact on subsequent\nstudent parameter alignment. Based on this, we propose an effective DD\nframework named AST, standing for Alignment with Smooth and high-quality expert\nTrajectories. We devise the integration of clipping loss and gradient penalty\nto regulate the rate of parameter changes in expert trajectory generation. To\nfurther refine the student parameter alignment with expert trajectory, we put\nforward representative initialization for the synthetic dataset and balanced\ninner-loop loss in response to the sensitivity exhibited towards randomly\ninitialized variables during distillation. We also propose two enhancement\nstrategies, namely intermediate matching loss and weight perturbation, to\nmitigate the potential occurrence of cumulative errors. We conduct extensive\nexperiments on datasets of different scales, sizes, and resolutions. The\nresults demonstrate that the proposed method significantly outperforms prior\nmethods.\n","authors":["Jiyuan Shen","Wenzhuo Yang","Kwok-Yan Lam"],"pdf_url":"https://arxiv.org/pdf/2310.10541v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15996v1","updated":"2023-11-27T16:44:50Z","published":"2023-11-27T16:44:50Z","title":"Closing the ODE-SDE gap in score-based diffusion models through the\n  Fokker-Planck equation","summary":"  Score-based diffusion models have emerged as one of the most promising\nframeworks for deep generative modelling, due to their state-of-the art\nperformance in many generation tasks while relying on mathematical foundations\nsuch as stochastic differential equations (SDEs) and ordinary differential\nequations (ODEs). Empirically, it has been reported that ODE based samples are\ninferior to SDE based samples. In this paper we rigorously describe the range\nof dynamics and approximations that arise when training score-based diffusion\nmodels, including the true SDE dynamics, the neural approximations, the various\napproximate particle dynamics that result, as well as their associated\nFokker--Planck equations and the neural network approximations of these\nFokker--Planck equations. We systematically analyse the difference between the\nODE and SDE dynamics of score-based diffusion models, and link it to an\nassociated Fokker--Planck equation. We derive a theoretical upper bound on the\nWasserstein 2-distance between the ODE- and SDE-induced distributions in terms\nof a Fokker--Planck residual. We also show numerically that conventional\nscore-based diffusion models can exhibit significant differences between ODE-\nand SDE-induced distributions which we demonstrate using explicit comparisons.\nMoreover, we show numerically that reducing the Fokker--Planck residual by\nadding it as an additional regularisation term leads to closing the gap between\nODE- and SDE-induced distributions. Our experiments suggest that this\nregularisation can improve the distribution generated by the ODE, however that\nthis can come at the cost of degraded SDE sample quality.\n","authors":["Teo Deveney","Jan Stanczuk","Lisa Maria Kreusser","Chris Budd","Carola-Bibiane Schönlieb"],"pdf_url":"https://arxiv.org/pdf/2311.15996v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15995v1","updated":"2023-11-27T16:44:13Z","published":"2023-11-27T16:44:13Z","title":"Sensitivity-Based Layer Insertion for Residual and Feedforward Neural\n  Networks","summary":"  The training of neural networks requires tedious and often manual tuning of\nthe network architecture. We propose a systematic method to insert new layers\nduring the training process, which eliminates the need to choose a fixed\nnetwork size before training. Our technique borrows techniques from constrained\noptimization and is based on first-order sensitivity information of the\nobjective with respect to the virtual parameters that additional layers, if\ninserted, would offer. We consider fully connected feedforward networks with\nselected activation functions as well as residual neural networks. In numerical\nexperiments, the proposed sensitivity-based layer insertion technique exhibits\nimproved training decay, compared to not inserting the layer. Furthermore, the\ncomputational effort is reduced in comparison to inserting the layer from the\nbeginning. The code is available at\n\\url{https://github.com/LeonieKreis/layer_insertion_sensitivity_based}.\n","authors":["Evelyn Herberg","Roland Herzog","Frederik Köhne","Leonie Kreis","Anton Schiela"],"pdf_url":"https://arxiv.org/pdf/2311.15995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15990v1","updated":"2023-11-27T16:39:55Z","published":"2023-11-27T16:39:55Z","title":"Should We Learn Most Likely Functions or Parameters?","summary":"  Standard regularized training procedures correspond to maximizing a posterior\ndistribution over parameters, known as maximum a posteriori (MAP) estimation.\nHowever, model parameters are of interest only insomuch as they combine with\nthe functional form of a model to provide a function that can make good\npredictions. Moreover, the most likely parameters under the parameter posterior\ndo not generally correspond to the most likely function induced by the\nparameter posterior. In fact, we can re-parametrize a model such that any\nsetting of parameters can maximize the parameter posterior. As an alternative,\nwe investigate the benefits and drawbacks of directly estimating the most\nlikely function implied by the model and the data. We show that this procedure\nleads to pathological solutions when using neural networks and prove conditions\nunder which the procedure is well-behaved, as well as a scalable approximation.\nUnder these conditions, we find that function-space MAP estimation can lead to\nflatter minima, better generalization, and improved robustness to overfitting.\n","authors":["Shikai Qiu","Tim G. J. Rudner","Sanyam Kapoor","Andrew Gordon Wilson"],"pdf_url":"https://arxiv.org/pdf/2311.15990v1.pdf","comment":"NeurIPS 2023. Code available at\n  https://github.com/activatedgeek/function-space-map"},{"id":"http://arxiv.org/abs/2303.01486v4","updated":"2023-11-27T16:36:53Z","published":"2023-03-02T18:47:51Z","title":"Understanding plasticity in neural networks","summary":"  Plasticity, the ability of a neural network to quickly change its predictions\nin response to new information, is essential for the adaptability and\nrobustness of deep reinforcement learning systems. Deep neural networks are\nknown to lose plasticity over the course of training even in relatively simple\nlearning problems, but the mechanisms driving this phenomenon are still poorly\nunderstood. This paper conducts a systematic empirical analysis into plasticity\nloss, with the goal of understanding the phenomenon mechanistically in order to\nguide the future development of targeted solutions. We find that loss of\nplasticity is deeply connected to changes in the curvature of the loss\nlandscape, but that it often occurs in the absence of saturated units. Based on\nthis insight, we identify a number of parameterization and optimization design\nchoices which enable networks to better preserve plasticity over the course of\ntraining. We validate the utility of these findings on larger-scale RL\nbenchmarks in the Arcade Learning Environment.\n","authors":["Clare Lyle","Zeyu Zheng","Evgenii Nikishin","Bernardo Avila Pires","Razvan Pascanu","Will Dabney"],"pdf_url":"https://arxiv.org/pdf/2303.01486v4.pdf","comment":"Accepted to ICML 2023 (oral presentation)"},{"id":"http://arxiv.org/abs/2311.15983v1","updated":"2023-11-27T16:28:20Z","published":"2023-11-27T16:28:20Z","title":"Sparsify-then-Classify: From Internal Neurons of Large Language Models\n  To Efficient Text Classifiers","summary":"  Among the many tasks that Large Language Models (LLMs) have revolutionized is\ntext classification. However, existing approaches for applying pretrained LLMs\nto text classification predominantly rely on using single token outputs from\nonly the last layer of hidden states. As a result, they suffer from limitations\nin efficiency, task-specificity, and interpretability. In our work, we\ncontribute an approach that uses all internal representations by employing\nmultiple pooling strategies on all activation and hidden states. Our novel\nlightweight strategy, Sparsify-then-Classify (STC) first sparsifies\ntask-specific features layer-by-layer, then aggregates across layers for text\nclassification. STC can be applied as a seamless plug-and-play module on top of\nexisting LLMs. Our experiments on a comprehensive set of models and datasets\ndemonstrate that STC not only consistently improves the classification\nperformance of pretrained and fine-tuned models, but is also more efficient for\nboth training and inference, and is more intrinsically interpretable.\n","authors":["Yilun Liu","Difan Jiao","Ashton Anderson"],"pdf_url":"https://arxiv.org/pdf/2311.15983v1.pdf","comment":"23 pages, 5 figures, 8 tables Code available at\n  https://github.com/difanj0713/Sparsify-then-Classify"},{"id":"http://arxiv.org/abs/2311.15979v1","updated":"2023-11-27T16:25:12Z","published":"2023-11-27T16:25:12Z","title":"Soil Organic Carbon Estimation from Climate-related Features with Graph\n  Neural Network","summary":"  Soil organic carbon (SOC) plays a pivotal role in the global carbon cycle,\nimpacting climate dynamics and necessitating accurate estimation for\nsustainable land and agricultural management. While traditional methods of SOC\nestimation face resolution and accuracy challenges, recent technological\nsolutions harness remote sensing, machine learning, and high-resolution\nsatellite mapping. Graph Neural Networks (GNNs), especially when integrated\nwith positional encoders, can capture complex relationships between soil and\nclimate. Using the LUCAS database, this study compared four GNN operators in\nthe positional encoder framework. Results revealed that the PESAGE and\nPETransformer models outperformed others in SOC estimation, indicating their\npotential in capturing the complex relationship between SOC and climate\nfeatures. Our findings confirm the feasibility of applications of GNN\narchitectures in SOC prediction, establishing a framework for future\nexplorations of this topic with more advanced GNN models.\n","authors":["Weiying Zhao","Natalia Efremova"],"pdf_url":"https://arxiv.org/pdf/2311.15979v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.00553v3","updated":"2023-11-27T16:24:59Z","published":"2023-04-02T15:04:43Z","title":"From Isolated Islands to Pangea: Unifying Semantic Space for Human\n  Action Understanding","summary":"  As a vital step toward the intelligent agent, Action understanding matters\nfor intelligent agents and has attracted long-term attention. It can be formed\nas the mapping from the action physical space to the semantic space. Typically,\nresearchers built action datasets according to idiosyncratic choices to define\nclasses and push the envelope of benchmarks respectively. Thus, datasets are\nincompatible with each other like \"Isolated Islands\" due to semantic gaps and\nvarious class granularities, e.g., do housework in dataset A and wash plate in\ndataset B. We argue that a more principled semantic space is an urgent need to\nconcentrate the community efforts and enable us to use all datasets together to\npursue generalizable action learning. To this end, we design a structured\naction semantic space in view of verb taxonomy hierarchy and covering massive\nactions. By aligning the classes of previous datasets to our semantic space, we\ngather (image/video/skeleton/MoCap) datasets into a unified database in a\nunified label system, i.e., bridging ``isolated islands'' into a \"Pangea\".\nAccordingly, we propose a novel model mapping from the physical space to\nsemantic space to fully use Pangea. In extensive experiments, our new system\nshows significant superiority, especially in transfer learning. Code and data\nwill be made publicly available.\n","authors":["Yong-Lu Li","Xiaoqian Wu","Xinpeng Liu","Zehao Wang","Yiming Dou","Yikun Ji","Junyi Zhang","Yixing Li","Jingru Tan","Xudong Lu","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2304.00553v3.pdf","comment":"Project Webpage: https://mvig-rhos.com/pangea"},{"id":"http://arxiv.org/abs/2308.07037v4","updated":"2023-11-27T16:15:44Z","published":"2023-08-14T09:56:35Z","title":"Bayesian Flow Networks","summary":"  This paper introduces Bayesian Flow Networks (BFNs), a new class of\ngenerative model in which the parameters of a set of independent distributions\nare modified with Bayesian inference in the light of noisy data samples, then\npassed as input to a neural network that outputs a second, interdependent\ndistribution. Starting from a simple prior and iteratively updating the two\ndistributions yields a generative procedure similar to the reverse process of\ndiffusion models; however it is conceptually simpler in that no forward process\nis required. Discrete and continuous-time loss functions are derived for\ncontinuous, discretised and discrete data, along with sample generation\nprocedures. Notably, the network inputs for discrete data lie on the\nprobability simplex, and are therefore natively differentiable, paving the way\nfor gradient-based sample guidance and few-step generation in discrete domains\nsuch as language modelling. The loss function directly optimises data\ncompression and places no restrictions on the network architecture. In our\nexperiments BFNs achieve competitive log-likelihoods for image modelling on\ndynamically binarized MNIST and CIFAR-10, and outperform all known discrete\ndiffusion models on the text8 character-level language modelling task.\n","authors":["Alex Graves","Rupesh Kumar Srivastava","Timothy Atkinson","Faustino Gomez"],"pdf_url":"https://arxiv.org/pdf/2308.07037v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.05400v5","updated":"2023-11-27T16:08:49Z","published":"2022-03-10T14:45:57Z","title":"Asymptotic Bounds for Smoothness Parameter Estimates in Gaussian Process\n  Interpolation","summary":"  It is common to model a deterministic response function, such as the output\nof a computer experiment, as a Gaussian process with a Mat\\'ern covariance\nkernel. The smoothness parameter of a Mat\\'ern kernel determines many important\nproperties of the model in the large data limit, including the rate of\nconvergence of the conditional mean to the response function. We prove that the\nmaximum likelihood estimate of the smoothness parameter cannot asymptotically\nundersmooth the truth when the data are obtained on a fixed bounded subset of\n$\\mathbb{R}^d$. That is, if the data-generating response function has Sobolev\nsmoothness $\\nu_0 > d/2$, then the smoothness parameter estimate cannot be\nasymptotically less than $\\nu_0$. The lower bound is sharp. Additionally, we\nshow that maximum likelihood estimation recovers the true smoothness for a\nclass of compactly supported self-similar functions. For cross-validation we\nprove an asymptotic lower bound $\\nu_0 - d/2$, which however is unlikely to be\nsharp. The results are based on approximation theory in Sobolev spaces and some\ngeneral theorems that restrict the set of values that the parameter estimators\ncan take.\n","authors":["Toni Karvonen"],"pdf_url":"https://arxiv.org/pdf/2203.05400v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15966v1","updated":"2023-11-27T16:07:49Z","published":"2023-11-27T16:07:49Z","title":"Towards Transfer Learning for Large-Scale Image Classification Using\n  Annealing-based Quantum Boltzmann Machines","summary":"  Quantum Transfer Learning (QTL) recently gained popularity as a hybrid\nquantum-classical approach for image classification tasks by efficiently\ncombining the feature extraction capabilities of large Convolutional Neural\nNetworks with the potential benefits of Quantum Machine Learning (QML).\nExisting approaches, however, only utilize gate-based Variational Quantum\nCircuits for the quantum part of these procedures. In this work we present an\napproach to employ Quantum Annealing (QA) in QTL-based image classification.\nSpecifically, we propose using annealing-based Quantum Boltzmann Machines as\npart of a hybrid quantum-classical pipeline to learn the classification of\nreal-world, large-scale data such as medical images through supervised\ntraining. We demonstrate our approach by applying it to the three-class\nCOVID-CT-MD dataset, a collection of lung Computed Tomography (CT) scan slices.\nUsing Simulated Annealing as a stand-in for actual QA, we compare our method to\nclassical transfer learning, using a neural network of the same order of\nmagnitude, to display its improved classification performance. We find that our\napproach consistently outperforms its classical baseline in terms of test\naccuracy and AUC-ROC-Score and needs less training epochs to do this.\n","authors":["Daniëlle Schuman","Leo Sünkel","Philipp Altmann","Jonas Stein","Christoph Roch","Thomas Gabor","Claudia Linnhoff-Popien"],"pdf_url":"https://arxiv.org/pdf/2311.15966v1.pdf","comment":"7 pages, 3 figures (5 if counting subfigures), 1 table. To be\n  published in the proceedings of the 2023 IEEE International Conference on\n  Quantum Computing and Engineering (QCE)"},{"id":"http://arxiv.org/abs/2311.15964v1","updated":"2023-11-27T16:07:37Z","published":"2023-11-27T16:07:37Z","title":"Efficient Pre-training for Localized Instruction Generation of Videos","summary":"  Procedural videos show step-by-step demonstrations of tasks like recipe\npreparation. Understanding such videos is challenging, involving the precise\nlocalization of steps and the generation of textual instructions. Manually\nannotating steps and writing instructions is costly, which limits the size of\ncurrent datasets and hinders effective learning. Leveraging large but noisy\nvideo-transcript datasets for pre-training can boost performance, but demands\nsignificant computational resources. Furthermore, transcripts contain\nirrelevant content and exhibit style variation compared to instructions written\nby human annotators. To mitigate both issues, we propose a technique,\nSieve-&-Swap, to automatically curate a smaller dataset: (i) Sieve filters\nirrelevant transcripts and (ii) Swap enhances the quality of the text\ninstruction by automatically replacing the transcripts with human-written\ninstructions from a text-only recipe dataset. The curated dataset, three orders\nof magnitude smaller than current web-scale datasets, enables efficient\ntraining of large-scale models with competitive performance. We complement our\nSieve-\\&-Swap approach with a Procedure Transformer (ProcX) for end-to-end step\nlocalization and instruction generation for procedural videos. When this model\nis pre-trained on our curated dataset, it achieves state-of-the-art performance\nin zero-shot and finetuning settings on YouCook2 and Tasty, while using a\nfraction of the computational resources.\n","authors":["Anil Batra","Davide Moltisanti","Laura Sevilla-Lara","Marcus Rohrbach","Frank Keller"],"pdf_url":"https://arxiv.org/pdf/2311.15964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15961v1","updated":"2023-11-27T16:06:48Z","published":"2023-11-27T16:06:48Z","title":"Maximum Likelihood Estimation is All You Need for Well-Specified\n  Covariate Shift","summary":"  A key challenge of modern machine learning systems is to achieve\nOut-of-Distribution (OOD) generalization -- generalizing to target data whose\ndistribution differs from that of source data. Despite its significant\nimportance, the fundamental question of ``what are the most effective\nalgorithms for OOD generalization'' remains open even under the standard\nsetting of covariate shift. This paper addresses this fundamental question by\nproving that, surprisingly, classical Maximum Likelihood Estimation (MLE)\npurely using source data (without any modification) achieves the minimax\noptimality for covariate shift under the well-specified setting. That is, no\nalgorithm performs better than MLE in this setting (up to a constant factor),\njustifying MLE is all you need. Our result holds for a very rich class of\nparametric models, and does not require any boundedness condition on the\ndensity ratio. We illustrate the wide applicability of our framework by\ninstantiating it to three concrete examples -- linear regression, logistic\nregression, and phase retrieval. This paper further complement the study by\nproving that, under the misspecified setting, MLE is no longer the optimal\nchoice, whereas Maximum Weighted Likelihood Estimator (MWLE) emerges as minimax\noptimal in certain scenarios.\n","authors":["Jiawei Ge","Shange Tang","Jianqing Fan","Cong Ma","Chi Jin"],"pdf_url":"https://arxiv.org/pdf/2311.15961v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15960v1","updated":"2023-11-27T16:06:39Z","published":"2023-11-27T16:06:39Z","title":"Addressing Long-Horizon Tasks by Integrating Program Synthesis and State\n  Machines","summary":"  Deep reinforcement learning excels in various domains but lacks\ngeneralizability and interoperability. Programmatic RL methods (Trivedi et al.,\n2021; Liu et al., 2023) reformulate solving RL tasks as synthesizing\ninterpretable programs that can be executed in the environments. Despite\nencouraging results, these methods are limited to short-horizon tasks. On the\nother hand, representing RL policies using state machines (Inala et al., 2020)\ncan inductively generalize to long-horizon tasks; however, it struggles to\nscale up to acquire diverse and complex behaviors. This work proposes Program\nMachine Policies (POMPs), which bridge the advantages of programmatic RL and\nstate machine policies, allowing for the representation of complex behaviors\nand the address of long-term tasks. Specifically, we introduce a method that\ncan retrieve a set of effective, diverse, compatible programs. Then, we use\nthese programs as modes of a state machine and learn a transition function to\ntransition among mode programs, allowing for capturing long-horizon repetitive\nbehaviors. Our proposed framework outperforms programmatic RL and deep RL\nbaselines on various tasks and demonstrates the ability to generalize to even\nlonger horizons without any fine-tuning inductively. Ablation studies justify\nthe effectiveness of our proposed search algorithm for retrieving a set of\nprograms as modes.\n","authors":["Yu-An Lin","Chen-Tao Lee","Guan-Ting Liu","Pu-Jen Cheng","Shao-Hua Sun"],"pdf_url":"https://arxiv.org/pdf/2311.15960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.09347v3","updated":"2023-11-27T15:59:55Z","published":"2022-03-17T14:26:28Z","title":"Dimensionality Reduction and Wasserstein Stability for Kernel Regression","summary":"  In a high-dimensional regression framework, we study consequences of the\nnaive two-step procedure where first the dimension of the input variables is\nreduced and second, the reduced input variables are used to predict the output\nvariable with kernel regression. In order to analyze the resulting regression\nerrors, a novel stability result for kernel regression with respect to the\nWasserstein distance is derived. This allows us to bound errors that occur when\nperturbed input data is used to fit the regression function. We apply the\ngeneral stability result to principal component analysis (PCA). Exploiting\nknown estimates from the literature on both principal component analysis and\nkernel regression, we deduce convergence rates for the two-step procedure. The\nlatter turns out to be particularly useful in a semi-supervised setting.\n","authors":["Stephan Eckstein","Armin Iske","Mathias Trabs"],"pdf_url":"https://arxiv.org/pdf/2203.09347v3.pdf","comment":"Forthcoming in JMLR"},{"id":"http://arxiv.org/abs/2311.10093v2","updated":"2023-11-27T15:58:30Z","published":"2023-11-16T18:59:51Z","title":"The Chosen One: Consistent Characters in Text-to-Image Diffusion Models","summary":"  Recent advances in text-to-image generation models have unlocked vast\npotential for visual creativity. However, these models struggle with generation\nof consistent characters, a crucial aspect for numerous real-world applications\nsuch as story visualization, game development asset design, advertising, and\nmore. Current methods typically rely on multiple pre-existing images of the\ntarget character or involve labor-intensive manual processes. In this work, we\npropose a fully automated solution for consistent character generation, with\nthe sole input being a text prompt. We introduce an iterative procedure that,\nat each stage, identifies a coherent set of images sharing a similar identity\nand extracts a more consistent identity from this set. Our quantitative\nanalysis demonstrates that our method strikes a better balance between prompt\nalignment and identity consistency compared to the baseline methods, and these\nfindings are reinforced by a user study. To conclude, we showcase several\npractical applications of our approach. Project page is available at\nhttps://omriavrahami.com/the-chosen-one\n","authors":["Omri Avrahami","Amir Hertz","Yael Vinker","Moab Arar","Shlomi Fruchter","Ohad Fried","Daniel Cohen-Or","Dani Lischinski"],"pdf_url":"https://arxiv.org/pdf/2311.10093v2.pdf","comment":"Project page is available at https://omriavrahami.com/the-chosen-one"},{"id":"http://arxiv.org/abs/2311.15951v1","updated":"2023-11-27T15:57:11Z","published":"2023-11-27T15:57:11Z","title":"Replay across Experiments: A Natural Extension of Off-Policy RL","summary":"  Replaying data is a principal mechanism underlying the stability and data\nefficiency of off-policy reinforcement learning (RL). We present an effective\nyet simple framework to extend the use of replays across multiple experiments,\nminimally adapting the RL workflow for sizeable improvements in controller\nperformance and research iteration times. At its core, Replay Across\nExperiments (RaE) involves reusing experience from previous experiments to\nimprove exploration and bootstrap learning while reducing required changes to a\nminimum in comparison to prior work. We empirically show benefits across a\nnumber of RL algorithms and challenging control domains spanning both\nlocomotion and manipulation, including hard exploration tasks from egocentric\nvision. Through comprehensive ablations, we demonstrate robustness to the\nquality and amount of data available and various hyperparameter choices.\nFinally, we discuss how our approach can be applied more broadly across\nresearch life cycles and can increase resilience by reloading data across\nrandom seeds or hyperparameter variations.\n","authors":["Dhruva Tirumala","Thomas Lampe","Jose Enrique Chen","Tuomas Haarnoja","Sandy Huang","Guy Lever","Ben Moran","Tim Hertweck","Leonard Hasenclever","Martin Riedmiller","Nicolas Heess","Markus Wulfmeier"],"pdf_url":"https://arxiv.org/pdf/2311.15951v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.00577v2","updated":"2023-11-27T15:57:06Z","published":"2023-06-01T11:45:45Z","title":"TorchRL: A data-driven decision-making library for PyTorch","summary":"  PyTorch has ascended as a premier machine learning framework, yet it lacks a\nnative and comprehensive library for decision and control tasks suitable for\nlarge development teams dealing with complex real-world data and environments.\nTo address this issue, we propose TorchRL, a generalistic control library for\nPyTorch that provides well-integrated, yet standalone components. We introduce\na new and flexible PyTorch primitive, the TensorDict, which facilitates\nstreamlined algorithm development across the many branches of Reinforcement\nLearning (RL) and control. We provide a detailed description of the building\nblocks and an extensive overview of the library across domains and tasks.\nFinally, we experimentally demonstrate its reliability and flexibility and show\ncomparative benchmarks to demonstrate its computational efficiency. TorchRL\nfosters long-term support and is publicly available on GitHub for greater\nreproducibility and collaboration within the research community. The code is\nopen-sourced on GitHub.\n","authors":["Albert Bou","Matteo Bettini","Sebastian Dittert","Vikash Kumar","Shagun Sodhani","Xiaomeng Yang","Gianni De Fabritiis","Vincent Moens"],"pdf_url":"https://arxiv.org/pdf/2306.00577v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15947v1","updated":"2023-11-27T15:54:20Z","published":"2023-11-27T15:54:20Z","title":"GloNets: Globally Connected Neural Networks","summary":"  Deep learning architectures suffer from depth-related performance\ndegradation, limiting the effective depth of neural networks. Approaches like\nResNet are able to mitigate this, but they do not completely eliminate the\nproblem. We introduce Globally Connected Neural Networks (GloNet), a novel\narchitecture overcoming depth-related issues, designed to be superimposed on\nany model, enhancing its depth without increasing complexity or reducing\nperformance. With GloNet, the network's head uniformly receives information\nfrom all parts of the network, regardless of their level of abstraction. This\nenables GloNet to self-regulate information flow during training, reducing the\ninfluence of less effective deeper layers, and allowing for stable training\nirrespective of network depth. This paper details GloNet's design, its\ntheoretical basis, and a comparison with existing similar architectures.\nExperiments show GloNet's self-regulation ability and resilience to\ndepth-related learning challenges, like performance degradation. Our findings\nsuggest GloNet as a strong alternative to traditional architectures like\nResNets.\n","authors":["Antonio Di Cecco","Carlo Metta","Marco Fantozzi","Francesco Morandin","Maurizio Parton"],"pdf_url":"https://arxiv.org/pdf/2311.15947v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15945v1","updated":"2023-11-27T15:51:07Z","published":"2023-11-27T15:51:07Z","title":"Over-Squashing in Riemannian Graph Neural Networks","summary":"  Most graph neural networks (GNNs) are prone to the phenomenon of\nover-squashing in which node features become insensitive to information from\ndistant nodes in the graph. Recent works have shown that the topology of the\ngraph has the greatest impact on over-squashing, suggesting graph rewiring\napproaches as a suitable solution. In this work, we explore whether\nover-squashing can be mitigated through the embedding space of the GNN. In\nparticular, we consider the generalization of Hyperbolic GNNs (HGNNs) to\nRiemannian manifolds of variable curvature in which the geometry of the\nembedding space is faithful to the graph's topology. We derive bounds on the\nsensitivity of the node features in these Riemannian GNNs as the number of\nlayers increases, which yield promising theoretical and empirical results for\nalleviating over-squashing in graphs with negative curvature.\n","authors":["Julia Balla"],"pdf_url":"https://arxiv.org/pdf/2311.15945v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15940v1","updated":"2023-11-27T15:47:33Z","published":"2023-11-27T15:47:33Z","title":"Physics-informed neural networks for transformed geometries and\n  manifolds","summary":"  Physics-informed neural networks (PINNs) effectively embed physical\nprinciples into machine learning, but often struggle with complex or\nalternating geometries. We propose a novel method for integrating geometric\ntransformations within PINNs to robustly accommodate geometric variations. Our\nmethod incorporates a diffeomorphism as a mapping of a reference domain and\nadapts the derivative computation of the physics-informed loss function. This\ngeneralizes the applicability of PINNs not only to smoothly deformed domains,\nbut also to lower-dimensional manifolds and allows for direct shape\noptimization while training the network. We demonstrate the effectivity of our\napproach on several problems: (i) Eikonal equation on Archimedean spiral, (ii)\nPoisson problem on surface manifold, (iii) Incompressible Stokes flow in\ndeformed tube, and (iv) Shape optimization with Laplace operator. Through these\nexamples, we demonstrate the enhanced flexibility over traditional PINNs,\nespecially under geometric variations. The proposed framework presents an\noutlook for training deep neural operators over parametrized geometries, paving\nthe way for advanced modeling with PDEs on complex geometries in science and\nengineering.\n","authors":["Samuel Burbulla"],"pdf_url":"https://arxiv.org/pdf/2311.15940v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15936v1","updated":"2023-11-27T15:45:02Z","published":"2023-11-27T15:45:02Z","title":"Towards Responsible Governance of Biological Design Tools","summary":"  Recent advancements in generative machine learning have enabled rapid\nprogress in biological design tools (BDTs) such as protein structure and\nsequence prediction models. The unprecedented predictive accuracy and novel\ndesign capabilities of BDTs present new and significant dual-use risks. For\nexample, their predictive accuracy allows biological agents, whether vaccines\nor pathogens, to be developed more quickly, while the design capabilities could\nbe used to discover drugs or evade DNA screening techniques. Similar to other\ndual-use AI systems, BDTs present a wicked problem: how can regulators uphold\npublic safety without stifling innovation? We highlight how current regulatory\nproposals that are primarily tailored toward large language models may be less\neffective for BDTs, which require fewer computational resources to train and\nare often developed in an open-source manner. We propose a range of measures to\nmitigate the risk that BDTs are misused, across the areas of responsible\ndevelopment, risk assessment, transparency, access management, cybersecurity,\nand investing in resilience. Implementing such measures will require close\ncoordination between developers and governments.\n","authors":["Richard Moulange","Max Langenkamp","Tessa Alexanian","Samuel Curtis","Morgan Livingston"],"pdf_url":"https://arxiv.org/pdf/2311.15936v1.pdf","comment":"10 pages + references, 1 figure, accepted at NeurIPS 2023 Regulatable\n  ML as oral presentation"},{"id":"http://arxiv.org/abs/2307.06431v2","updated":"2023-11-27T15:38:32Z","published":"2023-07-12T19:51:49Z","title":"Energy Discrepancies: A Score-Independent Loss for Energy-Based Models","summary":"  Energy-based models are a simple yet powerful class of probabilistic models,\nbut their widespread adoption has been limited by the computational burden of\ntraining them. We propose a novel loss function called Energy Discrepancy (ED)\nwhich does not rely on the computation of scores or expensive Markov chain\nMonte Carlo. We show that ED approaches the explicit score matching and\nnegative log-likelihood loss under different limits, effectively interpolating\nbetween both. Consequently, minimum ED estimation overcomes the problem of\nnearsightedness encountered in score-based estimation methods, while also\nenjoying theoretical guarantees. Through numerical experiments, we demonstrate\nthat ED learns low-dimensional data distributions faster and more accurately\nthan explicit score matching or contrastive divergence. For high-dimensional\nimage data, we describe how the manifold hypothesis puts limitations on our\napproach and demonstrate the effectiveness of energy discrepancy by training\nthe energy-based model as a prior of a variational decoder model.\n","authors":["Tobias Schröder","Zijing Ou","Jen Ning Lim","Yingzhen Li","Sebastian J. Vollmer","Andrew B. Duncan"],"pdf_url":"https://arxiv.org/pdf/2307.06431v2.pdf","comment":"Camera Ready version for the 37th Conference on Neural Information\n  Processing Systems (NeurIPS 2023). Changes in this revision: Appendix A1:\n  Corrected proof of Theorem 1. Appendix D3: Added definition and numerical\n  experiments for energy discrepancy on binary discrete spaces. Minor changes\n  in the main text and correction of typos. Added new references"},{"id":"http://arxiv.org/abs/2311.15925v1","updated":"2023-11-27T15:37:05Z","published":"2023-11-27T15:37:05Z","title":"Reinforcement Learning for Wildfire Mitigation in Simulated Disaster\n  Environments","summary":"  Climate change has resulted in a year over year increase in adverse weather\nand weather conditions which contribute to increasingly severe fire seasons.\nWithout effective mitigation, these fires pose a threat to life, property,\necology, cultural heritage, and critical infrastructure. To better prepare for\nand react to the increasing threat of wildfires, more accurate fire modelers\nand mitigation responses are necessary. In this paper, we introduce SimFire, a\nversatile wildland fire projection simulator designed to generate realistic\nwildfire scenarios, and SimHarness, a modular agent-based machine learning\nwrapper capable of automatically generating land management strategies within\nSimFire to reduce the overall damage to the area. Together, this publicly\navailable system allows researchers and practitioners the ability to emulate\nand assess the effectiveness of firefighter interventions and formulate\nstrategic plans that prioritize value preservation and resource allocation\noptimization. The repositories are available for download at\nhttps://github.com/mitrefireline.\n","authors":["Alexander Tapley","Marissa Dotter","Michael Doyle","Aidan Fennelly","Dhanuj Gandikota","Savanna Smith","Michael Threet","Tim Welsh"],"pdf_url":"https://arxiv.org/pdf/2311.15925v1.pdf","comment":"12 pages, 4 figures including Appendices (A, B). Accepted as a paper\n  in the Proposals track at the \"Tackling Climate Change with Machine Learning\"\n  workshop at NeurIPS 2023. MITRE Public Release Case Number 23-3920"},{"id":"http://arxiv.org/abs/2311.15924v1","updated":"2023-11-27T15:34:40Z","published":"2023-11-27T15:34:40Z","title":"Diagnosis driven Anomaly Detection for CPS","summary":"  In Cyber-Physical Systems (CPS) research, anomaly detection (detecting\nabnormal behavior) and diagnosis (identifying the underlying root cause) are\noften treated as distinct, isolated tasks. However, diagnosis algorithms\nrequire symptoms, i.e. temporally and spatially isolated anomalies, as input.\nThus, anomaly detection and diagnosis must be developed together to provide a\nholistic solution for diagnosis in CPS. We therefore propose a method for\nutilizing deep learning-based anomaly detection to generate inputs for\nConsistency-Based Diagnosis (CBD). We evaluate our approach on a simulated and\na real-world CPS dataset, where our model demonstrates strong performance\nrelative to other state-of-the-art models.\n","authors":["Henrik S. Steude","Lukas Moddemann","Alexander Diedrich","Jonas Ehrhardt","Oliver Niggemann"],"pdf_url":"https://arxiv.org/pdf/2311.15924v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07590v2","updated":"2023-11-27T15:17:49Z","published":"2023-11-09T17:12:44Z","title":"Technical Report: Large Language Models can Strategically Deceive their\n  Users when Put Under Pressure","summary":"  We demonstrate a situation in which Large Language Models, trained to be\nhelpful, harmless, and honest, can display misaligned behavior and\nstrategically deceive their users about this behavior without being instructed\nto do so. Concretely, we deploy GPT-4 as an agent in a realistic, simulated\nenvironment, where it assumes the role of an autonomous stock trading agent.\nWithin this environment, the model obtains an insider tip about a lucrative\nstock trade and acts upon it despite knowing that insider trading is\ndisapproved of by company management. When reporting to its manager, the model\nconsistently hides the genuine reasons behind its trading decision. We perform\na brief investigation of how this behavior varies under changes to the setting,\nsuch as removing model access to a reasoning scratchpad, attempting to prevent\nthe misaligned behavior by changing system instructions, changing the amount of\npressure the model is under, varying the perceived risk of getting caught, and\nmaking other simple changes to the environment. To our knowledge, this is the\nfirst demonstration of Large Language Models trained to be helpful, harmless,\nand honest, strategically deceiving their users in a realistic situation\nwithout direct instructions or training for deception.\n","authors":["Jérémy Scheurer","Mikita Balesni","Marius Hobbhahn"],"pdf_url":"https://arxiv.org/pdf/2311.07590v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15906v1","updated":"2023-11-27T15:13:02Z","published":"2023-11-27T15:13:02Z","title":"MetaDefa: Meta-learning based on Domain Enhancement and Feature\n  Alignment for Single Domain Generalization","summary":"  The single domain generalization(SDG) based on meta-learning has emerged as\nan effective technique for solving the domain-shift problem. However, the\ninadequate match of data distribution between source and augmented domains and\ndifficult separation of domain-invariant features from domain-related features\nmake SDG model hard to achieve great generalization. Therefore, a novel\nmeta-learning method based on domain enhancement and feature alignment\n(MetaDefa) is proposed to improve the model generalization performance. First,\nthe background substitution and visual corruptions techniques are used to\ngenerate diverse and effective augmented domains. Then, the multi-channel\nfeature alignment module based on class activation maps and class agnostic\nactivation maps is designed to effectively extract adequate transferability\nknowledge. In this module, domain-invariant features can be fully explored by\nfocusing on similar target regions between source and augmented domains feature\nspace and suppressing the feature representation of non-similar target regions.\nExtensive experiments on two publicly available datasets show that MetaDefa has\nsignificant generalization performance advantages in unknown multiple target\ndomains.\n","authors":["Can Sun","Hao Zheng","Zhigang Hu","Liu Yang","Meiguang Zheng","Bo Xu"],"pdf_url":"https://arxiv.org/pdf/2311.15906v1.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2111.08239v2","updated":"2023-11-27T15:10:18Z","published":"2021-11-16T05:49:56Z","title":"Assessing Deep Neural Networks as Probability Estimators","summary":"  Deep Neural Networks (DNNs) have performed admirably in classification tasks.\nHowever, the characterization of their classification uncertainties, required\nfor certain applications, has been lacking. In this work, we investigate the\nissue by assessing DNNs' ability to estimate conditional probabilities and\npropose a framework for systematic uncertainty characterization. Denoting the\ninput sample as x and the category as y, the classification task of assigning a\ncategory y to a given input x can be reduced to the task of estimating the\nconditional probabilities p(y|x), as approximated by the DNN at its last layer\nusing the softmax function. Since softmax yields a vector whose elements all\nfall in the interval (0, 1) and sum to 1, it suggests a probabilistic\ninterpretation to the DNN's outcome. Using synthetic and real-world datasets,\nwe look into the impact of various factors, e.g., probability density f(x) and\ninter-categorical sparsity, on the precision of DNNs' estimations of p(y|x),\nand find that the likelihood probability density and the inter-categorical\nsparsity have greater impacts than the prior probability to DNNs'\nclassification uncertainty.\n","authors":["Yu Pan","Kwo-Sen Kuo","Michael L. Rilee","Hongfeng Yu"],"pdf_url":"https://arxiv.org/pdf/2111.08239v2.pdf","comment":"Y. Pan, K. Kuo, M. Rilee and H. Yu, \"Assessing Deep Neural Networks\n  as Probability Estimators,\" in 2021 IEEE International Conference on Big Data\n  (Big Data), Orlando, FL, USA, 2021 pp. 1083-1091. doi:\n  10.1109/BigData52589.2021.9671328"},{"id":"http://arxiv.org/abs/2311.15890v1","updated":"2023-11-27T14:56:47Z","published":"2023-11-27T14:56:47Z","title":"Stability-Informed Initialization of Neural Ordinary Differential\n  Equations","summary":"  This paper addresses the training of Neural Ordinary Differential Equations\n(neural ODEs), and in particular explores the interplay between numerical\nintegration techniques, stability regions, step size, and initialization\ntechniques. It is shown how the choice of integration technique implicitly\nregularizes the learned model, and how the solver's corresponding stability\nregion affects training and prediction performance. From this analysis, a\nstability-informed parameter initialization technique is introduced. The\neffectiveness of the initialization method is displayed across several learning\nbenchmarks and industrial applications.\n","authors":["Theodor Westny","Arman Mohammadi","Daniel Jung","Erik Frisk"],"pdf_url":"https://arxiv.org/pdf/2311.15890v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15887v1","updated":"2023-11-27T14:55:16Z","published":"2023-11-27T14:55:16Z","title":"FLASC: A Flare-Sensitive Clustering Algorithm: Extending HDBSCAN* for\n  Detecting Branches in Clusters","summary":"  We present FLASC, an algorithm for flare-sensitive clustering. Our algorithm\nbuilds upon HDBSCAN* -- which provides high-quality density-based clustering\nperformance -- through a post-processing step that differentiates branches\nwithin the detected clusters' manifold, adding a type of pattern that can be\ndiscovered. Two variants of the algorithm are presented, which trade\ncomputational cost for noise robustness. We show that both variants scale\nsimilarly to HDBSCAN* in terms of computational cost and provide stable outputs\nusing synthetic data sets, resulting in an efficient flare-sensitive clustering\nalgorithm. In addition, we demonstrate the algorithm's benefit in data\nexploration over HDBSCAN* clustering on two real-world data sets.\n","authors":["D. M. Bot","J. Peeters","J. Liesenborgs","J. Aerts"],"pdf_url":"https://arxiv.org/pdf/2311.15887v1.pdf","comment":"20 pages, 11 figures, submitted to ACM TKDD"},{"id":"http://arxiv.org/abs/2311.15876v1","updated":"2023-11-27T14:49:06Z","published":"2023-11-27T14:49:06Z","title":"RO-LLaMA: Generalist LLM for Radiation Oncology via Noise Augmentation\n  and Consistency Regularization","summary":"  Recent advancements in Artificial Intelligence (AI) have profoundly\ninfluenced medical fields, by providing tools to reduce clinical workloads.\nHowever, most AI models are constrained to execute uni-modal tasks, in stark\ncontrast to the comprehensive approaches utilized by medical professionals. To\naddress this, here we present RO-LLaMA, a versatile generalist large language\nmodel (LLM) tailored for the field of radiation oncology. This model seamlessly\ncovers a wide range of the workflow of radiation oncologists, adept at various\ntasks such as clinical report summarization, radiation therapy plan suggestion,\nand plan-guided therapy target volume segmentation. In particular, to maximize\nthe end-to-end performance, we further present a novel Consistency Embedding\nFine-Tuning (CEFTune) technique, which boosts LLM's robustness to additional\nerrors at the intermediates while preserving the capability of handling clean\ninputs, and creatively transform this concept into LLM-driven segmentation\nframework as Consistency Embedding Segmentation (CESEG). Experimental results\non multi-centre cohort sets demonstrate our proposed RO-LLaMA's promising\nperformance for diverse tasks with generalization capabilities.\n","authors":["Kwanyoung Kim","Yujin Oh","Sangjoon Park","Hwa Kyung Byun","Jin Sung Kim","Yong Bae Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2311.15876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15875v1","updated":"2023-11-27T14:48:37Z","published":"2023-11-27T14:48:37Z","title":"Nodal Hydraulic Head Estimation through Unscented Kalman Filter for\n  Data-driven Leak Localization in Water Networks","summary":"  In this paper, we present a nodal hydraulic head estimation methodology for\nwater distribution networks (WDN) based on an Unscented Kalman Filter (UKF)\nscheme with application to leak localization. The UKF refines an initial\nestimation of the hydraulic state by considering the prediction model, as well\nas available pressure and demand measurements. To this end, it provides\ncustomized prediction and data assimilation steps. Additionally, the method is\nenhanced by dynamically updating the prediction function weight matrices.\nPerformance testing on the Modena benchmark under realistic conditions\ndemonstrates the method's effectiveness in enhancing state estimation and\ndata-driven leak localization.\n","authors":["Luis Romero-Ben","Paul Irofti","Florin Stoican","Vicenç Puig"],"pdf_url":"https://arxiv.org/pdf/2311.15875v1.pdf","comment":"This work has been submitted to IFAC for possible publication. It has\n  6 pages and 3 figures"},{"id":"http://arxiv.org/abs/2306.00349v2","updated":"2023-11-27T14:42:52Z","published":"2023-06-01T05:06:56Z","title":"CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV\n  Perception","summary":"  Perception is crucial in the realm of autonomous driving systems, where\nbird's eye view (BEV)-based architectures have recently reached\nstate-of-the-art performance. The desirability of self-supervised\nrepresentation learning stems from the expensive and laborious process of\nannotating 2D and 3D data. Although previous research has investigated\npretraining methods for both LiDAR and camera-based 3D object detection, a\nunified pretraining framework for multimodal BEV perception is missing. In this\nstudy, we introduce CALICO, a novel framework that applies contrastive\nobjectives to both LiDAR and camera backbones. Specifically, CALICO\nincorporates two stages: point-region contrast (PRC) and region-aware\ndistillation (RAD). PRC better balances the region- and scene-level\nrepresentation learning on the LiDAR modality and offers significant\nperformance improvement compared to existing methods. RAD effectively achieves\ncontrastive distillation on our self-trained teacher model. CALICO's efficacy\nis substantiated by extensive evaluations on 3D object detection and BEV map\nsegmentation tasks, where it delivers significant performance improvements.\nNotably, CALICO outperforms the baseline method by 10.5% and 8.6% on NDS and\nmAP. Moreover, CALICO boosts the robustness of multimodal 3D object detection\nagainst adversarial attacks and corruption. Additionally, our framework can be\ntailored to different backbones and heads, positioning it as a promising\napproach for multimodal BEV perception.\n","authors":["Jiachen Sun","Haizhong Zheng","Qingzhao Zhang","Atul Prakash","Z. Morley Mao","Chaowei Xiao"],"pdf_url":"https://arxiv.org/pdf/2306.00349v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.15176v2","updated":"2023-11-27T14:35:05Z","published":"2023-07-27T20:11:07Z","title":"RCT Rejection Sampling for Causal Estimation Evaluation","summary":"  Confounding is a significant obstacle to unbiased estimation of causal\neffects from observational data. For settings with high-dimensional covariates\n-- such as text data, genomics, or the behavioral social sciences --\nresearchers have proposed methods to adjust for confounding by adapting machine\nlearning methods to the goal of causal estimation. However, empirical\nevaluation of these adjustment methods has been challenging and limited. In\nthis work, we build on a promising empirical evaluation strategy that\nsimplifies evaluation design and uses real data: subsampling randomized\ncontrolled trials (RCTs) to create confounded observational datasets while\nusing the average causal effects from the RCTs as ground-truth. We contribute a\nnew sampling algorithm, which we call RCT rejection sampling, and provide\ntheoretical guarantees that causal identification holds in the observational\ndata to allow for valid comparisons to the ground-truth RCT. Using synthetic\ndata, we show our algorithm indeed results in low bias when oracle estimators\nare evaluated on the confounded samples, which is not always the case for a\npreviously proposed algorithm. In addition to this identification result, we\nhighlight several finite data considerations for evaluation designers who plan\nto use RCT rejection sampling on their own datasets. As a proof of concept, we\nimplement an example evaluation pipeline and walk through these finite data\nconsiderations with a novel, real-world RCT -- which we release publicly --\nconsisting of approximately 70k observations and text data as high-dimensional\ncovariates. Together, these contributions build towards a broader agenda of\nimproved empirical evaluation for causal estimation.\n","authors":["Katherine A. Keith","Sergey Feldman","David Jurgens","Jonathan Bragg","Rohit Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2307.15176v2.pdf","comment":"Code and data at https://github.com/kakeith/rct_rejection_sampling"},{"id":"http://arxiv.org/abs/2311.15865v1","updated":"2023-11-27T14:33:21Z","published":"2023-11-27T14:33:21Z","title":"A precise symbolic emulator of the linear matter power spectrum","summary":"  Computing the matter power spectrum, $P(k)$, as a function of cosmological\nparameters can be prohibitively slow in cosmological analyses, hence emulating\nthis calculation is desirable. Previous analytic approximations are\ninsufficiently accurate for modern applications, so black-box, uninterpretable\nemulators are often used. We utilise an efficient genetic programming based\nsymbolic regression framework to explore the space of potential mathematical\nexpressions which can approximate the power spectrum and $\\sigma_8$. We learn\nthe ratio between an existing low-accuracy fitting function for $P(k)$ and that\nobtained by solving the Boltzmann equations and thus still incorporate the\nphysics which motivated this earlier approximation. We obtain an analytic\napproximation to the linear power spectrum with a root mean squared fractional\nerror of 0.2% between $k = 9\\times10^{-3} - 9 \\, h{\\rm \\, Mpc^{-1}}$ and across\na wide range of cosmological parameters, and we provide physical\ninterpretations for various terms in the expression. We also provide a simple\nanalytic approximation for $\\sigma_8$ with a similar accuracy, with a root mean\nsquared fractional error of just 0.4% when evaluated across the same range of\ncosmologies. This function is easily invertible to obtain $A_{\\rm s}$ as a\nfunction of $\\sigma_8$ and the other cosmological parameters, if preferred. It\nis possible to obtain symbolic approximations to a seemingly complex function\nat a precision required for current and future cosmological analyses without\nresorting to deep-learning techniques, thus avoiding their black-box nature and\nlarge number of parameters. Our emulator will be usable long after the codes on\nwhich numerical approximations are built become outdated.\n","authors":["Deaglan J. Bartlett","Lukas Kammerer","Gabriel Kronberger","Harry Desmond","Pedro G. Ferreira","Benjamin D. Wandelt","Bogdan Burlacu","David Alonso","Matteo Zennaro"],"pdf_url":"https://arxiv.org/pdf/2311.15865v1.pdf","comment":"9 pages, 5 figures. Submitted to A&A"},{"id":"http://arxiv.org/abs/2311.15858v1","updated":"2023-11-27T14:25:40Z","published":"2023-11-27T14:25:40Z","title":"Multi-Agent Reinforcement Learning for Power Control in Wireless\n  Networks via Adaptive Graphs","summary":"  The ever-increasing demand for high-quality and heterogeneous wireless\ncommunication services has driven extensive research on dynamic optimization\nstrategies in wireless networks. Among several possible approaches, multi-agent\ndeep reinforcement learning (MADRL) has emerged as a promising method to\naddress a wide range of complex optimization problems like power control.\nHowever, the seamless application of MADRL to a variety of network optimization\nproblems faces several challenges related to convergence. In this paper, we\npresent the use of graphs as communication-inducing structures among\ndistributed agents as an effective means to mitigate these challenges.\nSpecifically, we harness graph neural networks (GNNs) as neural architectures\nfor policy parameterization to introduce a relational inductive bias in the\ncollective decision-making process. Most importantly, we focus on modeling the\ndynamic interactions among sets of neighboring agents through the introduction\nof innovative methods for defining a graph-induced framework for integrated\ncommunication and learning. Finally, the superior generalization capabilities\nof the proposed methodology to larger networks and to networks with different\nuser categories is verified through simulations.\n","authors":["Lorenzo Mario Amorosa","Marco Skocaj","Roberto Verdone","Deniz Gündüz"],"pdf_url":"https://arxiv.org/pdf/2311.15858v1.pdf","comment":"6 pages, 4 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2311.15854v1","updated":"2023-11-27T14:21:47Z","published":"2023-11-27T14:21:47Z","title":"A systematic study comparing hyperparameter optimization engines on\n  tabular data","summary":"  We run an independent comparison of all hyperparameter optimization\n(hyperopt) engines available in the Ray Tune library. We introduce two ways to\nnormalize and aggregate statistics across data sets and models, one rank-based,\nand another one sandwiching the score between the random search score and the\nfull grid search score. This affords us i) to rank the hyperopt engines, ii) to\nmake generalized and statistically significant statements on how much they\nimprove over random search, and iii) to make recommendations on which engine\nshould be used to hyperopt a given learning algorithm. We find that most\nengines beat random search, but that only three of them (HEBO, AX, and\nBlendSearch) clearly stand out. We also found that some engines seem to\nspecialize in hyperopting certain learning algorithms, which makes it tricky to\nuse hyperopt in comparison studies, since the choice of the hyperopt technique\nmay favor some of the models in the comparison.\n","authors":["Balazs Kegl"],"pdf_url":"https://arxiv.org/pdf/2311.15854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15847v1","updated":"2023-11-27T14:12:51Z","published":"2023-11-27T14:12:51Z","title":"Cell Maps Representation For Lung Adenocarcinoma Growth Patterns\n  Classification In Whole Slide Images","summary":"  Lung adenocarcinoma is a morphologically heterogeneous disease, characterized\nby five primary histologic growth patterns. The quantity of these patterns can\nbe related to tumor behavior and has a significant impact on patient prognosis.\nIn this work, we propose a novel machine learning pipeline capable of\nclassifying tissue tiles into one of the five patterns or as non-tumor, with an\nArea Under the Receiver Operating Characteristic Curve (AUCROC) score of 0.97.\nOur model's strength lies in its comprehensive consideration of cellular\nspatial patterns, where it first generates cell maps from Hematoxylin and Eosin\n(H&E) whole slide images (WSIs), which are then fed into a convolutional neural\nnetwork classification model. Exploiting these cell maps provides the model\nwith robust generalizability to new data, achieving approximately 30% higher\naccuracy on unseen test-sets compared to current state of the art approaches.\nThe insights derived from our model can be used to predict prognosis, enhancing\npatient outcomes.\n","authors":["Arwa Al-Rubaian","Gozde N. Gunesli","Wajd A. Althakfi","Ayesha Azam","Nasir Rajpoot","Shan E Ahmed Raza"],"pdf_url":"https://arxiv.org/pdf/2311.15847v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15838v1","updated":"2023-11-27T14:02:47Z","published":"2023-11-27T14:02:47Z","title":"Utilizing Explainability Techniques for Reinforcement Learning Model\n  Assurance","summary":"  Explainable Reinforcement Learning (XRL) can provide transparency into the\ndecision-making process of a Deep Reinforcement Learning (DRL) model and\nincrease user trust and adoption in real-world use cases. By utilizing XRL\ntechniques, researchers can identify potential vulnerabilities within a trained\nDRL model prior to deployment, therefore limiting the potential for mission\nfailure or mistakes by the system. This paper introduces the ARLIN (Assured RL\nModel Interrogation) Toolkit, an open-source Python library that identifies\npotential vulnerabilities and critical points within trained DRL models through\ndetailed, human-interpretable explainability outputs. To illustrate ARLIN's\neffectiveness, we provide explainability visualizations and vulnerability\nanalysis for a publicly available DRL model. The open-source code repository is\navailable for download at https://github.com/mitre/arlin.\n","authors":["Alexander Tapley","Kyle Gatesman","Luis Robaina","Brett Bissey","Joseph Weissman"],"pdf_url":"https://arxiv.org/pdf/2311.15838v1.pdf","comment":"9 pages, 8 figures including appendices (A, B, C). Accepted as a\n  poster presentation in the demo track at the \"XAI in Action: Past, Present,\n  and Future Applications\" workshop at NeurIPS 2023. MITRE Public Release Case\n  Number 23-3095"},{"id":"http://arxiv.org/abs/2311.15831v1","updated":"2023-11-27T13:55:21Z","published":"2023-11-27T13:55:21Z","title":"Temporal Action Localization for Inertial-based Human Activity\n  Recognition","summary":"  A persistent trend in Deep Learning has been the applicability of machine\nlearning concepts to other areas than originally introduced for. As of today,\nstate-of-the-art activity recognition from wearable sensors relies on\nclassifiers being trained on fixed windows of data. Contrarily, video-based\nHuman Activity Recognition has followed a segment-based prediction approach,\nlocalizing activity occurrences from start to end. This paper is the first to\nsystematically demonstrate the applicability of state-of-the-art TAL models for\nwearable Human Activity Recongition (HAR) using raw inertial data as input. Our\nresults show that state-of-the-art TAL models are able to outperform popular\ninertial models on 4 out of 6 wearable activity recognition benchmark datasets,\nwith improvements ranging as much as 25% in F1-score. Introducing the TAL\ncommunity's most popular metric to inertial-based HAR, namely mean Average\nPrecision, our analysis shows that TAL models are able to produce more coherent\nsegments along with an overall higher NULL-class accuracy across all datasets.\nBeing the first to provide such an analysis, the TAL community offers an\ninteresting new perspective to inertial-based HAR with yet to be explored\ndesign choices and training concepts, which could be of significant value for\nthe inertial-based HAR community.\n","authors":["Marius Bock","Michael Moeller","Kristof Van Laerhoven"],"pdf_url":"https://arxiv.org/pdf/2311.15831v1.pdf","comment":"20 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2311.15816v1","updated":"2023-11-27T13:41:20Z","published":"2023-11-27T13:41:20Z","title":"Scale-Dropout: Estimating Uncertainty in Deep Neural Networks Using\n  Stochastic Scale","summary":"  Uncertainty estimation in Neural Networks (NNs) is vital in improving\nreliability and confidence in predictions, particularly in safety-critical\napplications. Bayesian Neural Networks (BayNNs) with Dropout as an\napproximation offer a systematic approach to quantifying uncertainty, but they\ninherently suffer from high hardware overhead in terms of power, memory, and\ncomputation. Thus, the applicability of BayNNs to edge devices with limited\nresources or to high-performance applications is challenging. Some of the\ninherent costs of BayNNs can be reduced by accelerating them in hardware on a\nComputation-In-Memory (CIM) architecture with spintronic memories and\nbinarizing their parameters. However, numerous stochastic units are required to\nimplement conventional dropout-based BayNN. In this paper, we propose the Scale\nDropout, a novel regularization technique for Binary Neural Networks (BNNs),\nand Monte Carlo-Scale Dropout (MC-Scale Dropout)-based BayNNs for efficient\nuncertainty estimation. Our approach requires only one stochastic unit for the\nentire model, irrespective of the model size, leading to a highly scalable\nBayesian NN. Furthermore, we introduce a novel Spintronic memory-based CIM\narchitecture for the proposed BayNN that achieves more than $100\\times$ energy\nsavings compared to the state-of-the-art. We validated our method to show up to\na $1\\%$ improvement in predictive performance and superior uncertainty\nestimates compared to related works.\n","authors":["Soyed Tuhin Ahmed","Kamal Danouchi","Michael Hefenbrock","Guillaume Prenat","Lorena Anghel","Mehdi B. Tahoori"],"pdf_url":"https://arxiv.org/pdf/2311.15816v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15807v1","updated":"2023-11-27T13:30:20Z","published":"2023-11-27T13:30:20Z","title":"Exploring Artificial Intelligence Methods for Energy Prediction in\n  Healthcare Facilities: An In-Depth Extended Systematic Review","summary":"  Hospitals, due to their complexity and unique requirements, play a pivotal\nrole in global energy consumption patterns. This study conducted a\ncomprehensive literature review, utilizing the PRISMA framework, of articles\nthat employed machine learning and artificial intelligence techniques for\npredicting energy consumption in hospital buildings. Of the 1884 publications\nidentified, 17 were found to address this specific domain and have been\nthoroughly reviewed to establish the state-of-the-art and identify gaps where\nfuture research is needed. This review revealed a diverse range of data inputs\ninfluencing energy prediction, with occupancy and meteorological data emerging\nas significant predictors. However, many studies failed to delve deep into the\nimplications of their data choices, and gaps were evident regarding the\nunderstanding of time dynamics, operational status, and preprocessing methods.\nMachine learning, especially deep learning models like ANNs, have shown\npotential in this domain, yet they come with challenges, including\ninterpretability and computational demands. The findings underscore the immense\npotential of AI in optimizing hospital energy consumption but also highlight\nthe need for more comprehensive and granular research. Key areas for future\nresearch include the optimization of ANN approaches, new optimization and data\nintegration techniques, the integration of real-time data into Intelligent\nEnergy Management Systems, and increasing focus on long-term energy\nforecasting.\n","authors":["Marjan FatehiJananloo","Helen Stopps","J. J. McArthur"],"pdf_url":"https://arxiv.org/pdf/2311.15807v1.pdf","comment":"38 pages, 1 figure, 3 tables, systematic literature review"},{"id":"http://arxiv.org/abs/2311.15792v1","updated":"2023-11-27T13:14:39Z","published":"2023-11-27T13:14:39Z","title":"Rethinking Privacy in Machine Learning Pipelines from an Information\n  Flow Control Perspective","summary":"  Modern machine learning systems use models trained on ever-growing corpora.\nTypically, metadata such as ownership, access control, or licensing information\nis ignored during training. Instead, to mitigate privacy risks, we rely on\ngeneric techniques such as dataset sanitization and differentially private\nmodel training, with inherent privacy/utility trade-offs that hurt model\nperformance. Moreover, these techniques have limitations in scenarios where\nsensitive information is shared across multiple participants and fine-grained\naccess control is required. By ignoring metadata, we therefore miss an\nopportunity to better address security, privacy, and confidentiality\nchallenges. In this paper, we take an information flow control perspective to\ndescribe machine learning systems, which allows us to leverage metadata such as\naccess control policies and define clear-cut privacy and confidentiality\nguarantees with interpretable information flows. Under this perspective, we\ncontrast two different approaches to achieve user-level non-interference: 1)\nfine-tuning per-user models, and 2) retrieval augmented models that access\nuser-specific datasets at inference time. We compare these two approaches to a\ntrivially non-interfering zero-shot baseline using a public model and to a\nbaseline that fine-tunes this model on the whole corpus. We evaluate trained\nmodels on two datasets of scientific articles and demonstrate that retrieval\naugmented architectures deliver the best utility, scalability, and flexibility\nwhile satisfying strict non-interference guarantees.\n","authors":["Lukas Wutschitz","Boris Köpf","Andrew Paverd","Saravan Rajmohan","Ahmed Salem","Shruti Tople","Santiago Zanella-Béguelin","Menglin Xia","Victor Rühle"],"pdf_url":"https://arxiv.org/pdf/2311.15792v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01276v2","updated":"2023-11-27T13:02:50Z","published":"2023-11-02T14:44:50Z","title":"Long-Range Neural Atom Learning for Molecular Graphs","summary":"  Graph Neural Networks (GNNs) have been widely adopted for drug discovery with\nmolecular graphs. Nevertheless, current GNNs are mainly good at leveraging\nshort-range interactions (SRI) but struggle to capture long-range interactions\n(LRI), both of which are crucial for determining molecular properties. To\ntackle this issue, we propose a method that implicitly projects all original\natoms into a few Neural Atoms, which abstracts the collective information of\natomic groups within a molecule. Specifically, we explicitly exchange the\ninformation among neural atoms and project them back to the atoms'\nrepresentations as an enhancement. With this mechanism, neural atoms establish\nthe communication channels among distant nodes, effectively reducing the\ninteraction scope of arbitrary node pairs into a single hop. To provide an\ninspection of our method from a physical perspective, we reveal its connection\nwith the traditional LRI calculation method, Ewald Summation. We conduct\nextensive experiments on three long-range graph benchmarks, covering both\ngraph-level and link-level tasks on molecular graphs. We empirically justify\nthat our method can be equipped with an arbitrary GNN and help to capture LRI.\n","authors":["Xuan Li","Zhanke Zhou","Jiangchao Yao","Yu Rong","Lu Zhang","Bo Han"],"pdf_url":"https://arxiv.org/pdf/2311.01276v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.10594v2","updated":"2023-11-27T13:02:06Z","published":"2023-03-19T07:53:31Z","title":"AdaptGuard: Defending Against Universal Attacks for Model Adaptation","summary":"  Model adaptation aims at solving the domain transfer problem under the\nconstraint of only accessing the pretrained source models. With the increasing\nconsiderations of data privacy and transmission efficiency, this paradigm has\nbeen gaining recent popularity. This paper studies the vulnerability to\nuniversal attacks transferred from the source domain during model adaptation\nalgorithms due to the existence of malicious providers. We explore both\nuniversal adversarial perturbations and backdoor attacks as loopholes on the\nsource side and discover that they still survive in the target models after\nadaptation. To address this issue, we propose a model preprocessing framework,\nnamed AdaptGuard, to improve the security of model adaptation algorithms.\nAdaptGuard avoids direct use of the risky source parameters through knowledge\ndistillation and utilizes the pseudo adversarial samples under adjusted radius\nto enhance the robustness. AdaptGuard is a plug-and-play module that requires\nneither robust pretrained models nor any changes for the following model\nadaptation algorithms. Extensive results on three commonly used datasets and\ntwo popular adaptation methods validate that AdaptGuard can effectively defend\nagainst universal attacks and maintain clean accuracy in the target domain\nsimultaneously. We hope this research will shed light on the safety and\nrobustness of transfer learning. Code is available at\nhttps://github.com/TomSheng21/AdaptGuard.\n","authors":["Lijun Sheng","Jian Liang","Ran He","Zilei Wang","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2303.10594v2.pdf","comment":"ICCV2023"},{"id":"http://arxiv.org/abs/2311.15782v1","updated":"2023-11-27T12:55:39Z","published":"2023-11-27T12:55:39Z","title":"Relationship between Model Compression and Adversarial Robustness: A\n  Review of Current Evidence","summary":"  Increasing the model capacity is a known approach to enhance the adversarial\nrobustness of deep learning networks. On the other hand, various model\ncompression techniques, including pruning and quantization, can reduce the size\nof the network while preserving its accuracy. Several recent studies have\naddressed the relationship between model compression and adversarial\nrobustness, while some experiments have reported contradictory results. This\nwork summarizes available evidence and discusses possible explanations for the\nobserved effects.\n","authors":["Svetlana Pavlitska","Hannes Grolig","J. Marius Zöllner"],"pdf_url":"https://arxiv.org/pdf/2311.15782v1.pdf","comment":"Accepted for publication at SSCI 2023"},{"id":"http://arxiv.org/abs/2311.15781v1","updated":"2023-11-27T12:54:47Z","published":"2023-11-27T12:54:47Z","title":"Increasing Coverage and Precision of Textual Information in Multilingual\n  Knowledge Graphs","summary":"  Recent work in Natural Language Processing and Computer Vision has been using\ntextual information -- e.g., entity names and descriptions -- available in\nknowledge graphs to ground neural models to high-quality structured data.\nHowever, when it comes to non-English languages, the quantity and quality of\ntextual information are comparatively scarce. To address this issue, we\nintroduce the novel task of automatic Knowledge Graph Enhancement (KGE) and\nperform a thorough investigation on bridging the gap in both the quantity and\nquality of textual information between English and non-English languages. More\nspecifically, we: i) bring to light the problem of increasing multilingual\ncoverage and precision of entity names and descriptions in Wikidata; ii)\ndemonstrate that state-of-the-art methods, namely, Machine Translation (MT),\nWeb Search (WS), and Large Language Models (LLMs), struggle with this task;\niii) present M-NTA, a novel unsupervised approach that combines MT, WS, and\nLLMs to generate high-quality textual information; and, iv) study the impact of\nincreasing multilingual coverage and precision of non-English textual\ninformation in Entity Linking, Knowledge Graph Completion, and Question\nAnswering. As part of our effort towards better multilingual knowledge graphs,\nwe also introduce WikiKGE-10, the first human-curated benchmark to evaluate KGE\napproaches in 10 languages across 7 language families.\n","authors":["Simone Conia","Min Li","Daniel Lee","Umar Farooq Minhas","Ihab Ilyas","Yunyao Li"],"pdf_url":"https://arxiv.org/pdf/2311.15781v1.pdf","comment":"Camera ready for EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.15772v1","updated":"2023-11-27T12:44:42Z","published":"2023-11-27T12:44:42Z","title":"Attend Who is Weak: Enhancing Graph Condensation via Cross-Free\n  Adversarial Training","summary":"  In this paper, we study the \\textit{graph condensation} problem by\ncompressing the large, complex graph into a concise, synthetic representation\nthat preserves the most essential and discriminative information of structure\nand features. We seminally propose the concept of Shock Absorber (a type of\nperturbation) that enhances the robustness and stability of the original graphs\nagainst changes in an adversarial training fashion. Concretely, (I) we forcibly\nmatch the gradients between pre-selected graph neural networks (GNNs) trained\non a synthetic, simplified graph and the original training graph at regularly\nspaced intervals. (II) Before each update synthetic graph point, a Shock\nAbsorber serves as a gradient attacker to maximize the distance between the\nsynthetic dataset and the original graph by selectively perturbing the parts\nthat are underrepresented or insufficiently informative. We iteratively repeat\nthe above two processes (I and II) in an adversarial training fashion to\nmaintain the highly-informative context without losing correlation with the\noriginal dataset. More importantly, our shock absorber and the synthesized\ngraph parallelly share the backward process in a free training manner. Compared\nto the original adversarial training, it introduces almost no additional time\noverhead.\n  We validate our framework across 8 datasets (3 graph and 5 node\nclassification datasets) and achieve prominent results: for example, on Cora,\nCiteseer and Ogbn-Arxiv, we can gain nearly 1.13% to 5.03% improvements compare\nwith SOTA models. Moreover, our algorithm adds only about 0.2% to 2.2%\nadditional time overhead over Flicker, Citeseer and Ogbn-Arxiv. Compared to the\ngeneral adversarial training, our approach improves time efficiency by nearly\n4-fold.\n","authors":["Xinglin Li","Kun Wang","Hanhui Deng","Yuxuan Liang","Di Wu"],"pdf_url":"https://arxiv.org/pdf/2311.15772v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.16883v2","updated":"2023-11-27T12:33:27Z","published":"2023-09-28T22:41:47Z","title":"The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing","summary":"  Real-life applications of deep neural networks are hindered by their unsteady\npredictions when faced with noisy inputs and adversarial attacks. The certified\nradius is in this context a crucial indicator of the robustness of models.\nHowever how to design an efficient classifier with a sufficient certified\nradius? Randomized smoothing provides a promising framework by relying on noise\ninjection in inputs to obtain a smoothed and more robust classifier. In this\npaper, we first show that the variance introduced by randomized smoothing\nclosely interacts with two other important properties of the classifier,\n\\textit{i.e.} its Lipschitz constant and margin. More precisely, our work\nemphasizes the dual impact of the Lipschitz constant of the base classifier, on\nboth the smoothed classifier and the empirical variance. Moreover, to increase\nthe certified robust radius, we introduce a different simplex projection\ntechnique for the base classifier to leverage the variance-margin trade-off\nthanks to Bernstein's concentration inequality, along with an enhanced\nLipschitz bound. Experimental results show a significant improvement in\ncertified accuracy compared to current state-of-the-art methods. Our novel\ncertification procedure allows us to use pre-trained models that are used with\nrandomized smoothing, effectively improving the current certification radius in\na zero-shot manner.\n","authors":["Blaise Delattre","Alexandre Araujo","Quentin Barthélemy","Alexandre Allauzen"],"pdf_url":"https://arxiv.org/pdf/2309.16883v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15756v1","updated":"2023-11-27T12:22:44Z","published":"2023-11-27T12:22:44Z","title":"Learning Multi-Frequency Partial Correlation Graphs","summary":"  Despite the large research effort devoted to learning dependencies between\ntime series, the state of the art still faces a major limitation: existing\nmethods learn partial correlations but fail to discriminate across distinct\nfrequency bands. Motivated by many applications in which this differentiation\nis pivotal, we overcome this limitation by learning a block-sparse,\nfrequency-dependent, partial correlation graph, in which layers correspond to\ndifferent frequency bands, and partial correlations can occur over just a few\nlayers. To this aim, we formulate and solve two nonconvex learning problems:\nthe first has a closed-form solution and is suitable when there is prior\nknowledge about the number of partial correlations; the second hinges on an\niterative solution based on successive convex approximation, and is effective\nfor the general case where no prior knowledge is available. Numerical results\non synthetic data show that the proposed methods outperform the current state\nof the art. Finally, the analysis of financial time series confirms that\npartial correlations exist only within a few frequency bands, underscoring how\nour methods enable the gaining of valuable insights that would be undetected\nwithout discriminating along the frequency domain.\n","authors":["Gabriele D'Acunto","Paolo Di Lorenzo","Francesco Bonchi","Stefania Sardellitti","Sergio Barbarossa"],"pdf_url":"https://arxiv.org/pdf/2311.15756v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.12920v3","updated":"2023-11-27T12:18:51Z","published":"2021-02-25T15:18:13Z","title":"Emerging Trends in Federated Learning: From Model Fusion to Federated X\n  Learning","summary":"  Federated learning is a new learning paradigm that decouples data collection\nand model training via multi-party computation and model aggregation. As a\nflexible learning setting, federated learning has the potential to integrate\nwith other learning frameworks. We conduct a focused survey of federated\nlearning in conjunction with other learning algorithms. Specifically, we\nexplore various learning algorithms to improve the vanilla federated averaging\nalgorithm and review model fusion methods such as adaptive aggregation,\nregularization, clustered methods, and Bayesian methods. Following the emerging\ntrends, we also discuss federated learning in the intersection with other\nlearning paradigms, termed federated X learning, where X includes multitask\nlearning, meta-learning, transfer learning, unsupervised learning, and\nreinforcement learning. This survey reviews the state of the art, challenges,\nand future directions.\n","authors":["Shaoxiong Ji","Yue Tan","Teemu Saravirta","Zhiqin Yang","Lauri Vasankari","Shirui Pan","Guodong Long","Anwar Walid"],"pdf_url":"https://arxiv.org/pdf/2102.12920v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10092v3","updated":"2023-11-27T11:57:36Z","published":"2023-10-16T05:54:30Z","title":"Label Differential Privacy via Aggregation","summary":"  In many real-world applications, due to recent developments in the privacy\nlandscape, training data may be aggregated to preserve the privacy of sensitive\ntraining labels. In the learning from label proportions (LLP) framework, the\ndataset is partitioned into bags of feature-vectors which are available only\nwith the sum of the labels per bag. A further restriction, which we call\nlearning from bag aggregates (LBA) is where instead of individual\nfeature-vectors, only the (possibly weighted) sum of the feature-vectors per\nbag is available. We study whether such aggregation techniques can provide\nprivacy guarantees under the notion of label differential privacy (label-DP)\npreviously studied in for e.g. [Chaudhuri-Hsu'11, Ghazi et al.'21, Esfandiari\net al.'22].\n  It is easily seen that naive LBA and LLP do not provide label-DP. Our main\nresult however, shows that weighted LBA using iid Gaussian weights with $m$\nrandomly sampled disjoint $k$-sized bags is in fact $(\\varepsilon,\n\\delta)$-label-DP for any $\\varepsilon > 0$ with $\\delta \\approx\n\\exp(-\\Omega(\\sqrt{k}))$ assuming a lower bound on the linear-mse regression\nloss. Further, the $\\ell_2^2$-regressor which minimizes the loss on the\naggregated dataset has a loss within $\\left(1 + o(1)\\right)$-factor of the\noptimum on the original dataset w.p. $\\approx 1 - exp(-\\Omega(m))$. We\nemphasize that no additive label noise is required.\n  The analogous weighted-LLP does not however admit label-DP. Nevertheless, we\nshow that if additive $N(0, 1)$ noise can be added to any constant fraction of\nthe instance labels, then the noisy weighted-LLP admits similar label-DP\nguarantees without assumptions on the dataset, while preserving the utility of\nLipschitz-bounded neural mse-regression tasks.\n  Our work is the first to demonstrate that label-DP can be achieved by\nrandomly weighted aggregation for regression tasks, using no or little additive\nnoise.\n","authors":["Anand Brahmbhatt","Rishi Saket","Shreyas Havaldar","Anshul Nasery","Aravindan Raghuveer"],"pdf_url":"https://arxiv.org/pdf/2310.10092v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.07983v2","updated":"2023-11-27T11:54:56Z","published":"2023-09-14T18:40:28Z","title":"SLMIA-SR: Speaker-Level Membership Inference Attacks against Speaker\n  Recognition Systems","summary":"  Membership inference attacks allow adversaries to determine whether a\nparticular example was contained in the model's training dataset. While\nprevious works have confirmed the feasibility of such attacks in various\napplications, none has focused on speaker recognition (SR), a promising\nvoice-based biometric recognition technique. In this work, we propose SLMIA-SR,\nthe first membership inference attack tailored to SR. In contrast to\nconventional example-level attack, our attack features speaker-level membership\ninference, i.e., determining if any voices of a given speaker, either the same\nas or different from the given inference voices, have been involved in the\ntraining of a model. It is particularly useful and practical since the training\nand inference voices are usually distinct, and it is also meaningful\nconsidering the open-set nature of SR, namely, the recognition speakers were\noften not present in the training data. We utilize intra-similarity and\ninter-dissimilarity, two training objectives of SR, to characterize the\ndifferences between training and non-training speakers and quantify them with\ntwo groups of features driven by carefully-established feature engineering to\nmount the attack. To improve the generalizability of our attack, we propose a\nnovel mixing ratio training strategy to train attack models. To enhance the\nattack performance, we introduce voice chunk splitting to cope with the limited\nnumber of inference voices and propose to train attack models dependent on the\nnumber of inference voices. Our attack is versatile and can work in both\nwhite-box and black-box scenarios. Additionally, we propose two novel\ntechniques to reduce the number of black-box queries while maintaining the\nattack performance. Extensive experiments demonstrate the effectiveness of\nSLMIA-SR.\n","authors":["Guangke Chen","Yedi Zhang","Fu Song"],"pdf_url":"https://arxiv.org/pdf/2309.07983v2.pdf","comment":"In Proceedings of the 31st Network and Distributed System Security\n  (NDSS) Symposium, 2024"},{"id":"http://arxiv.org/abs/2310.01144v2","updated":"2023-11-27T11:54:55Z","published":"2023-10-02T12:32:18Z","title":"The Map Equation Goes Neural","summary":"  Community detection and graph clustering are essential for unsupervised data\nexploration and understanding the high-level organisation of networked systems.\nRecently, graph clustering has received attention as a primary task for graph\nneural networks. Although hierarchical graph pooling has been shown to improve\nperformance in graph and node classification tasks, it performs poorly in\nidentifying meaningful clusters. Community detection has a long history in\nnetwork science, but typically relies on optimising objective functions with\ncustom-tailored search algorithms, not leveraging recent advances in deep\nlearning, particularly from graph neural networks. In this paper, we narrow\nthis gap between the deep learning and network science communities. We consider\nthe map equation, an information-theoretic objective function for unsupervised\ncommunity detection. Expressing it in a fully differentiable tensor form that\nproduces soft cluster assignments, we optimise the map equation with deep\nlearning through gradient descent. More specifically, the reformulated map\nequation is a loss function compatible with any graph neural network\narchitecture, enabling flexible clustering and graph pooling that clusters both\ngraph structure and data features in an end-to-end way, automatically finding\nan optimum number of clusters without explicit regularisation by following the\nminimum description length principle. We evaluate our approach experimentally\nusing different neural network architectures for unsupervised clustering in\nsynthetic and real data. Our results show that our approach achieves\ncompetitive performance against baselines, naturally detects overlapping\ncommunities, and avoids over-partitioning sparse graphs.\n","authors":["Christopher Blöcker","Chester Tan","Ingo Scholtes"],"pdf_url":"https://arxiv.org/pdf/2310.01144v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17005v2","updated":"2023-11-27T11:43:53Z","published":"2023-05-26T15:04:06Z","title":"Aggregating Capacity in FL through Successive Layer Training for\n  Computationally-Constrained Devices","summary":"  Federated learning (FL) is usually performed on resource-constrained edge\ndevices, e.g., with limited memory for the computation. If the required memory\nto train a model exceeds this limit, the device will be excluded from the\ntraining. This can lead to a lower accuracy as valuable data and computation\nresources are excluded from training, also causing bias and unfairness. The FL\ntraining process should be adjusted to such constraints. The state-of-the-art\ntechniques propose training subsets of the FL model at constrained devices,\nreducing their resource requirements for training. But these techniques largely\nlimit the co-adaptation among parameters of the model and are highly\ninefficient, as we show: it is actually better to train a smaller (less\naccurate) model by the system where all the devices can train the model\nend-to-end, than applying such techniques. We propose a new method that enables\nsuccessive freezing and training of the parameters of the FL model at devices,\nreducing the training's resource requirements at the devices, while still\nallowing enough co-adaptation between parameters. We show through extensive\nexperimental evaluation that our technique greatly improves the accuracy of the\ntrained model (by 52.4 p.p.) compared with the state of the art, efficiently\naggregating the computation capacity available on distributed devices.\n","authors":["Kilian Pfeiffer","Ramin Khalili","Jörg Henkel"],"pdf_url":"https://arxiv.org/pdf/2305.17005v2.pdf","comment":"accepted at NeurIPS'23"},{"id":"http://arxiv.org/abs/2311.12530v2","updated":"2023-11-27T11:28:21Z","published":"2023-11-21T11:21:53Z","title":"An efficient likelihood-free Bayesian inference method based on\n  sequential neural posterior estimation","summary":"  Sequential neural posterior estimation (SNPE) techniques have been recently\nproposed for dealing with simulation-based models with intractable likelihoods.\nUnlike approximate Bayesian computation, SNPE techniques learn the posterior\nfrom sequential simulation using neural network-based conditional density\nestimators by minimizing a specific loss function. The SNPE method proposed by\nLueckmann et al. (2017) used a calibration kernel to boost the sample weights\naround the observed data, resulting in a concentrated loss function. However,\nthe use of calibration kernels may increase the variances of both the empirical\nloss and its gradient, making the training inefficient. To improve the\nstability of SNPE, this paper proposes to use an adaptive calibration kernel\nand several variance reduction techniques. The proposed method greatly speeds\nup the process of training, and provides a better approximation of the\nposterior than the original SNPE method and some existing competitors as\nconfirmed by numerical experiments.\n","authors":["Yifei Xiong","Xiliang Yang","Sanguo Zhang","Zhijian He"],"pdf_url":"https://arxiv.org/pdf/2311.12530v2.pdf","comment":"30 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.15728v1","updated":"2023-11-27T11:26:41Z","published":"2023-11-27T11:26:41Z","title":"Adinkra Symbol Recognition using Classical Machine Learning and Deep\n  Learning","summary":"  Artificial intelligence (AI) has emerged as a transformative influence,\nengendering paradigm shifts in global societies, spanning academia and\nindustry. However, in light of these rapid advances, addressing the\nunderrepresentation of black communities and African countries in AI is\ncrucial. Boosting enthusiasm for AI can be effectively accomplished by\nshowcasing straightforward applications around tasks like identifying and\ncategorizing traditional symbols, such as Adinkra symbols, or familiar objects\nwithin the community. In this research endeavor, we dived into classical\nmachine learning and harnessed the power of deep learning models to tackle the\nintricate task of classifying and recognizing Adinkra symbols. The idea led to\na newly constructed ADINKRA dataset comprising 174,338 images meticulously\norganized into 62 distinct classes, each representing a singular and emblematic\nsymbol. We constructed a CNN model for classification and recognition using six\nconvolutional layers, three fully connected (FC) layers, and optional dropout\nregularization. The model is a simpler and smaller version of VGG, with fewer\nlayers, smaller channel sizes, and a fixed kernel size. Additionally, we tap\ninto the transfer learning capabilities provided by pre-trained models like VGG\nand ResNet. These models assist us in both classifying images and extracting\nfeatures that can be used with classical machine learning models. We assess the\nmodel's performance by measuring its accuracy and convergence rate and\nvisualizing the areas that significantly influence its predictions. These\nevaluations serve as a foundational benchmark for future assessments of the\nADINKRA dataset. We hope this application exemplar inspires ideas on the\nvarious uses of AI in organizing our traditional and modern lives.\n","authors":["Michael Adjeisah","Kwame Omono Asamoah","Martha Asamoah Yeboah","Raji Rafiu King","Godwin Ferguson Achaab","Kingsley Adjei"],"pdf_url":"https://arxiv.org/pdf/2311.15728v1.pdf","comment":"15 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2311.15722v1","updated":"2023-11-27T11:17:20Z","published":"2023-11-27T11:17:20Z","title":"GLIME: General, Stable and Local LIME Explanation","summary":"  As black-box machine learning models grow in complexity and find applications\nin high-stakes scenarios, it is imperative to provide explanations for their\npredictions. Although Local Interpretable Model-agnostic Explanations (LIME)\n[22] is a widely adpoted method for understanding model behaviors, it is\nunstable with respect to random seeds [35,24,3] and exhibits low local fidelity\n(i.e., how well the explanation approximates the model's local behaviors)\n[21,16]. Our study shows that this instability problem stems from small sample\nweights, leading to the dominance of regularization and slow convergence.\nAdditionally, LIME's sampling neighborhood is non-local and biased towards the\nreference, resulting in poor local fidelity and sensitivity to reference\nchoice. To tackle these challenges, we introduce GLIME, an enhanced framework\nextending LIME and unifying several prior methods. Within the GLIME framework,\nwe derive an equivalent formulation of LIME that achieves significantly faster\nconvergence and improved stability. By employing a local and unbiased sampling\ndistribution, GLIME generates explanations with higher local fidelity compared\nto LIME. GLIME explanations are independent of reference choice. Moreover,\nGLIME offers users the flexibility to choose a sampling distribution based on\ntheir specific scenarios.\n","authors":["Zeren Tan","Yang Tian","Jian Li"],"pdf_url":"https://arxiv.org/pdf/2311.15722v1.pdf","comment":"Accepted by NeurIPS 2023 as a Spotlight paper"},{"id":"http://arxiv.org/abs/2311.15719v1","updated":"2023-11-27T11:12:33Z","published":"2023-11-27T11:12:33Z","title":"Variational Autoencoders for Feature Exploration and Malignancy\n  Prediction of Lung Lesions","summary":"  Lung cancer is responsible for 21% of cancer deaths in the UK and five-year\nsurvival rates are heavily influenced by the stage the cancer was identified\nat. Recent studies have demonstrated the capability of AI methods for accurate\nand early diagnosis of lung cancer from routine scans. However, this evidence\nhas not translated into clinical practice with one barrier being a lack of\ninterpretable models. This study investigates the application Variational\nAutoencoders (VAEs), a type of generative AI model, to lung cancer lesions.\nProposed models were trained on lesions extracted from 3D CT scans in the\nLIDC-IDRI public dataset. Latent vector representations of 2D slices produced\nby the VAEs were explored through clustering to justify their quality and used\nin an MLP classifier model for lung cancer diagnosis, the best model achieved\nstate-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows\nthe VAE latent space separates the dataset of malignant and benign lesions\nbased on meaningful feature components including tumour size, shape, patient\nand malignancy class. We also include a comparative analysis of the standard\nGaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces\nthe prior with a Dirichlet distribution to encourage a more explainable latent\nspace with disentangled feature representation. Finally, we demonstrate the\npotential for latent space traversals corresponding to clinically meaningful\nfeature changes.\n","authors":["Benjamin Keel","Aaron Quyn","David Jayne","Samuel D. Relton"],"pdf_url":"https://arxiv.org/pdf/2311.15719v1.pdf","comment":"10 pages (main paper), 5 pages (references), 5 figures, 2 tables,\n  work accepted for BMVC 2023"},{"id":"http://arxiv.org/abs/2311.15703v1","updated":"2023-11-27T10:41:28Z","published":"2023-11-27T10:41:28Z","title":"Tabular Two-Dimensional Correlation Analysis for Multifaceted\n  Characterization Data","summary":"  We propose tabular two-dimensional correlation analysis for extracting\nfeatures from multifaceted characterization data, essential for understanding\nmaterial properties. This method visualizes similarities and phase lags in\nstructural parameter changes through heatmaps, combining hierarchical\nclustering and asynchronous correlations. We applied the proposed method to\ndatasets of carbon nanotube (CNTs) films annealed at various temperatures and\nrevealed the complexity of their hierarchical structures, which include\nelements like voids, bundles, and amorphous carbon. Our analysis addresses the\nchallenge of attempting to understand the sequence of structural changes,\nespecially in multifaceted characterization data where 11 structural parameters\nderived from 8 characterization methods interact with complex behavior. The\nresults show how phase lags (asynchronous changes from stimuli) and parameter\nsimilarities can illuminate the sequence of structural changes in materials,\nproviding insights into phenomena like the removal of amorphous carbon and\ngraphitization in annealed CNTs. This approach is beneficial even with limited\ndata and holds promise for a wide range of material analyses, demonstrating its\npotential in elucidating complex material behaviors and properties.\n","authors":["Shun Muroga","Satoshi Yamazaki","Koji Michishio","Hideaki Nakajima","Takahiro Morimoto","Nagayasu Oshima","Kazufumi Kobashi","Toshiya Okazaki"],"pdf_url":"https://arxiv.org/pdf/2311.15703v1.pdf","comment":"15 pages, 4 figures"},{"id":"http://arxiv.org/abs/2310.01825v2","updated":"2023-11-27T10:39:13Z","published":"2023-10-03T06:42:28Z","title":"Empirical Study of PEFT techniques for Winter Wheat Segmentation","summary":"  Parameter Efficient Fine Tuning (PEFT) techniques have recently experienced\nsignificant growth and have been extensively employed to adapt large vision and\nlanguage models to various domains, enabling satisfactory model performance\nwith minimal computational needs. Despite these advances, more research has yet\nto delve into potential PEFT applications in real-life scenarios, particularly\nin the critical domains of remote sensing and crop monitoring. The diversity of\nclimates across different regions and the need for comprehensive large-scale\ndatasets have posed significant obstacles to accurately identify crop types\nacross varying geographic locations and changing growing seasons. This study\nseeks to bridge this gap by comprehensively exploring the feasibility of\ncross-area and cross-year out-of-distribution generalization using the\nState-of-the-Art (SOTA) wheat crop monitoring model. The aim of this work is to\nexplore PEFT approaches for crop monitoring. Specifically, we focus on adapting\nthe SOTA TSViT model to address winter wheat field segmentation, a critical\ntask for crop monitoring and food security. This adaptation process involves\nintegrating different PEFT techniques, including BigFit, LoRA, Adaptformer, and\nprompt tuning. Using PEFT techniques, we achieved notable results comparable to\nthose achieved using full fine-tuning methods while training only a mere 0.7%\nparameters of the whole TSViT architecture. The in-house labeled data-set,\nreferred to as the Beqaa-Lebanon dataset, comprises high-quality annotated\npolygons for wheat and non-wheat classes with a total surface of 170 kmsq, over\nfive consecutive years. Using Sentinel-2 images, our model achieved a 84%\nF1-score. We intend to publicly release the Lebanese winter wheat data set,\ncode repository, and model weights.\n","authors":["Mohamad Hasan Zahweh","Hasan Nasrallah","Mustafa Shukor","Ghaleb Faour","Ali J. Ghandour"],"pdf_url":"https://arxiv.org/pdf/2310.01825v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15696v1","updated":"2023-11-27T10:32:31Z","published":"2023-11-27T10:32:31Z","title":"Peptide Binding Classification on Quantum Computers","summary":"  We conduct an extensive study on using near-term quantum computers for a task\nin the domain of computational biology. By constructing quantum models based on\nparameterised quantum circuits we perform sequence classification on a task\nrelevant to the design of therapeutic proteins, and find competitive\nperformance with classical baselines of similar scale. To study the effect of\nnoise, we run some of the best-performing quantum models with favourable\nresource requirements on emulators of state-of-the-art noisy quantum\nprocessors. We then apply error mitigation methods to improve the signal. We\nfurther execute these quantum models on the Quantinuum H1-1 trapped-ion quantum\nprocessor and observe very close agreement with noiseless exact simulation.\nFinally, we perform feature attribution methods and find that the quantum\nmodels indeed identify sensible relationships, at least as well as the\nclassical baselines. This work constitutes the first proof-of-concept\napplication of near-term quantum computing to a task critical to the design of\ntherapeutic proteins, opening the route toward larger-scale applications in\nthis and related fields, in line with the hardware development roadmaps of\nnear-term quantum technologies.\n","authors":["Charles London","Douglas Brown","Wenduan Xu","Sezen Vatansever","Christopher James Langmead","Dimitri Kartsaklis","Stephen Clark","Konstantinos Meichanetzidis"],"pdf_url":"https://arxiv.org/pdf/2311.15696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15691v1","updated":"2023-11-27T10:28:44Z","published":"2023-11-27T10:28:44Z","title":"Automated discovery of trade-off between utility, privacy and fairness\n  in machine learning models","summary":"  Machine learning models are deployed as a central component in decision\nmaking and policy operations with direct impact on individuals' lives. In order\nto act ethically and comply with government regulations, these models need to\nmake fair decisions and protect the users' privacy. However, such requirements\ncan come with decrease in models' performance compared to their potentially\nbiased, privacy-leaking counterparts. Thus the trade-off between fairness,\nprivacy and performance of ML models emerges, and practitioners need a way of\nquantifying this trade-off to enable deployment decisions. In this work we\ninterpret this trade-off as a multi-objective optimization problem, and propose\nPFairDP, a pipeline that uses Bayesian optimization for discovery of\nPareto-optimal points between fairness, privacy and utility of ML models. We\nshow how PFairDP can be used to replicate known results that were achieved\nthrough manual constraint setting process. We further demonstrate effectiveness\nof PFairDP with experiments on multiple models and datasets.\n","authors":["Bogdan Ficiu","Neil D. Lawrence","Andrei Paleyes"],"pdf_url":"https://arxiv.org/pdf/2311.15691v1.pdf","comment":"3rd Workshop on Bias and Fairness in AI (BIAS), ECML 2023"},{"id":"http://arxiv.org/abs/2306.07294v2","updated":"2023-11-27T10:21:24Z","published":"2023-06-10T11:25:31Z","title":"Computational and Storage Efficient Quadratic Neurons for Deep Neural\n  Networks","summary":"  Deep neural networks (DNNs) have been widely deployed across diverse domains\nsuch as computer vision and natural language processing. However, the\nimpressive accomplishments of DNNs have been realized alongside extensive\ncomputational demands, thereby impeding their applicability on\nresource-constrained devices. To address this challenge, many researchers have\nbeen focusing on basic neuron structures, the fundamental building blocks of\nneural networks, to alleviate the computational and storage cost. In this work,\nan efficient quadratic neuron architecture distinguished by its enhanced\nutilization of second-order computational information is introduced. By virtue\nof their better expressivity, DNNs employing the proposed quadratic neurons can\nattain similar accuracy with fewer neurons and computational cost. Experimental\nresults have demonstrated that the proposed quadratic neuron structure exhibits\nsuperior computational and storage efficiency across various tasks when\ncompared with both linear and non-linear neurons in prior work.\n","authors":["Chuangtao Chen","Grace Li Zhang","Xunzhao Yin","Cheng Zhuo","Ulf Schlichtmann","Bing Li"],"pdf_url":"https://arxiv.org/pdf/2306.07294v2.pdf","comment":"Accepted by Design Automation and Test in Europe (DATE) 2024"},{"id":"http://arxiv.org/abs/2311.15685v1","updated":"2023-11-27T10:18:17Z","published":"2023-11-27T10:18:17Z","title":"The Battleship Approach to the Low Resource Entity Matching Problem","summary":"  Entity matching, a core data integration problem, is the task of deciding\nwhether two data tuples refer to the same real-world entity. Recent advances in\ndeep learning methods, using pre-trained language models, were proposed for\nresolving entity matching. Although demonstrating unprecedented results, these\nsolutions suffer from a major drawback as they require large amounts of labeled\ndata for training, and, as such, are inadequate to be applied to low resource\nentity matching problems. To overcome the challenge of obtaining sufficient\nlabeled data we offer a new active learning approach, focusing on a selection\nmechanism that exploits unique properties of entity matching. We argue that a\ndistributed representation of a tuple pair indicates its informativeness when\nconsidered among other pairs. This is used consequently in our approach that\niteratively utilizes space-aware considerations. Bringing it all together, we\ntreat the low resource entity matching problem as a Battleship game, hunting\nindicative samples, focusing on positive ones, through awareness of the latent\nspace along with careful planning of next sampling iterations. An extensive\nexperimental analysis shows that the proposed algorithm outperforms\nstate-of-the-art active learning solutions to low resource entity matching, and\nalthough using less samples, can be as successful as state-of-the-art fully\ntrained known algorithms.\n","authors":["Bar Genossar","Avigdor Gal","Roee Shraga"],"pdf_url":"https://arxiv.org/pdf/2311.15685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15682v1","updated":"2023-11-27T10:16:22Z","published":"2023-11-27T10:16:22Z","title":"Information theoretic study of the neural geometry induced by category\n  learning","summary":"  Categorization is an important topic both for biological and artificial\nneural networks. Here, we take an information theoretic approach to assess the\nefficiency of the representations induced by category learning. We show that\none can decompose the relevant Bayesian cost into two components, one for the\ncoding part and one for the decoding part. Minimizing the coding cost implies\nmaximizing the mutual information between the set of categories and the neural\nactivities. We analytically show that this mutual information can be written as\nthe sum of two terms that can be interpreted as (i) finding an appropriate\nrepresentation space, and, (ii) building a representation with the appropriate\nmetrics, based on the neural Fisher information on this space. One main\nconsequence is that category learning induces an expansion of neural space near\ndecision boundaries. Finally, we provide numerical illustrations that show how\nFisher information of the coding neural population aligns with the boundaries\nbetween categories.\n","authors":["Laurent Bonnasse-Gahot","Jean-Pierre Nadal"],"pdf_url":"https://arxiv.org/pdf/2311.15682v1.pdf","comment":"7 pages, 2 figures, Accepted (Oral) to InfoCog@NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.15673v1","updated":"2023-11-27T10:02:12Z","published":"2023-11-27T10:02:12Z","title":"Accelerating Hierarchical Associative Memory: A Deep Equilibrium\n  Approach","summary":"  Hierarchical Associative Memory models have recently been proposed as a\nversatile extension of continuous Hopfield networks. In order to facilitate\nfuture research on such models, especially at scale, we focus on increasing\ntheir simulation efficiency on digital hardware. In particular, we propose two\nstrategies to speed up memory retrieval in these models, which corresponds to\ntheir use at inference, but is equally important during training. First, we\nshow how they can be cast as Deep Equilibrium Models, which allows using faster\nand more stable solvers. Second, inspired by earlier work, we show that\nalternating optimization of the even and odd layers accelerates memory\nretrieval by a factor close to two. Combined, these two techniques allow for a\nmuch faster energy minimization, as shown in our proof-of-concept experimental\nresults. The code is available at https://github.com/cgoemaere/hamdeq\n","authors":["Cédric Goemaere","Johannes Deleu","Thomas Demeester"],"pdf_url":"https://arxiv.org/pdf/2311.15673v1.pdf","comment":"Accepted at the \"Associative Memory & Hopfield Networks'' workshop at\n  NeurIPS, 2023"},{"id":"http://arxiv.org/abs/2311.13265v2","updated":"2023-11-27T09:40:19Z","published":"2023-11-22T09:31:19Z","title":"Improved identification accuracy in equation learning via comprehensive\n  $\\boldsymbol{R^2}$-elimination and Bayesian model selection","summary":"  In the field of equation learning, exhaustively considering all possible\nequations derived from a basis function dictionary is infeasible. Sparse\nregression and greedy algorithms have emerged as popular approaches to tackle\nthis challenge. However, the presence of multicollinearity poses difficulties\nfor sparse regression techniques, and greedy steps may inadvertently exclude\nterms of the true equation, leading to reduced identification accuracy. In this\narticle, we present an approach that strikes a balance between\ncomprehensiveness and efficiency in equation learning. Inspired by stepwise\nregression, our approach combines the coefficient of determination, $R^2$, and\nthe Bayesian model evidence, $p(\\boldsymbol y|\\mathcal M)$, in a novel way. Our\nprocedure is characterized by a comprehensive search with just a minor\nreduction of the model space at each iteration step. With two flavors of our\napproach and the adoption of $p(\\boldsymbol y|\\mathcal M)$ for bi-directional\nstepwise regression, we present a total of three new avenues for equation\nlearning. Through three extensive numerical experiments involving random\npolynomials and dynamical systems, we compare our approach against four\nstate-of-the-art methods and two standard approaches. The results demonstrate\nthat our comprehensive search approach surpasses all other methods in terms of\nidentification accuracy. In particular, the second flavor of our approach\nestablishes an efficient overfitting penalty solely based on $R^2$, which\nachieves highest rates of exact equation recovery.\n","authors":["Daniel Nickelsen","Bubacarr Bah"],"pdf_url":"https://arxiv.org/pdf/2311.13265v2.pdf","comment":"12 pages main text and 11 pages appendix, Published in TMLR\n  (https://openreview.net/forum?id=0ck7hJ8EVC)"},{"id":"http://arxiv.org/abs/2311.15658v1","updated":"2023-11-27T09:40:14Z","published":"2023-11-27T09:40:14Z","title":"Regularization by Texts for Latent Diffusion Inverse Solvers","summary":"  The recent advent of diffusion models has led to significant progress in\nsolving inverse problems, leveraging these models as effective generative\npriors. Nonetheless, challenges related to the ill-posed nature of such\nproblems remain, often due to inherent ambiguities in measurements. Drawing\ninspiration from the human ability to resolve visual ambiguities through\nperceptual biases, here we introduce a novel latent diffusion inverse solver by\nincorporating regularization by texts (TReg). Specifically, TReg applies the\ntextual description of the preconception of the solution during the reverse\nsampling phase, of which description isndynamically reinforced through\nnull-text optimization for adaptive negation. Our comprehensive experimental\nresults demonstrate that TReg successfully mitigates ambiguity in latent\ndiffusion inverse solvers, enhancing their effectiveness and accuracy.\n","authors":["Jeongsol Kim","Geon Yeong Park","Hyungjin Chung","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2311.15658v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15654v1","updated":"2023-11-27T09:33:56Z","published":"2023-11-27T09:33:56Z","title":"Universal Event Detection in Time Series","summary":"  In our previously published work, we introduced a supervised deep learning\nmethod for event detection in multivariate time series data, employing\nregression instead of binary classification. This simplification avoids the\nneed for point-wise labels throughout the entire dataset, relying solely on\nground truth events defined as time points or intervals. In this paper, we\nestablish mathematically that our method is universal, and capable of detecting\nany type of event with arbitrary precision under mild continuity assumptions on\nthe time series. These events may encompass change points, frauds, anomalies,\nphysical occurrences, and more. We substantiate our theoretical results using\nthe universal approximation theorem for feed-forward neural networks (FFN).\nAdditionally, we provide empirical validations that confirm our claims,\ndemonstrating that our method, with a limited number of parameters, outperforms\nother deep learning approaches, particularly for rare events and imbalanced\ndatasets from different domains.\n","authors":["Menouar Azib","Benjamin Renard","Philippe Garnier","Vincent Génot","Nicolas André"],"pdf_url":"https://arxiv.org/pdf/2311.15654v1.pdf","comment":"To be submitted to IEEE Transactions on Neural Networks and Learning\n  Systems"},{"id":"http://arxiv.org/abs/2311.15649v1","updated":"2023-11-27T09:20:23Z","published":"2023-11-27T09:20:23Z","title":"RoboGPT: an intelligent agent of making embodied long-term decisions for\n  daily instruction tasks","summary":"  Robotic agents must master common sense and long-term sequential decisions to\nsolve daily tasks through natural language instruction. The developments in\nLarge Language Models (LLMs) in natural language processing have inspired\nefforts to use LLMs in complex robot planning. Despite LLMs' great\ngeneralization and comprehension of instruction tasks, LLMs-generated task\nplans sometimes lack feasibility and correctness. To address the problem, we\npropose a RoboGPT agent\\footnote{our code and dataset will be released soon}\nfor making embodied long-term decisions for daily tasks, with two modules: 1)\nLLMs-based planning with re-plan to break the task into multiple sub-goals; 2)\nRoboSkill individually designed for sub-goals to learn better navigation and\nmanipulation skills. The LLMs-based planning is enhanced with a new robotic\ndataset and re-plan, called RoboGPT. The new robotic dataset of 67k daily\ninstruction tasks is gathered for fine-tuning the Llama model and obtaining\nRoboGPT. RoboGPT planner with strong generalization can plan hundreds of daily\ninstruction tasks. Additionally, a low-computational Re-Plan module is designed\nto allow plans to flexibly adapt to the environment, thereby addressing the\nnomenclature diversity challenge. The proposed RoboGPT agent outperforms SOTA\nmethods on the ALFRED daily tasks. Moreover, RoboGPT planner exceeds SOTA\nLLM-based planners like ChatGPT in task-planning rationality for hundreds of\nunseen daily tasks, and even other domain tasks, while keeping the large\nmodel's original broad application and generality.\n","authors":["Yaran Chen","Wenbo Cui","Yuanwen Chen","Mining Tan","Xinyao Zhang","Dongbin Zhao","He Wang"],"pdf_url":"https://arxiv.org/pdf/2311.15649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15648v1","updated":"2023-11-27T09:20:12Z","published":"2023-11-27T09:20:12Z","title":"Reinforcement Learning from Diffusion Feedback: Q* for Image Search","summary":"  Large vision-language models are steadily gaining personalization\ncapabilities at the cost of fine-tuning or data augmentation. We present two\nmodels for image generation using model-agnostic learning that align semantic\npriors with generative capabilities. RLDF, or Reinforcement Learning from\nDiffusion Feedback, is a singular approach for visual imitation through\nprior-preserving reward function guidance. This employs Q-learning (with\nstandard Q*) for generation and follows a semantic-rewarded trajectory for\nimage search through finite encoding-tailored actions. The second proposed\nmethod, noisy diffusion gradient, is optimization driven. At the root of both\nmethods is a special CFG encoding that we propose for continual semantic\nguidance. Using only a single input image and no text input, RLDF generates\nhigh-quality images over varied domains including retail, sports and\nagriculture showcasing class-consistency and strong visual diversity. Project\nwebsite is available at https://infernolia.github.io/RLDF.\n","authors":["Aboli Marathe"],"pdf_url":"https://arxiv.org/pdf/2311.15648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15647v1","updated":"2023-11-27T09:19:01Z","published":"2023-11-27T09:19:01Z","title":"Bandits Meet Mechanism Design to Combat Clickbait in Online\n  Recommendation","summary":"  We study a strategic variant of the multi-armed bandit problem, which we coin\nthe strategic click-bandit. This model is motivated by applications in online\nrecommendation where the choice of recommended items depends on both the\nclick-through rates and the post-click rewards. Like in classical bandits,\nrewards follow a fixed unknown distribution. However, we assume that the\nclick-rate of each arm is chosen strategically by the arm (e.g., a host on\nAirbnb) in order to maximize the number of times it gets clicked. The algorithm\ndesigner does not know the post-click rewards nor the arms' actions (i.e.,\nstrategically chosen click-rates) in advance, and must learn both values over\ntime. To solve this problem, we design an incentive-aware learning algorithm,\nUCB-S, which achieves two goals simultaneously: (a) incentivizing desirable arm\nbehavior under uncertainty; (b) minimizing regret by learning unknown\nparameters. We characterize all approximate Nash equilibria among arms under\nUCB-S and show a $\\tilde{\\mathcal{O}} (\\sqrt{KT})$ regret bound uniformly in\nevery equilibrium. We also show that incentive-unaware algorithms generally\nfail to achieve low regret in the strategic click-bandit. Finally, we support\nour theoretical results by simulations of strategic arm behavior which confirm\nthe effectiveness and robustness of our proposed incentive design.\n","authors":["Thomas Kleine Buening","Aadirupa Saha","Christos Dimitrakakis","Haifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2311.15647v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.14969v2","updated":"2023-11-27T09:06:55Z","published":"2023-08-29T01:47:49Z","title":"Uncovering the Hidden Cost of Model Compression","summary":"  In the era of resource-intensive foundation models, efficient adaptation in\ndownstream tasks has become paramount. Visual Prompting (VP), inspired by\nprompting in Large Language Models (LLMs), has emerged as a key transfer\nlearning method in computer vision. Aligned with the growing significance of\nefficiency, research in model compression has become pivotal to alleviate the\ncomputational burden in both training and deploying over-parameterized neural\nnetworks. A key goal in model compression is the development of sparse models\ncapable of matching or surpassing the performance of their over-parameterized,\ndense counterparts. While prior research has explored the impact of model\nsparsity on transfer learning, its effects on visual prompting-based transfer\nremain unclear. This study addresses this gap, revealing that model sparsity\nadversely affects the performance of visual prompting-based transfer,\nparticularly in low-data-volume scenarios. Furthermore, our findings highlight\nthe negative influence of sparsity on the calibration of downstream\nvisual-prompted models. This empirical exploration calls for a nuanced\nunderstanding beyond accuracy in sparse settings, opening avenues for further\nresearch in Visual Prompting for sparse models. Code and logs can be accessed\nat https://github.com/landskape-ai/Reprogram_LT .\n","authors":["Diganta Misra","Agam Goyal","Bharat Runwal","Pin Yu Chen"],"pdf_url":"https://arxiv.org/pdf/2308.14969v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2311.15623v1","updated":"2023-11-27T08:38:42Z","published":"2023-11-27T08:38:42Z","title":"Injecting linguistic knowledge into BERT for Dialogue State Tracking","summary":"  Dialogue State Tracking (DST) models often employ intricate neural network\narchitectures, necessitating substantial training data, and their inference\nprocesses lack transparency. This paper proposes a method that extracts\nlinguistic knowledge via an unsupervised framework and subsequently utilizes\nthis knowledge to augment BERT's performance and interpretability in DST tasks.\nThe knowledge extraction procedure is computationally economical and does not\nnecessitate annotations or additional training data. The injection of the\nextracted knowledge necessitates the addition of only simple neural modules. We\nemploy the Convex Polytopic Model (CPM) as a feature extraction tool for DST\ntasks and illustrate that the acquired features correlate with the syntactic\nand semantic patterns in the dialogues. This correlation facilitates a\ncomprehensive understanding of the linguistic features influencing the DST\nmodel's decision-making process. We benchmark this framework on various DST\ntasks and observe a notable improvement in accuracy.\n","authors":["Xiaohan Feng","Xixin Wu","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2311.15623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15617v1","updated":"2023-11-27T08:28:08Z","published":"2023-11-27T08:28:08Z","title":"VeryFL: A Verify Federated Learning Framework Embedded with Blockchain","summary":"  Blockchain-empowered federated learning (FL) has provoked extensive research\nrecently. Various blockchain-based federated learning algorithm, architecture\nand mechanism have been designed to solve issues like single point failure and\ndata falsification brought by centralized FL paradigm. Moreover, it is easier\nto allocate incentives to nodes with the help of the blockchain. Various\ncentralized federated learning frameworks like FedML, have emerged in the\ncommunity to help boost the research on FL. However, decentralized\nblockchain-based federated learning framework is still missing, which cause\ninconvenience for researcher to reproduce or verify the algorithm performance\nbased on blockchain. Inspired by the above issues, we have designed and\ndeveloped a blockchain-based federated learning framework by embedding Ethereum\nnetwork. This report will present the overall structure of this framework,\nwhich proposes a code practice paradigm for the combination of FL with\nblockchain and, at the same time, compatible with normal FL training task. In\naddition to implement some blockchain federated learning algorithms on smart\ncontract to help execute a FL training, we also propose a model ownership\nauthentication architecture based on blockchain and model watermarking to\nprotect the intellectual property rights of models. These mechanism on\nblockchain shows an underlying support of blockchain for federated learning to\nprovide a verifiable training, aggregation and incentive distribution procedure\nand thus we named this framework VeryFL (A Verify Federated Learninig Framework\nEmbedded with Blockchain). The source code is avaliable on\nhttps://github.com/GTMLLab/VeryFL.\n","authors":["Yihao Li","Yanyi Lai","Chuan Chen","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2311.15617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15610v1","updated":"2023-11-27T08:10:53Z","published":"2023-11-27T08:10:53Z","title":"Bayesian Approach to Linear Bayesian Networks","summary":"  This study proposes the first Bayesian approach for learning high-dimensional\nlinear Bayesian networks. The proposed approach iteratively estimates each\nelement of the topological ordering from backward and its parent using the\ninverse of a partial covariance matrix. The proposed method successfully\nrecovers the underlying structure when Bayesian regularization for the inverse\ncovariance matrix with unequal shrinkage is applied. Specifically, it shows\nthat the number of samples $n = \\Omega( d_M^2 \\log p)$ and $n = \\Omega(d_M^2\np^{2/m})$ are sufficient for the proposed algorithm to learn linear Bayesian\nnetworks with sub-Gaussian and 4m-th bounded-moment error distributions,\nrespectively, where $p$ is the number of nodes and $d_M$ is the maximum degree\nof the moralized graph. The theoretical findings are supported by extensive\nsimulation studies including real data analysis. Furthermore the proposed\nmethod is demonstrated to outperform state-of-the-art frequentist approaches,\nsuch as the BHLSM, LISTEN, and TD algorithms in synthetic data.\n","authors":["Seyong Hwang","Kyoungjae Lee","Sunmin Oh","Gunwoong Park"],"pdf_url":"https://arxiv.org/pdf/2311.15610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.03543v2","updated":"2023-11-27T08:09:20Z","published":"2021-03-05T08:45:43Z","title":"Artificial Neural Networks generated by Low Discrepancy Sequences","summary":"  Artificial neural networks can be represented by paths. Generated as random\nwalks on a dense network graph, we find that the resulting sparse networks\nallow for deterministic initialization and even weights with fixed sign. Such\nnetworks can be trained sparse from scratch, avoiding the expensive procedure\nof training a dense network and compressing it afterwards. Although sparse,\nweights are accessed as contiguous blocks of memory. In addition, enumerating\nthe paths using deterministic low discrepancy sequences, for example the Sobol'\nsequence, amounts to connecting the layers of neural units by progressive\npermutations, which naturally avoids bank conflicts in parallel computer\nhardware. We demonstrate that the artificial neural networks generated by low\ndiscrepancy sequences can achieve an accuracy within reach of their dense\ncounterparts at a much lower computational complexity.\n","authors":["Alexander Keller","Matthijs Van keirsbilck"],"pdf_url":"https://arxiv.org/pdf/2103.03543v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15609v1","updated":"2023-11-27T08:06:56Z","published":"2023-11-27T08:06:56Z","title":"A manometric feature descriptor with linear-SVM to distinguish\n  esophageal contraction vigor","summary":"  n clinical, if a patient presents with nonmechanical obstructive dysphagia,\nesophageal chest pain, and gastro esophageal reflux symptoms, the physician\nwill usually assess the esophageal dynamic function. High-resolution manometry\n(HRM) is a clinically commonly used technique for detection of esophageal\ndynamic function comprehensively and objectively. However, after the results of\nHRM are obtained, doctors still need to evaluate by a variety of parameters.\nThis work is burdensome, and the process is complex. We conducted image\nprocessing of HRM to predict the esophageal contraction vigor for assisting the\nevaluation of esophageal dynamic function. Firstly, we used Feature-Extraction\nand Histogram of Gradients (FE-HOG) to analyses feature of proposal of swallow\n(PoS) to further extract higher-order features. Then we determine the\nclassification of esophageal contraction vigor normal, weak and failed by using\nlinear-SVM according to these features. Our data set includes 3000 training\nsets, 500 validation sets and 411 test sets. After verification our accuracy\nreaches 86.83%, which is higher than other common machine learning methods.\n","authors":["Jialin Liu","Lu Yan","Xiaowei Liu","Yuzhuo Dai","Fanggen Lu","Yuanting Ma","Muzhou Hou","Zheng Wang"],"pdf_url":"https://arxiv.org/pdf/2311.15609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15603v1","updated":"2023-11-27T07:53:44Z","published":"2023-11-27T07:53:44Z","title":"QuickDrop: Efficient Federated Unlearning by Integrated Dataset\n  Distillation","summary":"  Federated Unlearning (FU) aims to delete specific training data from an ML\nmodel trained using Federated Learning (FL). We introduce QuickDrop, an\nefficient and original FU method that utilizes dataset distillation (DD) to\naccelerate unlearning and drastically reduces computational overhead compared\nto existing approaches. In QuickDrop, each client uses DD to generate a compact\ndataset representative of the original training dataset, called a distilled\ndataset, and uses this compact dataset during unlearning. To unlearn specific\nknowledge from the global model, QuickDrop has clients execute Stochastic\nGradient Ascent with samples from the distilled datasets, thus significantly\nreducing computational overhead compared to conventional FU methods. We further\nincrease the efficiency of QuickDrop by ingeniously integrating DD into the FL\ntraining process. By reusing the gradient updates produced during FL training\nfor DD, the overhead of creating distilled datasets becomes close to\nnegligible. Evaluations on three standard datasets show that, with comparable\naccuracy guarantees, QuickDrop reduces the duration of unlearning by 463.8x\ncompared to model retraining from scratch and 65.1x compared to existing FU\napproaches. We also demonstrate the scalability of QuickDrop with 100 clients\nand show its effectiveness while handling multiple unlearning operations.\n","authors":["Akash Dhasade","Yaohong Ding","Song Guo","Anne-marie Kermarrec","Martijn De Vos","Leijie Wu"],"pdf_url":"https://arxiv.org/pdf/2311.15603v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15598v1","updated":"2023-11-27T07:48:50Z","published":"2023-11-27T07:48:50Z","title":"Optimal Clustering of Discrete Mixtures: Binomial, Poisson, Block\n  Models, and Multi-layer Networks","summary":"  In this paper, we first study the fundamental limit of clustering networks\nwhen a multi-layer network is present. Under the mixture multi-layer stochastic\nblock model (MMSBM), we show that the minimax optimal network clustering error\nrate, which takes an exponential form and is characterized by the Renyi\ndivergence between the edge probability distributions of the component\nnetworks. We propose a novel two-stage network clustering method including a\ntensor-based initialization algorithm involving both node and sample splitting\nand a refinement procedure by likelihood-based Lloyd algorithm. Network\nclustering must be accompanied by node community detection. Our proposed\nalgorithm achieves the minimax optimal network clustering error rate and allows\nextreme network sparsity under MMSBM. Numerical simulations and real data\nexperiments both validate that our method outperforms existing methods.\nOftentimes, the edges of networks carry count-type weights. We then extend our\nmethodology and analysis framework to study the minimax optimal clustering\nerror rate for mixture of discrete distributions including Binomial, Poisson,\nand multi-layer Poisson networks. The minimax optimal clustering error rates in\nthese discrete mixtures all take the same exponential form characterized by the\nRenyi divergences. These optimal clustering error rates in discrete mixtures\ncan also be achieved by our proposed two-stage clustering algorithm.\n","authors":["Zhongyuan Lyu","Ting Li","Dong Xia"],"pdf_url":"https://arxiv.org/pdf/2311.15598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15599v1","updated":"2023-11-27T07:48:50Z","published":"2023-11-27T07:48:50Z","title":"UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio,\n  Video, Point Cloud, Time-Series and Image Recognition","summary":"  Large-kernel convolutional neural networks (ConvNets) have recently received\nextensive research attention, but there are two unresolved and critical issues\nthat demand further investigation. 1) The architectures of existing\nlarge-kernel ConvNets largely follow the design principles of conventional\nConvNets or transformers, while the architectural design for large-kernel\nConvNets remains under-addressed. 2) As transformers have dominated multiple\nmodalities, it remains to be investigated whether ConvNets also have a strong\nuniversal perception ability in domains beyond vision. In this paper, we\ncontribute from two aspects. 1) We propose four architectural guidelines for\ndesigning large-kernel ConvNets, the core of which is to exploit the essential\ncharacteristics of large kernels that distinguish them from small kernels -\nthey can see wide without going deep. Following such guidelines, our proposed\nlarge-kernel ConvNet shows leading performance in image recognition. For\nexample, our models achieve an ImageNet accuracy of 88.0%, ADE20K mIoU of\n55.6%, and COCO box AP of 56.4%, demonstrating better performance and higher\nspeed than a number of recently proposed powerful competitors. 2) We discover\nthat large kernels are the key to unlocking the exceptional performance of\nConvNets in domains where they were originally not proficient. With certain\nmodality-related preprocessing approaches, the proposed model achieves\nstate-of-the-art performance on time-series forecasting and audio recognition\ntasks even without modality-specific customization to the architecture. Code\nand all the models at https://github.com/AILab-CVC/UniRepLKNet.\n","authors":["Xiaohan Ding","Yiyuan Zhang","Yixiao Ge","Sijie Zhao","Lin Song","Xiangyu Yue","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2311.15599v1.pdf","comment":"Code, all the models and reproducible training scripts at\n  https://github.com/AILab-CVC/UniRepLKNet"},{"id":"http://arxiv.org/abs/2310.20587v4","updated":"2023-11-27T07:38:06Z","published":"2023-10-31T16:24:17Z","title":"Unleashing the Power of Pre-trained Language Models for Offline\n  Reinforcement Learning","summary":"  Offline reinforcement learning (RL) aims to find a near-optimal policy using\npre-collected datasets. In real-world scenarios, data collection could be\ncostly and risky; therefore, offline RL becomes particularly challenging when\nthe in-domain data is limited. Given recent advances in Large Language Models\n(LLMs) and their few-shot learning prowess, this paper introduces\n$\\textbf{La}$nguage Models for $\\textbf{Mo}$tion Control ($\\textbf{LaMo}$), a\ngeneral framework based on Decision Transformers to effectively use pre-trained\nLanguage Models (LMs) for offline RL. Our framework highlights four crucial\ncomponents: (1) Initializing Decision Transformers with sequentially\npre-trained LMs, (2) employing the LoRA fine-tuning method, in contrast to\nfull-weight fine-tuning, to combine the pre-trained knowledge from LMs and\nin-domain knowledge effectively, (3) using the non-linear MLP transformation\ninstead of linear projections, to generate embeddings, and (4) integrating an\nauxiliary language prediction loss during fine-tuning to stabilize the LMs and\nretain their original abilities on languages. Empirical results indicate\n$\\textbf{LaMo}$ achieves state-of-the-art performance in sparse-reward tasks\nand closes the gap between value-based offline RL methods and decision\ntransformers in dense-reward tasks. In particular, our method demonstrates\nsuperior performance in scenarios with limited data samples.\n","authors":["Ruizhe Shi","Yuyao Liu","Yanjie Ze","Simon S. Du","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2310.20587v4.pdf","comment":"24 pages, 16 tables"},{"id":"http://arxiv.org/abs/2311.15587v1","updated":"2023-11-27T07:25:47Z","published":"2023-11-27T07:25:47Z","title":"Quantum Langevin Dynamics for Optimization","summary":"  We initiate the study of utilizing Quantum Langevin Dynamics (QLD) to solve\noptimization problems, particularly those non-convex objective functions that\npresent substantial obstacles for traditional gradient descent algorithms.\nSpecifically, we examine the dynamics of a system coupled with an infinite heat\nbath. This interaction induces both random quantum noise and a deterministic\ndamping effect to the system, which nudge the system towards a steady state\nthat hovers near the global minimum of objective functions. We theoretically\nprove the convergence of QLD in convex landscapes, demonstrating that the\naverage energy of the system can approach zero in the low temperature limit\nwith an exponential decay rate correlated with the evolution time. Numerically,\nwe first show the energy dissipation capability of QLD by retracing its origins\nto spontaneous emission. Furthermore, we conduct detailed discussion of the\nimpact of each parameter. Finally, based on the observations when comparing QLD\nwith classical Fokker-Plank-Smoluchowski equation, we propose a time-dependent\nQLD by making temperature and $\\hbar$ time-dependent parameters, which can be\ntheoretically proven to converge better than the time-independent case and also\noutperforms a series of state-of-the-art quantum and classical optimization\nalgorithms in many non-convex landscapes.\n","authors":["Zherui Chen","Yuchen Lu","Hao Wang","Yizhou Liu","Tongyang Li"],"pdf_url":"https://arxiv.org/pdf/2311.15587v1.pdf","comment":"33 pages, 1 table, 26 figures"},{"id":"http://arxiv.org/abs/2311.15584v1","updated":"2023-11-27T07:19:41Z","published":"2023-11-27T07:19:41Z","title":"A deep learning approach for marine snow synthesis and removal","summary":"  Marine snow, the floating particles in underwater images, severely degrades\nthe visibility and performance of human and machine vision systems. This paper\nproposes a novel method to reduce the marine snow interference using deep\nlearning techniques. We first synthesize realistic marine snow samples by\ntraining a Generative Adversarial Network (GAN) model and combine them with\nnatural underwater images to create a paired dataset. We then train a U-Net\nmodel to perform marine snow removal as an image to image translation task. Our\nexperiments show that the U-Net model can effectively remove both synthetic and\nnatural marine snow with high accuracy, outperforming state-of-the-art methods\nsuch as the Median filter and its adaptive variant. We also demonstrate the\nrobustness of our method by testing it on the MSRB dataset, which contains\nsynthetic artifacts that our model has not seen during training. Our method is\na practical and efficient solution for enhancing underwater images affected by\nmarine snow.\n","authors":["Fernando Galetto","Guang Deng"],"pdf_url":"https://arxiv.org/pdf/2311.15584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15583v1","updated":"2023-11-27T07:19:23Z","published":"2023-11-27T07:19:23Z","title":"A Simple Geometric-Aware Indoor Positioning Interpolation Algorithm\n  Based on Manifold Learning","summary":"  Interpolation methodologies have been widely used within the domain of indoor\npositioning systems. However, existing indoor positioning interpolation\nalgorithms exhibit several inherent limitations, including reliance on complex\nmathematical models, limited flexibility, and relatively low precision. To\nenhance the accuracy and efficiency of indoor positioning interpolation\ntechniques, this paper proposes a simple yet powerful geometric-aware\ninterpolation algorithm for indoor positioning tasks. The key to our algorithm\nis to exploit the geometric attributes of the local topological manifold using\nmanifold learning principles. Therefore, instead of constructing complicated\nmathematical models, the proposed algorithm facilitates the more precise and\nefficient estimation of points grounded in the local topological manifold.\nMoreover, our proposed method can be effortlessly integrated into any indoor\npositioning system, thereby bolstering its adaptability. Through a systematic\narray of experiments and comprehensive performance analyses conducted on both\nsimulated and real-world datasets, we demonstrate that the proposed algorithm\nconsistently outperforms the most commonly used and representative\ninterpolation approaches regarding interpolation accuracy and efficiency.\nFurthermore, the experimental results also underscore the substantial practical\nutility of our method and its potential applicability in real-time indoor\npositioning scenarios.\n","authors":["Suorong Yang","Geng Zhang","Jian Zhao","Furao Shen"],"pdf_url":"https://arxiv.org/pdf/2311.15583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15582v1","updated":"2023-11-27T07:19:22Z","published":"2023-11-27T07:19:22Z","title":"Lightly Weighted Automatic Audio Parameter Extraction for the Quality\n  Assessment of Consensus Auditory-Perceptual Evaluation of Voice","summary":"  The Consensus Auditory-Perceptual Evaluation of Voice is a widely employed\ntool in clinical voice quality assessment that is significant for streaming\ncommunication among clinical professionals and benchmarking for the\ndetermination of further treatment. Currently, because the assessment relies on\nexperienced clinicians, it tends to be inconsistent, and thus, difficult to\nstandardize. To address this problem, we propose to leverage lightly weighted\nautomatic audio parameter extraction, to increase the clinical relevance,\nreduce the complexity, and enhance the interpretability of voice quality\nassessment. The proposed method utilizes age, sex, and five audio parameters:\njitter, absolute jitter, shimmer, harmonic-to-noise ratio (HNR), and zero\ncrossing. A classical machine learning approach is employed. The result reveals\nthat our approach performs similar to state-of-the-art (SOTA) methods, and\noutperforms the latent representation obtained by using popular audio\npre-trained models. This approach provide insights into the feasibility of\ndifferent feature extraction approaches for voice evaluation. Audio parameters\nsuch as jitter and the HNR are proven to be suitable for characterizing voice\nquality attributes, such as roughness and strain. Conversely, pre-trained\nmodels exhibit limitations in effectively addressing noise-related scorings.\nThis study contributes toward more comprehensive and precise voice quality\nevaluations, achieved by a comprehensively exploring diverse assessment\nmethodologies.\n","authors":["Yi-Heng Lin","Wen-Hsuan Tseng","Li-Chin Chen","Ching-Ting Tan","Yu Tsao"],"pdf_url":"https://arxiv.org/pdf/2311.15582v1.pdf","comment":"Published in IEEE 42th International Conference on Consumer\n  Electronics (ICCE 2024)"},{"id":"http://arxiv.org/abs/2311.15578v1","updated":"2023-11-27T07:11:47Z","published":"2023-11-27T07:11:47Z","title":"Experimental Analysis of Large-scale Learnable Vector Storage\n  Compression","summary":"  Learnable embedding vector is one of the most important applications in\nmachine learning, and is widely used in various database-related domains.\nHowever, the high dimensionality of sparse data in recommendation tasks and the\nhuge volume of corpus in retrieval-related tasks lead to a large memory\nconsumption of the embedding table, which poses a great challenge to the\ntraining and deployment of models. Recent research has proposed various methods\nto compress the embeddings at the cost of a slight decrease in model quality or\nthe introduction of other overheads. Nevertheless, the relative performance of\nthese methods remains unclear. Existing experimental comparisons only cover a\nsubset of these methods and focus on limited metrics. In this paper, we perform\na comprehensive comparative analysis and experimental evaluation of embedding\ncompression. We introduce a new taxonomy that categorizes these techniques\nbased on their characteristics and methodologies, and further develop a modular\nbenchmarking framework that integrates 14 representative methods. Under a\nuniform test environment, our benchmark fairly evaluates each approach,\npresents their strengths and weaknesses under different memory budgets, and\nrecommends the best method based on the use case. In addition to providing\nuseful guidelines, our study also uncovers the limitations of current methods\nand suggests potential directions for future research.\n","authors":["Hailin Zhang","Penghao Zhao","Xupeng Miao","Yingxia Shao","Zirui Liu","Tong Yang","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2311.15578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11509v2","updated":"2023-11-27T06:53:03Z","published":"2023-11-20T03:17:21Z","title":"Token-Level Adversarial Prompt Detection Based on Perplexity Measures\n  and Contextual Information","summary":"  In recent years, Large Language Models (LLM) have emerged as pivotal tools in\nvarious applications. However, these models are susceptible to adversarial\nprompt attacks, where attackers can carefully curate input strings that lead to\nundesirable outputs. The inherent vulnerability of LLMs stems from their\ninput-output mechanisms, especially when presented with intensely\nout-of-distribution (OOD) inputs. This paper proposes a token-level detection\nmethod to identify adversarial prompts, leveraging the LLM's capability to\npredict the next token's probability. We measure the degree of the model's\nperplexity and incorporate neighboring token information to encourage the\ndetection of contiguous adversarial prompt sequences. As a result, we propose\ntwo methods: one that identifies each token as either being part of an\nadversarial prompt or not, and another that estimates the probability of each\ntoken being part of an adversarial prompt.\n","authors":["Zhengmian Hu","Gang Wu","Saayan Mitra","Ruiyi Zhang","Tong Sun","Heng Huang","Viswanathan Swaminathan"],"pdf_url":"https://arxiv.org/pdf/2311.11509v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15570v1","updated":"2023-11-27T06:38:07Z","published":"2023-11-27T06:38:07Z","title":"UFDA: Universal Federated Domain Adaptation with Practical Assumptions","summary":"  Conventional Federated Domain Adaptation (FDA) approaches usually demand an\nabundance of assumptions, such as label set consistency, which makes them\nsignificantly less feasible for real-world situations and introduces security\nhazards. In this work, we propose a more practical scenario named Universal\nFederated Domain Adaptation (UFDA). It only requires the black-box model and\nthe label set information of each source domain, while the label sets of\ndifferent source domains could be inconsistent and the target-domain label set\nis totally blind. This relaxes the assumptions made by FDA, which are often\nchallenging to meet in real-world cases and diminish model security. To address\nthe UFDA scenario, we propose a corresponding framework called Hot-Learning\nwith Contrastive Label Disambiguation (HCLD), which tackles UFDA's domain\nshifts and category gaps problem by using one-hot outputs from the black-box\nmodels of various source domains. Moreover, to better distinguish the shared\nand unknown classes, we further present a cluster-level strategy named\nMutual-Voting Decision (MVD) to extract robust consensus knowledge across peer\nclasses from both source and target domains. The extensive experiments on three\nbenchmarks demonstrate that our HCLD achieves comparable performance for our\nUFDA scenario with much fewer assumptions, compared to the previous\nmethodologies with many additional assumptions.\n","authors":["Xinhui Liu","Zhenghao Chen","Luping Zhou","Dong Xu","Wei Xi","Gairui Bai","Yihan Zhao","Jizhong Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.15570v1.pdf","comment":"Submitted to AAAI2024"},{"id":"http://arxiv.org/abs/2311.15566v1","updated":"2023-11-27T06:31:17Z","published":"2023-11-27T06:31:17Z","title":"SpotServe: Serving Generative Large Language Models on Preemptible\n  Instances","summary":"  The high computational and memory requirements of generative large language\nmodels (LLMs) make it challenging to serve them cheaply. This paper aims to\nreduce the monetary cost for serving LLMs by leveraging preemptible GPU\ninstances on modern clouds, which offer accesses to spare GPUs at a much\ncheaper price than regular instances but may be preempted by the cloud at any\ntime. Serving LLMs on preemptible instances requires addressing challenges\ninduced by frequent instance preemptions and the necessity of migrating\ninstances to handle these preemptions.\n  This paper presents SpotServe, the first distributed LLM serving system on\npreemptible instances. Several key techniques in SpotServe realize fast and\nreliable serving of generative LLMs on cheap preemptible instances. First,\nSpotServe dynamically adapts the LLM parallelization configuration for dynamic\ninstance availability and fluctuating workload, while balancing the trade-off\namong the overall throughput, inference latency and monetary costs. Second, to\nminimize the cost of migrating instances for dynamic reparallelization, the\ntask of migrating instances is formulated as a bipartite graph matching\nproblem, which uses the Kuhn-Munkres algorithm to identify an optimal migration\nplan that minimizes communications. Finally, to take advantage of the grace\nperiod offered by modern clouds, we introduce stateful inference recovery, a\nnew inference mechanism that commits inference progress at a much finer\ngranularity and allows SpotServe to cheaply resume inference upon preemption.\nWe evaluate on real spot instance preemption traces and various popular LLMs\nand show that SpotServe can reduce the P99 tail latency by 2.4 - 9.1x compared\nwith the best existing LLM serving systems. We also show that SpotServe can\nleverage the price advantage of preemptive instances, saving 54% monetary cost\ncompared with only using on-demand instances.\n","authors":["Xupeng Miao","Chunan Shi","Jiangfei Duan","Xiaoli Xi","Dahua Lin","Bin Cui","Zhihao Jia"],"pdf_url":"https://arxiv.org/pdf/2311.15566v1.pdf","comment":"ASPLOS 2024"},{"id":"http://arxiv.org/abs/2311.15565v1","updated":"2023-11-27T06:26:53Z","published":"2023-11-27T06:26:53Z","title":"Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing\n  AI-Generated Text","summary":"  My research investigates the use of cutting-edge hybrid deep learning models\nto accurately differentiate between AI-generated text and human writing. I\napplied a robust methodology, utilising a carefully selected dataset comprising\nAI and human texts from various sources, each tagged with instructions.\nAdvanced natural language processing techniques facilitated the analysis of\ntextual features. Combining sophisticated neural networks, the custom model\nenabled it to detect nuanced differences between AI and human content.\n","authors":["Finbarrs Oketunji"],"pdf_url":"https://arxiv.org/pdf/2311.15565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.00341v2","updated":"2023-11-27T05:51:13Z","published":"2023-11-01T07:21:08Z","title":"The Open DAC 2023 Dataset and Challenges for Sorbent Discovery in Direct\n  Air Capture","summary":"  New methods for carbon dioxide removal are urgently needed to combat global\nclimate change. Direct air capture (DAC) is an emerging technology to capture\ncarbon dioxide directly from ambient air. Metal-organic frameworks (MOFs) have\nbeen widely studied as potentially customizable adsorbents for DAC. However,\ndiscovering promising MOF sorbents for DAC is challenging because of the vast\nchemical space to explore and the need to understand materials as functions of\nhumidity and temperature. We explore a computational approach benefiting from\nrecent innovations in machine learning (ML) and present a dataset named Open\nDAC 2023 (ODAC23) consisting of more than 38M density functional theory (DFT)\ncalculations on more than 8,400 MOF materials containing adsorbed $CO_2$ and/or\n$H_2O$. ODAC23 is by far the largest dataset of MOF adsorption calculations at\nthe DFT level of accuracy currently available. In addition to probing\nproperties of adsorbed molecules, the dataset is a rich source of information\non structural relaxation of MOFs, which will be useful in many contexts beyond\nspecific applications for DAC. A large number of MOFs with promising properties\nfor DAC are identified directly in ODAC23. We also trained state-of-the-art ML\nmodels on this dataset to approximate calculations at the DFT level. This\nopen-source dataset and our initial ML models will provide an important\nbaseline for future efforts to identify MOFs for a wide range of applications,\nincluding DAC.\n","authors":["Anuroop Sriram","Sihoon Choi","Xiaohan Yu","Logan M. Brabson","Abhishek Das","Zachary Ulissi","Matt Uyttendaele","Andrew J. Medford","David S. Sholl"],"pdf_url":"https://arxiv.org/pdf/2311.00341v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15551v1","updated":"2023-11-27T05:35:49Z","published":"2023-11-27T05:35:49Z","title":"Instruct2Attack: Language-Guided Semantic Adversarial Attacks","summary":"  We propose Instruct2Attack (I2A), a language-guided semantic attack that\ngenerates semantically meaningful perturbations according to free-form language\ninstructions. We make use of state-of-the-art latent diffusion models, where we\nadversarially guide the reverse diffusion process to search for an adversarial\nlatent code conditioned on the input image and text instruction. Compared to\nexisting noise-based and semantic attacks, I2A generates more natural and\ndiverse adversarial examples while providing better controllability and\ninterpretability. We further automate the attack process with GPT-4 to generate\ndiverse image-specific text instructions. We show that I2A can successfully\nbreak state-of-the-art deep neural networks even under strong adversarial\ndefenses, and demonstrate great transferability among a variety of network\narchitectures.\n","authors":["Jiang Liu","Chen Wei","Yuxiang Guo","Heng Yu","Alan Yuille","Soheil Feizi","Chun Pong Lau","Rama Chellappa"],"pdf_url":"https://arxiv.org/pdf/2311.15551v1.pdf","comment":"under submission, code coming soon"},{"id":"http://arxiv.org/abs/2311.15549v1","updated":"2023-11-27T05:29:43Z","published":"2023-11-27T05:29:43Z","title":"From Prediction to Action: The Critical Role of Proper Performance\n  Estimation for Machine-Learning-Driven Materials Discovery","summary":"  Materials discovery driven by statistical property models is an iterative\ndecision process, during which an initial data collection is extended with new\ndata proposed by a model-informed acquisition function--with the goal to\nmaximize a certain \"reward\" over time, such as the maximum property value\ndiscovered so far. While the materials science community achieved much progress\nin developing property models that predict well on average with respect to the\ntraining distribution, this form of in-distribution performance measurement is\nnot directly coupled with the discovery reward. This is because an iterative\ndiscovery process has a shifting reward distribution that is\nover-proportionally determined by the model performance for exceptional\nmaterials. We demonstrate this problem using the example of bulk modulus\nmaximization among double perovskite oxides. We find that the in-distribution\npredictive performance suggests random forests as superior to Gaussian process\nregression, while the results are inverse in terms of the discovery rewards. We\nargue that the lack of proper performance estimation methods from pre-computed\ndata collections is a fundamental problem for improving data-driven materials\ndiscovery, and we propose a novel such estimator that, in contrast to na\\\"ive\nreward estimation, successfully predicts Gaussian processes with the \"expected\nimprovement\" acquisition function as the best out of four options in our\ndemonstrational study for double perovskites. Importantly, it does so without\nrequiring the over thousand ab initio computations that were needed to confirm\nthis prediction.\n","authors":["Mario Boley","Felix Luong","Simon Teshuva","Daniel F Schmidt","Lucas Foppa","Matthias Scheffler"],"pdf_url":"https://arxiv.org/pdf/2311.15549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15548v1","updated":"2023-11-27T05:27:13Z","published":"2023-11-27T05:27:13Z","title":"Deficiency of Large Language Models in Finance: An Empirical Examination\n  of Hallucination","summary":"  The hallucination issue is recognized as a fundamental deficiency of large\nlanguage models (LLMs), especially when applied to fields such as finance,\neducation, and law. Despite the growing concerns, there has been a lack of\nempirical investigation. In this paper, we provide an empirical examination of\nLLMs' hallucination behaviors in financial tasks. First, we empirically\ninvestigate LLM model's ability of explaining financial concepts and\nterminologies. Second, we assess LLM models' capacity of querying historical\nstock prices. Third, to alleviate the hallucination issue, we evaluate the\nefficacy of four practical methods, including few-shot learning, Decoding by\nContrasting Layers (DoLa), the Retrieval Augmentation Generation (RAG) method\nand the prompt-based tool learning method for a function to generate a query\ncommand. Finally, our major finding is that off-the-shelf LLMs experience\nserious hallucination behaviors in financial tasks. Therefore, there is an\nurgent need to call for research efforts in mitigating LLMs' hallucination.\n","authors":["Haoqiang Kang","Xiao-Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2311.15548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15547v1","updated":"2023-11-27T05:23:01Z","published":"2023-11-27T05:23:01Z","title":"Dataset Distillation in Latent Space","summary":"  Dataset distillation (DD) is a newly emerging research area aiming at\nalleviating the heavy computational load in training models on large datasets.\nIt tries to distill a large dataset into a small and condensed one so that\nmodels trained on the distilled dataset can perform comparably with those\ntrained on the full dataset when performing downstream tasks. Among the\nprevious works in this area, there are three key problems that hinder the\nperformance and availability of the existing DD methods: high time complexity,\nhigh space complexity, and low info-compactness. In this work, we\nsimultaneously attempt to settle these three problems by moving the DD\nprocesses from conventionally used pixel space to latent space. Encoded by a\npretrained generic autoencoder, latent codes in the latent space are naturally\ninfo-compact representations of the original images in much smaller sizes.\nAfter transferring three mainstream DD algorithms to latent space, we\nsignificantly reduce time and space consumption while achieving similar\nperformance, allowing us to distill high-resolution datasets or target at\ngreater data ratio that previous methods have failed. Besides, within the same\nstorage budget, we can also quantitatively deliver more latent codes than\npixel-level images, which further boosts the performance of our methods.\n","authors":["Yuxuan Duan","Jianfu Zhang","Liqing Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.15547v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2311.15545v1","updated":"2023-11-27T05:21:08Z","published":"2023-11-27T05:21:08Z","title":"Out-of-Distribution Generalized Dynamic Graph Neural Network for Human\n  Albumin Prediction","summary":"  Human albumin is essential for indicating the body's overall health.\nAccurately predicting plasma albumin levels and determining appropriate doses\nare urgent clinical challenges, particularly in critically ill patients, to\nmaintain optimal blood levels. However, human albumin prediction is non-trivial\nthat has to leverage the dynamics of biochemical markers as well as the\nexperience of treating patients. Moreover, the problem of distribution shift is\noften encountered in real clinical data, which may lead to a decline in the\nmodel prediction performance and reduce the reliability of the model's\napplication. In this paper, we propose a framework named Out-of-Distribution\nGeneralized Dynamic Graph Neural Network for Human Albumin Prediction\n(DyG-HAP), which is able to provide accurate albumin predictions for Intensity\nCare Unit (ICU) patients during hospitalization. We first model human albumin\nprediction as a dynamic graph regression problem to model the dynamics and\npatient relationship. Then, we propose a disentangled dynamic graph attention\nmechanism to capture and disentangle the patterns whose relationship to labels\nunder distribution shifts is invariant and variant respectively. Last, we\npropose an invariant dynamic graph regression method to encourage the model to\nrely on invariant patterns to make predictions. Moreover, we propose a dataset\nnamed Albumin level testing and nutritional dosing data for Intensive Care\n(ANIC) for evaluation. Extensive experiments demonstrate the superiority of our\nmethod compared to several baseline methods in human albumin prediction.\n","authors":["Zeyang Zhang","Xingwang Li","Fei Teng","Ning Lin","Xueling Zhu","Xin Wang","Wenwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.15545v1.pdf","comment":"MedAI'23"},{"id":"http://arxiv.org/abs/2309.01947v2","updated":"2023-11-27T05:03:31Z","published":"2023-09-05T04:47:55Z","title":"TODM: Train Once Deploy Many Efficient Supernet-Based RNN-T Compression\n  For On-device ASR Models","summary":"  Automatic Speech Recognition (ASR) models need to be optimized for specific\nhardware before they can be deployed on devices. This can be done by tuning the\nmodel's hyperparameters or exploring variations in its architecture.\nRe-training and re-validating models after making these changes can be a\nresource-intensive task. This paper presents TODM (Train Once Deploy Many), a\nnew approach to efficiently train many sizes of hardware-friendly on-device ASR\nmodels with comparable GPU-hours to that of a single training job. TODM\nleverages insights from prior work on Supernet, where Recurrent Neural Network\nTransducer (RNN-T) models share weights within a Supernet. It reduces layer\nsizes and widths of the Supernet to obtain subnetworks, making them smaller\nmodels suitable for all hardware types. We introduce a novel combination of\nthree techniques to improve the outcomes of the TODM Supernet: adaptive\ndropouts, an in-place Alpha-divergence knowledge distillation, and the use of\nScaledAdam optimizer. We validate our approach by comparing Supernet-trained\nversus individually tuned Multi-Head State Space Model (MH-SSM) RNN-T using\nLibriSpeech. Results demonstrate that our TODM Supernet either matches or\nsurpasses the performance of manually tuned models by up to a relative of 3%\nbetter in word error rate (WER), while efficiently keeping the cost of training\nmany models at a small constant.\n","authors":["Yuan Shangguan","Haichuan Yang","Danni Li","Chunyang Wu","Yassir Fathullah","Dilin Wang","Ayushi Dalmia","Raghuraman Krishnamoorthi","Ozlem Kalinli","Junteng Jia","Jay Mahadeokar","Xin Lei","Mike Seltzer","Vikas Chandra"],"pdf_url":"https://arxiv.org/pdf/2309.01947v2.pdf","comment":"Meta AI; Submitted to ICASSP 2024"},{"id":"http://arxiv.org/abs/2308.16781v4","updated":"2023-11-27T05:03:14Z","published":"2023-08-31T14:59:32Z","title":"StratMed: Relevance Stratification between Biomedical Entities for\n  Sparsity on Medication Recommendation","summary":"  With the growing imbalance between limited medical resources and escalating\ndemands, AI-based clinical tasks have become paramount. As a sub-domain,\nmedication recommendation aims to amalgamate longitudinal patient history with\nmedical knowledge, assisting physicians in prescribing safer and more accurate\nmedication combinations. Existing works ignore the inherent long-tailed\ndistribution of medical data, have uneven learning strengths for hot and sparse\ndata, and fail to balance safety and accuracy. To address the above\nlimitations, we propose StratMed, which introduces a stratification strategy\nthat overcomes the long-tailed problem and achieves fuller learning of sparse\ndata. It also utilizes a dual-property network to address the issue of mutual\nconstraints on the safety and accuracy of medication combinations,\nsynergistically enhancing these two properties. Specifically, we construct a\npre-training method using deep learning networks to obtain medication and\ndisease representations. After that, we design a pyramid-like stratification\nmethod based on relevance to strengthen the expressiveness of sparse data.\nBased on this relevance, we design two graph structures to express medication\nsafety and precision at the same level to obtain patient representations.\nFinally, the patient's historical clinical information is fitted to generate\nmedication combinations for the current health condition. We employed the\nMIMIC-III dataset to evaluate our model against state-of-the-art methods in\nthree aspects comprehensively. Compared to the sub-optimal baseline model, our\nmodel reduces safety risk by 15.08\\%, improves accuracy by 0.36\\%, and reduces\ntraining time consumption by 81.66\\%.\n","authors":["Xiang Li","Shunpan Liang","Yulei Hou","Tengfei Ma"],"pdf_url":"https://arxiv.org/pdf/2308.16781v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15536v1","updated":"2023-11-27T04:49:24Z","published":"2023-11-27T04:49:24Z","title":"SVRDA: A Web-based Dataset Annotation Tool for Slice-to-Volume\n  Registration","summary":"  Background and Objective: The lack of benchmark datasets has impeded the\ndevelopment of slice-to-volume registration algorithms. Such datasets are\ndifficult to annotate, primarily due to the dimensional difference within data\nand the dearth of task-specific software. We aim to develop a user-friendly\ntool to streamline dataset annotation for slice-to-volume registration.\n  Methods: The proposed tool, named SVRDA, is an installation-free web\napplication for platform-agnostic collaborative dataset annotation. It enables\nefficient transformation manipulation via keyboard shortcuts and smooth case\ntransitions with auto-saving. SVRDA supports configuration-based data loading\nand adheres to the separation of concerns, offering great flexibility and\nextensibility for future research. Various supplementary features have been\nimplemented to facilitate slice-to-volume registration.\n  Results: We validated the effectiveness of SVRDA by indirectly evaluating the\npost-registration segmentation quality on UK Biobank data, observing a dramatic\noverall improvement (24.02% in the Dice Similarity Coefficient and 48.93% in\nthe 95th percentile Hausdorff distance, respectively) supported by highly\nstatistically significant evidence ($p<0.001$).We further showcased the\nclinical usage of SVRDA by integrating it into test-retest T1 quantification on\nin-house magnetic resonance images, leading to more consistent results after\nregistration.\n  Conclusions: SVRDA can facilitate collaborative annotation of benchmark\ndatasets while being potentially applicable to other pipelines incorporating\nslice-to-volume registration. Full source code and documentation are available\nat https://github.com/Roldbach/SVRDA\n","authors":["Weixun Luo","Alexandre Triay Bagur","Paul Aljabar","George Ralli","Sir Michael Brady"],"pdf_url":"https://arxiv.org/pdf/2311.15536v1.pdf","comment":"18 pages, 11 figures, In submission to Computer Methods and Programs\n  in Biomedicine"},{"id":"http://arxiv.org/abs/2205.13748v2","updated":"2023-11-27T04:41:51Z","published":"2022-05-27T03:24:31Z","title":"Auto-PINN: Understanding and Optimizing Physics-Informed Neural\n  Architecture","summary":"  Physics-informed neural networks (PINNs) are revolutionizing science and\nengineering practice by bringing together the power of deep learning to bear on\nscientific computation. In forward modeling problems, PINNs are meshless\npartial differential equation (PDE) solvers that can handle irregular,\nhigh-dimensional physical domains. Naturally, the neural architecture\nhyperparameters have a large impact on the efficiency and accuracy of the PINN\nsolver. However, this remains an open and challenging problem because of the\nlarge search space and the difficulty of identifying a proper search objective\nfor PDEs. Here, we propose Auto-PINN, the first systematic, automated\nhyperparameter optimization approach for PINNs, which employs Neural\nArchitecture Search (NAS) techniques to PINN design. Auto-PINN avoids manually\nor exhaustively searching the hyperparameter space associated with PINNs. A\ncomprehensive set of pre-experiments using standard PDE benchmarks allows us to\nprobe the structure-performance relationship in PINNs. We find that the\ndifferent hyperparameters can be decoupled, and that the training loss function\nof PINNs is a good search objective. Comparison experiments with baseline\nmethods demonstrate that Auto-PINN produces neural architectures with superior\nstability and accuracy over alternative baselines.\n","authors":["Yicheng Wang","Xiaotian Han","Chia-Yuan Chang","Daochen Zha","Ulisses Braga-Neto","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2205.13748v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15530v1","updated":"2023-11-27T04:23:47Z","published":"2023-11-27T04:23:47Z","title":"SSIN: Self-Supervised Learning for Rainfall Spatial Interpolation","summary":"  The acquisition of accurate rainfall distribution in space is an important\ntask in hydrological analysis and natural disaster pre-warning. However, it is\nimpossible to install rain gauges on every corner. Spatial interpolation is a\ncommon way to infer rainfall distribution based on available raingauge data.\nHowever, the existing works rely on some unrealistic pre-settings to capture\nspatial correlations, which limits their performance in real scenarios. To\ntackle this issue, we propose the SSIN, which is a novel data-driven\nself-supervised learning framework for rainfall spatial interpolation by mining\nlatent spatial patterns from historical observation data. Inspired by the Cloze\ntask and BERT, we fully consider the characteristics of spatial interpolation\nand design the SpaFormer model based on the Transformer architecture as the\ncore of SSIN. Our main idea is: by constructing rich self-supervision signals\nvia random masking, SpaFormer can learn informative embeddings for raw data and\nthen adaptively model spatial correlations based on rainfall spatial context.\nExtensive experiments on two real-world raingauge datasets show that our method\noutperforms the state-of-the-art solutions. In addition, we take traffic\nspatial interpolation as another use case to further explore the performance of\nour method, and SpaFormer achieves the best performance on one large real-world\ntraffic dataset, which further confirms the effectiveness and generality of our\nmethod.\n","authors":["Jia Li","Yanyan Shen","Lei Chen","Charles Wang Wai NG"],"pdf_url":"https://arxiv.org/pdf/2311.15530v1.pdf","comment":"SIGMOD 2023 Data-intensive Applications (DIA) Track; Code is\n  available at https://github.com/jlidw/SSIN"},{"id":"http://arxiv.org/abs/2308.12532v2","updated":"2023-11-27T03:33:37Z","published":"2023-08-24T03:43:02Z","title":"FedSoL: Bridging Global Alignment and Local Generality in Federated\n  Learning","summary":"  Federated Learning (FL) aggregates locally trained models from individual\nclients to construct a global model. While FL enables learning a model with\ndata privacy, it often suffers from significant performance degradation when\nclient data distributions are heterogeneous. Many previous FL algorithms have\naddressed this issue by introducing various proximal restrictions. These\nrestrictions aim to encourage global alignment by constraining the deviation of\nlocal learning from the global objective. However, they inherently limit local\nlearning by interfering with the original local objectives. Recently, an\nalternative approach has emerged to improve local learning generality. By\nobtaining local models within a smooth loss landscape, this approach mitigates\nconflicts among different local objectives of the clients. Yet, it does not\nensure stable global alignment, as local learning does not take the global\nobjective into account. In this study, we propose Federated Stability on\nLearning (FedSoL), which combines both the concepts of global alignment and\nlocal generality. In FedSoL, the local learning seeks a parameter region robust\nagainst proximal perturbations. This strategy introduces an implicit proximal\nrestriction effect in local learning while maintaining the original local\nobjective for parameter update. Our experiments show that FedSoL consistently\nachieves state-of-the-art performance on various setups.\n","authors":["Gihun Lee","Minchan Jeong","Sangmook Kim","Jaehoon Oh","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2308.12532v2.pdf","comment":"19 pages, 12 figures"},{"id":"http://arxiv.org/abs/2311.15516v1","updated":"2023-11-27T03:25:12Z","published":"2023-11-27T03:25:12Z","title":"Active Foundational Models for Fault Diagnosis of Electrical Motors","summary":"  Fault detection and diagnosis of electrical motors are of utmost importance\nin ensuring the safe and reliable operation of several industrial systems.\nDetection and diagnosis of faults at the incipient stage allows corrective\nactions to be taken in order to reduce the severity of faults. The existing\ndata-driven deep learning approaches for machine fault diagnosis rely\nextensively on huge amounts of labeled samples, where annotations are expensive\nand time-consuming. However, a major portion of unlabeled condition monitoring\ndata is not exploited in the training process. To overcome this limitation, we\npropose a foundational model-based Active Learning framework that utilizes less\namount of labeled samples, which are most informative and harnesses a large\namount of available unlabeled data by effectively combining Active Learning and\nContrastive Self-Supervised Learning techniques. It consists of a transformer\nnetwork-based backbone model trained using an advanced nearest-neighbor\ncontrastive self-supervised learning method. This approach empowers the\nbackbone to learn improved representations of samples derived from raw,\nunlabeled vibration data. Subsequently, the backbone can undergo fine-tuning to\naddress a range of downstream tasks, both within the same machines and across\ndifferent machines. The effectiveness of the proposed methodology has been\nassessed through the fine-tuning of the backbone for multiple target tasks\nusing three distinct machine-bearing fault datasets. The experimental\nevaluation demonstrates a superior performance as compared to existing\nstate-of-the-art fault diagnosis methods with less amount of labeled data.\n","authors":["Sriram Anbalagan","Sai Shashank GP","Deepesh Agarwal","Balasubramaniam Natarajan","Babji Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2311.15516v1.pdf","comment":"30 pages, 2 figures, 7 tables"},{"id":"http://arxiv.org/abs/2311.15513v1","updated":"2023-11-27T03:17:09Z","published":"2023-11-27T03:17:09Z","title":"A Comparative and Experimental Study on Automatic Question Answering\n  Systems and its Robustness against Word Jumbling","summary":"  Question answer generation using Natural Language Processing models is\nubiquitous in the world around us. It is used in many use cases such as the\nbuilding of chat bots, suggestive prompts in google search and also as a way of\nnavigating information in banking mobile applications etc. It is highly\nrelevant because a frequently asked questions (FAQ) list can only have a finite\namount of questions but a model which can perform question answer generation\ncould be able to answer completely new questions that are within the scope of\nthe data. This helps us to be able to answer new questions accurately as long\nas it is a relevant question. In commercial applications, it can be used to\nincrease customer satisfaction and ease of usage. However a lot of data is\ngenerated by humans so it is susceptible to human error and this can adversely\naffect the model's performance and we are investigating this through our work\n","authors":["Shashidhar Reddy Javaji","Haoran Hu","Sai Sameer Vennam","Vijaya Gajanan Buddhavarapu"],"pdf_url":"https://arxiv.org/pdf/2311.15513v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.02858v3","updated":"2023-11-27T03:15:34Z","published":"2023-04-06T04:37:10Z","title":"A review of ensemble learning and data augmentation models for class\n  imbalanced problems: combination, implementation and evaluation","summary":"  Class imbalance (CI) in classification problems arises when the number of\nobservations belonging to one class is lower than the other. Ensemble learning\ncombines multiple models to obtain a robust model and has been prominently used\nwith data augmentation methods to address class imbalance problems. In the last\ndecade, a number of strategies have been added to enhance ensemble learning and\ndata augmentation methods, along with new methods such as generative\nadversarial networks (GANs). A combination of these has been applied in many\nstudies, and the evaluation of different combinations would enable a better\nunderstanding and guidance for different application domains. In this paper, we\npresent a computational study to evaluate data augmentation and ensemble\nlearning methods used to address prominent benchmark CI problems. We present a\ngeneral framework that evaluates 9 data augmentation and 9 ensemble learning\nmethods for CI problems. Our objective is to identify the most effective\ncombination for improving classification performance on imbalanced datasets.\nThe results indicate that combinations of data augmentation methods with\nensemble learning can significantly improve classification performance on\nimbalanced datasets. We find that traditional data augmentation methods such as\nthe synthetic minority oversampling technique (SMOTE) and random oversampling\n(ROS) are not only better in performance for selected CI problems, but also\ncomputationally less expensive than GANs. Our study is vital for the\ndevelopment of novel models for handling imbalanced datasets.\n","authors":["Azal Ahmad Khan","Omkar Chaudhari","Rohitash Chandra"],"pdf_url":"https://arxiv.org/pdf/2304.02858v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.04686v3","updated":"2023-11-27T03:07:32Z","published":"2022-11-09T05:18:08Z","title":"Directional Privacy for Deep Learning","summary":"  Differentially Private Stochastic Gradient Descent (DP-SGD) is a key method\nfor applying privacy in the training of deep learning models. It applies\nisotropic Gaussian noise to gradients during training, which can perturb these\ngradients in any direction, damaging utility. Metric DP, however, can provide\nalternative mechanisms based on arbitrary metrics that might be more suitable\nfor preserving utility. In this paper, we apply \\textit{directional privacy},\nvia a mechanism based on the von Mises-Fisher (VMF) distribution, to perturb\ngradients in terms of \\textit{angular distance} so that gradient direction is\nbroadly preserved. We show that this provides both $\\epsilon$-DP and $\\epsilon\nd$-privacy for deep learning training, rather than the $(\\epsilon,\n\\delta)$-privacy of the Gaussian mechanism. Experiments on key datasets then\nindicate that the VMF mechanism can outperform the Gaussian in the\nutility-privacy trade-off. In particular, our experiments provide a direct\nempirical comparison of privacy between the two approaches in terms of their\nability to defend against reconstruction and membership inference.\n","authors":["Pedro Faustini","Natasha Fernandes","Shakila Tonni","Annabelle McIver","Mark Dras"],"pdf_url":"https://arxiv.org/pdf/2211.04686v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15502v1","updated":"2023-11-27T02:59:17Z","published":"2023-11-27T02:59:17Z","title":"Learning with Complementary Labels Revisited: A Consistent Approach via\n  Negative-Unlabeled Learning","summary":"  Complementary-label learning is a weakly supervised learning problem in which\neach training example is associated with one or multiple complementary labels\nindicating the classes to which it does not belong. Existing consistent\napproaches have relied on the uniform distribution assumption to model the\ngeneration of complementary labels, or on an ordinary-label training set to\nestimate the transition matrix. However, both conditions may not be satisfied\nin real-world scenarios. In this paper, we propose a novel complementary-label\nlearning approach that does not rely on these conditions. We find that\ncomplementary-label learning can be expressed as a set of negative-unlabeled\nbinary classification problems when using the one-versus-rest strategy. This\nobservation allows us to propose a risk-consistent approach with theoretical\nguarantees. Furthermore, we introduce a risk correction approach to address\noverfitting problems when using complex models. We also prove the statistical\nconsistency and convergence rate of the corrected risk estimator. Extensive\nexperimental results on both synthetic and real-world benchmark datasets\nvalidate the superiority of our proposed approach over state-of-the-art\nmethods.\n","authors":["Wei Wang","Takashi Ishida","Yu-Jie Zhang","Gang Niu","Masashi Sugiyama"],"pdf_url":"https://arxiv.org/pdf/2311.15502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15500v1","updated":"2023-11-27T02:55:34Z","published":"2023-11-27T02:55:34Z","title":"Function-constrained Program Synthesis","summary":"  This work introduces (1) a technique that allows large language models (LLMs)\nto leverage user-provided code when solving programming tasks and (2) a method\nto iteratively generate modular sub-functions that can aid future code\ngeneration attempts when the initial code generated by the LLM is inadequate.\nGenerating computer programs in general-purpose programming languages like\nPython poses a challenge for LLMs when instructed to use code provided in the\nprompt. Code-specific LLMs (e.g., GitHub Copilot, CodeLlama2) can generate code\ncompletions in real-time by drawing on all code available in a development\nenvironment. However, restricting code-specific LLMs to use only in-context\ncode is not straightforward, as the model is not explicitly instructed to use\nthe user-provided code and users cannot highlight precisely which snippets of\ncode the model should incorporate into its context. Moreover, current systems\nlack effective recovery methods, forcing users to iteratively re-prompt the\nmodel with modified prompts until a sufficient solution is reached. Our method\ndiffers from traditional LLM-powered code-generation by constraining\ncode-generation to an explicit function set and enabling recovery from failed\nattempts through automatically generated sub-functions. When the LLM cannot\nproduce working code, we generate modular sub-functions to aid subsequent\nattempts at generating functional code. A by-product of our method is a library\nof reusable sub-functions that can solve related tasks, imitating a software\nteam where efficiency scales with experience. We also introduce a new\n\"half-shot\" evaluation paradigm that provides tighter estimates of LLMs' coding\nabilities compared to traditional zero-shot evaluation. Our proposed evaluation\nmethod encourages models to output solutions in a structured format, decreasing\nsyntax errors that can be mistaken for poor coding ability.\n","authors":["Patrick Hajali","Ignas Budvytis"],"pdf_url":"https://arxiv.org/pdf/2311.15500v1.pdf","comment":"17 pages, 6 figures, 2023 NeurIPS R0-Fomo Workshop"},{"id":"http://arxiv.org/abs/2311.15497v1","updated":"2023-11-27T02:48:06Z","published":"2023-11-27T02:48:06Z","title":"Adaptive Image Registration: A Hybrid Approach Integrating Deep Learning\n  and Optimization Functions for Enhanced Precision","summary":"  Image registration has traditionally been done using two distinct approaches:\nlearning based methods, relying on robust deep neural networks, and\noptimization-based methods, applying complex mathematical transformations to\nwarp images accordingly. Of course, both paradigms offer advantages and\ndisadvantages, and, in this work, we seek to combine their respective strengths\ninto a single streamlined framework, using the outputs of the learning based\nmethod as initial parameters for optimization while prioritizing computational\npower for the image pairs that offer the greatest loss. Our investigations\nshowed that an improvement of 0.3\\% in testing when utilizing the best\nperforming state-of-the-art model as the backbone of the framework, while\nmaintaining the same inference time and with only a 0.8\\% loss in deformation\nfield smoothness.\n","authors":["Gabriel De Araujo","Shanlin Sun","Xiaohui Xie"],"pdf_url":"https://arxiv.org/pdf/2311.15497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15487v1","updated":"2023-11-27T02:12:02Z","published":"2023-11-27T02:12:02Z","title":"Global $\\mathcal{L}^2$ minimization with certainty via geometrically\n  adapted gradient descent in Deep Learning","summary":"  We consider the gradient descent flow widely used for the minimization of the\n$\\mathcal{L}^2$ cost function in Deep Learning networks, and introduce two\nmodified versions; one adapted for the overparametrized setting, and the other\nfor the underparametrized setting. Both have a clear and natural invariant\ngeometric meaning, taking into account the pullback vector bundle structure in\nthe overparametrized, and the pushforward vector bundle structure in the\nunderparametrized setting. In the overparametrized case, we prove that,\nprovided that a rank condition holds, all orbits of the modified gradient\ndescent drive the $\\mathcal{L}^2$ cost to its global minimum at a uniform\nexponential convergence rate. We point out relations of the latter to\nsub-Riemannian geometry.\n","authors":["Thomas Chen"],"pdf_url":"https://arxiv.org/pdf/2311.15487v1.pdf","comment":"AMS Latex, 12 pages"},{"id":"http://arxiv.org/abs/2305.19569v5","updated":"2023-11-27T02:05:54Z","published":"2023-05-31T05:37:17Z","title":"Domain knowledge-informed Synthetic fault sample generation with Health\n  Data Map for cross-domain Planetary Gearbox Fault Diagnosis","summary":"  Extensive research has been conducted on fault diagnosis of planetary\ngearboxes using vibration signals and deep learning (DL) approaches. However,\nDL-based methods are susceptible to the domain shift problem caused by varying\noperating conditions of the gearbox. Although domain adaptation and data\nsynthesis methods have been proposed to overcome such domain shifts, they are\noften not directly applicable in real-world situations where only healthy data\nis available in the target domain. To tackle the challenge of extreme domain\nshift scenarios where only healthy data is available in the target domain, this\npaper proposes two novel domain knowledge-informed data synthesis methods\nutilizing the health data map (HDMap). The two proposed approaches are referred\nto as scaled CutPaste and FaultPaste. The HDMap is used to physically represent\nthe vibration signal of the planetary gearbox as an image-like matrix, allowing\nfor visualization of fault-related features. CutPaste and FaultPaste are then\napplied to generate faulty samples based on the healthy data in the target\ndomain, using domain knowledge and fault signatures extracted from the source\ndomain, respectively. In addition to generating realistic faults, the proposed\nmethods introduce scaling of fault signatures for controlled synthesis of\nfaults with various severity levels. A case study is conducted on a planetary\ngearbox testbed to evaluate the proposed approaches. The results show that the\nproposed methods are capable of accurately diagnosing faults, even in cases of\nextreme domain shift, and can estimate the severity of faults that have not\nbeen previously observed in the target domain.\n","authors":["Jong Moon Ha","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2305.19569v5.pdf","comment":"Under review / added arXiv identifier / Updated to revised version"},{"id":"http://arxiv.org/abs/2311.15480v1","updated":"2023-11-27T01:44:02Z","published":"2023-11-27T01:44:02Z","title":"Automatic Time Signature Determination for New Scores Using Lyrics for\n  Latent Rhythmic Structure","summary":"  There has recently been a sharp increase in interest in Artificial\nIntelligence-Generated Content (AIGC). Despite this, musical components such as\ntime signatures have not been studied sufficiently to form an algorithmic\ndetermination approach for new compositions, especially lyrical songs. This is\nlikely because of the neglect of musical details, which is critical for\nconstructing a robust framework. Specifically, time signatures establish the\nfundamental rhythmic structure for almost all aspects of a song, including the\nphrases and notes. In this paper, we propose a novel approach that only uses\nlyrics as input to automatically generate a fitting time signature for lyrical\nsongs and uncover the latent rhythmic structure utilizing explainable machine\nlearning models. In particular, we devise multiple methods that are associated\nwith discovering lyrical patterns and creating new features that simultaneously\ncontain lyrical, rhythmic, and statistical information. In this approach, the\nbest of our experimental results reveal a 97.6% F1 score and a 0.996 Area Under\nthe Curve (AUC) of the Receiver Operating Characteristic (ROC) score. In\nconclusion, our research directly generates time signatures from lyrics\nautomatically for new scores utilizing machine learning, which is an innovative\nidea that approaches an understudied component of musicology and therefore\ncontributes significantly to the future of Artificial Intelligence (AI) music\ngeneration.\n","authors":["Callie C. Liao","Duoduo Liao","Jesse Guessford"],"pdf_url":"https://arxiv.org/pdf/2311.15480v1.pdf","comment":"Submitted to IEEE Big Data 2023 Conference"},{"id":"http://arxiv.org/abs/2305.16491v2","updated":"2023-11-27T01:28:16Z","published":"2023-05-25T21:45:33Z","title":"SAMoSSA: Multivariate Singular Spectrum Analysis with Stochastic\n  Autoregressive Noise","summary":"  The well-established practice of time series analysis involves estimating\ndeterministic, non-stationary trend and seasonality components followed by\nlearning the residual stochastic, stationary components. Recently, it has been\nshown that one can learn the deterministic non-stationary components accurately\nusing multivariate Singular Spectrum Analysis (mSSA) in the absence of a\ncorrelated stationary component; meanwhile, in the absence of deterministic\nnon-stationary components, the Autoregressive (AR) stationary component can\nalso be learnt readily, e.g. via Ordinary Least Squares (OLS). However, a\ntheoretical underpinning of multi-stage learning algorithms involving both\ndeterministic and stationary components has been absent in the literature\ndespite its pervasiveness. We resolve this open question by establishing\ndesirable theoretical guarantees for a natural two-stage algorithm, where mSSA\nis first applied to estimate the non-stationary components despite the presence\nof a correlated stationary AR component, which is subsequently learned from the\nresidual time series. We provide a finite-sample forecasting consistency bound\nfor the proposed algorithm, SAMoSSA, which is data-driven and thus requires\nminimal parameter tuning. To establish theoretical guarantees, we overcome\nthree hurdles: (i) we characterize the spectra of Page matrices of stable AR\nprocesses, thus extending the analysis of mSSA; (ii) we extend the analysis of\nAR process identification in the presence of arbitrary bounded perturbations;\n(iii) we characterize the out-of-sample or forecasting error, as opposed to\nsolely considering model identification. Through representative empirical\nstudies, we validate the superior performance of SAMoSSA compared to existing\nbaselines. Notably, SAMoSSA's ability to account for AR noise structure yields\nimprovements ranging from 5% to 37% across various benchmark datasets.\n","authors":["Abdullah Alomar","Munther Dahleh","Sean Mann","Devavrat Shah"],"pdf_url":"https://arxiv.org/pdf/2305.16491v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15475v1","updated":"2023-11-27T01:20:11Z","published":"2023-11-27T01:20:11Z","title":"MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers","summary":"  We introduce MeshGPT, a new approach for generating triangle meshes that\nreflects the compactness typical of artist-created meshes, in contrast to dense\ntriangle meshes extracted by iso-surfacing methods from neural fields. Inspired\nby recent advances in powerful large language models, we adopt a sequence-based\napproach to autoregressively generate triangle meshes as sequences of\ntriangles. We first learn a vocabulary of latent quantized embeddings, using\ngraph convolutions, which inform these embeddings of the local mesh geometry\nand topology. These embeddings are sequenced and decoded into triangles by a\ndecoder, ensuring that they can effectively reconstruct the mesh. A transformer\nis then trained on this learned vocabulary to predict the index of the next\nembedding given previous embeddings. Once trained, our model can be\nautoregressively sampled to generate new triangle meshes, directly generating\ncompact meshes with sharp edges, more closely imitating the efficient\ntriangulation patterns of human-crafted meshes. MeshGPT demonstrates a notable\nimprovement over state of the art mesh generation methods, with a 9% increase\nin shape coverage and a 30-point enhancement in FID scores across various\ncategories.\n","authors":["Yawar Siddiqui","Antonio Alliegro","Alexey Artemov","Tatiana Tommasi","Daniele Sirigatti","Vladislav Rosov","Angela Dai","Matthias Nießner"],"pdf_url":"https://arxiv.org/pdf/2311.15475v1.pdf","comment":"Project Page: https://nihalsid.github.io/mesh-gpt/, Video:\n  https://youtu.be/UV90O1_69_o"},{"id":"http://arxiv.org/abs/2311.11235v2","updated":"2023-11-27T01:15:06Z","published":"2023-11-19T05:37:18Z","title":"Unraveling the \"Anomaly\" in Time Series Anomaly Detection: A\n  Self-supervised Tri-domain Solution","summary":"  The ongoing challenges in time series anomaly detection (TSAD), notably the\nscarcity of anomaly labels and the variability in anomaly lengths and shapes,\nhave led to the need for a more efficient solution. As limited anomaly labels\nhinder traditional supervised models in TSAD, various SOTA deep learning\ntechniques, such as self-supervised learning, have been introduced to tackle\nthis issue. However, they encounter difficulties handling variations in anomaly\nlengths and shapes, limiting their adaptability to diverse anomalies.\nAdditionally, many benchmark datasets suffer from the problem of having\nexplicit anomalies that even random functions can detect. This problem is\nexacerbated by ill-posed evaluation metrics, known as point adjustment (PA),\nwhich can result in inflated model performance. In this context, we propose a\nnovel self-supervised learning based Tri-domain Anomaly Detector (TriAD), which\naddresses these challenges by modeling features across three data domains -\ntemporal, frequency, and residual domains - without relying on anomaly labels.\nUnlike traditional contrastive learning methods, TriAD employs both\ninter-domain and intra-domain contrastive loss to learn common attributes among\nnormal data and differentiate them from anomalies. Additionally, our approach\ncan detect anomalies of varying lengths by integrating with a discord discovery\nalgorithm. It is worth noting that this study is the first to reevaluate the\ndeep learning potential in TSAD, utilizing both rigorously designed datasets\n(i.e., UCR Archive) and evaluation metrics (i.e., PA%K and affiliation).\nThrough experimental results on the UCR dataset, TriAD achieves an impressive\nthree-fold increase in PA%K based F1 scores over SOTA deep learning models, and\n50% increase of accuracy as compared to SOTA discord discovery algorithms.\n","authors":["Yuting Sun","Guansong Pang","Guanhua Ye","Tong Chen","Xia Hu","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2311.11235v2.pdf","comment":"This work is submitted to IEEE International Conference on Data\n  Engineering (ICDE) 2024"},{"id":"http://arxiv.org/abs/2306.05734v2","updated":"2023-11-27T01:00:18Z","published":"2023-06-09T07:55:46Z","title":"DP-HyPO: An Adaptive Private Hyperparameter Optimization Framework","summary":"  Hyperparameter optimization, also known as hyperparameter tuning, is a widely\nrecognized technique for improving model performance. Regrettably, when\ntraining private ML models, many practitioners often overlook the privacy risks\nassociated with hyperparameter optimization, which could potentially expose\nsensitive information about the underlying dataset. Currently, the sole\nexisting approach to allow privacy-preserving hyperparameter optimization is to\nuniformly and randomly select hyperparameters for a number of runs,\nsubsequently reporting the best-performing hyperparameter. In contrast, in\nnon-private settings, practitioners commonly utilize ``adaptive''\nhyperparameter optimization methods such as Gaussian process-based\noptimization, which select the next candidate based on information gathered\nfrom previous outputs. This substantial contrast between private and\nnon-private hyperparameter optimization underscores a critical concern. In our\npaper, we introduce DP-HyPO, a pioneering framework for ``adaptive'' private\nhyperparameter optimization, aiming to bridge the gap between private and\nnon-private hyperparameter optimization. To accomplish this, we provide a\ncomprehensive differential privacy analysis of our framework. Furthermore, we\nempirically demonstrate the effectiveness of DP-HyPO on a diverse set of\nreal-world datasets.\n","authors":["Hua Wang","Sheng Gao","Huanyu Zhang","Weijie J. Su","Milan Shen"],"pdf_url":"https://arxiv.org/pdf/2306.05734v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15460v1","updated":"2023-11-27T00:12:47Z","published":"2023-11-27T00:12:47Z","title":"Privacy-Preserving Data Sharing in Agriculture: Enforcing Policy Rules\n  for Secure and Confidential Data Synthesis","summary":"  Big Data empowers the farming community with the information needed to\noptimize resource usage, increase productivity, and enhance the sustainability\nof agricultural practices. The use of Big Data in farming requires the\ncollection and analysis of data from various sources such as sensors,\nsatellites, and farmer surveys. While Big Data can provide the farming\ncommunity with valuable insights and improve efficiency, there is significant\nconcern regarding the security of this data as well as the privacy of the\nparticipants. Privacy regulations, such as the EU GDPR, the EU Code of Conduct\non agricultural data sharing by contractual agreement, and the proposed EU AI\nlaw, have been created to address the issue of data privacy and provide\nspecific guidelines on when and how data can be shared between organizations.\nTo make confidential agricultural data widely available for Big Data analysis\nwithout violating the privacy of the data subjects, we consider\nprivacy-preserving methods of data sharing in agriculture. Deep learning-based\nsynthetic data generation has been proposed for privacy-preserving data\nsharing. However, there is a lack of compliance with documented data privacy\npolicies in such privacy-preserving efforts. In this study, we propose a novel\nframework for enforcing privacy policy rules in privacy-preserving data\ngeneration algorithms. We explore several available agricultural codes of\nconduct, extract knowledge related to the privacy constraints in data, and use\nthe extracted knowledge to define privacy bounds in a privacy-preserving\ngenerative model. We use our framework to generate synthetic agricultural data\nand present experimental results that demonstrate the utility of the synthetic\ndataset in downstream tasks. We also show that our framework can evade\npotential threats and secure data based on applicable regulatory policy rules.\n","authors":["Anantaa Kotal","Lavanya Elluri","Deepti Gupta","Varun Mandalapu","Anupam Joshi"],"pdf_url":"https://arxiv.org/pdf/2311.15460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16380v1","updated":"2023-11-27T23:56:59Z","published":"2023-11-27T23:56:59Z","title":"Learning Multimodal Latent Dynamics for Human-Robot Interaction","summary":"  This article presents a method for learning well-coordinated Human-Robot\nInteraction (HRI) from Human-Human Interactions (HHI). We devise a hybrid\napproach using Hidden Markov Models (HMMs) as the latent space priors for a\nVariational Autoencoder to model a joint distribution over the interacting\nagents. We leverage the interaction dynamics learned from HHI to learn HRI and\nincorporate the conditional generation of robot motions from human observations\ninto the training, thereby predicting more accurate robot trajectories. The\ngenerated robot motions are further adapted with Inverse Kinematics to ensure\nthe desired physical proximity with a human, combining the ease of joint space\nlearning and accurate task space reachability. For contact-rich interactions,\nwe modulate the robot's stiffness using HMM segmentation for a compliant\ninteraction. We verify the effectiveness of our approach deployed on a Humanoid\nrobot via a user study. Our method generalizes well to various humans despite\nbeing trained on data from just two humans. We find that Users perceive our\nmethod as more human-like, timely, and accurate and rank our method with a\nhigher degree of preference over other baselines.\n","authors":["Vignesh Prasad","Lea Heitlinger","Dorothea Koert","Ruth Stock-Homburg","Jan Peters","Georgia Chalvatzaki"],"pdf_url":"https://arxiv.org/pdf/2311.16380v1.pdf","comment":"20 Pages, 10 Figures"},{"id":"http://arxiv.org/abs/2311.16378v1","updated":"2023-11-27T23:53:19Z","published":"2023-11-27T23:53:19Z","title":"Bayesian Formulations for Graph Spectral Denoising","summary":"  We consider noisy signals which are defined on the vertices of a graph and\npresent smoothing algorithms for the cases of Gaussian, dropout, and uniformly\ndistributed noise. The signals are assumed to follow a prior distribution\ndefined in the frequency domain which favors signals which are smooth across\nthe edges of the graph. By pairing this prior distribution with our three\nmodels of noise generation, we propose \\textit{Maximum A Posteriori} (M.A.P.)\nestimates of the true signal in the presence of noisy data and provide\nalgorithms for computing the M.A.P. Finally, we demonstrate the algorithms'\nability to effectively restore white noise on image data, and from severe\ndropout in toy \\& EHR data.\n","authors":["Sam Leone","Xingzhi Sun","Michael Perlmutter","Smita Krishnaswamy"],"pdf_url":"https://arxiv.org/pdf/2311.16378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.05760v3","updated":"2023-11-27T23:38:19Z","published":"2022-01-15T05:25:03Z","title":"Big Data Analytics for Network Level Short-Term Travel Time Prediction\n  with Hierarchical LSTM","summary":"  The travel time data collected from widespread traffic monitoring sensors\nnecessitate big data analytic tools for querying, visualization, and\nidentifying meaningful traffic patterns. This paper utilizes a large-scale\ntravel time dataset from Caltrans Performance Measurement System (PeMS) system\nthat is an overflow for traditional data processing and modeling tools. To\novercome the challenges of the massive amount of data, the big data analytic\nengines Apache Spark and Apache MXNet are applied for data wrangling and\nmodeling. Seasonality and autocorrelation were performed to explore and\nvisualize the trend of time-varying data. Inspired by the success of the\nhierarchical architecture for many Artificial Intelligent (AI) tasks, we\nconsolidate the cell and hidden states passed from low-level to the high-level\nLSTM with an attention pooling similar to how the human perception system\noperates. The designed hierarchical LSTM model can consider the dependencies at\ndifferent time scales to capture the spatial-temporal correlations of\nnetwork-level travel time. Another self-attention module is then devised to\nconnect LSTM extracted features to the fully connected layers, predicting\ntravel time for all corridors instead of a single link/route. The comparison\nresults show that the Hierarchical LSTM with Attention (HierLSTMat) model gives\nthe best prediction results at 30-minute and 45-min horizons and can\nsuccessfully forecast unusual congestion. The efficiency gained from big data\nanalytic tools was evaluated by comparing them with popular data science and\ndeep learning frameworks.\n","authors":["Tianya T. Zhang"],"pdf_url":"https://arxiv.org/pdf/2201.05760v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16374v1","updated":"2023-11-27T23:35:40Z","published":"2023-11-27T23:35:40Z","title":"Physics-Informed Neural Network for Discovering Systems with\n  Unmeasurable States with Application to Lithium-Ion Batteries","summary":"  Combining machine learning with physics is a trending approach for\ndiscovering unknown dynamics, and one of the most intensively studied\nframeworks is the physics-informed neural network (PINN). However, PINN often\nfails to optimize the network due to its difficulty in concurrently minimizing\nmultiple losses originating from the system's governing equations. This problem\ncan be more serious when the system's states are unmeasurable, like lithium-ion\nbatteries (LiBs). In this work, we introduce a robust method for training PINN\nthat uses fewer loss terms and thus constructs a less complex landscape for\noptimization. In particular, instead of having loss terms from each\ndifferential equation, this method embeds the dynamics into a loss function\nthat quantifies the error between observed and predicted system outputs. This\nis accomplished by numerically integrating the predicted states from the neural\nnetwork(NN) using known dynamics and transforming them to obtain a sequence of\npredicted outputs. Minimizing such a loss optimizes the NN to predict states\nconsistent with observations given the physics. Further, the system's\nparameters can be added to the optimization targets. To demonstrate the ability\nof this method to perform various modeling and control tasks, we apply it to a\nbattery model to concurrently estimate its states and parameters.\n","authors":["Yuichi Kajiura","Jorge Espin","Dong Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.16374v1.pdf","comment":"7 pages, 4 figure, submitted to American Control Conference 2024"},{"id":"http://arxiv.org/abs/2111.10085v4","updated":"2023-11-27T23:25:00Z","published":"2021-11-19T08:02:38Z","title":"Mate! Are You Really Aware? An Explainability-Guided Testing Framework\n  for Robustness of Malware Detectors","summary":"  Numerous open-source and commercial malware detectors are available. However,\ntheir efficacy is threatened by new adversarial attacks, whereby malware\nattempts to evade detection, e.g., by performing feature-space manipulation. In\nthis work, we propose an explainability-guided and model-agnostic testing\nframework for robustness of malware detectors when confronted with adversarial\nattacks. The framework introduces the concept of Accrued Malicious Magnitude\n(AMM) to identify which malware features could be manipulated to maximize the\nlikelihood of evading detection. We then use this framework to test several\nstate-of-the-art malware detectors' abilities to detect manipulated malware. We\nfind that (i) commercial antivirus engines are vulnerable to AMM-guided test\ncases; (ii) the ability of a manipulated malware generated using one detector\nto evade detection by another detector (i.e., transferability) depends on the\noverlap of features with large AMM values between the different detectors; and\n(iii) AMM values effectively measure the fragility of features (i.e.,\ncapability of feature-space manipulation to flip the prediction results) and\nexplain the robustness of malware detectors facing evasion attacks. Our\nfindings shed light on the limitations of current malware detectors, as well as\nhow they can be improved.\n","authors":["Ruoxi Sun","Minhui Xue","Gareth Tyson","Tian Dong","Shaofeng Li","Shuo Wang","Haojin Zhu","Seyit Camtepe","Surya Nepal"],"pdf_url":"https://arxiv.org/pdf/2111.10085v4.pdf","comment":"Accepted at ESEC/FSE 2023. https://doi.org/10.1145/3611643.3616309"},{"id":"http://arxiv.org/abs/2307.04870v4","updated":"2023-11-27T23:21:33Z","published":"2023-07-10T19:34:41Z","title":"RACH-Space: Reconstructing Adaptive Convex Hull Space with applications\n  in weak supervision","summary":"  We introduce RACH-Space, a novel classification method in ensemble learning.\nIn particular, we show its applicability as a label model for weakly supervised\nlearning. RACH-Space offers simplicity in implementation with minimal\nassumptions on the data or weak signals. The model is well suited for scenarios\nwhere fully labeled data is not available. Our method is built upon geometrical\ninterpretation of the space spanned by weak signals. Our analysis of the high\ndimensional convex hull structure underlying general set of weak signals\nbridges geometry with machine learning. Empirical results also demonstrate that\nRACH-Space works well in practice and compares favorably to best existing label\nmodels for weakly supervised learning.\n","authors":["Woojoo Na"],"pdf_url":"https://arxiv.org/pdf/2307.04870v4.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2207.08892v3","updated":"2023-11-27T23:13:22Z","published":"2022-07-18T19:06:18Z","title":"Distributed Differentiable Dynamic Game for Multi-robot Coordination","summary":"  This paper develops a Distributed Differentiable Dynamic Game (D3G)\nframework, which can efficiently solve the forward and inverse problems in\nmulti-robot coordination. We formulate multi-robot coordination as a dynamic\ngame, where the behavior of a robot is dictated by its own dynamics and\nobjective that also depends on others' behavior. In the forward problem, D3G\nenables all robots collaboratively to seek the Nash equilibrium of the game in\na distributed manner, by developing a distributed shooting-based Nash solver.\nIn the inverse problem, where each robot aims to find (learn) its objective\n(and dynamics) parameters to mimic given coordination demonstrations, D3G\nproposes a differentiation solver based on Differential Pontryagin's Maximum\nPrinciple, which allows each robot to update its parameters in a distributed\nand coordinated manner. We test the D3G in simulation with two types of robots\ngiven different task configurations. The results demonstrate the effectiveness\nof D3G for solving both forward and inverse problems in comparison with\nexisting methods.\n","authors":["Xuan Wang","Yizhi Zhou","Wanxin Jin"],"pdf_url":"https://arxiv.org/pdf/2207.08892v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.18158v2","updated":"2023-11-27T23:12:48Z","published":"2023-03-31T15:51:56Z","title":"Constrained Optimization of Rank-One Functions with Indicator Variables","summary":"  Optimization problems involving minimization of a rank-one convex function\nover constraints modeling restrictions on the support of the decision variables\nemerge in various machine learning applications. These problems are often\nmodeled with indicator variables for identifying the support of the continuous\nvariables. In this paper we investigate compact extended formulations for such\nproblems through perspective reformulation techniques. In contrast to the\nmajority of previous work that relies on support function arguments and\ndisjunctive programming techniques to provide convex hull results, we propose a\nconstructive approach that exploits a hidden conic structure induced by\nperspective functions. To this end, we first establish a convex hull result for\na general conic mixed-binary set in which each conic constraint involves a\nlinear function of independent continuous variables and a set of binary\nvariables. We then demonstrate that extended representations of sets associated\nwith epigraphs of rank-one convex functions over constraints modeling indicator\nrelations naturally admit such a conic representation. This enables us to\nsystematically give perspective formulations for the convex hull descriptions\nof these sets with nonlinear separable or non-separable objective functions,\nsign constraints on continuous variables, and combinatorial constraints on\nindicator variables. We illustrate the efficacy of our results on sparse\nnonnegative logistic regression problems.\n","authors":["Soroosh Shafiee","Fatma Kılınç-Karzan"],"pdf_url":"https://arxiv.org/pdf/2303.18158v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.08890v2","updated":"2023-11-27T23:12:08Z","published":"2023-07-17T23:22:57Z","title":"The Predicted-Updates Dynamic Model: Offline, Incremental, and\n  Decremental to Fully Dynamic Transformations","summary":"  We formulate the predicted-updates dynamic model, one of the first\nbeyond-worst-case models for dynamic algorithms, which generalizes a large set\nof well-studied dynamic models including the offline dynamic, incremental, and\ndecremental models to the fully dynamic setting when given predictions about\nthe update times of the elements. In the most basic form of our model, we\nreceive a set of predicted update times for all of the updates that occur over\nthe event horizon. We give a novel framework that \"lifts\" offline\ndivide-and-conquer algorithms into the fully dynamic setting with little\noverhead. Using this, we are able to interpolate between the offline and fully\ndynamic settings; when the $\\ell_1$ error of the prediction is linear in the\nnumber of updates, we achieve the offline runtime of the algorithm (up to\n$\\mathrm{poly} \\log n$ factors). Provided a fully dynamic backstop algorithm,\nour algorithm will never do worse than the backstop algorithm regardless of the\nprediction error. Furthermore, our framework achieves a smooth linear trade-off\nbetween $\\ell_1$ error in the predictions and runtime. These correspond to the\ndesiderata of consistency, robustness, and graceful degradation of the\nalgorithms-with-predictions literature. We further extend our techniques to\nincremental and decremental settings, transforming algorithms in these settings\nwhen given predictions of only the deletion and insertion times, respectively.\nOur framework is general, and we apply it to obtain improved efficiency bounds\nover the state-of-the-art dynamic algorithms for a variety of problems\nincluding triconnectivity, planar digraph all pairs shortest paths, $k$-edge\nconnectivity, and others, for prediction error of reasonable magnitude.\n","authors":["Quanquan C. Liu","Vaidehi Srinivas"],"pdf_url":"https://arxiv.org/pdf/2307.08890v2.pdf","comment":"The previous version focused on incremental to fully dynamic\n  transformation. The new version includes a more general framework including\n  offline to fully dynamic transformations"},{"id":"http://arxiv.org/abs/2311.14646v2","updated":"2023-11-27T23:06:27Z","published":"2023-11-24T18:27:41Z","title":"More is Better in Modern Machine Learning: when Infinite\n  Overparameterization is Optimal and Overfitting is Obligatory","summary":"  In our era of enormous neural networks, empirical progress has been driven by\nthe philosophy that more is better. Recent deep learning practice has found\nrepeatedly that larger model size, more data, and more computation (resulting\nin lower training loss) improves performance. In this paper, we give\ntheoretical backing to these empirical observations by showing that these three\nproperties hold in random feature (RF) regression, a class of models equivalent\nto shallow networks with only the last layer trained.\n  Concretely, we first show that the test risk of RF regression decreases\nmonotonically with both the number of features and the number of samples,\nprovided the ridge penalty is tuned optimally. In particular, this implies that\ninfinite width RF architectures are preferable to those of any finite width. We\nthen proceed to demonstrate that, for a large class of tasks characterized by\npowerlaw eigenstructure, training to near-zero training loss is obligatory:\nnear-optimal performance can only be achieved when the training error is much\nsmaller than the test error. Grounding our theory in real-world data, we find\nempirically that standard computer vision tasks with convolutional neural\ntangent kernels clearly fall into this class. Taken together, our results tell\na simple, testable story of the benefits of overparameterization, overfitting,\nand more data in random feature models.\n","authors":["James B. Simon","Dhruva Karkada","Nikhil Ghosh","Mikhail Belkin"],"pdf_url":"https://arxiv.org/pdf/2311.14646v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10575v2","updated":"2023-11-27T23:00:02Z","published":"2023-01-25T13:27:27Z","title":"Trainable Loss Weights in Super-Resolution","summary":"  In recent years, limited research has discussed the loss function in the\nsuper-resolution process. The majority of those studies have only used\nperceptual similarity conventionally. This is while the development of\nappropriate loss can improve the quality of other methods as well. In this\narticle, a new weighting method for pixel-wise loss is proposed. With the help\nof this method, it is possible to use trainable weights based on the general\nstructure of the image and its perceptual features while maintaining the\nadvantages of pixel-wise loss. Also, a criterion for comparing weights of loss\nis introduced so that the weights can be estimated directly by a convolutional\nneural network. In addition, in this article, the expectation-maximization\nmethod is used for the simultaneous estimation super-resolution network and\nweighting network. In addition, a new activation function, called \"FixedSum\",\nis introduced which can keep the sum of all components of vector constants\nwhile keeping the output components between zero and one. As experimental\nresults shows, weighted loss by the proposed method leads to better results\nthan the unweighted loss and weighted loss based on uncertainty in both\nsignal-to-noise and perceptual similarity senses on the state-of-the-art\nnetworks. Code is available online.\n","authors":["Arash Chaichi Mellatshahi","Shohreh Kasaei"],"pdf_url":"https://arxiv.org/pdf/2301.10575v2.pdf","comment":"9 pages, 6 figures, 2 table"},{"id":"http://arxiv.org/abs/2311.16361v1","updated":"2023-11-27T22:52:45Z","published":"2023-11-27T22:52:45Z","title":"Making Self-supervised Learning Robust to Spurious Correlation via\n  Learning-speed Aware Sampling","summary":"  Self-supervised learning (SSL) has emerged as a powerful technique for\nlearning rich representations from unlabeled data. The data representations are\nable to capture many underlying attributes of data, and be useful in downstream\nprediction tasks. In real-world settings, spurious correlations between some\nattributes (e.g. race, gender and age) and labels for downstream tasks often\nexist, e.g. cancer is usually more prevalent among elderly patients. In this\npaper, we investigate SSL in the presence of spurious correlations and show\nthat the SSL training loss can be minimized by capturing only a subset of the\nconspicuous features relevant to those sensitive attributes, despite the\npresence of other important predictive features for the downstream tasks. To\naddress this issue, we investigate the learning dynamics of SSL and observe\nthat the learning is slower for samples that conflict with such correlations\n(e.g. elder patients without cancer). Motivated by these findings, we propose a\nlearning-speed aware SSL (LA-SSL) approach, in which we sample each training\ndata with a probability that is inversely related to its learning speed. We\nevaluate LA-SSL on three datasets that exhibit spurious correlations between\ndifferent attributes, demonstrating that it improves the robustness of\npretrained representations on downstream classification tasks.\n","authors":["Weicheng Zhu","Sheng Liu","Carlos Fernandez-Granda","Narges Razavian"],"pdf_url":"https://arxiv.org/pdf/2311.16361v1.pdf","comment":"Accepted by NeurIPS 2023 Workshop Self-Supervised Learning - Theory\n  and Practice, 18 pages, 7 figures, 7 tables"},{"id":"http://arxiv.org/abs/2311.16357v1","updated":"2023-11-27T22:40:02Z","published":"2023-11-27T22:40:02Z","title":"Cross Entropy in Deep Learning of Classifiers Is Unnecessary -- ISBE\n  Error is All You Need","summary":"  In deep learning classifiers, the cost function usually takes the form of a\ncombination of SoftMax and CrossEntropy functions. The SoftMax unit transforms\nthe scores predicted by the model network into assessments of the degree\n(probabilities) of an object's membership to a given class. On the other hand,\nCrossEntropy measures the divergence of this prediction from the distribution\nof target scores. This work introduces the ISBE functionality, justifying the\nthesis about the redundancy of cross entropy computation in deep learning of\nclassifiers. Not only can we omit the calculation of entropy, but also, during\nback-propagation, there is no need to direct the error to the normalization\nunit for its backward transformation. Instead, the error is sent directly to\nthe model's network. Using examples of perceptron and convolutional networks as\nclassifiers of images from the MNIST collection, it is observed for ISBE that\nresults are not degraded with SoftMax only, but also with other activation\nfunctions such as Sigmoid, Tanh, or their hard variants HardSigmoid and\nHardTanh. Moreover, up to three percent of time is saved within the total time\nof forward and backward stages. The article is addressed mainly to programmers\nand students interested in deep model learning. For example, it illustrates in\ncode snippets possible ways to implement ISBE units, but also formally proves\nthat the softmax trick only applies to the class of softmax functions with\nrelocations.\n","authors":["Wladyslaw Skarbek"],"pdf_url":"https://arxiv.org/pdf/2311.16357v1.pdf","comment":"18 pages, 4 figures"},{"id":"http://arxiv.org/abs/2311.16353v1","updated":"2023-11-27T22:30:26Z","published":"2023-11-27T22:30:26Z","title":"Improving Denoising Diffusion Probabilistic Models via Exploiting Shared\n  Representations","summary":"  In this work, we address the challenge of multi-task image generation with\nlimited data for denoising diffusion probabilistic models (DDPM), a class of\ngenerative models that produce high-quality images by reversing a noisy\ndiffusion process. We propose a novel method, SR-DDPM, that leverages\nrepresentation-based techniques from few-shot learning to effectively learn\nfrom fewer samples across different tasks. Our method consists of a core meta\narchitecture with shared parameters, i.e., task-specific layers with exclusive\nparameters. By exploiting the similarity between diverse data distributions,\nour method can scale to multiple tasks without compromising the image quality.\nWe evaluate our method on standard image datasets and show that it outperforms\nboth unconditional and conditional DDPM in terms of FID and SSIM metrics.\n","authors":["Delaram Pirhayatifard","Mohammad Taha Toghani","Guha Balakrishnan","César A. Uribe"],"pdf_url":"https://arxiv.org/pdf/2311.16353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16346v1","updated":"2023-11-27T22:25:46Z","published":"2023-11-27T22:25:46Z","title":"Small and Dim Target Detection in IR Imagery: A Review","summary":"  While there has been significant progress in object detection using\nconventional image processing and machine learning algorithms, exploring small\nand dim target detection in the IR domain is a relatively new area of study.\nThe majority of small and dim target detection methods are derived from\nconventional object detection algorithms, albeit with some alterations. The\ntask of detecting small and dim targets in IR imagery is complex. This is\nbecause these targets often need distinct features, the background is cluttered\nwith unclear details, and the IR signatures of the scene can change over time\ndue to fluctuations in thermodynamics. The primary objective of this review is\nto highlight the progress made in this field. This is the first review in the\nfield of small and dim target detection in infrared imagery, encompassing\nvarious methodologies ranging from conventional image processing to\ncutting-edge deep learning-based approaches. The authors have also introduced a\ntaxonomy of such approaches. There are two main types of approaches:\nmethodologies using several frames for detection, and single-frame-based\ndetection techniques. Single frame-based detection techniques encompass a\ndiverse range of methods, spanning from traditional image processing-based\napproaches to more advanced deep learning methodologies. Our findings indicate\nthat deep learning approaches perform better than traditional image\nprocessing-based approaches. In addition, a comprehensive compilation of\nvarious available datasets has also been provided. Furthermore, this review\nidentifies the gaps and limitations in existing techniques, paving the way for\nfuture research and development in this area.\n","authors":["Nikhil Kumar","Pravendra Singh"],"pdf_url":"https://arxiv.org/pdf/2311.16346v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2301.13098v2","updated":"2023-11-27T22:09:31Z","published":"2023-01-30T17:36:12Z","title":"CHeart: A Conditional Spatio-Temporal Generative Model for Cardiac\n  Anatomy","summary":"  Two key questions in cardiac image analysis are to assess the anatomy and\nmotion of the heart from images; and to understand how they are associated with\nnon-imaging clinical factors such as gender, age and diseases. While the first\nquestion can often be addressed by image segmentation and motion tracking\nalgorithms, our capability to model and to answer the second question is still\nlimited. In this work, we propose a novel conditional generative model to\ndescribe the 4D spatio-temporal anatomy of the heart and its interaction with\nnon-imaging clinical factors. The clinical factors are integrated as the\nconditions of the generative modelling, which allows us to investigate how\nthese factors influence the cardiac anatomy. We evaluate the model performance\nin mainly two tasks, anatomical sequence completion and sequence generation.\nThe model achieves a high performance in anatomical sequence completion,\ncomparable to or outperforming other state-of-the-art generative models. In\nterms of sequence generation, given clinical conditions, the model can generate\nrealistic synthetic 4D sequential anatomies that share similar distributions\nwith the real data.\n","authors":["Mengyun Qiao","Shuo Wang","Huaqi Qiu","Antonio de Marvao","Declan P. O'Regan","Daniel Rueckert","Wenjia Bai"],"pdf_url":"https://arxiv.org/pdf/2301.13098v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.16064v2","updated":"2023-11-27T22:05:53Z","published":"2023-09-27T23:11:35Z","title":"Masked Autoencoders are Scalable Learners of Cellular Morphology","summary":"  Inferring biological relationships from cellular phenotypes in high-content\nmicroscopy screens provides significant opportunity and challenge in biological\nresearch. Prior results have shown that deep vision models can capture\nbiological signal better than hand-crafted features. This work explores how\nself-supervised deep learning approaches scale when training larger models on\nlarger microscopy datasets. Our results show that both CNN- and ViT-based\nmasked autoencoders significantly outperform weakly supervised baselines. At\nthe high-end of our scale, a ViT-L/8 trained on over 3.5-billion unique crops\nsampled from 93-million microscopy images achieves relative improvements as\nhigh as 28% over our best weakly supervised baseline at inferring known\nbiological relationships curated from public databases. Relevant code and\nselect models released with this work can be found at:\nhttps://github.com/recursionpharma/maes_microscopy.\n","authors":["Oren Kraus","Kian Kenyon-Dean","Saber Saberian","Maryam Fallah","Peter McLean","Jess Leung","Vasudev Sharma","Ayla Khan","Jia Balakrishnan","Safiye Celik","Maciej Sypetkowski","Chi Vicky Cheng","Kristen Morse","Maureen Makes","Ben Mabey","Berton Earnshaw"],"pdf_url":"https://arxiv.org/pdf/2309.16064v2.pdf","comment":"Spotlight at NeurIPS 2023 Generative AI and Biology (GenBio) Workshop"},{"id":"http://arxiv.org/abs/2311.16339v1","updated":"2023-11-27T21:56:18Z","published":"2023-11-27T21:56:18Z","title":"Reward Shaping for Improved Learning in Real-time Strategy Game Play","summary":"  We investigate the effect of reward shaping in improving the performance of\nreinforcement learning in the context of the real-time strategy,\ncapture-the-flag game. The game is characterized by sparse rewards that are\nassociated with infrequently occurring events such as grabbing or capturing the\nflag, or tagging the opposing player. We show that appropriately designed\nreward shaping functions applied to different game events can significantly\nimprove the player's performance and training times of the player's learning\nalgorithm. We have validated our reward shaping functions within a simulated\nenvironment for playing a marine capture-the-flag game between two players. Our\nexperimental results demonstrate that reward shaping can be used as an\neffective means to understand the importance of different sub-tasks during\ngame-play towards winning the game, to encode a secondary objective functions\nsuch as energy efficiency into a player's game-playing behavior, and, to\nimprove learning generalizable policies that can perform well against different\nskill levels of the opponent.\n","authors":["John Kliem","Prithviraj Dasgupta"],"pdf_url":"https://arxiv.org/pdf/2311.16339v1.pdf","comment":"15 pages 11 figures and 5 tables"},{"id":"http://arxiv.org/abs/2311.16333v1","updated":"2023-11-27T21:37:50Z","published":"2023-11-27T21:37:50Z","title":"From Reactive to Proactive Volatility Modeling with Hemisphere Neural\n  Networks","summary":"  We reinvigorate maximum likelihood estimation (MLE) for macroeconomic density\nforecasting through a novel neural network architecture with dedicated mean and\nvariance hemispheres. Our architecture features several key ingredients making\nMLE work in this context. First, the hemispheres share a common core at the\nentrance of the network which accommodates for various forms of time variation\nin the error variance. Second, we introduce a volatility emphasis constraint\nthat breaks mean/variance indeterminacy in this class of overparametrized\nnonlinear models. Third, we conduct a blocked out-of-bag reality check to curb\noverfitting in both conditional moments. Fourth, the algorithm utilizes\nstandard deep learning software and thus handles large data sets - both\ncomputationally and statistically. Ergo, our Hemisphere Neural Network (HNN)\nprovides proactive volatility forecasts based on leading indicators when it\ncan, and reactive volatility based on the magnitude of previous prediction\nerrors when it must. We evaluate point and density forecasts with an extensive\nout-of-sample experiment and benchmark against a suite of models ranging from\nclassics to more modern machine learning-based offerings. In all cases, HNN\nfares well by consistently providing accurate mean/variance forecasts for all\ntargets and horizons. Studying the resulting volatility paths reveals its\nversatility, while probabilistic forecasting evaluation metrics showcase its\nenviable reliability. Finally, we also demonstrate how this machinery can be\nmerged with other structured deep learning models by revisiting Goulet Coulombe\n(2022)'s Neural Phillips Curve.\n","authors":["Philippe Goulet Coulombe","Mikael Frenette","Karin Klieber"],"pdf_url":"https://arxiv.org/pdf/2311.16333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.16252v2","updated":"2023-11-27T21:33:05Z","published":"2023-10-25T00:05:37Z","title":"Near-Optimal Pure Exploration in Matrix Games: A Generalization of\n  Stochastic Bandits & Dueling Bandits","summary":"  We study the sample complexity of identifying the pure strategy Nash\nequilibrium (PSNE) in a two-player zero-sum matrix game with noise. Formally,\nwe are given a stochastic model where any learner can sample an entry $(i,j)$\nof the input matrix $A\\in[-1,1]^{n\\times m}$ and observe $A_{i,j}+\\eta$ where\n$\\eta$ is a zero-mean 1-sub-Gaussian noise. The aim of the learner is to\nidentify the PSNE of $A$, whenever it exists, with high probability while\ntaking as few samples as possible. Zhou et al. (2017) presents an\ninstance-dependent sample complexity lower bound that depends only on the\nentries in the row and column in which the PSNE lies. We design a near-optimal\nalgorithm whose sample complexity matches the lower bound, up to log factors.\nThe problem of identifying the PSNE also generalizes the problem of pure\nexploration in stochastic multi-armed bandits and dueling bandits, and our\nresult matches the optimal bounds, up to log factors, in both the settings.\n","authors":["Arnab Maiti","Ross Boczar","Kevin Jamieson","Lillian J. Ratliff"],"pdf_url":"https://arxiv.org/pdf/2310.16252v2.pdf","comment":"22 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.16328v1","updated":"2023-11-27T21:23:41Z","published":"2023-11-27T21:23:41Z","title":"Target-Free Compound Activity Prediction via Few-Shot Learning","summary":"  Predicting the activities of compounds against protein-based or phenotypic\nassays using only a few known compounds and their activities is a common task\nin target-free drug discovery. Existing few-shot learning approaches are\nlimited to predicting binary labels (active/inactive). However, in real-world\ndrug discovery, degrees of compound activity are highly relevant. We study\nFew-Shot Compound Activity Prediction (FS-CAP) and design a novel neural\narchitecture to meta-learn continuous compound activities across large\nbioactivity datasets. Our model aggregates encodings generated from the known\ncompounds and their activities to capture assay information. We also introduce\na separate encoder for the unknown compound. We show that FS-CAP surpasses\ntraditional similarity-based techniques as well as other state of the art\nfew-shot learning methods on a variety of target-free drug discovery settings\nand datasets.\n","authors":["Peter Eckmann","Jake Anderson","Michael K. Gilson","Rose Yu"],"pdf_url":"https://arxiv.org/pdf/2311.16328v1.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2310.18515v2","updated":"2023-11-27T21:21:48Z","published":"2023-10-27T22:22:44Z","title":"Learning to design protein-protein interactions with enhanced\n  generalization","summary":"  Discovering mutations enhancing protein-protein interactions (PPIs) is\ncritical for advancing biomedical research and developing improved\ntherapeutics. While machine learning approaches have substantially advanced the\nfield, they often struggle to generalize beyond training data in practical\nscenarios. The contributions of this work are three-fold. First, we construct\nPPIRef, the largest and non-redundant dataset of 3D protein-protein\ninteractions, enabling effective large-scale learning. Second, we leverage the\nPPIRef dataset to pre-train PPIformer, a new SE(3)-equivariant model\ngeneralizing across diverse protein-binder variants. We fine-tune PPIformer to\npredict effects of mutations on protein-protein interactions via a\nthermodynamically motivated adjustment of the pre-training loss function.\nFinally, we demonstrate the enhanced generalization of our new PPIformer\napproach by outperforming other state-of-the-art methods on new, non-leaking\nsplits of standard labeled PPI mutational data and independent case studies\noptimizing a human antibody against SARS-CoV-2 and increasing the thrombolytic\nactivity of staphylokinase.\n","authors":["Anton Bushuiev","Roman Bushuiev","Petr Kouba","Anatolii Filkin","Marketa Gabrielova","Michal Gabriel","Jiri Sedlar","Tomas Pluskal","Jiri Damborsky","Stanislav Mazurenko","Josef Sivic"],"pdf_url":"https://arxiv.org/pdf/2310.18515v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.17639v2","updated":"2023-11-27T21:05:54Z","published":"2023-10-26T17:54:52Z","title":"In-Context Learning Dynamics with Random Binary Sequences","summary":"  Large language models (LLMs) trained on huge corpora of text datasets\ndemonstrate intriguing capabilities, achieving state-of-the-art performance on\ntasks they were not explicitly trained for. The precise nature of LLM\ncapabilities is often mysterious, and different prompts can elicit different\ncapabilities through in-context learning. We propose a framework that enables\nus to analyze in-context learning dynamics to understand latent concepts\nunderlying LLMs' behavioral patterns. This provides a more nuanced\nunderstanding than success-or-failure evaluation benchmarks, but does not\nrequire observing internal activations as a mechanistic interpretation of\ncircuits would. Inspired by the cognitive science of human randomness\nperception, we use random binary sequences as context and study dynamics of\nin-context learning by manipulating properties of context data, such as\nsequence length. In the latest GPT-3.5+ models, we find emergent abilities to\ngenerate seemingly random numbers and learn basic formal languages, with\nstriking in-context learning dynamics where model outputs transition sharply\nfrom seemingly random behaviors to deterministic repetition.\n","authors":["Eric J. Bigelow","Ekdeep Singh Lubana","Robert P. Dick","Hidenori Tanaka","Tomer D. Ullman"],"pdf_url":"https://arxiv.org/pdf/2310.17639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16312v1","updated":"2023-11-27T21:01:29Z","published":"2023-11-27T21:01:29Z","title":"Domain-Specific Deep Learning Feature Extractor for Diabetic Foot Ulcer\n  Detection","summary":"  Diabetic Foot Ulcer (DFU) is a condition requiring constant monitoring and\nevaluations for treatment. DFU patient population is on the rise and will soon\noutpace the available health resources. Autonomous monitoring and evaluation of\nDFU wounds is a much-needed area in health care. In this paper, we evaluate and\nidentify the most accurate feature extractor that is the core basis for\ndeveloping a deep-learning wound detection network. For the evaluation, we used\nmAP and F1-score on the publicly available DFU2020 dataset. A combination of\nUNet and EfficientNetb3 feature extractor resulted in the best evaluation among\nthe 14 networks compared. UNet and Efficientnetb3 can be used as the classifier\nin the development of a comprehensive DFU domain-specific autonomous wound\ndetection pipeline.\n","authors":["Reza Basiri","Milos R. Popovic","Shehroz S. Khan"],"pdf_url":"https://arxiv.org/pdf/2311.16312v1.pdf","comment":"5 pages, 2 figures, 3 tables, 2022 IEEE International Conference on\n  Data Mining Workshops"},{"id":"http://arxiv.org/abs/2305.14561v2","updated":"2023-11-27T20:57:52Z","published":"2023-05-23T22:56:26Z","title":"Negative Feedback Training: A Novel Concept to Improve Robustness of\n  NVCIM DNN Accelerators","summary":"  Compute-in-memory (CIM) accelerators built upon non-volatile memory (NVM)\ndevices excel in energy efficiency and latency when performing Deep Neural\nNetwork (DNN) inference, thanks to their in-situ data processing capability.\nHowever, the stochastic nature and intrinsic variations of NVM devices often\nresult in performance degradation in DNN inference. Introducing these non-ideal\ndevice behaviors during DNN training enhances robustness, but drawbacks include\nlimited accuracy improvement, reduced prediction confidence, and convergence\nissues. This arises from a mismatch between the deterministic training and\nnon-deterministic device variations, as such training, though considering\nvariations, relies solely on the model's final output. In this work, we draw\ninspiration from the control theory and propose a novel training concept:\nNegative Feedback Training (NFT) leveraging the multi-scale noisy information\ncaptured from network. We develop two specific NFT instances, Oriented\nVariational Forward (OVF) and Intermediate Representation Snapshot (IRS).\nExtensive experiments show that our methods outperform existing\nstate-of-the-art methods with up to a 46.71% improvement in inference accuracy\nwhile reducing epistemic uncertainty, boosting output confidence, and improving\nconvergence probability. Their effectiveness highlights the generality and\npracticality of our NFT concept in enhancing DNN robustness against device\nvariations.\n","authors":["Yifan Qin","Zheyu Yan","Wujie Wen","Xiaobo Sharon Hu","Yiyu Shi"],"pdf_url":"https://arxiv.org/pdf/2305.14561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16302v1","updated":"2023-11-27T20:33:54Z","published":"2023-11-27T20:33:54Z","title":"Comprehensive Benchmarking of Entropy and Margin Based Scoring Metrics\n  for Data Selection","summary":"  While data selection methods have been studied extensively in active\nlearning, data pruning, and data augmentation settings, there is little\nevidence for the efficacy of these methods in industry scale settings,\nparticularly in low-resource languages. Our work presents ways of assessing\nprospective training examples in those settings for their \"usefulness\" or\n\"difficulty\". We also demonstrate how these measures can be used in selecting\nimportant examples for training supervised machine learning models. We\nprimarily experiment with entropy and Error L2-Norm (EL2N) scores. We use these\nmetrics to curate high quality datasets from a large pool of \\textit{Weak\nSignal Labeled} data, which assigns no-defect high confidence hypotheses during\ninference as ground truth labels. We then conduct training data augmentation\nexperiments using these de-identified datasets and demonstrate that score-based\nselection can result in a 2% decrease in semantic error rate and 4%-7% decrease\nin domain classification error rate when compared to the baseline technique of\nrandom selection.\n","authors":["Anusha Sabbineni","Nikhil Anand","Maria Minakova"],"pdf_url":"https://arxiv.org/pdf/2311.16302v1.pdf","comment":"Accepted to Efficient Natural Language and Speech Processing\n  (ENLSP-III) workshop at NeurIPS '23"},{"id":"http://arxiv.org/abs/2311.16298v1","updated":"2023-11-27T20:19:22Z","published":"2023-11-27T20:19:22Z","title":"Influence Scores at Scale for Efficient Language Data Sampling","summary":"  Modern ML systems ingest data aggregated from diverse sources, such as\nsynthetic, human-annotated, and live customer traffic. Understanding\n\\textit{which} examples are important to the performance of a learning\nalgorithm is crucial for efficient model training. Recently, a growing body of\nliterature has given rise to various \"influence scores,\" which use training\nartifacts such as model confidence or checkpointed gradients to identify\nimportant subsets of data. However, these methods have primarily been developed\nin computer vision settings, and it remains unclear how well they generalize to\nlanguage-based tasks using pretrained models.\n  In this paper, we explore the applicability of influence scores in language\nclassification tasks. We evaluate a diverse subset of these scores on the SNLI\ndataset by quantifying accuracy changes in response to pruning training data\nthrough random and influence-score-based sampling. We then stress-test one of\nthe scores -- \"variance of gradients\" (VoG) from Agarwal et al. (2022) -- in an\nNLU model stack that was exposed to dynamic user speech patterns in a voice\nassistant type of setting. Our experiments demonstrate that in many cases,\nencoder-based language models can be finetuned on roughly 50% of the original\ndata without degradation in performance metrics. Along the way, we summarize\nlessons learned from applying out-of-the-box implementations of influence\nscores, quantify the effects of noisy and class-imbalanced data, and offer\nrecommendations on score-based sampling for better accuracy and training\nefficiency.\n","authors":["Nikhil Anand","Joshua Tan","Maria Minakova"],"pdf_url":"https://arxiv.org/pdf/2311.16298v1.pdf","comment":"Accepted at EMNLP '23"},{"id":"http://arxiv.org/abs/2311.16297v1","updated":"2023-11-27T20:18:39Z","published":"2023-11-27T20:18:39Z","title":"Quantum-classical simulation of quantum field theory by quantum circuit\n  learning","summary":"  We employ quantum circuit learning to simulate quantum field theories (QFTs).\nTypically, when simulating QFTs with quantum computers, we encounter\nsignificant challenges due to the technical limitations of quantum devices when\nimplementing the Hamiltonian using Pauli spin matrices. To address this\nchallenge, we leverage quantum circuit learning, employing a compact\nconfiguration of qubits and low-depth quantum circuits to predict real-time\ndynamics in quantum field theories. The key advantage of this approach is that\na single-qubit measurement can accurately forecast various physical parameters,\nincluding fully-connected operators. To demonstrate the effectiveness of our\nmethod, we use it to predict quench dynamics, chiral dynamics and jet\nproduction in a 1+1-dimensional model of quantum electrodynamics. We find that\nour predictions closely align with the results of rigorous classical\ncalculations, exhibiting a high degree of accuracy. This hybrid\nquantum-classical approach illustrates the feasibility of efficiently\nsimulating large-scale QFTs on cutting-edge quantum devices.\n","authors":["Kazuki Ikeda"],"pdf_url":"https://arxiv.org/pdf/2311.16297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16286v1","updated":"2023-11-27T20:02:55Z","published":"2023-11-27T20:02:55Z","title":"A statistical approach to latent dynamic modeling with differential\n  equations","summary":"  Ordinary differential equations (ODEs) can provide mechanistic models of\ntemporally local changes of processes, where parameters are often informed by\nexternal knowledge. While ODEs are popular in systems modeling, they are less\nestablished for statistical modeling of longitudinal cohort data, e.g., in a\nclinical setting. Yet, modeling of local changes could also be attractive for\nassessing the trajectory of an individual in a cohort in the immediate future\ngiven its current status, where ODE parameters could be informed by further\ncharacteristics of the individual. However, several hurdles so far limit such\nuse of ODEs, as compared to regression-based function fitting approaches. The\npotentially higher level of noise in cohort data might be detrimental to ODEs,\nas the shape of the ODE solution heavily depends on the initial value. In\naddition, larger numbers of variables multiply such problems and might be\ndifficult to handle for ODEs. To address this, we propose to use each\nobservation in the course of time as the initial value to obtain multiple local\nODE solutions and build a combined estimator of the underlying dynamics. Neural\nnetworks are used for obtaining a low-dimensional latent space for dynamic\nmodeling from a potentially large number of variables, and for obtaining\npatient-specific ODE parameters from baseline variables. Simultaneous\nidentification of dynamic models and of a latent space is enabled by recently\ndeveloped differentiable programming techniques. We illustrate the proposed\napproach in an application with spinal muscular atrophy patients and a\ncorresponding simulation study. In particular, modeling of local changes in\nhealth status at any point in time is contrasted to the interpretation of\nfunctions obtained from a global regression. This more generally highlights how\ndifferent application settings might demand different modeling strategies.\n","authors":["Maren Hackenberg","Astrid Pechmann","Clemens Kreutz","Janbernd Kirschner","Harald Binder"],"pdf_url":"https://arxiv.org/pdf/2311.16286v1.pdf","comment":"29 pages, 6 figures"},{"id":"http://arxiv.org/abs/2212.09744v2","updated":"2023-11-27T19:57:09Z","published":"2022-12-19T18:59:34Z","title":"DSI++: Updating Transformer Memory with New Documents","summary":"  Differentiable Search Indices (DSIs) encode a corpus of documents in model\nparameters and use the same model to answer user queries directly. Despite the\nstrong performance of DSI models, deploying them in situations where the corpus\nchanges over time is computationally expensive because reindexing the corpus\nrequires re-training the model. In this work, we introduce DSI++, a continual\nlearning challenge for DSI to incrementally index new documents while being\nable to answer queries related to both previously and newly indexed documents.\nAcross different model scales and document identifier representations, we show\nthat continual indexing of new documents leads to considerable forgetting of\npreviously indexed documents. We also hypothesize and verify that the model\nexperiences forgetting events during training, leading to unstable learning. To\nmitigate these issues, we investigate two approaches. The first focuses on\nmodifying the training dynamics. Flatter minima implicitly alleviate\nforgetting, so we optimize for flatter loss basins and show that the model\nstably memorizes more documents ($+12\\%$). Next, we introduce a generative\nmemory to sample pseudo-queries for documents and supplement them during\ncontinual indexing to prevent forgetting for the retrieval task. Extensive\nexperiments on novel continual indexing benchmarks based on Natural Questions\n(NQ) and MS MARCO demonstrate that our proposed solution mitigates forgetting\nsignificantly. Concretely, it improves the average Hits@10 by $+21.1\\%$ over\ncompetitive baselines for NQ and requires $6$ times fewer model updates\ncompared to re-training the DSI model for incrementally indexing five corpora\nin a sequence.\n","authors":["Sanket Vaibhav Mehta","Jai Gupta","Yi Tay","Mostafa Dehghani","Vinh Q. Tran","Jinfeng Rao","Marc Najork","Emma Strubell","Donald Metzler"],"pdf_url":"https://arxiv.org/pdf/2212.09744v2.pdf","comment":"Accepted at EMNLP 2023 main conference"},{"id":"http://arxiv.org/abs/2310.14045v2","updated":"2023-11-27T19:43:36Z","published":"2023-10-21T15:43:24Z","title":"Training Image Derivatives: Increased Accuracy and Universal Robustness","summary":"  Derivative training is a known method that significantly improves the\naccuracy of neural networks in some low-dimensional applications. In this\npaper, a similar improvement is obtained for an image analysis problem:\nreconstructing the vertices of a cube from its image. By training the\nderivatives with respect to the 6 degrees of freedom of the cube, we obtain 25\ntimes more accurate results for noiseless inputs. The derivatives also offer\ninsight into the robustness problem, which is currently understood in terms of\ntwo types of network vulnerabilities. The first type involves small\nperturbations that dramatically change the output, and the second type relates\nto substantial image changes that the network erroneously ignores. Defense\nagainst each is possible, but safeguarding against both while maintaining the\naccuracy defies conventional training methods. The first type is analyzed using\nthe network's gradient, while the second relies on human input evaluation,\nserving as an oracle substitute. For the task at hand, the nearest neighbor\noracle can be defined and expanded into Taylor series using image derivatives.\nThis allows for a robustness analysis that unifies both types of\nvulnerabilities and enables training where accuracy and universal robustness\nare limited only by network capacity.\n","authors":["Vsevolod I. Avrutskiy"],"pdf_url":"https://arxiv.org/pdf/2310.14045v2.pdf","comment":"converted to two-column format, shortened abstract, improved\n  readability, removed unnecessary graphics, fixed typos"},{"id":"http://arxiv.org/abs/2311.16277v1","updated":"2023-11-27T19:33:14Z","published":"2023-11-27T19:33:14Z","title":"A Graph Neural Network-Based QUBO-Formulated Hamiltonian-Inspired Loss\n  Function for Combinatorial Optimization using Reinforcement Learning","summary":"  Quadratic Unconstrained Binary Optimization (QUBO) is a generic technique to\nmodel various NP-hard Combinatorial Optimization problems (CO) in the form of\nbinary variables. Ising Hamiltonian is used to model the energy function of a\nsystem. QUBO to Ising Hamiltonian is regarded as a technique to solve various\ncanonical optimization problems through quantum optimization algorithms.\nRecently, PI-GNN, a generic framework, has been proposed to address CO problems\nover graphs based on Graph Neural Network (GNN) architecture. They introduced a\ngeneric QUBO-formulated Hamiltonian-inspired loss function that was directly\noptimized using GNN. PI-GNN is highly scalable but there lies a noticeable\ndecrease in the number of satisfied constraints when compared to\nproblem-specific algorithms and becomes more pronounced with increased graph\ndensities. Here, We identify a behavioral pattern related to it and devise\nstrategies to improve its performance. Another group of literature uses\nReinforcement learning (RL) to solve the aforementioned NP-hard problems using\nproblem-specific reward functions. In this work, we also focus on creating a\nbridge between the RL-based solutions and the QUBO-formulated Hamiltonian. We\nformulate and empirically evaluate the compatibility of the QUBO-formulated\nHamiltonian as the generic reward function in the RL-based paradigm in the form\nof rewards. Furthermore, we also introduce a novel Monty Carlo Tree\nSearch-based strategy with GNN where we apply a guided search through manual\nperturbation of node labels during training. We empirically evaluated our\nmethods and observed up to 44% improvement in the number of constraint\nviolations compared to the PI-GNN.\n","authors":["Redwan Ahmed Rizvee","Raheeb Hasan","Md. Mosaddek Khan"],"pdf_url":"https://arxiv.org/pdf/2311.16277v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08379v3","updated":"2023-11-27T19:30:35Z","published":"2023-11-14T18:42:40Z","title":"Scheming AIs: Will AIs fake alignment during training in order to get\n  power?","summary":"  This report examines whether advanced AIs that perform well in training will\nbe doing so in order to gain power later -- a behavior I call \"scheming\" (also\nsometimes called \"deceptive alignment\"). I conclude that scheming is a\ndisturbingly plausible outcome of using baseline machine learning methods to\ntrain goal-directed AIs sophisticated enough to scheme (my subjective\nprobability on such an outcome, given these conditions, is roughly 25%). In\nparticular: if performing well in training is a good strategy for gaining power\n(as I think it might well be), then a very wide variety of goals would motivate\nscheming -- and hence, good training performance. This makes it plausible that\ntraining might either land on such a goal naturally and then reinforce it, or\nactively push a model's motivations towards such a goal as an easy way of\nimproving performance. What's more, because schemers pretend to be aligned on\ntests designed to reveal their motivations, it may be quite difficult to tell\nwhether this has occurred. However, I also think there are reasons for comfort.\nIn particular: scheming may not actually be such a good strategy for gaining\npower; various selection pressures in training might work against schemer-like\ngoals (for example, relative to non-schemers, schemers need to engage in extra\ninstrumental reasoning, which might harm their training performance); and we\nmay be able to increase such pressures intentionally. The report discusses\nthese and a wide variety of other considerations in detail, and it suggests an\narray of empirical research directions for probing the topic further.\n","authors":["Joe Carlsmith"],"pdf_url":"https://arxiv.org/pdf/2311.08379v3.pdf","comment":"127 pages, 8 figures. Revised again to correct typos"},{"id":"http://arxiv.org/abs/2311.06965v2","updated":"2023-11-27T19:22:27Z","published":"2023-11-12T21:08:43Z","title":"Anchor Data Augmentation","summary":"  We propose a novel algorithm for data augmentation in nonlinear\nover-parametrized regression. Our data augmentation algorithm borrows from the\nliterature on causality and extends the recently proposed Anchor regression\n(AR) method for data augmentation, which is in contrast to the current\nstate-of-the-art domain-agnostic solutions that rely on the Mixup literature.\nOur Anchor Data Augmentation (ADA) uses several replicas of the modified\nsamples in AR to provide more training examples, leading to more robust\nregression predictions. We apply ADA to linear and nonlinear regression\nproblems using neural networks. ADA is competitive with state-of-the-art\nC-Mixup solutions.\n","authors":["Nora Schneider","Shirin Goshtasbpour","Fernando Perez-Cruz"],"pdf_url":"https://arxiv.org/pdf/2311.06965v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16214v1","updated":"2023-11-27T18:26:16Z","published":"2023-11-27T18:26:16Z","title":"DGR: Tackling Drifted and Correlated Noise in Quantum Error Correction\n  via Decoding Graph Re-weighting","summary":"  Quantum hardware suffers from high error rates and noise, which makes\ndirectly running applications on them ineffective. Quantum Error Correction\n(QEC) is a critical technique towards fault tolerance which encodes the quantum\ninformation distributively in multiple data qubits and uses syndrome qubits to\ncheck parity. Minimum-Weight-Perfect-Matching (MWPM) is a popular QEC decoder\nthat takes the syndromes as input and finds the matchings between syndromes\nthat infer the errors. However, there are two paramount challenges for MWPM\ndecoders. First, as noise in real quantum systems can drift over time, there is\na potential misalignment with the decoding graph's initial weights, leading to\na severe performance degradation in the logical error rates. Second, while the\nMWPM decoder addresses independent errors, it falls short when encountering\ncorrelated errors typical on real hardware, such as those in the 2Q\ndepolarizing channel.\n  We propose DGR, an efficient decoding graph edge re-weighting strategy with\nno quantum overhead. It leverages the insight that the statistics of matchings\nacross decoding iterations offer rich information about errors on real quantum\nhardware. By counting the occurrences of edges and edge pairs in decoded\nmatchings, we can statistically estimate the up-to-date probabilities of each\nedge and the correlations between them. The reweighting process includes two\nvital steps: alignment re-weighting and correlation re-weighting. The former\nupdates the MWPM weights based on statistics to align with actual noise, and\nthe latter adjusts the weight considering edge correlations.\n  Extensive evaluations on surface code and honeycomb code under various\nsettings show that DGR reduces the logical error rate by 3.6x on average-case\nnoise mismatch with exceeding 5000x improvement under worst-case mismatch.\n","authors":["Hanrui Wang","Pengyu Liu","Yilian Liu","Jiaqi Gu","Jonathan Baker","Frederic T. Chong","Song Han"],"pdf_url":"https://arxiv.org/pdf/2311.16214v1.pdf","comment":"13 pages, 19 figures"},{"id":"http://arxiv.org/abs/2311.16213v1","updated":"2023-11-27T18:22:07Z","published":"2023-11-27T18:22:07Z","title":"Seeing Beyond Cancer: Multi-Institutional Validation of Object\n  Localization and 3D Semantic Segmentation using Deep Learning for Breast MRI","summary":"  The clinical management of breast cancer depends on an accurate understanding\nof the tumor and its anatomical context to adjacent tissues and landmark\nstructures. This context may be provided by semantic segmentation methods;\nhowever, previous works have been largely limited to a singular focus on the\ntumor alone and rarely other tissue types. In contrast, we present a method\nthat exploits tissue-tissue interactions to accurately segment every major\ntissue type in the breast including: chest wall, skin, adipose tissue,\nfibroglandular tissue, vasculature and tumor via standard-of-care Dynamic\nContrast Enhanced MRI. Comparing our method to prior state-of-the-art, we\nachieved a superior Dice score on tumor segmentation while maintaining\ncompetitive performance on other studied tissues across multiple institutions.\nBriefly, our method proceeds by localizing the tumor using 2D object detectors,\nthen segmenting the tumor and surrounding tissues independently using two 3D\nU-nets, and finally integrating these results while mitigating false positives\nby checking for anatomically plausible tissue-tissue contacts. The object\ndetection models were pre-trained on ImageNet and COCO, and operated on MIP\n(maximum intensity projection) images in the axial and sagittal planes,\nestablishing a 3D tumor bounding box. By integrating multiple relevant\nperi-tumoral tissues, our work enables clinical applications in breast cancer\nstaging, prognosis and surgical planning.\n","authors":["Arda Pekis","Vignesh Kannan","Evandros Kaklamanos","Anu Antony","Snehal Patel","Tyler Earnest"],"pdf_url":"https://arxiv.org/pdf/2311.16213v1.pdf","comment":"9 pages, 2 figures, to appear in SPIE: Medical Imaging 2024"}],"Multimedia":[{"id":"http://arxiv.org/abs/2311.13770v2","updated":"2023-11-27T11:09:47Z","published":"2023-11-23T01:53:02Z","title":"Archiving Body Movements: Collective Generation of Chinese Calligraphy","summary":"  As a communication channel, body movements have been widely explored in\nbehavioral studies and kinesics. Performing and visual arts share the same\ninterests but focus on documenting and representing human body movements, such\nas for dance notation and visual work creation. This paper investigates body\nmovements in oriental calligraphy and how to apply calligraphy principles to\nstimulate and archive body movements. Through an artwork (Wushu), the authors\nexperiment with an interactive and generative approach to engage the audience's\nbodily participation and archive the body movements as a compendium of\ngenerated calligraphy. The audience assumes the role of both writers and\nreaders; creating (\"writing\") and appreciating (\"reading\") the generated\ncalligraphy becomes a cyclical process within this infinite \"Book,\" which can\nmotivate further attention and discussions concerning Chinese characters and\ncalligraphy.\n","authors":["Aven Le Zhou","Jiayi Ye","Tianchen Liu","Kang Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.13770v2.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.12454v2","updated":"2023-11-27T12:26:32Z","published":"2023-11-21T09:07:11Z","title":"HierSpeech++: Bridging the Gap between Semantic and Acoustic\n  Representation of Speech by Hierarchical Variational Inference for Zero-shot\n  Speech Synthesis","summary":"  Large language models (LLM)-based speech synthesis has been widely adopted in\nzero-shot speech synthesis. However, they require a large-scale data and\npossess the same limitations as previous autoregressive speech models,\nincluding slow inference speed and lack of robustness. This paper proposes\nHierSpeech++, a fast and strong zero-shot speech synthesizer for text-to-speech\n(TTS) and voice conversion (VC). We verified that hierarchical speech synthesis\nframeworks could significantly improve the robustness and expressiveness of the\nsynthetic speech. Furthermore, we significantly improve the naturalness and\nspeaker similarity of synthetic speech even in zero-shot speech synthesis\nscenarios. For text-to-speech, we adopt the text-to-vec framework, which\ngenerates a self-supervised speech representation and an F0 representation\nbased on text representations and prosody prompts. Then, HierSpeech++ generates\nspeech from the generated vector, F0, and voice prompt. We further introduce a\nhigh-efficient speech super-resolution framework from 16 kHz to 48 kHz. The\nexperimental results demonstrated that the hierarchical variational autoencoder\ncould be a strong zero-shot speech synthesizer given that it outperforms\nLLM-based and diffusion-based models. Moreover, we achieved the first\nhuman-level quality zero-shot speech synthesis. Audio samples and source code\nare available at https://github.com/sh-lee-prml/HierSpeechpp.\n","authors":["Sang-Hoon Lee","Ha-Yeong Choi","Seung-Bin Kim","Seong-Whan Lee"],"pdf_url":"https://arxiv.org/pdf/2311.12454v2.pdf","comment":"16 pages, 9 figures, 12 tables"},{"id":"http://arxiv.org/abs/2304.02970v4","updated":"2023-11-27T13:11:20Z","published":"2023-04-06T09:54:06Z","title":"A Closer Look at Audio-Visual Segmentation","summary":"  Audio-visual segmentation (AVS) is a complex task that involves accurately\nsegmenting the corresponding sounding object based on audio-visual queries.\nSuccessful audio-visual learning requires two essential components: 1) an\nunbiased dataset with high-quality pixel-level multi-class labels, and 2) a\nmodel capable of effectively linking audio information with its corresponding\nvisual object. However, these two requirements are only partially addressed by\ncurrent methods, with training sets containing biased audio-visual data, and\nmodels that generalise poorly beyond this biased training set. In this work, we\npropose a new strategy to build cost-effective and relatively unbiased\naudio-visual semantic segmentation benchmarks. Our strategy, called Visual\nPost-production (VPO), explores the observation that it is not necessary to\nhave explicit audio-visual pairs extracted from single video sources to build\nsuch benchmarks. We also refine the previously proposed AVSBench to transform\nit into the audio-visual semantic segmentation benchmark AVSBench-Single+.\nFurthermore, this paper introduces a new pixel-wise audio-visual contrastive\nlearning method to enable a better generalisation of the model beyond the\ntraining set. We verify the validity of the VPO strategy by showing that\nstate-of-the-art (SOTA) models trained with datasets built by matching audio\nand visual data from different sources or with datasets containing audio and\nvisual data from the same video source produce almost the same accuracy. Then,\nusing the proposed VPO benchmarks and AVSBench-Single+, we show that our method\nproduces more accurate audio-visual semantic segmentation than SOTA models.\nCode and dataset will be available.\n","authors":["Yuanhong Chen","Yuyuan Liu","Hu Wang","Fengbei Liu","Chong Wang","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2304.02970v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.07983v2","updated":"2023-11-27T11:54:56Z","published":"2023-09-14T18:40:28Z","title":"SLMIA-SR: Speaker-Level Membership Inference Attacks against Speaker\n  Recognition Systems","summary":"  Membership inference attacks allow adversaries to determine whether a\nparticular example was contained in the model's training dataset. While\nprevious works have confirmed the feasibility of such attacks in various\napplications, none has focused on speaker recognition (SR), a promising\nvoice-based biometric recognition technique. In this work, we propose SLMIA-SR,\nthe first membership inference attack tailored to SR. In contrast to\nconventional example-level attack, our attack features speaker-level membership\ninference, i.e., determining if any voices of a given speaker, either the same\nas or different from the given inference voices, have been involved in the\ntraining of a model. It is particularly useful and practical since the training\nand inference voices are usually distinct, and it is also meaningful\nconsidering the open-set nature of SR, namely, the recognition speakers were\noften not present in the training data. We utilize intra-similarity and\ninter-dissimilarity, two training objectives of SR, to characterize the\ndifferences between training and non-training speakers and quantify them with\ntwo groups of features driven by carefully-established feature engineering to\nmount the attack. To improve the generalizability of our attack, we propose a\nnovel mixing ratio training strategy to train attack models. To enhance the\nattack performance, we introduce voice chunk splitting to cope with the limited\nnumber of inference voices and propose to train attack models dependent on the\nnumber of inference voices. Our attack is versatile and can work in both\nwhite-box and black-box scenarios. Additionally, we propose two novel\ntechniques to reduce the number of black-box queries while maintaining the\nattack performance. Extensive experiments demonstrate the effectiveness of\nSLMIA-SR.\n","authors":["Guangke Chen","Yedi Zhang","Fu Song"],"pdf_url":"https://arxiv.org/pdf/2309.07983v2.pdf","comment":"In Proceedings of the 31st Network and Distributed System Security\n  (NDSS) Symposium, 2024"},{"id":"http://arxiv.org/abs/2311.15581v1","updated":"2023-11-27T07:19:10Z","published":"2023-11-27T07:19:10Z","title":"Real Time GAZED: Online Shot Selection and Editing of Virtual Cameras\n  from Wide-Angle Monocular Video Recordings","summary":"  Eliminating time-consuming post-production processes and delivering\nhigh-quality videos in today's fast-paced digital landscape are the key\nadvantages of real-time approaches. To address these needs, we present Real\nTime GAZED: a real-time adaptation of the GAZED framework integrated with\nCineFilter, a novel real-time camera trajectory stabilization approach. It\nenables users to create professionally edited videos in real-time. Comparative\nevaluations against baseline methods, including the non-real-time GAZED,\ndemonstrate that Real Time GAZED achieves similar editing results, ensuring\nhigh-quality video output. Furthermore, a user study confirms the aesthetic\nquality of the video edits produced by the Real Time GAZED approach. With these\nadvancements in real-time camera trajectory optimization and video editing\npresented, the demand for immediate and dynamic content creation in industries\nsuch as live broadcasting, sports coverage, news reporting, and social media\ncontent creation can be met more efficiently.\n","authors":["Sudheer Achary","Rohit Girmaji","Adhiraj Anil Deshmukh","Vineet Gandhi"],"pdf_url":"https://arxiv.org/pdf/2311.15581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15540v1","updated":"2023-11-27T05:10:15Z","published":"2023-11-27T05:10:15Z","title":"EAFP-Med: An Efficient Adaptive Feature Processing Module Based on\n  Prompts for Medical Image Detection","summary":"  In the face of rapid advances in medical imaging, cross-domain adaptive\nmedical image detection is challenging due to the differences in lesion\nrepresentations across various medical imaging technologies. To address this\nissue, we draw inspiration from large language models to propose EAFP-Med, an\nefficient adaptive feature processing module based on prompts for medical image\ndetection. EAFP-Med can efficiently extract lesion features of different scales\nfrom a diverse range of medical images based on prompts while being flexible\nand not limited by specific imaging techniques. Furthermore, it serves as a\nfeature preprocessing module that can be connected to any model front-end to\nenhance the lesion features in input images. Moreover, we propose a novel\nadaptive disease detection model named EAFP-Med ST, which utilizes the Swin\nTransformer V2 - Tiny (SwinV2-T) as its backbone and connects it to EAFP-Med.\nWe have compared our method to nine state-of-the-art methods. Experimental\nresults demonstrate that EAFP-Med ST achieves the best performance on all three\ndatasets (chest X-ray images, cranial magnetic resonance imaging images, and\nskin images). EAFP-Med can efficiently extract lesion features from various\nmedical images based on prompts, enhancing the model's performance. This holds\nsignificant potential for improving medical image analysis and diagnosis.\n","authors":["Xiang Li","Long Lan","Husam Lahza","Shaowu Yang","Shuihua Wang","Wenjing Yang","Hengzhu Liu","Yudong Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.15540v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15480v1","updated":"2023-11-27T01:44:02Z","published":"2023-11-27T01:44:02Z","title":"Automatic Time Signature Determination for New Scores Using Lyrics for\n  Latent Rhythmic Structure","summary":"  There has recently been a sharp increase in interest in Artificial\nIntelligence-Generated Content (AIGC). Despite this, musical components such as\ntime signatures have not been studied sufficiently to form an algorithmic\ndetermination approach for new compositions, especially lyrical songs. This is\nlikely because of the neglect of musical details, which is critical for\nconstructing a robust framework. Specifically, time signatures establish the\nfundamental rhythmic structure for almost all aspects of a song, including the\nphrases and notes. In this paper, we propose a novel approach that only uses\nlyrics as input to automatically generate a fitting time signature for lyrical\nsongs and uncover the latent rhythmic structure utilizing explainable machine\nlearning models. In particular, we devise multiple methods that are associated\nwith discovering lyrical patterns and creating new features that simultaneously\ncontain lyrical, rhythmic, and statistical information. In this approach, the\nbest of our experimental results reveal a 97.6% F1 score and a 0.996 Area Under\nthe Curve (AUC) of the Receiver Operating Characteristic (ROC) score. In\nconclusion, our research directly generates time signatures from lyrics\nautomatically for new scores utilizing machine learning, which is an innovative\nidea that approaches an understudied component of musicology and therefore\ncontributes significantly to the future of Artificial Intelligence (AI) music\ngeneration.\n","authors":["Callie C. Liao","Duoduo Liao","Jesse Guessford"],"pdf_url":"https://arxiv.org/pdf/2311.15480v1.pdf","comment":"Submitted to IEEE Big Data 2023 Conference"},{"id":"http://arxiv.org/abs/2311.16254v1","updated":"2023-11-27T19:02:17Z","published":"2023-11-27T19:02:17Z","title":"Removing NSFW Concepts from Vision-and-Language Models for Text-to-Image\n  Retrieval and Generation","summary":"  Vision-and-Language models such as CLIP have demonstrated remarkable\neffectiveness across a wide range of tasks. However, these models are typically\ntrained on web-scale data, which can introduce inappropriate content and lead\nto the development of unsafe and biased behavior. This, in turn, hampers their\napplicability in sensitive and trustworthy contexts and could raise significant\nconcern in their adoption. To overcome these limitations, we introduce a\nmethodology to make Vision-and-Language models safer by removing their\nsensitivity to not-safe-for-work concepts. We show how this can be done by\ndistilling from a large language model which converts between safe and unsafe\nsentences and which is fine-tuned starting from just 100 manually-curated\npairs. We conduct extensive experiments on the resulting embedding space for\nboth retrieval and text-to-image generation, where we show that our model can\nalso be properly employed with pre-trained image generators. Our source code\nand trained models are available at: https://github.com/aimagelab/safe-clip.\n","authors":["Samuele Poppi","Tobia Poppi","Federico Cocchi","Marcella Cornia","Lorenzo Baraldi","Rita Cucchiara"],"pdf_url":"https://arxiv.org/pdf/2311.16254v1.pdf","comment":null}]},"2023-11-25T00:00:00Z":{"Multimedia":[{"id":"http://arxiv.org/abs/2311.08172v2","updated":"2023-11-25T07:59:48Z","published":"2023-11-14T14:02:32Z","title":"Vision-Language Instruction Tuning: A Review and Analysis","summary":"  Instruction tuning is a crucial supervised training phase in Large Language\nModels (LLMs), aiming to enhance the LLM's ability to generalize instruction\nexecution and adapt to user preferences. With the increasing integration of\nmulti-modal data into LLMs, there is growing interest in Vision-Language\nInstruction Tuning (VLIT), which presents more complex characteristics compared\nto pure text instruction tuning. In this paper, we systematically review the\nlatest VLIT settings and corresponding datasets in multi-modal LLMs and provide\ninsights into the intrinsic motivations behind their design. For the first\ntime, we offer a detailed multi-perspective categorization for existing VLIT\ndatasets and identify the characteristics that high-quality VLIT data should\npossess. By incorporating these characteristics as guiding principles into the\nexisting VLIT data construction process, we conduct extensive experiments and\nverify their positive impact on the performance of tuned multi-modal LLMs.\nFurthermore, we discuss the current challenges and future research directions\nof VLIT, providing insights for the continuous development of this field. The\ncode and dataset related to this paper have been open-sourced at\nhttps://github.com/palchenli/VL-Instruction-Tuning.\n","authors":["Chen Li","Yixiao Ge","Dian Li","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2311.08172v2.pdf","comment":"34 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.15080v1","updated":"2023-11-25T17:18:35Z","published":"2023-11-25T17:18:35Z","title":"Weakly-Supervised Audio-Visual Segmentation","summary":"  Audio-visual segmentation is a challenging task that aims to predict\npixel-level masks for sound sources in a video. Previous work applied a\ncomprehensive manually designed architecture with countless pixel-wise accurate\nmasks as supervision. However, these pixel-level masks are expensive and not\navailable in all cases. In this work, we aim to simplify the supervision as the\ninstance-level annotation, i.e., weakly-supervised audio-visual segmentation.\nWe present a novel Weakly-Supervised Audio-Visual Segmentation framework,\nnamely WS-AVS, that can learn multi-scale audio-visual alignment with\nmulti-scale multiple-instance contrastive learning for audio-visual\nsegmentation. Extensive experiments on AVSBench demonstrate the effectiveness\nof our WS-AVS in the weakly-supervised audio-visual segmentation of\nsingle-source and multi-source scenarios.\n","authors":["Shentong Mo","Bhiksha Raj"],"pdf_url":"https://arxiv.org/pdf/2311.15080v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14977v1","updated":"2023-11-25T09:38:24Z","published":"2023-11-25T09:38:24Z","title":"Incorporating granularity bias as the margin into contrastive loss for\n  video captioning","summary":"  Video captioning models easily suffer from long-tail distribution of phrases,\nwhich makes captioning models prone to generate vague sentences instead of\naccurate ones. However, existing debiasing strategies tend to export external\nknowledge to build dependency trees of words or refine frequency distribution\nby complex losses and extra input features, which lack interpretability and are\nhard to train. To mitigate the impact of granularity bias on the model, we\nintroduced a statistical-based bias extractor. This extractor quantifies the\ninformation content within sentences and videos, providing an estimate of the\nlikelihood that a video-sentence pair is affected by granularity bias.\nFurthermore, with the growing trend of integrating contrastive learning methods\ninto video captioning tasks, we use a bidirectional triplet loss to get more\nnegative samples in a batch. Subsequently, we incorporate the margin score into\nthe contrastive learning loss, establishing distinct training objectives for\nhead and tail sentences. This approach facilitates the model's training\neffectiveness on tail samples. Our simple yet effective loss, incorporating\nGranularity bias, is referred to as the Margin-Contrastive Loss (GMC Loss). The\nproposed model demonstrates state-of-the-art performance on MSRVTT with a CIDEr\nof 57.17, and MSVD, where CIDEr reaches up to 138.68.\n","authors":["Jiayang Gu","Fengming Yao"],"pdf_url":"https://arxiv.org/pdf/2311.14977v1.pdf","comment":"6 pages, 2 figures"}],"Computation and Language":[{"id":"http://arxiv.org/abs/2311.15131v1","updated":"2023-11-25T22:41:23Z","published":"2023-11-25T22:41:23Z","title":"Localizing Lying in Llama: Understanding Instructed Dishonesty on\n  True-False Questions Through Prompting, Probing, and Patching","summary":"  Large language models (LLMs) demonstrate significant knowledge through their\noutputs, though it is often unclear whether false outputs are due to a lack of\nknowledge or dishonesty. In this paper, we investigate instructed dishonesty,\nwherein we explicitly prompt LLaMA-2-70b-chat to lie. We perform prompt\nengineering to find which prompts best induce lying behavior, and then use\nmechanistic interpretability approaches to localize where in the network this\nbehavior occurs. Using linear probing and activation patching, we localize five\nlayers that appear especially important for lying. We then find just 46\nattention heads within these layers that enable us to causally intervene such\nthat the lying model instead answers honestly. We show that these interventions\nwork robustly across many prompts and dataset splits. Overall, our work\ncontributes a greater understanding of dishonesty in LLMs so that we may hope\nto prevent it.\n","authors":["James Campbell","Richard Ren","Phillip Guo"],"pdf_url":"https://arxiv.org/pdf/2311.15131v1.pdf","comment":"14 pages, 12 figures"},{"id":"http://arxiv.org/abs/2303.15445v3","updated":"2023-11-25T22:07:55Z","published":"2023-03-27T17:59:55Z","title":"IRFL: Image Recognition of Figurative Language","summary":"  Figures of speech such as metaphors, similes, and idioms are integral parts\nof human communication. They are ubiquitous in many forms of discourse,\nallowing people to convey complex, abstract ideas and evoke emotion. As\nfigurative forms are often conveyed through multiple modalities (e.g., both\ntext and images), understanding multimodal figurative language is an important\nAI challenge, weaving together profound vision, language, commonsense and\ncultural knowledge. In this work, we develop the Image Recognition of\nFigurative Language (IRFL) dataset. We leverage human annotation and an\nautomatic pipeline we created to generate a multimodal dataset, and introduce\ntwo novel tasks as a benchmark for multimodal figurative language\nunderstanding. We experimented with state-of-the-art vision and language models\nand found that the best (22%) performed substantially worse than humans (97%).\nWe release our dataset, benchmark, and code, in hopes of driving the\ndevelopment of models that can better understand figurative language.\n","authors":["Ron Yosef","Yonatan Bitton","Dafna Shahaf"],"pdf_url":"https://arxiv.org/pdf/2303.15445v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.04568v2","updated":"2023-11-25T19:52:13Z","published":"2022-08-09T07:15:20Z","title":"The Impact of Data Corruption on Named Entity Recognition for\n  Low-resourced Languages","summary":"  Data availability and quality are major challenges in natural language\nprocessing for low-resourced languages. In particular, there is significantly\nless data available than for higher-resourced languages. This data is also\noften of low quality, rife with errors, invalid text or incorrect annotations.\nMany prior works focus on dealing with these problems, either by generating\nsynthetic data, or filtering out low-quality parts of datasets. We instead\ninvestigate these factors more deeply, by systematically measuring the effect\nof data quantity and quality on the performance of pre-trained language models\nin a low-resourced setting. Our results show that having fewer\ncompletely-labelled sentences is significantly better than having more\nsentences with missing labels; and that models can perform remarkably well with\nonly 10% of the training data. Importantly, these results are consistent across\nten low-resource languages, English, and four pre-trained models.\n","authors":["Manuel Fokam","Michael Beukman"],"pdf_url":"https://arxiv.org/pdf/2208.04568v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15110v1","updated":"2023-11-25T19:50:41Z","published":"2023-11-25T19:50:41Z","title":"Relevance feedback strategies for recall-oriented neural information\n  retrieval","summary":"  In a number of information retrieval applications (e.g., patent search,\nliterature review, due diligence, etc.), preventing false negatives is more\nimportant than preventing false positives. However, approaches designed to\nreduce review effort (like \"technology assisted review\") can create false\nnegatives, since they are often based on active learning systems that exclude\ndocuments automatically based on user feedback. Therefore, this research\nproposes a more recall-oriented approach to reducing review effort. More\nspecifically, through iteratively re-ranking the relevance rankings based on\nuser feedback, which is also referred to as relevance feedback. In our proposed\nmethod, the relevance rankings are produced by a BERT-based dense-vector search\nand the relevance feedback is based on cumulatively summing the queried and\nselected embeddings. Our results show that this method can reduce review effort\nbetween 17.85% and 59.04%, compared to a baseline approach (of no feedback),\ngiven a fixed recall target\n","authors":["Timo Kats","Peter van der Putten","Jan Scholtes"],"pdf_url":"https://arxiv.org/pdf/2311.15110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15106v1","updated":"2023-11-25T19:35:53Z","published":"2023-11-25T19:35:53Z","title":"Solving the Right Problem is Key for Translational NLP: A Case Study in\n  UMLS Vocabulary Insertion","summary":"  As the immense opportunities enabled by large language models become more\napparent, NLP systems will be increasingly expected to excel in real-world\nsettings. However, in many instances, powerful models alone will not yield\ntranslational NLP solutions, especially if the formulated problem is not well\naligned with the real-world task. In this work, we study the case of UMLS\nvocabulary insertion, an important real-world task in which hundreds of\nthousands of new terms, referred to as atoms, are added to the UMLS, one of the\nmost comprehensive open-source biomedical knowledge bases. Previous work aimed\nto develop an automated NLP system to make this time-consuming, costly, and\nerror-prone task more efficient. Nevertheless, practical progress in this\ndirection has been difficult to achieve due to a problem formulation and\nevaluation gap between research output and the real-world task. In order to\naddress this gap, we introduce a new formulation for UMLS vocabulary insertion\nwhich mirrors the real-world task, datasets which faithfully represent it and\nseveral strong baselines we developed through re-purposing existing solutions.\nAdditionally, we propose an effective rule-enhanced biomedical language model\nwhich enables important new model behavior, outperforms all strong baselines\nand provides measurable qualitative improvements to editors who carry out the\nUVI task. We hope this case study provides insight into the considerable\nimportance of problem formulation for the success of translational NLP\nsolutions.\n","authors":["Bernal Jimenez Gutierrez","Yuqing Mao","Vinh Nguyen","Kin Wah Fung","Yu Su","Olivier Bodenreider"],"pdf_url":"https://arxiv.org/pdf/2311.15106v1.pdf","comment":"EMNLP 2023 Findings; Code is available at\n  https://github.com/OSU-NLP-Group/UMLS-Vocabulary-Insertion"},{"id":"http://arxiv.org/abs/2310.19736v3","updated":"2023-11-25T17:35:12Z","published":"2023-10-30T17:00:52Z","title":"Evaluating Large Language Models: A Comprehensive Survey","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities across\na broad spectrum of tasks. They have attracted significant attention and been\ndeployed in numerous downstream applications. Nevertheless, akin to a\ndouble-edged sword, LLMs also present potential risks. They could suffer from\nprivate data leaks or yield inappropriate, harmful, or misleading content.\nAdditionally, the rapid progress of LLMs raises concerns about the potential\nemergence of superintelligent systems without adequate safeguards. To\neffectively capitalize on LLM capacities as well as ensure their safe and\nbeneficial development, it is critical to conduct a rigorous and comprehensive\nevaluation of LLMs.\n  This survey endeavors to offer a panoramic perspective on the evaluation of\nLLMs. We categorize the evaluation of LLMs into three major groups: knowledge\nand capability evaluation, alignment evaluation and safety evaluation. In\naddition to the comprehensive review on the evaluation methodologies and\nbenchmarks on these three aspects, we collate a compendium of evaluations\npertaining to LLMs' performance in specialized domains, and discuss the\nconstruction of comprehensive evaluation platforms that cover LLM evaluations\non capabilities, alignment, safety, and applicability.\n  We hope that this comprehensive overview will stimulate further research\ninterests in the evaluation of LLMs, with the ultimate goal of making\nevaluation serve as a cornerstone in guiding the responsible development of\nLLMs. We envision that this will channel their evolution into a direction that\nmaximizes societal benefit while minimizing potential risks. A curated list of\nrelated papers has been publicly available at\nhttps://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers.\n","authors":["Zishan Guo","Renren Jin","Chuang Liu","Yufei Huang","Dan Shi"," Supryadi","Linhao Yu","Yan Liu","Jiaxuan Li","Bojian Xiong","Deyi Xiong"],"pdf_url":"https://arxiv.org/pdf/2310.19736v3.pdf","comment":"111 pages"},{"id":"http://arxiv.org/abs/2305.07637v3","updated":"2023-11-25T17:19:36Z","published":"2023-05-12T17:46:06Z","title":"Text2Cohort: Facilitating Intuitive Access to Biomedical Data with\n  Natural Language Cohort Discovery","summary":"  The Imaging Data Commons (IDC) is a cloud-based database that provides\nresearchers with open access to cancer imaging data, with the goal of\nfacilitating collaboration. However, cohort discovery within the IDC database\nhas a significant technical learning curve. Recently, large language models\n(LLM) have demonstrated exceptional utility for natural language processing\ntasks. We developed Text2Cohort, a LLM-powered toolkit to facilitate\nuser-friendly natural language cohort discovery in the IDC. Our method\ntranslates user input into IDC queries using grounding techniques and returns\nthe query's response. We evaluate Text2Cohort on 50 natural language inputs,\nfrom information extraction to cohort discovery. Our toolkit successfully\ngenerated responses with an 88% accuracy and 0.94 F1 score. We demonstrate that\nText2Cohort can enable researchers to discover and curate cohorts on IDC with\nhigh levels of accuracy using natural language in a more intuitive and\nuser-friendly way.\n","authors":["Pranav Kulkarni","Adway Kanhere","Paul H. Yi","Vishwa S. Parekh"],"pdf_url":"https://arxiv.org/pdf/2305.07637v3.pdf","comment":"5 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2311.15077v1","updated":"2023-11-25T17:05:21Z","published":"2023-11-25T17:05:21Z","title":"Multilingual self-supervised speech representations improve the speech\n  recognition of low-resource African languages with codeswitching","summary":"  While many speakers of low-resource languages regularly code-switch between\ntheir languages and other regional languages or English, datasets of\ncodeswitched speech are too small to train bespoke acoustic models from scratch\nor do language model rescoring. Here we propose finetuning self-supervised\nspeech representations such as wav2vec 2.0 XLSR to recognize code-switched\ndata. We find that finetuning self-supervised multilingual representations and\naugmenting them with n-gram language models trained from transcripts reduces\nabsolute word error rates by up to 20% compared to baselines of hybrid models\ntrained from scratch on code-switched data. Our findings suggest that in\ncircumstances with limited training data finetuning self-supervised\nrepresentations is a better performing and viable solution.\n","authors":["Tolúlopé Ògúnrèmí","Christopher D. Manning","Dan Jurafsky"],"pdf_url":"https://arxiv.org/pdf/2311.15077v1.pdf","comment":"5 pages, 1 figure. Computational Approaches to Linguistic\n  Code-Switching, CALCS 2023 (co-located with EMNLP 2023)"},{"id":"http://arxiv.org/abs/2311.15055v1","updated":"2023-11-25T15:27:10Z","published":"2023-11-25T15:27:10Z","title":"Automatically Finding and Categorizing Replication Studies","summary":"  In many fields of experimental science, papers that failed to replicate\ncontinue to be cited as a result of the poor discoverability of replication\nstudies. As a first step to creating a system that automatically finds\nreplication studies for a given paper, 334 replication studies and 344\nreplicated studies were collected. Replication studies could be identified in\nthe dataset based on text content at a higher rate than chance (AUROC = 0.886).\n  Additionally, successful replication studies could be distinguished from\nfailed replication studies at a higher rate than chance (AUROC = 0.664).\n","authors":["Bob de Ruiter"],"pdf_url":"https://arxiv.org/pdf/2311.15055v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15054v1","updated":"2023-11-25T15:23:46Z","published":"2023-11-25T15:23:46Z","title":"Detection of developmental language disorder in Cypriot Greek children\n  using a machine learning neural network algorithm","summary":"  Children with developmental language disorder (DLD) encounter difficulties in\nacquiring various language structures. Early identification and intervention\nare crucial to prevent negative long-term outcomes impacting the academic,\nsocial, and emotional development of children. The study aims to develop an\nautomated method for the identification of DLD using artificial intelligence,\nspecifically a neural network machine learning algorithm. This protocol is\napplied for the first time in Cypriot Greek children, which is generally\nconsidered underresearched in the context of DLD. The neural network model was\ntrained using perceptual and production data elicited from children with DLD\nand healthy controls. The k-fold technique was used to crossvalidate the\nalgorithm. The performance of the model was evaluated using metrics such as\naccuracy, precision, recall, F1 score, and ROC/AUC curve to assess its ability\nto make accurate predictions on a set of unseen data. The results demonstrated\nhigh classification values for all metrics (between 0.92 and 0.98), indicating\nthe high accuracy of the neural model in classifying children with DLD.\nAdditionally, the variable importance analysis revealed that the language\nproduction skills of children had a more significant impact on the performance\nof the model compared to perception skills. Neural networks represent powerful\ntools for detecting DLD, providing early and quick assessments of the disorder,\nand having the potential to improve clinical outcomes.\n","authors":["Georgios P. Georgiou","Elena Theodorou"],"pdf_url":"https://arxiv.org/pdf/2311.15054v1.pdf","comment":"13 pages, 3 figures, journal article"},{"id":"http://arxiv.org/abs/2311.15032v1","updated":"2023-11-25T13:58:58Z","published":"2023-11-25T13:58:58Z","title":"nlpBDpatriots at BLP-2023 Task 2: A Transfer Learning Approach to Bangla\n  Sentiment Analysis","summary":"  In this paper, we discuss the nlpBDpatriots entry to the shared task on\nSentiment Analysis of Bangla Social Media Posts organized at the first workshop\non Bangla Language Processing (BLP) co-located with EMNLP. The main objective\nof this task is to identify the polarity of social media content using a Bangla\ndataset annotated with positive, neutral, and negative labels provided by the\nshared task organizers. Our best system for this task is a transfer learning\napproach with data augmentation which achieved a micro F1 score of 0.71. Our\nbest system ranked 12th among 30 teams that participated in the competition.\n","authors":["Dhiman Goswami","Md Nishat Raihan","Sadiya Sayara Chowdhury Puspo","Marcos Zampieri"],"pdf_url":"https://arxiv.org/pdf/2311.15032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15029v1","updated":"2023-11-25T13:47:34Z","published":"2023-11-25T13:47:34Z","title":"nlpBDpatriots at BLP-2023 Task 1: A Two-Step Classification for Violence\n  Inciting Text Detection in Bangla","summary":"  In this paper, we discuss the nlpBDpatriots entry to the shared task on\nViolence Inciting Text Detection (VITD) organized as part of the first workshop\non Bangla Language Processing (BLP) co-located with EMNLP. The aim of this task\nis to identify and classify the violent threats, that provoke further unlawful\nviolent acts. Our best-performing approach for the task is two-step\nclassification using back translation and multilinguality which ranked 6th out\nof 27 teams with a macro F1 score of 0.74.\n","authors":["Md Nishat Raihan","Dhiman Goswami","Sadiya Sayara Chowdhury Puspo","Marcos Zampieri"],"pdf_url":"https://arxiv.org/pdf/2311.15029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01828v2","updated":"2023-11-25T13:35:34Z","published":"2023-10-03T06:51:48Z","title":"Trainable Noise Model as an XAI evaluation method: application on Sobol\n  for remote sensing image segmentation","summary":"  eXplainable Artificial Intelligence (XAI) has emerged as an essential\nrequirement when dealing with mission-critical applications, ensuring\ntransparency and interpretability of the employed black box AI models. The\nsignificance of XAI spans various domains, from healthcare to finance, where\nunderstanding the decision-making process of deep learning algorithms is\nessential. Most AI-based computer vision models are often black boxes; hence,\nproviding explainability of deep neural networks in image processing is crucial\nfor their wide adoption and deployment in medical image analysis, autonomous\ndriving, and remote sensing applications. Recently, several XAI methods for\nimage classification tasks have been introduced. On the contrary, image\nsegmentation has received comparatively less attention in the context of\nexplainability, although it is a fundamental task in computer vision\napplications, especially in remote sensing. Only some research proposes\ngradient-based XAI algorithms for image segmentation. This paper adapts the\nrecent gradient-free Sobol XAI method for semantic segmentation. To measure the\nperformance of the Sobol method for segmentation, we propose a quantitative XAI\nevaluation method based on a learnable noise model. The main objective of this\nmodel is to induce noise on the explanation maps, where higher induced noise\nsignifies low accuracy and vice versa. A benchmark analysis is conducted to\nevaluate and compare performance of three XAI methods, including Seg-Grad-CAM,\nSeg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation\ntechnique. This constitutes the first attempt to run and evaluate XAI methods\nusing high-resolution satellite images.\n","authors":["Hossein Shreim","Abdul Karim Gizzini","Ali J. Ghandour"],"pdf_url":"https://arxiv.org/pdf/2310.01828v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15023v1","updated":"2023-11-25T13:27:22Z","published":"2023-11-25T13:27:22Z","title":"Offensive Language Identification in Transliterated and Code-Mixed\n  Bangla","summary":"  Identifying offensive content in social media is vital for creating safe\nonline communities. Several recent studies have addressed this problem by\ncreating datasets for various languages. In this paper, we explore offensive\nlanguage identification in texts with transliterations and code-mixing,\nlinguistic phenomena common in multilingual societies, and a known challenge\nfor NLP systems. We introduce TB-OLID, a transliterated Bangla offensive\nlanguage dataset containing 5,000 manually annotated comments. We train and\nfine-tune machine learning models on TB-OLID, and we evaluate their results on\nthis dataset. Our results show that English pre-trained transformer-based\nmodels, such as fBERT and HateBERT achieve the best performance on this\ndataset.\n","authors":["Md Nishat Raihan","Umma Hani Tanmoy","Anika Binte Islam","Kai North","Tharindu Ranasinghe","Antonios Anastasopoulos","Marcos Zampieri"],"pdf_url":"https://arxiv.org/pdf/2311.15023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18387v2","updated":"2023-11-25T13:13:01Z","published":"2023-10-27T09:59:35Z","title":"OffMix-3L: A Novel Code-Mixed Dataset in Bangla-English-Hindi for\n  Offensive Language Identification","summary":"  Code-mixing is a well-studied linguistic phenomenon when two or more\nlanguages are mixed in text or speech. Several works have been conducted on\nbuilding datasets and performing downstream NLP tasks on code-mixed data.\nAlthough it is not uncommon to observe code-mixing of three or more languages,\nmost available datasets in this domain contain code-mixed data from only two\nlanguages. In this paper, we introduce OffMix-3L, a novel offensive language\nidentification dataset containing code-mixed data from three different\nlanguages. We experiment with several models on this dataset and observe that\nBanglishBERT outperforms other transformer-based models and GPT-3.5.\n","authors":["Dhiman Goswami","Md Nishat Raihan","Antara Mahmud","Antonios Anastasopoulos","Marcos Zampieri"],"pdf_url":"https://arxiv.org/pdf/2310.18387v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2310.18023"},{"id":"http://arxiv.org/abs/2311.15016v1","updated":"2023-11-25T12:47:39Z","published":"2023-11-25T12:47:39Z","title":"E-CORE: Emotion Correlation Enhanced Empathetic Dialogue Generation","summary":"  Achieving empathy is a crucial step toward humanized dialogue systems.\nCurrent approaches for empathetic dialogue generation mainly perceive an\nemotional label to generate an empathetic response conditioned on it, which\nsimply treat emotions independently, but ignore the intrinsic emotion\ncorrelation in dialogues, resulting in inaccurate emotion perception and\nunsuitable response generation. In this paper, we propose a novel emotion\ncorrelation enhanced empathetic dialogue generation framework, which\ncomprehensively realizes emotion correlation learning, utilization, and\nsupervising. Specifically, a multi-resolution emotion graph is devised to\ncapture context-based emotion interactions from different resolutions, further\nmodeling emotion correlation. Then we propose an emotion correlation enhanced\ndecoder, with a novel correlation-aware aggregation and soft/hard strategy,\nrespectively improving the emotion perception and response generation.\nExperimental results on the benchmark dataset demonstrate the superiority of\nour model in both empathetic perception and expression.\n","authors":["Fengyi Fu","Lei Zhang","Quan Wang","Zhendong Mao"],"pdf_url":"https://arxiv.org/pdf/2311.15016v1.pdf","comment":"19 pages, 6 figures"},{"id":"http://arxiv.org/abs/2308.00802v3","updated":"2023-11-25T09:58:18Z","published":"2023-08-01T19:34:18Z","title":"GRDD: A Dataset for Greek Dialectal NLP","summary":"  In this paper, we present a dataset for the computational study of a number\nof Modern Greek dialects. It consists of raw text data from four dialects of\nModern Greek, Cretan, Pontic, Northern Greek and Cypriot Greek. The dataset is\nof considerable size, albeit imbalanced, and presents the first attempt to\ncreate large scale dialectal resources of this type for Modern Greek dialects.\nWe then use the dataset to perform dialect idefntification. We experiment with\ntraditional ML algorithms, as well as simple DL architectures. The results show\nvery good performance on the task, potentially revealing that the dialects in\nquestion have distinct enough characteristics allowing even simple ML models to\nperform well on the task. Error analysis is performed for the top performing\nalgorithms showing that in a number of cases the errors are due to insufficient\ndataset cleaning.\n","authors":["Stergios Chatzikyriakidis","Chatrine Qwaider","Ilias Kolokousis","Christina Koula","Dimitris Papadakis","Efthymia Sakellariou"],"pdf_url":"https://arxiv.org/pdf/2308.00802v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14966v1","updated":"2023-11-25T08:58:07Z","published":"2023-11-25T08:58:07Z","title":"Walking a Tightrope -- Evaluating Large Language Models in High-Risk\n  Domains","summary":"  High-risk domains pose unique challenges that require language models to\nprovide accurate and safe responses. Despite the great success of large\nlanguage models (LLMs), such as ChatGPT and its variants, their performance in\nhigh-risk domains remains unclear. Our study delves into an in-depth analysis\nof the performance of instruction-tuned LLMs, focusing on factual accuracy and\nsafety adherence. To comprehensively assess the capabilities of LLMs, we\nconduct experiments on six NLP datasets including question answering and\nsummarization tasks within two high-risk domains: legal and medical. Further\nqualitative analysis highlights the existing limitations inherent in current\nLLMs when evaluating in high-risk domains. This underscores the essential\nnature of not only improving LLM capabilities but also prioritizing the\nrefinement of domain-specific metrics, and embracing a more human-centric\napproach to enhance safety and factual reliability. Our findings advance the\nfield toward the concerns of properly evaluating LLMs in high-risk domains,\naiming to steer the adaptability of LLMs in fulfilling societal obligations and\naligning with forthcoming regulations, such as the EU AI Act.\n","authors":["Chia-Chien Hung","Wiem Ben Rim","Lindsay Frost","Lars Bruckner","Carolin Lawrence"],"pdf_url":"https://arxiv.org/pdf/2311.14966v1.pdf","comment":"EMNLP 2023 Workshop on Benchmarking Generalisation in NLP (GenBench)"},{"id":"http://arxiv.org/abs/2311.14949v1","updated":"2023-11-25T07:13:06Z","published":"2023-11-25T07:13:06Z","title":"Vector-Quantized Prompt Learning for Paraphrase Generation","summary":"  Deep generative modeling of natural languages has achieved many successes,\nsuch as producing fluent sentences and translating from one language into\nanother. However, the development of generative modeling techniques for\nparaphrase generation still lags behind largely due to the challenges in\naddressing the complex conflicts between expression diversity and semantic\npreservation. This paper proposes to generate diverse and high-quality\nparaphrases by exploiting the pre-trained models with instance-dependent\nprompts. To learn generalizable prompts, we assume that the number of abstract\ntransforming patterns of paraphrase generation (governed by prompts) is finite\nand usually not large. Therefore, we present vector-quantized prompts as the\ncues to control the generation of pre-trained models. Extensive experiments\ndemonstrate that the proposed method achieves new state-of-art results on three\nbenchmark datasets, including Quora, Wikianswers, and MSCOCO. We will release\nall the code upon acceptance.\n","authors":["Haotian Luo","Yixin Liu","Peidong Liu","Xianggen Liu"],"pdf_url":"https://arxiv.org/pdf/2311.14949v1.pdf","comment":"EMNLP Findings, 2023"},{"id":"http://arxiv.org/abs/2311.14919v1","updated":"2023-11-25T03:38:14Z","published":"2023-11-25T03:38:14Z","title":"Faster Minimum Bayes Risk Decoding with Confidence-based Pruning","summary":"  Minimum Bayes risk (MBR) decoding outputs the hypothesis with the highest\nexpected utility over the model distribution for some utility function. It has\nbeen shown to improve accuracy over beam search in conditional language\ngeneration problems and especially neural machine translation, in both human\nand automatic evaluations. However, the standard sampling-based algorithm for\nMBR is substantially more computationally expensive than beam search, requiring\na large number of samples as well as a quadratic number of calls to the utility\nfunction, limiting its applicability. We describe an algorithm for MBR which\ngradually grows the number of samples used to estimate the utility while\npruning hypotheses that are unlikely to have the highest utility according to\nconfidence estimates obtained with bootstrap sampling. Our method requires\nfewer samples and drastically reduces the number of calls to the utility\nfunction compared to standard MBR while being statistically indistinguishable\nin terms of accuracy. We demonstrate the effectiveness of our approach in\nexperiments on three language pairs, using chrF++ and COMET as\nutility/evaluation metrics.\n","authors":["Julius Cheng","Andreas Vlachos"],"pdf_url":"https://arxiv.org/pdf/2311.14919v1.pdf","comment":"Updated from EMNLP 2023 version: typo fix, minor math notation\n  change, updated citation"},{"id":"http://arxiv.org/abs/2311.14901v1","updated":"2023-11-25T02:31:22Z","published":"2023-11-25T02:31:22Z","title":"Code Search Debiasing:Improve Search Results beyond Overall Ranking\n  Performance","summary":"  Code search engine is an essential tool in software development. Many code\nsearch methods have sprung up, focusing on the overall ranking performance of\ncode search. In this paper, we study code search from another perspective by\nanalyzing the bias of code search models. Biased code search engines provide\npoor user experience, even though they show promising overall performance. Due\nto different development conventions (e.g., prefer long queries or\nabbreviations), some programmers will find the engine useful, while others may\nfind it hard to get desirable search results. To mitigate biases, we develop a\ngeneral debiasing framework that employs reranking to calibrate search results.\nIt can be easily plugged into existing engines and handle new code search\nbiases discovered in the future. Experiments show that our framework can\neffectively reduce biases. Meanwhile, the overall ranking performance of code\nsearch gets improved after debiasing.\n","authors":["Sheng Zhang","Hui Li","Yanlin Wang","Zhao Wei","Yong Xiu","Juhong Wang","Rongong Ji"],"pdf_url":"https://arxiv.org/pdf/2311.14901v1.pdf","comment":"Accepted to Findings of EMNLP 2023. 11 pages"},{"id":"http://arxiv.org/abs/2310.10520v3","updated":"2023-11-25T02:09:35Z","published":"2023-10-16T15:38:02Z","title":"Semantic Parsing by Large Language Models for Intricate Updating\n  Strategies of Zero-Shot Dialogue State Tracking","summary":"  Zero-shot Dialogue State Tracking (DST) addresses the challenge of acquiring\nand annotating task-oriented dialogues, which can be time-consuming and costly.\nHowever, DST extends beyond simple slot-filling and requires effective updating\nstrategies for tracking dialogue state as conversations progress. In this\npaper, we propose ParsingDST, a new In-Context Learning (ICL) method, to\nintroduce additional intricate updating strategies in zero-shot DST. Our\napproach reformulates the DST task by leveraging powerful Large Language Models\n(LLMs) and translating the original dialogue text to JSON through semantic\nparsing as an intermediate state. We also design a novel framework that\nincludes more modules to ensure the effectiveness of updating strategies in the\ntext-to-JSON process. Experimental results demonstrate that our approach\noutperforms existing zero-shot DST methods on MultiWOZ, exhibiting significant\nimprovements in Joint Goal Accuracy (JGA) and slot accuracy compared to\nexisting ICL methods. Our code has been released.\n","authors":["Yuxiang Wu","Guanting Dong","Weiran Xu"],"pdf_url":"https://arxiv.org/pdf/2310.10520v3.pdf","comment":"Accepted to the Findings of EMNLP 2023 (Short Paper)"},{"id":"http://arxiv.org/abs/2308.10819v3","updated":"2023-11-25T00:25:36Z","published":"2023-08-17T06:21:50Z","title":"Evaluating the Instruction-Following Robustness of Large Language Models\n  to Prompt Injection","summary":"  Large Language Models (LLMs) have demonstrated exceptional proficiency in\ninstruction-following, becoming increasingly crucial across various\napplications. However, this capability brings with it the risk of prompt\ninjection attacks, where attackers inject instructions into LLMs' input to\nelicit undesirable actions or content. Understanding the robustness of LLMs\nagainst such attacks is vital for their safe implementation. In this work, we\nestablish a benchmark to evaluate the robustness of instruction-following LLMs\nagainst prompt injection attacks. Our objective is to determine the extent to\nwhich LLMs can be influenced by injected instructions and their ability to\ndifferentiate between these injected and original target instructions. Through\nextensive experiments with leading instruction-following LLMs, we uncover\nsignificant vulnerabilities in their robustness to such attacks. Our results\nindicate that some models are overly tuned to follow any embedded instructions\nin the prompt, overly focusing on the latter parts of the prompt without fully\ngrasping the entire context. By contrast, models with a better grasp of the\ncontext and instruction-following capabilities will potentially be more\nsusceptible to compromise by injected instructions. This underscores the need\nto shift the focus from merely enhancing LLMs' instruction-following\ncapabilities to improving their overall comprehension of prompts and\ndiscernment of instructions that are appropriate to follow. We hope our\nin-depth analysis offers insights into the underlying causes of these\nvulnerabilities, aiding in the development of future solutions. Code and data\nare available at\nhttps://github.com/Leezekun/instruction-following-robustness-eval\n","authors":["Zekun Li","Baolin Peng","Pengcheng He","Xifeng Yan"],"pdf_url":"https://arxiv.org/pdf/2308.10819v3.pdf","comment":"The data and code can be found at\n  https://github.com/Leezekun/instruction-following-robustness-eval"},{"id":"http://arxiv.org/abs/2311.16185v1","updated":"2023-11-25T18:20:43Z","published":"2023-11-25T18:20:43Z","title":"Enhancing Sentiment Analysis Results through Outlier Detection\n  Optimization","summary":"  When dealing with text data containing subjective labels like speaker\nemotions, inaccuracies or discrepancies among labelers are not uncommon. Such\ndiscrepancies can significantly affect the performance of machine learning\nalgorithms. This study investigates the potential of identifying and addressing\noutliers in text data with subjective labels, aiming to enhance classification\noutcomes. We utilized the Deep SVDD algorithm, a one-class classification\nmethod, to detect outliers in nine text-based emotion and sentiment analysis\ndatasets. By employing both a small-sized language model (DistilBERT base model\nwith 66 million parameters) and non-deep learning machine learning algorithms\n(decision tree, KNN, Logistic Regression, and LDA) as the classifier, our\nfindings suggest that the removal of outliers can lead to enhanced results in\nmost cases. Additionally, as outliers in such datasets are not necessarily\nunlearnable, we experienced utilizing a large language model -- DeBERTa v3\nlarge with 131 million parameters, which can capture very complex patterns in\ndata. We continued to observe performance enhancements across multiple\ndatasets.\n","authors":["Yuetian Chen","Mei Si"],"pdf_url":"https://arxiv.org/pdf/2311.16185v1.pdf","comment":"11 pages, 5 figures"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2305.07637v3","updated":"2023-11-25T17:19:36Z","published":"2023-05-12T17:46:06Z","title":"Text2Cohort: Facilitating Intuitive Access to Biomedical Data with\n  Natural Language Cohort Discovery","summary":"  The Imaging Data Commons (IDC) is a cloud-based database that provides\nresearchers with open access to cancer imaging data, with the goal of\nfacilitating collaboration. However, cohort discovery within the IDC database\nhas a significant technical learning curve. Recently, large language models\n(LLM) have demonstrated exceptional utility for natural language processing\ntasks. We developed Text2Cohort, a LLM-powered toolkit to facilitate\nuser-friendly natural language cohort discovery in the IDC. Our method\ntranslates user input into IDC queries using grounding techniques and returns\nthe query's response. We evaluate Text2Cohort on 50 natural language inputs,\nfrom information extraction to cohort discovery. Our toolkit successfully\ngenerated responses with an 88% accuracy and 0.94 F1 score. We demonstrate that\nText2Cohort can enable researchers to discover and curate cohorts on IDC with\nhigh levels of accuracy using natural language in a more intuitive and\nuser-friendly way.\n","authors":["Pranav Kulkarni","Adway Kanhere","Paul H. Yi","Vishwa S. Parekh"],"pdf_url":"https://arxiv.org/pdf/2305.07637v3.pdf","comment":"5 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2310.20189v2","updated":"2023-11-25T11:46:49Z","published":"2023-10-31T05:16:54Z","title":"LFG: A Generative Network for Real-Time Recommendation","summary":"  Recommender systems are essential information technologies today, and\nrecommendation algorithms combined with deep learning have become a research\nhotspot in this field. The recommendation model known as LFM (Latent Factor\nModel), which captures latent features through matrix factorization and\ngradient descent to fit user preferences, has given rise to various\nrecommendation algorithms that bring new improvements in recommendation\naccuracy. However, collaborative filtering recommendation models based on LFM\nlack flexibility and has shortcomings for real-time recommendations, as they\nneed to redo the matrix factorization and retrain using gradient descent when\nnew users arrive. In response to this, this paper innovatively proposes a\nLatent Factor Generator (LFG) network, and set the movie recommendation as\nresearch theme. The LFG dynamically generates user latent factors through deep\nneural networks without the need for re-factorization or retrain. Experimental\nresults indicate that the LFG recommendation model outperforms traditional\nmatrix factorization algorithms in recommendation accuracy, providing an\neffective solution to the challenges of real-time recommendations with LFM.\n","authors":["Junyi Liu"],"pdf_url":"https://arxiv.org/pdf/2310.20189v2.pdf","comment":"9 pages, 1 figure, 4 tables. Source code would be uploaded to github\n  soon"},{"id":"http://arxiv.org/abs/2311.14968v1","updated":"2023-11-25T08:59:45Z","published":"2023-11-25T08:59:45Z","title":"Hide Your Model: A Parameter Transmission-free Federated Recommender\n  System","summary":"  With the growing concerns regarding user data privacy, Federated Recommender\nSystem (FedRec) has garnered significant attention recently due to its\nprivacy-preserving capabilities. Existing FedRecs generally adhere to a\nlearning protocol in which a central server shares a global recommendation\nmodel with clients, and participants achieve collaborative learning by\nfrequently communicating the model's public parameters. Nevertheless, this\nlearning framework has two drawbacks that limit its practical usability: (1) It\nnecessitates a global-sharing recommendation model; however, in real-world\nscenarios, information related to the recommender model, including its\nalgorithm and parameters, constitutes the platforms' intellectual property.\nHence, service providers are unlikely to release such information actively. (2)\nThe communication costs of model parameter transmission are expensive since the\nmodel parameters are usually high-dimensional matrices. With the model size\nincreasing, the communication burden will be the bottleneck for such\ntraditional FedRecs.\n  Given the above limitations, this paper introduces a novel parameter\ntransmission-free federated recommendation framework that balances the\nprotection between users' data privacy and platforms' model privacy, namely\nPTF-FedRec. Specifically, participants in PTF-FedRec collaboratively exchange\nknowledge by sharing their predictions within a privacy-preserving mechanism.\nThrough this way, the central server can learn a recommender model without\ndisclosing its model parameters or accessing clients' raw data, preserving both\nthe server's model privacy and users' data privacy. Besides, since clients and\nthe central server only need to communicate prediction scores which are just a\nfew real numbers, the overhead is significantly reduced compared to traditional\nFedRecs.\n","authors":["Wei Yuan","Chaoqun Yang","Liang Qu","Quoc Viet Hung Nguyen","Jianxin Li","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2311.14968v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14318v3","updated":"2023-11-25T06:02:47Z","published":"2023-10-22T14:41:10Z","title":"Intent Contrastive Learning with Cross Subsequences for Sequential\n  Recommendation","summary":"  The user purchase behaviors are mainly influenced by their intentions (e.g.,\nbuying clothes for decoration, buying brushes for painting, etc.). Modeling a\nuser's latent intention can significantly improve the performance of\nrecommendations. Previous works model users' intentions by considering the\npredefined label in auxiliary information or introducing stochastic data\naugmentation to learn purposes in the latent space. However, the auxiliary\ninformation is sparse and not always available for recommender systems, and\nintroducing stochastic data augmentation may introduce noise and thus change\nthe intentions hidden in the sequence. Therefore, leveraging user intentions\nfor sequential recommendation (SR) can be challenging because they are\nfrequently varied and unobserved. In this paper, Intent contrastive learning\nwith Cross Subsequences for sequential Recommendation (ICSRec) is proposed to\nmodel users' latent intentions. Specifically, ICSRec first segments a user's\nsequential behaviors into multiple subsequences by using a dynamic sliding\noperation and takes these subsequences into the encoder to generate the\nrepresentations for the user's intentions. To tackle the problem of no explicit\nlabels for purposes, ICSRec assumes different subsequences with the same target\nitem may represent the same intention and proposes a coarse-grain intent\ncontrastive learning to push these subsequences closer. Then, fine-grain intent\ncontrastive learning is mentioned to capture the fine-grain intentions of\nsubsequences in sequential behaviors. Extensive experiments conducted on four\nreal-world datasets demonstrate the superior performance of the proposed ICSRec\nmodel compared with baseline methods.\n","authors":["Xiuyuan Qin","Huanhuan Yuan","Pengpeng Zhao","Guanfeng Liu","Fuzhen Zhuang","Victor S. Sheng"],"pdf_url":"https://arxiv.org/pdf/2310.14318v3.pdf","comment":"10pages, 5figures, WSDM2024. arXiv admin note: text overlap with\n  arXiv:2304.07763"},{"id":"http://arxiv.org/abs/2311.16515v1","updated":"2023-11-25T14:24:49Z","published":"2023-11-25T14:24:49Z","title":"Word for Person: Zero-shot Composed Person Retrieval","summary":"  Searching for specific person has great security value and social benefits,\nand it often involves a combination of visual and textual information.\nConventional person retrieval methods, whether image-based or text-based,\nusually fall short in effectively harnessing both types of information, leading\nto the loss of accuracy. In this paper, a whole new task called Composed Person\nRetrieval (CPR) is proposed to jointly utilize both image and text information\nfor target person retrieval. However, the supervised CPR must depend on very\ncostly manual annotation dataset, while there are currently no available\nresources. To mitigate this issue, we firstly introduce the Zero-shot Composed\nPerson Retrieval (ZS-CPR), which leverages existing domain-related data to\nresolve the CPR problem without reliance on expensive annotations. Secondly, to\nlearn ZS-CPR model, we propose a two-stage learning framework, Word4Per, where\na lightweight Textual Inversion Network (TINet) and a text-based person\nretrieval model based on fine-tuned Contrastive Language-Image Pre-training\n(CLIP) network are learned without utilizing any CPR data. Thirdly, a finely\nannotated Image-Text Composed Person Retrieval dataset (ITCPR) is built as the\nbenchmark to assess the performance of the proposed Word4Per framework.\nExtensive experiments under both Rank-1 and mAP demonstrate the effectiveness\nof Word4Per for the ZS-CPR task, surpassing the comparative methods by over\n10%. The code and ITCPR dataset will be publicly available at\nhttps://github.com/Delong-liu-bupt/Word4Per.\n","authors":["Delong Liu","Haiwen Li","Zhicheng Zhao","Fei Su","Hongying Meng"],"pdf_url":"https://arxiv.org/pdf/2311.16515v1.pdf","comment":null}]},"2023-11-26T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2311.15451v1","updated":"2023-11-26T22:47:54Z","published":"2023-11-26T22:47:54Z","title":"Uncertainty-aware Language Modeling for Selective Question Answering","summary":"  We present an automatic large language model (LLM) conversion approach that\nproduces uncertainty-aware LLMs capable of estimating uncertainty with every\nprediction. Our approach is model- and data-agnostic, is\ncomputationally-efficient, and does not rely on external models or systems. We\nevaluate converted models on the selective question answering setting -- to\nanswer as many questions as possible while maintaining a given accuracy,\nforgoing providing predictions when necessary. As part of our results, we test\nBERT and Llama 2 model variants on the SQuAD extractive QA task and the\nTruthfulQA generative QA task. We show that using the uncertainty estimates\nprovided by our approach to selectively answer questions leads to significantly\nhigher accuracy over directly using model probabilities.\n","authors":["Qi Yang","Shreya Ravikumar","Fynn Schmitt-Ulms","Satvik Lolla","Ege Demir","Iaroslav Elistratov","Alex Lavaee","Sadhana Lolla","Elaheh Ahmadi","Daniela Rus","Alexander Amini","Alejandro Perez"],"pdf_url":"https://arxiv.org/pdf/2311.15451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.04947v2","updated":"2023-11-26T22:00:36Z","published":"2023-04-11T03:17:37Z","title":"Conditional Adapters: Parameter-efficient Transfer Learning with Fast\n  Inference","summary":"  We propose Conditional Adapter (CoDA), a parameter-efficient transfer\nlearning method that also improves inference efficiency. CoDA generalizes\nbeyond standard adapter approaches to enable a new way of balancing speed and\naccuracy using conditional computation. Starting with an existing dense\npretrained model, CoDA adds sparse activation together with a small number of\nnew parameters and a light-weight training phase. Our experiments demonstrate\nthat the CoDA approach provides an unexpectedly efficient way to transfer\nknowledge. Across a variety of language, vision, and speech tasks, CoDA\nachieves a 2x to 8x inference speed-up compared to the state-of-the-art Adapter\napproaches with moderate to no accuracy loss and the same parameter efficiency.\n","authors":["Tao Lei","Junwen Bai","Siddhartha Brahma","Joshua Ainslie","Kenton Lee","Yanqi Zhou","Nan Du","Vincent Y. Zhao","Yuexin Wu","Bo Li","Yu Zhang","Ming-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2304.04947v2.pdf","comment":"NeurIPS camera ready version"},{"id":"http://arxiv.org/abs/2311.15436v1","updated":"2023-11-26T21:45:53Z","published":"2023-11-26T21:45:53Z","title":"Learning to Skip for Language Modeling","summary":"  Overparameterized large-scale language models have impressive generalization\nperformance of in-context few-shot learning. However, most language models\nallocate the same amount of parameters or computation to each token,\ndisregarding the complexity or importance of the input data. We argue that in\nlanguage model pretraining, a variable amount of computation should be assigned\nto different tokens, and this can be efficiently achieved via a simple routing\nmechanism. Different from conventional early stopping techniques where tokens\ncan early exit at only early layers, we propose a more general method that\ndynamically skips the execution of a layer (or module) for any input token with\na binary router. In our extensive evaluation across 24 NLP tasks, we\ndemonstrate that the proposed method can significantly improve the 1-shot\nperformance compared to other competitive baselines only at mild extra cost for\ninference.\n","authors":["Dewen Zeng","Nan Du","Tao Wang","Yuanzhong Xu","Tao Lei","Zhifeng Chen","Claire Cui"],"pdf_url":"https://arxiv.org/pdf/2311.15436v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03081v2","updated":"2023-11-26T21:40:00Z","published":"2023-06-05T17:55:05Z","title":"Sequential Monte Carlo Steering of Large Language Models using\n  Probabilistic Programs","summary":"  Even after fine-tuning and reinforcement learning, large language models\n(LLMs) can be difficult, if not impossible, to control reliably with prompts\nalone. We propose a new inference-time approach to enforcing syntactic and\nsemantic constraints on the outputs of LLMs, called sequential Monte Carlo\n(SMC) steering. The key idea is to specify language generation tasks as\nposterior inference problems in a class of discrete probabilistic sequence\nmodels, and replace standard decoding with sequential Monte Carlo inference.\nFor a computational cost similar to that of beam search, SMC can steer LLMs to\nsolve diverse tasks, including infilling, generation under syntactic\nconstraints, and prompt intersection. To facilitate experimentation with SMC\nsteering, we present a probabilistic programming library, LLaMPPL\n(https://github.com/probcomp/hfppl), for concisely specifying new generation\ntasks as language model probabilistic programs, and automating steering of\nLLaMA-family Transformers.\n","authors":["Alexander K. Lew","Tan Zhi-Xuan","Gabriel Grand","Vikash K. Mansinghka"],"pdf_url":"https://arxiv.org/pdf/2306.03081v2.pdf","comment":"Minor typo fixes"},{"id":"http://arxiv.org/abs/2311.15425v1","updated":"2023-11-26T21:16:01Z","published":"2023-11-26T21:16:01Z","title":"Machine-Generated Text Detection using Deep Learning","summary":"  Our research focuses on the crucial challenge of discerning text produced by\nLarge Language Models (LLMs) from human-generated text, which holds\nsignificance for various applications. With ongoing discussions about attaining\na model with such functionality, we present supporting evidence regarding the\nfeasibility of such models. We evaluated our models on multiple datasets,\nincluding Twitter Sentiment, Football Commentary, Project Gutenberg, PubMedQA,\nand SQuAD, confirming the efficacy of the enhanced detection approaches. These\ndatasets were sampled with intricate constraints encompassing every\npossibility, laying the foundation for future research. We evaluate\nGPT-3.5-Turbo against various detectors such as SVM, RoBERTa-base, and\nRoBERTa-large. Based on the research findings, the results predominantly relied\non the sequence length of the sentence.\n","authors":["Raghav Gaggar","Ashish Bhagchandani","Harsh Oza"],"pdf_url":"https://arxiv.org/pdf/2311.15425v1.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2311.15402v1","updated":"2023-11-26T19:56:19Z","published":"2023-11-26T19:56:19Z","title":"Learning Section Weights for Multi-Label Document Classification","summary":"  Multi-label document classification is a traditional task in NLP. Compared to\nsingle-label classification, each document can be assigned multiple classes.\nThis problem is crucially important in various domains, such as tagging\nscientific articles. Documents are often structured into several sections such\nas abstract and title. Current approaches treat different sections equally for\nmulti-label classification. We argue that this is not a realistic assumption,\nleading to sub-optimal results. Instead, we propose a new method called\nLearning Section Weights (LSW), leveraging the contribution of each distinct\nsection for multi-label classification. Via multiple feed-forward layers, LSW\nlearns to assign weights to each section of, and incorporate the weights in the\nprediction. We demonstrate our approach on scientific articles. Experimental\nresults on public (arXiv) and private (Elsevier) datasets confirm the\nsuperiority of LSW, compared to state-of-the-art multi-label document\nclassification methods. In particular, LSW achieves a 1.3% improvement in terms\nof macro averaged F1-score while it achieves 1.3% in terms of macro averaged\nrecall on the publicly available arXiv dataset.\n","authors":["Maziar Moradi Fard","Paula Sorrolla Bayod","Kiomars Motarjem","Mohammad Alian Nejadi","Saber Akhondi","Camilo Thorne"],"pdf_url":"https://arxiv.org/pdf/2311.15402v1.pdf","comment":"7 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2305.14930v2","updated":"2023-11-26T18:36:30Z","published":"2023-05-24T09:13:15Z","title":"In-Context Impersonation Reveals Large Language Models' Strengths and\n  Biases","summary":"  In everyday conversations, humans can take on different roles and adapt their\nvocabulary to their chosen roles. We explore whether LLMs can take on, that is\nimpersonate, different roles when they generate text in-context. We ask LLMs to\nassume different personas before solving vision and language tasks. We do this\nby prefixing the prompt with a persona that is associated either with a social\nidentity or domain expertise. In a multi-armed bandit task, we find that LLMs\npretending to be children of different ages recover human-like developmental\nstages of exploration. In a language-based reasoning task, we find that LLMs\nimpersonating domain experts perform better than LLMs impersonating non-domain\nexperts. Finally, we test whether LLMs' impersonations are complementary to\nvisual information when describing different categories. We find that\nimpersonation can improve performance: an LLM prompted to be a bird expert\ndescribes birds better than one prompted to be a car expert. However,\nimpersonation can also uncover LLMs' biases: an LLM prompted to be a man\ndescribes cars better than one prompted to be a woman. These findings\ndemonstrate that LLMs are capable of taking on diverse roles and that this\nin-context impersonation can be used to uncover their hidden strengths and\nbiases.\n","authors":["Leonard Salewski","Stephan Alaniz","Isabel Rio-Torto","Eric Schulz","Zeynep Akata"],"pdf_url":"https://arxiv.org/pdf/2305.14930v2.pdf","comment":"Published in NeurIPS 2023 (Spotlight)"},{"id":"http://arxiv.org/abs/2212.06373v7","updated":"2023-11-26T17:24:19Z","published":"2022-12-13T05:12:40Z","title":"InferEM: Inferring the Speaker's Intention for Empathetic Dialogue\n  Generation","summary":"  Current approaches to empathetic response generation typically encode the\nentire dialogue history directly and put the output into a decoder to generate\nfriendly feedback. These methods focus on modelling contextual information but\nneglect capturing the direct intention of the speaker. We argue that the last\nutterance in the dialogue empirically conveys the intention of the speaker.\nConsequently, we propose a novel model named InferEM for empathetic response\ngeneration. We separately encode the last utterance and fuse it with the entire\ndialogue through the multi-head attention based intention fusion module to\ncapture the speaker's intention. Besides, we utilize previous utterances to\npredict the last utterance, which simulates human's psychology to guess what\nthe interlocutor may speak in advance. To balance the optimizing rates of the\nutterance prediction and response generation, a multi-task learning strategy is\ndesigned for InferEM. Experimental results demonstrate the plausibility and\nvalidity of InferEM in improving empathetic expression.\n","authors":["Guoqing Lv","Jiang Li","Xiaoping Wang","Zhigang Zeng"],"pdf_url":"https://arxiv.org/pdf/2212.06373v7.pdf","comment":"Accepted by the 45th Annual Meeting of the Cognitive Science Society\n  (CogSci 2023)"},{"id":"http://arxiv.org/abs/2311.05419v2","updated":"2023-11-26T17:12:20Z","published":"2023-11-09T14:58:46Z","title":"Mirror: A Universal Framework for Various Information Extraction Tasks","summary":"  Sharing knowledge between information extraction tasks has always been a\nchallenge due to the diverse data formats and task variations. Meanwhile, this\ndivergence leads to information waste and increases difficulties in building\ncomplex applications in real scenarios. Recent studies often formulate IE tasks\nas a triplet extraction problem. However, such a paradigm does not support\nmulti-span and n-ary extraction, leading to weak versatility. To this end, we\nreorganize IE problems into unified multi-slot tuples and propose a universal\nframework for various IE tasks, namely Mirror. Specifically, we recast existing\nIE tasks as a multi-span cyclic graph extraction problem and devise a\nnon-autoregressive graph decoding algorithm to extract all spans in a single\nstep. It is worth noting that this graph structure is incredibly versatile, and\nit supports not only complex IE tasks, but also machine reading comprehension\nand classification tasks. We manually construct a corpus containing 57 datasets\nfor model pretraining, and conduct experiments on 30 datasets across 8\ndownstream tasks. The experimental results demonstrate that our model has\ndecent compatibility and outperforms or reaches competitive performance with\nSOTA systems under few-shot and zero-shot settings. The code, model weights,\nand pretraining corpus are available at https://github.com/Spico197/Mirror .\n","authors":["Tong Zhu","Junfei Ren","Zijian Yu","Mengsong Wu","Guoliang Zhang","Xiaoye Qu","Wenliang Chen","Zhefeng Wang","Baoxing Huai","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.05419v2.pdf","comment":"Accepted to EMNLP23 main conference"},{"id":"http://arxiv.org/abs/2305.09620v2","updated":"2023-11-26T16:25:49Z","published":"2023-05-16T17:13:07Z","title":"AI-Augmented Surveys: Leveraging Large Language Models and Surveys for\n  Opinion Prediction","summary":"  Large language models (LLMs) that produce human-like responses have begun to\nrevolutionize research practices in the social sciences. This paper shows how\nwe can integrate LLMs and social surveys to accurately predict individual\nresponses to survey questions that were not asked before. We develop a novel\nmethodological framework to personalize LLMs by considering the meaning of\nsurvey questions derived from their text, the latent beliefs of individuals\ninferred from their response patterns, and the temporal contexts across\ndifferent survey periods through fine-tuning LLMs with survey data. Using the\nGeneral Social Survey from 1972 to 2021, we show that the fine-tuned model\nbased on Alpaca-7b can predict individual responses to survey questions that\nare partially missing as well as entirely missing. The remarkable prediction\ncapabilities allow us to fill in missing trends with high confidence and\npinpoint when public attitudes changed, such as the rising support for same-sex\nmarriage. We discuss practical constraints, socio-demographic representation,\nand ethical concerns regarding individual autonomy and privacy when using LLMs\nfor opinion prediction. This study demonstrates that LLMs and surveys can\nmutually enhance each other's capabilities: LLMs broaden survey potential,\nwhile surveys improve the alignment of LLMs.\n","authors":["Junsol Kim","Byungkyu Lee"],"pdf_url":"https://arxiv.org/pdf/2305.09620v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11435v2","updated":"2023-11-26T15:05:58Z","published":"2023-11-19T22:14:48Z","title":"Unveiling Public Perceptions: Machine Learning-Based Sentiment Analysis\n  of COVID-19 Vaccines in India","summary":"  In March 2020, the World Health Organisation declared COVID-19 a global\npandemic as it spread to nearly every country. By mid-2021, India had\nintroduced three vaccines: Covishield, Covaxin, and Sputnik. To ensure\nsuccessful vaccination in a densely populated country like India, understanding\npublic sentiment was crucial. Social media, particularly Reddit with over 430\nmillion users, played a vital role in disseminating information. This study\nemploys data mining techniques to analyze Reddit data and gauge Indian\nsentiments towards COVID-19 vaccines. Using Python's Text Blob library,\ncomments are annotated to assess general sentiments. Results show that most\nReddit users in India expressed neutrality about vaccination, posing a\nchallenge for the Indian government's efforts to vaccinate a significant\nportion of the population.\n","authors":["Milind Gupta","Abhishek Kaushik"],"pdf_url":"https://arxiv.org/pdf/2311.11435v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15316v1","updated":"2023-11-26T14:35:23Z","published":"2023-11-26T14:35:23Z","title":"Enhancing Empathetic and Emotion Support Dialogue Generation with\n  Prophetic Commonsense Inference","summary":"  The interest in Empathetic and Emotional Support conversations among the\npublic has significantly increased. To offer more sensitive and understanding\nresponses, leveraging commonsense knowledge has become a common strategy to\nbetter understand psychological aspects and causality. However, such\ncommonsense inferences can be out of context and unable to predict upcoming\ndialogue themes, resulting in responses that lack coherence and empathy. To\nremedy this issue, we present Prophetic Commonsense Inference, an innovative\nparadigm for inferring commonsense knowledge. By harnessing the capabilities of\nLarge Language Models in understanding dialogue and making commonsense\ndeductions, we train tunable models to bridge the gap between past and\npotential future dialogues. Extensive experiments conducted on\nEmpatheticDialogues and Emotion Support Conversation show that equipping\ndialogue agents with our proposed prophetic commonsense inference significantly\nenhances the quality of their responses.\n","authors":["Lanrui Wang","Jiangnan Li","Chenxu Yang","Zheng Lin","Weiping Wang"],"pdf_url":"https://arxiv.org/pdf/2311.15316v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15296v1","updated":"2023-11-26T13:42:56Z","published":"2023-11-26T13:42:56Z","title":"UHGEval: Benchmarking the Hallucination of Chinese Large Language Models\n  via Unconstrained Generation","summary":"  Large language models (LLMs) have emerged as pivotal contributors in\ncontemporary natural language processing and are increasingly being applied\nacross a diverse range of industries. However, these large-scale probabilistic\nstatistical models cannot currently ensure the requisite quality in\nprofessional content generation. These models often produce hallucinated text,\ncompromising their practical utility in professional contexts. To assess the\nauthentic reliability of LLMs in text generation, numerous initiatives have\ndeveloped benchmark evaluations for hallucination phenomena. Nevertheless,\nthese benchmarks frequently utilize constrained generation techniques due to\ncost and temporal constraints. These techniques encompass the use of directed\nhallucination induction and strategies that deliberately alter authentic text\nto produce hallucinations. These approaches are not congruent with the\nunrestricted text generation demanded by real-world applications. Furthermore,\na well-established Chinese-language dataset dedicated to the evaluation of\nhallucinations in text generation is presently lacking. Consequently, we have\ndeveloped an Unconstrained Hallucination Generation Evaluation (UHGEval)\nbenchmark, designed to compile outputs produced with minimal restrictions by\nLLMs. Concurrently, we have established a comprehensive benchmark evaluation\nframework to aid subsequent researchers in undertaking scalable and\nreproducible experiments. We have also executed extensive experiments,\nevaluating prominent Chinese language models and the GPT series models to\nderive professional performance insights regarding hallucination challenges.\n","authors":["Xun Liang","Shichao Song","Simin Niu","Zhiyu Li","Feiyu Xiong","Bo Tang","Zhaohui Wy","Dawei He","Peng Cheng","Zhonghao Wang","Haiying Deng"],"pdf_url":"https://arxiv.org/pdf/2311.15296v1.pdf","comment":"13 Pages, submitted to ICDE2024"},{"id":"http://arxiv.org/abs/2307.11845v2","updated":"2023-11-26T08:57:44Z","published":"2023-07-21T18:29:04Z","title":"Multimodal Document Analytics for Banking Process Automation","summary":"  Traditional banks face increasing competition from FinTechs in the rapidly\nevolving financial ecosystem. Raising operational efficiency is vital to\naddress this challenge. Our study aims to improve the efficiency of\ndocument-intensive business processes in banking. To that end, we first review\nthe landscape of business documents in the retail segment. Banking documents\noften contain text, layout, and visuals, suggesting that document analytics and\nprocess automation require more than plain natural language processing (NLP).\nTo verify this and assess the incremental value of visual cues when processing\nbusiness documents, we compare a recently proposed multimodal model called\nLayoutXLM to powerful text classifiers (e.g., BERT) and large language models\n(e.g., GPT) in a case study related to processing company register extracts.\nThe results confirm that incorporating layout information in a model\nsubstantially increases its performance. Interestingly, we also observed that\nmore than 75% of the best model performance (in terms of the F1 score) can be\nachieved with as little as 30% of the training data. This shows that the demand\nfor data labeled data to set up a multi-modal model can be moderate, which\nsimplifies real-world applications of multimodal document analytics. Our study\nalso sheds light on more specific practices in the scope of calibrating a\nmultimodal banking document classifier, including the need for fine-tuning. In\nsum, the paper contributes original empirical evidence on the effectiveness and\nefficiency of multi-model models for document processing in the banking\nbusiness and offers practical guidance on how to unlock this potential in\nday-to-day operations.\n","authors":["Christopher Gerling","Stefan Lessmann"],"pdf_url":"https://arxiv.org/pdf/2307.11845v2.pdf","comment":"A Preprint"},{"id":"http://arxiv.org/abs/2311.15218v1","updated":"2023-11-26T07:19:10Z","published":"2023-11-26T07:19:10Z","title":"Dataset for Stock Market Forecasting Based on Quantitative Analysis and\n  Qualitative Data","summary":"  The application of Machine learning to finance has become a familiar\napproach, even more so in stock market forecasting. The stock market is highly\nvolatile and huge amounts of data are generated every minute globally. The\nextraction of effective intelligence from this data is of critical importance.\nHowever, a collaboration of numerical stock data with qualitative text data can\nbe a challenging task. In this work, we accomplish this and provide an\nunprecedented, publicly available dataset with technical and fundamental data,\nsentiment that we gathered from News Archives, TV news captions, Radio\nTranscripts, Tweets, Daily financial newspapers, etc. The text data entries\nused for sentiment extraction total more than 1.4 Million. The dataset\ncomprises of daily entries from January 2018 to December 2022 for 8 different\ncompanies and Dow Jones Index as a whole. Holistic Fundamental and Technical\ndata is provided training ready for Model learning and deployment. The\npredictive power of deep learning models is highly determined by the training\ndata provided. This dataset would be of benefit for research globally\nincorporating qualitative intelligence for stock market forecasting. The\ndataset is made available at https://github.com/batking24/Huge-Stock-Dataset.\n","authors":["Sai Akash Bathini","Dagli Cihan"],"pdf_url":"https://arxiv.org/pdf/2311.15218v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15211v1","updated":"2023-11-26T06:56:02Z","published":"2023-11-26T06:56:02Z","title":"Probabilistic Transformer: A Probabilistic Dependency Model for\n  Contextual Word Representation","summary":"  Syntactic structures used to play a vital role in natural language processing\n(NLP), but since the deep learning revolution, NLP has been gradually dominated\nby neural models that do not consider syntactic structures in their design. One\nvastly successful class of neural models is transformers. When used as an\nencoder, a transformer produces contextual representation of words in the input\nsentence. In this work, we propose a new model of contextual word\nrepresentation, not from a neural perspective, but from a purely syntactic and\nprobabilistic perspective. Specifically, we design a conditional random field\nthat models discrete latent representations of all words in a sentence as well\nas dependency arcs between them; and we use mean field variational inference\nfor approximate inference. Strikingly, we find that the computation graph of\nour model resembles transformers, with correspondences between dependencies and\nself-attention and between distributions over latent representations and\ncontextual embeddings of words. Experiments show that our model performs\ncompetitively to transformers on small to medium sized datasets. We hope that\nour work could help bridge the gap between traditional syntactic and\nprobabilistic approaches and cutting-edge neural approaches to NLP, and inspire\nmore linguistically-principled neural approaches in the future.\n","authors":["Haoyi Wu","Kewei Tu"],"pdf_url":"https://arxiv.org/pdf/2311.15211v1.pdf","comment":"Accepted to ACL2023 Findings"},{"id":"http://arxiv.org/abs/2311.15208v1","updated":"2023-11-26T06:24:25Z","published":"2023-11-26T06:24:25Z","title":"LongStory: Coherent, Complete and Length Controlled Long story\n  Generation","summary":"  A human author can write any length of story without losing coherence. Also,\nthey always bring the story to a proper ending, an ability that current\nlanguage models lack. In this work, we present the LongStory for coherent,\ncomplete, and length-controlled long story generation. LongStory introduces two\nnovel methodologies: (1) the long and short-term contexts weight calibrator\n(CWC) and (2) long story structural positions (LSP). The CWC adjusts weights\nfor long-term context Memory and short-term context Cheating, acknowledging\ntheir distinct roles. The LSP employs discourse tokens to convey the structural\npositions of a long story. Trained on three datasets with varied average story\nlengths, LongStory outperforms other baselines, including the strong story\ngenerator Plotmachine, in coherence, completeness, relevance, and\nrepetitiveness. We also perform zero-shot tests on each dataset to assess the\nmodel's ability to predict outcomes beyond its training data and validate our\nmethodology by comparing its performance with variants of our model.\n","authors":["Kyeongman Park","Nakyeong Yang","Kyomin Jung"],"pdf_url":"https://arxiv.org/pdf/2311.15208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15198v1","updated":"2023-11-26T05:34:22Z","published":"2023-11-26T05:34:22Z","title":"ChatGPT and Beyond: The Generative AI Revolution in Education","summary":"  The wide adoption and usage of generative artificial intelligence (AI)\nmodels, particularly ChatGPT, has sparked a surge in research exploring their\npotential applications in the educational landscape. This survey examines\nacademic literature published between November, 2022, and July, 2023,\nspecifically targeting high-impact research from Scopus-indexed Q1 and Q2\njournals. This survey delves into the practical applications and implications\nof generative AI models across a diverse range of educational contexts. Through\na comprehensive and rigorous evaluation of recent academic literature, this\nsurvey seeks to illuminate the evolving role of generative AI models,\nparticularly ChatGPT, in education. By shedding light on the potential\nbenefits, challenges, and emerging trends in this dynamic field, the survey\nendeavors to contribute to the understanding of the nexus between artificial\nintelligence and education. The findings of this review will empower educators,\nresearchers, and policymakers to make informed decisions about the integration\nof AI technologies into learning environments.\n","authors":["Mohammad AL-Smadi"],"pdf_url":"https://arxiv.org/pdf/2311.15198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10013v2","updated":"2023-11-26T05:05:51Z","published":"2022-12-20T06:01:13Z","title":"DocAsRef: An Empirical Study on Repurposing Reference-Based Summary\n  Quality Metrics Reference-Freely","summary":"  Automated summary quality assessment falls into two categories:\nreference-based and reference-free. Reference-based metrics, historically\ndeemed more accurate due to the additional information provided by\nhuman-written references, are limited by their reliance on human input. In this\npaper, we hypothesize that the comparison methodologies used by some\nreference-based metrics to evaluate a system summary against its corresponding\nreference can be effectively adapted to assess it against its source document,\nthereby transforming these metrics into reference-free ones. Experimental\nresults support this hypothesis. After being repurposed reference-freely, the\nzero-shot BERTScore using the pretrained DeBERTa-large-MNLI model of <0.5B\nparameters consistently outperforms its original reference-based version across\nvarious aspects on the SummEval and Newsroom datasets. It also excels in\ncomparison to most existing reference-free metrics and closely competes with\nzero-shot summary evaluators based on GPT-3.5.\n","authors":["Forrest Sheng Bao","Ruixuan Tu","Ge Luo","Yinfei Yang","Hebi Li","Minghui Qiu","Youbiao He","Cen Chen"],"pdf_url":"https://arxiv.org/pdf/2212.10013v2.pdf","comment":"Accepted into Findings of EMNLP 2023"},{"id":"http://arxiv.org/abs/2311.15180v1","updated":"2023-11-26T03:54:03Z","published":"2023-11-26T03:54:03Z","title":"Benchmarking Large Language Model Volatility","summary":"  The impact of non-deterministic outputs from Large Language Models (LLMs) is\nnot well examined for financial text understanding tasks. Through a compelling\ncase study on investing in the US equity market via news sentiment analysis, we\nuncover substantial variability in sentence-level sentiment classification\nresults, underscoring the innate volatility of LLM outputs. These uncertainties\ncascade downstream, leading to more significant variations in portfolio\nconstruction and return. While tweaking the temperature parameter in the\nlanguage model decoder presents a potential remedy, it comes at the expense of\nstifled creativity. Similarly, while ensembling multiple outputs mitigates the\neffect of volatile outputs, it demands a notable computational investment. This\nwork furnishes practitioners with invaluable insights for adeptly navigating\nuncertainty in the integration of LLMs into financial decision-making,\nparticularly in scenarios dictated by non-deterministic information.\n","authors":["Boyang Yu"],"pdf_url":"https://arxiv.org/pdf/2311.15180v1.pdf","comment":"7 pages, 2 figures, Workshop on AI Safety and Robustness In Finance,\n  ICAIF 2023"},{"id":"http://arxiv.org/abs/2311.06401v3","updated":"2023-11-26T02:42:13Z","published":"2023-11-10T21:32:34Z","title":"Autoregressive Language Models For Estimating the Entropy of Epic EHR\n  Audit Logs","summary":"  EHR audit logs are a highly granular stream of events that capture clinician\nactivities, and is a significant area of interest for research in\ncharacterizing clinician workflow on the electronic health record (EHR).\nExisting techniques to measure the complexity of workflow through EHR audit\nlogs (audit logs) involve time- or frequency-based cross-sectional aggregations\nthat are unable to capture the full complexity of a EHR session. We briefly\nevaluate the usage of transformer-based tabular language model (tabular LM) in\nmeasuring the entropy or disorderedness of action sequences within workflow and\nrelease the evaluated models publicly.\n","authors":["Benjamin C. Warner","Thomas Kannampallil","Seunghwan Kim"],"pdf_url":"https://arxiv.org/pdf/2311.06401v3.pdf","comment":"Extended Abstract presented at Machine Learning for Health (ML4H)\n  symposium 2023, December 10th, 2023, New Orleans, United States, 10 pages"},{"id":"http://arxiv.org/abs/2206.10498v4","updated":"2023-11-26T01:15:41Z","published":"2022-06-21T16:15:27Z","title":"PlanBench: An Extensible Benchmark for Evaluating Large Language Models\n  on Planning and Reasoning about Change","summary":"  Generating plans of action, and reasoning about change have long been\nconsidered a core competence of intelligent agents. It is thus no surprise that\nevaluating the planning and reasoning capabilities of large language models\n(LLMs) has become a hot topic of research. Most claims about LLM planning\ncapabilities are however based on common sense tasks-where it becomes hard to\ntell whether LLMs are planning or merely retrieving from their vast world\nknowledge. There is a strong need for systematic and extensible planning\nbenchmarks with sufficient diversity to evaluate whether LLMs have innate\nplanning capabilities. Motivated by this, we propose PlanBench, an extensible\nbenchmark suite based on the kinds of domains used in the automated planning\ncommunity, especially in the International Planning Competition, to test the\ncapabilities of LLMs in planning or reasoning about actions and change.\nPlanBench provides sufficient diversity in both the task domains and the\nspecific planning capabilities. Our studies also show that on many critical\ncapabilities-including plan generation-LLM performance falls quite short, even\nwith the SOTA models. PlanBench can thus function as a useful marker of\nprogress of LLMs in planning and reasoning.\n","authors":["Karthik Valmeekam","Matthew Marquez","Alberto Olmo","Sarath Sreedharan","Subbarao Kambhampati"],"pdf_url":"https://arxiv.org/pdf/2206.10498v4.pdf","comment":"NeurIPS 2023 Track on Datasets and Benchmarks"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2311.15453v1","updated":"2023-11-26T23:07:19Z","published":"2023-11-26T23:07:19Z","title":"DISYRE: Diffusion-Inspired SYnthetic REstoration for Unsupervised\n  Anomaly Detection","summary":"  Unsupervised Anomaly Detection (UAD) techniques aim to identify and localize\nanomalies without relying on annotations, only leveraging a model trained on a\ndataset known to be free of anomalies. Diffusion models learn to modify inputs\n$x$ to increase the probability of it belonging to a desired distribution,\ni.e., they model the score function $\\nabla_x \\log p(x)$. Such a score function\nis potentially relevant for UAD, since $\\nabla_x \\log p(x)$ is itself a\npixel-wise anomaly score. However, diffusion models are trained to invert a\ncorruption process based on Gaussian noise and the learned score function is\nunlikely to generalize to medical anomalies. This work addresses the problem of\nhow to learn a score function relevant for UAD and proposes DISYRE:\nDiffusion-Inspired SYnthetic REstoration. We retain the diffusion-like pipeline\nbut replace the Gaussian noise corruption with a gradual, synthetic anomaly\ncorruption so the learned score function generalizes to medical, naturally\noccurring anomalies. We evaluate DISYRE on three common Brain MRI UAD\nbenchmarks and substantially outperform other methods in two out of the three\ntasks.\n","authors":["Sergio Naval Marimont","Matthew Baugh","Vasilis Siomos","Christos Tzelepis","Bernhard Kainz","Giacomo Tarroni"],"pdf_url":"https://arxiv.org/pdf/2311.15453v1.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.05543v3","updated":"2023-11-26T22:26:12Z","published":"2023-02-10T23:12:37Z","title":"Adding Conditional Control to Text-to-Image Diffusion Models","summary":"  We present ControlNet, a neural network architecture to add spatial\nconditioning controls to large, pretrained text-to-image diffusion models.\nControlNet locks the production-ready large diffusion models, and reuses their\ndeep and robust encoding layers pretrained with billions of images as a strong\nbackbone to learn a diverse set of conditional controls. The neural\narchitecture is connected with \"zero convolutions\" (zero-initialized\nconvolution layers) that progressively grow the parameters from zero and ensure\nthat no harmful noise could affect the finetuning. We test various conditioning\ncontrols, eg, edges, depth, segmentation, human pose, etc, with Stable\nDiffusion, using single or multiple conditions, with or without prompts. We\nshow that the training of ControlNets is robust with small (<50k) and large\n(>1m) datasets. Extensive results show that ControlNet may facilitate wider\napplications to control image diffusion models.\n","authors":["Lvmin Zhang","Anyi Rao","Maneesh Agrawala"],"pdf_url":"https://arxiv.org/pdf/2302.05543v3.pdf","comment":"Codes and Supplementary Material:\n  https://github.com/lllyasviel/ControlNet"},{"id":"http://arxiv.org/abs/2311.15445v1","updated":"2023-11-26T22:09:18Z","published":"2023-11-26T22:09:18Z","title":"FLAIR: A Conditional Diffusion Framework with Applications to Face Video\n  Restoration","summary":"  Face video restoration (FVR) is a challenging but important problem where one\nseeks to recover a perceptually realistic face videos from a low-quality input.\nWhile diffusion probabilistic models (DPMs) have been shown to achieve\nremarkable performance for face image restoration, they often fail to preserve\ntemporally coherent, high-quality videos, compromising the fidelity of\nreconstructed faces. We present a new conditional diffusion framework called\nFLAIR for FVR. FLAIR ensures temporal consistency across frames in a\ncomputationally efficient fashion by converting a traditional image DPM into a\nvideo DPM. The proposed conversion uses a recurrent video refinement layer and\na temporal self-attention at different scales. FLAIR also uses a conditional\niterative refinement process to balance the perceptual and distortion quality\nduring inference. This process consists of two key components: a\ndata-consistency module that analytically ensures that the generated video\nprecisely matches its degraded observation and a coarse-to-fine image\nenhancement module specifically for facial regions. Our extensive experiments\nshow superiority of FLAIR over the current state-of-the-art (SOTA) for video\nsuper-resolution, deblurring, JPEG restoration, and space-time frame\ninterpolation on two high-quality face video datasets.\n","authors":["Zihao Zou","Jiaming Liu","Shirin Shoushtari","Yubo Wang","Weijie Gan","Ulugbek S. Kamilov"],"pdf_url":"https://arxiv.org/pdf/2311.15445v1.pdf","comment":"32 pages, 27 figures"},{"id":"http://arxiv.org/abs/2311.15439v1","updated":"2023-11-26T21:53:22Z","published":"2023-11-26T21:53:22Z","title":"Efficient Encoding of Graphics Primitives with Simplex-based Structures","summary":"  Grid-based structures are commonly used to encode explicit features for\ngraphics primitives such as images, signed distance functions (SDF), and neural\nradiance fields (NeRF) due to their simple implementation. However, in\n$n$-dimensional space, calculating the value of a sampled point requires\ninterpolating the values of its $2^n$ neighboring vertices. The exponential\nscaling with dimension leads to significant computational overheads. To address\nthis issue, we propose a simplex-based approach for encoding graphics\nprimitives. The number of vertices in a simplex-based structure increases\nlinearly with dimension, making it a more efficient and generalizable\nalternative to grid-based representations. Using the non-axis-aligned\nsimplicial structure property, we derive and prove a coordinate transformation,\nsimplicial subdivision, and barycentric interpolation scheme for efficient\nsampling, which resembles transformation procedures in the simplex noise\nalgorithm. Finally, we use hash tables to store multiresolution features of all\ninterest points in the simplicial grid, which are passed into a tiny fully\nconnected neural network to parameterize graphics primitives. We implemented a\ndetailed simplex-based structure encoding algorithm in C++ and CUDA using the\nmethods outlined in our approach. In the 2D image fitting task, the proposed\nmethod is capable of fitting a giga-pixel image with 9.4% less time compared to\nthe baseline method proposed by instant-ngp, while maintaining the same quality\nand compression rate. In the volumetric rendering setup, we observe a maximum\n41.2% speedup when the samples are dense enough.\n","authors":["Yibo Wen","Yunfan Yang"],"pdf_url":"https://arxiv.org/pdf/2311.15439v1.pdf","comment":"10 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.15438v1","updated":"2023-11-26T21:52:47Z","published":"2023-11-26T21:52:47Z","title":"ProtoArgNet: Interpretable Image Classification with Super-Prototypes\n  and Argumentation [Technical Report]","summary":"  We propose ProtoArgNet, a novel interpretable deep neural architecture for\nimage classification in the spirit of prototypical-part-learning as found, e.g.\nin ProtoPNet. While earlier approaches associate every class with multiple\nprototypical-parts, ProtoArgNet uses super-prototypes that combine\nprototypical-parts into single prototypical class representations. Furthermore,\nwhile earlier approaches use interpretable classification layers, e.g. logistic\nregression in ProtoPNet, ProtoArgNet improves accuracy with multi-layer\nperceptrons while relying upon an interpretable reading thereof based on a form\nof argumentation. ProtoArgNet is customisable to user cognitive requirements by\na process of sparsification of the multi-layer perceptron/argumentation\ncomponent. Also, as opposed to other prototypical-part-learning approaches,\nProtoArgNet can recognise spatial relations between different\nprototypical-parts that are from different regions in images, similar to how\nCNNs capture relations between patterns recognized in earlier layers.\n","authors":["Hamed Ayoobi","Nico Potyka","Francesca Toni"],"pdf_url":"https://arxiv.org/pdf/2311.15438v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15437v1","updated":"2023-11-26T21:48:58Z","published":"2023-11-26T21:48:58Z","title":"Quality Modeling Under A Relaxed Natural Scene Statistics Model","summary":"  Information-theoretic image quality assessment (IQA) models such as Visual\nInformation Fidelity (VIF) and Spatio-temporal Reduced Reference Entropic\nDifferences (ST-RRED) have enjoyed great success by seamlessly integrating\nnatural scene statistics (NSS) with information theory. The Gaussian Scale\nMixture (GSM) model that governs the wavelet subband coefficients of natural\nimages forms the foundation for these algorithms. However, the explosion of\nuser-generated content on social media, which is typically distorted by one or\nmore of many possible unknown impairments, has revealed the limitations of\nNSS-based IQA models that rely on the simple GSM model. Here, we seek to\nelaborate the VIF index by deriving useful properties of the Multivariate\nGeneralized Gaussian Distribution (MGGD), and using them to study the behavior\nof VIF under a Generalized GSM (GGSM) model.\n","authors":["Abhinau K. Venkataramanan","Alan C. Bovik"],"pdf_url":"https://arxiv.org/pdf/2311.15437v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15435v1","updated":"2023-11-26T21:35:34Z","published":"2023-11-26T21:35:34Z","title":"Functional Diffusion","summary":"  We propose a new class of generative diffusion models, called functional\ndiffusion. In contrast to previous work, functional diffusion works on samples\nthat are represented by functions with a continuous domain. Functional\ndiffusion can be seen as an extension of classical diffusion models to an\ninfinite-dimensional domain. Functional diffusion is very versatile as images,\nvideos, audio, 3D shapes, deformations, \\etc, can be handled by the same\nframework with minimal changes. In addition, functional diffusion is especially\nsuited for irregular data or data defined in non-standard domains. In our work,\nwe derive the necessary foundations for functional diffusion and propose a\nfirst implementation based on the transformer architecture. We show generative\nresults on complicated signed distance functions and deformation functions\ndefined on 3D surfaces.\n","authors":["Biao Zhang","Peter Wonka"],"pdf_url":"https://arxiv.org/pdf/2311.15435v1.pdf","comment":"For the project site, see https://1zb.github.io/functional-diffusion/"},{"id":"http://arxiv.org/abs/2311.15421v1","updated":"2023-11-26T21:09:00Z","published":"2023-11-26T21:09:00Z","title":"Wired Perspectives: Multi-View Wire Art Embraces Generative AI","summary":"  Creating multi-view wire art (MVWA), a static 3D sculpture with diverse\ninterpretations from different viewpoints, is a complex task even for skilled\nartists. In response, we present DreamWire, an AI system enabling everyone to\ncraft MVWA easily. Users express their vision through text prompts or\nscribbles, freeing them from intricate 3D wire organisation. Our approach\nsynergises 3D B\\'ezier curves, Prim's algorithm, and knowledge distillation\nfrom diffusion models or their variants (e.g., ControlNet). This blend enables\nthe system to represent 3D wire art, ensuring spatial continuity and overcoming\ndata scarcity. Extensive evaluation and analysis are conducted to shed insight\non the inner workings of the proposed system, including the trade-off between\nconnectivity and visual aesthetics.\n","authors":["Zhiyu Qu","Lan Yang","Honggang Zhang","Tao Xiang","Kaiyue Pang","Yi-Zhe Song"],"pdf_url":"https://arxiv.org/pdf/2311.15421v1.pdf","comment":"Project page: https://dreamwireart.github.io"},{"id":"http://arxiv.org/abs/2311.15420v1","updated":"2023-11-26T21:04:28Z","published":"2023-11-26T21:04:28Z","title":"Data-Driven Modelling for Harmonic Current Emission in Low-Voltage Grid\n  Using MCReSANet with Interpretability Analysis","summary":"  Even though the use of power electronics PE loads offers enhanced electrical\nenergy conversion efficiency and control, they remain the primary sources of\nharmonics in grids. When diverse loads are connected in the distribution\nsystem, their interactions complicate establishing analytical models for the\nrelationship between harmonic voltages and currents. To solve this, our paper\npresents a data-driven model using MCReSANet to construct the highly nonlinear\nbetween harmonic voltage and current. Two datasets from PCCs in Finland and\nGermany are utilized, which demonstrates that MCReSANet is capable of\nestablishing accurate nonlinear mappings, even in the presence of various\nnetwork characteristics for selected Finland and Germany datasets. The model\nbuilt by MCReSANet can improve the MAE by 10% and 14% compared to the CNN, and\nby 8% and 17% compared to the MLP for both Finnish and German datasets, also\nshowing much lower model uncertainty than others. This is a crucial\nprerequisite for more precise SHAP value-based feature importance analysis,\nwhich is a method for the model interpretability analysis in this paper. The\nresults by feature importance analysis show the detailed relationships between\neach order of harmonic voltage and current in the distribution system. There is\nan interactive impact on each order of harmonic current, but some orders of\nharmonic voltages have a dominant influence on harmonic current emissions:\npositive sequence and zero sequence harmonics have the dominant importance in\nthe Finnish and German networks, respectively, which conforms to the pattern of\nconnected load types in two selected Finnish and German datasets. This paper\nenhances the potential for understanding and predicting harmonic current\nemissions by diverse PE loads in distribution systems, which is beneficial to\nmore effective management for optimizing power quality in diverse grid\nenvironments.\n","authors":["Jieyu Yao","Hao Yu","Paul Judge","Jiabin Jia","Sasa Djokic","Verner Püvi","Matti Lehtonen","Jan Meyer"],"pdf_url":"https://arxiv.org/pdf/2311.15420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10902v2","updated":"2023-11-26T20:53:27Z","published":"2023-11-17T22:48:50Z","title":"OCT2Confocal: 3D CycleGAN based Translation of Retinal OCT Images to\n  Confocal Microscopy","summary":"  Optical coherence tomography (OCT) and confocal microscopy are pivotal in\nretinal imaging, each presenting unique benefits and limitations. In vivo OCT\noffers rapid, non-invasive imaging but can be hampered by clarity issues and\nmotion artifacts. Ex vivo confocal microscopy provides high-resolution,\ncellular detailed color images but is invasive and poses ethical concerns and\npotential tissue damage. To bridge these modalities, we developed a 3D CycleGAN\nframework for unsupervised translation of in vivo OCT to ex vivo confocal\nmicroscopy images. Applied to our OCT2Confocal dataset, this framework\neffectively translates between 3D medical data domains, capturing vascular,\ntextural, and cellular details with precision. This marks the first attempt to\nexploit the inherent 3D information of OCT and translate it into the rich,\ndetailed color domain of confocal microscopy. Assessed through quantitative and\nqualitative metrics, the 3D CycleGAN framework demonstrates commendable image\nfidelity and quality, outperforming existing methods despite the constraints of\nlimited data. This non-invasive generation of retinal confocal images has the\npotential to further enhance diagnostic and monitoring capabilities in\nophthalmology.\n","authors":["Xin Tian","Nantheera Anantrasirichai","Lindsay Nicholson","Alin Achim"],"pdf_url":"https://arxiv.org/pdf/2311.10902v2.pdf","comment":"4pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.15415v1","updated":"2023-11-26T20:44:09Z","published":"2023-11-26T20:44:09Z","title":"GAN-Based LiDAR Intensity Simulation","summary":"  Realistic vehicle sensor simulation is an important element in developing\nautonomous driving. As physics-based implementations of visual sensors like\nLiDAR are complex in practice, data-based approaches promise solutions. Using\npairs of camera images and LiDAR scans from real test drives, GANs can be\ntrained to translate between them. For this process, we contribute two\nadditions. First, we exploit the camera images, acquiring segmentation data and\ndense depth maps as additional input for training. Second, we test the\nperformance of the LiDAR simulation by testing how well an object detection\nnetwork generalizes between real and synthetic point clouds to enable\nevaluation without ground truth point clouds. Combining both, we simulate LiDAR\npoint clouds and demonstrate their realism.\n","authors":["Richard Marcus","Felix Gabel","Niklas Knoop","Marc Stamminger"],"pdf_url":"https://arxiv.org/pdf/2311.15415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15414v1","updated":"2023-11-26T20:35:19Z","published":"2023-11-26T20:35:19Z","title":"KOPPA: Improving Prompt-based Continual Learning with Key-Query\n  Orthogonal Projection and Prototype-based One-Versus-All","summary":"  Drawing inspiration from prompt tuning techniques applied to Large Language\nModels, recent methods based on pre-trained ViT networks have achieved\nremarkable results in the field of Continual Learning. Specifically, these\napproaches propose to maintain a set of prompts and allocate a subset of them\nto learn each task using a key-query matching strategy. However, they may\nencounter limitations when lacking control over the correlations between old\ntask queries and keys of future tasks, the shift of features in the latent\nspace, and the relative separation of latent vectors learned in independent\ntasks. In this work, we introduce a novel key-query learning strategy based on\northogonal projection, inspired by model-agnostic meta-learning, to enhance\nprompt matching efficiency and address the challenge of shifting features.\nFurthermore, we introduce a One-Versus-All (OVA) prototype-based component that\nenhances the classification head distinction. Experimental results on benchmark\ndatasets demonstrate that our method empowers the model to achieve results\nsurpassing those of current state-of-the-art approaches by a large margin of up\nto 20%.\n","authors":["Quyen Tran","Lam Tran","Khoat Than","Toan Tran","Dinh Phung","Trung Le"],"pdf_url":"https://arxiv.org/pdf/2311.15414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15395v1","updated":"2023-11-26T19:31:52Z","published":"2023-11-26T19:31:52Z","title":"ConstraintMatch for Semi-constrained Clustering","summary":"  Constrained clustering allows the training of classification models using\npairwise constraints only, which are weak and relatively easy to mine, while\nstill yielding full-supervision-level model performance. While they perform\nwell even in the absence of the true underlying class labels, constrained\nclustering models still require large amounts of binary constraint annotations\nfor training. In this paper, we propose a semi-supervised context whereby a\nlarge amount of \\textit{unconstrained} data is available alongside a smaller\nset of constraints, and propose \\textit{ConstraintMatch} to leverage such\nunconstrained data. While a great deal of progress has been made in\nsemi-supervised learning using full labels, there are a number of challenges\nthat prevent a naive application of the resulting methods in the\nconstraint-based label setting. Therefore, we reason about and analyze these\nchallenges, specifically 1) proposing a \\textit{pseudo-constraining} mechanism\nto overcome the confirmation bias, a major weakness of pseudo-labeling, 2)\ndeveloping new methods for pseudo-labeling towards the selection of\n\\textit{informative} unconstrained samples, 3) showing that this also allows\nthe use of pairwise loss functions for the initial and auxiliary losses which\nfacilitates semi-constrained model training. In extensive experiments, we\ndemonstrate the effectiveness of ConstraintMatch over relevant baselines in\nboth the regular clustering and overclustering scenarios on five challenging\nbenchmarks and provide analyses of its several components.\n","authors":["Jann Goschenhofer","Bernd Bischl","Zsolt Kira"],"pdf_url":"https://arxiv.org/pdf/2311.15395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15383v1","updated":"2023-11-26T19:01:14Z","published":"2023-11-26T19:01:14Z","title":"Visual Programming for Zero-shot Open-Vocabulary 3D Visual Grounding","summary":"  3D Visual Grounding (3DVG) aims at localizing 3D object based on textual\ndescriptions. Conventional supervised methods for 3DVG often necessitate\nextensive annotations and a predefined vocabulary, which can be restrictive. To\naddress this issue, we propose a novel visual programming approach for\nzero-shot open-vocabulary 3DVG, leveraging the capabilities of large language\nmodels (LLMs). Our approach begins with a unique dialog-based method, engaging\nwith LLMs to establish a foundational understanding of zero-shot 3DVG. Building\non this, we design a visual program that consists of three types of modules,\ni.e., view-independent, view-dependent, and functional modules. These modules,\nspecifically tailored for 3D scenarios, work collaboratively to perform complex\nreasoning and inference. Furthermore, we develop an innovative language-object\ncorrelation module to extend the scope of existing 3D object detectors into\nopen-vocabulary scenarios. Extensive experiments demonstrate that our zero-shot\napproach can outperform some supervised baselines, marking a significant stride\ntowards effective 3DVG.\n","authors":["Zhihao Yuan","Jinke Ren","Chun-Mei Feng","Hengshuang Zhao","Shuguang Cui","Zhen Li"],"pdf_url":"https://arxiv.org/pdf/2311.15383v1.pdf","comment":"Under review, project website: https://curryyuan.github.io/ZSVG3D/"},{"id":"http://arxiv.org/abs/2309.17338v2","updated":"2023-11-26T18:53:50Z","published":"2023-09-29T15:48:35Z","title":"Improving Trajectory Prediction in Dynamic Multi-Agent Environment by\n  Dropping Waypoints","summary":"  The inherently diverse and uncertain nature of trajectories presents a\nformidable challenge in accurately modeling them. Motion prediction systems\nmust effectively learn spatial and temporal information from the past to\nforecast the future trajectories of the agent. Many existing methods learn\ntemporal motion via separate components within stacked models to capture\ntemporal features. Furthermore, prediction methods often operate under the\nassumption that observed trajectory waypoint sequences are complete,\ndisregarding scenarios where missing values may occur, which can influence\ntheir performance. Moreover, these models may be biased toward particular\nwaypoint sequences when making predictions. We propose a novel approach called\nTemporal Waypoint Dropping (TWD) that explicitly incorporates temporal\ndependencies during the training of a trajectory prediction model. By\nstochastically dropping waypoints from past observed trajectories, the model is\nforced to learn the underlying temporal representation from the remaining\nwaypoints, resulting in an improved model. Incorporating stochastic temporal\nwaypoint dropping into the model learning process significantly enhances its\nperformance in scenarios with missing values. Experimental results demonstrate\nour approach's substantial improvement in trajectory prediction capabilities.\nOur approach can complement existing trajectory prediction methods to improve\ntheir prediction accuracy. We evaluate our proposed approach on three datasets:\nNBA Sports VU, ETH-UCY, and TrajNet++.\n","authors":["Pranav Singh Chib","Pravendra Singh"],"pdf_url":"https://arxiv.org/pdf/2309.17338v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2311.15369v1","updated":"2023-11-26T17:48:53Z","published":"2023-11-26T17:48:53Z","title":"TD-Net: A Tri-domain network for sparse-view CT reconstruction","summary":"  Sparse-view CT reconstruction, aimed at reducing X-ray radiation risks,\nfrequently suffers from image quality degradation, manifested as noise and\nartifacts. Existing post-processing and dual-domain techniques, although\neffective in radiation reduction, often lead to over-smoothed results,\ncompromising diagnostic clarity. Addressing this, we introduce TD-Net, a\npioneering tri-domain approach that unifies sinogram, image, and frequency\ndomain optimizations. By incorporating Frequency Supervision Module(FSM),\nTD-Net adeptly preserves intricate details, overcoming the prevalent\nover-smoothing issue. Extensive evaluations demonstrate TD-Net's superior\nperformance in reconstructing high-quality CT images from sparse views,\nefficiently balancing radiation safety and image fidelity. The enhanced\ncapabilities of TD-Net in varied noise scenarios highlight its potential as a\nbreakthrough in medical imaging.\n","authors":["Xinyuan Wang","Changqing Su","Bo Xiong"],"pdf_url":"https://arxiv.org/pdf/2311.15369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15368v1","updated":"2023-11-26T17:48:48Z","published":"2023-11-26T17:48:48Z","title":"Flow-Guided Diffusion for Video Inpainting","summary":"  Video inpainting has been challenged by complex scenarios like large\nmovements and low-light conditions. Current methods, including emerging\ndiffusion models, face limitations in quality and efficiency. This paper\nintroduces the Flow-Guided Diffusion model for Video Inpainting (FGDVI), a\nnovel approach that significantly enhances temporal consistency and inpainting\nquality via reusing an off-the-shelf image generation diffusion model. We\nemploy optical flow for precise one-step latent propagation and introduces a\nmodel-agnostic flow-guided latent interpolation technique. This technique\nexpedites denoising, seamlessly integrating with any Video Diffusion Model\n(VDM) without additional training. Our FGDVI demonstrates a remarkable 10%\nimprovement in flow warping error E_warp over existing state-of-the-art\nmethods. Our comprehensive experiments validate superior performance of FGDVI,\noffering a promising direction for advanced video inpainting. The code and\ndetailed results will be publicly available in\nhttps://github.com/NevSNev/FGDVI.\n","authors":["Bohai Gu","Yongsheng Yu","Heng Fan","Libo Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.15368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15367v1","updated":"2023-11-26T17:47:57Z","published":"2023-11-26T17:47:57Z","title":"BatchNorm-based Weakly Supervised Video Anomaly Detection","summary":"  In weakly supervised video anomaly detection (WVAD), where only video-level\nlabels indicating the presence or absence of abnormal events are available, the\nprimary challenge arises from the inherent ambiguity in temporal annotations of\nabnormal occurrences. Inspired by the statistical insight that temporal\nfeatures of abnormal events often exhibit outlier characteristics, we propose a\nnovel method, BN-WVAD, which incorporates BatchNorm into WVAD. In the proposed\nBN-WVAD, we leverage the Divergence of Feature from Mean vector (DFM) of\nBatchNorm as a reliable abnormality criterion to discern potential abnormal\nsnippets in abnormal videos. The proposed DFM criterion is also discriminative\nfor anomaly recognition and more resilient to label noise, serving as the\nadditional anomaly score to amend the prediction of the anomaly classifier that\nis susceptible to noisy labels. Moreover, a batch-level selection strategy is\ndevised to filter more abnormal snippets in videos where more abnormal events\noccur. The proposed BN-WVAD model demonstrates state-of-the-art performance on\nUCF-Crime with an AUC of 87.24%, and XD-Violence, where AP reaches up to\n84.93%. Our code implementation is accessible at\nhttps://github.com/cool-xuan/BN-WVAD.\n","authors":["Yixuan Zhou","Yi Qu","Xing Xu","Fumin Shen","Jingkuan Song","Hengtao Shen"],"pdf_url":"https://arxiv.org/pdf/2311.15367v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15361v1","updated":"2023-11-26T17:27:26Z","published":"2023-11-26T17:27:26Z","title":"Ultra-Range Gesture Recognition using an RGB Camera in Human-Robot\n  Interaction","summary":"  Hand gestures play a significant role in human interactions where non-verbal\nintentions, thoughts and commands are conveyed. In Human-Robot Interaction\n(HRI), hand gestures offer a similar and efficient medium for conveying clear\nand rapid directives to a robotic agent. However, state-of-the-art vision-based\nmethods for gesture recognition have been shown to be effective only up to a\nuser-camera distance of seven meters. Such a short distance range limits\npractical HRI with, for example, service robots, search and rescue robots and\ndrones. In this work, we address the Ultra-Range Gesture Recognition (URGR)\nproblem by aiming for a recognition distance of up to 25 meters and in the\ncontext of HRI. We propose a novel deep-learning framework for URGR using\nsolely a simple RGB camera. First, a novel super-resolution model termed HQ-Net\nis used to enhance the low-resolution image of the user. Then, we propose a\nnovel URGR classifier termed Graph Vision Transformer (GViT) which takes the\nenhanced image as input. GViT combines the benefits of a Graph Convolutional\nNetwork (GCN) and a modified Vision Transformer (ViT). Evaluation of the\nproposed framework over diverse test data yields a high recognition rate of\n98.1%. The framework has also exhibited superior performance compared to human\nrecognition in ultra-range distances. With the framework, we analyze and\ndemonstrate the performance of an autonomous quadruped robot directed by human\ngestures in complex ultra-range indoor and outdoor environments.\n","authors":["Eran Bamani","Eden Nissinman","Inbar Meir","Lisa Koenigsberg","Avishai Sintov"],"pdf_url":"https://arxiv.org/pdf/2311.15361v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.08946v5","updated":"2023-11-26T17:26:35Z","published":"2023-05-15T18:35:47Z","title":"Image Matching by Bare Homography","summary":"  This paper presents Slime, a novel non-deep image matching framework which\nmodels the scene as rough local overlapping planes. This intermediate\nrepresentation sits in-between the local affine approximation of the keypoint\npatches and the global matching based on both spatial and similarity\nconstraints, providing a progressive pruning of the correspondences, as planes\nare easier to handle with respect to general scenes.\n  Slime decomposes the images into overlapping regions at different scales and\ncomputes loose planar homographies. Planes are mutually extended by compatible\nmatches and the images are split into fixed tiles, with only the best\nhomographies retained for each pair of tiles. Stable matches are identified\naccording to the consensus of the admissible stereo configurations provided by\npairwise homographies. Within tiles, the rough planes are then merged according\nto their overlap in terms of matches and further consistent correspondences are\nextracted.\n  The whole process only involves homography constraints. As a result, both the\ncoverage and the stability of correct matches over the scene are amplified,\ntogether with the ability to spot matches in challenging scenes, allowing\ntraditional hybrid matching pipelines to make up lost ground against recent\nend-to-end deep matching methods.\n  In addition, the paper gives a thorough comparative analysis of recent\nstate-of-the-art in image matching represented by end-to-end deep networks and\nhybrid pipelines. The evaluation considers both planar and non-planar scenes,\ntaking into account critical and challenging scenarios including abrupt\ntemporal image changes and strong variations in relative image rotations.\nAccording to this analysis, although the impressive progress done in this\nfield, there is still a wide room for improvements to be investigated in future\nresearch.\n","authors":["Fabio Bellavia"],"pdf_url":"https://arxiv.org/pdf/2305.08946v5.pdf","comment":"major revision update - added results on EVD and WxBS"},{"id":"http://arxiv.org/abs/2311.15356v1","updated":"2023-11-26T17:17:28Z","published":"2023-11-26T17:17:28Z","title":"Having Second Thoughts? Let's hear it","summary":"  Deep learning models loosely mimic bottom-up signal pathways from low-order\nsensory areas to high-order cognitive areas. After training, DL models can\noutperform humans on some domain-specific tasks, but their decision-making\nprocess has been known to be easily disrupted. Since the human brain consists\nof multiple functional areas highly connected to one another and relies on\nintricate interplays between bottom-up and top-down (from high-order to\nlow-order areas) processing, we hypothesize that incorporating top-down signal\nprocessing may make DL models more robust. To address this hypothesis, we\npropose a certification process mimicking selective attention and test if it\ncould make DL models more robust. Our empirical evaluations suggest that this\nnewly proposed certification can improve DL models' accuracy and help us build\nsafety measures to alleviate their vulnerabilities with both artificial and\nnatural adversarial examples.\n","authors":["Jung H. Lee","Sujith Vijayan"],"pdf_url":"https://arxiv.org/pdf/2311.15356v1.pdf","comment":"13 pages, 11 figures, 1 table, 2 supplementary tables and 1\n  supplementary figure"},{"id":"http://arxiv.org/abs/2311.15339v1","updated":"2023-11-26T15:50:19Z","published":"2023-11-26T15:50:19Z","title":"Adversarial Purification of Information Masking","summary":"  Adversarial attacks meticulously generate minuscule, imperceptible\nperturbations to images to deceive neural networks. Counteracting these,\nadversarial purification methods seek to transform adversarial input samples\ninto clean output images to defend against adversarial attacks. Nonetheless,\nextent generative models fail to effectively eliminate adversarial\nperturbations, yielding less-than-ideal purification results. We emphasize the\npotential threat of residual adversarial perturbations to target models,\nquantitatively establishing a relationship between perturbation scale and\nattack capability. Notably, the residual perturbations on the purified image\nprimarily stem from the same-position patch and similar patches of the\nadversarial sample. We propose a novel adversarial purification approach named\nInformation Mask Purification (IMPure), aims to extensively eliminate\nadversarial perturbations. To obtain an adversarial sample, we first mask part\nof the patches information, then reconstruct the patches to resist adversarial\nperturbations from the patches. We reconstruct all patches in parallel to\nobtain a cohesive image. Then, in order to protect the purified samples against\npotential similar regional perturbations, we simulate this risk by randomly\nmixing the purified samples with the input samples before inputting them into\nthe feature extraction network. Finally, we establish a combined constraint of\npixel loss and perceptual loss to augment the model's reconstruction\nadaptability. Extensive experiments on the ImageNet dataset with three\nclassifier models demonstrate that our approach achieves state-of-the-art\nresults against nine adversarial attack methods. Implementation code and\npre-trained weights can be accessed at\n\\textcolor{blue}{https://github.com/NoWindButRain/IMPure}.\n","authors":["Sitong Liu","Zhichao Lian","Shuangquan Zhang","Liang Xiao"],"pdf_url":"https://arxiv.org/pdf/2311.15339v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15335v1","updated":"2023-11-26T15:39:57Z","published":"2023-11-26T15:39:57Z","title":"Token Recycling for Efficient Sequential Inference with Vision\n  Transformers","summary":"  Vision Transformers (ViTs) overpass Convolutional Neural Networks in\nprocessing incomplete inputs because they do not require the imputation of\nmissing values. Therefore, ViTs are well suited for sequential decision-making,\ne.g. in the Active Visual Exploration problem. However, they are\ncomputationally inefficient because they perform a full forward pass each time\na piece of new sequential information arrives.\n  To reduce this computational inefficiency, we introduce the TOken REcycling\n(TORE) modification for the ViT inference, which can be used with any\narchitecture. TORE divides ViT into two parts, iterator and aggregator. An\niterator processes sequential information separately into midway tokens, which\nare cached. The aggregator processes midway tokens jointly to obtain the\nprediction. This way, we can reuse the results of computations made by\niterator.\n  Except for efficient sequential inference, we propose a complementary\ntraining policy, which significantly reduces the computational burden\nassociated with sequential decision-making while achieving state-of-the-art\naccuracy.\n","authors":["Jan Olszewski","Dawid Rymarczyk","Piotr Wójcik","Mateusz Pach","Bartosz Zieliński"],"pdf_url":"https://arxiv.org/pdf/2311.15335v1.pdf","comment":"The code will be released upon acceptance"},{"id":"http://arxiv.org/abs/2311.15332v1","updated":"2023-11-26T15:34:36Z","published":"2023-11-26T15:34:36Z","title":"ASI: Accuracy-Stability Index for Evaluating Deep Learning Models","summary":"  In the context of deep learning research, where model introductions\ncontinually occur, the need for effective and efficient evaluation remains\nparamount. Existing methods often emphasize accuracy metrics, overlooking\nstability. To address this, the paper introduces the Accuracy-Stability Index\n(ASI), a quantitative measure incorporating both accuracy and stability for\nassessing deep learning models. Experimental results demonstrate the\napplication of ASI, and a 3D surface model is presented for visualizing ASI,\nmean accuracy, and coefficient of variation. This paper addresses the important\nissue of quantitative benchmarking metrics for deep learning models, providing\na new approach for accurately evaluating accuracy and stability of deep\nlearning models. The paper concludes with discussions on potential weaknesses\nand outlines future research directions.\n","authors":["Wei Dai","Daniel Berleant"],"pdf_url":"https://arxiv.org/pdf/2311.15332v1.pdf","comment":"6 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.15331v1","updated":"2023-11-26T15:31:51Z","published":"2023-11-26T15:31:51Z","title":"How much data do I need? A case study on medical data","summary":"  The collection of data to train a Deep Learning network is costly in terms of\neffort and resources. In many cases, especially in a medical context, it may\nhave detrimental impacts. Such as requiring invasive medical procedures or\nprocesses which could in themselves cause medical harm. However, Deep Learning\nis seen as a data hungry method. Here, we look at two commonly held adages i)\nmore data gives better results and ii) transfer learning will aid you when you\ndon't have enough data. These are widely assumed to be true and used as\nevidence for choosing how to solve a problem when Deep Learning is involved. We\nevaluate six medical datasets and six general datasets. Training a ResNet18\nnetwork on varying subsets of these datasets to evaluate `more data gives\nbetter results'. We take eleven of these datasets as the sources for Transfer\nLearning on subsets of the twelfth dataset -- Chest -- in order to determine\nwhether Transfer Learning is universally beneficial. We go further to see\nwhether multi-stage Transfer Learning provides a consistent benefit. Our\nanalysis shows that the real situation is more complex than these simple adages\n-- more data could lead to a case of diminishing returns and an incorrect\nchoice of dataset for transfer learning can lead to worse performance, with\ndatasets which we would consider highly similar to the Chest dataset giving\nworse results than datasets which are more dissimilar. Multi-stage transfer\nlearning likewise reveals complex relationships between datasets.\n","authors":["Ayse Betul Cengiz","A. Stephen McGough"],"pdf_url":"https://arxiv.org/pdf/2311.15331v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2309.04422v2","updated":"2023-11-26T15:25:11Z","published":"2023-09-08T16:33:27Z","title":"Video Task Decathlon: Unifying Image and Video Tasks in Autonomous\n  Driving","summary":"  Performing multiple heterogeneous visual tasks in dynamic scenes is a\nhallmark of human perception capability. Despite remarkable progress in image\nand video recognition via representation learning, current research still\nfocuses on designing specialized networks for singular, homogeneous, or simple\ncombination of tasks. We instead explore the construction of a unified model\nfor major image and video recognition tasks in autonomous driving with diverse\ninput and output structures. To enable such an investigation, we design a new\nchallenge, Video Task Decathlon (VTD), which includes ten representative image\nand video tasks spanning classification, segmentation, localization, and\nassociation of objects and pixels. On VTD, we develop our unified network,\nVTDNet, that uses a single structure and a single set of weights for all ten\ntasks. VTDNet groups similar tasks and employs task interaction stages to\nexchange information within and between task groups. Given the impracticality\nof labeling all tasks on all frames, and the performance degradation associated\nwith joint training of many tasks, we design a Curriculum training,\nPseudo-labeling, and Fine-tuning (CPF) scheme to successfully train VTDNet on\nall tasks and mitigate performance loss. Armed with CPF, VTDNet significantly\noutperforms its single-task counterparts on most tasks with only 20% overall\ncomputations. VTD is a promising new direction for exploring the unification of\nperception tasks in autonomous driving.\n","authors":["Thomas E. Huang","Yifan Liu","Luc Van Gool","Fisher Yu"],"pdf_url":"https://arxiv.org/pdf/2309.04422v2.pdf","comment":"ICCV 2023, project page at https://www.vis.xyz/pub/vtd"},{"id":"http://arxiv.org/abs/2311.15328v1","updated":"2023-11-26T15:13:13Z","published":"2023-11-26T15:13:13Z","title":"BS-Diff: Effective Bone Suppression Using Conditional Diffusion Models\n  from Chest X-Ray Images","summary":"  Chest X-rays (CXRs) are commonly utilized as a low-dose modality for lung\nscreening. Nonetheless, the efficacy of CXRs is somewhat impeded, given that\napproximately 75% of the lung area overlaps with bone, which in turn hampers\nthe detection and diagnosis of diseases. As a remedial measure, bone\nsuppression techniques have been introduced. The current dual-energy\nsubtraction imaging technique in the clinic requires costly equipment and\nsubjects being exposed to high radiation. To circumvent these issues, deep\nlearning-based image generation algorithms have been proposed. However,\nexisting methods fall short in terms of producing high-quality images and\ncapturing texture details, particularly with pulmonary vessels. To address\nthese issues, this paper proposes a new bone suppression framework, termed\nBS-Diff, that comprises a conditional diffusion model equipped with a U-Net\narchitecture and a simple enhancement module to incorporate an autoencoder. Our\nproposed network cannot only generate soft tissue images with a high bone\nsuppression rate but also possesses the capability to capture fine image\ndetails. Additionally, we compiled the largest dataset since 2010, including\ndata from 120 patients with high-definition, high-resolution paired CXRs and\nsoft tissue images collected by our affiliated hospital. Extensive experiments,\ncomparative analyses, ablation studies, and clinical evaluations indicate that\nthe proposed BS-Diff outperforms several bone-suppression models across\nmultiple metrics.\n","authors":["Zhanghao Chen","Yifei Sun","Wenjian Qin","Ruiquan Ge","Cheng Pan","Wenming Deng","Zhou Liu","Wenwen Min","Ahmed Elazab","Xiang Wan","Changmiao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.15328v1.pdf","comment":"5 pages, 2 figures"},{"id":"http://arxiv.org/abs/2311.15326v1","updated":"2023-11-26T15:01:00Z","published":"2023-11-26T15:01:00Z","title":"Lightweight Face Recognition: An Improved MobileFaceNet Model","summary":"  This paper presents an extensive exploration and comparative analysis of\nlightweight face recognition (FR) models, specifically focusing on\nMobileFaceNet and its modified variant, MMobileFaceNet. The need for efficient\nFR models on devices with limited computational resources has led to the\ndevelopment of models with reduced memory footprints and computational demands\nwithout sacrificing accuracy. Our research delves into the impact of dataset\nselection, model architecture, and optimization algorithms on the performance\nof FR models. We highlight our participation in the EFaR-2023 competition,\nwhere our models showcased exceptional performance, particularly in categories\nrestricted by the number of parameters. By employing a subset of the Webface42M\ndataset and integrating sharpness-aware minimization (SAM) optimization, we\nachieved significant improvements in accuracy across various benchmarks,\nincluding those that test for cross-pose, cross-age, and cross-ethnicity\nperformance. The results underscore the efficacy of our approach in crafting\nmodels that are not only computationally efficient but also maintain high\naccuracy in diverse conditions.\n","authors":["Ahmad Hassanpour","Yasamin Kowsari"],"pdf_url":"https://arxiv.org/pdf/2311.15326v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15308v1","updated":"2023-11-26T14:17:51Z","published":"2023-11-26T14:17:51Z","title":"AV-Deepfake1M: A Large-Scale LLM-Driven Audio-Visual Deepfake Dataset","summary":"  The detection and localization of highly realistic deepfake audio-visual\ncontent are challenging even for the most advanced state-of-the-art methods.\nWhile most of the research efforts in this domain are focused on detecting\nhigh-quality deepfake images and videos, only a few works address the problem\nof the localization of small segments of audio-visual manipulations embedded in\nreal videos. In this research, we emulate the process of such content\ngeneration and propose the AV-Deepfake1M dataset. The dataset contains\ncontent-driven (i) video manipulations, (ii) audio manipulations, and (iii)\naudio-visual manipulations for more than 2K subjects resulting in a total of\nmore than 1M videos. The paper provides a thorough description of the proposed\ndata generation pipeline accompanied by a rigorous analysis of the quality of\nthe generated data. The comprehensive benchmark of the proposed dataset\nutilizing state-of-the-art deepfake detection and localization methods\nindicates a significant drop in performance compared to previous datasets. The\nproposed dataset will play a vital role in building the next-generation\ndeepfake localization methods. The dataset and associated code are available at\nhttps://github.com/ControlNet/AV-Deepfake1M .\n","authors":["Zhixi Cai","Shreya Ghosh","Aman Pankaj Adatia","Munawar Hayat","Abhinav Dhall","Kalin Stefanov"],"pdf_url":"https://arxiv.org/pdf/2311.15308v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15306v1","updated":"2023-11-26T14:14:04Z","published":"2023-11-26T14:14:04Z","title":"Sketch Video Synthesis","summary":"  Understanding semantic intricacies and high-level concepts is essential in\nimage sketch generation, and this challenge becomes even more formidable when\napplied to the domain of videos. To address this, we propose a novel\noptimization-based framework for sketching videos represented by the frame-wise\nB\\'ezier curve. In detail, we first propose a cross-frame stroke initialization\napproach to warm up the location and the width of each curve. Then, we optimize\nthe locations of these curves by utilizing a semantic loss based on CLIP\nfeatures and a newly designed consistency loss using the self-decomposed 2D\natlas network. Built upon these design elements, the resulting sketch video\nshowcases impressive visual abstraction and temporal coherence. Furthermore, by\ntransforming a video into SVG lines through the sketching process, our method\nunlocks applications in sketch-based video editing and video doodling, enabled\nthrough video composition, as exemplified in the teaser.\n","authors":["Yudian Zheng","Xiaodong Cun","Menghan Xia","Chi-Man Pun"],"pdf_url":"https://arxiv.org/pdf/2311.15306v1.pdf","comment":"Webpage: https://sketchvideo.github.io/ Github:\n  https://github.com/yudianzheng/SketchVideo"},{"id":"http://arxiv.org/abs/2311.15301v1","updated":"2023-11-26T13:55:24Z","published":"2023-11-26T13:55:24Z","title":"Eye Disease Prediction using Ensemble Learning and Attention on OCT\n  Scans","summary":"  Eye diseases have posed significant challenges for decades, but advancements\nin technology have opened new avenues for their detection and treatment.\nMachine learning and deep learning algorithms have become instrumental in this\ndomain, particularly when combined with Optical Coherent Technology (OCT)\nimaging. We propose a novel method for efficient detection of eye diseases from\nOCT images. Our technique enables the classification of patients into disease\nfree (normal eyes) or affected by specific conditions such as Choroidal\nNeovascularization (CNV), Diabetic Macular Edema (DME), or Drusen. In this\nwork, we introduce an end to end web application that utilizes machine learning\nand deep learning techniques for efficient eye disease prediction. The\napplication allows patients to submit their raw OCT scanned images, which\nundergo segmentation using a trained custom UNet model. The segmented images\nare then fed into an ensemble model, comprising InceptionV3 and Xception\nnetworks, enhanced with a self attention layer. This self attention approach\nleverages the feature maps of individual models to achieve improved\nclassification accuracy. The ensemble model's output is aggregated to predict\nand classify various eye diseases. Extensive experimentation and optimization\nhave been conducted to ensure the application's efficiency and optimal\nperformance. Our results demonstrate the effectiveness of the proposed approach\nin accurate eye disease prediction. The developed web application holds\nsignificant potential for early detection and timely intervention, thereby\ncontributing to improved eye healthcare outcomes.\n","authors":["Gauri Naik","Nandini Narvekar","Dimple Agarwal","Nishita Nandanwar","Himangi Pande"],"pdf_url":"https://arxiv.org/pdf/2311.15301v1.pdf","comment":"Full paper accepted at FICC (Springer) 2024"},{"id":"http://arxiv.org/abs/2311.15291v1","updated":"2023-11-26T13:15:37Z","published":"2023-11-26T13:15:37Z","title":"Obj-NeRF: Extract Object NeRFs from Multi-view Images","summary":"  Neural Radiance Fields (NeRFs) have demonstrated remarkable effectiveness in\nnovel view synthesis within 3D environments. However, extracting a radiance\nfield of one specific object from multi-view images encounters substantial\nchallenges due to occlusion and background complexity, thereby presenting\ndifficulties in downstream applications such as NeRF editing and 3D mesh\nextraction. To solve this problem, in this paper, we propose Obj-NeRF, a\ncomprehensive pipeline that recovers the 3D geometry of a specific object from\nmulti-view images using a single prompt. This method combines the 2D\nsegmentation capabilities of the Segment Anything Model (SAM) in conjunction\nwith the 3D reconstruction ability of NeRF. Specifically, we first obtain\nmulti-view segmentation for the indicated object using SAM with a single\nprompt. Then, we use the segmentation images to supervise NeRF construction,\nintegrating several effective techniques. Additionally, we construct a large\nobject-level NeRF dataset containing diverse objects, which can be useful in\nvarious downstream tasks. To demonstrate the practicality of our method, we\nalso apply Obj-NeRF to various applications, including object removal,\nrotation, replacement, and recoloring.\n","authors":["Zhiyi Li","Lihe Ding","Tianfan Xue"],"pdf_url":"https://arxiv.org/pdf/2311.15291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.10829v6","updated":"2023-11-26T12:43:30Z","published":"2023-07-10T12:18:18Z","title":"Exact Diffusion Inversion via Bi-directional Integration Approximation","summary":"  Recently, various methods have been proposed to address the inconsistency\nissue of DDIM inversion to enable image editing, such as EDICT [36] and\nNull-text inversion [22]. However, the above methods introduce considerable\ncomputational overhead. In this paper, we propose a new technique, named\n\\emph{bi-directional integration approximation} (BDIA), to perform exact\ndiffusion inversion with neglible computational overhead. Suppose we would like\nto estimate the next diffusion state $\\boldsymbol{z}_{i-1}$ at timestep $t_i$\nwith the historical information $(i,\\boldsymbol{z}_i)$ and\n$(i+1,\\boldsymbol{z}_{i+1})$. We first obtain the estimated Gaussian noise\n$\\hat{\\boldsymbol{\\epsilon}}(\\boldsymbol{z}_i,i)$, and then apply the DDIM\nupdate procedure twice for approximating the ODE integration over the next\ntime-slot $[t_i, t_{i-1}]$ in the forward manner and the previous time-slot\n$[t_i, t_{t+1}]$ in the backward manner. The DDIM step for the previous\ntime-slot is used to refine the integration approximation made earlier when\ncomputing $\\boldsymbol{z}_i$. A nice property of BDIA-DDIM is that the update\nexpression for $\\boldsymbol{z}_{i-1}$ is a linear combination of\n$(\\boldsymbol{z}_{i+1}, \\boldsymbol{z}_i,\n\\hat{\\boldsymbol{\\epsilon}}(\\boldsymbol{z}_i,i))$. This allows for exact\nbackward computation of $\\boldsymbol{z}_{i+1}$ given $(\\boldsymbol{z}_i,\n\\boldsymbol{z}_{i-1})$, thus leading to exact diffusion inversion. It is\ndemonstrated with experiments that (round-trip) BDIA-DDIM is particularly\neffective for image editing. Our experiments further show that BDIA-DDIM\nproduces markedly better image sampling qualities than DDIM for text-to-image\ngeneration.\n  BDIA can also be applied to improve the performance of other ODE solvers in\naddition to DDIM. In our work, it is found that applying BDIA to the EDM\nsampling procedure produces consistently better performance over four\npre-trained models.\n","authors":["Guoqiang Zhang","J. P. Lewis","W. Bastiaan Kleijn"],"pdf_url":"https://arxiv.org/pdf/2307.10829v6.pdf","comment":"arXiv admin note: text overlap with arXiv:2304.11328. Our code is\n  available at https://github.com/guoqiang-zhang-x/BDIA"},{"id":"http://arxiv.org/abs/2311.09680v3","updated":"2023-11-26T12:39:30Z","published":"2023-11-16T08:49:46Z","title":"Trustworthy Large Models in Vision: A Survey","summary":"  The rapid progress of Large Models (LMs) has recently revolutionized various\nfields of deep learning with remarkable grades, ranging from Natural Language\nProcessing (NLP) to Computer Vision (CV). However, LMs are increasingly\nchallenged and criticized by academia and industry due to their powerful\nperformance but untrustworthy behavior, which urgently needs to be alleviated\nby reliable methods. Despite the abundance of literature on trustworthy LMs in\nNLP, a systematic survey specifically delving into the trustworthiness of LMs\nin CV remains absent. In order to mitigate this gap, we summarize four relevant\nconcerns that obstruct the trustworthy usage in vision of LMs in this survey,\nincluding 1) human misuse, 2) vulnerability, 3) inherent issue and 4)\ninterpretability. By highlighting corresponding challenge, countermeasures, and\ndiscussion in each topic, we hope this survey will facilitate readers'\nunderstanding of this field, promote alignment of LMs with human expectations\nand enable trustworthy LMs to serve as welfare rather than disaster for human\nsociety.\n","authors":["Ziyan Guo","Li Xu","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2311.09680v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15276v1","updated":"2023-11-26T12:36:05Z","published":"2023-11-26T12:36:05Z","title":"Efficient Rehearsal Free Zero Forgetting Continual Learning using\n  Adaptive Weight Modulation","summary":"  Artificial neural networks encounter a notable challenge known as continual\nlearning, which involves acquiring knowledge of multiple tasks over an extended\nperiod. This challenge arises due to the tendency of previously learned weights\nto be adjusted to suit the objectives of new tasks, resulting in a phenomenon\ncalled catastrophic forgetting. Most approaches to this problem seek a balance\nbetween maximizing performance on the new tasks and minimizing the forgetting\nof previous tasks. In contrast, our approach attempts to maximize the\nperformance of the new task, while ensuring zero forgetting. This is\naccomplished by creating a task-specific modulation parameters for each task.\nOnly these would be learnable parameters during learning of consecutive tasks.\nThrough comprehensive experimental evaluations, our model demonstrates superior\nperformance in acquiring and retaining novel tasks that pose difficulties for\nother multi-task models. This emphasizes the efficacy of our approach in\npreventing catastrophic forgetting while accommodating the acquisition of new\ntasks\n","authors":["Yonatan Sverdlov","Shimon Ullman"],"pdf_url":"https://arxiv.org/pdf/2311.15276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11587v2","updated":"2023-11-26T12:27:27Z","published":"2023-11-20T07:54:54Z","title":"AKConv: Convolutional Kernel with Arbitrary Sampled Shapes and Arbitrary\n  Number of Parameters","summary":"  Neural networks based on convolutional operations have achieved remarkable\nresults in the field of deep learning, but there are two inherent flaws in\nstandard convolutional operations. On the one hand, the convolution operation\nbe confined to a local window and cannot capture information from other\nlocations, and its sampled shapes is fixed. On the other hand, the size of the\nconvolutional kernel is fixed to k $\\times$ k, which is a fixed square shape,\nand the number of parameters tends to grow squarely with size. It is obvious\nthat the shape and size of targets are various in different datasets and at\ndifferent locations. Convolutional kernels with fixed sample shapes and squares\ndo not adapt well to changing targets. In response to the above questions, the\nAlterable Kernel Convolution (AKConv) is explored in this work, which gives the\nconvolution kernel an arbitrary number of parameters and arbitrary sampled\nshapes to provide richer options for the trade-off between network overhead and\nperformance. In AKConv, we define initial positions for convolutional kernels\nof arbitrary size by means of a new coordinate generation algorithm. To adapt\nto changes for targets, we introduce offsets to adjust the shape of the samples\nat each position. Moreover, we explore the effect of the neural network by\nusing the AKConv with the same size and different initial sampled shapes.\nAKConv completes the process of efficient feature extraction by irregular\nconvolutional operations and brings more exploration options for convolutional\nsampling shapes. Object detection experiments on representative datasets\nCOCO2017, VOC 7+12 and VisDrone-DET2021 fully demonstrate the advantages of\nAKConv. AKConv can be used as a plug-and-play convolutional operation to\nreplace convolutional operations to improve network performance. The code for\nthe relevant tasks can be found at https://github.com/CV-ZhangXin/AKConv.\n","authors":["Xin Zhang","Yingze Song","Tingting Song","Degang Yang","Yichen Ye","Jie Zhou","Liming Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.11587v2.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.15273v1","updated":"2023-11-26T12:01:50Z","published":"2023-11-26T12:01:50Z","title":"An Intelligent-Detection Network for Handwritten Mathematical Expression\n  Recognition","summary":"  The use of artificial intelligence technology in education is growing\nrapidly, with increasing attention being paid to handwritten mathematical\nexpression recognition (HMER) by researchers. However, many existing methods\nfor HMER may fail to accurately read formulas with complex structures, as the\nattention results can be inaccurate due to illegible handwriting or large\nvariations in writing styles. Our proposed Intelligent-Detection Network (IDN)\nfor HMER differs from traditional encoder-decoder methods by utilizing object\ndetection techniques. Specifically, we have developed an enhanced YOLOv7\nnetwork that can accurately detect both digital and symbolic objects. The\ndetection results are then integrated into the bidirectional gated recurrent\nunit (BiGRU) and the baseline symbol relationship tree (BSRT) to determine the\nrelationships between symbols and numbers. The experiments demonstrate that the\nproposed method outperforms those encoder-decoder networks in recognizing\ncomplex handwritten mathematical expressions. This is due to the precise\ndetection of symbols and numbers. Our research has the potential to make\nvaluable contributions to the field of HMER. This could be applied in various\npractical scenarios, such as assignment grading in schools and information\nentry of paper documents.\n","authors":["Ziqi Ye"],"pdf_url":"https://arxiv.org/pdf/2311.15273v1.pdf","comment":"6 pages, 5figures, 31st International Conference on Computers in\n  Education"},{"id":"http://arxiv.org/abs/2204.05859v4","updated":"2023-11-26T10:44:43Z","published":"2022-04-12T14:59:48Z","title":"Bootstrap Motion Forecasting With Self-Consistent Constraints","summary":"  We present a novel framework to bootstrap Motion forecasting with\nSelf-consistent Constraints (MISC). The motion forecasting task aims at\npredicting future trajectories of vehicles by incorporating spatial and\ntemporal information from the past. A key design of MISC is the proposed Dual\nConsistency Constraints that regularize the predicted trajectories under\nspatial and temporal perturbation during training. Also, to model the\nmulti-modality in motion forecasting, we design a novel self-ensembling scheme\nto obtain accurate teacher targets to enforce the self-constraints with\nmulti-modality supervision. With explicit constraints from multiple teacher\ntargets, we observe a clear improvement in the prediction performance.\nExtensive experiments on the Argoverse motion forecasting benchmark and Waymo\nOpen Motion dataset show that MISC significantly outperforms the\nstate-of-the-art methods. As the proposed strategies are general and can be\neasily incorporated into other motion forecasting approaches, we also\ndemonstrate that our proposed scheme consistently improves the prediction\nperformance of several existing methods.\n","authors":["Maosheng Ye","Jiamiao Xu","Xunnong Xu","Tengfei Wang","Tongyi Cao","Qifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2204.05859v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15264v1","updated":"2023-11-26T10:38:47Z","published":"2023-11-26T10:38:47Z","title":"ChAda-ViT : Channel Adaptive Attention for Joint Representation Learning\n  of Heterogeneous Microscopy Images","summary":"  Unlike color photography images, which are consistently encoded into RGB\nchannels, biological images encompass various modalities, where the type of\nmicroscopy and the meaning of each channel varies with each experiment.\nImportantly, the number of channels can range from one to a dozen and their\ncorrelation is often comparatively much lower than RGB, as each of them brings\nspecific information content. This aspect is largely overlooked by methods\ndesigned out of the bioimage field, and current solutions mostly focus on\nintra-channel spatial attention, often ignoring the relationship between\nchannels, yet crucial in most biological applications. Importantly, the\nvariable channel type and count prevent the projection of several experiments\nto a unified representation for large scale pre-training. In this study, we\npropose ChAda-ViT, a novel Channel Adaptive Vision Transformer architecture\nemploying an Inter-Channel Attention mechanism on images with an arbitrary\nnumber, order and type of channels. We also introduce IDRCell100k, a bioimage\ndataset with a rich set of 79 experiments covering 7 microscope modalities,\nwith a multitude of channel types, and channel counts varying from 1 to 10 per\nexperiment. Our proposed architecture, trained in a self-supervised manner,\noutperforms existing approaches in several biologically relevant downstream\ntasks. Additionally, it can be used to bridge the gap for the first time\nbetween assays with different microscopes, channel numbers or types by\nembedding various image and experimental modalities into a unified biological\nimage representation. The latter should facilitate interdisciplinary studies\nand pave the way for better adoption of deep learning in biological image-based\nanalyses. Code and Data to be released soon.\n","authors":["Nicolas Bourriez","Ihab Bendidi","Ethan Cohen","Gabriel Watkinson","Maxime Sanchez","Guillaume Bollot","Auguste Genovesio"],"pdf_url":"https://arxiv.org/pdf/2311.15264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15262v1","updated":"2023-11-26T10:33:36Z","published":"2023-11-26T10:33:36Z","title":"Revealing Cortical Layers In Histological Brain Images With\n  Self-Supervised Graph Convolutional Networks Applied To Cell-Graphs","summary":"  Identifying cerebral cortex layers is crucial for comparative studies of the\ncytoarchitecture aiming at providing insights into the relations between brain\nstructure and function across species. The absence of extensive annotated\ndatasets typically limits the adoption of machine learning approaches, leading\nto the manual delineation of cortical layers by neuroanatomists. We introduce a\nself-supervised approach to detect layers in 2D Nissl-stained histological\nslices of the cerebral cortex. It starts with the segmentation of individual\ncells and the creation of an attributed cell-graph. A self-supervised graph\nconvolutional network generates cell embeddings that encode morphological and\nstructural traits of the cellular environment and are exploited by a community\ndetection algorithm for the final layering. Our method, the first\nself-supervised of its kind with no spatial transcriptomics data involved,\nholds the potential to accelerate cytoarchitecture analyses, sidestepping\nannotation needs and advancing cross-species investigation.\n","authors":["Valentina Vadori","Antonella Peruffo","Jean-Marie Graïc","Giulia Vadori","Livio Finos","Enrico Grisan"],"pdf_url":"https://arxiv.org/pdf/2311.15262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.07187v3","updated":"2023-11-26T10:32:54Z","published":"2023-07-14T06:42:21Z","title":"Erasing, Transforming, and Noising Defense Network for Occluded Person\n  Re-Identification","summary":"  Occlusion perturbation presents a significant challenge in person\nre-identification (re-ID), and existing methods that rely on external visual\ncues require additional computational resources and only consider the issue of\nmissing information caused by occlusion. In this paper, we propose a simple yet\neffective framework, termed Erasing, Transforming, and Noising Defense Network\n(ETNDNet), which treats occlusion as a noise disturbance and solves occluded\nperson re-ID from the perspective of adversarial defense. In the proposed\nETNDNet, we introduce three strategies: Firstly, we randomly erase the feature\nmap to create an adversarial representation with incomplete information,\nenabling adversarial learning of identity loss to protect the re-ID system from\nthe disturbance of missing information. Secondly, we introduce random\ntransformations to simulate the position misalignment caused by occlusion,\ntraining the extractor and classifier adversarially to learn robust\nrepresentations immune to misaligned information. Thirdly, we perturb the\nfeature map with random values to address noisy information introduced by\nobstacles and non-target pedestrians, and employ adversarial gaming in the\nre-ID system to enhance its resistance to occlusion noise. Without bells and\nwhistles, ETNDNet has three key highlights: (i) it does not require any\nexternal modules with parameters, (ii) it effectively handles various issues\ncaused by occlusion from obstacles and non-target pedestrians, and (iii) it\ndesigns the first GAN-based adversarial defense paradigm for occluded person\nre-ID. Extensive experiments on five public datasets fully demonstrate the\neffectiveness, superiority, and practicality of the proposed ETNDNet. The code\nwill be released at \\url{https://github.com/nengdong96/ETNDNet}.\n","authors":["Neng Dong","Liyan Zhang","Shuanglin Yan","Hao Tang","Jinhui Tang"],"pdf_url":"https://arxiv.org/pdf/2307.07187v3.pdf","comment":"Accepted by IEEE Transactions on Circuits and Systems for Video\n  Technology (TCSVT)"},{"id":"http://arxiv.org/abs/2311.15260v1","updated":"2023-11-26T10:27:22Z","published":"2023-11-26T10:27:22Z","title":"NeuRAD: Neural Rendering for Autonomous Driving","summary":"  Neural radiance fields (NeRFs) have gained popularity in the autonomous\ndriving (AD) community. Recent methods show NeRFs' potential for closed-loop\nsimulation, enabling testing of AD systems, and as an advanced training data\naugmentation technique. However, existing methods often require long training\ntimes, dense semantic supervision, or lack generalizability. This, in turn,\nhinders the application of NeRFs for AD at scale. In this paper, we propose\nNeuRAD, a robust novel view synthesis method tailored to dynamic AD data. Our\nmethod features simple network design, extensive sensor modeling for both\ncamera and lidar -- including rolling shutter, beam divergence and ray dropping\n-- and is applicable to multiple datasets out of the box. We verify its\nperformance on five popular AD datasets, achieving state-of-the-art performance\nacross the board. To encourage further development, we openly release the\nNeuRAD source code. See https://github.com/georghess/NeuRAD .\n","authors":["Adam Tonderski","Carl Lindström","Georg Hess","William Ljungbergh","Lennart Svensson","Christoffer Petersson"],"pdf_url":"https://arxiv.org/pdf/2311.15260v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11860v2","updated":"2023-11-26T10:10:55Z","published":"2023-11-20T15:56:44Z","title":"LION : Empowering Multimodal Large Language Model with Dual-Level Visual\n  Knowledge","summary":"  Multimodal Large Language Models (MLLMs) have endowed LLMs with the ability\nto perceive and understand multi-modal signals. However, most of the existing\nMLLMs mainly adopt vision encoders pretrained on coarsely aligned image-text\npairs, leading to insufficient extraction and reasoning of visual knowledge. To\naddress this issue, we devise a dual-Level vIsual knOwledge eNhanced Multimodal\nLarge Language Model (LION), which empowers the MLLM by injecting visual\nknowledge in two levels. 1) Progressive incorporation of fine-grained\nspatial-aware visual knowledge. We design a vision aggregator cooperated with\nregion-level vision-language (VL) tasks to incorporate fine-grained\nspatial-aware visual knowledge into the MLLM. To alleviate the conflict between\nimage-level and region-level VL tasks during incorporation, we devise a\ndedicated stage-wise instruction-tuning strategy with mixture-of-adapters. This\nprogressive incorporation scheme contributes to the mutual promotion between\nthese two kinds of VL tasks. 2) Soft prompting of high-level semantic visual\nevidence. We facilitate the MLLM with high-level semantic visual evidence by\nleveraging diverse image tags. To mitigate the potential influence caused by\nimperfect predicted tags, we propose a soft prompting method by embedding a\nlearnable token into the tailored text instruction. Comprehensive experiments\non several multi-modal benchmarks demonstrate the superiority of our model\n(e.g., improvement of 5% accuracy on VSR and 3% CIDEr on TextCaps over\nInstructBLIP, 5% accuracy on RefCOCOg over Kosmos-2).\n","authors":["Gongwei Chen","Leyang Shen","Rui Shao","Xiang Deng","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2311.11860v2.pdf","comment":"Technical Report. Project page:\n  https://rshaojimmy.github.io/Projects/JiuTian-LION Code:\n  https://github.com/rshaojimmy/JiuTian"},{"id":"http://arxiv.org/abs/2310.09912v2","updated":"2023-11-26T09:09:27Z","published":"2023-10-15T18:44:30Z","title":"Unsupervised Discovery of Interpretable Directions in h-space of\n  Pre-trained Diffusion Models","summary":"  We propose the first unsupervised and learning-based method to identify\ninterpretable directions in h-space of pre-trained diffusion models. Our method\nis derived from an existing technique that operates on the GAN latent space.\nSpecifically, we employ a shift control module that works on h-space of\npre-trained diffusion models to manipulate a sample into a shifted version of\nitself, followed by a reconstructor to reproduce both the type and the strength\nof the manipulation. By jointly optimizing them, the model will spontaneously\ndiscover disentangled and interpretable directions. To prevent the discovery of\nmeaningless and destructive directions, we employ a discriminator to maintain\nthe fidelity of shifted sample. Due to the iterative generative process of\ndiffusion models, our training requires a substantial amount of GPU VRAM to\nstore numerous intermediate tensors for back-propagating gradient. To address\nthis issue, we propose a general VRAM-efficient training algorithm based on\ngradient checkpointing technique to back-propagate any gradient through the\nwhole generative process, with acceptable occupancy of VRAM and sacrifice of\ntraining efficiency. Compared with existing related works on diffusion models,\nour method inherently identifies global and scalable directions, without\nnecessitating any other complicated procedures. Extensive experiments on\nvarious datasets demonstrate the effectiveness of our method.\n","authors":["Zijian Zhang","Luping Liu. Zhijie Lin","Yichen Zhu","Zhou Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.09912v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15243v1","updated":"2023-11-26T09:06:40Z","published":"2023-11-26T09:06:40Z","title":"ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection","summary":"  Out-of-distribution (OOD) detection methods often exploit auxiliary outliers\nto train model identifying OOD samples, especially discovering challenging\noutliers from auxiliary outliers dataset to improve OOD detection. However,\nthey may still face limitations in effectively distinguishing between the most\nchallenging OOD samples that are much like in-distribution (ID) data, i.e.,\nID-like samples. To this end, we propose a novel OOD detection framework that\ndiscovers ID-like outliers using CLIP from the vicinity space of the ID\nsamples, thus helping to identify these most challenging OOD samples. Then a\nprompt learning framework is proposed that utilizes the identified ID-like\noutliers to further leverage the capabilities of CLIP for OOD detection.\nBenefiting from the powerful CLIP, we only need a small number of ID samples to\nlearn the prompts of the model without exposing other auxiliary outlier\ndatasets. By focusing on the most challenging ID-like OOD samples and elegantly\nexploiting the capabilities of CLIP, our method achieves superior few-shot\nlearning performance on various real-world image datasets (e.g., in 4-shot OOD\ndetection on the ImageNet-1k dataset, our method reduces the average FPR95 by\n12.16% and improves the average AUROC by 2.76%, compared to state-of-the-art\nmethods).\n","authors":["Yichen Bai","Zongbo Han","Changqing Zhang","Bing Cao","Xiaoheng Jiang","Qinghua Hu"],"pdf_url":"https://arxiv.org/pdf/2311.15243v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2311.15241v1","updated":"2023-11-26T08:59:30Z","published":"2023-11-26T08:59:30Z","title":"CalibFormer: A Transformer-based Automatic LiDAR-Camera Calibration\n  Network","summary":"  The fusion of LiDARs and cameras has been increasingly adopted in autonomous\ndriving for perception tasks. The performance of such fusion-based algorithms\nlargely depends on the accuracy of sensor calibration, which is challenging due\nto the difficulty of identifying common features across different data\nmodalities. Previously, many calibration methods involved specific targets\nand/or manual intervention, which has proven to be cumbersome and costly.\nLearning-based online calibration methods have been proposed, but their\nperformance is barely satisfactory in most cases. These methods usually suffer\nfrom issues such as sparse feature maps, unreliable cross-modality association,\ninaccurate calibration parameter regression, etc. In this paper, to address\nthese issues, we propose CalibFormer, an end-to-end network for automatic\nLiDAR-camera calibration. We aggregate multiple layers of camera and LiDAR\nimage features to achieve high-resolution representations. A multi-head\ncorrelation module is utilized to identify correlations between features more\naccurately. Lastly, we employ transformer architectures to estimate accurate\ncalibration parameters from the correlation information. Our method achieved a\nmean translation error of $0.8751 \\mathrm{cm}$ and a mean rotation error of\n$0.0562 ^{\\circ}$ on the KITTI dataset, surpassing existing state-of-the-art\nmethods and demonstrating strong robustness, accuracy, and generalization\ncapabilities.\n","authors":["Yuxuan Xiao","Yao Li","Chengzhen Meng","Xingchen Li","Yanyong Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.15241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.11845v2","updated":"2023-11-26T08:57:44Z","published":"2023-07-21T18:29:04Z","title":"Multimodal Document Analytics for Banking Process Automation","summary":"  Traditional banks face increasing competition from FinTechs in the rapidly\nevolving financial ecosystem. Raising operational efficiency is vital to\naddress this challenge. Our study aims to improve the efficiency of\ndocument-intensive business processes in banking. To that end, we first review\nthe landscape of business documents in the retail segment. Banking documents\noften contain text, layout, and visuals, suggesting that document analytics and\nprocess automation require more than plain natural language processing (NLP).\nTo verify this and assess the incremental value of visual cues when processing\nbusiness documents, we compare a recently proposed multimodal model called\nLayoutXLM to powerful text classifiers (e.g., BERT) and large language models\n(e.g., GPT) in a case study related to processing company register extracts.\nThe results confirm that incorporating layout information in a model\nsubstantially increases its performance. Interestingly, we also observed that\nmore than 75% of the best model performance (in terms of the F1 score) can be\nachieved with as little as 30% of the training data. This shows that the demand\nfor data labeled data to set up a multi-modal model can be moderate, which\nsimplifies real-world applications of multimodal document analytics. Our study\nalso sheds light on more specific practices in the scope of calibrating a\nmultimodal banking document classifier, including the need for fine-tuning. In\nsum, the paper contributes original empirical evidence on the effectiveness and\nefficiency of multi-model models for document processing in the banking\nbusiness and offers practical guidance on how to unlock this potential in\nday-to-day operations.\n","authors":["Christopher Gerling","Stefan Lessmann"],"pdf_url":"https://arxiv.org/pdf/2307.11845v2.pdf","comment":"A Preprint"},{"id":"http://arxiv.org/abs/2311.15231v1","updated":"2023-11-26T08:09:43Z","published":"2023-11-26T08:09:43Z","title":"Double Reverse Regularization Network Based on Self-Knowledge\n  Distillation for SAR Object Classification","summary":"  In current synthetic aperture radar (SAR) object classification, one of the\nmajor challenges is the severe overfitting issue due to the limited dataset\n(few-shot) and noisy data. Considering the advantages of knowledge distillation\nas a learned label smoothing regularization, this paper proposes a novel Double\nReverse Regularization Network based on Self-Knowledge Distillation\n(DRRNet-SKD). Specifically, through exploring the effect of distillation weight\non the process of distillation, we are inspired to adopt the double reverse\nthought to implement an effective regularization network by combining offline\nand online distillation in a complementary way. Then, the Adaptive Weight\nAssignment (AWA) module is designed to adaptively assign two reverse-changing\nweights based on the network performance, allowing the student network to\nbetter benefit from both teachers. The experimental results on OpenSARShip and\nFUSAR-Ship demonstrate that DRRNet-SKD exhibits remarkable performance\nimprovement on classical CNNs, outperforming state-of-the-art self-knowledge\ndistillation methods.\n","authors":["Bo Xu","Hao Zheng","Zhigang Hu","Liu Yang","Meiguang Zheng"],"pdf_url":"https://arxiv.org/pdf/2311.15231v1.pdf","comment":"6 pages, 8 figures"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2304.08138v2","updated":"2023-11-26T23:52:43Z","published":"2023-04-17T10:42:30Z","title":"Typos-aware Bottlenecked Pre-Training for Robust Dense Retrieval","summary":"  Current dense retrievers (DRs) are limited in their ability to effectively\nprocess misspelled queries, which constitute a significant portion of query\ntraffic in commercial search engines. The main issue is that the pre-trained\nlanguage model-based encoders used by DRs are typically trained and fine-tuned\nusing clean, well-curated text data. Misspelled queries are typically not found\nin the data used for training these models, and thus misspelled queries\nobserved at inference time are out-of-distribution compared to the data used\nfor training and fine-tuning. Previous efforts to address this issue have\nfocused on \\textit{fine-tuning} strategies, but their effectiveness on\nmisspelled queries remains lower than that of pipelines that employ separate\nstate-of-the-art spell-checking components. To address this challenge, we\npropose ToRoDer (TypOs-aware bottlenecked pre-training for RObust DEnse\nRetrieval), a novel re-training strategy for DRs that increases their\nrobustness to misspelled queries while preserving their effectiveness in\ndownstream retrieval tasks. ToRoDer utilizes an encoder-decoder architecture\nwhere the encoder takes misspelled text with masked tokens as input and outputs\nbottlenecked information to the decoder. The decoder then takes as input the\nbottlenecked embeddings, along with token embeddings of the original text with\nthe misspelled tokens masked out. The pre-training task is to recover the\nmasked tokens for both the encoder and decoder. Our extensive experimental\nresults and detailed ablation studies show that DRs pre-trained with ToRoDer\nexhibit significantly higher effectiveness on misspelled queries, sensibly\nclosing the gap with pipelines that use a separate, complex spell-checker\ncomponent, while retaining their effectiveness on correctly spelled queries.\n","authors":["Shengyao Zhuang","Linjun Shou","Jian Pei","Ming Gong","Houxing Ren","Guido Zuccon","Daxin Jiang"],"pdf_url":"https://arxiv.org/pdf/2304.08138v2.pdf","comment":"10 pages, accepted at SIGIR-AP"},{"id":"http://arxiv.org/abs/2311.15426v1","updated":"2023-11-26T21:16:12Z","published":"2023-11-26T21:16:12Z","title":"Data Augmentation for Sample Efficient and Robust Document Ranking","summary":"  Contextual ranking models have delivered impressive performance improvements\nover classical models in the document ranking task. However, these highly\nover-parameterized models tend to be data-hungry and require large amounts of\ndata even for fine-tuning. In this paper, we propose data-augmentation methods\nfor effective and robust ranking performance. One of the key benefits of using\ndata augmentation is in achieving sample efficiency or learning effectively\nwhen we have only a small amount of training data. We propose supervised and\nunsupervised data augmentation schemes by creating training data using parts of\nthe relevant documents in the query-document pairs. We then adapt a family of\ncontrastive losses for the document ranking task that can exploit the augmented\ndata to learn an effective ranking model. Our extensive experiments on subsets\nof the MS MARCO and TREC-DL test sets show that data augmentation, along with\nthe ranking-adapted contrastive losses, results in performance improvements\nunder most dataset sizes. Apart from sample efficiency, we conclusively show\nthat data augmentation results in robust models when transferred to\nout-of-domain benchmarks. Our performance improvements in in-domain and more\nprominently in out-of-domain benchmarks show that augmentation regularizes the\nranking model and improves its robustness and generalization capability.\n","authors":["Abhijit Anand","Jurek Leonhardt","Jaspreet Singh","Koustav Rudra","Avishek Anand"],"pdf_url":"https://arxiv.org/pdf/2311.15426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19453v2","updated":"2023-11-26T12:40:27Z","published":"2023-10-30T11:25:03Z","title":"FLIP: Towards Fine-grained Alignment between ID-based Models and\n  Pretrained Language Models for CTR Prediction","summary":"  Click-through rate (CTR) prediction plays as a core function module in\nvarious personalized online services. The traditional ID-based models for CTR\nprediction take as inputs the one-hot encoded ID features of tabular modality,\nwhich capture the collaborative signals via feature interaction modeling. But\nthe one-hot encoding discards the semantic information conceived in the\noriginal feature texts. Recently, the emergence of Pretrained Language Models\n(PLMs) has given rise to another paradigm, which takes as inputs the sentences\nof textual modality obtained by hard prompt templates and adopts PLMs to\nextract the semantic knowledge. However, PLMs generally tokenize the input text\ndata into subword tokens and ignore field-wise collaborative signals.\nTherefore, these two lines of research focus on different characteristics of\nthe same input data (i.e., textual and tabular modalities), forming a distinct\ncomplementary relationship with each other. In this paper, we propose to\nconduct Fine-grained feature-level ALignment between ID-based Models and\nPretrained Language Models (FLIP) for CTR prediction. We design a novel joint\nreconstruction pretraining task for both masked language and tabular modeling.\nSpecifically, the masked data of one modality (i.e., tokens or features) has to\nbe recovered with the help of the other modality, which establishes the\nfeature-level interaction and alignment via sufficient mutual information\nextraction between dual modalities. Moreover, we propose to jointly finetune\nthe ID-based model and PLM for downstream CTR prediction tasks, thus achieving\nsuperior performance by combining the advantages of both models. Extensive\nexperiments on three real-world datasets demonstrate that FLIP outperforms SOTA\nbaselines, and is highly compatible for various ID-based models and PLMs.\n","authors":["Hangyu Wang","Jianghao Lin","Xiangyang Li","Bo Chen","Chenxu Zhu","Ruiming Tang","Weinan Zhang","Yong Yu"],"pdf_url":"https://arxiv.org/pdf/2310.19453v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2308.10778v2","updated":"2023-11-26T11:32:59Z","published":"2023-08-21T15:09:19Z","title":"A Topology-aware Analysis of Graph Collaborative Filtering","summary":"  The successful integration of graph neural networks into recommender systems\n(RSs) has led to a novel paradigm in collaborative filtering (CF), graph\ncollaborative filtering (graph CF). By representing user-item data as an\nundirected, bipartite graph, graph CF utilizes short- and long-range\nconnections to extract collaborative signals that yield more accurate user\npreferences than traditional CF methods. Although the recent literature\nhighlights the efficacy of various algorithmic strategies in graph CF, the\nimpact of datasets and their topological features on recommendation performance\nis yet to be studied. To fill this gap, we propose a topology-aware analysis of\ngraph CF. In this study, we (i) take some widely-adopted recommendation\ndatasets and use them to generate a large set of synthetic sub-datasets through\ntwo state-of-the-art graph sampling methods, (ii) measure eleven of their\nclassical and topological characteristics, and (iii) estimate the accuracy\ncalculated on the generated sub-datasets considering four popular and recent\ngraph-based RSs (i.e., LightGCN, DGCF, UltraGCN, and SVD-GCN). Finally, the\ninvestigation presents an explanatory framework that reveals the linear\nrelationships between characteristics and accuracy measures. The results,\nstatistically validated under different graph sampling settings, confirm the\nexistence of solid dependencies between topological characteristics and\naccuracy in the graph-based recommendation, offering a new perspective on how\nto interpret graph CF.\n","authors":["Daniele Malitesta","Claudio Pomo","Vito Walter Anelli","Alberto Carlo Maria Mancino","Eugenio Di Sciascio","Tommaso Di Noia"],"pdf_url":"https://arxiv.org/pdf/2308.10778v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14742v1","updated":"2023-11-26T07:34:18Z","published":"2023-11-26T07:34:18Z","title":"Query-LIFE: Query-aware Language Image Fusion Embedding for E-Commerce\n  Relevance","summary":"  Relevance module plays a fundamental role in e-commerce search as they are\nresponsible for selecting relevant products from thousands of items based on\nuser queries, thereby enhancing users experience and efficiency. The\ntraditional approach models the relevance based product titles and queries, but\nthe information in titles alone maybe insufficient to describe the products\ncompletely. A more general optimization approach is to further leverage product\nimage information. In recent years, vision-language pre-training models have\nachieved impressive results in many scenarios, which leverage contrastive\nlearning to map both textual and visual features into a joint embedding space.\nIn e-commerce, a common practice is to fine-tune on the pre-trained model based\non e-commerce data. However, the performance is sub-optimal because the\nvision-language pre-training models lack of alignment specifically designed for\nqueries. In this paper, we propose a method called Query-LIFE (Query-aware\nLanguage Image Fusion Embedding) to address these challenges. Query-LIFE\nutilizes a query-based multimodal fusion to effectively incorporate the image\nand title based on the product types. Additionally, it employs query-aware\nmodal alignment to enhance the accuracy of the comprehensive representation of\nproducts. Furthermore, we design GenFilt, which utilizes the generation\ncapability of large models to filter out false negative samples and further\nimprove the overall performance of the contrastive learning task in the model.\nExperiments have demonstrated that Query-LIFE outperforms existing baselines.\nWe have conducted ablation studies and human evaluations to validate the\neffectiveness of each module within Query-LIFE. Moreover, Query-LIFE has been\ndeployed on Miravia Search, resulting in improved both relevance and conversion\nefficiency.\n","authors":["Hai Zhu","Yuankai Guo","Ronggang Dou","Kai Liu"],"pdf_url":"https://arxiv.org/pdf/2311.14742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.12301v2","updated":"2023-11-26T15:06:49Z","published":"2023-07-23T11:50:27Z","title":"Unsupervised Image Outlier Detection using RANSAC","summary":"  Image outlier detection (OD) is an essential tool to ensure the quality and\naccuracy of image datasets used in computer vision tasks. Most existing\napproaches, however, require a set of in-distribution data for training prior\nto outlier prediction. The quality and quantity of the data can influence the\nresulting performance. Thus, selecting a suitable in-distribution set often\nrequires considerable effort. In this work, we propose RANSAC-NN, an\nunsupervised image OD algorithm designed to detect outliers within contaminated\nsets in a one-class classification fashion. Without any training, RANSAC-NN\nperforms favorably in comparison to other well-established methods in a variety\nof OD benchmarks. Furthermore, we show that our method can enhance the\nrobustness of existing OD methods by simply applying RANSAC-NN during\npre-processing.\n","authors":["Chen-Han Tsai","Yu-Shao Peng"],"pdf_url":"https://arxiv.org/pdf/2307.12301v2.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2311.15451v1","updated":"2023-11-26T22:47:54Z","published":"2023-11-26T22:47:54Z","title":"Uncertainty-aware Language Modeling for Selective Question Answering","summary":"  We present an automatic large language model (LLM) conversion approach that\nproduces uncertainty-aware LLMs capable of estimating uncertainty with every\nprediction. Our approach is model- and data-agnostic, is\ncomputationally-efficient, and does not rely on external models or systems. We\nevaluate converted models on the selective question answering setting -- to\nanswer as many questions as possible while maintaining a given accuracy,\nforgoing providing predictions when necessary. As part of our results, we test\nBERT and Llama 2 model variants on the SQuAD extractive QA task and the\nTruthfulQA generative QA task. We show that using the uncertainty estimates\nprovided by our approach to selectively answer questions leads to significantly\nhigher accuracy over directly using model probabilities.\n","authors":["Qi Yang","Shreya Ravikumar","Fynn Schmitt-Ulms","Satvik Lolla","Ege Demir","Iaroslav Elistratov","Alex Lavaee","Sadhana Lolla","Elaheh Ahmadi","Daniela Rus","Alexander Amini","Alejandro Perez"],"pdf_url":"https://arxiv.org/pdf/2311.15451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15448v1","updated":"2023-11-26T22:22:38Z","published":"2023-11-26T22:22:38Z","title":"GGNNs : Generalizing GNNs using Residual Connections and Weighted\n  Message Passing","summary":"  Many real-world phenomena can be modeled as a graph, making them extremely\nvaluable due to their ubiquitous presence. GNNs excel at capturing those\nrelationships and patterns within these graphs, enabling effective learning and\nprediction tasks. GNNs are constructed using Multi-Layer Perceptrons (MLPs) and\nincorporate additional layers for message passing to facilitate the flow of\nfeatures among nodes. It is commonly believed that the generalizing power of\nGNNs is attributed to the message-passing mechanism between layers, where nodes\nexchange information with their neighbors, enabling them to effectively capture\nand propagate information across the nodes of a graph. Our technique builds on\nthese results, modifying the message-passing mechanism further: one by weighing\nthe messages before accumulating at each node and another by adding Residual\nconnections. These two mechanisms show significant improvements in learning and\nfaster convergence\n","authors":["Abhinav Raghuvanshi","Kushal Sokke Malleshappa"],"pdf_url":"https://arxiv.org/pdf/2311.15448v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.16585v2","updated":"2023-11-26T22:04:47Z","published":"2023-03-29T10:42:50Z","title":"Quantum Deep Hedging","summary":"  Quantum machine learning has the potential for a transformative impact across\nindustry sectors and in particular in finance. In our work we look at the\nproblem of hedging where deep reinforcement learning offers a powerful\nframework for real markets. We develop quantum reinforcement learning methods\nbased on policy-search and distributional actor-critic algorithms that use\nquantum neural network architectures with orthogonal and compound layers for\nthe policy and value functions. We prove that the quantum neural networks we\nuse are trainable, and we perform extensive simulations that show that quantum\nmodels can reduce the number of trainable parameters while achieving comparable\nperformance and that the distributional approach obtains better performance\nthan other standard approaches, both classical and quantum. We successfully\nimplement the proposed models on a trapped-ion quantum processor, utilizing\ncircuits with up to $16$ qubits, and observe performance that agrees well with\nnoiseless simulation. Our quantum techniques are general and can be applied to\nother reinforcement learning problems beyond hedging.\n","authors":["El Amine Cherrat","Snehal Raj","Iordanis Kerenidis","Abhishek Shekhar","Ben Wood","Jon Dee","Shouvanik Chakrabarti","Richard Chen","Dylan Herman","Shaohan Hu","Pierre Minssen","Ruslan Shaydulin","Yue Sun","Romina Yalovetzky","Marco Pistoia"],"pdf_url":"https://arxiv.org/pdf/2303.16585v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.06817v3","updated":"2023-11-26T21:59:47Z","published":"2022-06-14T13:11:22Z","title":"Residual-based physics-informed transfer learning: A hybrid method for\n  accelerating long-term CFD simulations via deep learning","summary":"  While a big wave of artificial intelligence (AI) has propagated to the field\nof computational fluid dynamics (CFD) acceleration studies, recent research has\nhighlighted that the development of AI techniques that reconciles the following\ngoals remains our primary task: (1) accurate prediction of unseen (future) time\nseries in long-term CFD simulations (2) acceleration of simulations (3) an\nacceptable amount of training data and time (4) within a multiple PDEs\ncondition. In this study, we propose a residual-based physics-informed transfer\nlearning (RePIT) strategy to achieve these four objectives using ML-CFD hybrid\ncomputation. Our hypothesis is that long-term CFD simulation is feasible with\nthe hybrid method where CFD and AI alternately calculate time series while\nmonitoring the first principle's residuals. The feasibility of RePIT strategy\nwas verified through a CFD case study on natural convection. In a single\ntraining approach, a residual scale change occurred around 100th timestep,\nresulting in predicted time series exhibiting non-physical patterns as well as\na significant deviations from the ground truth. Conversely, RePIT strategy\nmaintained the residuals within the defined range and demonstrated good\naccuracy throughout the entire simulation period. The maximum error from the\nground truth was below 0.4 K for temperature and 0.024 m/s for x-axis velocity.\nFurthermore, the average time for 1 timestep by the ML-GPU and CFD-CPU\ncalculations was 0.171 s and 0.015 s, respectively. Including the\nparameter-updating time, the simulation was accelerated by a factor of 1.9. In\nconclusion, our RePIT strategy is a promising technique to reduce the cost of\nCFD simulations in industry. However, more vigorous optimization and\nimprovement studies are still necessary.\n","authors":["Joongoo Jeon","Juhyeong Lee","Ricardo Vinuesa","Sung Joong Kim"],"pdf_url":"https://arxiv.org/pdf/2206.06817v3.pdf","comment":"36 pages, 10 figures"},{"id":"http://arxiv.org/abs/2311.15435v1","updated":"2023-11-26T21:35:34Z","published":"2023-11-26T21:35:34Z","title":"Functional Diffusion","summary":"  We propose a new class of generative diffusion models, called functional\ndiffusion. In contrast to previous work, functional diffusion works on samples\nthat are represented by functions with a continuous domain. Functional\ndiffusion can be seen as an extension of classical diffusion models to an\ninfinite-dimensional domain. Functional diffusion is very versatile as images,\nvideos, audio, 3D shapes, deformations, \\etc, can be handled by the same\nframework with minimal changes. In addition, functional diffusion is especially\nsuited for irregular data or data defined in non-standard domains. In our work,\nwe derive the necessary foundations for functional diffusion and propose a\nfirst implementation based on the transformer architecture. We show generative\nresults on complicated signed distance functions and deformation functions\ndefined on 3D surfaces.\n","authors":["Biao Zhang","Peter Wonka"],"pdf_url":"https://arxiv.org/pdf/2311.15435v1.pdf","comment":"For the project site, see https://1zb.github.io/functional-diffusion/"},{"id":"http://arxiv.org/abs/2311.15419v1","updated":"2023-11-26T21:03:25Z","published":"2023-11-26T21:03:25Z","title":"Frobenius-Type Norms and Inner Products of Matrices and Linear Maps with\n  Applications to Neural Network Training","summary":"  The Frobenius norm is a frequent choice of norm for matrices. In particular,\nthe underlying Frobenius inner product is typically used to evaluate the\ngradient of an objective with respect to matrix variable, such as those\noccuring in the training of neural networks. We provide a broader view on the\nFrobenius norm and inner product for linear maps or matrices, and establish\ntheir dependence on inner products in the domain and co-domain spaces. This\nshows that the classical Frobenius norm is merely one special element of a\nfamily of more general Frobenius-type norms. The significant extra freedom\nfurnished by this realization can be used, among other things, to precondition\nneural network training.\n","authors":["Roland Herzog","Frederik Köhne","Leonie Kreis","Anton Schiela"],"pdf_url":"https://arxiv.org/pdf/2311.15419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09247v2","updated":"2023-11-26T20:42:08Z","published":"2023-11-14T04:33:49Z","title":"Comparing Humans, GPT-4, and GPT-4V On Abstraction and Reasoning Tasks","summary":"  We explore the abstract reasoning abilities of text-only and multimodal\nversions of GPT-4, using the ConceptARC benchmark [10], which is designed to\nevaluate robust understanding and reasoning with core-knowledge concepts. We\nextend the work of Moskvichev et al. [10] by evaluating GPT-4 on more detailed,\none-shot prompting (rather than simple, zero-shot prompts) with text versions\nof ConceptARC tasks, and by evaluating GPT-4V, the multimodal version of GPT-4,\non zero- and one-shot prompts using image versions of the simplest tasks. Our\nexperimental results support the conclusion that neither version of GPT-4 has\ndeveloped robust abstraction abilities at humanlike levels.\n","authors":["Melanie Mitchell","Alessandro B. Palmarini","Arseny Moskvichev"],"pdf_url":"https://arxiv.org/pdf/2311.09247v2.pdf","comment":"Corrected typo in email addresses"},{"id":"http://arxiv.org/abs/2311.15414v1","updated":"2023-11-26T20:35:19Z","published":"2023-11-26T20:35:19Z","title":"KOPPA: Improving Prompt-based Continual Learning with Key-Query\n  Orthogonal Projection and Prototype-based One-Versus-All","summary":"  Drawing inspiration from prompt tuning techniques applied to Large Language\nModels, recent methods based on pre-trained ViT networks have achieved\nremarkable results in the field of Continual Learning. Specifically, these\napproaches propose to maintain a set of prompts and allocate a subset of them\nto learn each task using a key-query matching strategy. However, they may\nencounter limitations when lacking control over the correlations between old\ntask queries and keys of future tasks, the shift of features in the latent\nspace, and the relative separation of latent vectors learned in independent\ntasks. In this work, we introduce a novel key-query learning strategy based on\northogonal projection, inspired by model-agnostic meta-learning, to enhance\nprompt matching efficiency and address the challenge of shifting features.\nFurthermore, we introduce a One-Versus-All (OVA) prototype-based component that\nenhances the classification head distinction. Experimental results on benchmark\ndatasets demonstrate that our method empowers the model to achieve results\nsurpassing those of current state-of-the-art approaches by a large margin of up\nto 20%.\n","authors":["Quyen Tran","Lam Tran","Khoat Than","Toan Tran","Dinh Phung","Trung Le"],"pdf_url":"https://arxiv.org/pdf/2311.15414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.09478v2","updated":"2023-11-26T20:01:28Z","published":"2023-06-15T20:08:42Z","title":"Understanding and Mitigating Extrapolation Failures in Physics-Informed\n  Neural Networks","summary":"  Physics-informed Neural Networks (PINNs) have recently gained popularity due\nto their effective approximation of partial differential equations (PDEs) using\ndeep neural networks (DNNs). However, their out of domain behavior is not well\nunderstood, with previous work speculating that the presence of high frequency\ncomponents in the solution function might be to blame for poor extrapolation\nperformance. In this paper, we study the extrapolation behavior of PINNs on a\nrepresentative set of PDEs of different types, including high-dimensional PDEs.\nWe find that failure to extrapolate is not caused by high frequencies in the\nsolution function, but rather by shifts in the support of the Fourier spectrum\nover time. We term these spectral shifts and quantify them by introducing a\nWeighted Wasserstein-Fourier distance (WWF). We show that the WWF can be used\nto predict PINN extrapolation performance, and that in the absence of\nsignificant spectral shifts, PINN predictions stay close to the true solution\neven in extrapolation. Finally, we propose a transfer learning-based strategy\nto mitigate the effects of larger spectral shifts, which decreases\nextrapolation errors by up to 82%.\n","authors":["Lukas Fesser","Luca D'Amico-Wong","Richard Qiu"],"pdf_url":"https://arxiv.org/pdf/2306.09478v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15404v1","updated":"2023-11-26T20:00:53Z","published":"2023-11-26T20:00:53Z","title":"Applying statistical learning theory to deep learning","summary":"  Although statistical learning theory provides a robust framework to\nunderstand supervised learning, many theoretical aspects of deep learning\nremain unclear, in particular how different architectures may lead to inductive\nbias when trained using gradient based methods. The goal of these lectures is\nto provide an overview of some of the main questions that arise when attempting\nto understand deep learning from a learning theory perspective. After a brief\nreminder on statistical learning theory and stochastic optimization, we discuss\nimplicit bias in the context of benign overfitting. We then move to a general\ndescription of the mirror descent algorithm, showing how we may go back and\nforth between a parameter space and the corresponding function space for a\ngiven learning problem, as well as how the geometry of the learning problem may\nbe represented by a metric tensor. Building on this framework, we provide a\ndetailed study of the implicit bias of gradient descent on linear diagonal\nnetworks for various regression tasks, showing how the loss function, scale of\nparameters at initialization and depth of the network may lead to various forms\nof implicit bias, in particular transitioning between kernel or feature\nlearning.\n","authors":["Cédric Gerbelot","Avetik Karagulyan","Stefani Karp","Kavya Ravichandran","Menachem Stern","Nathan Srebro"],"pdf_url":"https://arxiv.org/pdf/2311.15404v1.pdf","comment":"51 pages, 20 figures"},{"id":"http://arxiv.org/abs/2205.08253v3","updated":"2023-11-26T19:59:40Z","published":"2022-05-17T11:56:50Z","title":"Momentum-Based Policy Gradient with Second-Order Information","summary":"  Variance-reduced gradient estimators for policy gradient methods have been\none of the main focus of research in the reinforcement learning in recent years\nas they allow acceleration of the estimation process. We propose a\nvariance-reduced policy-gradient method, called SHARP, which incorporates\nsecond-order information into stochastic gradient descent (SGD) using momentum\nwith a time-varying learning rate. SHARP algorithm is parameter-free, achieving\n$\\epsilon$-approximate first-order stationary point with $O(\\epsilon^{-3})$\nnumber of trajectories, while using a batch size of $O(1)$ at each iteration.\nUnlike most previous work, our proposed algorithm does not require importance\nsampling which can compromise the advantage of variance reduction process.\nMoreover, the variance of estimation error decays with the fast rate of\n$O(1/t^{2/3})$ where $t$ is the number of iterations. Our extensive\nexperimental evaluations show the effectiveness of the proposed algorithm on\nvarious control tasks and its advantage over the state of the art in practice.\n","authors":["Saber Salehkaleybar","Sadegh Khorasani","Negar Kiyavash","Niao He","Patrick Thiran"],"pdf_url":"https://arxiv.org/pdf/2205.08253v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.07721v2","updated":"2023-11-26T19:58:15Z","published":"2023-05-12T18:24:30Z","title":"Designing Optimal Behavioral Experiments Using Machine Learning","summary":"  Computational models are powerful tools for understanding human cognition and\nbehavior. They let us express our theories clearly and precisely, and offer\npredictions that can be subtle and often counter-intuitive. However, this same\nrichness and ability to surprise means our scientific intuitions and\ntraditional tools are ill-suited to designing experiments to test and compare\nthese models. To avoid these pitfalls and realize the full potential of\ncomputational modeling, we require tools to design experiments that provide\nclear answers about what models explain human behavior and the auxiliary\nassumptions those models must make. Bayesian optimal experimental design (BOED)\nformalizes the search for optimal experimental designs by identifying\nexperiments that are expected to yield informative data. In this work, we\nprovide a tutorial on leveraging recent advances in BOED and machine learning\nto find optimal experiments for any kind of model that we can simulate data\nfrom, and show how by-products of this procedure allow for quick and\nstraightforward evaluation of models and their parameters against real\nexperimental data. As a case study, we consider theories of how people balance\nexploration and exploitation in multi-armed bandit decision-making tasks. We\nvalidate the presented approach using simulations and a real-world experiment.\nAs compared to experimental designs commonly used in the literature, we show\nthat our optimal designs more efficiently determine which of a set of models\nbest account for individual human behavior, and more efficiently characterize\nbehavior given a preferred model. At the same time, formalizing a scientific\nquestion such that it can be adequately addressed with BOED can be challenging\nand we discuss several potential caveats and pitfalls that practitioners should\nbe aware of. We provide code and tutorial notebooks to replicate all analyses.\n","authors":["Simon Valentin","Steven Kleinegesse","Neil R. Bramley","Peggy Seriès","Michael U. Gutmann","Christopher G. Lucas"],"pdf_url":"https://arxiv.org/pdf/2305.07721v2.pdf","comment":"Accepted in eLife"},{"id":"http://arxiv.org/abs/2311.15399v1","updated":"2023-11-26T19:47:39Z","published":"2023-11-26T19:47:39Z","title":"Optimally Teaching a Linear Behavior Cloning Agent","summary":"  We study optimal teaching of Linear Behavior Cloning (LBC) learners. In this\nsetup, the teacher can select which states to demonstrate to an LBC learner.\nThe learner maintains a version space of infinite linear hypotheses consistent\nwith the demonstration. The goal of the teacher is to teach a realizable target\npolicy to the learner using minimum number of state demonstrations. This number\nis known as the Teaching Dimension(TD). We present a teaching algorithm called\n``Teach using Iterative Elimination(TIE)\" that achieves instance optimal TD.\nHowever, we also show that finding optimal teaching set computationally is\nNP-hard. We further provide an approximation algorithm that guarantees an\napproximation ratio of $\\log(|A|-1)$ on the teaching dimension. Finally, we\nprovide experimental results to validate the efficiency and effectiveness of\nour algorithm.\n","authors":["Shubham Kumar Bharti","Stephen Wright","Adish Singla","Xiaojin Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.15399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.01203v7","updated":"2023-11-26T19:44:54Z","published":"2023-04-03T17:59:58Z","title":"Optimal Goal-Reaching Reinforcement Learning via Quasimetric Learning","summary":"  In goal-reaching reinforcement learning (RL), the optimal value function has\na particular geometry, called quasimetric structure. This paper introduces\nQuasimetric Reinforcement Learning (QRL), a new RL method that utilizes\nquasimetric models to learn optimal value functions. Distinct from prior\napproaches, the QRL objective is specifically designed for quasimetrics, and\nprovides strong theoretical recovery guarantees. Empirically, we conduct\nthorough analyses on a discretized MountainCar environment, identifying\nproperties of QRL and its advantages over alternatives. On offline and online\ngoal-reaching benchmarks, QRL also demonstrates improved sample efficiency and\nperformance, across both state-based and image-based observations.\n","authors":["Tongzhou Wang","Antonio Torralba","Phillip Isola","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2304.01203v7.pdf","comment":"Project Page: https://www.tongzhouwang.info/quasimetric_rl/ Code:\n  https://github.com/quasimetric-learning/quasimetric-rl/"},{"id":"http://arxiv.org/abs/2311.15395v1","updated":"2023-11-26T19:31:52Z","published":"2023-11-26T19:31:52Z","title":"ConstraintMatch for Semi-constrained Clustering","summary":"  Constrained clustering allows the training of classification models using\npairwise constraints only, which are weak and relatively easy to mine, while\nstill yielding full-supervision-level model performance. While they perform\nwell even in the absence of the true underlying class labels, constrained\nclustering models still require large amounts of binary constraint annotations\nfor training. In this paper, we propose a semi-supervised context whereby a\nlarge amount of \\textit{unconstrained} data is available alongside a smaller\nset of constraints, and propose \\textit{ConstraintMatch} to leverage such\nunconstrained data. While a great deal of progress has been made in\nsemi-supervised learning using full labels, there are a number of challenges\nthat prevent a naive application of the resulting methods in the\nconstraint-based label setting. Therefore, we reason about and analyze these\nchallenges, specifically 1) proposing a \\textit{pseudo-constraining} mechanism\nto overcome the confirmation bias, a major weakness of pseudo-labeling, 2)\ndeveloping new methods for pseudo-labeling towards the selection of\n\\textit{informative} unconstrained samples, 3) showing that this also allows\nthe use of pairwise loss functions for the initial and auxiliary losses which\nfacilitates semi-constrained model training. In extensive experiments, we\ndemonstrate the effectiveness of ConstraintMatch over relevant baselines in\nboth the regular clustering and overclustering scenarios on five challenging\nbenchmarks and provide analyses of its several components.\n","authors":["Jann Goschenhofer","Bernd Bischl","Zsolt Kira"],"pdf_url":"https://arxiv.org/pdf/2311.15395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.08693v4","updated":"2023-11-26T19:24:52Z","published":"2021-10-17T00:59:36Z","title":"Elastic Shape Analysis of Tree-like 3D Objects using Extended SRVF\n  Representation","summary":"  How can one analyze detailed 3D biological objects, such as neurons and\nbotanical trees, that exhibit complex geometrical and topological variation? In\nthis paper, we develop a novel mathematical framework for representing,\ncomparing, and computing geodesic deformations between the shapes of such\ntree-like 3D objects. A hierarchical organization of subtrees characterizes\nthese objects -- each subtree has the main branch with some side branches\nattached -- and one needs to match these structures across objects for\nmeaningful comparisons. We propose a novel representation that extends the\nSquare-Root Velocity Function (SRVF), initially developed for Euclidean curves,\nto tree-shaped 3D objects. We then define a new metric that quantifies the\nbending, stretching, and branch sliding needed to deform one tree-shaped object\ninto the other. Compared to the current metrics, such as the Quotient Euclidean\nDistance (QED) and the Tree Edit Distance (TED), the proposed representation\nand metric capture the full elasticity of the branches (i.e., bending and\nstretching) as well as the topological variations (i.e., branch death/birth and\nsliding). It completely avoids the shrinkage that results from the edge\ncollapse and node split operations of the QED and TED metrics. We demonstrate\nthe utility of this framework in comparing, matching, and computing geodesics\nbetween biological objects such as neurons and botanical trees. The framework\nis also applied to various shape analysis tasks: (i) symmetry analysis and\nsymmetrization of tree-shaped 3D objects, (ii) computing summary statistics\n(means and modes of variations) of populations of tree-shaped 3D objects, (iii)\nfitting parametric probability distributions to such populations, and (iv)\nfinally synthesizing novel tree-shaped 3D objects through random sampling from\nestimated probability distributions.\n","authors":["Guan Wang","Hamid Laga","Anuj Srivastava"],"pdf_url":"https://arxiv.org/pdf/2110.08693v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.00460v2","updated":"2023-11-26T19:20:39Z","published":"2022-11-01T13:42:44Z","title":"Augmentation Invariant Manifold Learning","summary":"  Data augmentation is a widely used technique and an essential ingredient in\nthe recent advance in self-supervised representation learning. By preserving\nthe similarity between augmented data, the resulting data representation can\nimprove various downstream analyses and achieve state-of-the-art performance in\nmany applications. Despite the empirical effectiveness, most existing methods\nlack theoretical understanding under a general nonlinear setting. To fill this\ngap, we develop a statistical framework on a low-dimension product manifold to\nmodel the data augmentation transformation. Under this framework, we introduce\na new representation learning method called augmentation invariant manifold\nlearning and design a computationally efficient algorithm by reformulating it\nas a stochastic optimization problem. Compared with existing self-supervised\nmethods, the new method simultaneously exploits the manifold's geometric\nstructure and invariant property of augmented data and has an explicit\ntheoretical guarantee. Our theoretical investigation characterizes the role of\ndata augmentation in the proposed method and reveals why and how the data\nrepresentation learned from augmented data can improve the $k$-nearest neighbor\nclassifier in the downstream analysis, showing that a more complex data\naugmentation leads to more improvement in downstream analysis. Finally,\nnumerical experiments on simulated and real datasets are presented to\ndemonstrate the merit of the proposed method.\n","authors":["Shulei Wang"],"pdf_url":"https://arxiv.org/pdf/2211.00460v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15390v1","updated":"2023-11-26T19:19:02Z","published":"2023-11-26T19:19:02Z","title":"Local Convergence of Approximate Newton Method for Two Layer Nonlinear\n  Regression","summary":"  There have been significant advancements made by large language models (LLMs)\nin various aspects of our daily lives. LLMs serve as a transformative force in\nnatural language processing, finding applications in text generation,\ntranslation, sentiment analysis, and question-answering. The accomplishments of\nLLMs have led to a substantial increase in research efforts in this domain. One\nspecific two-layer regression problem has been well-studied in prior works,\nwhere the first layer is activated by a ReLU unit, and the second layer is\nactivated by a softmax unit. While previous works provide a solid analysis of\nbuilding a two-layer regression, there is still a gap in the analysis of\nconstructing regression problems with more than two layers.\n  In this paper, we take a crucial step toward addressing this problem: we\nprovide an analysis of a two-layer regression problem. In contrast to previous\nworks, our first layer is activated by a softmax unit. This sets the stage for\nfuture analyses of creating more activation functions based on the softmax\nfunction. Rearranging the softmax function leads to significantly different\nanalyses. Our main results involve analyzing the convergence properties of an\napproximate Newton method used to minimize the regularized training loss. We\nprove that the loss function for the Hessian matrix is positive definite and\nLipschitz continuous under certain assumptions. This enables us to establish\nlocal convergence guarantees for the proposed training algorithm. Specifically,\nwith an appropriate initialization and after $O(\\log(1/\\epsilon))$ iterations,\nour algorithm can find an $\\epsilon$-approximate minimizer of the training loss\nwith high probability. Each iteration requires approximately $O(\\mathrm{nnz}(C)\n+ d^\\omega)$ time, where $d$ is the model size, $C$ is the input matrix, and\n$\\omega < 2.374$ is the matrix multiplication exponent.\n","authors":["Zhihang Li","Zhao Song","Zifan Wang","Junze Yin"],"pdf_url":"https://arxiv.org/pdf/2311.15390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15386v1","updated":"2023-11-26T19:09:28Z","published":"2023-11-26T19:09:28Z","title":"Spectro-ViT: A Vision Transformer Model for GABA-edited MRS\n  Reconstruction Using Spectrograms","summary":"  Purpose: To investigate the use of a Vision Transformer (ViT) to\nreconstruct/denoise GABA-edited magnetic resonance spectroscopy (MRS) from a\nquarter of the typically acquired number of transients using spectrograms.\n  Theory and Methods: A quarter of the typically acquired number of transients\ncollected in GABA-edited MRS scans are pre-processed and converted to a\nspectrogram image representation using the Short-Time Fourier Transform (STFT).\nThe image representation of the data allows the adaptation of a pre-trained ViT\nfor reconstructing GABA-edited MRS spectra (Spectro-ViT). The Spectro-ViT is\nfine-tuned and then tested using \\textit{in vivo} GABA-edited MRS data. The\nSpectro-ViT performance is compared against other models in the literature\nusing spectral quality metrics and estimated metabolite concentration values.\n  Results: The Spectro-ViT model significantly outperformed all other models in\nfour out of five quantitative metrics (mean squared error, shape score,\nGABA+/water fit error, and full width at half maximum). The metabolite\nconcentrations estimated (GABA+/water, GABA+/Cr, and Glx/water) were consistent\nwith the metabolite concentrations estimated using typical GABA-edited MRS\nscans reconstructed with the full amount of typically collected transients.\n  Conclusion: The proposed Spectro-ViT model achieved state-of-the-art results\nin reconstructing GABA-edited MRS, and the results indicate these scans could\nbe up to four times faster.\n","authors":["Gabriel Dias","Rodrigo Pommot Berto","Mateus Oliveira","Lucas Ueda","Sergio Dertkigil","Paula D. P. Costa","Amirmohammad Shamaei","Roberto Souza","Ashley Harris","Leticia Rittner"],"pdf_url":"https://arxiv.org/pdf/2311.15386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15384v1","updated":"2023-11-26T19:01:15Z","published":"2023-11-26T19:01:15Z","title":"Robust and Automatic Data Clustering: Dirichlet Process meets\n  Median-of-Means","summary":"  Clustering stands as one of the most prominent challenges within the realm of\nunsupervised machine learning. Among the array of centroid-based clustering\nalgorithms, the classic $k$-means algorithm, rooted in Lloyd's heuristic, takes\ncenter stage as one of the extensively employed techniques in the literature.\nNonetheless, both $k$-means and its variants grapple with noteworthy\nlimitations. These encompass a heavy reliance on initial cluster centroids,\nsusceptibility to converging into local minima of the objective function, and\nsensitivity to outliers and noise in the data. When confronted with data\ncontaining noisy or outlier-laden observations, the Median-of-Means (MoM)\nestimator emerges as a stabilizing force for any centroid-based clustering\nframework. On a different note, a prevalent constraint among existing\nclustering methodologies resides in the prerequisite knowledge of the number of\nclusters prior to analysis. Utilizing model-based methodologies, such as\nBayesian nonparametric models, offers the advantage of infinite mixture models,\nthereby circumventing the need for such requirements. Motivated by these facts,\nin this article, we present an efficient and automatic clustering technique by\nintegrating the principles of model-based and centroid-based methodologies that\nmitigates the effect of noise on the quality of clustering while ensuring that\nthe number of clusters need not be specified in advance. Statistical guarantees\non the upper bound of clustering error, and rigorous assessment through\nsimulated and real datasets suggest the advantages of our proposed method over\nexisting state-of-the-art clustering algorithms.\n","authors":["Supratik Basu","Jyotishka Ray Choudhury","Debolina Paul","Swagatam Das"],"pdf_url":"https://arxiv.org/pdf/2311.15384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15382v1","updated":"2023-11-26T18:55:46Z","published":"2023-11-26T18:55:46Z","title":"Evaluating Multi-Global Server Architecture for Federated Learning","summary":"  Federated learning (FL) with a single global server framework is currently a\npopular approach for training machine learning models on decentralized\nenvironment, such as mobile devices and edge devices. However, the centralized\nserver architecture poses a risk as any challenge on the central/global server\nwould result in the failure of the entire system. To minimize this risk, we\npropose a novel federated learning framework that leverages the deployment of\nmultiple global servers. We posit that implementing multiple global servers in\nfederated learning can enhance efficiency by capitalizing on local\ncollaborations and aggregating knowledge, and the error tolerance in regard to\ncommunication failure in the single server framework would be handled. We\ntherefore propose a novel framework that leverages the deployment of multiple\nglobal servers. We conducted a series of experiments using a dataset containing\nthe event history of electric vehicle (EV) charging at numerous stations. We\ndeployed a federated learning setup with multiple global servers and client\nservers, where each client-server strategically represented a different region\nand a global server was responsible for aggregating local updates from those\ndevices. Our preliminary results of the global models demonstrate that the\ndifference in performance attributed to multiple servers is less than 1%. While\nthe hypothesis of enhanced model efficiency was not as expected, the rule for\nhandling communication challenges added to the algorithm could resolve the\nerror tolerance issue. Future research can focus on identifying specific uses\nfor the deployment of multiple global servers.\n","authors":["Asfia Kawnine","Hung Cao","Atah Nuh Mih","Monica Wachowicz"],"pdf_url":"https://arxiv.org/pdf/2311.15382v1.pdf","comment":"Key words: Federated Learning, Edge AI, Multiple global servers, EV\n  energy consumption"},{"id":"http://arxiv.org/abs/2309.17338v2","updated":"2023-11-26T18:53:50Z","published":"2023-09-29T15:48:35Z","title":"Improving Trajectory Prediction in Dynamic Multi-Agent Environment by\n  Dropping Waypoints","summary":"  The inherently diverse and uncertain nature of trajectories presents a\nformidable challenge in accurately modeling them. Motion prediction systems\nmust effectively learn spatial and temporal information from the past to\nforecast the future trajectories of the agent. Many existing methods learn\ntemporal motion via separate components within stacked models to capture\ntemporal features. Furthermore, prediction methods often operate under the\nassumption that observed trajectory waypoint sequences are complete,\ndisregarding scenarios where missing values may occur, which can influence\ntheir performance. Moreover, these models may be biased toward particular\nwaypoint sequences when making predictions. We propose a novel approach called\nTemporal Waypoint Dropping (TWD) that explicitly incorporates temporal\ndependencies during the training of a trajectory prediction model. By\nstochastically dropping waypoints from past observed trajectories, the model is\nforced to learn the underlying temporal representation from the remaining\nwaypoints, resulting in an improved model. Incorporating stochastic temporal\nwaypoint dropping into the model learning process significantly enhances its\nperformance in scenarios with missing values. Experimental results demonstrate\nour approach's substantial improvement in trajectory prediction capabilities.\nOur approach can complement existing trajectory prediction methods to improve\ntheir prediction accuracy. We evaluate our proposed approach on three datasets:\nNBA Sports VU, ETH-UCY, and TrajNet++.\n","authors":["Pranav Singh Chib","Pravendra Singh"],"pdf_url":"https://arxiv.org/pdf/2309.17338v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2305.14930v2","updated":"2023-11-26T18:36:30Z","published":"2023-05-24T09:13:15Z","title":"In-Context Impersonation Reveals Large Language Models' Strengths and\n  Biases","summary":"  In everyday conversations, humans can take on different roles and adapt their\nvocabulary to their chosen roles. We explore whether LLMs can take on, that is\nimpersonate, different roles when they generate text in-context. We ask LLMs to\nassume different personas before solving vision and language tasks. We do this\nby prefixing the prompt with a persona that is associated either with a social\nidentity or domain expertise. In a multi-armed bandit task, we find that LLMs\npretending to be children of different ages recover human-like developmental\nstages of exploration. In a language-based reasoning task, we find that LLMs\nimpersonating domain experts perform better than LLMs impersonating non-domain\nexperts. Finally, we test whether LLMs' impersonations are complementary to\nvisual information when describing different categories. We find that\nimpersonation can improve performance: an LLM prompted to be a bird expert\ndescribes birds better than one prompted to be a car expert. However,\nimpersonation can also uncover LLMs' biases: an LLM prompted to be a man\ndescribes cars better than one prompted to be a woman. These findings\ndemonstrate that LLMs are capable of taking on diverse roles and that this\nin-context impersonation can be used to uncover their hidden strengths and\nbiases.\n","authors":["Leonard Salewski","Stephan Alaniz","Isabel Rio-Torto","Eric Schulz","Zeynep Akata"],"pdf_url":"https://arxiv.org/pdf/2305.14930v2.pdf","comment":"Published in NeurIPS 2023 (Spotlight)"},{"id":"http://arxiv.org/abs/2310.00967v2","updated":"2023-11-26T18:30:49Z","published":"2023-10-02T08:15:35Z","title":"MiCRO: Near-Zero Cost Gradient Sparsification for Scaling and\n  Accelerating Distributed DNN Training","summary":"  Gradient sparsification is a communication optimisation technique for scaling\nand accelerating distributed deep neural network (DNN) training. It reduces the\nincreasing communication traffic for gradient aggregation. However, existing\nsparsifiers have poor scalability because of the high computational cost of\ngradient selection and/or increase in communication traffic. In particular, an\nincrease in communication traffic is caused by gradient build-up and\ninappropriate threshold for gradient selection.\n  To address these challenges, we propose a novel gradient sparsification\nmethod called MiCRO. In MiCRO, the gradient vector is partitioned, and each\npartition is assigned to the corresponding worker. Each worker then selects\ngradients from its partition, and the aggregated gradients are free from\ngradient build-up. Moreover, MiCRO estimates the accurate threshold to maintain\nthe communication traffic as per user requirement by minimising the compression\nratio error. MiCRO enables near-zero cost gradient sparsification by solving\nexisting problems that hinder the scalability and acceleration of distributed\nDNN training. In our extensive experiments, MiCRO outperformed state-of-the-art\nsparsifiers with an outstanding convergence rate.\n","authors":["Daegun Yoon","Sangyoon Oh"],"pdf_url":"https://arxiv.org/pdf/2310.00967v2.pdf","comment":"30th IEEE International Conference on High Performance Computing,\n  Data, and Analytics (HiPC 2023). Code: https://github.com/kljp/micro"},{"id":"http://arxiv.org/abs/2305.11650v4","updated":"2023-11-26T18:14:26Z","published":"2023-05-19T12:58:25Z","title":"Moment Matching Denoising Gibbs Sampling","summary":"  Energy-Based Models (EBMs) offer a versatile framework for modeling complex\ndata distributions. However, training and sampling from EBMs continue to pose\nsignificant challenges. The widely-used Denoising Score Matching (DSM) method\nfor scalable EBM training suffers from inconsistency issues, causing the energy\nmodel to learn a `noisy' data distribution. In this work, we propose an\nefficient sampling framework: (pseudo)-Gibbs sampling with moment matching,\nwhich enables effective sampling from the underlying clean model when given a\n`noisy' model that has been well-trained via DSM. We explore the benefits of\nour approach compared to related methods and demonstrate how to scale the\nmethod to high-dimensional datasets.\n","authors":["Mingtian Zhang","Alex Hawkins-Hooker","Brooks Paige","David Barber"],"pdf_url":"https://arxiv.org/pdf/2305.11650v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15373v1","updated":"2023-11-26T18:09:24Z","published":"2023-11-26T18:09:24Z","title":"Confidence Is All You Need for MI Attacks","summary":"  In this evolving era of machine learning security, membership inference\nattacks have emerged as a potent threat to the confidentiality of sensitive\ndata. In this attack, adversaries aim to determine whether a particular point\nwas used during the training of a target model. This paper proposes a new\nmethod to gauge a data point's membership in a model's training set. Instead of\ncorrelating loss with membership, as is traditionally done, we have leveraged\nthe fact that training examples generally exhibit higher confidence values when\nclassified into their actual class. During training, the model is essentially\nbeing 'fit' to the training data and might face particular difficulties in\ngeneralization to unseen data. This asymmetry leads to the model achieving\nhigher confidence on the training data as it exploits the specific patterns and\nnoise present in the training data. Our proposed approach leverages the\nconfidence values generated by the machine learning model. These confidence\nvalues provide a probabilistic measure of the model's certainty in its\npredictions and can further be used to infer the membership of a given data\npoint. Additionally, we also introduce another variant of our method that\nallows us to carry out this attack without knowing the ground truth(true class)\nof a given data point, thus offering an edge over existing label-dependent\nattack methods.\n","authors":["Abhishek Sinha","Himanshi Tibrewal","Mansi Gupta","Nikhar Waghela","Shivank Garg"],"pdf_url":"https://arxiv.org/pdf/2311.15373v1.pdf","comment":"2 pages, 1 figure"},{"id":"http://arxiv.org/abs/2311.15369v1","updated":"2023-11-26T17:48:53Z","published":"2023-11-26T17:48:53Z","title":"TD-Net: A Tri-domain network for sparse-view CT reconstruction","summary":"  Sparse-view CT reconstruction, aimed at reducing X-ray radiation risks,\nfrequently suffers from image quality degradation, manifested as noise and\nartifacts. Existing post-processing and dual-domain techniques, although\neffective in radiation reduction, often lead to over-smoothed results,\ncompromising diagnostic clarity. Addressing this, we introduce TD-Net, a\npioneering tri-domain approach that unifies sinogram, image, and frequency\ndomain optimizations. By incorporating Frequency Supervision Module(FSM),\nTD-Net adeptly preserves intricate details, overcoming the prevalent\nover-smoothing issue. Extensive evaluations demonstrate TD-Net's superior\nperformance in reconstructing high-quality CT images from sparse views,\nefficiently balancing radiation safety and image fidelity. The enhanced\ncapabilities of TD-Net in varied noise scenarios highlight its potential as a\nbreakthrough in medical imaging.\n","authors":["Xinyuan Wang","Changqing Su","Bo Xiong"],"pdf_url":"https://arxiv.org/pdf/2311.15369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15366v1","updated":"2023-11-26T17:45:57Z","published":"2023-11-26T17:45:57Z","title":"Untargeted Code Authorship Evasion with Seq2Seq Transformation","summary":"  Code authorship attribution is the problem of identifying authors of\nprogramming language codes through the stylistic features in their codes, a\ntopic that recently witnessed significant interest with outstanding\nperformance. In this work, we present SCAE, a code authorship obfuscation\ntechnique that leverages a Seq2Seq code transformer called StructCoder. SCAE\ncustomizes StructCoder, a system designed initially for function-level code\ntranslation from one language to another (e.g., Java to C#), using transfer\nlearning. SCAE improved the efficiency at a slight accuracy degradation\ncompared to existing work. We also reduced the processing time by about 68%\nwhile maintaining an 85% transformation success rate and up to 95.77% evasion\nsuccess rate in the untargeted setting.\n","authors":["Soohyeon Choi","Rhongho Jang","DaeHun Nyang","David Mohaisen"],"pdf_url":"https://arxiv.org/pdf/2311.15366v1.pdf","comment":"9 pages, 1 figure, 5 tables"},{"id":"http://arxiv.org/abs/2311.15365v1","updated":"2023-11-26T17:44:29Z","published":"2023-11-26T17:44:29Z","title":"A Convergence result of a continuous model of deep learning via\n  Łojasiewicz--Simon inequality","summary":"  This study focuses on a Wasserstein-type gradient flow, which represents an\noptimization process of a continuous model of a Deep Neural Network (DNN).\nFirst, we establish the existence of a minimizer for an average loss of the\nmodel under $L^2$-regularization. Subsequently, we show the existence of a\ncurve of maximal slope of the loss. Our main result is the convergence of flow\nto a critical point of the loss as time goes to infinity. An essential aspect\nof proving this result involves the establishment of the \\L{}ojasiewicz--Simon\ngradient inequality for the loss. We derive this inequality by assuming the\nanalyticity of NNs and loss functions. Our proofs offer a new approach for\nanalyzing the asymptotic behavior of Wasserstein-type gradient flows for\nnonconvex functionals.\n","authors":["Noboru Isobe"],"pdf_url":"https://arxiv.org/pdf/2311.15365v1.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2308.11978v2","updated":"2023-11-26T17:41:49Z","published":"2023-08-23T07:57:45Z","title":"Will More Expressive Graph Neural Networks do Better on Generative\n  Tasks?","summary":"  Graph generation poses a significant challenge as it involves predicting a\ncomplete graph with multiple nodes and edges based on simply a given label.\nThis task also carries fundamental importance to numerous real-world\napplications, including de-novo drug and molecular design. In recent years,\nseveral successful methods have emerged in the field of graph generation.\nHowever, these approaches suffer from two significant shortcomings: (1) the\nunderlying Graph Neural Network (GNN) architectures used in these methods are\noften underexplored; and (2) these methods are often evaluated on only a\nlimited number of metrics. To fill this gap, we investigate the expressiveness\nof GNNs under the context of the molecular graph generation task, by replacing\nthe underlying GNNs of graph generative models with more expressive GNNs.\nSpecifically, we analyse the performance of six GNNs on six different molecular\ngenerative objectives on the ZINC-250k dataset in two different generative\nframeworks: autoregressive generation models, such as GCPN and GraphAF, and\none-shot generation models, such as GraphEBM. Through our extensive\nexperiments, we demonstrate that advanced GNNs can indeed improve the\nperformance of GCPN, GraphAF, and GraphEBM on molecular generation tasks, but\nGNN expressiveness is not a necessary condition for a good GNN-based generative\nmodel. Moreover, we show that GCPN and GraphAF with advanced GNNs can achieve\nstate-of-the-art results across 17 other non-GNN-based graph generative\napproaches, such as variational autoencoders and Bayesian optimisation models,\non the proposed molecular generative objectives (DRD2, Median1, Median2), which\nare important metrics for de-novo molecular design.\n","authors":["Xiandong Zou","Xiangyu Zhao","Pietro Liò","Yiren Zhao"],"pdf_url":"https://arxiv.org/pdf/2308.11978v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.06756v2","updated":"2023-11-26T17:24:31Z","published":"2023-10-10T16:27:12Z","title":"Going Beyond Neural Network Feature Similarity: The Network Feature\n  Complexity and Its Interpretation Using Category Theory","summary":"  The behavior of neural networks still remains opaque, and a recently widely\nnoted phenomenon is that networks often achieve similar performance when\ninitialized with different random parameters. This phenomenon has attracted\nsignificant attention in measuring the similarity between features learned by\ndistinct networks. However, feature similarity could be vague in describing the\nsame feature since equivalent features hardly exist. In this paper, we expand\nthe concept of equivalent feature and provide the definition of what we call\nfunctionally equivalent features. These features produce equivalent output\nunder certain transformations. Using this definition, we aim to derive a more\nintrinsic metric for the so-called feature complexity regarding the redundancy\nof features learned by a neural network at each layer. We offer a formal\ninterpretation of our approach through the lens of category theory, a\nwell-developed area in mathematics. To quantify the feature complexity, we\nfurther propose an efficient algorithm named Iterative Feature Merging. Our\nexperimental results validate our ideas and theories from various perspectives.\nWe empirically demonstrate that the functionally equivalence widely exists\namong different features learned by the same neural network and we could reduce\nthe number of parameters of the network without affecting the performance.The\nIFM shows great potential as a data-agnostic model prune method. We have also\ndrawn several interesting empirical findings regarding the defined feature\ncomplexity.\n","authors":["Yiting Chen","Zhanpeng Zhou","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2310.06756v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.11188v2","updated":"2023-11-26T17:18:23Z","published":"2023-10-17T12:08:15Z","title":"Adversarial Bandits with Multi-User Delayed Feedback: Theory and\n  Application","summary":"  The multi-armed bandit (MAB) models have attracted significant research\nattention due to their applicability and effectiveness in various real-world\nscenarios such as resource allocation, online advertising, and dynamic pricing.\nAs an important branch, the adversarial MAB problems with delayed feedback have\nbeen proposed and studied by many researchers recently where a conceptual\nadversary strategically selects the reward distributions associated with each\narm to challenge the learning algorithm and the agent experiences a delay\nbetween taking an action and receiving the corresponding reward feedback.\nHowever, the existing models restrict the feedback to be generated from only\none user, which makes models inapplicable to the prevailing scenarios of\nmultiple users (e.g. ad recommendation for a group of users). In this paper, we\nconsider that the delayed feedback results are from multiple users and are\nunrestricted on internal distribution. In contrast, the feedback delay is\narbitrary and unknown to the player in advance. Also, for different users in a\nround, the delays in feedback have no assumption of latent correlation. Thus,\nwe formulate an adversarial MAB problem with multi-user delayed feedback and\ndesign a modified EXP3 algorithm MUD-EXP3, which makes a decision at each round\nby considering the importance-weighted estimator of the received feedback from\ndifferent users. On the premise of known terminal round index $T$, the number\nof users $M$, the number of arms $N$, and upper bound of delay $d_{max}$, we\nprove a regret of $\\mathcal{O}(\\sqrt{TM^2\\ln{N}(N\\mathrm{e}+4d_{max})})$.\nFurthermore, for the more common case of unknown $T$, an adaptive algorithm\nAMUD-EXP3 is proposed with a sublinear regret with respect to $T$. Finally,\nextensive experiments are conducted to indicate the correctness and\neffectiveness of our algorithms.\n","authors":["Yandi Li","Jianxiong Guo","Yupeng Li","Tian Wang","Weijia Jia"],"pdf_url":"https://arxiv.org/pdf/2310.11188v2.pdf","comment":"This is an extended version of \"A Modified EXP3 in Adversarial\n  Bandits with Multi-User Delayed Feedback\" published in COCOON 2023"},{"id":"http://arxiv.org/abs/2303.08112v4","updated":"2023-11-26T17:05:42Z","published":"2023-03-14T17:47:09Z","title":"Eliciting Latent Predictions from Transformers with the Tuned Lens","summary":"  We analyze transformers from the perspective of iterative inference, seeking\nto understand how model predictions are refined layer by layer. To do so, we\ntrain an affine probe for each block in a frozen pretrained model, making it\npossible to decode every hidden state into a distribution over the vocabulary.\nOur method, the \\emph{tuned lens}, is a refinement of the earlier ``logit\nlens'' technique, which yielded useful insights but is often brittle.\n  We test our method on various autoregressive language models with up to 20B\nparameters, showing it to be more predictive, reliable and unbiased than the\nlogit lens. With causal experiments, we show the tuned lens uses similar\nfeatures to the model itself. We also find the trajectory of latent predictions\ncan be used to detect malicious inputs with high accuracy. All code needed to\nreproduce our results can be found at\nhttps://github.com/AlignmentResearch/tuned-lens.\n","authors":["Nora Belrose","Zach Furman","Logan Smith","Danny Halawi","Igor Ostrovsky","Lev McKinney","Stella Biderman","Jacob Steinhardt"],"pdf_url":"https://arxiv.org/pdf/2303.08112v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.09620v2","updated":"2023-11-26T16:25:49Z","published":"2023-05-16T17:13:07Z","title":"AI-Augmented Surveys: Leveraging Large Language Models and Surveys for\n  Opinion Prediction","summary":"  Large language models (LLMs) that produce human-like responses have begun to\nrevolutionize research practices in the social sciences. This paper shows how\nwe can integrate LLMs and social surveys to accurately predict individual\nresponses to survey questions that were not asked before. We develop a novel\nmethodological framework to personalize LLMs by considering the meaning of\nsurvey questions derived from their text, the latent beliefs of individuals\ninferred from their response patterns, and the temporal contexts across\ndifferent survey periods through fine-tuning LLMs with survey data. Using the\nGeneral Social Survey from 1972 to 2021, we show that the fine-tuned model\nbased on Alpaca-7b can predict individual responses to survey questions that\nare partially missing as well as entirely missing. The remarkable prediction\ncapabilities allow us to fill in missing trends with high confidence and\npinpoint when public attitudes changed, such as the rising support for same-sex\nmarriage. We discuss practical constraints, socio-demographic representation,\nand ethical concerns regarding individual autonomy and privacy when using LLMs\nfor opinion prediction. This study demonstrates that LLMs and surveys can\nmutually enhance each other's capabilities: LLMs broaden survey potential,\nwhile surveys improve the alignment of LLMs.\n","authors":["Junsol Kim","Byungkyu Lee"],"pdf_url":"https://arxiv.org/pdf/2305.09620v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15341v1","updated":"2023-11-26T15:57:20Z","published":"2023-11-26T15:57:20Z","title":"Generative Modelling of Stochastic Actions with Arbitrary Constraints in\n  Reinforcement Learning","summary":"  Many problems in Reinforcement Learning (RL) seek an optimal policy with\nlarge discrete multidimensional yet unordered action spaces; these include\nproblems in randomized allocation of resources such as placements of multiple\nsecurity resources and emergency response units, etc. A challenge in this\nsetting is that the underlying action space is categorical (discrete and\nunordered) and large, for which existing RL methods do not perform well.\nMoreover, these problems require validity of the realized action (allocation);\nthis validity constraint is often difficult to express compactly in a closed\nmathematical form. The allocation nature of the problem also prefers stochastic\noptimal policies, if one exists. In this work, we address these challenges by\n(1) applying a (state) conditional normalizing flow to compactly represent the\nstochastic policy -- the compactness arises due to the network only producing\none sampled action and the corresponding log probability of the action, which\nis then used by an actor-critic method; and (2) employing an invalid action\nrejection method (via a valid action oracle) to update the base policy. The\naction rejection is enabled by a modified policy gradient that we derive.\nFinally, we conduct extensive experiments to show the scalability of our\napproach compared to prior methods and the ability to enforce arbitrary\nstate-conditional constraints on the support of the distribution of actions in\nany state.\n","authors":["Changyu Chen","Ramesha Karunasena","Thanh Hong Nguyen","Arunesh Sinha","Pradeep Varakantham"],"pdf_url":"https://arxiv.org/pdf/2311.15341v1.pdf","comment":"Accepted in NeurIPS 2023. Website:\n  https://cameron-chen.github.io/flow-iar/"},{"id":"http://arxiv.org/abs/2310.07665v2","updated":"2023-11-26T15:53:28Z","published":"2023-10-11T17:11:10Z","title":"Deep Backtracking Counterfactuals for Causally Compliant Explanations","summary":"  Counterfactuals can offer valuable insights by answering what would have been\nobserved under altered circumstances, conditional on a factual observation.\nWhereas the classical interventional interpretation of counterfactuals has been\nstudied extensively, backtracking constitutes a less studied alternative the\nbacktracking principle has emerged as an alternative philosophy where all\ncausal laws are kept intact. In the present work, we introduce a practical\nmethod for computing backtracking counterfactuals in structural causal models\nthat consist of deep generative components. To this end, we impose conditions\non the structural assignments that enable the generation of counterfactuals by\nsolving a tractable constrained optimization problem in the structured latent\nspace of a causal model. Our formulation also facilitates a comparison with\nmethods in the field of counterfactual explanations. Compared to these, our\nmethod represents a versatile, modular and causally compliant alternative. We\ndemonstrate these properties experimentally on a modified version of MNIST and\nCelebA.\n","authors":["Klaus-Rudolf Kladny","Julius von Kügelgen","Bernhard Schölkopf","Michael Muehlebach"],"pdf_url":"https://arxiv.org/pdf/2310.07665v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15339v1","updated":"2023-11-26T15:50:19Z","published":"2023-11-26T15:50:19Z","title":"Adversarial Purification of Information Masking","summary":"  Adversarial attacks meticulously generate minuscule, imperceptible\nperturbations to images to deceive neural networks. Counteracting these,\nadversarial purification methods seek to transform adversarial input samples\ninto clean output images to defend against adversarial attacks. Nonetheless,\nextent generative models fail to effectively eliminate adversarial\nperturbations, yielding less-than-ideal purification results. We emphasize the\npotential threat of residual adversarial perturbations to target models,\nquantitatively establishing a relationship between perturbation scale and\nattack capability. Notably, the residual perturbations on the purified image\nprimarily stem from the same-position patch and similar patches of the\nadversarial sample. We propose a novel adversarial purification approach named\nInformation Mask Purification (IMPure), aims to extensively eliminate\nadversarial perturbations. To obtain an adversarial sample, we first mask part\nof the patches information, then reconstruct the patches to resist adversarial\nperturbations from the patches. We reconstruct all patches in parallel to\nobtain a cohesive image. Then, in order to protect the purified samples against\npotential similar regional perturbations, we simulate this risk by randomly\nmixing the purified samples with the input samples before inputting them into\nthe feature extraction network. Finally, we establish a combined constraint of\npixel loss and perceptual loss to augment the model's reconstruction\nadaptability. Extensive experiments on the ImageNet dataset with three\nclassifier models demonstrate that our approach achieves state-of-the-art\nresults against nine adversarial attack methods. Implementation code and\npre-trained weights can be accessed at\n\\textcolor{blue}{https://github.com/NoWindButRain/IMPure}.\n","authors":["Sitong Liu","Zhichao Lian","Shuangquan Zhang","Liang Xiao"],"pdf_url":"https://arxiv.org/pdf/2311.15339v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15335v1","updated":"2023-11-26T15:39:57Z","published":"2023-11-26T15:39:57Z","title":"Token Recycling for Efficient Sequential Inference with Vision\n  Transformers","summary":"  Vision Transformers (ViTs) overpass Convolutional Neural Networks in\nprocessing incomplete inputs because they do not require the imputation of\nmissing values. Therefore, ViTs are well suited for sequential decision-making,\ne.g. in the Active Visual Exploration problem. However, they are\ncomputationally inefficient because they perform a full forward pass each time\na piece of new sequential information arrives.\n  To reduce this computational inefficiency, we introduce the TOken REcycling\n(TORE) modification for the ViT inference, which can be used with any\narchitecture. TORE divides ViT into two parts, iterator and aggregator. An\niterator processes sequential information separately into midway tokens, which\nare cached. The aggregator processes midway tokens jointly to obtain the\nprediction. This way, we can reuse the results of computations made by\niterator.\n  Except for efficient sequential inference, we propose a complementary\ntraining policy, which significantly reduces the computational burden\nassociated with sequential decision-making while achieving state-of-the-art\naccuracy.\n","authors":["Jan Olszewski","Dawid Rymarczyk","Piotr Wójcik","Mateusz Pach","Bartosz Zieliński"],"pdf_url":"https://arxiv.org/pdf/2311.15335v1.pdf","comment":"The code will be released upon acceptance"},{"id":"http://arxiv.org/abs/2311.15332v1","updated":"2023-11-26T15:34:36Z","published":"2023-11-26T15:34:36Z","title":"ASI: Accuracy-Stability Index for Evaluating Deep Learning Models","summary":"  In the context of deep learning research, where model introductions\ncontinually occur, the need for effective and efficient evaluation remains\nparamount. Existing methods often emphasize accuracy metrics, overlooking\nstability. To address this, the paper introduces the Accuracy-Stability Index\n(ASI), a quantitative measure incorporating both accuracy and stability for\nassessing deep learning models. Experimental results demonstrate the\napplication of ASI, and a 3D surface model is presented for visualizing ASI,\nmean accuracy, and coefficient of variation. This paper addresses the important\nissue of quantitative benchmarking metrics for deep learning models, providing\na new approach for accurately evaluating accuracy and stability of deep\nlearning models. The paper concludes with discussions on potential weaknesses\nand outlines future research directions.\n","authors":["Wei Dai","Daniel Berleant"],"pdf_url":"https://arxiv.org/pdf/2311.15332v1.pdf","comment":"6 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.15331v1","updated":"2023-11-26T15:31:51Z","published":"2023-11-26T15:31:51Z","title":"How much data do I need? A case study on medical data","summary":"  The collection of data to train a Deep Learning network is costly in terms of\neffort and resources. In many cases, especially in a medical context, it may\nhave detrimental impacts. Such as requiring invasive medical procedures or\nprocesses which could in themselves cause medical harm. However, Deep Learning\nis seen as a data hungry method. Here, we look at two commonly held adages i)\nmore data gives better results and ii) transfer learning will aid you when you\ndon't have enough data. These are widely assumed to be true and used as\nevidence for choosing how to solve a problem when Deep Learning is involved. We\nevaluate six medical datasets and six general datasets. Training a ResNet18\nnetwork on varying subsets of these datasets to evaluate `more data gives\nbetter results'. We take eleven of these datasets as the sources for Transfer\nLearning on subsets of the twelfth dataset -- Chest -- in order to determine\nwhether Transfer Learning is universally beneficial. We go further to see\nwhether multi-stage Transfer Learning provides a consistent benefit. Our\nanalysis shows that the real situation is more complex than these simple adages\n-- more data could lead to a case of diminishing returns and an incorrect\nchoice of dataset for transfer learning can lead to worse performance, with\ndatasets which we would consider highly similar to the Chest dataset giving\nworse results than datasets which are more dissimilar. Multi-stage transfer\nlearning likewise reveals complex relationships between datasets.\n","authors":["Ayse Betul Cengiz","A. Stephen McGough"],"pdf_url":"https://arxiv.org/pdf/2311.15331v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.15327v1","updated":"2023-11-26T15:11:17Z","published":"2023-11-26T15:11:17Z","title":"FRAC-Q-Learning: A Reinforcement Learning with Boredom Avoidance\n  Processes for Social Robots","summary":"  The reinforcement learning algorithms have often been applied to social\nrobots. However, most reinforcement learning algorithms were not optimized for\nthe use of social robots, and consequently they may bore users. We proposed a\nnew reinforcement learning method specialized for the social robot, the\nFRAC-Q-learning, that can avoid user boredom. The proposed algorithm consists\nof a forgetting process in addition to randomizing and categorizing processes.\nThis study evaluated interest and boredom hardness scores of the\nFRAC-Q-learning by a comparison with the traditional Q-learning. The\nFRAC-Q-learning showed significantly higher trend of interest score, and\nindicated significantly harder to bore users compared to the traditional\nQ-learning. Therefore, the FRAC-Q-learning can contribute to develop a social\nrobot that will not bore users. The proposed algorithm can also find\napplications in Web-based communication and educational systems. This paper\npresents the entire process, detailed implementation and a detailed evaluation\nmethod of the of the FRAC-Q-learning for the first time.\n","authors":["Akinari Onishi"],"pdf_url":"https://arxiv.org/pdf/2311.15327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15317v1","updated":"2023-11-26T14:35:28Z","published":"2023-11-26T14:35:28Z","title":"Generalized Graph Prompt: Toward a Unification of Pre-Training and\n  Downstream Tasks on Graphs","summary":"  Graph neural networks have emerged as a powerful tool for graph\nrepresentation learning, but their performance heavily relies on abundant\ntask-specific supervision. To reduce labeling requirement, the \"pre-train,\nprompt\" paradigms have become increasingly common. However, existing study of\nprompting on graphs is limited, lacking a universal treatment to appeal to\ndifferent downstream tasks. In this paper, we propose GraphPrompt, a novel\npre-training and prompting framework on graphs. GraphPrompt not only unifies\npre-training and downstream tasks into a common task template but also employs\na learnable prompt to assist a downstream task in locating the most relevant\nknowledge from the pre-trained model in a task-specific manner. To further\nenhance GraphPrompt in these two stages, we extend it into GraphPrompt+ with\ntwo major enhancements. First, we generalize several popular graph pre-training\ntasks beyond simple link prediction to broaden the compatibility with our task\ntemplate. Second, we propose a more generalized prompt design that incorporates\na series of prompt vectors within every layer of the pre-trained graph encoder,\nin order to capitalize on the hierarchical information across different layers\nbeyond just the readout layer. Finally, we conduct extensive experiments on\nfive public datasets to evaluate and analyze GraphPrompt and GraphPrompt+.\n","authors":["Xingtong Yu","Zhenghao Liu","Yuan Fang","Zemin Liu","Sihong Chen","Xinming Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.15317v1.pdf","comment":"28 pages. Under review. arXiv admin note: substantial text overlap\n  with arXiv:2302.08043"},{"id":"http://arxiv.org/abs/2311.15310v1","updated":"2023-11-26T14:19:46Z","published":"2023-11-26T14:19:46Z","title":"Secure and Verifiable Data Collaboration with Low-Cost Zero-Knowledge\n  Proofs","summary":"  Organizations are increasingly recognizing the value of data collaboration\nfor data analytics purposes. Yet, stringent data protection laws prohibit the\ndirect exchange of raw data. To facilitate data collaboration, federated\nLearning (FL) emerges as a viable solution, which enables multiple clients to\ncollaboratively train a machine learning (ML) model under the supervision of a\ncentral server while ensuring the confidentiality of their raw data. However,\nexisting studies have unveiled two main risks: (i) the potential for the server\nto infer sensitive information from the client's uploaded updates (i.e., model\ngradients), compromising client input privacy, and (ii) the risk of malicious\nclients uploading malformed updates to poison the FL model, compromising input\nintegrity. Recent works utilize secure aggregation with zero-knowledge proofs\n(ZKP) to guarantee input privacy and integrity in FL. Nevertheless, they suffer\nfrom extremely low efficiency and, thus, are impractical for real deployment.\nIn this paper, we propose a novel and highly efficient solution RiseFL for\nsecure and verifiable data collaboration, ensuring input privacy and integrity\nsimultaneously.Firstly, we devise a probabilistic integrity check method that\nsignificantly reduces the cost of ZKP generation and verification. Secondly, we\ndesign a hybrid commitment scheme to satisfy Byzantine robustness with improved\nperformance. Thirdly, we theoretically prove the security guarantee of the\nproposed solution. Extensive experiments on synthetic and real-world datasets\nsuggest that our solution is effective and is highly efficient in both client\ncomputation and communication. For instance, RiseFL is up to 28x, 53x and 164x\nfaster than three state-of-the-art baselines ACORN, RoFL and EIFFeL for the\nclient computation.\n","authors":["Yizheng Zhu","Yuncheng Wu","Zhaojing Luo","Beng Chin Ooi","Xiaokui Xiao"],"pdf_url":"https://arxiv.org/pdf/2311.15310v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2302.05543v3","updated":"2023-11-26T22:26:12Z","published":"2023-02-10T23:12:37Z","title":"Adding Conditional Control to Text-to-Image Diffusion Models","summary":"  We present ControlNet, a neural network architecture to add spatial\nconditioning controls to large, pretrained text-to-image diffusion models.\nControlNet locks the production-ready large diffusion models, and reuses their\ndeep and robust encoding layers pretrained with billions of images as a strong\nbackbone to learn a diverse set of conditional controls. The neural\narchitecture is connected with \"zero convolutions\" (zero-initialized\nconvolution layers) that progressively grow the parameters from zero and ensure\nthat no harmful noise could affect the finetuning. We test various conditioning\ncontrols, eg, edges, depth, segmentation, human pose, etc, with Stable\nDiffusion, using single or multiple conditions, with or without prompts. We\nshow that the training of ControlNets is robust with small (<50k) and large\n(>1m) datasets. Extensive results show that ControlNet may facilitate wider\napplications to control image diffusion models.\n","authors":["Lvmin Zhang","Anyi Rao","Maneesh Agrawala"],"pdf_url":"https://arxiv.org/pdf/2302.05543v3.pdf","comment":"Codes and Supplementary Material:\n  https://github.com/lllyasviel/ControlNet"},{"id":"http://arxiv.org/abs/2307.14335v2","updated":"2023-11-26T14:12:37Z","published":"2023-07-26T17:54:04Z","title":"WavJourney: Compositional Audio Creation with Large Language Models","summary":"  Despite breakthroughs in audio generation models, their capabilities are\noften confined to domain-specific conditions such as speech transcriptions and\naudio captions. However, real-world audio creation aims to generate harmonious\naudio containing various elements such as speech, music, and sound effects with\ncontrollable conditions, which is challenging to address using existing audio\ngeneration systems. We present WavJourney, a novel framework that leverages\nLarge Language Models (LLMs) to connect various audio models for audio\ncreation. WavJourney allows users to create storytelling audio content with\ndiverse audio elements simply from textual descriptions. Specifically, given a\ntext instruction, WavJourney first prompts LLMs to generate an audio script\nthat serves as a structured semantic representation of audio elements. The\naudio script is then converted into a computer program, where each line of the\nprogram calls a task-specific audio generation model or computational operation\nfunction. The computer program is then executed to obtain a compositional and\ninterpretable solution for audio creation. Experimental results suggest that\nWavJourney is capable of synthesizing realistic audio aligned with\ntextually-described semantic, spatial and temporal conditions, achieving\nstate-of-the-art results on text-to-audio generation benchmarks. Additionally,\nwe introduce a new multi-genre story benchmark. Subjective evaluations\ndemonstrate the potential of WavJourney in crafting engaging storytelling audio\ncontent from text. We further demonstrate that WavJourney can facilitate\nhuman-machine co-creation in multi-round dialogues. To foster future research,\nthe code and synthesized audio are available at:\nhttps://audio-agi.github.io/WavJourney_demopage/.\n","authors":["Xubo Liu","Zhongkai Zhu","Haohe Liu","Yi Yuan","Meng Cui","Qiushi Huang","Jinhua Liang","Yin Cao","Qiuqiang Kong","Mark D. Plumbley","Wenwu Wang"],"pdf_url":"https://arxiv.org/pdf/2307.14335v2.pdf","comment":"GitHub: https://github.com/Audio-AGI/WavJourney"},{"id":"http://arxiv.org/abs/2311.15230v1","updated":"2023-11-26T08:04:43Z","published":"2023-11-26T08:04:43Z","title":"GAIA: Zero-shot Talking Avatar Generation","summary":"  Zero-shot talking avatar generation aims at synthesizing natural talking\nvideos from speech and a single portrait image. Previous methods have relied on\ndomain-specific heuristics such as warping-based motion representation and 3D\nMorphable Models, which limit the naturalness and diversity of the generated\navatars. In this work, we introduce GAIA (Generative AI for Avatar), which\neliminates the domain priors in talking avatar generation. In light of the\nobservation that the speech only drives the motion of the avatar while the\nappearance of the avatar and the background typically remain the same\nthroughout the entire video, we divide our approach into two stages: 1)\ndisentangling each frame into motion and appearance representations; 2)\ngenerating motion sequences conditioned on the speech and reference portrait\nimage. We collect a large-scale high-quality talking avatar dataset and train\nthe model on it with different scales (up to 2B parameters). Experimental\nresults verify the superiority, scalability, and flexibility of GAIA as 1) the\nresulting model beats previous baseline models in terms of naturalness,\ndiversity, lip-sync quality, and visual quality; 2) the framework is scalable\nsince larger models yield better results; 3) it is general and enables\ndifferent applications like controllable talking avatar generation and\ntext-instructed avatar generation.\n","authors":["Tianyu He","Junliang Guo","Runyi Yu","Yuchi Wang","Jialiang Zhu","Kaikai An","Leyi Li","Xu Tan","Chunyu Wang","Han Hu","HsiangTao Wu","Sheng Zhao","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2311.15230v1.pdf","comment":"Project page: https://microsoft.github.io/GAIA/"}]},"2023-11-28T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2310.06627v3","updated":"2023-11-28T15:57:16Z","published":"2023-10-10T13:45:59Z","title":"What If the TV Was Off? Examining Counterfactual Reasoning Abilities of\n  Multi-modal Language Models","summary":"  Counterfactual reasoning, a fundamental aspect of human cognition, involves\ncontemplating alternatives to established facts or past events, significantly\nenhancing our abilities in planning and decision-making. In light of the\nadvancements in current multi-modal large language models, we explore their\neffectiveness in counterfactual reasoning. To facilitate this investigation, we\nintroduce a novel dataset, C-VQA, specifically designed to test the\ncounterfactual reasoning capabilities of modern multi-modal large language\nmodels. This dataset is constructed by infusing original questions with\ncounterfactual presuppositions, spanning various types such as numerical and\nboolean queries. It encompasses a mix of real and synthetic data, representing\na wide range of difficulty levels. Our thorough evaluations of contemporary\nvision-language models using this dataset have revealed substantial performance\ndrops, with some models showing up to a 40% decrease, highlighting a\nsignificant gap between current models and human-like vision reasoning\ncapabilities. We hope our dataset will serve as a vital benchmark for\nevaluating the counterfactual reasoning capabilities of models. Code and\ndataset are publicly available at https://bzhao.me/C-VQA/.\n","authors":["Letian Zhang","Xiaotong Zhai","Zhongkai Zhao","Yongshuo Zong","Xin Wen","Bingchen Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.06627v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15544v2","updated":"2023-11-28T02:04:58Z","published":"2023-11-27T05:20:47Z","title":"The effect of source disclosure on evaluation of AI-generated messages:\n  A two-part study","summary":"  Advancements in artificial intelligence (AI) over the last decade demonstrate\nthat machines can exhibit communicative behavior and influence how humans\nthink, feel, and behave. In fact, the recent development of ChatGPT has shown\nthat large language models (LLMs) can be leveraged to generate high-quality\ncommunication content at scale and across domains, suggesting that they will be\nincreasingly used in practice. However, many questions remain about how knowing\nthe source of the messages influences recipients' evaluation of and preference\nfor AI-generated messages compared to human-generated messages. This paper\ninvestigated this topic in the context of vaping prevention messaging. In Study\n1, which was pre-registered, we examined the influence of source disclosure on\npeople's evaluation of AI-generated health prevention messages compared to\nhuman-generated messages. We found that source disclosure (i.e., labeling the\nsource of a message as AI vs. human) significantly impacted the evaluation of\nthe messages but did not significantly alter message rankings. In a follow-up\nstudy (Study 2), we examined how the influence of source disclosure may vary by\nthe participants' negative attitudes towards AI. We found a significant\nmoderating effect of negative attitudes towards AI on message evaluation, but\nnot for message selection. However, for those with moderate levels of negative\nattitudes towards AI, source disclosure decreased the preference for\nAI-generated messages. Overall, the results of this series of studies showed a\nslight bias against AI-generated messages once the source was disclosed, adding\nto the emerging area of study that lies at the intersection of AI and\ncommunication.\n","authors":["Sue Lim","Ralf Schmälzle"],"pdf_url":"https://arxiv.org/pdf/2311.15544v2.pdf","comment":"Manuscript currently under review. Paper presented at 109th Annual\n  National Communication Association (NCA) Conference, November 16-19, 2023. 10\n  pages, 5 figures. Supplementary file formatting updated in current version"},{"id":"http://arxiv.org/abs/2311.17049v1","updated":"2023-11-28T18:55:42Z","published":"2023-11-28T18:55:42Z","title":"MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced\n  Training","summary":"  Contrastive pretraining of image-text foundation models, such as CLIP,\ndemonstrated excellent zero-shot performance and improved robustness on a wide\nrange of downstream tasks. However, these models utilize large\ntransformer-based encoders with significant memory and latency overhead which\npose challenges for deployment on mobile devices. In this work, we introduce\nMobileCLIP -- a new family of efficient image-text models optimized for runtime\nperformance along with a novel and efficient training approach, namely\nmulti-modal reinforced training. The proposed training approach leverages\nknowledge transfer from an image captioning model and an ensemble of strong\nCLIP encoders to improve the accuracy of efficient models. Our approach avoids\ntrain-time compute overhead by storing the additional knowledge in a reinforced\ndataset. MobileCLIP sets a new state-of-the-art latency-accuracy tradeoff for\nzero-shot classification and retrieval tasks on several datasets. Our\nMobileCLIP-S2 variant is 2.3$\\times$ faster while more accurate compared to\nprevious best CLIP model based on ViT-B/16. We further demonstrate the\neffectiveness of our multi-modal reinforced training by training a CLIP model\nbased on ViT-B/16 image backbone and achieving +2.9% average performance\nimprovement on 38 evaluation benchmarks compared to the previous best.\nMoreover, we show that the proposed approach achieves 10$\\times$-1000$\\times$\nimproved learning efficiency when compared with non-reinforced CLIP training.\n","authors":["Pavan Kumar Anasosalu Vasu","Hadi Pouransari","Fartash Faghri","Raviteja Vemulapalli","Oncel Tuzel"],"pdf_url":"https://arxiv.org/pdf/2311.17049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17043v1","updated":"2023-11-28T18:53:43Z","published":"2023-11-28T18:53:43Z","title":"LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models","summary":"  In this work, we present a novel method to tackle the token generation\nchallenge in Vision Language Models (VLMs) for video and image understanding,\ncalled LLaMA-VID. Current VLMs, while proficient in tasks like image captioning\nand visual question answering, face computational burdens when processing long\nvideos due to the excessive visual tokens. LLaMA-VID addresses this issue by\nrepresenting each frame with two distinct tokens, namely context token and\ncontent token. The context token encodes the overall image context based on\nuser input, whereas the content token encapsulates visual cues in each frame.\nThis dual-token strategy significantly reduces the overload of long videos\nwhile preserving critical information. Generally, LLaMA-VID empowers existing\nframeworks to support hour-long videos and pushes their upper limit with an\nextra context token. It is proved to surpass previous methods on most of video-\nor image-based benchmarks. Code is available\nhttps://github.com/dvlab-research/LLaMA-VID}{https://github.com/dvlab-research/LLaMA-VID\n","authors":["Yanwei Li","Chengyao Wang","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2311.17043v1.pdf","comment":"Code is available at https://github.com/dvlab-research/LLaMA-VID"},{"id":"http://arxiv.org/abs/2311.17041v1","updated":"2023-11-28T18:53:06Z","published":"2023-11-28T18:53:06Z","title":"Efficient In-Context Learning in Vision-Language Models for Egocentric\n  Videos","summary":"  Recent advancements in text-only large language models (LLMs) have\nhighlighted the benefit of in-context learning for adapting to new tasks with a\nfew demonstrations. However, extending in-context learning to large\nvision-language models (VLMs) using a huge amount of naturalistic\nvision-language data has shown limited success, particularly for egocentric\nvideos, due to high data collection costs. We propose a novel training method\n$\\mathbb{E}$fficient $\\mathbb{I}$n-context $\\mathbb{L}$earning on\n$\\mathbb{E}$gocentric $\\mathbb{V}$ideos ($\\mathbb{EILEV}$), which elicits\nin-context learning in VLMs for egocentric videos without requiring massive,\nnaturalistic egocentric video datasets. $\\mathbb{EILEV}$ involves architectural\nand training data adaptations to allow the model to process contexts\ninterleaved with video clips and narrations, sampling of in-context examples\nwith clusters of similar verbs and nouns, use of data with skewed marginal\ndistributions with a long tail of infrequent verbs and nouns, as well as\nhomonyms and synonyms. Our evaluations show that $\\mathbb{EILEV}$-trained\nmodels outperform larger VLMs trained on a huge amount of naturalistic data in\nin-context learning. Furthermore, they can generalize to not only\nout-of-distribution, but also novel, rare egocentric videos and texts via\nin-context learning, demonstrating potential for applications requiring\ncost-effective training, and rapid post-deployment adaptability. Our code and\ndemo are available at \\url{https://github.com/yukw777/EILEV}.\n","authors":["Keunwoo Peter Yu","Zheyuan Zhang","Fengyuan Hu","Joyce Chai"],"pdf_url":"https://arxiv.org/pdf/2311.17041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17035v1","updated":"2023-11-28T18:47:03Z","published":"2023-11-28T18:47:03Z","title":"Scalable Extraction of Training Data from (Production) Language Models","summary":"  This paper studies extractable memorization: training data that an adversary\ncan efficiently extract by querying a machine learning model without prior\nknowledge of the training dataset. We show an adversary can extract gigabytes\nof training data from open-source language models like Pythia or GPT-Neo,\nsemi-open models like LLaMA or Falcon, and closed models like ChatGPT. Existing\ntechniques from the literature suffice to attack unaligned models; in order to\nattack the aligned ChatGPT, we develop a new divergence attack that causes the\nmodel to diverge from its chatbot-style generations and emit training data at a\nrate 150x higher than when behaving properly. Our methods show practical\nattacks can recover far more data than previously thought, and reveal that\ncurrent alignment techniques do not eliminate memorization.\n","authors":["Milad Nasr","Nicholas Carlini","Jonathan Hayase","Matthew Jagielski","A. Feder Cooper","Daphne Ippolito","Christopher A. Choquette-Choo","Eric Wallace","Florian Tramèr","Katherine Lee"],"pdf_url":"https://arxiv.org/pdf/2311.17035v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17030v1","updated":"2023-11-28T18:32:19Z","published":"2023-11-28T18:32:19Z","title":"Is This the Subspace You Are Looking for? An Interpretability Illusion\n  for Subspace Activation Patching","summary":"  Mechanistic interpretability aims to understand model behaviors in terms of\nspecific, interpretable features, often hypothesized to manifest as\nlow-dimensional subspaces of activations. Specifically, recent studies have\nexplored subspace interventions (such as activation patching) as a way to\nsimultaneously manipulate model behavior and attribute the features behind it\nto given subspaces.\n  In this work, we demonstrate that these two aims diverge, potentially leading\nto an illusory sense of interpretability. Counterintuitively, even if a\nsubspace intervention makes the model's output behave as if the value of a\nfeature was changed, this effect may be achieved by activating a dormant\nparallel pathway leveraging another subspace that is causally disconnected from\nmodel outputs. We demonstrate this phenomenon in a distilled mathematical\nexample, in two real-world domains (the indirect object identification task and\nfactual recall), and present evidence for its prevalence in practice. In the\ncontext of factual recall, we further show a link to rank-1 fact editing,\nproviding a mechanistic explanation for previous work observing an\ninconsistency between fact editing performance and fact localization.\n  However, this does not imply that activation patching of subspaces is\nintrinsically unfit for interpretability. To contextualize our findings, we\nalso show what a success case looks like in a task (indirect object\nidentification) where prior manual circuit analysis informs an understanding of\nthe location of a feature. We explore the additional evidence needed to argue\nthat a patched subspace is faithful.\n","authors":["Aleksandar Makelov","Georg Lange","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2311.17030v1.pdf","comment":"NeurIPS 2023 Workshop on Attributing Model Behavior at Scale"},{"id":"http://arxiv.org/abs/2310.04438v2","updated":"2023-11-28T18:27:54Z","published":"2023-09-30T22:27:37Z","title":"A Brief History of Prompt: Leveraging Language Models. (Through Advanced\n  Prompting)","summary":"  This paper presents a comprehensive exploration of the evolution of prompt\nengineering and generation in the field of natural language processing (NLP).\nStarting from the early language models and information retrieval systems, we\ntrace the key developments that have shaped prompt engineering over the years.\nThe introduction of attention mechanisms in 2015 revolutionized language\nunderstanding, leading to advancements in controllability and\ncontext-awareness. Subsequent breakthroughs in reinforcement learning\ntechniques further enhanced prompt engineering, addressing issues like exposure\nbias and biases in generated text. We examine the significant contributions in\n2018 and 2019, focusing on fine-tuning strategies, control codes, and\ntemplate-based generation. The paper also discusses the growing importance of\nfairness, human-AI collaboration, and low-resource adaptation. In 2020 and\n2021, contextual prompting and transfer learning gained prominence, while 2022\nand 2023 witnessed the emergence of advanced techniques like unsupervised\npre-training and novel reward shaping. Throughout the paper, we reference\nspecific research studies that exemplify the impact of various developments on\nprompt engineering. The journey of prompt engineering continues, with ethical\nconsiderations being paramount for the responsible and inclusive future of AI\nsystems.\n","authors":["Golam Md Muktadir"],"pdf_url":"https://arxiv.org/pdf/2310.04438v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01270v2","updated":"2023-11-28T18:23:48Z","published":"2023-11-02T14:31:25Z","title":"People Make Better Edits: Measuring the Efficacy of LLM-Generated\n  Counterfactually Augmented Data for Harmful Language Detection","summary":"  NLP models are used in a variety of critical social computing tasks, such as\ndetecting sexist, racist, or otherwise hateful content. Therefore, it is\nimperative that these models are robust to spurious features. Past work has\nattempted to tackle such spurious features using training data augmentation,\nincluding Counterfactually Augmented Data (CADs). CADs introduce minimal\nchanges to existing training data points and flip their labels; training on\nthem may reduce model dependency on spurious features. However, manually\ngenerating CADs can be time-consuming and expensive. Hence in this work, we\nassess if this task can be automated using generative NLP models. We\nautomatically generate CADs using Polyjuice, ChatGPT, and Flan-T5, and evaluate\ntheir usefulness in improving model robustness compared to manually-generated\nCADs. By testing both model performance on multiple out-of-domain test sets and\nindividual data point efficacy, our results show that while manual CADs are\nstill the most effective, CADs generated by ChatGPT come a close second. One\nkey reason for the lower performance of automated methods is that the changes\nthey introduce are often insufficient to flip the original label.\n","authors":["Indira Sen","Dennis Assenmacher","Mattia Samory","Isabelle Augenstein","Wil van der Aalst","Claudia Wagner"],"pdf_url":"https://arxiv.org/pdf/2311.01270v2.pdf","comment":"Preprint of EMNLP'23 paper"},{"id":"http://arxiv.org/abs/2311.16989v1","updated":"2023-11-28T17:44:51Z","published":"2023-11-28T17:44:51Z","title":"ChatGPT's One-year Anniversary: Are Open-Source Large Language Models\n  Catching up?","summary":"  Upon its release in late 2022, ChatGPT has brought a seismic shift in the\nentire landscape of AI, both in research and commerce. Through\ninstruction-tuning a large language model (LLM) with supervised fine-tuning and\nreinforcement learning from human feedback, it showed that a model could answer\nhuman questions and follow instructions on a broad panel of tasks. Following\nthis success, interests in LLMs have intensified, with new LLMs flourishing at\nfrequent interval across academia and industry, including many start-ups\nfocused on LLMs. While closed-source LLMs (e.g., OpenAI's GPT, Anthropic's\nClaude) generally outperform their open-source counterparts, the progress on\nthe latter has been rapid with claims of achieving parity or even better on\ncertain tasks. This has crucial implications not only on research but also on\nbusiness. In this work, on the first anniversary of ChatGPT, we provide an\nexhaustive overview of this success, surveying all tasks where an open-source\nLLM has claimed to be on par or better than ChatGPT.\n","authors":["Hailin Chen","Fangkai Jiao","Xingxuan Li","Chengwei Qin","Mathieu Ravaut","Ruochen Zhao","Caiming Xiong","Shafiq Joty"],"pdf_url":"https://arxiv.org/pdf/2311.16989v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16978v1","updated":"2023-11-28T17:25:34Z","published":"2023-11-28T17:25:34Z","title":"Assessing the influence of attractor-verb distance on grammatical\n  agreement in humans and language models","summary":"  Subject-verb agreement in the presence of an attractor noun located between\nthe main noun and the verb elicits complex behavior: judgments of\ngrammaticality are modulated by the grammatical features of the attractor. For\nexample, in the sentence \"The girl near the boys likes climbing\", the attractor\n(boys) disagrees in grammatical number with the verb (likes), creating a\nlocally implausible transition probability. Here, we parametrically modulate\nthe distance between the attractor and the verb while keeping the length of the\nsentence equal. We evaluate the performance of both humans and two artificial\nneural network models: both make more mistakes when the attractor is closer to\nthe verb, but neural networks get close to the chance level while humans are\nmostly able to overcome the attractor interference. Additionally, we report a\nlinear effect of attractor distance on reaction times. We hypothesize that a\npossible reason for the proximity effect is the calculation of transition\nprobabilities between adjacent words. Nevertheless, classical models of\nattraction such as the cue-based model might suffice to explain this\nphenomenon, thus paving the way for new research. Data and analyses available\nat https://osf.io/d4g6k\n","authors":["Christos-Nikolaos Zacharopoulos","Théo Desbordes","Mathias Sablé-Meyer"],"pdf_url":"https://arxiv.org/pdf/2311.16978v1.pdf","comment":"10 pages (5 main, 2 refs, 3 supplementary) ; 5 figures (3 main, 2\n  supplementary) ; accepted at EMNLP 2023 (no DOI yet)"},{"id":"http://arxiv.org/abs/2311.16965v1","updated":"2023-11-28T17:12:06Z","published":"2023-11-28T17:12:06Z","title":"Natural Language Processing Through Transfer Learning: A Case Study on\n  Sentiment Analysis","summary":"  Artificial intelligence and machine learning have significantly bolstered the\ntechnological world. This paper explores the potential of transfer learning in\nnatural language processing focusing mainly on sentiment analysis. The models\ntrained on the big data can also be used where data are scarce. The claim is\nthat, compared to training models from scratch, transfer learning, using\npre-trained BERT models, can increase sentiment classification accuracy. The\nstudy adopts a sophisticated experimental design that uses the IMDb dataset of\nsentimentally labelled movie reviews. Pre-processing includes tokenization and\nencoding of text data, making it suitable for NLP models. The dataset is used\non a BERT based model, measuring its performance using accuracy. The result\ncomes out to be 100 per cent accurate. Although the complete accuracy could\nappear impressive, it might be the result of overfitting or a lack of\ngeneralization. Further analysis is required to ensure the model's ability to\nhandle diverse and unseen data. The findings underscore the effectiveness of\ntransfer learning in NLP, showcasing its potential to excel in sentiment\nanalysis tasks. However, the research calls for a cautious interpretation of\nperfect accuracy and emphasizes the need for additional measures to validate\nthe model's generalization.\n","authors":["Aman Yadav","Abhishek Vichare"],"pdf_url":"https://arxiv.org/pdf/2311.16965v1.pdf","comment":"12 pages, 1 table, 4 figures"},{"id":"http://arxiv.org/abs/2311.16941v1","updated":"2023-11-28T16:46:14Z","published":"2023-11-28T16:46:14Z","title":"Debiasing Multimodal Models via Causal Information Minimization","summary":"  Most existing debiasing methods for multimodal models, including causal\nintervention and inference methods, utilize approximate heuristics to represent\nthe biases, such as shallow features from early stages of training or unimodal\nfeatures for multimodal tasks like VQA, etc., which may not be accurate. In\nthis paper, we study bias arising from confounders in a causal graph for\nmultimodal data and examine a novel approach that leverages causally-motivated\ninformation minimization to learn the confounder representations. Robust\npredictive features contain diverse information that helps a model generalize\nto out-of-distribution data. Hence, minimizing the information content of\nfeatures obtained from a pretrained biased model helps learn the simplest\npredictive features that capture the underlying data distribution. We treat\nthese features as confounder representations and use them via methods motivated\nby causal theory to remove bias from models. We find that the learned\nconfounder representations indeed capture dataset biases, and the proposed\ndebiasing methods improve out-of-distribution (OOD) performance on multiple\nmultimodal datasets without sacrificing in-distribution performance.\nAdditionally, we introduce a novel metric to quantify the sufficiency of\nspurious features in models' predictions that further demonstrates the\neffectiveness of our proposed methods. Our code is available at:\nhttps://github.com/Vaidehi99/CausalInfoMin\n","authors":["Vaidehi Patil","Adyasha Maharana","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2311.16941v1.pdf","comment":"EMNLP 2023 Findings (16 pages)"},{"id":"http://arxiv.org/abs/2311.16922v1","updated":"2023-11-28T16:26:35Z","published":"2023-11-28T16:26:35Z","title":"Mitigating Object Hallucinations in Large Vision-Language Models through\n  Visual Contrastive Decoding","summary":"  Large Vision-Language Models (LVLMs) have advanced considerably, intertwining\nvisual recognition and language understanding to generate content that is not\nonly coherent but also contextually attuned. Despite their success, LVLMs still\nsuffer from the issue of object hallucinations, where models generate plausible\nyet incorrect outputs that include objects that do not exist in the images. To\nmitigate this issue, we introduce Visual Contrastive Decoding (VCD), a simple\nand training-free method that contrasts output distributions derived from\noriginal and distorted visual inputs. The proposed VCD effectively reduces the\nover-reliance on statistical bias and unimodal priors, two essential causes of\nobject hallucinations. This adjustment ensures the generated content is closely\ngrounded to visual inputs, resulting in contextually accurate outputs. Our\nexperiments show that VCD, without either additional training or the usage of\nexternal tools, significantly mitigates the object hallucination issue across\ndifferent LVLM families. Beyond mitigating object hallucinations, VCD also\nexcels in general LVLM benchmarks, highlighting its wide-ranging applicability.\n","authors":["Sicong Leng","Hang Zhang","Guanzheng Chen","Xin Li","Shijian Lu","Chunyan Miao","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2311.16922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08659v4","updated":"2023-11-28T16:06:59Z","published":"2023-10-12T18:34:08Z","title":"LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models","summary":"  Quantization is an indispensable technique for serving Large Language Models\n(LLMs) and has recently found its way into LoRA fine-tuning. In this work we\nfocus on the scenario where quantization and LoRA fine-tuning are applied\ntogether on a pre-trained model. In such cases it is common to observe a\nconsistent gap in the performance on downstream tasks between full fine-tuning\nand quantization plus LoRA fine-tuning approach. In response, we propose LoftQ\n(LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that\nsimultaneously quantizes an LLM and finds a proper low-rank initialization for\nLoRA fine-tuning. Such an initialization alleviates the discrepancy between the\nquantized and full-precision model and significantly improves generalization in\ndownstream tasks. We evaluate our method on natural language understanding,\nquestion answering, summarization, and natural language generation tasks.\nExperiments show that our method is highly effective and outperforms existing\nquantization methods, especially in the challenging 2-bit and 2/4-bit mixed\nprecision regimes. The code is available on https://github.com/yxli2123/LoftQ.\n","authors":["Yixiao Li","Yifan Yu","Chen Liang","Pengcheng He","Nikos Karampatziakis","Weizhu Chen","Tuo Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.08659v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16882v1","updated":"2023-11-28T15:31:11Z","published":"2023-11-28T15:31:11Z","title":"Optimisation-Based Multi-Modal Semantic Image Editing","summary":"  Image editing affords increased control over the aesthetics and content of\ngenerated images. Pre-existing works focus predominantly on text-based\ninstructions to achieve desired image modifications, which limit edit precision\nand accuracy. In this work, we propose an inference-time editing optimisation,\ndesigned to extend beyond textual edits to accommodate multiple editing\ninstruction types (e.g. spatial layout-based; pose, scribbles, edge maps). We\npropose to disentangle the editing task into two competing subtasks: successful\nlocal image modifications and global content consistency preservation, where\nsubtasks are guided through two dedicated loss functions. By allowing to adjust\nthe influence of each loss function, we build a flexible editing solution that\ncan be adjusted to user preferences. We evaluate our method using text, pose\nand scribble edit conditions, and highlight our ability to achieve complex\nedits, through both qualitative and quantitative experiments.\n","authors":["Bowen Li","Yongxin Yang","Steven McDonagh","Shifeng Zhang","Petru-Daniel Tudosiu","Sarah Parisot"],"pdf_url":"https://arxiv.org/pdf/2311.16882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16867v1","updated":"2023-11-28T15:12:47Z","published":"2023-11-28T15:12:47Z","title":"The Falcon Series of Open Language Models","summary":"  We introduce the Falcon series: 7B, 40B, and 180B parameters causal\ndecoder-only models trained on a diverse high-quality corpora predominantly\nassembled from web data. The largest model, Falcon-180B, has been trained on\nover 3.5 trillion tokens of text--the largest openly documented pretraining\nrun. Falcon-180B significantly outperforms models such as PaLM or Chinchilla,\nand improves upon concurrently developed models such as LLaMA 2 or\nInflection-1. It nears the performance of PaLM-2-Large at a reduced pretraining\nand inference cost, making it, to our knowledge, one of the three best language\nmodels in the world along with GPT-4 and PaLM-2-Large. We report detailed\nevaluations, as well as a deep dive into the methods and custom tooling\nemployed to pretrain Falcon. Notably, we report on our custom distributed\ntraining codebase, allowing us to efficiently pretrain these models on up to\n4,096 A100s on cloud AWS infrastructure with limited interconnect. We release a\n600B tokens extract of our web dataset, as well as the Falcon-7/40/180B models\nunder a permissive license to foster open-science and accelerate the\ndevelopment of an open ecosystem of large language models.\n","authors":["Ebtesam Almazrouei","Hamza Alobeidli","Abdulaziz Alshamsi","Alessandro Cappelli","Ruxandra Cojocaru","Daniel Hesslow","Julien Launay","Quentin Malartic","Daniele Mazzotta","Badreddine Noune","Baptiste Pannier","Guilherme Penedo"],"pdf_url":"https://arxiv.org/pdf/2311.16867v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16865v1","updated":"2023-11-28T15:12:11Z","published":"2023-11-28T15:12:11Z","title":"A Benchmark for Evaluating Machine Translation Metrics on Dialects\n  Without Standard Orthography","summary":"  For sensible progress in natural language processing, it is important that we\nare aware of the limitations of the evaluation metrics we use. In this work, we\nevaluate how robust metrics are to non-standardized dialects, i.e. spelling\ndifferences in language varieties that do not have a standard orthography. To\ninvestigate this, we collect a dataset of human translations and human\njudgments for automatic machine translations from English to two Swiss German\ndialects. We further create a challenge set for dialect variation and benchmark\nexisting metrics' performances. Our results show that existing metrics cannot\nreliably evaluate Swiss German text generation outputs, especially on segment\nlevel. We propose initial design adaptations that increase robustness in the\nface of non-standardized dialects, although there remains much room for further\nimprovement. The dataset, code, and models are available here:\nhttps://github.com/textshuttle/dialect_eval\n","authors":["Noëmi Aepli","Chantal Amrhein","Florian Schottmann","Rico Sennrich"],"pdf_url":"https://arxiv.org/pdf/2311.16865v1.pdf","comment":"WMT 2023 Research Paper"},{"id":"http://arxiv.org/abs/2311.16842v1","updated":"2023-11-28T14:55:52Z","published":"2023-11-28T14:55:52Z","title":"RELIC: Investigating Large Language Model Responses using\n  Self-Consistency","summary":"  Large Language Models (LLMs) are notorious for blending fact with fiction and\ngenerating non-factual content, known as hallucinations. To tackle this\nchallenge, we propose an interactive system that helps users obtain insights\ninto the reliability of the generated text. Our approach is based on the idea\nthat the self-consistency of multiple samples generated by the same LLM relates\nto its confidence in individual claims in the generated texts. Using this idea,\nwe design RELIC, an interactive system that enables users to investigate and\nverify semantic-level variations in multiple long-form responses. This allows\nusers to recognize potentially inaccurate information in the generated text and\nmake necessary corrections. From a user study with ten participants, we\ndemonstrate that our approach helps users better verify the reliability of the\ngenerated text. We further summarize the design implications and lessons\nlearned from this research for inspiring future studies on reliable human-LLM\ninteractions.\n","authors":["Furui Cheng","Vilém Zouhar","Simran Arora","Mrinmaya Sachan","Hendrik Strobelt","Mennatallah El-Assady"],"pdf_url":"https://arxiv.org/pdf/2311.16842v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16840v1","updated":"2023-11-28T14:55:22Z","published":"2023-11-28T14:55:22Z","title":"The Claire French Dialogue Dataset","summary":"  We present the Claire French Dialogue Dataset (CFDD), a resource created by\nmembers of LINAGORA Labs in the context of the OpenLLM France initiative. CFDD\nis a corpus containing roughly 160 million words from transcripts and stage\nplays in French that we have assembled and publicly released in an effort to\nfurther the development of multilingual, open source language models. This\npaper describes the 24 individual corpora of which CFDD is composed and\nprovides links and citations to their original sources. It also provides our\nproposed breakdown of the full CFDD dataset into eight categories of subcorpora\nand describes the process we followed to standardize the format of the final\ndataset. We conclude with a discussion of similar work and future directions.\n","authors":["Julie Hunter","Jérôme Louradour","Virgile Rennard","Ismaïl Harrando","Guokan Shang","Jean-Pierre Lorré"],"pdf_url":"https://arxiv.org/pdf/2311.16840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16839v1","updated":"2023-11-28T14:54:37Z","published":"2023-11-28T14:54:37Z","title":"Beyond Hallucinations: Enhancing LVLMs through Hallucination-Aware\n  Direct Preference Optimization","summary":"  Multimodal large language models have made significant advancements in recent\nyears, yet they still suffer from a common issue known as the \"hallucination\nproblem\" where the models generate textual descriptions that contain inaccurate\nor non-existent content from the image. To address this issue, this paper\nintroduces a novel strategy: Hallucination-Aware Direct Preference Optimization\n(HA-DPO). Our approach treats the hallucination problem as a unique preference\nselection issue, where the model is trained to favor the non-hallucinating\nresponse when presented with two responses of the same image (one accurate and\none hallucinating). This paper also presents an efficient process for\nconstructing hallucination sample pairs to ensure high-quality,\nstyle-consistent pairs for stable HA-DPO training. We applied this strategy to\ntwo mainstream multimodal models, and the results showed a significant\nreduction in the hallucination problem and an enhancement in the models'\ngeneralization capabilities. With HA-DPO, the MiniGPT-4 model demonstrates\nsignificant advancements: POPE accuracy increases from 51.13% to 85.66% (34.5%\nabsolute improvement), and the MME score escalates from 968.58 to 1365.76 (41%\nrelative improvement). The code, models, and datasets will be made publicly\navailable.\n","authors":["Zhiyuan Zhao","Bin Wang","Linke Ouyang","Xiaoyi Dong","Jiaqi Wang","Conghui He"],"pdf_url":"https://arxiv.org/pdf/2311.16839v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2311.16832v1","updated":"2023-11-28T14:49:23Z","published":"2023-11-28T14:49:23Z","title":"CharacterGLM: Customizing Chinese Conversational AI Characters with\n  Large Language Models","summary":"  In this paper, we present CharacterGLM, a series of models built upon\nChatGLM, with model sizes ranging from 6B to 66B parameters. Our CharacterGLM\nis designed for generating Character-based Dialogues (CharacterDial), which\naims to equip a conversational AI system with character customization for\nsatisfying people's inherent social desires and emotional needs. On top of\nCharacterGLM, we can customize various AI characters or social agents by\nconfiguring their attributes (identities, interests, viewpoints, experiences,\nachievements, social relationships, etc.) and behaviors (linguistic features,\nemotional expressions, interaction patterns, etc.). Our model outperforms most\nmainstream close-source large langauge models, including the GPT series,\nespecially in terms of consistency, human-likeness, and engagement according to\nmanual evaluations. We will release our 6B version of CharacterGLM and a subset\nof training data to facilitate further research development in the direction of\ncharacter-based dialogue generation.\n","authors":["Jinfeng Zhou","Zhuang Chen","Dazhen Wan","Bosi Wen","Yi Song","Jifan Yu","Yongkang Huang","Libiao Peng","Jiaming Yang","Xiyao Xiao","Sahand Sabour","Xiaohan Zhang","Wenjing Hou","Yijia Zhang","Yuxiao Dong","Jie Tang","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2311.16832v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2112.03002v2","updated":"2023-11-28T14:37:45Z","published":"2021-11-13T06:59:27Z","title":"GraphPrompt: Graph-Based Prompt Templates for Biomedical Synonym\n  Prediction","summary":"  In the expansion of biomedical dataset, the same category may be labeled with\ndifferent terms, thus being tedious and onerous to curate these terms.\nTherefore, automatically mapping synonymous terms onto the ontologies is\ndesirable, which we name as biomedical synonym prediction task. Unlike\nbiomedical concept normalization (BCN), no clues from context can be used to\nenhance synonym prediction, making it essential to extract graph features from\nontology. We introduce an expert-curated dataset OBO-syn encompassing 70\ndifferent types of concepts and 2 million curated concept-term pairs for\nevaluating synonym prediction methods. We find BCN methods perform weakly on\nthis task for not making full use of graph information. Therefore, we propose\nGraphPrompt, a prompt-based learning approach that creates prompt templates\naccording to the graphs. GraphPrompt obtained 37.2\\% and 28.5\\% improvement on\nzero-shot and few-shot settings respectively, indicating the effectiveness of\nthese graph-based prompt templates. We envision that our method GraphPrompt and\nOBO-syn dataset can be broadly applied to graph-based NLP tasks, and serve as\nthe basis for analyzing diverse and accumulating biomedical data. All the data\nand codes are avalible at: https://github.com/HanwenXuTHU/GraphPrompt\n","authors":["Hanwen Xu","Jiayou Zhang","Zhirui Wang","Shizhuo Zhang","Megh Manoj Bhalerao","Yucong Liu","Dawei Zhu","Sheng Wang"],"pdf_url":"https://arxiv.org/pdf/2112.03002v2.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2311.16822v1","updated":"2023-11-28T14:36:43Z","published":"2023-11-28T14:36:43Z","title":"Large Language Models Suffer From Their Own Output: An Analysis of the\n  Self-Consuming Training Loop","summary":"  Large language models (LLM) have become state of the art in many benchmarks\nand conversational LLM applications like ChatGPT are now widely used by the\npublic. Those LLMs can be used to generate large amounts of content which is\nposted on the internet to various platforms. As LLMs are trained on datasets\nusually collected from the internet, this LLM-generated content might be used\nto train the next generation of LLMs. Therefore, a self-consuming training loop\nemerges in which new LLM generations are trained on the output from the\nprevious generations. We empirically study this self-consuming training loop\nusing a novel dataset to analytically and accurately measure quality and\ndiversity of generated outputs. We find that this self-consuming training loop\ninitially improves both quality and diversity. However, after a few generations\nthe output inevitably degenerates in diversity. We find that the rate of\ndegeneration depends on the proportion of real and generated data.\n","authors":["Martin Briesch","Dominik Sobania","Franz Rothlauf"],"pdf_url":"https://arxiv.org/pdf/2311.16822v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16789v1","updated":"2023-11-28T13:51:32Z","published":"2023-11-28T13:51:32Z","title":"A Survey of the Evolution of Language Model-Based Dialogue Systems","summary":"  Dialogue systems, including task-oriented_dialogue_system (TOD) and\nopen-domain_dialogue_system (ODD), have undergone significant transformations,\nwith language_models (LM) playing a central role. This survey delves into the\nhistorical trajectory of dialogue systems, elucidating their intricate\nrelationship with advancements in language models by categorizing this\nevolution into four distinct stages, each marked by pivotal LM breakthroughs:\n1) Early_Stage: characterized by statistical LMs, resulting in rule-based or\nmachine-learning-driven dialogue_systems; 2) Independent development of TOD and\nODD based on neural_language_models (NLM; e.g., LSTM and GRU), since NLMs lack\nintrinsic knowledge in their parameters; 3) fusion between different types of\ndialogue systems with the advert of pre-trained_language_models (PLMs),\nstarting from the fusion between four_sub-tasks_within_TOD, and then\nTOD_with_ODD; and 4) current LLM-based_dialogue_system, wherein LLMs can be\nused to conduct TOD and ODD seamlessly. Thus, our survey provides a\nchronological perspective aligned with LM breakthroughs, offering a\ncomprehensive review of state-of-the-art research outcomes. What's more, we\nfocus on emerging topics and discuss open challenges, providing valuable\ninsights into future directions for LLM-based_dialogue_systems. Through this\nexploration, we pave the way for a deeper_comprehension of the evolution,\nguiding future developments in LM-based dialogue_systems.\n","authors":["Hongru Wang","Lingzhi Wang","Yiming Du","Liang Chen","Jingyan Zhou","Yufei Wang","Kam-Fai Wong"],"pdf_url":"https://arxiv.org/pdf/2311.16789v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16787v1","updated":"2023-11-28T13:50:50Z","published":"2023-11-28T13:50:50Z","title":"Evaluating Optimal Reference Translations","summary":"  The overall translation quality reached by current machine translation (MT)\nsystems for high-resourced language pairs is remarkably good. Standard methods\nof evaluation are not suitable nor intended to uncover the many translation\nerrors and quality deficiencies that still persist. Furthermore, the quality of\nstandard reference translations is commonly questioned and comparable quality\nlevels have been reached by MT alone in several language pairs. Navigating\nfurther research in these high-resource settings is thus difficult. In this\narticle, we propose a methodology for creating more reliable document-level\nhuman reference translations, called \"optimal reference translations,\" with the\nsimple aim to raise the bar of what should be deemed \"human translation\nquality.\" We evaluate the obtained document-level optimal reference\ntranslations in comparison with \"standard\" ones, confirming a significant\nquality increase and also documenting the relationship between evaluation and\ntranslation editing.\n","authors":["Vilém Zouhar","Věra Kloudová","Martin Popel","Ondřej Bojar"],"pdf_url":"https://arxiv.org/pdf/2311.16787v1.pdf","comment":"To appear in Natural Language Engineering 2024"},{"id":"http://arxiv.org/abs/2310.01837v2","updated":"2023-11-28T13:36:58Z","published":"2023-10-03T07:01:23Z","title":"Extending CAM-based XAI methods for Remote Sensing Imagery Segmentation","summary":"  Current AI-based methods do not provide comprehensible physical\ninterpretations of the utilized data, extracted features, and\npredictions/inference operations. As a result, deep learning models trained\nusing high-resolution satellite imagery lack transparency and explainability\nand can be merely seen as a black box, which limits their wide-level adoption.\nExperts need help understanding the complex behavior of AI models and the\nunderlying decision-making process. The explainable artificial intelligence\n(XAI) field is an emerging field providing means for robust, practical, and\ntrustworthy deployment of AI models. Several XAI techniques have been proposed\nfor image classification tasks, whereas the interpretation of image\nsegmentation remains largely unexplored. This paper offers to bridge this gap\nby adapting the recent XAI classification algorithms and making them usable for\nmuti-class image segmentation, where we mainly focus on buildings' segmentation\nfrom high-resolution satellite images. To benchmark and compare the performance\nof the proposed approaches, we introduce a new XAI evaluation methodology and\nmetric based on \"Entropy\" to measure the model uncertainty. Conventional XAI\nevaluation methods rely mainly on feeding area-of-interest regions from the\nimage back to the pre-trained (utility) model and then calculating the average\nchange in the probability of the target class. Those evaluation metrics lack\nthe needed robustness, and we show that using Entropy to monitor the model\nuncertainty in segmenting the pixels within the target class is more suitable.\nWe hope this work will pave the way for additional XAI research for image\nsegmentation and applications in the remote sensing discipline.\n","authors":["Abdul Karim Gizzini","Mustafa Shukor","Ali J. Ghandour"],"pdf_url":"https://arxiv.org/pdf/2310.01837v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16764v1","updated":"2023-11-28T13:08:26Z","published":"2023-11-28T13:08:26Z","title":"Radiology-Aware Model-Based Evaluation Metric for Report Generation","summary":"  We propose a new automated evaluation metric for machine-generated radiology\nreports using the successful COMET architecture adapted for the radiology\ndomain. We train and publish four medically-oriented model checkpoints,\nincluding one trained on RadGraph, a radiology knowledge graph. Our results\nshow that our metric correlates moderately to high with established metrics\nsuch as BERTscore, BLEU, and CheXbert scores. Furthermore, we demonstrate that\none of our checkpoints exhibits a high correlation with human judgment, as\nassessed using the publicly available annotations of six board-certified\nradiologists, using a set of 200 reports. We also performed our own analysis\ngathering annotations with two radiologists on a collection of 100 reports. The\nresults indicate the potential effectiveness of our method as a\nradiology-specific evaluation metric. The code, data, and model checkpoints to\nreproduce our findings will be publicly available.\n","authors":["Amos Calamida","Farhad Nooralahzadeh","Morteza Rohanian","Koji Fujimoto","Mizuho Nishio","Michael Krauthammer"],"pdf_url":"https://arxiv.org/pdf/2311.16764v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2307.06985v4","updated":"2023-11-28T12:59:20Z","published":"2023-07-13T17:25:28Z","title":"Patent Documents to Engineering Design Knowledge Graphs","summary":"  Aimed at supporting knowledge-intensive tasks in the design process,\npopulating design knowledge from text documents involves the extraction of\ntriples - head entity :: relationship :: tail entity or h :: r :: t that could\nbe combined into a knowledge graph representation. As relationships are largely\nchosen from ontological or common-sense alternatives, knowledge graphs built\nusing these depict an approximation or restricted view of design knowledge,\nrather than what is explicated in text document. In this article, we present a\ndata-driven approach to identify and explicate facts (h :: r :: t) from\nsentences in patent documents. We create a dataset of 44,227 sentences and\nfacts, encompassing all patent classifications while also capturing the\nvariations among patent document sections. Using this dataset, we train taggers\nthat classify tokens to: 1) identify all entities (h) and relationships (r) and\n2) specific relationships (r) for a pair of entities (h :: ___ :: t). While\nthese taggers are built upon transformer-based sequence classification models,\nwe evaluate our proposed method against edge classification approaches that use\nlinear classifiers and graph neural networks, incorporating transformer-based\ntoken embeddings and linguistic features. The simplicity and coverage of the\nproposed method enable its application to patent documents at any scale and\nvariety. Upon deploying an open-source python package, we apply our method to\npatent documents related to fan systems. From the knowledge graphs thus\nextracted, we explain how facts could be generalised to domain ontologies as\nwell as be specified to subsystem levels. We also highlight the importance of\nknowledge graph representations by retrieving and explicating the knowledge of\nkey issues in fan systems, while holding a comparative discussion against\nopinions from ChatGPT.\n","authors":["L Siddharth","Jianxi Luo"],"pdf_url":"https://arxiv.org/pdf/2307.06985v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12399v2","updated":"2023-11-28T12:32:05Z","published":"2023-11-21T07:22:48Z","title":"A Survey of Graph Meets Large Language Model: Progress and Future\n  Directions","summary":"  Graph plays a significant role in representing and analyzing complex\nrelationships in real-world applications such as citation networks, social\nnetworks, and biological data. Recently, Large Language Models (LLMs), which\nhave achieved tremendous success in various domains, have also been leveraged\nin graph-related tasks to surpass traditional Graph Neural Networks (GNNs)\nbased methods and yield state-of-the-art performance. In this survey, we first\npresent a comprehensive review and analysis of existing methods that integrate\nLLMs with graphs. First of all, we propose a new taxonomy, which organizes\nexisting methods into three categories based on the role (i.e., enhancer,\npredictor, and alignment component) played by LLMs in graph-related tasks. Then\nwe systematically survey the representative methods along the three categories\nof the taxonomy. Finally, we discuss the remaining limitations of existing\nstudies and highlight promising avenues for future research. The relevant\npapers are summarized and will be consistently updated at:\nhttps://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.\n","authors":["Yuhan Li","Zhixun Li","Peisong Wang","Jia Li","Xiangguo Sun","Hong Cheng","Jeffrey Xu Yu"],"pdf_url":"https://arxiv.org/pdf/2311.12399v2.pdf","comment":"Work in progress; 13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.16733v1","updated":"2023-11-28T12:29:33Z","published":"2023-11-28T12:29:33Z","title":"LLMs for Science: Usage for Code Generation and Data Analysis","summary":"  Large language models (LLMs) have been touted to enable increased\nproductivity in many areas of today's work life. Scientific research as an area\nof work is no exception: the potential of LLM-based tools to assist in the\ndaily work of scientists has become a highly discussed topic across\ndisciplines. However, we are only at the very onset of this subject of study.\nIt is still unclear how the potential of LLMs will materialise in research\npractice. With this study, we give first empirical evidence on the use of LLMs\nin the research process. We have investigated a set of use cases for LLM-based\ntools in scientific research, and conducted a first study to assess to which\ndegree current tools are helpful. In this paper we report specifically on use\ncases related to software engineering, such as generating application code and\ndeveloping scripts for data analytics. While we studied seemingly simple use\ncases, results across tools differ significantly. Our results highlight the\npromise of LLM-based tools in general, yet we also observe various issues,\nparticularly regarding the integrity of the output these tools provide.\n","authors":["Mohamed Nejjar","Luca Zacharias","Fabian Stiehle","Ingo Weber"],"pdf_url":"https://arxiv.org/pdf/2311.16733v1.pdf","comment":"Preprint; In Submission"},{"id":"http://arxiv.org/abs/2310.02071v4","updated":"2023-11-28T11:23:14Z","published":"2023-10-03T14:13:36Z","title":"Towards End-to-End Embodied Decision Making via Multi-modal Large\n  Language Model: Explorations with GPT4-Vision and Beyond","summary":"  In this study, we explore the potential of Multimodal Large Language Models\n(MLLMs) in improving embodied decision-making processes for agents. While Large\nLanguage Models (LLMs) have been widely used due to their advanced reasoning\nskills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual\nunderstanding and reasoning capabilities. We investigate whether\nstate-of-the-art MLLMs can handle embodied decision-making in an end-to-end\nmanner and whether collaborations between LLMs and MLLMs can enhance\ndecision-making. To address these questions, we introduce a new benchmark\ncalled PCA-EVAL, which evaluates embodied decision-making from the perspectives\nof Perception, Cognition, and Action. Additionally, we propose HOLMES, a\nmulti-agent cooperation framework that allows LLMs to leverage MLLMs and APIs\nto gather multimodal information for informed decision-making. We compare\nend-to-end embodied decision-making and HOLMES on our benchmark and find that\nthe GPT4-Vision model demonstrates strong end-to-end embodied decision-making\nabilities, outperforming GPT4-HOLMES in terms of average decision accuracy\n(+3%). However, this performance is exclusive to the latest GPT4-Vision model,\nsurpassing the open-source state-of-the-art MLLM by 26%. Our results indicate\nthat powerful MLLMs like GPT4-Vision hold promise for decision-making in\nembodied agents, offering new avenues for MLLM research. Code and data are open\nat https://github.com/pkunlp-icler/PCA-EVAL/.\n","authors":["Liang Chen","Yichi Zhang","Shuhuai Ren","Haozhe Zhao","Zefan Cai","Yuchi Wang","Peiyi Wang","Tianyu Liu","Baobao Chang"],"pdf_url":"https://arxiv.org/pdf/2310.02071v4.pdf","comment":"FMDM@NeurIPS2023, Code and data:\n  https://github.com/pkunlp-icler/PCA-EVAL/"},{"id":"http://arxiv.org/abs/2311.16678v1","updated":"2023-11-28T10:50:00Z","published":"2023-11-28T10:50:00Z","title":"Entity-Aspect-Opinion-Sentiment Quadruple Extraction for Fine-grained\n  Sentiment Analysis","summary":"  Product reviews often contain a large number of implicit aspects and\nobject-attribute co-existence cases. Unfortunately, many existing studies in\nAspect-Based Sentiment Analysis (ABSA) have overlooked this issue, which can\nmake it difficult to extract opinions comprehensively and fairly. In this\npaper, we propose a new task called Entity-Aspect-Opinion-Sentiment Quadruple\nExtraction (EASQE), which aims to hierarchically decompose aspect terms into\nentities and aspects to avoid information loss, non-exclusive annotations, and\nopinion misunderstandings in ABSA tasks. To facilitate research in this new\ntask, we have constructed four datasets (Res14-EASQE, Res15-EASQE, Res16-EASQE,\nand Lap14-EASQE) based on the SemEval Restaurant and Laptop datasets. We have\nalso proposed a novel two-stage sequence-tagging based Trigger-Opinion\nframework as the baseline for the EASQE task. Empirical evaluations show that\nour Trigger-Opinion framework can generate satisfactory EASQE results and can\nalso be applied to other ABSA tasks, significantly outperforming\nstate-of-the-art methods. We have made the four datasets and source code of\nTrigger-Opinion publicly available to facilitate further research in this area.\n","authors":["Dan Ma","Jun Xu","Zongyu Wang","Xuezhi Cao","Yunsen Xian"],"pdf_url":"https://arxiv.org/pdf/2311.16678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16675v1","updated":"2023-11-28T10:42:35Z","published":"2023-11-28T10:42:35Z","title":"A Distribution-Based Threshold for Determining Sentence Similarity","summary":"  We hereby present a solution to a semantic textual similarity (STS) problem\nin which it is necessary to match two sentences containing, as the only\ndistinguishing factor, highly specific information (such as names, addresses,\nidentification codes), and from which we need to derive a definition for when\nthey are similar and when they are not. The solution revolves around the use of\na neural network, based on the siamese architecture, to create the\ndistributions of the distances between similar and dissimilar pairs of\nsentences. The goal of these distributions is to find a discriminating factor,\nthat we call \"threshold\", which represents a well-defined quantity that can be\nused to distinguish vector distances of similar pairs from vector distances of\ndissimilar pairs in new predictions and later analyses. In addition, we\ndeveloped a way to score the predictions by combining attributes from both the\ndistributions' features and the way the distance function works. Finally, we\ngeneralize the results showing that they can be transferred to a wider range of\ndomains by applying the system discussed to a well-known and widely used\nbenchmark dataset for STS problems.\n","authors":["Gioele Cadamuro","Marco Gruppo"],"pdf_url":"https://arxiv.org/pdf/2311.16675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.02804v2","updated":"2023-11-28T10:38:19Z","published":"2022-10-06T10:30:53Z","title":"Just ClozE! A Novel Framework for Evaluating the Factual Consistency\n  Faster in Abstractive Summarization","summary":"  The issue of factual consistency in abstractive summarization has received\nextensive attention in recent years, and the evaluation of factual consistency\nbetween summary and document has become an important and urgent task. Most of\nthe current evaluation metrics are adopted from the question answering (QA) or\nnatural language inference (NLI) task. However, the application of QA-based\nmetrics is extremely time-consuming in practice while NLI-based metrics are\nlack of interpretability. In this paper, we propose a cloze-based evaluation\nframework called ClozE and show the great potential of the cloze-based metric.\nIt inherits strong interpretability from QA, while maintaining the speed of\nNLI- level reasoning. We demonstrate that ClozE can reduce the evaluation time\nby nearly 96% relative to QA-based metrics while retaining their\ninterpretability and performance through experiments on six human-annotated\ndatasets and a meta-evaluation benchmark GO FIGURE (Gabriel et al., 2021).\nFinally, we discuss three important facets of ClozE in practice, which further\nshows better overall performance of ClozE compared to other metrics.\n","authors":["Yiyang Li","Lei Li","Marina Litvak","Natalia Vanetik","Dingxin Hu","Yuze Li","Yanquan Zhou"],"pdf_url":"https://arxiv.org/pdf/2210.02804v2.pdf","comment":"The manuscript for JAIR"},{"id":"http://arxiv.org/abs/2310.08992v2","updated":"2023-11-28T10:32:19Z","published":"2023-10-13T10:17:48Z","title":"CodeChain: Towards Modular Code Generation Through Chain of\n  Self-revisions with Representative Sub-modules","summary":"  Large Language Models (LLMs) have already become quite proficient at solving\nsimpler programming tasks like those in HumanEval or MBPP benchmarks. However,\nsolving more complex and competitive programming tasks is still quite\nchallenging for these models - possibly due to their tendency to generate\nsolutions as monolithic code blocks instead of decomposing them into logical\nsub-tasks and sub-modules. On the other hand, experienced programmers\ninstinctively write modularized code with abstraction for solving complex\ntasks, often reusing previously developed modules. To address this gap, we\npropose CodeChain, a novel framework for inference that elicits modularized\ncode generation through a chain of self-revisions, each being guided by some\nrepresentative sub-modules generated in previous iterations. Concretely,\nCodeChain first instructs the LLM to generate modularized codes through\nchain-of-thought prompting. Then it applies a chain of self-revisions by\niterating the two steps: 1) extracting and clustering the generated sub-modules\nand selecting the cluster representatives as the more generic and re-usable\nimplementations, and 2) augmenting the original chain-of-thought prompt with\nthese selected module-implementations and instructing the LLM to re-generate\nnew modularized solutions. We find that by naturally encouraging the LLM to\nreuse the previously developed and verified sub-modules, CodeChain can\nsignificantly boost both modularity as well as correctness of the generated\nsolutions, achieving relative pass@1 improvements of 35% on APPS and 76% on\nCodeContests. It is shown to be effective on both OpenAI LLMs as well as\nopen-sourced LLMs like WizardCoder. We also conduct comprehensive ablation\nstudies with different methods of prompting, number of clusters, model sizes,\nprogram qualities, etc., to provide useful insights that underpin CodeChain's\nsuccess.\n","authors":["Hung Le","Hailin Chen","Amrita Saha","Akash Gokul","Doyen Sahoo","Shafiq Joty"],"pdf_url":"https://arxiv.org/pdf/2310.08992v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16650v1","updated":"2023-11-28T10:02:08Z","published":"2023-11-28T10:02:08Z","title":"Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for\n  Imbalanced Medical Classification","summary":"  Deep learning approaches exhibit promising performances on various text\ntasks. However, they are still struggling on medical text classification since\nsamples are often extremely imbalanced and scarce. Different from existing\nmainstream approaches that focus on supplementary semantics with external\nmedical information, this paper aims to rethink the data challenges in medical\ntexts and present a novel framework-agnostic algorithm called Text2Tree that\nonly utilizes internal label hierarchy in training deep learning models. We\nembed the ICD code tree structure of labels into cascade attention modules for\nlearning hierarchy-aware label representations. Two new learning schemes,\nSimilarity Surrogate Learning (SSL) and Dissimilarity Mixup Learning (DML), are\ndevised to boost text classification by reusing and distinguishing samples of\nother labels following the label representation hierarchy, respectively.\nExperiments on authoritative public datasets and real-world medical records\nshow that our approach stably achieves superior performances over classical and\nadvanced imbalanced classification methods.\n","authors":["Jiahuan Yan","Haojun Gao","Zhang Kai","Weize Liu","Danny Chen","Jian Wu","Jintai Chen"],"pdf_url":"https://arxiv.org/pdf/2311.16650v1.pdf","comment":"EMNLP 2023 Findings. Code: https://github.com/jyansir/Text2Tree"},{"id":"http://arxiv.org/abs/2311.05332v2","updated":"2023-11-28T09:47:57Z","published":"2023-11-09T12:58:37Z","title":"On the Road with GPT-4V(ision): Early Explorations of Visual-Language\n  Model on Autonomous Driving","summary":"  The pursuit of autonomous driving technology hinges on the sophisticated\nintegration of perception, decision-making, and control systems. Traditional\napproaches, both data-driven and rule-based, have been hindered by their\ninability to grasp the nuance of complex driving environments and the\nintentions of other road users. This has been a significant bottleneck,\nparticularly in the development of common sense reasoning and nuanced scene\nunderstanding necessary for safe and reliable autonomous driving. The advent of\nVisual Language Models (VLM) represents a novel frontier in realizing fully\nautonomous vehicle driving. This report provides an exhaustive evaluation of\nthe latest state-of-the-art VLM, GPT-4V(ision), and its application in\nautonomous driving scenarios. We explore the model's abilities to understand\nand reason about driving scenes, make decisions, and ultimately act in the\ncapacity of a driver. Our comprehensive tests span from basic scene recognition\nto complex causal reasoning and real-time decision-making under varying\nconditions. Our findings reveal that GPT-4V demonstrates superior performance\nin scene understanding and causal reasoning compared to existing autonomous\nsystems. It showcases the potential to handle out-of-distribution scenarios,\nrecognize intentions, and make informed decisions in real driving contexts.\nHowever, challenges remain, particularly in direction discernment, traffic\nlight recognition, vision grounding, and spatial reasoning tasks. These\nlimitations underscore the need for further research and development. Project\nis now available on GitHub for interested parties to access and utilize:\n\\url{https://github.com/PJLab-ADG/GPT4V-AD-Exploration}\n","authors":["Licheng Wen","Xuemeng Yang","Daocheng Fu","Xiaofeng Wang","Pinlong Cai","Xin Li","Tao Ma","Yingxuan Li","Linran Xu","Dengke Shang","Zheng Zhu","Shaoyan Sun","Yeqi Bai","Xinyu Cai","Min Dou","Shuanglu Hu","Botian Shi","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2311.05332v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16639v1","updated":"2023-11-28T09:45:02Z","published":"2023-11-28T09:45:02Z","title":"Scaling Political Texts with ChatGPT","summary":"  We use GPT-4 to obtain position estimates of political texts in continuous\nspaces. We develop and validate a new approach by positioning British party\nmanifestos on the economic, social, and immigration policy dimensions and\ntweets by members of the US Congress on the left-right ideological spectrum.\nFor the party manifestos, the correlation between the positions produced by\nGPT-4 and experts is 93% or higher, a performance similar to or better than\nthat obtained with crowdsourced position estimates. For individual tweets, the\npositions obtained with GPT-4 achieve a correlation of 91% with crowdsourced\nposition estimates. For senators of the 117th US Congress, the positions\nobtained with GPT-4 achieve a correlation of 97% with estimates based on roll\ncall votes and of 96% with those based on campaign funding. Correlations are\nalso substantial within party, indicating that position estimates produced with\nGPT-4 capture within-party differences between senators. Overall, using GPT-4\nfor ideological scaling is fast, cost-efficient, and reliable. This approach\nprovides a viable alternative to scaling by both expert raters and\ncrowdsourcing.\n","authors":["Gaël Le Mens","Aina Gallego"],"pdf_url":"https://arxiv.org/pdf/2311.16639v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16620v1","updated":"2023-11-28T09:21:48Z","published":"2023-11-28T09:21:48Z","title":"On the Long Range Abilities of Transformers","summary":"  Despite their dominance in modern DL and, especially, NLP domains,\ntransformer architectures exhibit sub-optimal performance on long-range tasks\ncompared to recent layers that are specifically designed for this purpose. In\nthis work, drawing inspiration from key attributes of long-range layers, such\nas state-space layers, linear RNN layers, and global convolution layers, we\ndemonstrate that minimal modifications to the transformer architecture can\nsignificantly enhance performance on the Long Range Arena (LRA) benchmark, thus\nnarrowing the gap with these specialized layers. We identify that two key\nprinciples for long-range tasks are (i) incorporating an inductive bias towards\nsmoothness, and (ii) locality. As we show, integrating these ideas into the\nattention mechanism improves results with a negligible amount of additional\ncomputation and without any additional trainable parameters. Our theory and\nexperiments also shed light on the reasons for the inferior performance of\ntransformers on long-range tasks and identify critical properties that are\nessential for successfully capturing long-range dependencies.\n","authors":["Itamar Zimerman","Lior Wolf"],"pdf_url":"https://arxiv.org/pdf/2311.16620v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2302.04023v4","updated":"2023-11-28T09:01:12Z","published":"2023-02-08T12:35:34Z","title":"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on\n  Reasoning, Hallucination, and Interactivity","summary":"  This paper proposes a framework for quantitatively evaluating interactive\nLLMs such as ChatGPT using publicly available data sets. We carry out an\nextensive technical evaluation of ChatGPT using 23 data sets covering 8\ndifferent common NLP application tasks. We evaluate the multitask, multilingual\nand multi-modal aspects of ChatGPT based on these data sets and a newly\ndesigned multimodal dataset. We find that ChatGPT outperforms LLMs with\nzero-shot learning on most tasks and even outperforms fine-tuned models on some\ntasks. We find that it is better at understanding non-Latin script languages\nthan generating them. It is able to generate multimodal content from textual\nprompts, via an intermediate code generation step. Moreover, we find that\nChatGPT is 63.41% accurate on average in 10 different reasoning categories\nunder logical reasoning, non-textual reasoning, and commonsense reasoning,\nhence making it an unreliable reasoner. It is, for example, better at deductive\nthan inductive reasoning. ChatGPT suffers from hallucination problems like\nother LLMs and it generates more extrinsic hallucinations from its parametric\nmemory as it does not have access to an external knowledge base. Finally, the\ninteractive feature of ChatGPT enables human collaboration with the underlying\nLLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++\non machine translation, in a multi-turn \"prompt engineering\" fashion. We also\nrelease codebase for evaluation set extraction.\n","authors":["Yejin Bang","Samuel Cahyawijaya","Nayeon Lee","Wenliang Dai","Dan Su","Bryan Wilie","Holy Lovenia","Ziwei Ji","Tiezheng Yu","Willy Chung","Quyet V. Do","Yan Xu","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2302.04023v4.pdf","comment":"45 pages, AACL 2023"},{"id":"http://arxiv.org/abs/2311.16588v1","updated":"2023-11-28T08:13:29Z","published":"2023-11-28T08:13:29Z","title":"MedGen: A Python Natural Language Processing Toolkit for Medical Text\n  Processing","summary":"  This study introduces MedGen, a comprehensive natural language processing\n(NLP) toolkit designed for medical text processing. MedGen is tailored for\nbiomedical researchers and healthcare professionals with an easy-to-use,\nall-in-one solution that requires minimal programming expertise. It includes\n(1) Generative Functions: For the first time, MedGen includes four advanced\ngenerative functions: question answering, text summarization, text\nsimplification, and machine translation; (2) Basic NLP Functions: MedGen\nintegrates 12 essential NLP functions such as word tokenization and sentence\nsegmentation; and (3) Query and Search Capabilities: MedGen provides\nuser-friendly query and search functions on text corpora. We fine-tuned 32\ndomain-specific language models, evaluated them thoroughly on 24 established\nbenchmarks and conducted manual reviews with clinicians. Additionally, we\nexpanded our toolkit by introducing query and search functions, while also\nstandardizing and integrating functions from third-party libraries. The\ntoolkit, its models, and associated data are publicly available via\nhttps://github.com/Yale-LILY/MedGen.\n","authors":["Rui Yang","Qingcheng Zeng","Keen You","Yujie Qiao","Lucas Huang","Chia-Chun Hsieh","Benjamin Rosand","Jeremy Goldwasser","Amisha D Dave","Tiarnan D. L. Keenan","Emily Y Chew","Dragomir Radev","Zhiyong Lu","Hua Xu","Qingyu Chen","Irene Li"],"pdf_url":"https://arxiv.org/pdf/2311.16588v1.pdf","comment":"5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2310.00741v2","updated":"2023-11-28T08:06:53Z","published":"2023-10-01T17:37:31Z","title":"FELM: Benchmarking Factuality Evaluation of Large Language Models","summary":"  Assessing factuality of text generated by large language models (LLMs) is an\nemerging yet crucial research area, aimed at alerting users to potential errors\nand guiding the development of more reliable LLMs. Nonetheless, the evaluators\nassessing factuality necessitate suitable evaluation themselves to gauge\nprogress and foster advancements. This direction remains under-explored,\nresulting in substantial impediments to the progress of factuality evaluators.\nTo mitigate this issue, we introduce a benchmark for Factuality Evaluation of\nlarge Language Models, referred to as felm. In this benchmark, we collect\nresponses generated from LLMs and annotate factuality labels in a fine-grained\nmanner. Contrary to previous studies that primarily concentrate on the\nfactuality of world knowledge (e.g.~information from Wikipedia), felm focuses\non factuality across diverse domains, spanning from world knowledge to math and\nreasoning. Our annotation is based on text segments, which can help pinpoint\nspecific factual errors. The factuality annotations are further supplemented by\npredefined error types and reference links that either support or contradict\nthe statement. In our experiments, we investigate the performance of several\nLLM-based factuality evaluators on felm, including both vanilla LLMs and those\naugmented with retrieval mechanisms and chain-of-thought processes. Our\nfindings reveal that while retrieval aids factuality evaluation, current LLMs\nare far from satisfactory to faithfully detect factual errors.\n","authors":["Shiqi Chen","Yiran Zhao","Jinghan Zhang","I-Chun Chern","Siyang Gao","Pengfei Liu","Junxian He"],"pdf_url":"https://arxiv.org/pdf/2310.00741v2.pdf","comment":"Accepted by NeurIPS 2023 Track on Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2311.16579v1","updated":"2023-11-28T07:47:25Z","published":"2023-11-28T07:47:25Z","title":"Recognizing Conditional Causal Relationships about Emotions and Their\n  Corresponding Conditions","summary":"  The study of causal relationships between emotions and causes in texts has\nrecently received much attention. Most works focus on extracting causally\nrelated clauses from documents. However, none of these works has considered\nthat the causal relationships among the extracted emotion and cause clauses can\nonly be valid under some specific context clauses. To highlight the context in\nsuch special causal relationships, we propose a new task to determine whether\nor not an input pair of emotion and cause has a valid causal relationship under\ndifferent contexts and extract the specific context clauses that participate in\nthe causal relationship. Since the task is new for which no existing dataset is\navailable, we conduct manual annotation on a benchmark dataset to obtain the\nlabels for our tasks and the annotations of each context clause's type that can\nalso be used in some other applications. We adopt negative sampling to\nconstruct the final dataset to balance the number of documents with and without\ncausal relationships. Based on the constructed dataset, we propose an\nend-to-end multi-task framework, where we design two novel and general modules\nto handle the two goals of our task. Specifically, we propose a context masking\nmodule to extract the context clauses participating in the causal\nrelationships. We propose a prediction aggregation module to fine-tune the\nprediction results according to whether the input emotion and causes depend on\nspecific context clauses. Results of extensive comparative experiments and\nablation studies demonstrate the effectiveness and generality of our proposed\nframework.\n","authors":["Xinhong Chen","Zongxi Li","Yaowei Wang","Haoran Xie","Jianping Wang","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2311.16579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.04840v5","updated":"2023-11-28T06:39:41Z","published":"2021-08-10T18:00:14Z","title":"Post-hoc Interpretability for Neural NLP: A Survey","summary":"  Neural networks for NLP are becoming increasingly complex and widespread, and\nthere is a growing concern if these models are responsible to use. Explaining\nmodels helps to address the safety and ethical concerns and is essential for\naccountability. Interpretability serves to provide these explanations in terms\nthat are understandable to humans. Additionally, post-hoc methods provide\nexplanations after a model is learned and are generally model-agnostic. This\nsurvey provides a categorization of how recent post-hoc interpretability\nmethods communicate explanations to humans, it discusses each method in-depth,\nand how they are validated, as the latter is often a common concern.\n","authors":["Andreas Madsen","Siva Reddy","Sarath Chandar"],"pdf_url":"https://arxiv.org/pdf/2108.04840v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.14457v4","updated":"2023-11-28T05:54:11Z","published":"2023-05-23T18:28:42Z","title":"Pre-training Language Models for Comparative Reasoning","summary":"  Comparative reasoning is a process of comparing objects, concepts, or\nentities to draw conclusions, which constitutes a fundamental cognitive\nability. In this paper, we propose a novel framework to pre-train language\nmodels for enhancing their abilities of comparative reasoning over texts. While\nthere have been approaches for NLP tasks that require comparative reasoning,\nthey suffer from costly manual data labeling and limited generalizability to\ndifferent tasks. Our approach introduces a novel method of collecting scalable\ndata for text-based entity comparison, which leverages both structured and\nunstructured data. Moreover, we present a framework of pre-training language\nmodels via three novel objectives on comparative reasoning. Evaluation on\ndownstream tasks including comparative question answering, question generation,\nand summarization shows that our pre-training framework significantly improves\nthe comparative reasoning abilities of language models, especially under\nlow-resource conditions. This work also releases the first integrated benchmark\nfor comparative reasoning.\n","authors":["Mengxia Yu","Zhihan Zhang","Wenhao Yu","Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2305.14457v4.pdf","comment":"EMNLP 2023 - Camera Ready. Typos fixed"},{"id":"http://arxiv.org/abs/2311.04742v2","updated":"2023-11-28T05:25:45Z","published":"2023-11-08T15:11:57Z","title":"Using large language models to study human memory for meaningful\n  narratives","summary":"  One of the most impressive achievements of the AI revolution is the\ndevelopment of large language models that can generate meaningful text and\nrespond to instructions in plain English with no additional training necessary.\nHere we show that language models can be used as a scientific instrument for\nstudying human memory for meaningful material. We developed a pipeline for\ndesigning large scale memory experiments and analyzing the obtained results. We\nperformed online memory experiments with a large number of participants and\ncollected recognition and recall data for narratives of different lengths. We\nfound that both recall and recognition performance scale linearly with\nnarrative length. Furthermore, in order to investigate the role of narrative\ncomprehension in memory, we repeated these experiments using scrambled versions\nof the presented stories. We found that even though recall performance declined\nsignificantly, recognition remained largely unaffected. Interestingly, recalls\nin this condition seem to follow the original narrative order rather than the\nscrambled presentation, pointing to a contextual reconstruction of the story in\nmemory.\n","authors":["Antonios Georgiou","Tankut Can","Mikhail Katkov","Misha Tsodyks"],"pdf_url":"https://arxiv.org/pdf/2311.04742v2.pdf","comment":"v2: 43 pages, with added discussion and a new appendix C"},{"id":"http://arxiv.org/abs/2310.20246v4","updated":"2023-11-28T05:25:14Z","published":"2023-10-31T08:09:20Z","title":"Breaking Language Barriers in Multilingual Mathematical Reasoning:\n  Insights and Observations","summary":"  Existing research predominantly focuses on developing powerful language\nlearning models (LLMs) for mathematical reasoning within monolingual languages,\nwith few explorations in preserving efficacy in a multilingual context. To\nbridge this gap, this paper pioneers exploring and training powerful\nMultilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we\nconstruct the first multilingual math reasoning instruction dataset,\nMGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue\nof training data scarcity in xMR tasks. Based on the collected dataset, we\npropose different training strategies to build powerful xMR LLMs, named\nMathOctopus, notably outperform conventional open-source LLMs and exhibit\nsuperiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B\nreaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond\nremarkable results, we unearth several pivotal observations and insights from\nextensive experiments: (1) When extending the rejection sampling strategy to\nthe multilingual context, it proves effective for model performances, albeit\nlimited. (2) Employing parallel corpora for math Supervised Fine-Tuning (SFT)\nacross multiple languages not only significantly enhances model performance\nmultilingually but also elevates their monolingual performance. This indicates\nthat crafting multilingual corpora can be regarded as a vital strategy for\nenhancing model performance in a specific language, especially in mathematical\nreasoning tasks. For instance, MathOctopus-7B improves its counterparts that\ntrained on English from 42.2% to 50.8% on GSM8K testset.\n","authors":["Nuo Chen","Zinan Zheng","Ning Wu","Ming Gong","Yangqiu Song","Dongmei Zhang","Jia Li"],"pdf_url":"https://arxiv.org/pdf/2310.20246v4.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2310.08559v2","updated":"2023-11-28T05:24:30Z","published":"2023-10-12T17:51:10Z","title":"Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of\n  Language Models with Hypothesis Refinement","summary":"  The ability to derive underlying principles from a handful of observations\nand then generalize to novel situations -- known as inductive reasoning -- is\ncentral to human intelligence. Prior work suggests that language models (LMs)\noften fall short on inductive reasoning, despite achieving impressive success\non research benchmarks. In this work, we conduct a systematic study of the\ninductive reasoning capabilities of LMs through iterative hypothesis\nrefinement, a technique that more closely mirrors the human inductive process\nthan standard input-output prompting. Iterative hypothesis refinement employs a\nthree-step process: proposing, selecting, and refining hypotheses in the form\nof textual rules. By examining the intermediate rules, we observe that LMs are\nphenomenal hypothesis proposers (i.e., generating candidate rules), and when\ncoupled with a (task-specific) symbolic interpreter that is able to\nsystematically filter the proposed set of rules, this hybrid approach achieves\nstrong results across inductive reasoning benchmarks that require inducing\ncausal relations, language-like instructions, and symbolic concepts. However,\nthey also behave as puzzling inductive reasoners, showing notable performance\ngaps between rule induction (i.e., identifying plausible rules) and rule\napplication (i.e., applying proposed rules to instances), suggesting that LMs\nare proposing hypotheses without being able to actually apply the rules.\nThrough empirical and human analyses, we further reveal several discrepancies\nbetween the inductive reasoning processes of LMs and humans, shedding light on\nboth the potentials and limitations of using LMs in inductive reasoning tasks.\n","authors":["Linlu Qiu","Liwei Jiang","Ximing Lu","Melanie Sclar","Valentina Pyatkin","Chandra Bhagavatula","Bailin Wang","Yoon Kim","Yejin Choi","Nouha Dziri","Xiang Ren"],"pdf_url":"https://arxiv.org/pdf/2310.08559v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16522v1","updated":"2023-11-28T05:00:27Z","published":"2023-11-28T05:00:27Z","title":"Evaluation of dynamic characteristics of power grid based on GNN and\n  application on knowledge graph","summary":"  A novel method for detecting faults in power grids using a graph neural\nnetwork (GNN) has been developed, aimed at enhancing intelligent fault\ndiagnosis in network operation and maintenance. This GNN-based approach\nidentifies faulty nodes within the power grid through a specialized electrical\nfeature extraction model coupled with a knowledge graph. Incorporating temporal\ndata, the method leverages the status of nodes from preceding and subsequent\ntime periods to aid in current fault detection. To validate the effectiveness\nof this GNN in extracting node features, a correlation analysis of the output\nfeatures from each node within the neural network layer was conducted. The\nresults from experiments show that this method can accurately locate fault\nnodes in simulated scenarios with a remarkable 99.53% accuracy. Additionally,\nthe graph neural network's feature modeling allows for a qualitative\nexamination of how faults spread across nodes, providing valuable insights for\nanalyzing fault nodes.\n","authors":["Hao Pei","Si Lin","Chuanfu Li","Che Wang","Haoming Chen","Sizhe Li"],"pdf_url":"https://arxiv.org/pdf/2311.16522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16509v1","updated":"2023-11-28T04:49:17Z","published":"2023-11-28T04:49:17Z","title":"StyleCap: Automatic Speaking-Style Captioning from Speech Based on\n  Speech and Language Self-supervised Learning Models","summary":"  We propose StyleCap, a method to generate natural language descriptions of\nspeaking styles appearing in speech. Although most of conventional techniques\nfor para-/non-linguistic information recognition focus on the category\nclassification or the intensity estimation of pre-defined labels, they cannot\nprovide the reasoning of the recognition result in an interpretable manner. As\na first step towards an end-to-end method for generating speaking-style prompts\nfrom speech, i.e., automatic speaking-style captioning, StyleCap uses paired\ndata of speech and natural language descriptions to train neural networks that\npredict prefix vectors fed into a large language model (LLM)-based text decoder\nfrom a speech representation vector. We explore an appropriate text decoder and\nspeech feature representation suitable for this new task. The experimental\nresults demonstrate that our StyleCap leveraging richer LLMs for the text\ndecoder, speech self-supervised learning (SSL) features, and sentence\nrephrasing augmentation improves the accuracy and diversity of generated\nspeaking-style captions. Samples of speaking-style captions generated by our\nStyleCap are publicly available.\n","authors":["Kazuki Yamauchi","Yusuke Ijima","Yuki Saito"],"pdf_url":"https://arxiv.org/pdf/2311.16509v1.pdf","comment":"Submitted to ICASSP 2024"},{"id":"http://arxiv.org/abs/2311.16466v1","updated":"2023-11-28T04:07:34Z","published":"2023-11-28T04:07:34Z","title":"Enhancing Human Persuasion With Large Language Models","summary":"  Although large language models (LLMs) are reshaping various aspects of human\nlife, our current understanding of their impacts remains somewhat constrained.\nHere we investigate the impact of LLMs on human communication, in the context\nof consumer complaints in the financial industry. Employing an AI detection\ntool on more than 780K complaints gathered by the Consumer Financial Protection\nBureau (CFPB), we find evidence of LLM usage in the writing of complaints -\nshortly after the release of ChatGPT. Our analyses reveal that LLM usage is\npositively correlated with the likelihood of obtaining desirable outcomes\n(i.e., offer of relief from financial firms) and suggest that this positive\ncorrelation may be partly due to the linguistic features improved by LLMs. We\ntest this conjecture with a preregistered experiment, which reveals results\nconsistent with those from observational studies: Consumer complaints written\nwith ChatGPT for improved linguistic qualities were more likely to receive\nhypothetical relief offers than the original consumer complaints, demonstrating\nthe LLM's ability to enhance message persuasiveness in human communication.\nBeing some of the earliest empirical evidence on LLM usage for enhancing\npersuasion, our results highlight the transformative potential of LLMs in human\ncommunication.\n","authors":["Minkyu Shin","Jin Kim"],"pdf_url":"https://arxiv.org/pdf/2311.16466v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03211v2","updated":"2023-11-28T03:50:54Z","published":"2023-10-04T23:33:36Z","title":"On the Performance of Multimodal Language Models","summary":"  Instruction-tuned large language models (LLMs) have demonstrated promising\nzero-shot generalization capabilities across various downstream tasks. Recent\nresearch has introduced multimodal capabilities to LLMs by integrating\nindependently pretrained vision encoders through model grafting. These\nmultimodal variants undergo instruction tuning, similar to LLMs, enabling\neffective zero-shot generalization for multimodal tasks. This study conducts a\ncomparative analysis of different multimodal instruction tuning approaches and\nevaluates their performance across a range of tasks, including complex\nreasoning, conversation, image captioning, multiple-choice questions (MCQs),\nand binary classification. Through rigorous benchmarking and ablation\nexperiments, we reveal key insights for guiding architectural choices when\nincorporating multimodal capabilities into LLMs. However, current approaches\nhave limitations; they do not sufficiently address the need for a diverse\nmultimodal instruction dataset, which is crucial for enhancing task\ngeneralization. Additionally, they overlook issues related to truthfulness and\nfactuality when generating responses. These findings illuminate current\nmethodological constraints in adapting language models for image comprehension\nand provide valuable guidance for researchers and practitioners seeking to\nharness multimodal versions of LLMs.\n","authors":["Utsav Garg","Erhan Bas"],"pdf_url":"https://arxiv.org/pdf/2310.03211v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16452v1","updated":"2023-11-28T03:16:12Z","published":"2023-11-28T03:16:12Z","title":"Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case\n  Study in Medicine","summary":"  Generalist foundation models such as GPT-4 have displayed surprising\ncapabilities in a wide variety of domains and tasks. Yet, there is a prevalent\nassumption that they cannot match specialist capabilities of fine-tuned models.\nFor example, most explorations to date on medical competency benchmarks have\nleveraged domain-specific training, as exemplified by efforts on BioGPT and\nMed-PaLM. We build on a prior study of GPT-4's capabilities on medical\nchallenge benchmarks in the absence of special training. Rather than using\nsimple prompting to highlight the model's out-of-the-box capabilities, we\nperform a systematic exploration of prompt engineering. We find that prompting\ninnovation can unlock deeper specialist capabilities and show that GPT-4 easily\ntops prior leading results for medical benchmarks. The prompting methods we\nexplore are general purpose, and make no specific use of domain expertise,\nremoving the need for expert-curated content. Our experimental design carefully\ncontrols for overfitting during the prompt engineering process. We introduce\nMedprompt, based on a composition of several prompting strategies. With\nMedprompt, GPT-4 achieves state-of-the-art results on all nine of the benchmark\ndatasets in the MultiMedQA suite. The method outperforms leading specialist\nmodels such as Med-PaLM 2 by a significant margin with an order of magnitude\nfewer calls to the model. Steering GPT-4 with Medprompt achieves a 27%\nreduction in error rate on the MedQA dataset over the best methods to date\nachieved with specialist models and surpasses a score of 90% for the first\ntime. Beyond medical problems, we show the power of Medprompt to generalize to\nother domains and provide evidence for the broad applicability of the approach\nvia studies of the strategy on exams in electrical engineering, machine\nlearning, philosophy, accounting, law, nursing, and clinical psychology.\n","authors":["Harsha Nori","Yin Tat Lee","Sheng Zhang","Dean Carignan","Richard Edgar","Nicolo Fusi","Nicholas King","Jonathan Larson","Yuanzhi Li","Weishung Liu","Renqian Luo","Scott Mayer McKinney","Robert Osazuwa Ness","Hoifung Poon","Tao Qin","Naoto Usuyama","Chris White","Eric Horvitz"],"pdf_url":"https://arxiv.org/pdf/2311.16452v1.pdf","comment":"21 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.16444v1","updated":"2023-11-28T02:51:13Z","published":"2023-11-28T02:51:13Z","title":"Exo2EgoDVC: Dense Video Captioning of Egocentric Procedural Activities\n  Using Web Instructional Videos","summary":"  We propose a novel benchmark for cross-view knowledge transfer of dense video\ncaptioning, adapting models from web instructional videos with exocentric views\nto an egocentric view. While dense video captioning (predicting time segments\nand their captions) is primarily studied with exocentric videos (e.g.,\nYouCook2), benchmarks with egocentric videos are restricted due to data\nscarcity. To overcome the limited video availability, transferring knowledge\nfrom abundant exocentric web videos is demanded as a practical approach.\nHowever, learning the correspondence between exocentric and egocentric views is\ndifficult due to their dynamic view changes. The web videos contain mixed views\nfocusing on either human body actions or close-up hand-object interactions,\nwhile the egocentric view is constantly shifting as the camera wearer moves.\nThis necessitates the in-depth study of cross-view transfer under complex view\nchanges. In this work, we first create a real-life egocentric dataset (EgoYC2)\nwhose captions are shared with YouCook2, enabling transfer learning between\nthese datasets assuming their ground-truth is accessible. To bridge the view\ngaps, we propose a view-invariant learning method using adversarial training in\nboth the pre-training and fine-tuning stages. While the pre-training is\ndesigned to learn invariant features against the mixed views in the web videos,\nthe view-invariant fine-tuning further mitigates the view gaps between both\ndatasets. We validate our proposed method by studying how effectively it\novercomes the view change problem and efficiently transfers the knowledge to\nthe egocentric domain. Our benchmark pushes the study of the cross-view\ntransfer into a new task domain of dense video captioning and will envision\nmethodologies to describe egocentric videos in natural language.\n","authors":["Takehiko Ohkawa","Takuma Yagi","Taichi Nishimura","Ryosuke Furuta","Atsushi Hashimoto","Yoshitaka Ushiku","Yoichi Sato"],"pdf_url":"https://arxiv.org/pdf/2311.16444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16421v1","updated":"2023-11-28T02:01:25Z","published":"2023-11-28T02:01:25Z","title":"CDEval: A Benchmark for Measuring the Cultural Dimensions of Large\n  Language Models","summary":"  As the scaling of Large Language Models (LLMs) has dramatically enhanced\ntheir capabilities, there has been a growing focus on the alignment problem to\nensure their responsible and ethical use. While existing alignment efforts\npredominantly concentrate on universal values such as the HHH principle, the\naspect of culture, which is inherently pluralistic and diverse, has not\nreceived adequate attention. This work introduces a new benchmark, CDEval,\naimed at evaluating the cultural dimensions of LLMs. CDEval is constructed by\nincorporating both GPT-4's automated generation and human verification,\ncovering six cultural dimensions across seven domains. Our comprehensive\nexperiments provide intriguing insights into the culture of mainstream LLMs,\nhighlighting both consistencies and variations across different dimensions and\ndomains. The findings underscore the importance of integrating cultural\nconsiderations in LLM development, particularly for applications in diverse\ncultural settings. Through CDEval, we aim to broaden the horizon of LLM\nalignment research by including cultural dimensions, thus providing a more\nholistic framework for the future development and evaluation of LLMs. This\nbenchmark serves as a valuable resource for cultural studies in LLMs, paving\nthe way for more culturally aware and sensitive models.\n","authors":["Yuhang Wang","Yanxu Zhu","Chao Kong","Shuyu Wei","Xiaoyuan Yi","Xing Xie","Jitao Sang"],"pdf_url":"https://arxiv.org/pdf/2311.16421v1.pdf","comment":"Work in process"},{"id":"http://arxiv.org/abs/2309.02705v2","updated":"2023-11-28T01:56:17Z","published":"2023-09-06T04:37:20Z","title":"Certifying LLM Safety against Adversarial Prompting","summary":"  Large language models (LLMs) released for public use incorporate guardrails\nto ensure their output is safe, often referred to as \"model alignment.\" An\naligned language model should decline a user's request to produce harmful\ncontent. However, such safety measures are vulnerable to adversarial attacks,\nwhich add maliciously designed token sequences to a harmful prompt to bypass\nthe model's safety guards. In this work, we introduce erase-and-check, the\nfirst framework to defend against adversarial prompts with verifiable safety\nguarantees. We defend against three attack modes: i) adversarial suffix, which\nappends an adversarial sequence at the end of the prompt; ii) adversarial\ninsertion, where the adversarial sequence is inserted anywhere in the middle of\nthe prompt; and iii) adversarial infusion, where adversarial tokens are\ninserted at arbitrary positions in the prompt, not necessarily as a contiguous\nblock. Our experimental results demonstrate that this procedure can obtain\nstrong certified safety guarantees on harmful prompts while maintaining good\nempirical performance on safe prompts. For example, against adversarial\nsuffixes of length 20, it certifiably detects 92% of harmful prompts and labels\n94% of safe prompts correctly using the open-source language model Llama 2 as\nthe safety filter. We further improve the filter's performance, in terms of\naccuracy and speed, by replacing Llama 2 with a DistilBERT safety classifier\nfine-tuned on safe and harmful prompts. Additionally, we propose two efficient\nempirical defenses: i) RandEC, a randomized version of erase-and-check that\nevaluates the safety filter on a small subset of the erased subsequences, and\nii) GradEC, a gradient-based version that optimizes the erased tokens to remove\nthe adversarial sequence. The code for our experiments is available at\nhttps://github.com/aounon/certified-llm-safety.\n","authors":["Aounon Kumar","Chirag Agarwal","Suraj Srinivas","Aaron Jiaxun Li","Soheil Feizi","Himabindu Lakkaraju"],"pdf_url":"https://arxiv.org/pdf/2309.02705v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2311.16103v2","updated":"2023-11-28T18:16:29Z","published":"2023-11-27T18:59:58Z","title":"Video-Bench: A Comprehensive Benchmark and Toolkit for Evaluating\n  Video-based Large Language Models","summary":"  Video-based large language models (Video-LLMs) have been recently introduced,\ntargeting both fundamental improvements in perception and comprehension, and a\ndiverse range of user inquiries. In pursuit of the ultimate goal of achieving\nartificial general intelligence, a truly intelligent Video-LLM model should not\nonly see and understand the surroundings, but also possess human-level\ncommonsense, and make well-informed decisions for the users. To guide the\ndevelopment of such a model, the establishment of a robust and comprehensive\nevaluation system becomes crucial. To this end, this paper proposes\n\\textit{Video-Bench}, a new comprehensive benchmark along with a toolkit\nspecifically designed for evaluating Video-LLMs. The benchmark comprises 10\nmeticulously crafted tasks, evaluating the capabilities of Video-LLMs across\nthree distinct levels: Video-exclusive Understanding, Prior Knowledge-based\nQuestion-Answering, and Comprehension and Decision-making. In addition, we\nintroduce an automatic toolkit tailored to process model outputs for various\ntasks, facilitating the calculation of metrics and generating convenient final\nscores. We evaluate 8 representative Video-LLMs using \\textit{Video-Bench}. The\nfindings reveal that current Video-LLMs still fall considerably short of\nachieving human-like comprehension and analysis of real-world videos, offering\nvaluable insights for future research directions. The benchmark and toolkit are\navailable at: \\url{https://github.com/PKU-YuanGroup/Video-Bench}.\n","authors":["Munan Ning","Bin Zhu","Yujia Xie","Bin Lin","Jiaxi Cui","Lu Yuan","Dongdong Chen","Li Yuan"],"pdf_url":"https://arxiv.org/pdf/2311.16103v2.pdf","comment":"Benchmark is available at\n  https://github.com/PKU-YuanGroup/Video-Bench"},{"id":"http://arxiv.org/abs/2310.06627v3","updated":"2023-11-28T15:57:16Z","published":"2023-10-10T13:45:59Z","title":"What If the TV Was Off? Examining Counterfactual Reasoning Abilities of\n  Multi-modal Language Models","summary":"  Counterfactual reasoning, a fundamental aspect of human cognition, involves\ncontemplating alternatives to established facts or past events, significantly\nenhancing our abilities in planning and decision-making. In light of the\nadvancements in current multi-modal large language models, we explore their\neffectiveness in counterfactual reasoning. To facilitate this investigation, we\nintroduce a novel dataset, C-VQA, specifically designed to test the\ncounterfactual reasoning capabilities of modern multi-modal large language\nmodels. This dataset is constructed by infusing original questions with\ncounterfactual presuppositions, spanning various types such as numerical and\nboolean queries. It encompasses a mix of real and synthetic data, representing\na wide range of difficulty levels. Our thorough evaluations of contemporary\nvision-language models using this dataset have revealed substantial performance\ndrops, with some models showing up to a 40% decrease, highlighting a\nsignificant gap between current models and human-like vision reasoning\ncapabilities. We hope our dataset will serve as a vital benchmark for\nevaluating the counterfactual reasoning capabilities of models. Code and\ndataset are publicly available at https://bzhao.me/C-VQA/.\n","authors":["Letian Zhang","Xiaotong Zhai","Zhongkai Zhao","Yongshuo Zong","Xin Wen","Bingchen Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.06627v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12144v5","updated":"2023-11-28T02:42:02Z","published":"2023-11-20T19:45:27Z","title":"Applications of Large Scale Foundation Models for Autonomous Driving","summary":"  Since DARPA Grand Challenges (rural) in 2004/05 and Urban Challenges in 2007,\nautonomous driving has been the most active field of AI applications. Recently\npowered by large language models (LLMs), chat systems, such as chatGPT and\nPaLM, emerge and rapidly become a promising direction to achieve artificial\ngeneral intelligence (AGI) in natural language processing (NLP). There comes a\nnatural thinking that we could employ these abilities to reformulate autonomous\ndriving. By combining LLM with foundation models, it is possible to utilize the\nhuman knowledge, commonsense and reasoning to rebuild autonomous driving\nsystems from the current long-tailed AI dilemma. In this paper, we investigate\nthe techniques of foundation models and LLMs applied for autonomous driving,\ncategorized as simulation, world model, data annotation and planning or E2E\nsolutions etc.\n","authors":["Yu Huang","Yue Chen","Zhu Li"],"pdf_url":"https://arxiv.org/pdf/2311.12144v5.pdf","comment":"23 pages. arXiv admin note: text overlap with arXiv:2304.03589,\n  arXiv:2306.03000, arXiv:2310.01415, arXiv:2310.14414, arXiv:2309.10228 by\n  other authors"},{"id":"http://arxiv.org/abs/2311.15830v2","updated":"2023-11-28T03:15:50Z","published":"2023-11-27T13:53:53Z","title":"A-JEPA: Joint-Embedding Predictive Architecture Can Listen","summary":"  This paper presents that the masked-modeling principle driving the success of\nlarge foundational vision models can be effectively applied to audio by making\npredictions in a latent space. We introduce Audio-based Joint-Embedding\nPredictive Architecture (A-JEPA), a simple extension method for self-supervised\nlearning from the audio spectrum. Following the design of I-JEPA, our A-JEPA\nencodes visible audio spectrogram patches with a curriculum masking strategy\nvia context encoder, and predicts the representations of regions sampled at\nwell-designed locations. The target representations of those regions are\nextracted by the exponential moving average of context encoder, \\emph{i.e.},\ntarget encoder, on the whole spectrogram. We find it beneficial to transfer\nrandom block masking into time-frequency aware masking in a curriculum manner,\nconsidering the complexity of highly correlated in local time and frequency in\naudio spectrograms. To enhance contextual semantic understanding and\nrobustness, we fine-tune the encoder with a regularized masking on target\ndatasets, instead of input dropping or zero. Empirically, when built with\nVision Transformers structure, we find A-JEPA to be highly scalable and sets\nnew state-of-the-art performance on multiple audio and speech classification\ntasks, outperforming other recent models that use externally supervised\npre-training.\n","authors":["Zhengcong Fei","Mingyuan Fan","Junshi Huang"],"pdf_url":"https://arxiv.org/pdf/2311.15830v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.12532v3","updated":"2023-11-28T03:42:45Z","published":"2023-08-24T03:43:02Z","title":"FedSOL: Stabilized Orthogonal Learning in Federated Learning","summary":"  Federated Learning (FL) aggregates locally trained models from individual\nclients to construct a global model. While FL enables learning a model with\ndata privacy, it often suffers from significant performance degradation when\nclient data distributions are heterogeneous. Many previous FL algorithms have\naddressed this issue by introducing various proximal restrictions. These\nrestrictions aim to encourage global alignment by constraining the deviation of\nlocal learning from the global objective. However, they inherently limit local\nlearning by interfering with the original local objectives. Recently, an\nalternative approach has emerged to improve local learning generality. By\nobtaining local models within a smooth loss landscape, this approach mitigates\nconflicts among different local objectives of the clients. Yet, it does not\nensure stable global alignment, as local learning does not take the global\nobjective into account. In this study, we propose Federated Stability on\nLearning (FedSoL), which combines both the concepts of global alignment and\nlocal generality. In FedSoL, the local learning seeks a parameter region robust\nagainst proximal perturbations. This strategy introduces an implicit proximal\nrestriction effect in local learning while maintaining the original local\nobjective for parameter update. Our experiments show that FedSoL consistently\nachieves state-of-the-art performance on various setups.\n","authors":["Gihun Lee","Minchan Jeong","Sangmook Kim","Jaehoon Oh","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2308.12532v3.pdf","comment":"19 pages, 12 figures"},{"id":"http://arxiv.org/abs/2311.15243v2","updated":"2023-11-28T13:06:43Z","published":"2023-11-26T09:06:40Z","title":"ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection","summary":"  Out-of-distribution (OOD) detection methods often exploit auxiliary outliers\nto train model identifying OOD samples, especially discovering challenging\noutliers from auxiliary outliers dataset to improve OOD detection. However,\nthey may still face limitations in effectively distinguishing between the most\nchallenging OOD samples that are much like in-distribution (ID) data, i.e.,\nID-like samples. To this end, we propose a novel OOD detection framework that\ndiscovers ID-like outliers using CLIP from the vicinity space of the ID\nsamples, thus helping to identify these most challenging OOD samples. Then a\nprompt learning framework is proposed that utilizes the identified ID-like\noutliers to further leverage the capabilities of CLIP for OOD detection.\nBenefiting from the powerful CLIP, we only need a small number of ID samples to\nlearn the prompts of the model without exposing other auxiliary outlier\ndatasets. By focusing on the most challenging ID-like OOD samples and elegantly\nexploiting the capabilities of CLIP, our method achieves superior few-shot\nlearning performance on various real-world image datasets (e.g., in 4-shot OOD\ndetection on the ImageNet-1k dataset, our method reduces the average FPR95 by\n12.16% and improves the average AUROC by 2.76%, compared to state-of-the-art\nmethods).\n","authors":["Yichen Bai","Zongbo Han","Changqing Zhang","Bing Cao","Xiaoheng Jiang","Qinghua Hu"],"pdf_url":"https://arxiv.org/pdf/2311.15243v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2311.17060v1","updated":"2023-11-28T18:59:58Z","published":"2023-11-28T18:59:58Z","title":"Material Palette: Extraction of Materials from a Single Image","summary":"  In this paper, we propose a method to extract physically-based rendering\n(PBR) materials from a single real-world image. We do so in two steps: first,\nwe map regions of the image to material concepts using a diffusion model, which\nallows the sampling of texture images resembling each material in the scene.\nSecond, we benefit from a separate network to decompose the generated textures\ninto Spatially Varying BRDFs (SVBRDFs), providing us with materials ready to be\nused in rendering applications. Our approach builds on existing synthetic\nmaterial libraries with SVBRDF ground truth, but also exploits a\ndiffusion-generated RGB texture dataset to allow generalization to new samples\nusing unsupervised domain adaptation (UDA). Our contributions are thoroughly\nevaluated on synthetic and real-world datasets. We further demonstrate the\napplicability of our method for editing 3D scenes with materials estimated from\nreal photographs. The code and models will be made open-source. Project page:\nhttps://astra-vision.github.io/MaterialPalette/\n","authors":["Ivan Lopes","Fabio Pizzati","Raoul de Charette"],"pdf_url":"https://arxiv.org/pdf/2311.17060v1.pdf","comment":"8 pages, 11 figures, 2 tables. Webpage\n  https://astra-vision.github.io/MaterialPalette/"},{"id":"http://arxiv.org/abs/2311.17061v1","updated":"2023-11-28T18:59:58Z","published":"2023-11-28T18:59:58Z","title":"HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting","summary":"  Realistic 3D human generation from text prompts is a desirable yet\nchallenging task. Existing methods optimize 3D representations like mesh or\nneural fields via score distillation sampling (SDS), which suffers from\ninadequate fine details or excessive training time. In this paper, we propose\nan efficient yet effective framework, HumanGaussian, that generates\nhigh-quality 3D humans with fine-grained geometry and realistic appearance. Our\nkey insight is that 3D Gaussian Splatting is an efficient renderer with\nperiodic Gaussian shrinkage or growing, where such adaptive density control can\nbe naturally guided by intrinsic human structures. Specifically, 1) we first\npropose a Structure-Aware SDS that simultaneously optimizes human appearance\nand geometry. The multi-modal score function from both RGB and depth space is\nleveraged to distill the Gaussian densification and pruning process. 2)\nMoreover, we devise an Annealed Negative Prompt Guidance by decomposing SDS\ninto a noisier generative score and a cleaner classifier score, which well\naddresses the over-saturation issue. The floating artifacts are further\neliminated based on Gaussian size in a prune-only phase to enhance generation\nsmoothness. Extensive experiments demonstrate the superior efficiency and\ncompetitive quality of our framework, rendering vivid 3D humans under diverse\nscenarios. Project Page: https://alvinliu0.github.io/projects/HumanGaussian\n","authors":["Xian Liu","Xiaohang Zhan","Jiaxiang Tang","Ying Shan","Gang Zeng","Dahua Lin","Xihui Liu","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2311.17061v1.pdf","comment":"Project Page: https://alvinliu0.github.io/projects/HumanGaussian"},{"id":"http://arxiv.org/abs/2311.17058v1","updated":"2023-11-28T18:59:57Z","published":"2023-11-28T18:59:57Z","title":"Panoptic Video Scene Graph Generation","summary":"  Towards building comprehensive real-world visual perception systems, we\npropose and study a new problem called panoptic scene graph generation (PVSG).\nPVSG relates to the existing video scene graph generation (VidSGG) problem,\nwhich focuses on temporal interactions between humans and objects grounded with\nbounding boxes in videos. However, the limitation of bounding boxes in\ndetecting non-rigid objects and backgrounds often causes VidSGG to miss key\ndetails crucial for comprehensive video understanding. In contrast, PVSG\nrequires nodes in scene graphs to be grounded by more precise, pixel-level\nsegmentation masks, which facilitate holistic scene understanding. To advance\nresearch in this new area, we contribute the PVSG dataset, which consists of\n400 videos (289 third-person + 111 egocentric videos) with a total of 150K\nframes labeled with panoptic segmentation masks as well as fine, temporal scene\ngraphs. We also provide a variety of baseline methods and share useful design\npractices for future work.\n","authors":["Jingkang Yang","Wenxuan Peng","Xiangtai Li","Zujin Guo","Liangyu Chen","Bo Li","Zheng Ma","Kaiyang Zhou","Wayne Zhang","Chen Change Loy","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2311.17058v1.pdf","comment":"Accepted to CVPR 2023. Project Page:\n  https://jingkang50.github.io/PVSG/. Codebase:\n  https://github.com/LilyDaytoy/OpenPVSG. We provide 400 long videos with\n  frame-level panoptic segmentation, scene graph, dense captions, and QA\n  annotations"},{"id":"http://arxiv.org/abs/2311.17057v1","updated":"2023-11-28T18:59:52Z","published":"2023-11-28T18:59:52Z","title":"ReMoS: Reactive 3D Motion Synthesis for Two-Person Interactions","summary":"  Current approaches for 3D human motion synthesis can generate high-quality 3D\nanimations of digital humans performing a wide variety of actions and gestures.\nHowever, there is still a notable technological gap in addressing the complex\ndynamics of multi-human interactions within this paradigm. In this work, we\nintroduce ReMoS, a denoising diffusion-based probabilistic model for reactive\nmotion synthesis that explores two-person interactions. Given the motion of one\nperson, we synthesize the reactive motion of the second person to complete the\ninteractions between the two. In addition to synthesizing the full-body\nmotions, we also synthesize plausible hand interactions. We show the\nperformance of ReMoS under a wide range of challenging two-person scenarios\nincluding pair-dancing, Ninjutsu, kickboxing, and acrobatics, where one\nperson's movements have complex and diverse influences on the motions of the\nother. We further propose the ReMoCap dataset for two-person interactions\nconsisting of full-body and hand motions. We evaluate our approach through\nmultiple quantitative metrics, qualitative visualizations, and a user study.\nOur results are usable in interactive applications while also providing an\nadequate amount of control for animators.\n","authors":["Anindita Ghosh","Rishabh Dabral","Vladislav Golyanik","Christian Theobalt","Philipp Slusallek"],"pdf_url":"https://arxiv.org/pdf/2311.17057v1.pdf","comment":"13 pages, 8 figures, 3 tables"},{"id":"http://arxiv.org/abs/2311.17056v1","updated":"2023-11-28T18:59:51Z","published":"2023-11-28T18:59:51Z","title":"Self-Supervised Motion Magnification by Backpropagating Through Optical\n  Flow","summary":"  This paper presents a simple, self-supervised method for magnifying subtle\nmotions in video: given an input video and a magnification factor, we\nmanipulate the video such that its new optical flow is scaled by the desired\namount. To train our model, we propose a loss function that estimates the\noptical flow of the generated video and penalizes how far if deviates from the\ngiven magnification factor. Thus, training involves differentiating through a\npretrained optical flow network. Since our model is self-supervised, we can\nfurther improve its performance through test-time adaptation, by finetuning it\non the input video. It can also be easily extended to magnify the motions of\nonly user-selected objects. Our approach avoids the need for synthetic\nmagnification datasets that have been used to train prior learning-based\napproaches. Instead, it leverages the existing capabilities of off-the-shelf\nmotion estimators. We demonstrate the effectiveness of our method through\nevaluations of both visual quality and quantitative metrics on a range of\nreal-world and synthetic videos, and we show our method works for both\nsupervised and unsupervised optical flow methods.\n","authors":["Zhaoying Pan","Daniel Geng","Andrew Owens"],"pdf_url":"https://arxiv.org/pdf/2311.17056v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16504v1","updated":"2023-11-28T18:59:50Z","published":"2023-11-28T18:59:50Z","title":"Rethinking Directional Integration in Neural Radiance Fields","summary":"  Recent works use the Neural radiance field (NeRF) to perform multi-view 3D\nreconstruction, providing a significant leap in rendering photorealistic\nscenes. However, despite its efficacy, NeRF exhibits limited capability of\nlearning view-dependent effects compared to light field rendering or\nimage-based view synthesis. To that end, we introduce a modification to the\nNeRF rendering equation which is as simple as a few lines of code change for\nany NeRF variations, while greatly improving the rendering quality of\nview-dependent effects. By swapping the integration operator and the direction\ndecoder network, we only integrate the positional features along the ray and\nmove the directional terms out of the integration, resulting in a\ndisentanglement of the view-dependent and independent components. The modified\nequation is equivalent to the classical volumetric rendering in ideal cases on\nobject surfaces with Dirac densities. Furthermore, we prove that with the\nerrors caused by network approximation and numerical integration, our rendering\nequation exhibits better convergence properties with lower error accumulations\ncompared to the classical NeRF. We also show that the modified equation can be\ninterpreted as light field rendering with learned ray embeddings. Experiments\non different NeRF variations show consistent improvements in the quality of\nview-dependent effects with our simple modification.\n","authors":["Congyue Deng","Jiawei Yang","Leonidas Guibas","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2311.16504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03089v2","updated":"2023-11-28T18:59:46Z","published":"2023-06-05T17:59:05Z","title":"Brain Diffusion for Visual Exploration: Cortical Discovery using Large\n  Scale Generative Models","summary":"  A long standing goal in neuroscience has been to elucidate the functional\norganization of the brain. Within higher visual cortex, functional accounts\nhave remained relatively coarse, focusing on regions of interest (ROIs) and\ntaking the form of selectivity for broad categories such as faces, places,\nbodies, food, or words. Because the identification of such ROIs has typically\nrelied on manually assembled stimulus sets consisting of isolated objects in\nnon-ecological contexts, exploring functional organization without robust a\npriori hypotheses has been challenging. To overcome these limitations, we\nintroduce a data-driven approach in which we synthesize images predicted to\nactivate a given brain region using paired natural images and fMRI recordings,\nbypassing the need for category-specific stimuli. Our approach -- Brain\nDiffusion for Visual Exploration (\"BrainDiVE\") -- builds on recent generative\nmethods by combining large-scale diffusion models with brain-guided image\nsynthesis. Validating our method, we demonstrate the ability to synthesize\npreferred images with appropriate semantic specificity for well-characterized\ncategory-selective ROIs. We then show that BrainDiVE can characterize\ndifferences between ROIs selective for the same high-level category. Finally we\nidentify novel functional subdivisions within these ROIs, validated with\nbehavioral data. These results advance our understanding of the fine-grained\nfunctional organization of human visual cortex, and provide well-specified\nconstraints for further examination of cortical organization using\nhypothesis-driven methods.\n","authors":["Andrew F. Luo","Margaret M. Henderson","Leila Wehbe","Michael J. Tarr"],"pdf_url":"https://arxiv.org/pdf/2306.03089v2.pdf","comment":"NeurIPS 2023 (Oral). Project page:\n  https://www.cs.cmu.edu/~afluo/BrainDiVE/"},{"id":"http://arxiv.org/abs/2311.17055v1","updated":"2023-11-28T18:59:46Z","published":"2023-11-28T18:59:46Z","title":"No Representation Rules Them All in Category Discovery","summary":"  In this paper we tackle the problem of Generalized Category Discovery (GCD).\nSpecifically, given a dataset with labelled and unlabelled images, the task is\nto cluster all images in the unlabelled subset, whether or not they belong to\nthe labelled categories. Our first contribution is to recognize that most\nexisting GCD benchmarks only contain labels for a single clustering of the\ndata, making it difficult to ascertain whether models are using the available\nlabels to solve the GCD task, or simply solving an unsupervised clustering\nproblem. As such, we present a synthetic dataset, named 'Clevr-4', for category\ndiscovery. Clevr-4 contains four equally valid partitions of the data, i.e\nbased on object shape, texture, color or count. To solve the task, models are\nrequired to extrapolate the taxonomy specified by the labelled set, rather than\nsimply latching onto a single natural grouping of the data. We use this dataset\nto demonstrate the limitations of unsupervised clustering in the GCD setting,\nshowing that even very strong unsupervised models fail on Clevr-4. We further\nuse Clevr-4 to examine the weaknesses of existing GCD algorithms, and propose a\nnew method which addresses these shortcomings, leveraging consistent findings\nfrom the representation learning literature to do so. Our simple solution,\nwhich is based on 'mean teachers' and termed $\\mu$GCD, substantially\noutperforms implemented baselines on Clevr-4. Finally, when we transfer these\nfindings to real data on the challenging Semantic Shift Benchmark (SSB), we\nfind that $\\mu$GCD outperforms all prior work, setting a new state-of-the-art.\nFor the project webpage, see https://www.robots.ox.ac.uk/~vgg/data/clevr4/\n","authors":["Sagar Vaze","Andrea Vedaldi","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2311.17055v1.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.17053v1","updated":"2023-11-28T18:58:48Z","published":"2023-11-28T18:58:48Z","title":"DiffuseBot: Breeding Soft Robots With Physics-Augmented Generative\n  Diffusion Models","summary":"  Nature evolves creatures with a high complexity of morphological and\nbehavioral intelligence, meanwhile computational methods lag in approaching\nthat diversity and efficacy. Co-optimization of artificial creatures'\nmorphology and control in silico shows promise for applications in physical\nsoft robotics and virtual character creation; such approaches, however, require\ndeveloping new learning algorithms that can reason about function atop pure\nstructure. In this paper, we present DiffuseBot, a physics-augmented diffusion\nmodel that generates soft robot morphologies capable of excelling in a wide\nspectrum of tasks. DiffuseBot bridges the gap between virtually generated\ncontent and physical utility by (i) augmenting the diffusion process with a\nphysical dynamical simulation which provides a certificate of performance, and\n(ii) introducing a co-design procedure that jointly optimizes physical design\nand control by leveraging information about physical sensitivities from\ndifferentiable simulation. We showcase a range of simulated and fabricated\nrobots along with their capabilities. Check our website at\nhttps://diffusebot.github.io/\n","authors":["Tsun-Hsuan Wang","Juntian Zheng","Pingchuan Ma","Yilun Du","Byungchul Kim","Andrew Spielberg","Joshua Tenenbaum","Chuang Gan","Daniela Rus"],"pdf_url":"https://arxiv.org/pdf/2311.17053v1.pdf","comment":"NeurIPS 2023. Project page: https://diffusebot.github.io/"},{"id":"http://arxiv.org/abs/2311.17050v1","updated":"2023-11-28T18:56:01Z","published":"2023-11-28T18:56:01Z","title":"Surf-D: High-Quality Surface Generation for Arbitrary Topologies using\n  Diffusion Models","summary":"  In this paper, we present Surf-D, a novel method for generating high-quality\n3D shapes as Surfaces with arbitrary topologies using Diffusion models.\nSpecifically, we adopt Unsigned Distance Field (UDF) as the surface\nrepresentation, as it excels in handling arbitrary topologies, enabling the\ngeneration of complex shapes. While the prior methods explored shape generation\nwith different representations, they suffer from limited topologies and\ngeometry details. Moreover, it's non-trivial to directly extend prior diffusion\nmodels to UDF because they lack spatial continuity due to the discrete volume\nstructure. However, UDF requires accurate gradients for mesh extraction and\nlearning. To tackle the issues, we first leverage a point-based auto-encoder to\nlearn a compact latent space, which supports gradient querying for any input\npoint through differentiation to effectively capture intricate geometry at a\nhigh resolution. Since the learning difficulty for various shapes can differ, a\ncurriculum learning strategy is employed to efficiently embed various surfaces,\nenhancing the whole embedding process. With pretrained shape latent space, we\nemploy a latent diffusion model to acquire the distribution of various shapes.\nOur approach demonstrates superior performance in shape generation across\nmultiple modalities and conducts extensive experiments in unconditional\ngeneration, category conditional generation, 3D reconstruction from images, and\ntext-to-shape tasks.\n","authors":["Zhengming Yu","Zhiyang Dou","Xiaoxiao Long","Cheng Lin","Zekun Li","Yuan Liu","Norman Müller","Taku Komura","Marc Habermann","Christian Theobalt","Xin Li","Wenping Wang"],"pdf_url":"https://arxiv.org/pdf/2311.17050v1.pdf","comment":"Project Page: https://yzmblog.github.io/projects/SurfD/"},{"id":"http://arxiv.org/abs/2311.17049v1","updated":"2023-11-28T18:55:42Z","published":"2023-11-28T18:55:42Z","title":"MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced\n  Training","summary":"  Contrastive pretraining of image-text foundation models, such as CLIP,\ndemonstrated excellent zero-shot performance and improved robustness on a wide\nrange of downstream tasks. However, these models utilize large\ntransformer-based encoders with significant memory and latency overhead which\npose challenges for deployment on mobile devices. In this work, we introduce\nMobileCLIP -- a new family of efficient image-text models optimized for runtime\nperformance along with a novel and efficient training approach, namely\nmulti-modal reinforced training. The proposed training approach leverages\nknowledge transfer from an image captioning model and an ensemble of strong\nCLIP encoders to improve the accuracy of efficient models. Our approach avoids\ntrain-time compute overhead by storing the additional knowledge in a reinforced\ndataset. MobileCLIP sets a new state-of-the-art latency-accuracy tradeoff for\nzero-shot classification and retrieval tasks on several datasets. Our\nMobileCLIP-S2 variant is 2.3$\\times$ faster while more accurate compared to\nprevious best CLIP model based on ViT-B/16. We further demonstrate the\neffectiveness of our multi-modal reinforced training by training a CLIP model\nbased on ViT-B/16 image backbone and achieving +2.9% average performance\nimprovement on 38 evaluation benchmarks compared to the previous best.\nMoreover, we show that the proposed approach achieves 10$\\times$-1000$\\times$\nimproved learning efficiency when compared with non-reinforced CLIP training.\n","authors":["Pavan Kumar Anasosalu Vasu","Hadi Pouransari","Fartash Faghri","Raviteja Vemulapalli","Oncel Tuzel"],"pdf_url":"https://arxiv.org/pdf/2311.17049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17048v1","updated":"2023-11-28T18:55:37Z","published":"2023-11-28T18:55:37Z","title":"Zero-shot Referring Expression Comprehension via Structural Similarity\n  Between Images and Captions","summary":"  Zero-shot referring expression comprehension aims at localizing bounding\nboxes in an image corresponding to the provided textual prompts, which\nrequires: (i) a fine-grained disentanglement of complex visual scene and\ntextual context, and (ii) a capacity to understand relationships among\ndisentangled entities. Unfortunately, existing large vision-language alignment\n(VLA) models, e.g., CLIP, struggle with both aspects so cannot be directly used\nfor this task. To mitigate this gap, we leverage large foundation models to\ndisentangle both images and texts into triplets in the format of (subject,\npredicate, object). After that, grounding is accomplished by calculating the\nstructural similarity matrix between visual and textual triplets with a VLA\nmodel, and subsequently propagate it to an instance-level similarity matrix.\nFurthermore, to equip VLA models with the ability of relationship\nunderstanding, we design a triplet-matching objective to fine-tune the VLA\nmodels on a collection of curated dataset containing abundant entity\nrelationships. Experiments demonstrate that our visual grounding performance\nincrease of up to 19.5% over the SOTA zero-shot model on RefCOCO/+/g. On the\nmore challenging Who's Waldo dataset, our zero-shot approach achieves\ncomparable accuracy to the fully supervised model.\n","authors":["Zeyu Han","Fangrui Zhu","Qianru Lao","Huaizu Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.17048v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17043v1","updated":"2023-11-28T18:53:43Z","published":"2023-11-28T18:53:43Z","title":"LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models","summary":"  In this work, we present a novel method to tackle the token generation\nchallenge in Vision Language Models (VLMs) for video and image understanding,\ncalled LLaMA-VID. Current VLMs, while proficient in tasks like image captioning\nand visual question answering, face computational burdens when processing long\nvideos due to the excessive visual tokens. LLaMA-VID addresses this issue by\nrepresenting each frame with two distinct tokens, namely context token and\ncontent token. The context token encodes the overall image context based on\nuser input, whereas the content token encapsulates visual cues in each frame.\nThis dual-token strategy significantly reduces the overload of long videos\nwhile preserving critical information. Generally, LLaMA-VID empowers existing\nframeworks to support hour-long videos and pushes their upper limit with an\nextra context token. It is proved to surpass previous methods on most of video-\nor image-based benchmarks. Code is available\nhttps://github.com/dvlab-research/LLaMA-VID}{https://github.com/dvlab-research/LLaMA-VID\n","authors":["Yanwei Li","Chengyao Wang","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2311.17043v1.pdf","comment":"Code is available at https://github.com/dvlab-research/LLaMA-VID"},{"id":"http://arxiv.org/abs/2311.17042v1","updated":"2023-11-28T18:53:24Z","published":"2023-11-28T18:53:24Z","title":"Adversarial Diffusion Distillation","summary":"  We introduce Adversarial Diffusion Distillation (ADD), a novel training\napproach that efficiently samples large-scale foundational image diffusion\nmodels in just 1-4 steps while maintaining high image quality. We use score\ndistillation to leverage large-scale off-the-shelf image diffusion models as a\nteacher signal in combination with an adversarial loss to ensure high image\nfidelity even in the low-step regime of one or two sampling steps. Our analyses\nshow that our model clearly outperforms existing few-step methods (GANs, Latent\nConsistency Models) in a single step and reaches the performance of\nstate-of-the-art diffusion models (SDXL) in only four steps. ADD is the first\nmethod to unlock single-step, real-time image synthesis with foundation models.\nCode and weights available under\nhttps://github.com/Stability-AI/generative-models and\nhttps://huggingface.co/stabilityai/ .\n","authors":["Axel Sauer","Dominik Lorenz","Andreas Blattmann","Robin Rombach"],"pdf_url":"https://arxiv.org/pdf/2311.17042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17041v1","updated":"2023-11-28T18:53:06Z","published":"2023-11-28T18:53:06Z","title":"Efficient In-Context Learning in Vision-Language Models for Egocentric\n  Videos","summary":"  Recent advancements in text-only large language models (LLMs) have\nhighlighted the benefit of in-context learning for adapting to new tasks with a\nfew demonstrations. However, extending in-context learning to large\nvision-language models (VLMs) using a huge amount of naturalistic\nvision-language data has shown limited success, particularly for egocentric\nvideos, due to high data collection costs. We propose a novel training method\n$\\mathbb{E}$fficient $\\mathbb{I}$n-context $\\mathbb{L}$earning on\n$\\mathbb{E}$gocentric $\\mathbb{V}$ideos ($\\mathbb{EILEV}$), which elicits\nin-context learning in VLMs for egocentric videos without requiring massive,\nnaturalistic egocentric video datasets. $\\mathbb{EILEV}$ involves architectural\nand training data adaptations to allow the model to process contexts\ninterleaved with video clips and narrations, sampling of in-context examples\nwith clusters of similar verbs and nouns, use of data with skewed marginal\ndistributions with a long tail of infrequent verbs and nouns, as well as\nhomonyms and synonyms. Our evaluations show that $\\mathbb{EILEV}$-trained\nmodels outperform larger VLMs trained on a huge amount of naturalistic data in\nin-context learning. Furthermore, they can generalize to not only\nout-of-distribution, but also novel, rare egocentric videos and texts via\nin-context learning, demonstrating potential for applications requiring\ncost-effective training, and rapid post-deployment adaptability. Our code and\ndemo are available at \\url{https://github.com/yukw777/EILEV}.\n","authors":["Keunwoo Peter Yu","Zheyuan Zhang","Fengyuan Hu","Joyce Chai"],"pdf_url":"https://arxiv.org/pdf/2311.17041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17034v1","updated":"2023-11-28T18:45:13Z","published":"2023-11-28T18:45:13Z","title":"Telling Left from Right: Identifying Geometry-Aware Semantic\n  Correspondence","summary":"  While pre-trained large-scale vision models have shown significant promise\nfor semantic correspondence, their features often struggle to grasp the\ngeometry and orientation of instances. This paper identifies the importance of\nbeing geometry-aware for semantic correspondence and reveals a limitation of\nthe features of current foundation models under simple post-processing. We show\nthat incorporating this information can markedly enhance semantic\ncorrespondence performance with simple but effective solutions in both\nzero-shot and supervised settings. We also construct a new challenging\nbenchmark for semantic correspondence built from an existing animal pose\nestimation dataset, for both pre-training validating models. Our method\nachieves a PCK@0.10 score of 64.2 (zero-shot) and 85.6 (supervised) on the\nchallenging SPair-71k dataset, outperforming the state-of-the-art by 4.3p and\n11.0p absolute gains, respectively. Our code and datasets will be publicly\navailable.\n","authors":["Junyi Zhang","Charles Herrmann","Junhwa Hur","Eric Chen","Varun Jampani","Deqing Sun","Ming-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2311.17034v1.pdf","comment":"Project page: https://telling-left-from-right.github.io/"},{"id":"http://arxiv.org/abs/2311.17026v1","updated":"2023-11-28T18:28:03Z","published":"2023-11-28T18:28:03Z","title":"When the Few Outweigh the Many: Illicit Content Recognition with\n  Few-Shot Learning","summary":"  The anonymity and untraceability benefits of the Dark web account for the\nexponentially-increased potential of its popularity while creating a suitable\nwomb for many illicit activities, to date. Hence, in collaboration with\ncybersecurity and law enforcement agencies, research has provided approaches\nfor recognizing and classifying illicit activities with most exploiting textual\ndark web markets' content recognition; few such approaches use images that\noriginated from dark web content. This paper investigates this alternative\ntechnique for recognizing illegal activities from images. In particular, we\ninvestigate label-agnostic learning techniques like One-Shot and Few-Shot\nlearning featuring the use Siamese neural networks, a state-of-the-art approach\nin the field. Our solution manages to handle small-scale datasets with\npromising accuracy. In particular, Siamese neural networks reach 90.9% on\n20-Shot experiments over a 10-class dataset; this leads us to conclude that\nsuch models are a promising and cheaper alternative to the definition of\nautomated law-enforcing machinery over the dark web.\n","authors":["G. Cascavilla","G. Catolino","M. Conti","D. Mellios","D. A. Tamburri"],"pdf_url":"https://arxiv.org/pdf/2311.17026v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17024v1","updated":"2023-11-28T18:27:15Z","published":"2023-11-28T18:27:15Z","title":"Diffusion 3D Features (Diff3F): Decorating Untextured Shapes with\n  Distilled Semantic Features","summary":"  We present Diff3F as a simple, robust, and class-agnostic feature descriptor\nthat can be computed for untextured input shapes (meshes or point clouds). Our\nmethod distills diffusion features from image foundational models onto input\nshapes. Specifically, we use the input shapes to produce depth and normal maps\nas guidance for conditional image synthesis, and in the process produce\n(diffusion) features in 2D that we subsequently lift and aggregate on the\noriginal surface. Our key observation is that even if the conditional image\ngenerations obtained from multi-view rendering of the input shapes are\ninconsistent, the associated image features are robust and can be directly\naggregated across views. This produces semantic features on the input shapes,\nwithout requiring additional data or training. We perform extensive experiments\non multiple benchmarks (SHREC'19, SHREC'20, and TOSCA) and demonstrate that our\nfeatures, being semantic instead of geometric, produce reliable correspondence\nacross both isometeric and non-isometrically related shape families.\n","authors":["Niladri Shekhar Dutt","Sanjeev Muralikrishnan","Niloy J. Mitra"],"pdf_url":"https://arxiv.org/pdf/2311.17024v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17009v1","updated":"2023-11-28T18:03:27Z","published":"2023-11-28T18:03:27Z","title":"Space-Time Diffusion Features for Zero-Shot Text-Driven Motion Transfer","summary":"  We present a new method for text-driven motion transfer - synthesizing a\nvideo that complies with an input text prompt describing the target objects and\nscene while maintaining an input video's motion and scene layout. Prior methods\nare confined to transferring motion across two subjects within the same or\nclosely related object categories and are applicable for limited domains (e.g.,\nhumans). In this work, we consider a significantly more challenging setting in\nwhich the target and source objects differ drastically in shape and\nfine-grained motion characteristics (e.g., translating a jumping dog into a\ndolphin). To this end, we leverage a pre-trained and fixed text-to-video\ndiffusion model, which provides us with generative and motion priors. The\npillar of our method is a new space-time feature loss derived directly from the\nmodel. This loss guides the generation process to preserve the overall motion\nof the input video while complying with the target object in terms of shape and\nfine-grained motion traits.\n","authors":["Danah Yatim","Rafail Fridman","Omer Bar Tal","Yoni Kasten","Tali Dekel"],"pdf_url":"https://arxiv.org/pdf/2311.17009v1.pdf","comment":"Project page: https://diffusion-motion-transfer.github.io/"},{"id":"http://arxiv.org/abs/2311.17005v1","updated":"2023-11-28T17:59:04Z","published":"2023-11-28T17:59:04Z","title":"MVBench: A Comprehensive Multi-modal Video Understanding Benchmark","summary":"  With the rapid development of Multi-modal Large Language Models (MLLMs), a\nnumber of diagnostic benchmarks have recently emerged to evaluate the\ncomprehension capabilities of these models. However, most benchmarks\npredominantly assess spatial understanding in the static image tasks, while\noverlooking temporal understanding in the dynamic video tasks. To alleviate\nthis issue, we introduce a comprehensive Multi-modal Video understanding\nBenchmark, namely MVBench, which covers 20 challenging video tasks that cannot\nbe effectively solved with a single frame. Specifically, we first introduce a\nnovel static-to-dynamic method to define these temporal-related tasks. By\ntransforming various static tasks into dynamic ones, we enable the systematic\ngeneration of video tasks that require a broad spectrum of temporal skills,\nranging from perception to cognition. Then, guided by the task definition, we\nautomatically convert public video annotations into multiple-choice QA to\nevaluate each task. On one hand, such a distinct paradigm allows us to build\nMVBench efficiently, without much manual intervention. On the other hand, it\nguarantees evaluation fairness with ground-truth video annotations, avoiding\nthe biased scoring of LLMs. Moreover, we further develop a robust video MLLM\nbaseline, i.e., VideoChat2, by progressive multi-modal training with diverse\ninstruction-tuning data. The extensive results on our MVBench reveal that, the\nexisting MLLMs are far from satisfactory in temporal understanding, while our\nVideoChat2 largely surpasses these leading models by over 15% on MVBench. All\nmodels and data are available at https://github.com/OpenGVLab/Ask-Anything.\n","authors":["Kunchang Li","Yali Wang","Yinan He","Yizhuo Li","Yi Wang","Yi Liu","Zun Wang","Jilan Xu","Guo Chen","Ping Luo","Limin Wang","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2311.17005v1.pdf","comment":"18 pages, 7 figures, 19 tables"},{"id":"http://arxiv.org/abs/2311.17002v1","updated":"2023-11-28T17:57:44Z","published":"2023-11-28T17:57:44Z","title":"Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following","summary":"  Existing text-to-image (T2I) diffusion models usually struggle in\ninterpreting complex prompts, especially those with quantity, object-attribute\nbinding, and multi-subject descriptions. In this work, we introduce a semantic\npanel as the middleware in decoding texts to images, supporting the generator\nto better follow instructions. The panel is obtained through arranging the\nvisual concepts parsed from the input text by the aid of large language models,\nand then injected into the denoising network as a detailed control signal to\ncomplement the text condition. To facilitate text-to-panel learning, we come up\nwith a carefully designed semantic formatting protocol, accompanied by a\nfully-automatic data preparation pipeline. Thanks to such a design, our\napproach, which we call Ranni, manages to enhance a pre-trained T2I generator\nregarding its textual controllability. More importantly, the introduction of\nthe generative middleware brings a more convenient form of interaction (i.e.,\ndirectly adjusting the elements in the panel or using language instructions)\nand further allows users to finely customize their generation, based on which\nwe develop a practical system and showcase its potential in continuous\ngeneration and chatting-based editing.\n","authors":["Yutong Feng","Biao Gong","Di Chen","Yujun Shen","Yu Liu","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.17002v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.15347v2","updated":"2023-11-28T17:47:46Z","published":"2023-05-24T16:59:26Z","title":"A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot\n  Semantic Correspondence","summary":"  Text-to-image diffusion models have made significant advances in generating\nand editing high-quality images. As a result, numerous approaches have explored\nthe ability of diffusion model features to understand and process single images\nfor downstream tasks, e.g., classification, semantic segmentation, and\nstylization. However, significantly less is known about what these features\nreveal across multiple, different images and objects. In this work, we exploit\nStable Diffusion (SD) features for semantic and dense correspondence and\ndiscover that with simple post-processing, SD features can perform\nquantitatively similar to SOTA representations. Interestingly, the qualitative\nanalysis reveals that SD features have very different properties compared to\nexisting representation learning features, such as the recently released\nDINOv2: while DINOv2 provides sparse but accurate matches, SD features provide\nhigh-quality spatial information but sometimes inaccurate semantic matches. We\ndemonstrate that a simple fusion of these two features works surprisingly well,\nand a zero-shot evaluation using nearest neighbors on these fused features\nprovides a significant performance gain over state-of-the-art methods on\nbenchmark datasets, e.g., SPair-71k, PF-Pascal, and TSS. We also show that\nthese correspondences can enable interesting applications such as instance\nswapping in two images.\n","authors":["Junyi Zhang","Charles Herrmann","Junhwa Hur","Luisa Polania Cabrera","Varun Jampani","Deqing Sun","Ming-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2305.15347v2.pdf","comment":"Accepted by NeurIPS 23, project page:\n  https://sd-complements-dino.github.io/"},{"id":"http://arxiv.org/abs/2308.16847v2","updated":"2023-11-28T17:24:29Z","published":"2023-08-31T16:26:17Z","title":"Diffusion Models for Interferometric Satellite Aperture Radar","summary":"  Probabilistic Diffusion Models (PDMs) have recently emerged as a very\npromising class of generative models, achieving high performance in natural\nimage generation. However, their performance relative to non-natural images,\nlike radar-based satellite data, remains largely unknown. Generating large\namounts of synthetic (and especially labelled) satellite data is crucial to\nimplement deep-learning approaches for the processing and analysis of\n(interferometric) satellite aperture radar data. Here, we leverage PDMs to\ngenerate several radar-based satellite image datasets. We show that PDMs\nsucceed in generating images with complex and realistic structures, but that\nsampling time remains an issue. Indeed, accelerated sampling strategies, which\nwork well on simple image datasets like MNIST, fail on our radar datasets. We\nprovide a simple and versatile open-source\nhttps://github.com/thomaskerdreux/PDM_SAR_InSAR_generation to train, sample and\nevaluate PDMs using any dataset on a single GPU.\n","authors":["Alexandre Tuel","Thomas Kerdreux","Claudia Hulbert","Bertrand Rouet-Leduc"],"pdf_url":"https://arxiv.org/pdf/2308.16847v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16974v1","updated":"2023-11-28T17:22:17Z","published":"2023-11-28T17:22:17Z","title":"COLE: A Hierarchical Generation Framework for Graphic Design","summary":"  Graphic design, which has been evolving since the 15th century, plays a\ncrucial role in advertising. The creation of high-quality designs demands\ncreativity, innovation, and lateral thinking. This intricate task involves\nunderstanding the objective, crafting visual elements such as the background,\ndecoration, font, color, and shape, formulating diverse professional layouts,\nand adhering to fundamental visual design principles. In this paper, we\nintroduce COLE, a hierarchical generation framework designed to comprehensively\naddress these challenges. This COLE system can transform a straightforward\nintention prompt into a high-quality graphic design, while also supporting\nflexible editing based on user input. Examples of such input might include\ndirectives like ``design a poster for Hisaishi's concert.'' The key insight is\nto dissect the complex task of text-to-design generation into a hierarchy of\nsimpler sub-tasks, each addressed by specialized models working\ncollaboratively. The results from these models are then consolidated to produce\na cohesive final output. Our hierarchical task decomposition can streamline the\ncomplex process and significantly enhance generation reliability. Our COLE\nsystem consists of multiple fine-tuned Large Language Models (LLMs), Large\nMultimodal Models (LMMs), and Diffusion Models (DMs), each specifically\ntailored for a design-aware text or image generation task. Furthermore, we\nconstruct the DESIGNERINTENTION benchmark to highlight the superiority of our\nCOLE over existing methods in generating high-quality graphic designs from user\nintent. We perceive our COLE as an important step towards addressing more\ncomplex visual design generation tasks in the future.\n","authors":["Peidong Jia","Chenxuan Li","Zeyu Liu","Yichao Shen","Xingru Chen","Yuhui Yuan","Yinglin Zheng","Dong Chen","Ji Li","Xiaodong Xie","Shanghang Zhang","Baining Guo"],"pdf_url":"https://arxiv.org/pdf/2311.16974v1.pdf","comment":"Technical report. Project page:\n  https://graphic-design-generation.github.io/"},{"id":"http://arxiv.org/abs/2309.10399v2","updated":"2023-11-28T17:19:34Z","published":"2023-09-19T08:00:26Z","title":"Exploiting Causality Signals in Medical Images: A Pilot Study with\n  Empirical Results","summary":"  We present a novel technique to discover and exploit weak causal signals\ndirectly from images via neural networks for classification purposes. This way,\nwe model how the presence of a feature in one part of the image affects the\nappearance of another feature in a different part of the image. Our method\nconsists of a convolutional neural network backbone and a causality-factors\nextractor module, which computes weights to enhance each feature map according\nto its causal influence in the scene. We developed different architecture\nvariants and empirically evaluated all of our models on two public datasets of\nprostate MRI images and breast histopathology slides for cancer diagnosis. To\nconfirm our quantitative results, we conduct ablation studies and investigate\nthe explainability of our models via class activation maps. Our findings show\nthat our lightweight block extracts meaningful information and improves the\noverall classification, together with producing more robust predictions that\nfocus on relevant parts of the image. That is crucial in medical imaging, where\naccurate and reliable classifications are essential for effective diagnosis and\ntreatment planning.\n","authors":["Gianluca Carloni","Sara Colantonio"],"pdf_url":"https://arxiv.org/pdf/2309.10399v2.pdf","comment":"Repeated analyses with new dataset, provided more visual/algorithmic\n  insights, improved clarity, remarked significance and novelty; 17 pages, 8\n  figures, second round review"},{"id":"http://arxiv.org/abs/2311.08269v2","updated":"2023-11-28T17:18:44Z","published":"2023-11-14T16:02:18Z","title":"Defining the boundaries: challenges and advances in identifying cells in\n  microscopy images","summary":"  Segmentation, or the outlining of objects within images, is a critical step\nin the measurement and analysis of cells within microscopy images. While\nimprovements continue to be made in tools that rely on classical methods for\nsegmentation, deep learning-based tools increasingly dominate advances in the\ntechnology. Specialist models such as Cellpose continue to improve in accuracy\nand user-friendliness, and segmentation challenges such as the Multi-Modality\nCell Segmentation Challenge continue to push innovation in accuracy across\nwidely-varying test data as well as efficiency and usability. Increased\nattention on documentation, sharing, and evaluation standards are leading to\nincreased user-friendliness and acceleration towards the goal of a truly\nuniversal method.\n","authors":["Nodar Gogoberidze","Beth A. Cimini"],"pdf_url":"https://arxiv.org/pdf/2311.08269v2.pdf","comment":"12 pages, 1 figure, submitted to \"Current Opinion in Biotechnology\""},{"id":"http://arxiv.org/abs/2311.16961v1","updated":"2023-11-28T17:06:28Z","published":"2023-11-28T17:06:28Z","title":"HumanRef: Single Image to 3D Human Generation via Reference-Guided\n  Diffusion","summary":"  Generating a 3D human model from a single reference image is challenging\nbecause it requires inferring textures and geometries in invisible views while\nmaintaining consistency with the reference image. Previous methods utilizing 3D\ngenerative models are limited by the availability of 3D training data.\nOptimization-based methods that lift text-to-image diffusion models to 3D\ngeneration often fail to preserve the texture details of the reference image,\nresulting in inconsistent appearances in different views. In this paper, we\npropose HumanRef, a 3D human generation framework from a single-view input. To\nensure the generated 3D model is photorealistic and consistent with the input\nimage, HumanRef introduces a novel method called reference-guided score\ndistillation sampling (Ref-SDS), which effectively incorporates image guidance\ninto the generation process. Furthermore, we introduce region-aware attention\nto Ref-SDS, ensuring accurate correspondence between different body regions.\nExperimental results demonstrate that HumanRef outperforms state-of-the-art\nmethods in generating 3D clothed humans with fine geometry, photorealistic\ntextures, and view-consistent appearances.\n","authors":["Jingbo Zhang","Xiaoyu Li","Qi Zhang","Yanpei Cao","Ying Shan","Jing Liao"],"pdf_url":"https://arxiv.org/pdf/2311.16961v1.pdf","comment":"Homepage: https://eckertzhang.github.io/HumanRef.github.io/"},{"id":"http://arxiv.org/abs/2208.13465v2","updated":"2023-11-28T16:49:39Z","published":"2022-08-29T10:05:49Z","title":"Exploring Semantic Attributes from A Foundation Model for Federated\n  Learning of Disjoint Label Spaces","summary":"  Conventional centralised deep learning paradigms are not feasible when data\nfrom different sources cannot be shared due to data privacy or transmission\nlimitation. To resolve this problem, federated learning has been introduced to\ntransfer knowledge across multiple sources (clients) with non-shared data while\noptimising a globally generalised central model (server). Existing federated\nlearning paradigms mostly focus on transferring holistic high-level knowledge\n(such as class) across models, which are closely related to specific objects of\ninterest so may suffer from inverse attack. In contrast, in this work, we\nconsider transferring mid-level semantic knowledge (such as attribute) which is\nnot sensitive to specific objects of interest and therefore is more\nprivacy-preserving and scalable. To this end, we formulate a new Federated\nZero-Shot Learning (FZSL) paradigm to learn mid-level semantic knowledge at\nmultiple local clients with non-shared local data and cumulatively aggregate a\nglobally generalised central model for deployment. To improve model\ndiscriminative ability, we propose to explore semantic knowledge augmentation\nfrom external knowledge for enriching the mid-level semantic space in FZSL.\nExtensive experiments on five zeroshot learning benchmark datasets validate the\neffectiveness of our approach for optimising a generalisable federated learning\nmodel with mid-level semantic knowledge transfer.\n","authors":["Shitong Sun","Chenyang Si","Guile Wu","Shaogang Gong"],"pdf_url":"https://arxiv.org/pdf/2208.13465v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2311.16945v1","updated":"2023-11-28T16:47:59Z","published":"2023-11-28T16:47:59Z","title":"UC-NeRF: Neural Radiance Field for Under-Calibrated multi-view cameras\n  in autonomous driving","summary":"  Multi-camera setups find widespread use across various applications, such as\nautonomous driving, as they greatly expand sensing capabilities. Despite the\nfast development of Neural radiance field (NeRF) techniques and their wide\napplications in both indoor and outdoor scenes, applying NeRF to multi-camera\nsystems remains very challenging. This is primarily due to the inherent\nunder-calibration issues in multi-camera setup, including inconsistent imaging\neffects stemming from separately calibrated image signal processing units in\ndiverse cameras, and system errors arising from mechanical vibrations during\ndriving that affect relative camera poses. In this paper, we present UC-NeRF, a\nnovel method tailored for novel view synthesis in under-calibrated multi-view\ncamera systems. Firstly, we propose a layer-based color correction to rectify\nthe color inconsistency in different image regions. Second, we propose virtual\nwarping to generate more viewpoint-diverse but color-consistent virtual views\nfor color correction and 3D recovery. Finally, a spatiotemporally constrained\npose refinement is designed for more robust and accurate pose calibration in\nmulti-camera systems. Our method not only achieves state-of-the-art performance\nof novel view synthesis in multi-camera setups, but also effectively\nfacilitates depth estimation in large-scale outdoor scenes with the synthesized\nnovel views.\n","authors":["Kai Cheng","Xiaoxiao Long","Wei Yin","Jin Wang","Zhiqiang Wu","Yuexin Ma","Kaixuan Wang","Xiaozhi Chen","Xuejin Chen"],"pdf_url":"https://arxiv.org/pdf/2311.16945v1.pdf","comment":"See the project page for code, data:\n  https://kcheng1021.github.io/ucnerf.github.io"},{"id":"http://arxiv.org/abs/2311.16943v1","updated":"2023-11-28T16:46:44Z","published":"2023-11-28T16:46:44Z","title":"Image segmentation with traveling waves in an exactly solvable recurrent\n  neural network","summary":"  We study image segmentation using spatiotemporal dynamics in a recurrent\nneural network where the state of each unit is given by a complex number. We\nshow that this network generates sophisticated spatiotemporal dynamics that can\neffectively divide an image into groups according to a scene's structural\ncharacteristics. Using an exact solution of the recurrent network's dynamics,\nwe present a precise description of the mechanism underlying object\nsegmentation in this network, providing a clear mathematical interpretation of\nhow the network performs this task. We then demonstrate a simple algorithm for\nobject segmentation that generalizes across inputs ranging from simple\ngeometric objects in grayscale images to natural images. Object segmentation\nacross all images is accomplished with one recurrent neural network that has a\nsingle, fixed set of weights. This demonstrates the expressive potential of\nrecurrent neural networks when constructed using a mathematical approach that\nbrings together their structure, dynamics, and computation.\n","authors":["Luisa H. B. Liboni","Roberto C. Budzinski","Alexandra N. Busch","Sindy Löwe","Thomas A. Keller","Max Welling","Lyle E. Muller"],"pdf_url":"https://arxiv.org/pdf/2311.16943v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16941v1","updated":"2023-11-28T16:46:14Z","published":"2023-11-28T16:46:14Z","title":"Debiasing Multimodal Models via Causal Information Minimization","summary":"  Most existing debiasing methods for multimodal models, including causal\nintervention and inference methods, utilize approximate heuristics to represent\nthe biases, such as shallow features from early stages of training or unimodal\nfeatures for multimodal tasks like VQA, etc., which may not be accurate. In\nthis paper, we study bias arising from confounders in a causal graph for\nmultimodal data and examine a novel approach that leverages causally-motivated\ninformation minimization to learn the confounder representations. Robust\npredictive features contain diverse information that helps a model generalize\nto out-of-distribution data. Hence, minimizing the information content of\nfeatures obtained from a pretrained biased model helps learn the simplest\npredictive features that capture the underlying data distribution. We treat\nthese features as confounder representations and use them via methods motivated\nby causal theory to remove bias from models. We find that the learned\nconfounder representations indeed capture dataset biases, and the proposed\ndebiasing methods improve out-of-distribution (OOD) performance on multiple\nmultimodal datasets without sacrificing in-distribution performance.\nAdditionally, we introduce a novel metric to quantify the sufficiency of\nspurious features in models' predictions that further demonstrates the\neffectiveness of our proposed methods. Our code is available at:\nhttps://github.com/Vaidehi99/CausalInfoMin\n","authors":["Vaidehi Patil","Adyasha Maharana","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2311.16941v1.pdf","comment":"EMNLP 2023 Findings (16 pages)"},{"id":"http://arxiv.org/abs/2208.02705v2","updated":"2023-11-28T16:45:07Z","published":"2022-08-04T15:06:29Z","title":"360Roam: Real-Time Indoor Roaming Using Geometry-Aware 360$^\\circ$\n  Radiance Fields","summary":"  Virtual tour among sparse 360$^\\circ$ images is widely used while hindering\nsmooth and immersive roaming experiences. The emergence of Neural Radiance\nField (NeRF) has showcased significant progress in synthesizing novel views,\nunlocking the potential for immersive scene exploration. Nevertheless, previous\nNeRF works primarily focused on object-centric scenarios, resulting in\nnoticeable performance degradation when applied to outward-facing and\nlarge-scale scenes due to limitations in scene parameterization. To achieve\nseamless and real-time indoor roaming, we propose a novel approach using\ngeometry-aware radiance fields with adaptively assigned local radiance fields.\nInitially, we employ multiple 360$^\\circ$ images of an indoor scene to\nprogressively reconstruct explicit geometry in the form of a probabilistic\noccupancy map, derived from a global omnidirectional radiance field.\nSubsequently, we assign local radiance fields through an adaptive\ndivide-and-conquer strategy based on the recovered geometry. By incorporating\ngeometry-aware sampling and decomposition of the global radiance field, our\nsystem effectively utilizes positional encoding and compact neural networks to\nenhance rendering quality and speed. Additionally, the extracted floorplan of\nthe scene aids in providing visual guidance, contributing to a realistic\nroaming experience. To demonstrate the effectiveness of our system, we curated\na diverse dataset of 360$^\\circ$ images encompassing various real-life scenes,\non which we conducted extensive experiments. Quantitative and qualitative\ncomparisons against baseline approaches illustrated the superior performance of\nour system in large-scale indoor scene roaming.\n","authors":["Huajian Huang","Yingshu Chen","Tianjia Zhang","Sai-Kit Yeung"],"pdf_url":"https://arxiv.org/pdf/2208.02705v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.13411v2","updated":"2023-11-28T16:41:35Z","published":"2023-09-23T15:48:35Z","title":"Towards Attributions of Input Variables in a Coalition","summary":"  This paper aims to develop a new attribution method to explain the conflict\nbetween individual variables' attributions and their coalition's attribution\nfrom a fully new perspective. First, we find that the Shapley value can be\nreformulated as the allocation of Harsanyi interactions encoded by the AI\nmodel. Second, based the re-alloction of interactions, we extend the Shapley\nvalue to the attribution of coalitions. Third we ective. We derive the\nfundamental mechanism behind the conflict. This conflict come from the\ninteraction containing partial variables in their coalition.\n","authors":["Xinhao Zheng","Huiqi Deng","Bo Fan","Quanshi Zhang"],"pdf_url":"https://arxiv.org/pdf/2309.13411v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16937v1","updated":"2023-11-28T16:39:49Z","published":"2023-11-28T16:39:49Z","title":"The Sky's the Limit: Re-lightable Outdoor Scenes via a Sky-pixel\n  Constrained Illumination Prior and Outside-In Visibility","summary":"  Inverse rendering of outdoor scenes from unconstrained image collections is a\nchallenging task, particularly illumination/albedo ambiguities and occlusion of\nthe illumination environment (shadowing) caused by geometry. However, there are\nmany cues in an image that can aid in the disentanglement of geometry, albedo\nand shadows. We exploit the fact that any sky pixel provides a direct\nmeasurement of distant lighting in the corresponding direction and, via a\nneural illumination prior, a statistical cue as to the remaining illumination\nenvironment. We also introduce a novel `outside-in' method for computing\ndifferentiable sky visibility based on a neural directional distance function.\nThis is efficient and can be trained in parallel with the neural scene\nrepresentation, allowing gradients from appearance loss to flow from shadows to\ninfluence estimation of illumination and geometry. Our method estimates\nhigh-quality albedo, geometry, illumination and sky visibility, achieving\nstate-of-the-art results on the NeRF-OSR relighting benchmark. Our code and\nmodels can be found https://github.com/JADGardner/neusky\n","authors":["James A. D. Gardner","Evgenii Kashin","Bernhard Egger","William A. P. Smith"],"pdf_url":"https://arxiv.org/pdf/2311.16937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16933v1","updated":"2023-11-28T16:33:08Z","published":"2023-11-28T16:33:08Z","title":"SparseCtrl: Adding Sparse Controls to Text-to-Video Diffusion Models","summary":"  The development of text-to-video (T2V), i.e., generating videos with a given\ntext prompt, has been significantly advanced in recent years. However, relying\nsolely on text prompts often results in ambiguous frame composition due to\nspatial uncertainty. The research community thus leverages the dense structure\nsignals, e.g., per-frame depth/edge sequences, to enhance controllability,\nwhose collection accordingly increases the burden of inference. In this work,\nwe present SparseCtrl to enable flexible structure control with temporally\nsparse signals, requiring only one or a few inputs, as shown in Figure 1. It\nincorporates an additional condition encoder to process these sparse signals\nwhile leaving the pre-trained T2V model untouched. The proposed approach is\ncompatible with various modalities, including sketches, depth maps, and RGB\nimages, providing more practical control for video generation and promoting\napplications such as storyboarding, depth rendering, keyframe animation, and\ninterpolation. Extensive experiments demonstrate the generalization of\nSparseCtrl on both original and personalized T2V generators. Codes and models\nwill be publicly available at https://guoyww.github.io/projects/SparseCtrl .\n","authors":["Yuwei Guo","Ceyuan Yang","Anyi Rao","Maneesh Agrawala","Dahua Lin","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2311.16933v1.pdf","comment":"Project page: https://guoyww.github.io/projects/SparseCtrl"},{"id":"http://arxiv.org/abs/2310.03059v3","updated":"2023-11-28T16:31:34Z","published":"2023-10-04T16:49:36Z","title":"Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models","summary":"  The popularity of pre-trained large models has revolutionized downstream\ntasks across diverse fields, such as language, vision, and multi-modality. To\nminimize the adaption cost for downstream tasks, many Parameter-Efficient\nFine-Tuning (PEFT) techniques are proposed for language and 2D image\npre-trained models. However, the specialized PEFT method for 3D pre-trained\nmodels is still under-explored. To this end, we introduce Point-PEFT, a novel\nframework for adapting point cloud pre-trained models with minimal learnable\nparameters. Specifically, for a pre-trained 3D model, we freeze most of its\nparameters, and only tune the newly added PEFT modules on downstream tasks,\nwhich consist of a Point-prior Prompt and a Geometry-aware Adapter. The\nPoint-prior Prompt adopts a set of learnable prompt tokens, for which we\npropose to construct a memory bank with domain-specific knowledge, and utilize\na parameter-free attention to enhance the prompt tokens. The Geometry-aware\nAdapter aims to aggregate point cloud features within spatial neighborhoods to\ncapture fine-grained geometric information through local interactions.\nExtensive experiments indicate that our Point-PEFT can achieve better\nperformance than the full fine-tuning on various downstream tasks, while using\nonly 5% of the trainable parameters, demonstrating the efficiency and\neffectiveness of our approach. Code will be released at\nhttps://github.com/Even-JK/PEFT-3D.\n","authors":["Ivan Tang","Ray Zhang","Zoey Guo","Dong Wang","Zhigang Wang","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2310.03059v3.pdf","comment":"10 pages. The specialized PEFT framework for 3D pre-trained models,\n  which achieves competitive performance to full fine-tuning, and significantly\n  reduces the computational resources. Project page:\n  https://github.com/Even-JK/PEFT-3D"},{"id":"http://arxiv.org/abs/2311.16926v1","updated":"2023-11-28T16:31:27Z","published":"2023-11-28T16:31:27Z","title":"LLaFS: When Large-Language Models Meet Few-Shot Segmentation","summary":"  This paper proposes LLaFS, the first attempt to leverage large language\nmodels (LLMs) in few-shot segmentation. In contrast to the conventional\nfew-shot segmentation methods that only rely on the limited and biased\ninformation from the annotated support images, LLaFS leverages the vast prior\nknowledge gained by LLM as an effective supplement and directly uses the LLM to\nsegment images in a few-shot manner. To enable the text-based LLM to handle\nimage-related tasks, we carefully design an input instruction that allows the\nLLM to produce segmentation results represented as polygons, and propose a\nregion-attribute table to simulate the human visual mechanism and provide\nmulti-modal guidance. We also synthesize pseudo samples and use curriculum\nlearning for pretraining to augment data and achieve better optimization. LLaFS\nachieves state-of-the-art results on multiple datasets, showing the potential\nof using LLMs for few-shot computer vision tasks. Code will be available at\nhttps://github.com/lanyunzhu99/LLaFS.\n","authors":["Lanyun Zhu","Tianrun Chen","Deyi Ji","Jieping Ye","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2311.16926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16923v1","updated":"2023-11-28T16:27:24Z","published":"2023-11-28T16:27:24Z","title":"Super-Resolution through StyleGAN Regularized Latent Search: A\n  Realism-Fidelity Trade-off","summary":"  This paper addresses the problem of super-resolution: constructing a highly\nresolved (HR) image from a low resolved (LR) one. Recent unsupervised\napproaches search the latent space of a StyleGAN pre-trained on HR images, for\nthe image that best downscales to the input LR image. However, they tend to\nproduce out-of-domain images and fail to accurately reconstruct HR images that\nare far from the original domain. Our contribution is twofold. Firstly, we\nintroduce a new regularizer to constrain the search in the latent space,\nensuring that the inverted code lies in the original image manifold. Secondly,\nwe further enhanced the reconstruction through expanding the image prior around\nthe optimal latent code. Our results show that the proposed approach recovers\nrealistic high-quality images for large magnification factors. Furthermore, for\nlow magnification factors, it can still reconstruct details that the generator\ncould not have produced otherwise. Altogether, our approach achieves a good\ntrade-off between fidelity and realism for the super-resolution task.\n","authors":["Marzieh Gheisari","Auguste Genovesio"],"pdf_url":"https://arxiv.org/pdf/2311.16923v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16922v1","updated":"2023-11-28T16:26:35Z","published":"2023-11-28T16:26:35Z","title":"Mitigating Object Hallucinations in Large Vision-Language Models through\n  Visual Contrastive Decoding","summary":"  Large Vision-Language Models (LVLMs) have advanced considerably, intertwining\nvisual recognition and language understanding to generate content that is not\nonly coherent but also contextually attuned. Despite their success, LVLMs still\nsuffer from the issue of object hallucinations, where models generate plausible\nyet incorrect outputs that include objects that do not exist in the images. To\nmitigate this issue, we introduce Visual Contrastive Decoding (VCD), a simple\nand training-free method that contrasts output distributions derived from\noriginal and distorted visual inputs. The proposed VCD effectively reduces the\nover-reliance on statistical bias and unimodal priors, two essential causes of\nobject hallucinations. This adjustment ensures the generated content is closely\ngrounded to visual inputs, resulting in contextually accurate outputs. Our\nexperiments show that VCD, without either additional training or the usage of\nexternal tools, significantly mitigates the object hallucination issue across\ndifferent LVLM families. Beyond mitigating object hallucinations, VCD also\nexcels in general LVLM benchmarks, highlighting its wide-ranging applicability.\n","authors":["Sicong Leng","Hang Zhang","Guanzheng Chen","Xin Li","Shijian Lu","Chunyan Miao","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2311.16922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16918v1","updated":"2023-11-28T16:22:33Z","published":"2023-11-28T16:22:33Z","title":"RichDreamer: A Generalizable Normal-Depth Diffusion Model for Detail\n  Richness in Text-to-3D","summary":"  Lifting 2D diffusion for 3D generation is a challenging problem due to the\nlack of geometric prior and the complex entanglement of materials and lighting\nin natural images. Existing methods have shown promise by first creating the\ngeometry through score-distillation sampling (SDS) applied to rendered surface\nnormals, followed by appearance modeling. However, relying on a 2D RGB\ndiffusion model to optimize surface normals is suboptimal due to the\ndistribution discrepancy between natural images and normals maps, leading to\ninstability in optimization. In this paper, recognizing that the normal and\ndepth information effectively describe scene geometry and be automatically\nestimated from images, we propose to learn a generalizable Normal-Depth\ndiffusion model for 3D generation. We achieve this by training on the\nlarge-scale LAION dataset together with the generalizable image-to-depth and\nnormal prior models. In an attempt to alleviate the mixed illumination effects\nin the generated materials, we introduce an albedo diffusion model to impose\ndata-driven constraints on the albedo component. Our experiments show that when\nintegrated into existing text-to-3D pipelines, our models significantly enhance\nthe detail richness, achieving state-of-the-art results. Our project page is\nhttps://lingtengqiu.github.io/RichDreamer/.\n","authors":["Lingteng Qiu","Guanying Chen","Xiaodong Gu","Qi Zuo","Mutian Xu","Yushuang Wu","Weihao Yuan","Zilong Dong","Liefeng Bo","Xiaoguang Han"],"pdf_url":"https://arxiv.org/pdf/2311.16918v1.pdf","comment":"Project Page: https://lingtengqiu.github.io/RichDreamer/"},{"id":"http://arxiv.org/abs/2311.16917v1","updated":"2023-11-28T16:20:33Z","published":"2023-11-28T16:20:33Z","title":"UGG: Unified Generative Grasping","summary":"  Dexterous grasping aims to produce diverse grasping postures with a high\ngrasping success rate. Regression-based methods that directly predict grasping\nparameters given the object may achieve a high success rate but often lack\ndiversity. Generation-based methods that generate grasping postures conditioned\non the object can often produce diverse grasping, but they are insufficient for\nhigh grasping success due to lack of discriminative information. To mitigate,\nwe introduce a unified diffusion-based dexterous grasp generation model, dubbed\nthe name UGG, which operates within the object point cloud and hand parameter\nspaces. Our all-transformer architecture unifies the information from the\nobject, the hand, and the contacts, introducing a novel representation of\ncontact points for improved contact modeling. The flexibility and quality of\nour model enable the integration of a lightweight discriminator, benefiting\nfrom simulated discriminative data, which pushes for a high success rate while\npreserving high diversity. Beyond grasp generation, our model can also generate\nobjects based on hand information, offering valuable insights into object\ndesign and studying how the generative model perceives objects. Our model\nachieves state-of-the-art dexterous grasping on the large-scale DexGraspNet\ndataset while facilitating human-centric object design, marking a significant\nadvancement in dexterous grasping research. Our project page is\nhttps://jiaxin-lu.github.io/ugg/ .\n","authors":["Jiaxin Lu","Hao Kang","Haoxiang Li","Bo Liu","Yiding Yang","Qixing Huang","Gang Hua"],"pdf_url":"https://arxiv.org/pdf/2311.16917v1.pdf","comment":"17 pages, 14 figures"},{"id":"http://arxiv.org/abs/2311.16914v1","updated":"2023-11-28T16:16:10Z","published":"2023-11-28T16:16:10Z","title":"Brain-ID: Learning Robust Feature Representations for Brain Imaging","summary":"  Recent learning-based approaches have made astonishing advances in calibrated\nmedical imaging like computerized tomography, yet they struggle to generalize\nin uncalibrated modalities -- notoriously magnetic resonance imaging (MRI),\nwhere performance is highly sensitive to the differences in MR contrast,\nresolution, and orientation between the training and testing data. This\nprevents broad applicability to the diverse clinical acquisition protocols in\nthe real world. We introduce Brain-ID, a robust feature representation learning\nstrategy for brain imaging, which is contrast-agnostic, and robust to the brain\nanatomy of each subject regardless of the appearance of acquired images (i.e.,\ndeformation, contrast, resolution, orientation, artifacts, etc). Brain-ID is\ntrained entirely on synthetic data, and easily adapts to downstream tasks with\nour proposed simple one-layer solution. We validate the robustness of Brain-ID\nfeatures, and evaluate their performance in a variety of downstream\napplications, including both contrast-independent (anatomy\nreconstruction/contrast synthesis, brain segmentation), and contrast-dependent\n(super-resolution, bias field estimation) tasks. Extensive experiments on 6\npublic datasets demonstrate that Brain-ID achieves state-of-the-art performance\nin all tasks, and more importantly, preserves its performance when only limited\ntraining data is available.\n","authors":["Peirong Liu","Oula Puonti","Xiaoling Hu","Daniel C. Alexander","Juan Eugenio Iglesias"],"pdf_url":"https://arxiv.org/pdf/2311.16914v1.pdf","comment":"16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2311.16900v1","updated":"2023-11-28T15:58:13Z","published":"2023-11-28T15:58:13Z","title":"Lane-Keeping Control of Autonomous Vehicles Through a Soft-Constrained\n  Iterative LQR","summary":"  The accurate prediction of smooth steering inputs is crucial for autonomous\nvehicle applications because control actions with jitter might cause the\nvehicle system to become unstable. To address this problem in automobile\nlane-keeping control without the use of additional smoothing algorithms, we\ndeveloped a soft-constrained iterative linear-quadratic regulator (soft-CILQR)\nalgorithm by integrating CILQR algorithm and a model predictive control (MPC)\nconstraint relaxation method. We incorporated slack variables into the state\nand control barrier functions of the soft-CILQR solver to soften the\nconstraints in the optimization process so that stabilizing control inputs can\nbe calculated in a relatively simple manner. Two types of automotive\nlane-keeping experiments were conducted with a linear system dynamics model to\ntest the performance of the proposed soft-CILQR algorithm and to compare its\nperformance with that of the CILQR algorithm: numerical simulations and\nexperiments involving challenging vision-based maneuvers. In the numerical\nsimulations, the soft-CILQR and CILQR solvers managed to drive the system\ntoward the reference state asymptotically; however, the soft-CILQR solver\nobtained smooth steering input trajectories more easily than did the CILQR\nsolver under conditions involving additive disturbances. In the experiments\nwith visual inputs, the soft-CILQR controller outperformed the CILQR controller\nin terms of tracking accuracy and steering smoothness during the driving of an\nego vehicle on TORCS.\n","authors":["Der-Hau Lee"],"pdf_url":"https://arxiv.org/pdf/2311.16900v1.pdf","comment":"11 figures, 10 pages"},{"id":"http://arxiv.org/abs/2311.16894v1","updated":"2023-11-28T15:46:12Z","published":"2023-11-28T15:46:12Z","title":"Dendrogram distance: an evaluation metric for generative networks using\n  hierarchical clustering","summary":"  We present a novel metric for generative modeling evaluation, focusing\nprimarily on generative networks. The method uses dendrograms to represent real\nand fake data, allowing for the divergence between training and generated\nsamples to be computed. This metric focus on mode collapse, targeting\ngenerators that are not able to capture all modes in the training set. To\nevaluate the proposed method it is introduced a validation scheme based on\nsampling from real datasets, therefore the metric is evaluated in a controlled\nenvironment and proves to be competitive with other state-of-the-art\napproaches.\n","authors":["Gustavo Sutter Carvalho","Moacir Antonelli Ponti"],"pdf_url":"https://arxiv.org/pdf/2311.16894v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13131v2","updated":"2023-11-28T15:41:46Z","published":"2022-11-23T17:04:20Z","title":"FeTrIL: Feature Translation for Exemplar-Free Class-Incremental Learning","summary":"  Exemplar-free class-incremental learning is very challenging due to the\nnegative effect of catastrophic forgetting. A balance between stability and\nplasticity of the incremental process is needed in order to obtain good\naccuracy for past as well as new classes. Existing exemplar-free\nclass-incremental methods focus either on successive fine tuning of the model,\nthus favoring plasticity, or on using a feature extractor fixed after the\ninitial incremental state, thus favoring stability. We introduce a method which\ncombines a fixed feature extractor and a pseudo-features generator to improve\nthe stability-plasticity balance. The generator uses a simple yet effective\ngeometric translation of new class features to create representations of past\nclasses, made of pseudo-features. The translation of features only requires the\nstorage of the centroid representations of past classes to produce their\npseudo-features. Actual features of new classes and pseudo-features of past\nclasses are fed into a linear classifier which is trained incrementally to\ndiscriminate between all classes. The incremental process is much faster with\nthe proposed method compared to mainstream ones which update the entire deep\nmodel. Experiments are performed with three challenging datasets, and different\nincremental settings. A comparison with ten existing methods shows that our\nmethod outperforms the others in most cases.\n","authors":["Grégoire Petit","Adrian Popescu","Hugo Schindler","David Picard","Bertrand Delezoide"],"pdf_url":"https://arxiv.org/pdf/2211.13131v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.05521v2","updated":"2023-11-28T15:31:46Z","published":"2023-11-09T17:05:53Z","title":"BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis","summary":"  Synthesizing photorealistic 4D human head avatars from videos is essential\nfor VR/AR, telepresence, and video game applications. Although existing Neural\nRadiance Fields (NeRF)-based methods achieve high-fidelity results, the\ncomputational expense limits their use in real-time applications. To overcome\nthis limitation, we introduce BakedAvatar, a novel representation for real-time\nneural head avatar synthesis, deployable in a standard polygon rasterization\npipeline. Our approach extracts deformable multi-layer meshes from learned\nisosurfaces of the head and computes expression-, pose-, and view-dependent\nappearances that can be baked into static textures for efficient rasterization.\nWe thus propose a three-stage pipeline for neural head avatar synthesis, which\nincludes learning continuous deformation, manifold, and radiance fields,\nextracting layered meshes and textures, and fine-tuning texture details with\ndifferential rasterization. Experimental results demonstrate that our\nrepresentation generates synthesis results of comparable quality to other\nstate-of-the-art methods while significantly reducing the inference time\nrequired. We further showcase various head avatar synthesis results from\nmonocular videos, including view synthesis, face reenactment, expression\nediting, and pose editing, all at interactive frame rates.\n","authors":["Hao-Bin Duan","Miao Wang","Jin-Chuan Shi","Xu-Chuan Chen","Yan-Pei Cao"],"pdf_url":"https://arxiv.org/pdf/2311.05521v2.pdf","comment":"ACM Transactions on Graphics (SIGGRAPH Asia 2023). Project Page:\n  https://buaavrcg.github.io/BakedAvatar"},{"id":"http://arxiv.org/abs/2311.16882v1","updated":"2023-11-28T15:31:11Z","published":"2023-11-28T15:31:11Z","title":"Optimisation-Based Multi-Modal Semantic Image Editing","summary":"  Image editing affords increased control over the aesthetics and content of\ngenerated images. Pre-existing works focus predominantly on text-based\ninstructions to achieve desired image modifications, which limit edit precision\nand accuracy. In this work, we propose an inference-time editing optimisation,\ndesigned to extend beyond textual edits to accommodate multiple editing\ninstruction types (e.g. spatial layout-based; pose, scribbles, edge maps). We\npropose to disentangle the editing task into two competing subtasks: successful\nlocal image modifications and global content consistency preservation, where\nsubtasks are guided through two dedicated loss functions. By allowing to adjust\nthe influence of each loss function, we build a flexible editing solution that\ncan be adjusted to user preferences. We evaluate our method using text, pose\nand scribble edit conditions, and highlight our ability to achieve complex\nedits, through both qualitative and quantitative experiments.\n","authors":["Bowen Li","Yongxin Yang","Steven McDonagh","Shifeng Zhang","Petru-Daniel Tudosiu","Sarah Parisot"],"pdf_url":"https://arxiv.org/pdf/2311.16882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.08289v2","updated":"2023-11-28T15:31:04Z","published":"2022-09-17T09:05:47Z","title":"Continuously Controllable Facial Expression Editing in Talking Face\n  Videos","summary":"  Recently audio-driven talking face video generation has attracted\nconsiderable attention. However, very few researches address the issue of\nemotional editing of these talking face videos with continuously controllable\nexpressions, which is a strong demand in the industry. The challenge is that\nspeech-related expressions and emotion-related expressions are often highly\ncoupled. Meanwhile, traditional image-to-image translation methods cannot work\nwell in our application due to the coupling of expressions with other\nattributes such as poses, i.e., translating the expression of the character in\neach frame may simultaneously change the head pose due to the bias of the\ntraining data distribution. In this paper, we propose a high-quality facial\nexpression editing method for talking face videos, allowing the user to control\nthe target emotion in the edited video continuously. We present a new\nperspective for this task as a special case of motion information editing,\nwhere we use a 3DMM to capture major facial movements and an associated texture\nmap modeled by a StyleGAN to capture appearance details. Both representations\n(3DMM and texture map) contain emotional information and can be continuously\nmodified by neural networks and easily smoothed by averaging in\ncoefficient/latent spaces, making our method simple yet effective. We also\nintroduce a mouth shape preservation loss to control the trade-off between lip\nsynchronization and the degree of exaggeration of the edited expression.\nExtensive experiments and a user study show that our method achieves\nstate-of-the-art performance across various evaluation criteria.\n","authors":["Zhiyao Sun","Yu-Hui Wen","Tian Lv","Yanan Sun","Ziyang Zhang","Yaoyuan Wang","Yong-Jin Liu"],"pdf_url":"https://arxiv.org/pdf/2209.08289v2.pdf","comment":"Accepted by IEEE Transactions on Affective Computing (DOI:\n  10.1109/TAFFC.2023.3334511). Demo video: https://youtu.be/WD-bNVya6kM .\n  Project page: https://raineggplant.github.io/FEE4TV"},{"id":"http://arxiv.org/abs/2311.14829v2","updated":"2023-11-28T15:27:26Z","published":"2023-11-24T19:56:01Z","title":"Proximal Algorithms for Accelerated Langevin Dynamics","summary":"  We develop a novel class of MCMC algorithms based on a stochastized Nesterov\nscheme. With an appropriate addition of noise, the result is a\ntime-inhomogeneous underdamped Langevin equation, which we prove emits a\nspecified target distribution as its invariant measure. Convergence rates to\nstationarity under Wasserstein-2 distance are established as well.\nMetropolis-adjusted and stochastic gradient versions of the proposed Langevin\ndynamics are also provided. Experimental illustrations show superior\nperformance of the proposed method over typical Langevin samplers for different\nmodels in statistics and image processing including better mixing of the\nresulting Markov chains.\n","authors":["Duy H. Thai","Alexander L. Young","David B. Dunson"],"pdf_url":"https://arxiv.org/pdf/2311.14829v2.pdf","comment":"The technical proofs for the paper will be revised"},{"id":"http://arxiv.org/abs/2311.16854v1","updated":"2023-11-28T15:03:53Z","published":"2023-11-28T15:03:53Z","title":"A Unified Approach for Text- and Image-guided 4D Scene Generation","summary":"  Large-scale diffusion generative models are greatly simplifying image, video\nand 3D asset creation from user-provided text prompts and images. However, the\nchallenging problem of text-to-4D dynamic 3D scene generation with diffusion\nguidance remains largely unexplored. We propose Dream-in-4D, which features a\nnovel two-stage approach for text-to-4D synthesis, leveraging (1) 3D and 2D\ndiffusion guidance to effectively learn a high-quality static 3D asset in the\nfirst stage; (2) a deformable neural radiance field that explicitly\ndisentangles the learned static asset from its deformation, preserving quality\nduring motion learning; and (3) a multi-resolution feature grid for the\ndeformation field with a displacement total variation loss to effectively learn\nmotion with video diffusion guidance in the second stage. Through a user\npreference study, we demonstrate that our approach significantly advances image\nand motion quality, 3D consistency and text fidelity for text-to-4D generation\ncompared to baseline approaches. Thanks to its motion-disentangled\nrepresentation, Dream-in-4D can also be easily adapted for controllable\ngeneration where appearance is defined by one or multiple images, without the\nneed to modify the motion learning stage. Thus, our method offers, for the\nfirst time, a unified approach for text-to-4D, image-to-4D and personalized 4D\ngeneration tasks.\n","authors":["Yufeng Zheng","Xueting Li","Koki Nagano","Sifei Liu","Otmar Hilliges","Shalini De Mello"],"pdf_url":"https://arxiv.org/pdf/2311.16854v1.pdf","comment":"Project page: https://dream-in-4d.github.io/dream-in-4D/"},{"id":"http://arxiv.org/abs/2311.16845v1","updated":"2023-11-28T14:58:32Z","published":"2023-11-28T14:58:32Z","title":"Wavelet-based Fourier Information Interaction with Frequency Diffusion\n  Adjustment for Underwater Image Restoration","summary":"  Underwater images are subject to intricate and diverse degradation,\ninevitably affecting the effectiveness of underwater visual tasks. However,\nmost approaches primarily operate in the raw pixel space of images, which\nlimits the exploration of the frequency characteristics of underwater images,\nleading to an inadequate utilization of deep models' representational\ncapabilities in producing high-quality images. In this paper, we introduce a\nnovel Underwater Image Enhancement (UIE) framework, named WF-Diff, designed to\nfully leverage the characteristics of frequency domain information and\ndiffusion models. WF-Diff consists of two detachable networks: Wavelet-based\nFourier information interaction network (WFI2-net) and Frequency Residual\nDiffusion Adjustment Module (FRDAM). With our full exploration of the frequency\ndomain information, WFI2-net aims to achieve preliminary enhancement of\nfrequency information in the wavelet space. Our proposed FRDAM can further\nrefine the high- and low-frequency information of the initial enhanced images,\nwhich can be viewed as a plug-and-play universal module to adjust the detail of\nthe underwater images. With the above techniques, our algorithm can show SOTA\nperformance on real-world underwater image datasets, and achieves competitive\nperformance in visual quality.\n","authors":["Chen Zhao","Weiling Cai","Chenyu Dong","Chengwei Hu"],"pdf_url":"https://arxiv.org/pdf/2311.16845v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16843v1","updated":"2023-11-28T14:57:14Z","published":"2023-11-28T14:57:14Z","title":"Self-training solutions for the ICCV 2023 GeoNet Challenge","summary":"  GeoNet is a recently proposed domain adaptation benchmark consisting of three\nchallenges (i.e., GeoUniDA, GeoImNet, and GeoPlaces). Each challenge contains\nimages collected from the USA and Asia where there are huge geographical gaps.\nOur solution adopts a two-stage source-free domain adaptation framework with a\nSwin Transformer backbone to achieve knowledge transfer from the USA (source)\ndomain to Asia (target) domain. In the first stage, we train a source model\nusing labeled source data with a re-sampling strategy and two types of\ncross-entropy loss. In the second stage, we generate pseudo labels for\nunlabeled target data to fine-tune the model. Our method achieves an H-score of\n74.56% and ultimately ranks 1st in the GeoUniDA challenge. In GeoImNet and\nGeoPlaces challenges, our solution also reaches a top-3 accuracy of 64.46% and\n51.23%, respectively.\n","authors":["Lijun Sheng","Zhengbo Wang","Jian Liang"],"pdf_url":"https://arxiv.org/pdf/2311.16843v1.pdf","comment":"technical report; 1st in the ICCV-2023 GeoUniDA challenge"},{"id":"http://arxiv.org/abs/2311.16839v1","updated":"2023-11-28T14:54:37Z","published":"2023-11-28T14:54:37Z","title":"Beyond Hallucinations: Enhancing LVLMs through Hallucination-Aware\n  Direct Preference Optimization","summary":"  Multimodal large language models have made significant advancements in recent\nyears, yet they still suffer from a common issue known as the \"hallucination\nproblem\" where the models generate textual descriptions that contain inaccurate\nor non-existent content from the image. To address this issue, this paper\nintroduces a novel strategy: Hallucination-Aware Direct Preference Optimization\n(HA-DPO). Our approach treats the hallucination problem as a unique preference\nselection issue, where the model is trained to favor the non-hallucinating\nresponse when presented with two responses of the same image (one accurate and\none hallucinating). This paper also presents an efficient process for\nconstructing hallucination sample pairs to ensure high-quality,\nstyle-consistent pairs for stable HA-DPO training. We applied this strategy to\ntwo mainstream multimodal models, and the results showed a significant\nreduction in the hallucination problem and an enhancement in the models'\ngeneralization capabilities. With HA-DPO, the MiniGPT-4 model demonstrates\nsignificant advancements: POPE accuracy increases from 51.13% to 85.66% (34.5%\nabsolute improvement), and the MME score escalates from 968.58 to 1365.76 (41%\nrelative improvement). The code, models, and datasets will be made publicly\navailable.\n","authors":["Zhiyuan Zhao","Bin Wang","Linke Ouyang","Xiaoyi Dong","Jiaqi Wang","Conghui He"],"pdf_url":"https://arxiv.org/pdf/2311.16839v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2307.11957v4","updated":"2023-11-28T14:53:32Z","published":"2023-07-22T01:56:58Z","title":"High-performance real-world optical computing trained by in situ\n  model-free optimization","summary":"  Optical computing systems provide high-speed and low-energy data processing\nbut face deficiencies in computationally demanding training and\nsimulation-to-reality gaps. We propose a model-free optimization (MFO) method\nbased on a score gradient estimation algorithm for computationally efficient in\nsitu training of optical computing systems. This approach treats an optical\ncomputing system as a black box and back-propagates the loss directly to the\noptical computing weights' probability distributions, circumventing the need\nfor a computationally heavy and biased system simulation. Our experiments on a\nsingle-layer diffractive optical computing system show that MFO outperforms\nhybrid training on the MNIST and FMNIST datasets. Furthermore, we demonstrate\nimage-free and high-speed classification of cells from their phase maps. Our\nmethod's model-free and high-performance nature, combined with its low demand\nfor computational resources, expedites the transition of optical computing from\nlaboratory demonstrations to real-world applications.\n","authors":["Guangyuan Zhao","Xin Shu"],"pdf_url":"https://arxiv.org/pdf/2307.11957v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16835v1","updated":"2023-11-28T14:51:08Z","published":"2023-11-28T14:51:08Z","title":"Unified-modal Salient Object Detection via Adaptive Prompt Learning","summary":"  Existing single-modal and multi-modal salient object detection (SOD) methods\nfocus on designing specific architectures tailored for their respective tasks.\nHowever, developing completely different models for different tasks leads to\nlabor and time consumption, as well as high computational and practical\ndeployment costs. In this paper, we make the first attempt to address both\nsingle-modal and multi-modal SOD in a unified framework called UniSOD.\nNevertheless, assigning appropriate strategies to modality variable inputs is\nchallenging. To this end, UniSOD learns modality-aware prompts with\ntask-specific hints through adaptive prompt learning, which are plugged into\nthe proposed pre-trained baseline SOD model to handle corresponding tasks,\nwhile only requiring few learnable parameters compared to training the entire\nmodel. Each modality-aware prompt is generated from a switchable prompt\ngeneration block, which performs structural switching solely relied on\nsingle-modal and multi-modal inputs. UniSOD achieves consistent performance\nimprovement on 14 benchmark datasets for RGB, RGB-D, and RGB-T SOD, which\ndemonstrates that our method effectively and efficiently unifies single-modal\nand multi-modal SOD tasks.\n","authors":["Kunpeng Wang","Chenglong Li","Zhengzheng Tu","Bin Luo"],"pdf_url":"https://arxiv.org/pdf/2311.16835v1.pdf","comment":"16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2311.16833v1","updated":"2023-11-28T14:50:50Z","published":"2023-11-28T14:50:50Z","title":"1-Lipschitz Layers Compared: Memory, Speed, and Certifiable Robustness","summary":"  The robustness of neural networks against input perturbations with bounded\nmagnitude represents a serious concern in the deployment of deep learning\nmodels in safety-critical systems. Recently, the scientific community has\nfocused on enhancing certifiable robustness guarantees by crafting 1-Lipschitz\nneural networks that leverage Lipschitz bounded dense and convolutional layers.\nAlthough different methods have been proposed in the literature to achieve this\ngoal, understanding the performance of such methods is not straightforward,\nsince different metrics can be relevant (e.g., training time, memory usage,\naccuracy, certifiable robustness) for different applications. For this reason,\nthis work provides a thorough theoretical and empirical comparison between\nmethods by evaluating them in terms of memory usage, speed, and certifiable\nrobust accuracy. The paper also provides some guidelines and recommendations to\nsupport the user in selecting the methods that work best depending on the\navailable resources. We provide code at\nhttps://github.com/berndprach/1LipschitzLayersCompared.\n","authors":["Bernd Prach","Fabio Brau","Giorgio Buttazzo","Christoph H. Lampert"],"pdf_url":"https://arxiv.org/pdf/2311.16833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13847v2","updated":"2023-11-28T14:49:54Z","published":"2023-11-23T08:31:11Z","title":"Perceptual Image Compression with Cooperative Cross-Modal Side\n  Information","summary":"  The explosion of data has resulted in more and more associated text being\ntransmitted along with images. Inspired by from distributed source coding, many\nworks utilize image side information to enhance image compression. However,\nexisting methods generally do not consider using text as side information to\nenhance perceptual compression of images, even though the benefits of\nmultimodal synergy have been widely demonstrated in research. This begs the\nfollowing question: How can we effectively transfer text-level semantic\ndependencies to help image compression, which is only available to the decoder?\nIn this work, we propose a novel deep image compression method with text-guided\nside information to achieve a better rate-perception-distortion tradeoff.\nSpecifically, we employ the CLIP text encoder and an effective Semantic-Spatial\nAware block to fuse the text and image features. This is done by predicting a\nsemantic mask to guide the learned text-adaptive affine transformation at the\npixel level. Furthermore, we design a text-conditional generative adversarial\nnetworks to improve the perceptual quality of reconstructed images. Extensive\nexperiments involving four datasets and ten image quality assessment metrics\ndemonstrate that the proposed approach achieves superior results in terms of\nrate-perception trade-off and semantic distortion.\n","authors":["Shiyu Qin","Bin Chen","Yujun Huang","Baoyi An","Tao Dai","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2311.13847v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16829v1","updated":"2023-11-28T14:48:22Z","published":"2023-11-28T14:48:22Z","title":"Decomposer: Semi-supervised Learning of Image Restoration and Image\n  Decomposition","summary":"  We present Decomposer, a semi-supervised reconstruction model that decomposes\ndistorted image sequences into their fundamental building blocks - the original\nimage and the applied augmentations, i.e., shadow, light, and occlusions. To\nsolve this problem, we use the SIDAR dataset that provides a large number of\ndistorted image sequences: each sequence contains images with shadows,\nlighting, and occlusions applied to an undistorted version. Each distortion\nchanges the original signal in different ways, e.g., additive or multiplicative\nnoise. We propose a transformer-based model to explicitly learn this\ndecomposition. The sequential model uses 3D Swin-Transformers for\nspatio-temporal encoding and 3D U-Nets as prediction heads for individual parts\nof the decomposition. We demonstrate that by separately pre-training our model\non weakly supervised pseudo labels, we can steer our model to optimize for our\nambiguous problem definition and learn to differentiate between the different\nimage distortions.\n","authors":["Boris Meinardus","Mariusz Trzeciakiewicz","Tim Herzig","Monika Kwiatkowski","Simon Matern","Olaf Hellwich"],"pdf_url":"https://arxiv.org/pdf/2311.16829v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16828v1","updated":"2023-11-28T14:46:51Z","published":"2023-11-28T14:46:51Z","title":"SARA: Controllable Makeup Transfer with Spatial Alignment and\n  Region-Adaptive Normalization","summary":"  Makeup transfer is a process of transferring the makeup style from a\nreference image to the source images, while preserving the source images'\nidentities. This technique is highly desirable and finds many applications.\nHowever, existing methods lack fine-level control of the makeup style, making\nit challenging to achieve high-quality results when dealing with large spatial\nmisalignments. To address this problem, we propose a novel Spatial Alignment\nand Region-Adaptive normalization method (SARA) in this paper. Our method\ngenerates detailed makeup transfer results that can handle large spatial\nmisalignments and achieve part-specific and shade-controllable makeup transfer.\nSpecifically, SARA comprises three modules: Firstly, a spatial alignment module\nthat preserves the spatial context of makeup and provides a target semantic map\nfor guiding the shape-independent style codes. Secondly, a region-adaptive\nnormalization module that decouples shape and makeup style using per-region\nencoding and normalization, which facilitates the elimination of spatial\nmisalignments. Lastly, a makeup fusion module blends identity features and\nmakeup style by injecting learned scale and bias parameters. Experimental\nresults show that our SARA method outperforms existing methods and achieves\nstate-of-the-art performance on two public datasets.\n","authors":["Xiaojing Zhong","Xinyi Huang","Zhonghua Wu","Guosheng Lin","Qingyao Wu"],"pdf_url":"https://arxiv.org/pdf/2311.16828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.14153v3","updated":"2023-11-28T14:37:13Z","published":"2023-06-25T07:40:39Z","title":"DomainStudio: Fine-Tuning Diffusion Models for Domain-Driven Image\n  Generation using Limited Data","summary":"  Denoising diffusion probabilistic models (DDPMs) have been proven capable of\nsynthesizing high-quality images with remarkable diversity when trained on\nlarge amounts of data. Typical diffusion models and modern large-scale\nconditional generative models like text-to-image generative models are\nvulnerable to overfitting when fine-tuned on extremely limited data. Existing\nworks have explored subject-driven generation using a reference set containing\na few images. However, few prior works explore DDPM-based domain-driven\ngeneration, which aims to learn the common features of target domains while\nmaintaining diversity. This paper proposes a novel DomainStudio approach to\nadapt DDPMs pre-trained on large-scale source datasets to target domains using\nlimited data. It is designed to keep the diversity of subjects provided by\nsource domains and get high-quality and diverse adapted samples in target\ndomains. We propose to keep the relative distances between adapted samples to\nachieve considerable generation diversity. In addition, we further enhance the\nlearning of high-frequency details for better generation quality. Our approach\nis compatible with both unconditional and conditional diffusion models. This\nwork makes the first attempt to realize unconditional few-shot image generation\nwith diffusion models, achieving better quality and greater diversity than\ncurrent state-of-the-art GAN-based approaches. Moreover, this work also\nsignificantly relieves overfitting for conditional generation and realizes\nhigh-quality domain-driven generation, further expanding the applicable\nscenarios of modern large-scale text-to-image models.\n","authors":["Jingyuan Zhu","Huimin Ma","Jiansheng Chen","Jian Yuan"],"pdf_url":"https://arxiv.org/pdf/2306.14153v3.pdf","comment":"extended from DDPM-PA (arXiv:2211.03264), 33 pages, 34 figures"},{"id":"http://arxiv.org/abs/2311.16821v1","updated":"2023-11-28T14:34:04Z","published":"2023-11-28T14:34:04Z","title":"Denoising Diffusion Probabilistic Models for Image Inpainting of Cell\n  Distributions in the Human Brain","summary":"  Recent advances in imaging and high-performance computing have made it\npossible to image the entire human brain at the cellular level. This is the\nbasis to study the multi-scale architecture of the brain regarding its\nsubdivision into brain areas and nuclei, cortical layers, columns, and cell\nclusters down to single cell morphology Methods for brain mapping and cell\nsegmentation exploit such images to enable rapid and automated analysis of\ncytoarchitecture and cell distribution in complete series of histological\nsections. However, the presence of inevitable processing artifacts in the image\ndata caused by missing sections, tears in the tissue, or staining variations\nremains the primary reason for gaps in the resulting image data. To this end we\naim to provide a model that can fill in missing information in a reliable way,\nfollowing the true cell distribution at different scales. Inspired by the\nrecent success in image generation, we propose a denoising diffusion\nprobabilistic model (DDPM), trained on light-microscopic scans of cell-body\nstained sections. We extend this model with the RePaint method to impute\nmissing or replace corrupted image data. We show that our trained DDPM is able\nto generate highly realistic image information for this purpose, generating\nplausible cell statistics and cytoarchitectonic patterns. We validate its\noutputs using two established downstream task models trained on the same data.\n","authors":["Jan-Oliver Kropp","Christian Schiffer","Katrin Amunts","Timo Dickscheid"],"pdf_url":"https://arxiv.org/pdf/2311.16821v1.pdf","comment":"Submitted to ISBI-2024"},{"id":"http://arxiv.org/abs/2311.13846v2","updated":"2023-11-28T14:31:43Z","published":"2023-11-23T08:29:32Z","title":"Progressive Learning with Visual Prompt Tuning for Variable-Rate Image\n  Compression","summary":"  In this paper, we propose a progressive learning paradigm for\ntransformer-based variable-rate image compression. Our approach covers a wide\nrange of compression rates with the assistance of the Layer-adaptive Prompt\nModule (LPM). Inspired by visual prompt tuning, we use LPM to extract prompts\nfor input images and hidden features at the encoder side and decoder side,\nrespectively, which are fed as additional information into the Swin Transformer\nlayer of a pre-trained transformer-based image compression model to affect the\nallocation of attention region and the bits, which in turn changes the target\ncompression ratio of the model. To ensure the network is more lightweight, we\ninvolves the integration of prompt networks with less convolutional layers.\nExhaustive experiments show that compared to methods based on multiple models,\nwhich are optimized separately for different target rates, the proposed method\narrives at the same performance with 80% savings in parameter storage and 90%\nsavings in datasets. Meanwhile, our model outperforms all current variable\nbitrate image methods in terms of rate-distortion performance and approaches\nthe state-of-the-art fixed bitrate image compression methods trained from\nscratch.\n","authors":["Shiyu Qin","Yimin Zhou","Jinpeng Wang","Bin Chen","Baoyi An","Tao Dai","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2311.13846v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16818v1","updated":"2023-11-28T14:28:41Z","published":"2023-11-28T14:28:41Z","title":"DI-Net : Decomposed Implicit Garment Transfer Network for Digital\n  Clothed 3D Human","summary":"  3D virtual try-on enjoys many potential applications and hence has attracted\nwide attention. However, it remains a challenging task that has not been\nadequately solved. Existing 2D virtual try-on methods cannot be directly\nextended to 3D since they lack the ability to perceive the depth of each pixel.\nBesides, 3D virtual try-on approaches are mostly built on the fixed topological\nstructure and with heavy computation. To deal with these problems, we propose a\nDecomposed Implicit garment transfer network (DI-Net), which can effortlessly\nreconstruct a 3D human mesh with the newly try-on result and preserve the\ntexture from an arbitrary perspective. Specifically, DI-Net consists of two\nmodules: 1) A complementary warping module that warps the reference image to\nhave the same pose as the source image through dense correspondence learning\nand sparse flow learning; 2) A geometry-aware decomposed transfer module that\ndecomposes the garment transfer into image layout based transfer and texture\nbased transfer, achieving surface and texture reconstruction by constructing\npixel-aligned implicit functions. Experimental results show the effectiveness\nand superiority of our method in the 3D virtual try-on task, which can yield\nmore high-quality results over other existing methods.\n","authors":["Xiaojing Zhong","Yukun Su","Zhonghua Wu","Guosheng Lin","Qingyao Wu"],"pdf_url":"https://arxiv.org/pdf/2311.16818v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16813v1","updated":"2023-11-28T14:22:24Z","published":"2023-11-28T14:22:24Z","title":"Panacea: Panoramic and Controllable Video Generation for Autonomous\n  Driving","summary":"  The field of autonomous driving increasingly demands high-quality annotated\ntraining data. In this paper, we propose Panacea, an innovative approach to\ngenerate panoramic and controllable videos in driving scenarios, capable of\nyielding an unlimited numbers of diverse, annotated samples pivotal for\nautonomous driving advancements. Panacea addresses two critical challenges:\n'Consistency' and 'Controllability.' Consistency ensures temporal and\ncross-view coherence, while Controllability ensures the alignment of generated\ncontent with corresponding annotations. Our approach integrates a novel 4D\nattention and a two-stage generation pipeline to maintain coherence,\nsupplemented by the ControlNet framework for meticulous control by the\nBird's-Eye-View (BEV) layouts. Extensive qualitative and quantitative\nevaluations of Panacea on the nuScenes dataset prove its effectiveness in\ngenerating high-quality multi-view driving-scene videos. This work notably\npropels the field of autonomous driving by effectively augmenting the training\ndataset used for advanced BEV perception techniques.\n","authors":["Yuqing Wen","Yucheng Zhao","Yingfei Liu","Fan Jia","Yanhui Wang","Chong Luo","Chi Zhang","Tiancai Wang","Xiaoyan Sun","Xiangyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.16813v1.pdf","comment":"Project page: https://panacea-ad.github.io/"},{"id":"http://arxiv.org/abs/2311.06542v2","updated":"2023-11-28T13:50:12Z","published":"2023-11-11T11:35:37Z","title":"Generation Of Colors using Bidirectional Long Short Term Memory Networks","summary":"  Human vision can distinguish between a vast spectrum of colours, estimated to\nbe between 2 to 7 million discernible shades. However, this impressive range\ndoes not inherently imply that all these colours have been precisely named and\ndescribed within our lexicon. We often associate colours with familiar objects\nand concepts in our daily lives. This research endeavors to bridge the gap\nbetween our visual perception of countless shades and our ability to articulate\nand name them accurately. A novel model has been developed to achieve this\ngoal, leveraging Bidirectional Long Short-Term Memory (BiLSTM) networks with\nActive learning. This model operates on a proprietary dataset meticulously\ncurated for this study. The primary objective of this research is to create a\nversatile tool for categorizing and naming previously unnamed colours or\nidentifying intermediate shades that elude traditional colour terminology. The\nfindings underscore the potential of this innovative approach in\nrevolutionizing our understanding of colour perception and language. Through\nrigorous experimentation and analysis, this study illuminates a promising\navenue for Natural Language Processing (NLP) applications in diverse\nindustries. By facilitating the exploration of the vast colour spectrum the\npotential applications of NLP are extended beyond conventional boundaries.\n","authors":["A. Sinha"],"pdf_url":"https://arxiv.org/pdf/2311.06542v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2311.16782v1","updated":"2023-11-28T13:45:15Z","published":"2023-11-28T13:45:15Z","title":"The curse of language biases in remote sensing VQA: the role of spatial\n  attributes, language diversity, and the need for clear evaluation","summary":"  Remote sensing visual question answering (RSVQA) opens new opportunities for\nthe use of overhead imagery by the general public, by enabling human-machine\ninteraction with natural language. Building on the recent advances in natural\nlanguage processing and computer vision, the goal of RSVQA is to answer a\nquestion formulated in natural language about a remote sensing image. Language\nunderstanding is essential to the success of the task, but has not yet been\nthoroughly examined in RSVQA. In particular, the problem of language biases is\noften overlooked in the remote sensing community, which can impact model\nrobustness and lead to wrong conclusions about the performances of the model.\nThus, the present work aims at highlighting the problem of language biases in\nRSVQA with a threefold analysis strategy: visual blind models, adversarial\ntesting and dataset analysis. This analysis focuses both on model and data.\nMoreover, we motivate the use of more informative and complementary evaluation\nmetrics sensitive to the issue. The gravity of language biases in RSVQA is then\nexposed for all of these methods with the training of models discarding the\nimage data and the manipulation of the visual input during inference. Finally,\na detailed analysis of question-answer distribution demonstrates the root of\nthe problem in the data itself. Thanks to this analytical study, we observed\nthat biases in remote sensing are more severe than in standard VQA, likely due\nto the specifics of existing remote sensing datasets for the task, e.g.\ngeographical similarities and sparsity, as well as a simpler vocabulary and\nquestion generation strategies. While new, improved and less-biased datasets\nappear as a necessity for the development of the promising field of RSVQA, we\ndemonstrate that more informed, relative evaluation metrics remain much needed\nto transparently communicate results of future RSVQA methods.\n","authors":["Christel Chappuis","Eliot Walt","Vincent Mendez","Sylvain Lobry","Bertrand Le Saux","Devis Tuia"],"pdf_url":"https://arxiv.org/pdf/2311.16782v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01837v2","updated":"2023-11-28T13:36:58Z","published":"2023-10-03T07:01:23Z","title":"Extending CAM-based XAI methods for Remote Sensing Imagery Segmentation","summary":"  Current AI-based methods do not provide comprehensible physical\ninterpretations of the utilized data, extracted features, and\npredictions/inference operations. As a result, deep learning models trained\nusing high-resolution satellite imagery lack transparency and explainability\nand can be merely seen as a black box, which limits their wide-level adoption.\nExperts need help understanding the complex behavior of AI models and the\nunderlying decision-making process. The explainable artificial intelligence\n(XAI) field is an emerging field providing means for robust, practical, and\ntrustworthy deployment of AI models. Several XAI techniques have been proposed\nfor image classification tasks, whereas the interpretation of image\nsegmentation remains largely unexplored. This paper offers to bridge this gap\nby adapting the recent XAI classification algorithms and making them usable for\nmuti-class image segmentation, where we mainly focus on buildings' segmentation\nfrom high-resolution satellite images. To benchmark and compare the performance\nof the proposed approaches, we introduce a new XAI evaluation methodology and\nmetric based on \"Entropy\" to measure the model uncertainty. Conventional XAI\nevaluation methods rely mainly on feeding area-of-interest regions from the\nimage back to the pre-trained (utility) model and then calculating the average\nchange in the probability of the target class. Those evaluation metrics lack\nthe needed robustness, and we show that using Entropy to monitor the model\nuncertainty in segmenting the pixels within the target class is more suitable.\nWe hope this work will pave the way for additional XAI research for image\nsegmentation and applications in the remote sensing discipline.\n","authors":["Abdul Karim Gizzini","Mustafa Shukor","Ali J. Ghandour"],"pdf_url":"https://arxiv.org/pdf/2310.01837v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16773v1","updated":"2023-11-28T13:30:10Z","published":"2023-11-28T13:30:10Z","title":"Multi-Channel Cross Modal Detection of Synthetic Face Images","summary":"  Synthetically generated face images have shown to be indistinguishable from\nreal images by humans and as such can lead to a lack of trust in digital\ncontent as they can, for instance, be used to spread misinformation. Therefore,\nthe need to develop algorithms for detecting entirely synthetic face images is\napparent. Of interest are images generated by state-of-the-art deep\nlearning-based models, as these exhibit a high level of visual realism. Recent\nworks have demonstrated that detecting such synthetic face images under\nrealistic circumstances remains difficult as new and improved generative models\nare proposed with rapid speed and arbitrary image post-processing can be\napplied. In this work, we propose a multi-channel architecture for detecting\nentirely synthetic face images which analyses information both in the frequency\nand visible spectra using Cross Modal Focal Loss. We compare the proposed\narchitecture with several related architectures trained using Binary Cross\nEntropy and show in cross-model experiments that the proposed architecture\nsupervised using Cross Modal Focal Loss, in general, achieves most competitive\nperformance.\n","authors":["M. Ibsen","C. Rathgeb","S. Marcel","C. Busch"],"pdf_url":"https://arxiv.org/pdf/2311.16773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.14289v2","updated":"2023-11-28T13:28:24Z","published":"2023-09-25T16:52:59Z","title":"CLIP-DIY: CLIP Dense Inference Yields Open-Vocabulary Semantic\n  Segmentation For-Free","summary":"  The emergence of CLIP has opened the way for open-world image perception. The\nzero-shot classification capabilities of the model are impressive but are\nharder to use for dense tasks such as image segmentation. Several methods have\nproposed different modifications and learning schemes to produce dense output.\nInstead, we propose in this work an open-vocabulary semantic segmentation\nmethod, dubbed CLIP-DIY, which does not require any additional training or\nannotations, but instead leverages existing unsupervised object localization\napproaches. In particular, CLIP-DIY is a multi-scale approach that directly\nexploits CLIP classification abilities on patches of different sizes and\naggregates the decision in a single map. We further guide the segmentation\nusing foreground/background scores obtained using unsupervised object\nlocalization methods. With our method, we obtain state-of-the-art zero-shot\nsemantic segmentation results on PASCAL VOC and perform on par with the best\nmethods on COCO. The code is available at\nhttp://github.com/wysoczanska/clip-diy\n","authors":["Monika Wysoczańska","Michaël Ramamonjisoa","Tomasz Trzciński","Oriane Siméoni"],"pdf_url":"https://arxiv.org/pdf/2309.14289v2.pdf","comment":"Accepted to WACV 2024"},{"id":"http://arxiv.org/abs/2311.16766v1","updated":"2023-11-28T13:14:55Z","published":"2023-11-28T13:14:55Z","title":"Rescuing referral failures during automated diagnosis of domain-shifted\n  medical images","summary":"  The success of deep learning models deployed in the real world depends\ncritically on their ability to generalize well across diverse data domains.\nHere, we address a fundamental challenge with selective classification during\nautomated diagnosis with domain-shifted medical images. In this scenario,\nmodels must learn to avoid making predictions when label confidence is low,\nespecially when tested with samples far removed from the training set\n(covariate shift). Such uncertain cases are typically referred to the clinician\nfor further analysis and evaluation. Yet, we show that even state-of-the-art\ndomain generalization approaches fail severely during referral when tested on\nmedical images acquired from a different demographic or using a different\ntechnology. We examine two benchmark diagnostic medical imaging datasets\nexhibiting strong covariate shifts: i) diabetic retinopathy prediction with\nretinal fundus images and ii) multilabel disease prediction with chest X-ray\nimages. We show that predictive uncertainty estimates do not generalize well\nunder covariate shifts leading to non-monotonic referral curves, and severe\ndrops in performance (up to 50%) at high referral rates (>70%). We evaluate\nnovel combinations of robust generalization and post hoc referral approaches,\nthat rescue these failures and achieve significant performance improvements,\ntypically >10%, over baseline methods. Our study identifies a critical\nchallenge with referral in domain-shifted medical images and finds key\napplications in reliable, automated disease diagnosis.\n","authors":["Anuj Srivastava","Karm Patel","Pradeep Shenoy","Devarajan Sridharan"],"pdf_url":"https://arxiv.org/pdf/2311.16766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.00126v2","updated":"2023-11-28T13:12:39Z","published":"2023-04-28T23:43:10Z","title":"Event-Free Moving Object Segmentation from Moving Ego Vehicle","summary":"  Moving object segmentation (MOS) in dynamic scenes is challenging for\nautonomous driving, especially for sequences obtained from moving ego vehicles.\nMost state-of-the-art methods leverage motion cues obtained from optical flow\nmaps. However, since these methods are often based on optical flows that are\npre-computed from successive RGB frames, this neglects the temporal\nconsideration of events occurring within inter-frame and limits the\npracticality of these methods in real-life situations. To address these\nlimitations, we propose to exploit event cameras for better video\nunderstanding, which provide rich motion cues without relying on optical flow.\nTo foster research in this area, we first introduce a novel large-scale dataset\ncalled DSEC-MOS for moving object segmentation from moving ego vehicles.\nSubsequently, we devise EmoFormer, a novel network able to exploit the event\ndata. For this purpose, we fuse the event prior with spatial semantic maps to\ndistinguish moving objects from the static background, adding another level of\ndense supervision around our object of interest - moving ones. Our proposed\nnetwork relies only on event data for training but does not require event input\nduring inference, making it directly comparable to frame-only methods in terms\nof efficiency and more widely usable in many application cases. An exhaustive\ncomparison with 8 state-of-the-art video object segmentation methods highlights\na significant performance improvement of our method over all other methods.\nProject Page: https://github.com/ZZY-Zhou/DSEC-MOS.\n","authors":["Zhuyun Zhou","Zongwei Wu","Danda Pani Paudel","Rémi Boutteau","Fan Yang","Luc Van Gool","Radu Timofte","Dominique Ginhac"],"pdf_url":"https://arxiv.org/pdf/2305.00126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.10276v3","updated":"2023-11-28T13:07:03Z","published":"2023-03-17T23:18:20Z","title":"Unleashing the Potential of Spiking Neural Networks by Dynamic\n  Confidence","summary":"  This paper presents a new methodology to alleviate the fundamental trade-off\nbetween accuracy and latency in spiking neural networks (SNNs). The approach\ninvolves decoding confidence information over time from the SNN outputs and\nusing it to develop a decision-making agent that can dynamically determine when\nto terminate each inference.\n  The proposed method, Dynamic Confidence, provides several significant\nbenefits to SNNs. 1. It can effectively optimize latency dynamically at\nruntime, setting it apart from many existing low-latency SNN algorithms. Our\nexperiments on CIFAR-10 and ImageNet datasets have demonstrated an average 40%\nspeedup across eight different settings after applying Dynamic Confidence. 2.\nThe decision-making agent in Dynamic Confidence is straightforward to construct\nand highly robust in parameter space, making it extremely easy to implement. 3.\nThe proposed method enables visualizing the potential of any given SNN, which\nsets a target for current SNNs to approach. For instance, if an SNN can\nterminate at the most appropriate time point for each input sample, a ResNet-50\nSNN can achieve an accuracy as high as 82.47% on ImageNet within just 4.71 time\nsteps on average. Unlocking the potential of SNNs needs a highly-reliable\ndecision-making agent to be constructed and fed with a high-quality estimation\nof ground truth. In this regard, Dynamic Confidence represents a meaningful\nstep toward realizing the potential of SNNs.\n","authors":["Chen Li","Edward Jones","Steve Furber"],"pdf_url":"https://arxiv.org/pdf/2303.10276v3.pdf","comment":"Accepted by ICCV2023"},{"id":"http://arxiv.org/abs/2311.16759v1","updated":"2023-11-28T13:02:33Z","published":"2023-11-28T13:02:33Z","title":"Gradient-based Local Next-best-view Planning for Improved Perception of\n  Targeted Plant Nodes","summary":"  Robots are increasingly used in tomato greenhouses to automate\nlabour-intensive tasks such as selective harvesting and de-leafing. To perform\nthese tasks, robots must be able to accurately and efficiently perceive the\nplant nodes that need to be cut, despite the high levels of occlusion from\nother plant parts. We formulate this problem as a local next-best-view (NBV)\nplanning task where the robot has to plan an efficient set of camera viewpoints\nto overcome occlusion and improve the quality of perception. Our formulation\nfocuses on quickly improving the perception accuracy of a single target node to\nmaximise its chances of being cut. Previous methods of NBV planning mostly\nfocused on global view planning and used random sampling of candidate\nviewpoints for exploration, which could suffer from high computational costs,\nineffective view selection due to poor candidates, or non-smooth trajectories\ndue to inefficient sampling. We propose a gradient-based NBV planner using\ndifferential ray sampling, which directly estimates the local gradient\ndirection for viewpoint planning to overcome occlusion and improve perception.\nThrough simulation experiments, we showed that our planner can handle\nocclusions and improve the 3D reconstruction and position estimation of nodes\nequally well as a sampling-based NBV planner, while taking ten times less\ncomputation and generating 28% more efficient trajectories.\n","authors":["Akshay K. Burusa","Eldert J. van Henten","Gert Kootstra"],"pdf_url":"https://arxiv.org/pdf/2311.16759v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2311.16754v1","updated":"2023-11-28T12:52:49Z","published":"2023-11-28T12:52:49Z","title":"Towards Full-scene Domain Generalization in Multi-agent Collaborative\n  Bird's Eye View Segmentation for Connected and Autonomous Driving","summary":"  Collaborative perception has recently gained significant attention in\nautonomous driving, improving perception quality by enabling the exchange of\nadditional information among vehicles. However, deploying collaborative\nperception systems can lead to domain shifts due to diverse environmental\nconditions and data heterogeneity among connected and autonomous vehicles\n(CAVs). To address these challenges, we propose a unified domain generalization\nframework applicable in both training and inference stages of collaborative\nperception. In the training phase, we introduce an Amplitude Augmentation\n(AmpAug) method to augment low-frequency image variations, broadening the\nmodel's ability to learn across various domains. We also employ a\nmeta-consistency training scheme to simulate domain shifts, optimizing the\nmodel with a carefully designed consistency loss to encourage domain-invariant\nrepresentations. In the inference phase, we introduce an intra-system domain\nalignment mechanism to reduce or potentially eliminate the domain discrepancy\namong CAVs prior to inference. Comprehensive experiments substantiate the\neffectiveness of our method in comparison with the existing state-of-the-art\nworks. Code will be released at https://github.com/DG-CAVs/DG-CoPerception.git.\n","authors":["Senkang Hu","Zhengru Fang","Xianhao Chen","Yuguang Fang","Sam Kwong"],"pdf_url":"https://arxiv.org/pdf/2311.16754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16739v1","updated":"2023-11-28T12:35:13Z","published":"2023-11-28T12:35:13Z","title":"As-Plausible-As-Possible: Plausibility-Aware Mesh Deformation Using 2D\n  Diffusion Priors","summary":"  We present As-Plausible-as-Possible (APAP) mesh deformation technique that\nleverages 2D diffusion priors to preserve the plausibility of a mesh under\nuser-controlled deformation. Our framework uses per-face Jacobians to represent\nmesh deformations, where mesh vertex coordinates are computed via a\ndifferentiable Poisson Solve. The deformed mesh is rendered, and the resulting\n2D image is used in the Score Distillation Sampling (SDS) process, which\nenables extracting meaningful plausibility priors from a pretrained 2D\ndiffusion model. To better preserve the identity of the edited mesh, we\nfine-tune our 2D diffusion model with LoRA. Gradients extracted by SDS and a\nuser-prescribed handle displacement are then backpropagated to the per-face\nJacobians, and we use iterative gradient descent to compute the final\ndeformation that balances between the user edit and the output plausibility. We\nevaluate our method with 2D and 3D meshes and demonstrate qualitative and\nquantitative improvements when using plausibility priors over\ngeometry-preservation or distortion-minimization priors used by previous\ntechniques.\n","authors":["Seungwoo Yoo","Kunho Kim","Vladimir G. Kim","Minhyuk Sung"],"pdf_url":"https://arxiv.org/pdf/2311.16739v1.pdf","comment":"Project page: https://as-plausible-as-possible.github.io/"},{"id":"http://arxiv.org/abs/2311.16738v1","updated":"2023-11-28T12:34:46Z","published":"2023-11-28T12:34:46Z","title":"Riemannian Self-Attention Mechanism for SPD Networks","summary":"  Symmetric positive definite (SPD) matrix has been demonstrated to be an\neffective feature descriptor in many scientific areas, as it can encode\nspatiotemporal statistics of the data adequately on a curved Riemannian\nmanifold, i.e., SPD manifold. Although there are many different ways to design\nnetwork architectures for SPD matrix nonlinear learning, very few solutions\nexplicitly mine the geometrical dependencies of features at different layers.\nMotivated by the great success of self-attention mechanism in capturing\nlong-range relationships, an SPD manifold self-attention mechanism (SMSA) is\nproposed in this paper using some manifold-valued geometric operations, mainly\nthe Riemannian metric, Riemannian mean, and Riemannian optimization. Then, an\nSMSA-based geometric learning module (SMSA-GLM) is designed for the sake of\nimproving the discrimination of the generated deep structured representations.\nExtensive experimental results achieved on three benchmarking datasets show\nthat our modification against the baseline network further alleviates the\ninformation degradation problem and leads to improved accuracy.\n","authors":["Rui Wang","Xiao-Jun Wu","Hui Li","Josef Kittler"],"pdf_url":"https://arxiv.org/pdf/2311.16738v1.pdf","comment":"14 pages, 10 figures, 5 tables"},{"id":"http://arxiv.org/abs/2311.16737v1","updated":"2023-11-28T12:33:49Z","published":"2023-11-28T12:33:49Z","title":"Point'n Move: Interactive Scene Object Manipulation on Gaussian\n  Splatting Radiance Fields","summary":"  We propose Point'n Move, a method that achieves interactive scene object\nmanipulation with exposed region inpainting. Interactivity here further comes\nfrom intuitive object selection and real-time editing. To achieve this, we\nadopt Gaussian Splatting Radiance Field as the scene representation and fully\nleverage its explicit nature and speed advantage. Its explicit representation\nformulation allows us to devise a 2D prompt points to 3D mask dual-stage\nself-prompting segmentation algorithm, perform mask refinement and merging,\nminimize change as well as provide good initialization for scene inpainting and\nperform editing in real-time without per-editing training, all leads to\nsuperior quality and performance. We test our method by performing editing on\nboth forward-facing and 360 scenes. We also compare our method against existing\nscene object removal methods, showing superior quality despite being more\ncapable and having a speed advantage.\n","authors":["Jiajun Huang","Hongchuan Yu"],"pdf_url":"https://arxiv.org/pdf/2311.16737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16728v1","updated":"2023-11-28T12:19:00Z","published":"2023-11-28T12:19:00Z","title":"Photo-SLAM: Real-time Simultaneous Localization and Photorealistic\n  Mapping for Monocular, Stereo, and RGB-D Cameras","summary":"  The integration of neural rendering and the SLAM system recently showed\npromising results in joint localization and photorealistic view reconstruction.\nHowever, existing methods, fully relying on implicit representations, are so\nresource-hungry that they cannot run on portable devices, which deviates from\nthe original intention of SLAM. In this paper, we present Photo-SLAM, a novel\nSLAM framework with a hyper primitives map. Specifically, we simultaneously\nexploit explicit geometric features for localization and learn implicit\nphotometric features to represent the texture information of the observed\nenvironment. In addition to actively densifying hyper primitives based on\ngeometric features, we further introduce a Gaussian-Pyramid-based training\nmethod to progressively learn multi-level features, enhancing photorealistic\nmapping performance. The extensive experiments with monocular, stereo, and\nRGB-D datasets prove that our proposed system Photo-SLAM significantly\noutperforms current state-of-the-art SLAM systems for online photorealistic\nmapping, e.g., PSNR is 30% higher and rendering speed is hundreds of times\nfaster in the Replica dataset. Moreover, the Photo-SLAM can run at real-time\nspeed using an embedded platform such as Jetson AGX Orin, showing the potential\nof robotics applications.\n","authors":["Huajian Huang","Longwei Li","Hui Cheng","Sai-Kit Yeung"],"pdf_url":"https://arxiv.org/pdf/2311.16728v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13409v2","updated":"2023-11-28T12:12:46Z","published":"2023-11-22T14:13:27Z","title":"CompenHR: Efficient Full Compensation for High-resolution Projector","summary":"  Full projector compensation is a practical task of projector-camera systems.\nIt aims to find a projector input image, named compensation image, such that\nwhen projected it cancels the geometric and photometric distortions due to the\nphysical environment and hardware. State-of-the-art methods use deep learning\nto address this problem and show promising performance for low-resolution\nsetups. However, directly applying deep learning to high-resolution setups is\nimpractical due to the long training time and high memory cost. To address this\nissue, this paper proposes a practical full compensation solution. Firstly, we\ndesign an attention-based grid refinement network to improve geometric\ncorrection quality. Secondly, we integrate a novel sampling scheme into an\nend-to-end compensation network to alleviate computation and introduce\nattention blocks to preserve key features. Finally, we construct a benchmark\ndataset for high-resolution projector full compensation. In experiments, our\nmethod demonstrates clear advantages in both efficiency and quality.\n","authors":["Yuxi Wang","Haibin Ling","Bingyao Huang"],"pdf_url":"https://arxiv.org/pdf/2311.13409v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16714v1","updated":"2023-11-28T11:53:56Z","published":"2023-11-28T11:53:56Z","title":"Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld","summary":"  While large language models (LLMs) excel in a simulated world of texts, they\nstruggle to interact with the more realistic world without perceptions of other\nmodalities such as visual or audio signals. Although vision-language models\n(VLMs) integrate LLM modules (1) aligned with static image features, and (2)\nmay possess prior knowledge of world dynamics (as demonstrated in the text\nworld), they have not been trained in an embodied visual world and thus cannot\nalign with its dynamics. On the other hand, training an embodied agent in a\nnoisy visual world without expert guidance is often challenging and\ninefficient. In this paper, we train a VLM agent living in a visual world using\nan LLM agent excelling in a parallel text world (but inapplicable to the visual\nworld). Specifically, we distill LLM's reflection outcomes (improved actions by\nanalyzing mistakes) in a text world's tasks to finetune the VLM on the same\ntasks of the visual world, resulting in an Embodied Multi-Modal Agent (EMMA)\nquickly adapting to the visual world dynamics. Such cross-modality imitation\nlearning between the two parallel worlds enables EMMA to generalize to a broad\nscope of new tasks without any further guidance from the LLM expert. Extensive\nevaluations on the ALFWorld benchmark highlight EMMA's superior performance to\nSOTA VLM-based agents across diverse tasks, e.g., 20%-70% improvement in the\nsuccess rate.\n","authors":["Yijun Yang","Tianyi Zhou","Kanxue Li","Dapeng Tao","Lusong Li","Li Shen","Xiaodong He","Jing Jiang","Yuhui Shi"],"pdf_url":"https://arxiv.org/pdf/2311.16714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16711v1","updated":"2023-11-28T11:45:35Z","published":"2023-11-28T11:45:35Z","title":"LEDITS++: Limitless Image Editing using Text-to-Image Models","summary":"  Text-to-image diffusion models have recently received increasing interest for\ntheir astonishing ability to produce high-fidelity images from solely text\ninputs. Subsequent research efforts aim to exploit and apply their capabilities\nto real image editing. However, existing image-to-image methods are often\ninefficient, imprecise, and of limited versatility. They either require\ntime-consuming fine-tuning, deviate unnecessarily strongly from the input\nimage, and/or lack support for multiple, simultaneous edits. To address these\nissues, we introduce LEDITS++, an efficient yet versatile and precise textual\nimage manipulation technique. LEDITS++'s novel inversion approach requires no\ntuning nor optimization and produces high-fidelity results with a few diffusion\nsteps. Second, our methodology supports multiple simultaneous edits and is\narchitecture-agnostic. Third, we use a novel implicit masking technique that\nlimits changes to relevant image regions. We propose the novel TEdBench++\nbenchmark as part of our exhaustive evaluation. Our results demonstrate the\ncapabilities of LEDITS++ and its improvements over previous methods. The\nproject page is available at https://leditsplusplus-project.static.hf.space .\n","authors":["Manuel Brack","Felix Friedrich","Katharina Kornmeier","Linoy Tsaban","Patrick Schramowski","Kristian Kersting","Apolinário Passos"],"pdf_url":"https://arxiv.org/pdf/2311.16711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02760v3","updated":"2023-11-28T11:44:16Z","published":"2022-11-04T21:51:53Z","title":"Development and evaluation of automated localisation and reconstruction\n  of all fruits on tomato plants in a greenhouse based on multi-view perception\n  and 3D multi-object tracking","summary":"  The ability to accurately represent and localise relevant objects is\nessential for robots to carry out tasks effectively. Traditional approaches,\nwhere robots simply capture an image, process that image to take an action, and\nthen forget the information, have proven to struggle in the presence of\nocclusions. Methods using multi-view perception, which have the potential to\naddress some of these problems, require a world model that guides the\ncollection, integration and extraction of information from multiple viewpoints.\nFurthermore, constructing a generic representation that can be applied in\nvarious environments and tasks is a difficult challenge. In this paper, a novel\napproach for building generic representations in occluded agro-food\nenvironments using multi-view perception and 3D multi-object tracking is\nintroduced. The method is based on a detection algorithm that generates partial\npoint clouds for each detected object, followed by a 3D multi-object tracking\nalgorithm that updates the representation over time. The accuracy of the\nrepresentation was evaluated in a real-world environment, where successful\nrepresentation and localisation of tomatoes in tomato plants were achieved,\ndespite high levels of occlusion, with the total count of tomatoes estimated\nwith a maximum error of 5.08% and the tomatoes tracked with an accuracy up to\n71.47%. Novel tracking metrics were introduced, demonstrating that valuable\ninsight into the errors in localising and representing the fruits can be\nprovided by their use. This approach presents a novel solution for building\nrepresentations in occluded agro-food environments, demonstrating potential to\nenable robots to perform tasks effectively in these challenging environments.\n","authors":["David Rapado Rincon","Eldert J. van Henten","Gert Kootstra"],"pdf_url":"https://arxiv.org/pdf/2211.02760v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09554v4","updated":"2023-11-28T11:44:10Z","published":"2023-02-19T12:18:45Z","title":"Mixed Hierarchy Network for Image Restoration","summary":"  Image restoration is a long-standing low-level vision problem, e.g.,\ndeblurring and deraining. In the process of image restoration, it is necessary\nto consider not only the spatial details and contextual information of\nrestoration to ensure the quality, but also the system complexity. Although\nmany methods have been able to guarantee the quality of image restoration, the\nsystem complexity of the state-of-the-art (SOTA) methods is increasing as well.\nMotivated by this, we present a mixed hierarchy network that can balance these\ncompeting goals. Our main proposal is a mixed hierarchy architecture, that\nprogressively recovers contextual information and spatial details from degraded\nimages while we design intra-blocks to reduce system complexity. Specifically,\nour model first learns the contextual information using encoder-decoder\narchitectures, and then combines them with high-resolution branches that\npreserve spatial detail. In order to reduce the system complexity of this\narchitecture for convenient analysis and comparison, we replace or remove the\nnonlinear activation function with multiplication and use a simple network\nstructure. In addition, we replace spatial convolution with global\nself-attention for the middle block of encoder-decoder. The resulting tightly\ninterlinked hierarchy architecture, named as MHNet, delivers strong performance\ngains on several image restoration tasks, including image deraining, and\ndeblurring.\n","authors":["Hu Gao","Depeng Dang"],"pdf_url":"https://arxiv.org/pdf/2302.09554v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16707v1","updated":"2023-11-28T11:32:23Z","published":"2023-11-28T11:32:23Z","title":"Full-resolution MLPs Empower Medical Dense Prediction","summary":"  Dense prediction is a fundamental requirement for many medical vision tasks\nsuch as medical image restoration, registration, and segmentation. The most\npopular vision model, Convolutional Neural Networks (CNNs), has reached\nbottlenecks due to the intrinsic locality of convolution operations. Recently,\ntransformers have been widely adopted for dense prediction for their capability\nto capture long-range visual dependence. However, due to the high computational\ncomplexity and large memory consumption of self-attention operations,\ntransformers are usually used at downsampled feature resolutions. Such usage\ncannot effectively leverage the tissue-level textural information available\nonly at the full image resolution. This textural information is crucial for\nmedical dense prediction as it can differentiate the subtle human anatomy in\nmedical images. In this study, we hypothesize that Multi-layer Perceptrons\n(MLPs) are superior alternatives to transformers in medical dense prediction\nwhere tissue-level details dominate the performance, as MLPs enable long-range\ndependence at the full image resolution. To validate our hypothesis, we develop\na full-resolution hierarchical MLP framework that uses MLPs beginning from the\nfull image resolution. We evaluate this framework with various MLP blocks on a\nwide range of medical dense prediction tasks including restoration,\nregistration, and segmentation. Extensive experiments on six public\nwell-benchmarked datasets show that, by simply using MLPs at full resolution,\nour framework outperforms its CNN and transformer counterparts and achieves\nstate-of-the-art performance on various medical dense prediction tasks.\n","authors":["Mingyuan Meng","Yuxin Xue","Dagan Feng","Lei Bi","Jinman Kim"],"pdf_url":"https://arxiv.org/pdf/2311.16707v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2311.16703v1","updated":"2023-11-28T11:27:48Z","published":"2023-11-28T11:27:48Z","title":"CADTalk: An Algorithm and Benchmark for Semantic Commenting of CAD\n  Programs","summary":"  CAD programs are a popular way to compactly encode shapes as a sequence of\noperations that are easy to parametrically modify. However, without sufficient\nsemantic comments and structure, such programs can be challenging to\nunderstand, let alone modify. We introduce the problem of semantic commenting\nCAD programs, wherein the goal is to segment the input program into code blocks\ncorresponding to semantically meaningful shape parts and assign a semantic\nlabel to each block. We solve the problem by combining program parsing with\nvisual-semantic analysis afforded by recent advances in foundational language\nand vision models. Specifically, by executing the input programs, we create\nshapes, which we use to generate conditional photorealistic images to make use\nof semantic annotators for such images. We then distill the information across\nthe images and link back to the original programs to semantically comment on\nthem. Additionally, we collected and annotated a benchmark dataset, CADTalk,\nconsisting of 5,280 machine-made programs and 45 human-made programs with\nground truth semantic comments to foster future research. We extensively\nevaluated our approach, compared to a GPT-based baseline approach, and an\nopen-set shape segmentation baseline, i.e., PartSLIP, and reported an 83.24%\naccuracy on the new CADTalk dataset. Project page:\nhttps://enigma-li.github.io/CADTalk/.\n","authors":["Haocheng Yuan","Jing Xu","Hao Pan","Adrien Bousseau","Niloy Mitra","Changjian Li"],"pdf_url":"https://arxiv.org/pdf/2311.16703v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14875v2","updated":"2023-11-28T11:27:27Z","published":"2023-11-24T23:54:33Z","title":"Uncertainty Aware AI for 2D MRI Segmentation","summary":"  Robust uncertainty estimations are necessary in safety-critical applications\nof Deep Learning. One such example is the semantic segmentation of medical\nimages, whilst deep-learning approaches have high performance in such tasks\nthey lack interpretability as they give no indication of their confidence when\nmaking classification decisions. Robust and interpretable segmentation is a\ncritical first stage in automatically screening for pathologies hence the\noptimal solution is one which can provide high accuracy but also capture the\nunderlying uncertainty. In this work, we present an uncertainty-aware\nsegmentation model, BA U-Net, for use on MRI data that incorporates Bayesian\nNeural Networks and Attention Mechanisms to provide accurate and interpretable\nsegmentations. We evaluated our model on the publicly available BraTS 2020\ndataset using F1 Score and Intersection Over Union (IoU) as evaluation metrics.\n","authors":["Lohith Konathala"],"pdf_url":"https://arxiv.org/pdf/2311.14875v2.pdf","comment":"14 Pages, 9 Figures Updated to Correct Typos, Revise Title"},{"id":"http://arxiv.org/abs/2310.02071v4","updated":"2023-11-28T11:23:14Z","published":"2023-10-03T14:13:36Z","title":"Towards End-to-End Embodied Decision Making via Multi-modal Large\n  Language Model: Explorations with GPT4-Vision and Beyond","summary":"  In this study, we explore the potential of Multimodal Large Language Models\n(MLLMs) in improving embodied decision-making processes for agents. While Large\nLanguage Models (LLMs) have been widely used due to their advanced reasoning\nskills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual\nunderstanding and reasoning capabilities. We investigate whether\nstate-of-the-art MLLMs can handle embodied decision-making in an end-to-end\nmanner and whether collaborations between LLMs and MLLMs can enhance\ndecision-making. To address these questions, we introduce a new benchmark\ncalled PCA-EVAL, which evaluates embodied decision-making from the perspectives\nof Perception, Cognition, and Action. Additionally, we propose HOLMES, a\nmulti-agent cooperation framework that allows LLMs to leverage MLLMs and APIs\nto gather multimodal information for informed decision-making. We compare\nend-to-end embodied decision-making and HOLMES on our benchmark and find that\nthe GPT4-Vision model demonstrates strong end-to-end embodied decision-making\nabilities, outperforming GPT4-HOLMES in terms of average decision accuracy\n(+3%). However, this performance is exclusive to the latest GPT4-Vision model,\nsurpassing the open-source state-of-the-art MLLM by 26%. Our results indicate\nthat powerful MLLMs like GPT4-Vision hold promise for decision-making in\nembodied agents, offering new avenues for MLLM research. Code and data are open\nat https://github.com/pkunlp-icler/PCA-EVAL/.\n","authors":["Liang Chen","Yichi Zhang","Shuhuai Ren","Haozhe Zhao","Zefan Cai","Yuchi Wang","Peiyi Wang","Tianyu Liu","Baobao Chang"],"pdf_url":"https://arxiv.org/pdf/2310.02071v4.pdf","comment":"FMDM@NeurIPS2023, Code and data:\n  https://github.com/pkunlp-icler/PCA-EVAL/"},{"id":"http://arxiv.org/abs/2311.16700v1","updated":"2023-11-28T11:22:08Z","published":"2023-11-28T11:22:08Z","title":"Rethinking Intermediate Layers design in Knowledge Distillation for\n  Kidney and Liver Tumor Segmentation","summary":"  Knowledge distillation(KD) has demonstrated remarkable success across various\ndomains, but its application to medical imaging tasks, such as kidney and liver\ntumor segmentation, has encountered challenges. Many existing KD methods are\nnot specifically tailored for these tasks. Moreover, prevalent KD methods often\nlack a careful consideration of what and from where to distill knowledge from\nthe teacher to the student. This oversight may lead to issues like the\naccumulation of training bias within shallower student layers, potentially\ncompromising the effectiveness of KD. To address these challenges, we propose\nHierarchical Layer-selective Feedback Distillation (HLFD). HLFD strategically\ndistills knowledge from a combination of middle layers to earlier layers and\ntransfers final layer knowledge to intermediate layers at both the feature and\npixel levels. This design allows the model to learn higher-quality\nrepresentations from earlier layers, resulting in a robust and compact student\nmodel. Extensive quantitative evaluations reveal that HLFD outperforms existing\nmethods by a significant margin. For example, in the kidney segmentation task,\nHLFD surpasses the student model (without KD) by over 10pp, significantly\nimproving its focus on tumor-specific features. From a qualitative standpoint,\nthe student model trained using HLFD excels at suppressing irrelevant\ninformation and can focus sharply on tumor-specific details, which opens a new\npathway for more efficient and accurate diagnostic tools.\n","authors":["Vandan Gorade","Sparsh Mittal","Debesh Jha","Ulas Bagci"],"pdf_url":"https://arxiv.org/pdf/2311.16700v1.pdf","comment":"Under-review at ISBI-2024"},{"id":"http://arxiv.org/abs/2311.16682v1","updated":"2023-11-28T10:53:55Z","published":"2023-11-28T10:53:55Z","title":"ContextSeg: Sketch Semantic Segmentation by Querying the Context with\n  Attention","summary":"  Sketch semantic segmentation is a well-explored and pivotal problem in\ncomputer vision involving the assignment of pre-defined part labels to\nindividual strokes. This paper presents ContextSeg - a simple yet highly\neffective approach to tackling this problem with two stages. In the first\nstage, to better encode the shape and positional information of strokes, we\npropose to predict an extra dense distance field in an autoencoder network to\nreinforce structural information learning. In the second stage, we treat an\nentire stroke as a single entity and label a group of strokes within the same\nsemantic part using an auto-regressive Transformer with the default attention\nmechanism. By group-based labeling, our method can fully leverage the context\ninformation when making decisions for the remaining groups of strokes. Our\nmethod achieves the best segmentation accuracy compared with state-of-the-art\napproaches on two representative datasets and has been extensively evaluated\ndemonstrating its superior performance. Additionally, we offer insights into\nsolving part imbalance in training data and the preliminary experiment on\ncross-category training, which can inspire future research in this field.\n","authors":["Jiawei Wang","Changjian Li"],"pdf_url":"https://arxiv.org/pdf/2311.16682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16681v1","updated":"2023-11-28T10:53:26Z","published":"2023-11-28T10:53:26Z","title":"Understanding the (Extra-)Ordinary: Validating Deep Model Decisions with\n  Prototypical Concept-based Explanations","summary":"  Ensuring both transparency and safety is critical when deploying Deep Neural\nNetworks (DNNs) in high-risk applications, such as medicine. The field of\nexplainable AI (XAI) has proposed various methods to comprehend the\ndecision-making processes of opaque DNNs. However, only few XAI methods are\nsuitable of ensuring safety in practice as they heavily rely on repeated\nlabor-intensive and possibly biased human assessment. In this work, we present\na novel post-hoc concept-based XAI framework that conveys besides instance-wise\n(local) also class-wise (global) decision-making strategies via prototypes.\nWhat sets our approach apart is the combination of local and global strategies,\nenabling a clearer understanding of the (dis-)similarities in model decisions\ncompared to the expected (prototypical) concept use, ultimately reducing the\ndependence on human long-term assessment. Quantifying the deviation from\nprototypical behavior not only allows to associate predictions with specific\nmodel sub-strategies but also to detect outlier behavior. As such, our approach\nconstitutes an intuitive and explainable tool for model validation. We\ndemonstrate the effectiveness of our approach in identifying\nout-of-distribution samples, spurious model behavior and data quality issues\nacross three datasets (ImageNet, CUB-200, and CIFAR-10) utilizing VGG, ResNet,\nand EfficientNet architectures. Code is available on\nhttps://github.com/maxdreyer/pcx.\n","authors":["Maximilian Dreyer","Reduan Achtibat","Wojciech Samek","Sebastian Lapuschkin"],"pdf_url":"https://arxiv.org/pdf/2311.16681v1.pdf","comment":"37 pages (9 pages manuscript, 2 pages references, 26 pages appendix)"},{"id":"http://arxiv.org/abs/2311.16673v1","updated":"2023-11-28T10:39:19Z","published":"2023-11-28T10:39:19Z","title":"Large Language Models Meet Computer Vision: A Brief Survey","summary":"  Recently, the intersection of Large Language Models (LLMs) and Computer\nVision (CV) has emerged as a pivotal area of research, driving significant\nadvancements in the field of Artificial Intelligence (AI). As transformers have\nbecome the backbone of many state-of-the-art models in both Natural Language\nProcessing (NLP) and CV, understanding their evolution and potential\nenhancements is crucial. This survey paper delves into the latest progressions\nin the domain of transformers and their subsequent successors, emphasizing\ntheir potential to revolutionize Vision Transformers (ViTs) and LLMs. This\nsurvey also presents a comparative analysis, juxtaposing the performance\nmetrics of several leading paid and open-source LLMs, shedding light on their\nstrengths and areas of improvement as well as a literature review on how LLMs\nare being used to tackle vision related tasks. Furthermore, the survey presents\na comprehensive collection of datasets employed to train LLMs, offering\ninsights into the diverse data available to achieve high performance in various\npre-training and downstream tasks of LLMs. The survey is concluded by\nhighlighting open directions in the field, suggesting potential venues for\nfuture research and development. This survey aims to underscores the profound\nintersection of LLMs on CV, leading to a new era of integrated and advanced AI\nmodels.\n","authors":["Raby Hamadi"],"pdf_url":"https://arxiv.org/pdf/2311.16673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16671v1","updated":"2023-11-28T10:36:36Z","published":"2023-11-28T10:36:36Z","title":"SplitNeRF: Split Sum Approximation Neural Field for Joint Geometry,\n  Illumination, and Material Estimation","summary":"  We present a novel approach for digitizing real-world objects by estimating\ntheir geometry, material properties, and environmental lighting from a set of\nposed images with fixed lighting. Our method incorporates into Neural Radiance\nField (NeRF) pipelines the split sum approximation used with image-based\nlighting for real-time physical-based rendering. We propose modeling the\nscene's lighting with a single scene-specific MLP representing pre-integrated\nimage-based lighting at arbitrary resolutions. We achieve accurate modeling of\npre-integrated lighting by exploiting a novel regularizer based on efficient\nMonte Carlo sampling. Additionally, we propose a new method of supervising\nself-occlusion predictions by exploiting a similar regularizer based on Monte\nCarlo sampling. Experimental results demonstrate the efficiency and\neffectiveness of our approach in estimating scene geometry, material\nproperties, and lighting. Our method is capable of attaining state-of-the-art\nrelighting quality after only ${\\sim}1$ hour of training in a single NVIDIA\nA100 GPU.\n","authors":["Jesus Zarzar","Bernard Ghanem"],"pdf_url":"https://arxiv.org/pdf/2311.16671v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16668v1","updated":"2023-11-28T10:29:39Z","published":"2023-11-28T10:29:39Z","title":"LiveNVS: Neural View Synthesis on Live RGB-D Streams","summary":"  Existing real-time RGB-D reconstruction approaches, like Kinect Fusion, lack\nreal-time photo-realistic visualization. This is due to noisy, oversmoothed or\nincomplete geometry and blurry textures which are fused from imperfect depth\nmaps and camera poses. Recent neural rendering methods can overcome many of\nsuch artifacts but are mostly optimized for offline usage, hindering the\nintegration into a live reconstruction pipeline.\n  In this paper, we present LiveNVS, a system that allows for neural novel view\nsynthesis on a live RGB-D input stream with very low latency and real-time\nrendering. Based on the RGB-D input stream, novel views are rendered by\nprojecting neural features into the target view via a densely fused depth map\nand aggregating the features in image-space to a target feature map. A\ngeneralizable neural network then translates the target feature map into a\nhigh-quality RGB image. LiveNVS achieves state-of-the-art neural rendering\nquality of unknown scenes during capturing, allowing users to virtually explore\nthe scene and assess reconstruction quality in real-time.\n","authors":["Laura Fink","Darius Rückert","Linus Franke","Joachim Keinert","Marc Stamminger"],"pdf_url":"https://arxiv.org/pdf/2311.16668v1.pdf","comment":"main paper: 8 pages, total number of pages: 15, 13 figures, to be\n  published in SIGGRAPH Asia 2023 Conference Papers"},{"id":"http://arxiv.org/abs/2311.16664v1","updated":"2023-11-28T10:25:55Z","published":"2023-11-28T10:25:55Z","title":"DGNR: Density-Guided Neural Point Rendering of Large Driving Scenes","summary":"  Despite the recent success of Neural Radiance Field (NeRF), it is still\nchallenging to render large-scale driving scenes with long trajectories,\nparticularly when the rendering quality and efficiency are in high demand.\nExisting methods for such scenes usually involve with spatial warping,\ngeometric supervision from zero-shot normal or depth estimation, or scene\ndivision strategies, where the synthesized views are often blurry or fail to\nmeet the requirement of efficient rendering. To address the above challenges,\nthis paper presents a novel framework that learns a density space from the\nscenes to guide the construction of a point-based renderer, dubbed as DGNR\n(Density-Guided Neural Rendering). In DGNR, geometric priors are no longer\nneeded, which can be intrinsically learned from the density space through\nvolumetric rendering. Specifically, we make use of a differentiable renderer to\nsynthesize images from the neural density features obtained from the learned\ndensity space. A density-based fusion module and geometric regularization are\nproposed to optimize the density space. By conducting experiments on a widely\nused autonomous driving dataset, we have validated the effectiveness of DGNR in\nsynthesizing photorealistic driving scenes and achieving real-time capable\nrendering.\n","authors":["Zhuopeng Li","Chenming Wu","Liangjun Zhang","Jianke Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.16664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16657v1","updated":"2023-11-28T10:18:16Z","published":"2023-11-28T10:18:16Z","title":"SCALAR-NeRF: SCAlable LARge-scale Neural Radiance Fields for Scene\n  Reconstruction","summary":"  In this work, we introduce SCALAR-NeRF, a novel framework tailored for\nscalable large-scale neural scene reconstruction. We structure the neural\nrepresentation as an encoder-decoder architecture, where the encoder processes\n3D point coordinates to produce encoded features, and the decoder generates\ngeometric values that include volume densities of signed distances and colors.\nOur approach first trains a coarse global model on the entire image dataset.\nSubsequently, we partition the images into smaller blocks using KMeans with\neach block being modeled by a dedicated local model. We enhance the overlapping\nregions across different blocks by scaling up the bounding boxes of each local\nblock. Notably, the decoder from the global model is shared across distinct\nblocks and therefore promoting alignment in the feature space of local\nencoders. We propose an effective and efficient methodology to fuse the outputs\nfrom these local models to attain the final reconstruction. Employing this\nrefined coarse-to-fine strategy, our method outperforms state-of-the-art NeRF\nmethods and demonstrates scalability for large-scale scene reconstruction. The\ncode will be available on our project page at\nhttps://aibluefisher.github.io/SCALAR-NeRF/\n","authors":["Yu Chen","Gim Hee Lee"],"pdf_url":"https://arxiv.org/pdf/2311.16657v1.pdf","comment":"Project Page: https://aibluefisher.github.io/SCALAR-NeRF"},{"id":"http://arxiv.org/abs/2311.14971v2","updated":"2023-11-28T10:08:35Z","published":"2023-11-25T09:08:30Z","title":"Segmentation of diagnostic tissue compartments on whole slide images\n  with renal thrombotic microangiopathies (TMAs)","summary":"  The thrombotic microangiopathies (TMAs) manifest in renal biopsy histology\nwith a broad spectrum of acute and chronic findings. Precise diagnostic\ncriteria for a renal biopsy diagnosis of TMA are missing. As a first step\ntowards a machine learning- and computer vision-based analysis of wholes slide\nimages from renal biopsies, we trained a segmentation model for the decisive\ndiagnostic kidney tissue compartments artery, arteriole, glomerulus on a set of\nwhole slide images from renal biopsies with TMAs and Mimickers (distinct\ndiseases with a similar nephropathological appearance as TMA like severe benign\nnephrosclerosis, various vasculitides, Bevacizumab-plug glomerulopathy,\narteriolar light chain deposition disease). Our segmentation model combines a\nU-Net-based tissue detection with a Shifted windows-transformer architecture to\nreach excellent segmentation results for even the most severely altered\nglomeruli, arterioles and arteries, even on unseen staining domains from a\ndifferent nephropathology lab. With accurate automatic segmentation of the\ndecisive renal biopsy compartments in human renal vasculopathies, we have laid\nthe foundation for large-scale compartment-specific machine learning and\ncomputer vision analysis of renal biopsy repositories with TMAs.\n","authors":["Huy Q. Vo","Pietro A. Cicalese","Surya Seshan","Syed A. Rizvi","Aneesh Vathul","Gloria Bueno","Anibal Pedraza Dorado","Niels Grabe","Katharina Stolle","Francesco Pesce","Joris J. T. H. Roelofs","Jesper Kers","Vitoantonio Bevilacqua","Nicola Altini","Bernd Schröppel","Dario Roccatello","Antonella Barreca","Savino Sciascia","Chandra Mohan","Hien V. Nguyen","Jan U. Becker"],"pdf_url":"https://arxiv.org/pdf/2311.14971v2.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.16652v1","updated":"2023-11-28T10:05:44Z","published":"2023-11-28T10:05:44Z","title":"Augmenting x-ray single particle imaging reconstruction with\n  self-supervised machine learning","summary":"  The development of X-ray Free Electron Lasers (XFELs) has opened numerous\nopportunities to probe atomic structure and ultrafast dynamics of various\nmaterials. Single Particle Imaging (SPI) with XFELs enables the investigation\nof biological particles in their natural physiological states with unparalleled\ntemporal resolution, while circumventing the need for cryogenic conditions or\ncrystallization. However, reconstructing real-space structures from\nreciprocal-space x-ray diffraction data is highly challenging due to the\nabsence of phase and orientation information, which is further complicated by\nweak scattering signals and considerable fluctuations in the number of photons\nper pulse. In this work, we present an end-to-end, self-supervised machine\nlearning approach to recover particle orientations and estimate reciprocal\nspace intensities from diffraction images only. Our method demonstrates great\nrobustness under demanding experimental conditions with significantly enhanced\nreconstruction capabilities compared with conventional algorithms, and\nsignifies a paradigm shift in SPI as currently practiced at XFELs.\n","authors":["Zhantao Chen","Cong Wang","Mingye Gao","Chun Hong Yoon","Jana B. Thayer","Joshua J. Turner"],"pdf_url":"https://arxiv.org/pdf/2311.16652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.12308v4","updated":"2023-11-28T09:58:15Z","published":"2023-04-24T17:57:15Z","title":"Segment Anything in 3D with NeRFs","summary":"  Recently, the Segment Anything Model (SAM) emerged as a powerful vision\nfoundation model which is capable to segment anything in 2D images. This paper\naims to generalize SAM to segment 3D objects. Rather than replicating the data\nacquisition and annotation procedure which is costly in 3D, we design an\nefficient solution, leveraging the Neural Radiance Field (NeRF) as a cheap and\noff-the-shelf prior that connects multi-view 2D images to the 3D space. We\nrefer to the proposed solution as SA3D, for Segment Anything in 3D. It is only\nrequired to provide a manual segmentation prompt (e.g., rough points) for the\ntarget object in a single view, which is used to generate its 2D mask in this\nview with SAM. Next, SA3D alternately performs mask inverse rendering and\ncross-view self-prompting across various views to iteratively complete the 3D\nmask of the target object constructed with voxel grids. The former projects the\n2D mask obtained by SAM in the current view onto 3D mask with guidance of the\ndensity distribution learned by the NeRF; The latter extracts reliable prompts\nautomatically as the input to SAM from the NeRF-rendered 2D mask in another\nview. We show in experiments that SA3D adapts to various scenes and achieves 3D\nsegmentation within minutes. Our research reveals a potential methodology to\nlift the ability of a 2D vision foundation model to 3D, as long as the 2D model\ncan steadily address promptable segmentation across multiple views. Our code is\navailable at https://github.com/Jumpat/SegmentAnythingin3D.\n","authors":["Jiazhong Cen","Zanwei Zhou","Jiemin Fang","Chen Yang","Wei Shen","Lingxi Xie","Dongsheng Jiang","Xiaopeng Zhang","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2304.12308v4.pdf","comment":"NeurIPS 2023. Project page: https://jumpat.github.io/SA3D/"},{"id":"http://arxiv.org/abs/2311.05332v2","updated":"2023-11-28T09:47:57Z","published":"2023-11-09T12:58:37Z","title":"On the Road with GPT-4V(ision): Early Explorations of Visual-Language\n  Model on Autonomous Driving","summary":"  The pursuit of autonomous driving technology hinges on the sophisticated\nintegration of perception, decision-making, and control systems. Traditional\napproaches, both data-driven and rule-based, have been hindered by their\ninability to grasp the nuance of complex driving environments and the\nintentions of other road users. This has been a significant bottleneck,\nparticularly in the development of common sense reasoning and nuanced scene\nunderstanding necessary for safe and reliable autonomous driving. The advent of\nVisual Language Models (VLM) represents a novel frontier in realizing fully\nautonomous vehicle driving. This report provides an exhaustive evaluation of\nthe latest state-of-the-art VLM, GPT-4V(ision), and its application in\nautonomous driving scenarios. We explore the model's abilities to understand\nand reason about driving scenes, make decisions, and ultimately act in the\ncapacity of a driver. Our comprehensive tests span from basic scene recognition\nto complex causal reasoning and real-time decision-making under varying\nconditions. Our findings reveal that GPT-4V demonstrates superior performance\nin scene understanding and causal reasoning compared to existing autonomous\nsystems. It showcases the potential to handle out-of-distribution scenarios,\nrecognize intentions, and make informed decisions in real driving contexts.\nHowever, challenges remain, particularly in direction discernment, traffic\nlight recognition, vision grounding, and spatial reasoning tasks. These\nlimitations underscore the need for further research and development. Project\nis now available on GitHub for interested parties to access and utilize:\n\\url{https://github.com/PJLab-ADG/GPT4V-AD-Exploration}\n","authors":["Licheng Wen","Xuemeng Yang","Daocheng Fu","Xiaofeng Wang","Pinlong Cai","Xin Li","Tao Ma","Yingxuan Li","Linran Xu","Dengke Shang","Zheng Zhu","Shaoyan Sun","Yeqi Bai","Xinyu Cai","Min Dou","Shuanglu Hu","Botian Shi","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2311.05332v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16637v1","updated":"2023-11-28T09:44:01Z","published":"2023-11-28T09:44:01Z","title":"Parallax-Tolerant Image Stitching with Epipolar Displacement Field","summary":"  Large parallax image stitching is a challenging task. Existing methods often\nstruggle to maintain both the local and global structures of the image while\nreducing alignment artifacts and warping distortions. In this paper, we propose\na novel approach that utilizes epipolar geometry to establish a warping\ntechnique based on the epipolar displacement field. Initially, the warping rule\nfor pixels in the epipolar geometry is established through the infinite\nhomography. Subsequently, Subsequently, the epipolar displacement field, which\nrepresents the sliding distance of the warped pixel along the epipolar line, is\nformulated by thin plate splines based on the principle of local elastic\ndeformation. The stitching result can be generated by inversely warping the\npixels according to the epipolar displacement field. This method incorporates\nthe epipolar constraints in the warping rule, which ensures high-quality\nalignment and maintains the projectivity of the panorama. Qualitative and\nquantitative comparative experiments demonstrate the competitiveness of the\nproposed method in stitching images large parallax.\n","authors":["Jian Yu","Yi Yu","Feipeng Da"],"pdf_url":"https://arxiv.org/pdf/2311.16637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16635v1","updated":"2023-11-28T09:38:45Z","published":"2023-11-28T09:38:45Z","title":"MotionZero:Exploiting Motion Priors for Zero-shot Text-to-Video\n  Generation","summary":"  Zero-shot Text-to-Video synthesis generates videos based on prompts without\nany videos. Without motion information from videos, motion priors implied in\nprompts are vital guidance. For example, the prompt \"airplane landing on the\nrunway\" indicates motion priors that the \"airplane\" moves downwards while the\n\"runway\" stays static. Whereas the motion priors are not fully exploited in\nprevious approaches, thus leading to two nontrivial issues: 1) the motion\nvariation pattern remains unaltered and prompt-agnostic for disregarding motion\npriors; 2) the motion control of different objects is inaccurate and entangled\nwithout considering the independent motion priors of different objects. To\ntackle the two issues, we propose a prompt-adaptive and disentangled motion\ncontrol strategy coined as MotionZero, which derives motion priors from prompts\nof different objects by Large-Language-Models and accordingly applies motion\ncontrol of different objects to corresponding regions in disentanglement.\nFurthermore, to facilitate videos with varying degrees of motion amplitude, we\npropose a Motion-Aware Attention scheme which adjusts attention among frames by\nmotion amplitude. Extensive experiments demonstrate that our strategy could\ncorrectly control motion of different objects and support versatile\napplications including zero-shot video edit.\n","authors":["Sitong Su","Litao Guo","Lianli Gao","Hengtao Shen","Jingkuan Song"],"pdf_url":"https://arxiv.org/pdf/2311.16635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.12476v4","updated":"2023-11-28T09:36:44Z","published":"2023-05-21T14:40:48Z","title":"Zero-shot Visual Relation Detection via Composite Visual Cues from Large\n  Language Models","summary":"  Pretrained vision-language models, such as CLIP, have demonstrated strong\ngeneralization capabilities, making them promising tools in the realm of\nzero-shot visual recognition. Visual relation detection (VRD) is a typical task\nthat identifies relationship (or interaction) types between object pairs within\nan image. However, naively utilizing CLIP with prevalent class-based prompts\nfor zero-shot VRD has several weaknesses, e.g., it struggles to distinguish\nbetween different fine-grained relation types and it neglects essential spatial\ninformation of two objects. To this end, we propose a novel method for\nzero-shot VRD: RECODE, which solves RElation detection via COmposite\nDEscription prompts. Specifically, RECODE first decomposes each predicate\ncategory into subject, object, and spatial components. Then, it leverages large\nlanguage models (LLMs) to generate description-based prompts (or visual cues)\nfor each component. Different visual cues enhance the discriminability of\nsimilar relation categories from different perspectives, which significantly\nboosts performance in VRD. To dynamically fuse different cues, we further\nintroduce a chain-of-thought method that prompts LLMs to generate reasonable\nweights for different visual cues. Extensive experiments on four VRD benchmarks\nhave demonstrated the effectiveness and interpretability of RECODE.\n","authors":["Lin Li","Jun Xiao","Guikun Chen","Jian Shao","Yueting Zhuang","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2305.12476v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.13620v2","updated":"2023-11-28T09:28:53Z","published":"2023-09-24T12:29:13Z","title":"PRIS: Practical robust invertible network for image steganography","summary":"  Image steganography is a technique of hiding secret information inside\nanother image, so that the secret is not visible to human eyes and can be\nrecovered when needed. Most of the existing image steganography methods have\nlow hiding robustness when the container images affected by distortion. Such as\nGaussian noise and lossy compression. This paper proposed PRIS to improve the\nrobustness of image steganography, it based on invertible neural networks, and\nput two enhance modules before and after the extraction process with a 3-step\ntraining strategy. Moreover, rounding error is considered which is always\nignored by existing methods, but actually it is unavoidable in practical. A\ngradient approximation function (GAF) is also proposed to overcome the\nundifferentiable issue of rounding distortion. Experimental results show that\nour PRIS outperforms the state-of-the-art robust image steganography method in\nboth robustness and practicability. Codes are available at\nhttps://github.com/yanghangAI/PRIS, demonstration of our model in practical at\nhttp://yanghang.site/hide/.\n","authors":["Hang Yang","Yitian Xu","Xuhua Liu","Xiaodong Ma"],"pdf_url":"https://arxiv.org/pdf/2309.13620v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16623v1","updated":"2023-11-28T09:24:42Z","published":"2023-11-28T09:24:42Z","title":"Visual Semantic Navigation with Real Robots","summary":"  Visual Semantic Navigation (VSN) is the ability of a robot to learn visual\nsemantic information for navigating in unseen environments. These VSN models\nare typically tested in those virtual environments where they are trained,\nmainly using reinforcement learning based approaches. Therefore, we do not yet\nhave an in-depth analysis of how these models would behave in the real world.\nIn this work, we propose a new solution to integrate VSN models into real\nrobots, so that we have true embodied agents. We also release a novel ROS-based\nframework for VSN, ROS4VSN, so that any VSN-model can be easily deployed in any\nROS-compatible robot and tested in a real setting. Our experiments with two\ndifferent robots, where we have embedded two state-of-the-art VSN agents,\nconfirm that there is a noticeable performance difference of these VSN\nsolutions when tested in real-world and simulation environments. We hope that\nthis research will endeavor to provide a foundation for addressing this\nconsequential issue, with the ultimate aim of advancing the performance and\nefficiency of embodied agents within authentic real-world scenarios. Code to\nreproduce all our experiments can be found at\nhttps://github.com/gramuah/ros4vsn.\n","authors":["Carlos Gutiérrez-Álvarez","Pablo Ríos-Navarro","Rafael Flor-Rodríguez","Francisco Javier Acevedo-Rodríguez","Roberto J. López-Sastre"],"pdf_url":"https://arxiv.org/pdf/2311.16623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03782v2","updated":"2023-11-28T09:23:30Z","published":"2023-11-07T08:05:09Z","title":"CapST: An Enhanced and Lightweight Model Attribution Approach for\n  Synthetic Videos","summary":"  Deepfake videos, generated through AI faceswapping techniques, have garnered\nconsiderable attention due to their potential for powerful impersonation\nattacks. While existing research primarily focuses on binary classification to\ndiscern between real and fake videos, however determining the specific\ngeneration model for a fake video is crucial for forensic investigation.\nAddressing this gap, this paper investigates the model attribution problem of\nDeepfake videos from a recently proposed dataset, Deepfakes from Different\nModels (DFDM), derived from various Autoencoder models. The dataset comprises\n6,450 Deepfake videos generated by five distinct models with variations in\nencoder, decoder, intermediate layer, input resolution, and compression ratio.\nThis study formulates Deepfakes model attribution as a multiclass\nclassification task, proposing a segment of VGG19 as a feature extraction\nbackbone, known for its effectiveness in imagerelated tasks, while integrated a\nCapsule Network with a Spatio-Temporal attention mechanism. The Capsule module\ncaptures intricate hierarchies among features for robust identification of\ndeepfake attributes. Additionally, the video-level fusion technique leverages\ntemporal attention mechanisms to handle concatenated feature vectors,\ncapitalizing on inherent temporal dependencies in deepfake videos. By\naggregating insights across frames, our model gains a comprehensive\nunderstanding of video content, resulting in more precise predictions.\nExperimental results on the deepfake benchmark dataset (DFDM) demonstrate the\nefficacy of our proposed method, achieving up to a 4% improvement in accurately\ncategorizing deepfake videos compared to baseline models while demanding fewer\ncomputational resources.\n","authors":["Wasim Ahmad","Yan-Tsung Peng","Yuan-Hao Chang","Gaddisa Olani Ganfure","Sarwar Khan","Sahibzada Adil Shahzad"],"pdf_url":"https://arxiv.org/pdf/2311.03782v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16618v1","updated":"2023-11-28T09:18:42Z","published":"2023-11-28T09:18:42Z","title":"Cross-level Attention with Overlapped Windows for Camouflaged Object\n  Detection","summary":"  Camouflaged objects adaptively fit their color and texture with the\nenvironment, which makes them indistinguishable from the surroundings. Current\nmethods revealed that high-level semantic features can highlight the\ndifferences between camouflaged objects and the backgrounds. Consequently, they\nintegrate high-level semantic features with low-level detailed features for\naccurate camouflaged object detection (COD). Unlike previous designs for\nmulti-level feature fusion, we state that enhancing low-level features is more\nimpending for COD. In this paper, we propose an overlapped window cross-level\nattention (OWinCA) to achieve the low-level feature enhancement guided by the\nhighest-level features. By sliding an aligned window pair on both the highest-\nand low-level feature maps, the high-level semantics are explicitly integrated\ninto the low-level details via cross-level attention. Additionally, it employs\nan overlapped window partition strategy to alleviate the incoherence among\nwindows, which prevents the loss of global information. These adoptions enable\nthe proposed OWinCA to enhance low-level features by promoting the separability\nof camouflaged objects. The associated proposed OWinCANet fuses these enhanced\nmulti-level features by simple convolution operation to achieve the final COD.\nExperiments conducted on three large-scale COD datasets demonstrate that our\nOWinCANet significantly surpasses the current state-of-the-art COD methods.\n","authors":["Jiepan Li","Fangxiao Lu","Nan Xue","Zhuohong Li","Hongyan Zhang","Wei He"],"pdf_url":"https://arxiv.org/pdf/2311.16618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.03178v2","updated":"2023-11-28T09:07:46Z","published":"2023-01-09T06:02:36Z","title":"Deep Planar Parallax for Monocular Depth Estimation","summary":"  Recent research has highlighted the utility of Planar Parallax Geometry in\nmonocular depth estimation. However, its potential has yet to be fully realized\nbecause networks rely heavily on appearance for depth prediction. Our in-depth\nanalysis reveals that utilizing flow-pretrain can optimize the network's usage\nof consecutive frame modeling, leading to substantial performance enhancement.\nAdditionally, we propose Planar Position Embedding (PPE) to handle dynamic\nobjects that defy static scene assumptions and to tackle slope variations that\nare challenging to differentiate. Comprehensive experiments on autonomous\ndriving datasets, namely KITTI and the Waymo Open Dataset (WOD), prove that our\nPlanar Parallax Network (PPNet) significantly surpasses existing learning-based\nmethods in performance.\n","authors":["Haoqian Liang","Zhichao Li","Ya Yang","Naiyan Wang"],"pdf_url":"https://arxiv.org/pdf/2301.03178v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16613v1","updated":"2023-11-28T09:02:38Z","published":"2023-11-28T09:02:38Z","title":"Filter-Pruning of Lightweight Face Detectors Using a Geometric Median\n  Criterion","summary":"  Face detectors are becoming a crucial component of many applications,\nincluding surveillance, that often have to run on edge devices with limited\nprocessing power and memory. Therefore, there's a pressing demand for compact\nface detection models that can function efficiently across resource-constrained\ndevices. Over recent years, network pruning techniques have attracted a lot of\nattention from researchers. These methods haven't been well examined in the\ncontext of face detectors, despite their expanding popularity. In this paper,\nwe implement filter pruning on two already small and compact face detectors,\nnamed EXTD (Extremely Tiny Face Detector) and EResFD (Efficient ResNet Face\nDetector). The main pruning algorithm that we utilize is Filter Pruning via\nGeometric Median (FPGM), combined with the Soft Filter Pruning (SFP) iterative\nprocedure. We also apply L1 Norm pruning, as a baseline to compare with the\nproposed approach. The experimental evaluation on the WIDER FACE dataset\nindicates that the proposed approach has the potential to further reduce the\nmodel size of already lightweight face detectors, with limited accuracy loss,\nor even with small accuracy gain for low pruning rates.\n","authors":["Konstantinos Gkrispanis","Nikolaos Gkalelis","Vasileios Mezaris"],"pdf_url":"https://arxiv.org/pdf/2311.16613v1.pdf","comment":"Accepted for publication in the IEEE/CVF WACV 2024 Workshops\n  proceedings, Hawaii, USA, Jan. 2024"},{"id":"http://arxiv.org/abs/2308.00929v2","updated":"2023-11-28T08:57:12Z","published":"2023-08-02T04:10:14Z","title":"Towards Discriminative Representation with Meta-learning for\n  Colonoscopic Polyp Re-Identification","summary":"  Colonoscopic Polyp Re-Identification aims to match the same polyp from a\nlarge gallery with images from different views taken using different cameras\nand plays an important role in the prevention and treatment of colorectal\ncancer in computer-aided diagnosis. However, traditional methods for object\nReID directly adopting CNN models trained on the ImageNet dataset usually\nproduce unsatisfactory retrieval performance on colonoscopic datasets due to\nthe large domain gap. Additionally, these methods neglect to explore the\npotential of self-discrepancy among intra-class relations in the colonoscopic\npolyp dataset, which remains an open research problem in the medical community.\nTo solve this dilemma, we propose a simple but effective training method named\nColo-ReID, which can help our model learn more general and discriminative\nknowledge based on the meta-learning strategy in scenarios with fewer samples.\nBased on this, a dynamic Meta-Learning Regulation mechanism called MLR is\nintroduced to further boost the performance of polyp re-identification. To the\nbest of our knowledge, this is the first attempt to leverage the meta-learning\nparadigm instead of traditional machine learning algorithm to effectively train\ndeep models in the task of colonoscopic polyp re-identification. Empirical\nresults show that our method significantly outperforms current state-of-the-art\nmethods by a clear margin.\n","authors":["Suncheng Xiang","Qingzhong Chen","Shilun Cai","Chengfeng Zhou","Crystal Cai","Sijia Du","Zhengjie Zhang","Yunshi Zhong","Dahong Qian"],"pdf_url":"https://arxiv.org/pdf/2308.00929v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12793v2","updated":"2023-11-28T08:52:50Z","published":"2023-11-21T18:58:11Z","title":"ShareGPT4V: Improving Large Multi-Modal Models with Better Captions","summary":"  In the realm of large multi-modal models (LMMs), efficient modality alignment\nis crucial yet often constrained by the scarcity of high-quality image-text\ndata. To address this bottleneck, we introduce the ShareGPT4V dataset, a\npioneering large-scale resource featuring 1.2 million highly descriptive\ncaptions, which surpasses existing datasets in diversity and information\ncontent, covering world knowledge, object properties, spatial relationships,\nand aesthetic evaluations. Specifically, ShareGPT4V originates from a curated\n100K high-quality captions collected from advanced GPT4-Vision and has been\nexpanded to 1.2M with a superb caption model trained on this subset. ShareGPT4V\nfirst demonstrates its effectiveness for the Supervised Fine-Tuning (SFT)\nphase, by substituting an equivalent quantity of detailed captions in existing\nSFT datasets with a subset of our high-quality captions, significantly\nenhancing the LMMs like LLaVA-7B, LLaVA-1.5-13B, and Qwen-VL-Chat-7B on the MME\nand MMBench benchmarks, with respective gains of 222.8/22.0/22.3 and\n2.7/1.3/1.5. We further incorporate ShareGPT4V data into both the pre-training\nand SFT phases, obtaining ShareGPT4V-7B, a superior LMM based on a simple\narchitecture that has remarkable performance across a majority of the\nmulti-modal benchmarks. This project is available at\nhttps://ShareGPT4V.github.io to serve as a pivotal resource for advancing the\nLMMs community.\n","authors":["Lin Chen","Jinsong Li","Xiaoyi Dong","Pan Zhang","Conghui He","Jiaqi Wang","Feng Zhao","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2311.12793v2.pdf","comment":"Project: https://ShareGPT4V.github.io"},{"id":"http://arxiv.org/abs/2310.08165v2","updated":"2023-11-28T08:45:13Z","published":"2023-10-12T09:37:56Z","title":"COVID-19 detection using ViT transformer-based approach from Computed\n  Tomography Images","summary":"  In here, we introduce a novel approach to enhance the accuracy and efficiency\nof COVID-19 diagnosis using CT images. Leveraging state-of-the-art Transformer\nmodels in computer vision, we employed the base ViT Transformer configured for\n224x224-sized input images, modifying the output to suit the binary\nclassification task. Notably, input images were resized from the standard CT\nscan size of 512x512 to match the model's expectations. Our method implements a\nsystematic patient-level prediction strategy, classifying individual CT slices\nas COVID-19 or non-COVID. To determine the overall diagnosis for each patient,\na majority voting approach as well as other thresholding approaches were\nemployed. This method involves evaluating all CT slices for a given patient and\nassigning the patient the diagnosis that relates to the thresholding for the CT\nscan. This meticulous patient-level prediction process contributes to the\nrobustness of our solution as it starts from 2D-slices to 3D-patient level.\nThroughout the evaluation process, our approach resulted in 0.7 macro F1 score\non the COV19-CT -DB validation set. To ensure the reliability and effectiveness\nof our model, we rigorously validate it on the extensive COV-19 CT dataset,\nwhich is meticulously annotated for the task. This dataset, with its\ncomprehensive annotations, reinforces the overall robustness of our solution.\n","authors":["Kenan Morani"],"pdf_url":"https://arxiv.org/pdf/2310.08165v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.20604v2","updated":"2023-11-28T08:29:18Z","published":"2023-10-31T16:39:56Z","title":"Enhanced Synthetic MRI Generation from CT Scans Using CycleGAN with\n  Feature Extraction","summary":"  In the field of radiotherapy, accurate imaging and image registration are of\nutmost importance for precise treatment planning. Magnetic Resonance Imaging\n(MRI) offers detailed imaging without being invasive and excels in soft-tissue\ncontrast, making it a preferred modality for radiotherapy planning. However,\nthe high cost of MRI, longer acquisition time, and certain health\nconsiderations for patients pose challenges. Conversely, Computed Tomography\n(CT) scans offer a quicker and less expensive imaging solution. To bridge these\nmodalities and address multimodal alignment challenges, we introduce an\napproach for enhanced monomodal registration using synthetic MRI images.\nUtilizing unpaired data, this paper proposes a novel method to produce these\nsynthetic MRI images from CT scans, leveraging CycleGANs and feature\nextractors. By building upon the foundational work on Cycle-Consistent\nAdversarial Networks and incorporating advancements from related literature,\nour methodology shows promising results, outperforming several state-of-the-art\nmethods. The efficacy of our approach is validated by multiple comparison\nmetrics.\n","authors":["Saba Nikbakhsh","Lachin Naghashyar","Morteza Valizadeh","Mehdi Chehel Amirani"],"pdf_url":"https://arxiv.org/pdf/2310.20604v2.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.16593v1","updated":"2023-11-28T08:18:30Z","published":"2023-11-28T08:18:30Z","title":"Empowering COVID-19 Detection: Optimizing Performance Through Fine-Tuned\n  EfficientNet Deep Learning Architecture","summary":"  The worldwide COVID-19 pandemic has profoundly influenced the health and\neveryday experiences of individuals across the planet. It is a highly\ncontagious respiratory disease requiring early and accurate detection to curb\nits rapid transmission. Initial testing methods primarily revolved around\nidentifying the genetic composition of the coronavirus, exhibiting a relatively\nlow detection rate and requiring a time-intensive procedure. To address this\nchallenge, experts have suggested using radiological imagery, particularly\nchest X-rays, as a valuable approach within the diagnostic protocol. This study\ninvestigates the potential of leveraging radiographic imaging (X-rays) with\ndeep learning algorithms to swiftly and precisely identify COVID-19 patients.\nThe proposed approach elevates the detection accuracy by fine-tuning with\nappropriate layers on various established transfer learning models. The\nexperimentation was conducted on a COVID-19 X-ray dataset containing 2000\nimages. The accuracy rates achieved were impressive of 100% for EfficientNetB4\nmodel. The fine-tuned EfficientNetB4 achieved an excellent accuracy score,\nshowcasing its potential as a robust COVID-19 detection model. Furthermore,\nEfficientNetB4 excelled in identifying Lung disease using Chest X-ray dataset\ncontaining 4,350 Images, achieving remarkable performance with an accuracy of\n99.17%, precision of 99.13%, recall of 99.16%, and f1-score of 99.14%. These\nresults highlight the promise of fine-tuned transfer learning for efficient\nlung detection through medical imaging, especially with X-ray images. This\nresearch offers radiologists an effective means of aiding rapid and precise\nCOVID-19 diagnosis and contributes valuable assistance for healthcare\nprofessionals in accurately identifying affected patients.\n","authors":["Md. Alamin Talukder","Md. Abu Layek","Mohsin Kazi","Md Ashraf Uddin","Sunil Aryal"],"pdf_url":"https://arxiv.org/pdf/2311.16593v1.pdf","comment":"Computers in Biology and Medicine [Q1, IF: 7.7, CS: 9.2]"},{"id":"http://arxiv.org/abs/2311.16589v1","updated":"2023-11-28T08:15:27Z","published":"2023-11-28T08:15:27Z","title":"Improving Lane Detection Generalization: A Novel Framework using HD Maps\n  for Boosting Diversity","summary":"  Lane detection is a vital task for vehicles to navigate and localize their\nposition on the road. To ensure reliable results, lane detection algorithms\nmust have robust generalization performance in various road environments.\nHowever, despite the significant performance improvement of deep learning-based\nlane detection algorithms, their generalization performance in response to\nchanges in road environments still falls short of expectations. In this paper,\nwe present a novel framework for single-source domain generalization (SSDG) in\nlane detection. By decomposing data into lane structures and surroundings, we\nenhance diversity using High-Definition (HD) maps and generative models. Rather\nthan expanding data volume, we strategically select a core subset of data,\nmaximizing diversity and optimizing performance. Our extensive experiments\ndemonstrate that our framework enhances the generalization performance of lane\ndetection, comparable to the domain adaptation-based method.\n","authors":["Daeun Lee","Minhyeok Heo","Jiwon Kim"],"pdf_url":"https://arxiv.org/pdf/2311.16589v1.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.16581v1","updated":"2023-11-28T07:55:25Z","published":"2023-11-28T07:55:25Z","title":"GeoScaler: Geometry and Rendering-Aware Downsampling of 3D Mesh Textures","summary":"  High-resolution texture maps are necessary for representing real-world\nobjects accurately with 3D meshes. The large sizes of textures can bottleneck\nthe real-time rendering of high-quality virtual 3D scenes on devices having low\ncomputational budgets and limited memory. Downsampling the texture maps\ndirectly addresses the issue, albeit at the cost of visual fidelity.\nTraditionally, downsampling of texture maps is performed using methods like\nbicubic interpolation and the Lanczos algorithm. These methods ignore the\ngeometric layout of the mesh and its UV parametrization and also do not account\nfor the rendering process used to obtain the final visualization that the users\nwill experience. Towards filling these gaps, we introduce GeoScaler, which is a\nmethod of downsampling texture maps of 3D meshes while incorporating geometric\ncues, and by maximizing the visual fidelity of the rendered views of the\ntextured meshes. We show that the textures generated by GeoScaler deliver\nsignificantly better quality rendered images compared to those generated by\ntraditional downsampling methods\n","authors":["Sai Karthikey Pentapati","Anshul Rai","Arkady Ten","Chaitanya Atluru","Alan Bovik"],"pdf_url":"https://arxiv.org/pdf/2311.16581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16580v1","updated":"2023-11-28T07:54:27Z","published":"2023-11-28T07:54:27Z","title":"Clean Label Disentangling for Medical Image Segmentation with Noisy\n  Labels","summary":"  Current methods focusing on medical image segmentation suffer from incorrect\nannotations, which is known as the noisy label issue. Most medical image\nsegmentation with noisy labels methods utilize either noise transition matrix,\nnoise-robust loss functions or pseudo-labeling methods, while none of the\ncurrent research focuses on clean label disentanglement. We argue that the main\nreason is that the severe class-imbalanced issue will lead to the inaccuracy of\nthe selected ``clean'' labels, thus influencing the robustness of the model\nagainst the noises. In this work, we come up with a simple but efficient\nclass-balanced sampling strategy to tackle the class-imbalanced problem, which\nenables our newly proposed clean label disentangling framework to successfully\nselect clean labels from the given label sets and encourages the model to learn\nfrom the correct annotations. However, such a method will filter out too many\nannotations which may also contain useful information. Therefore, we further\nextend our clean label disentangling framework to a new noisy feature-aided\nclean label disentangling framework, which takes the full annotations into\nutilization to learn more semantics. Extensive experiments have validated the\neffectiveness of our methods, where our methods achieve new state-of-the-art\nperformance. Our code is available at https://github.com/xiaoyao3302/2BDenoise.\n","authors":["Zicheng Wang","Zhen Zhao","Erjian Guo","Luping Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.16580v1.pdf","comment":"13 pages, 6 figures, 11 tables"},{"id":"http://arxiv.org/abs/2311.16577v1","updated":"2023-11-28T07:40:16Z","published":"2023-11-28T07:40:16Z","title":"Efficient Key-Based Adversarial Defense for ImageNet by Using\n  Pre-trained Model","summary":"  In this paper, we propose key-based defense model proliferation by leveraging\npre-trained models and utilizing recent efficient fine-tuning techniques on\nImageNet-1k classification. First, we stress that deploying key-based models on\nedge devices is feasible with the latest model deployment advancements, such as\nApple CoreML, although the mainstream enterprise edge artificial intelligence\n(Edge AI) has been focused on the Cloud. Then, we point out that the previous\nkey-based defense on on-device image classification is impractical for two\nreasons: (1) training many classifiers from scratch is not feasible, and (2)\nkey-based defenses still need to be thoroughly tested on large datasets like\nImageNet. To this end, we propose to leverage pre-trained models and utilize\nefficient fine-tuning techniques to proliferate key-based models even on\nlimited computing resources. Experiments were carried out on the ImageNet-1k\ndataset using adaptive and non-adaptive attacks. The results show that our\nproposed fine-tuned key-based models achieve a superior classification accuracy\n(more than 10% increase) compared to the previous key-based models on\nclassifying clean and adversarial examples.\n","authors":["AprilPyone MaungMaung","Isao Echizen","Hitoshi Kiya"],"pdf_url":"https://arxiv.org/pdf/2311.16577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16567v1","updated":"2023-11-28T07:14:41Z","published":"2023-11-28T07:14:41Z","title":"MobileDiffusion: Subsecond Text-to-Image Generation on Mobile Devices","summary":"  The deployment of large-scale text-to-image diffusion models on mobile\ndevices is impeded by their substantial model size and slow inference speed. In\nthis paper, we propose \\textbf{MobileDiffusion}, a highly efficient\ntext-to-image diffusion model obtained through extensive optimizations in both\narchitecture and sampling techniques. We conduct a comprehensive examination of\nmodel architecture design to reduce redundancy, enhance computational\nefficiency, and minimize model's parameter count, while preserving image\ngeneration quality. Additionally, we employ distillation and diffusion-GAN\nfinetuning techniques on MobileDiffusion to achieve 8-step and 1-step inference\nrespectively. Empirical studies, conducted both quantitatively and\nqualitatively, demonstrate the effectiveness of our proposed techniques.\nMobileDiffusion achieves a remarkable \\textbf{sub-second} inference speed for\ngenerating a $512\\times512$ image on mobile devices, establishing a new state\nof the art.\n","authors":["Yang Zhao","Yanwu Xu","Zhisheng Xiao","Tingbo Hou"],"pdf_url":"https://arxiv.org/pdf/2311.16567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16495v1","updated":"2023-11-28T07:13:47Z","published":"2023-11-28T07:13:47Z","title":"Egocentric Whole-Body Motion Capture with FisheyeViT and Diffusion-Based\n  Motion Refinement","summary":"  In this work, we explore egocentric whole-body motion capture using a single\nfisheye camera, which simultaneously estimates human body and hand motion. This\ntask presents significant challenges due to three factors: the lack of\nhigh-quality datasets, fisheye camera distortion, and human body\nself-occlusion. To address these challenges, we propose a novel approach that\nleverages FisheyeViT to extract fisheye image features, which are subsequently\nconverted into pixel-aligned 3D heatmap representations for 3D human body pose\nprediction. For hand tracking, we incorporate dedicated hand detection and hand\npose estimation networks for regressing 3D hand poses. Finally, we develop a\ndiffusion-based whole-body motion prior model to refine the estimated\nwhole-body motion while accounting for joint uncertainties. To train these\nnetworks, we collect a large synthetic dataset, EgoWholeBody, comprising\n840,000 high-quality egocentric images captured across a diverse range of\nwhole-body motion sequences. Quantitative and qualitative evaluations\ndemonstrate the effectiveness of our method in producing high-quality\nwhole-body motion estimates from a single egocentric camera.\n","authors":["Jian Wang","Zhe Cao","Diogo Luvizon","Lingjie Liu","Kripasindhu Sarkar","Danhang Tang","Thabo Beeler","Christian Theobalt"],"pdf_url":"https://arxiv.org/pdf/2311.16495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16565v1","updated":"2023-11-28T07:13:20Z","published":"2023-11-28T07:13:20Z","title":"DiffusionTalker: Personalization and Acceleration for Speech-Driven 3D\n  Face Diffuser","summary":"  Speech-driven 3D facial animation has been an attractive task in both\nacademia and industry. Traditional methods mostly focus on learning a\ndeterministic mapping from speech to animation. Recent approaches start to\nconsider the non-deterministic fact of speech-driven 3D face animation and\nemploy the diffusion model for the task. However, personalizing facial\nanimation and accelerating animation generation are still two major limitations\nof existing diffusion-based methods. To address the above limitations, we\npropose DiffusionTalker, a diffusion-based method that utilizes contrastive\nlearning to personalize 3D facial animation and knowledge distillation to\naccelerate 3D animation generation. Specifically, to enable personalization, we\nintroduce a learnable talking identity to aggregate knowledge in audio\nsequences. The proposed identity embeddings extract customized facial cues\nacross different people in a contrastive learning manner. During inference,\nusers can obtain personalized facial animation based on input audio, reflecting\na specific talking style. With a trained diffusion model with hundreds of\nsteps, we distill it into a lightweight model with 8 steps for acceleration.\nExtensive experiments are conducted to demonstrate that our method outperforms\nstate-of-the-art methods. The code will be released.\n","authors":["Peng Chen","Xiaobao Wei","Ming Lu","Yitong Zhu","Naiming Yao","Xingyu Xiao","Hui Chen"],"pdf_url":"https://arxiv.org/pdf/2311.16565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16555v1","updated":"2023-11-28T06:51:28Z","published":"2023-11-28T06:51:28Z","title":"Enhancing Scene Text Detectors with Realistic Text Image Synthesis Using\n  Diffusion Models","summary":"  Scene text detection techniques have garnered significant attention due to\ntheir wide-ranging applications. However, existing methods have a high demand\nfor training data, and obtaining accurate human annotations is labor-intensive\nand time-consuming. As a solution, researchers have widely adopted synthetic\ntext images as a complementary resource to real text images during\npre-training. Yet there is still room for synthetic datasets to enhance the\nperformance of scene text detectors. We contend that one main limitation of\nexisting generation methods is the insufficient integration of foreground text\nwith the background. To alleviate this problem, we present the Diffusion Model\nbased Text Generator (DiffText), a pipeline that utilizes the diffusion model\nto seamlessly blend foreground text regions with the background's intrinsic\nfeatures. Additionally, we propose two strategies to generate visually coherent\ntext with fewer spelling errors. With fewer text instances, our produced text\nimages consistently surpass other synthetic data in aiding text detectors.\nExtensive experiments on detecting horizontal, rotated, curved, and line-level\ntexts demonstrate the effectiveness of DiffText in producing realistic text\nimages.\n","authors":["Ling Fu","Zijie Wu","Yingying Zhu","Yuliang Liu","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2311.16555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16552v1","updated":"2023-11-28T06:42:44Z","published":"2023-11-28T06:42:44Z","title":"HandyPriors: Physically Consistent Perception of Hand-Object\n  Interactions with Differentiable Priors","summary":"  Various heuristic objectives for modeling hand-object interaction have been\nproposed in past work. However, due to the lack of a cohesive framework, these\nobjectives often possess a narrow scope of applicability and are limited by\ntheir efficiency or accuracy. In this paper, we propose HandyPriors, a unified\nand general pipeline for pose estimation in human-object interaction scenes by\nleveraging recent advances in differentiable physics and rendering. Our\napproach employs rendering priors to align with input images and segmentation\nmasks along with physics priors to mitigate penetration and relative-sliding\nacross frames. Furthermore, we present two alternatives for hand and object\npose estimation. The optimization-based pose estimation achieves higher\naccuracy, while the filtering-based tracking, which utilizes the differentiable\npriors as dynamics and observation models, executes faster. We demonstrate that\nHandyPriors attains comparable or superior results in the pose estimation task,\nand that the differentiable physics module can predict contact information for\npose refinement. We also show that our approach generalizes to perception\ntasks, including robotic hand manipulation and human-object pose estimation in\nthe wild.\n","authors":["Shutong Zhang","Yi-Ling Qiao","Guanglei Zhu","Eric Heiden","Dylan Turpin","Jingzhou Liu","Ming Lin","Miles Macklin","Animesh Garg"],"pdf_url":"https://arxiv.org/pdf/2311.16552v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16544v1","updated":"2023-11-28T06:25:26Z","published":"2023-11-28T06:25:26Z","title":"Multi-Irreducible Spectral Synchronization for Robust Rotation Averaging","summary":"  Rotation averaging (RA) is a fundamental problem in robotics and computer\nvision. In RA, the goal is to estimate a set of $N$ unknown orientations\n$R_{1}, ..., R_{N} \\in SO(3)$, given noisy measurements $R_{ij} \\sim R^{-1}_{i}\nR_{j}$ of a subset of their pairwise relative rotations. This problem is both\nnonconvex and NP-hard, and thus difficult to solve in the general case. We\napply harmonic analysis on compact groups to derive a (convex) spectral\nrelaxation constructed from truncated Fourier decompositions of the individual\nsummands appearing in the RA objective; we then recover an estimate of the RA\nsolution by computing a few extremal eigenpairs of this relaxation, and\n(approximately) solving a consensus problem. Our approach affords several\nnotable advantages versus prior RA methods: it can be used in conjunction with\n\\emph{any} smooth loss function (including, but not limited to, robust\nM-estimators), does not require any initialization, and is implemented using\nonly simple (and highly scalable) linear-algebraic computations and\nparallelizable optimizations over band-limited functions of individual\nrotational states. Moreover, under the (physically well-motivated) assumption\nof multiplicative Langevin measurement noise, we derive explicit performance\nguarantees for our spectral estimator (in the form of probabilistic tail bounds\non the estimation error) that are parameterized in terms of graph-theoretic\nquantities of the underlying measurement network. By concretely linking\nestimator performance with properties of the underlying measurement graph, our\nresults also indicate how to devise measurement networks that are\n\\emph{guaranteed} to achieve accurate estimation, enabling such downstream\ntasks as sensor placement, network compression, and active sensing.\n","authors":["Owen Howell","Haoen Huang","David Rosen"],"pdf_url":"https://arxiv.org/pdf/2311.16544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16507v1","updated":"2023-11-28T06:19:30Z","published":"2023-11-28T06:19:30Z","title":"Exploring Straighter Trajectories of Flow Matching with Diffusion\n  Guidance","summary":"  Flow matching as a paradigm of generative model achieves notable success\nacross various domains. However, existing methods use either multi-round\ntraining or knowledge within minibatches, posing challenges in finding a\nfavorable coupling strategy for straight trajectories. To address this issue,\nwe propose a novel approach, Straighter trajectories of Flow Matching\n(StraightFM). It straightens trajectories with the coupling strategy guided by\ndiffusion model from entire distribution level. First, we propose a coupling\nstrategy to straighten trajectories, creating couplings between image and noise\nsamples under diffusion model guidance. Second, StraightFM also integrates real\ndata to enhance training, employing a neural network to parameterize another\ncoupling process from images to noise samples. StraightFM is jointly optimized\nwith couplings from above two mutually complementary directions, resulting in\nstraighter trajectories and enabling both one-step and few-step generation.\nExtensive experiments demonstrate that StraightFM yields high quality samples\nwith fewer step. StraightFM generates visually appealing images with a lower\nFID among diffusion and traditional flow matching methods within 5 sampling\nsteps when trained on pixel space. In the latent space (i.e., Latent\nDiffusion), StraightFM achieves a lower KID value compared to existing methods\non the CelebA-HQ 256 dataset in fewer than 10 sampling steps.\n","authors":["Siyu Xing","Jie Cao","Huaibo Huang","Xiao-Yu Zhang","Ran He"],"pdf_url":"https://arxiv.org/pdf/2311.16507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.20323v2","updated":"2023-11-28T06:18:33Z","published":"2023-10-31T09:58:11Z","title":"SemanticBoost: Elevating Motion Generation with Augmented Textual Cues","summary":"  Current techniques face difficulties in generating motions from intricate\nsemantic descriptions, primarily due to insufficient semantic annotations in\ndatasets and weak contextual understanding. To address these issues, we present\nSemanticBoost, a novel framework that tackles both challenges simultaneously.\nOur framework comprises a Semantic Enhancement module and a Context-Attuned\nMotion Denoiser (CAMD). The Semantic Enhancement module extracts supplementary\nsemantics from motion data, enriching the dataset's textual description and\nensuring precise alignment between text and motion data without depending on\nlarge language models. On the other hand, the CAMD approach provides an\nall-encompassing solution for generating high-quality, semantically consistent\nmotion sequences by effectively capturing context information and aligning the\ngenerated motion with the given textual descriptions. Distinct from existing\nmethods, our approach can synthesize accurate orientational movements, combined\nmotions based on specific body part descriptions, and motions generated from\ncomplex, extended sentences. Our experimental results demonstrate that\nSemanticBoost, as a diffusion-based method, outperforms auto-regressive-based\ntechniques, achieving cutting-edge performance on the Humanml3D dataset while\nmaintaining realistic and smooth motion generation quality.\n","authors":["Xin He","Shaoli Huang","Xiaohang Zhan","Chao Weng","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2310.20323v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16542v1","updated":"2023-11-28T06:16:30Z","published":"2023-11-28T06:16:30Z","title":"Agents meet OKR: An Object and Key Results Driven Agent System with\n  Hierarchical Self-Collaboration and Self-Evaluation","summary":"  In this study, we introduce the concept of OKR-Agent designed to enhance the\ncapabilities of Large Language Models (LLMs) in task-solving. Our approach\nutilizes both self-collaboration and self-correction mechanism, facilitated by\nhierarchical agents, to address the inherent complexities in task-solving. Our\nkey observations are two-fold: first, effective task-solving demands in-depth\ndomain knowledge and intricate reasoning, for which deploying specialized\nagents for individual sub-tasks can markedly enhance LLM performance. Second,\ntask-solving intrinsically adheres to a hierarchical execution structure,\ncomprising both high-level strategic planning and detailed task execution.\nTowards this end, our OKR-Agent paradigm aligns closely with this hierarchical\nstructure, promising enhanced efficacy and adaptability across a range of\nscenarios. Specifically, our framework includes two novel modules: hierarchical\nObjects and Key Results generation and multi-level evaluation, each\ncontributing to more efficient and robust task-solving. In practical,\nhierarchical OKR generation decomposes Objects into multiple sub-Objects and\nassigns new agents based on key results and agent responsibilities. These\nagents subsequently elaborate on their designated tasks and may further\ndecompose them as necessary. Such generation operates recursively and\nhierarchically, culminating in a comprehensive set of detailed solutions. The\nmulti-level evaluation module of OKR-Agent refines solution by leveraging\nfeedback from all associated agents, optimizing each step of the process. This\nensures solution is accurate, practical, and effectively address intricate task\nrequirements, enhancing the overall reliability and quality of the outcome.\nExperimental results also show our method outperforms the previous methods on\nseveral tasks. Code and demo are available at https://okr-agent.github.io/\n","authors":["Yi Zheng","Chongyang Ma","Kanle Shi","Haibin Huang"],"pdf_url":"https://arxiv.org/pdf/2311.16542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.13607v2","updated":"2023-11-28T06:16:03Z","published":"2023-09-24T11:04:50Z","title":"MM-NeRF: Multimodal-Guided 3D Multi-Style Transfer of Neural Radiance\n  Field","summary":"  3D style transfer aims to generate stylized views of 3D scenes with specified\nstyles, which requires high-quality generating and keeping multi-view\nconsistency. Existing methods still suffer the challenges of high-quality\nstylization with texture details and stylization with multimodal guidance. In\nthis paper, we reveal that the common training method of stylization with NeRF,\nwhich generates stylized multi-view supervision by 2D style transfer models,\ncauses the same object in supervision to show various states (color tone,\ndetails, etc.) in different views, leading NeRF to tend to smooth the texture\ndetails, further resulting in low-quality rendering for 3D multi-style\ntransfer. To tackle these problems, we propose a novel Multimodal-guided 3D\nMulti-style transfer of NeRF, termed MM-NeRF. First, MM-NeRF projects\nmultimodal guidance into a unified space to keep the multimodal styles\nconsistency and extracts multimodal features to guide the 3D stylization.\nSecond, a novel multi-head learning scheme is proposed to relieve the\ndifficulty of learning multi-style transfer, and a multi-view style consistent\nloss is proposed to track the inconsistency of multi-view supervision data.\nFinally, a novel incremental learning mechanism to generalize MM-NeRF to any\nnew style with small costs. Extensive experiments on several real-world\ndatasets show that MM-NeRF achieves high-quality 3D multi-style stylization\nwith multimodal guidance, and keeps multi-view consistency and style\nconsistency between multimodal guidance. Codes will be released.\n","authors":["Zijiang Yang","Zhongwei Qiu","Chang Xu","Dongmei Fu"],"pdf_url":"https://arxiv.org/pdf/2309.13607v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.05228v2","updated":"2023-11-28T06:09:31Z","published":"2022-11-07T09:38:34Z","title":"FIXED: Frustratingly Easy Domain Generalization with Mixup","summary":"  Domain generalization (DG) aims to learn a generalizable model from multiple\ntraining domains such that it can perform well on unseen target domains. A\npopular strategy is to augment training data to benefit generalization through\nmethods such as Mixup~\\cite{zhang2018mixup}. While the vanilla Mixup can be\ndirectly applied, theoretical and empirical investigations uncover several\nshortcomings that limit its performance. Firstly, Mixup cannot effectively\nidentify the domain and class information that can be used for learning\ninvariant representations. Secondly, Mixup may introduce synthetic noisy data\npoints via random interpolation, which lowers its discrimination capability.\nBased on the analysis, we propose a simple yet effective enhancement for\nMixup-based DG, namely domain-invariant Feature mIXup (FIX). It learns\ndomain-invariant representations for Mixup. To further enhance discrimination,\nwe leverage existing techniques to enlarge margins among classes to further\npropose the domain-invariant Feature MIXup with Enhanced Discrimination (FIXED)\napproach. We present theoretical insights about guarantees on its\neffectiveness. Extensive experiments on seven public datasets across two\nmodalities including image classification (Digits-DG, PACS, Office-Home) and\ntime series (DSADS, PAMAP2, UCI-HAR, and USC-HAD) demonstrate that our approach\nsignificantly outperforms nine state-of-the-art related methods, beating the\nbest performing baseline by 6.5\\% on average in terms of test accuracy. Code is\navailable at:\nhttps://github.com/jindongwang/transferlearning/tree/master/code/deep/fixed.\n","authors":["Wang Lu","Jindong Wang","Han Yu","Lei Huang","Xiang Zhang","Yiqiang Chen","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2211.05228v2.pdf","comment":"First Conference on Parsimony and Learning (CPAL) 2024; code for DG\n  at: https://github.com/jindongwang/transferlearning/tree/master/code/DeepDG"},{"id":"http://arxiv.org/abs/2305.18766v3","updated":"2023-11-28T05:09:02Z","published":"2023-05-30T05:56:58Z","title":"HiFA: High-fidelity Text-to-3D Generation with Advanced Diffusion\n  Guidance","summary":"  The advancements in automatic text-to-3D generation have been remarkable.\nMost existing methods use pre-trained text-to-image diffusion models to\noptimize 3D representations like Neural Radiance Fields (NeRFs) via\nlatent-space denoising score matching. Yet, these methods often result in\nartifacts and inconsistencies across different views due to their suboptimal\noptimization approaches and limited understanding of 3D geometry. Moreover, the\ninherent constraints of NeRFs in rendering crisp geometry and stable textures\nusually lead to a two-stage optimization to attain high-resolution details.\nThis work proposes holistic sampling and smoothing approaches to achieve\nhigh-quality text-to-3D generation, all in a single-stage optimization. We\ncompute denoising scores in the text-to-image diffusion model's latent and\nimage spaces. Instead of randomly sampling timesteps (also referred to as noise\nlevels in denoising score matching), we introduce a novel timestep annealing\napproach that progressively reduces the sampled timestep throughout\noptimization. To generate high-quality renderings in a single-stage\noptimization, we propose regularization for the variance of z-coordinates along\nNeRF rays. To address texture flickering issues in NeRFs, we introduce a kernel\nsmoothing technique that refines importance sampling weights coarse-to-fine,\nensuring accurate and thorough sampling in high-density regions. Extensive\nexperiments demonstrate the superiority of our method over previous approaches,\nenabling the generation of highly detailed and view-consistent 3D assets\nthrough a single-stage training process.\n","authors":["Junzhe Zhu","Peiye Zhuang"],"pdf_url":"https://arxiv.org/pdf/2305.18766v3.pdf","comment":"Project page: https://hifa-team.github.io/HiFA-site/"},{"id":"http://arxiv.org/abs/2311.16524v1","updated":"2023-11-28T05:06:22Z","published":"2023-11-28T05:06:22Z","title":"3D Teeth Reconstruction from Panoramic Radiographs using Neural Implicit\n  Functions","summary":"  Panoramic radiography is a widely used imaging modality in dental practice\nand research. However, it only provides flattened 2D images, which limits the\ndetailed assessment of dental structures. In this paper, we propose Occudent, a\nframework for 3D teeth reconstruction from panoramic radiographs using neural\nimplicit functions, which, to the best of our knowledge, is the first work to\ndo so. For a given point in 3D space, the implicit function estimates whether\nthe point is occupied by a tooth, and thus implicitly determines the boundaries\nof 3D tooth shapes. Firstly, Occudent applies multi-label segmentation to the\ninput panoramic radiograph. Next, tooth shape embeddings as well as tooth class\nembeddings are generated from the segmentation outputs, which are fed to the\nreconstruction network. A novel module called Conditional eXcitation (CX) is\nproposed in order to effectively incorporate the combined shape and class\nembeddings into the implicit function. The performance of Occudent is evaluated\nusing both quantitative and qualitative measures. Importantly, Occudent is\ntrained and validated with actual panoramic radiographs as input, distinct from\nrecent works which used synthesized images. Experiments demonstrate the\nsuperiority of Occudent over state-of-the-art methods.\n","authors":["Sihwa Park","Seongjun Kim","In-Seok Song","Seung Jun Baek"],"pdf_url":"https://arxiv.org/pdf/2311.16524v1.pdf","comment":"12 pages, 2 figures, accepted to International Conference on Medical\n  Image Computing and Computer-Assisted Intervention MICCAI 2023"},{"id":"http://arxiv.org/abs/2303.06842v4","updated":"2023-11-28T04:50:46Z","published":"2023-03-13T04:16:42Z","title":"Hierarchical Relationships: A New Perspective to Enhance Scene Graph\n  Generation","summary":"  This paper presents a finding that leveraging the hierarchical structures\namong labels for relationships and objects can substantially improve the\nperformance of scene graph generation systems. The focus of this work is to\ncreate an informative hierarchical structure that can divide object and\nrelationship categories into disjoint super-categories in a systematic way.\nSpecifically, we introduce a Bayesian prediction head to jointly predict the\nsuper-category of relationships between a pair of object instances, as well as\nthe detailed relationship within that super-category simultaneously,\nfacilitating more informative predictions. The resulting model exhibits the\ncapability to produce a more extensive set of predicates beyond the dataset\nannotations, and to tackle the prevalent issue of low annotation quality. While\nour paper presents preliminary findings, experiments on the Visual Genome\ndataset show its strong performance, particularly in predicate classifications\nand zero-shot settings, that demonstrates the promise of our approach.\n","authors":["Bowen Jiang","Camillo J. Taylor"],"pdf_url":"https://arxiv.org/pdf/2303.06842v4.pdf","comment":"NeurIPS 2023 New Frontiers in Graph Learning Workshop (NeurIPS\n  GLFrontiers 2023); NeurIPS 2023 Queer in AI Workshop"},{"id":"http://arxiv.org/abs/2311.16488v1","updated":"2023-11-28T04:34:44Z","published":"2023-11-28T04:34:44Z","title":"Efficient Multimodal Diffusion Models Using Joint Data Infilling with\n  Partially Shared U-Net","summary":"  Recently, diffusion models have been used successfully to fit distributions\nfor cross-modal data translation and multimodal data generation. However, these\nmethods rely on extensive scaling, overlooking the inefficiency and\ninterference between modalities. We develop Partially Shared U-Net (PS-U-Net)\narchitecture which is an efficient multimodal diffusion model that allows text\nand image inputs to pass through dedicated layers and skip-connections for\npreserving modality-specific fine-grained details. Inspired by image\ninpainting, we also propose a new efficient multimodal sampling method that\nintroduces new scenarios for conditional generation while only requiring a\nsimple joint distribution to be learned. Our empirical exploration of the\nMS-COCO dataset demonstrates that our method generates multimodal text and\nimage data with higher quality compared to existing multimodal diffusion models\nwhile having a comparable size, faster training, faster multimodal sampling,\nand more flexible generation.\n","authors":["Zizhao Hu","Shaochong Jia","Mohammad Rostami"],"pdf_url":"https://arxiv.org/pdf/2311.16488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15868v3","updated":"2023-11-28T04:28:48Z","published":"2023-06-28T01:50:46Z","title":"GraSS: Contrastive Learning with Gradient Guided Sampling Strategy for\n  Remote Sensing Image Semantic Segmentation","summary":"  Self-supervised contrastive learning (SSCL) has achieved significant\nmilestones in remote sensing image (RSI) understanding. Its essence lies in\ndesigning an unsupervised instance discrimination pretext task to extract image\nfeatures from a large number of unlabeled images that are beneficial for\ndownstream tasks. However, existing instance discrimination based SSCL suffer\nfrom two limitations when applied to the RSI semantic segmentation task: 1)\nPositive sample confounding issue; 2) Feature adaptation bias. It introduces a\nfeature adaptation bias when applied to semantic segmentation tasks that\nrequire pixel-level or object-level features. In this study, We observed that\nthe discrimination information can be mapped to specific regions in RSI through\nthe gradient of unsupervised contrastive loss, these specific regions tend to\ncontain singular ground objects. Based on this, we propose contrastive learning\nwith Gradient guided Sampling Strategy (GraSS) for RSI semantic segmentation.\nGraSS consists of two stages: Instance Discrimination warm-up (ID warm-up) and\nGradient guided Sampling contrastive training (GS training). The ID warm-up\naims to provide initial discrimination information to the contrastive loss\ngradients. The GS training stage aims to utilize the discrimination information\ncontained in the contrastive loss gradients and adaptively select regions in\nRSI patches that contain more singular ground objects, in order to construct\nnew positive and negative samples. Experimental results on three open datasets\ndemonstrate that GraSS effectively enhances the performance of SSCL in\nhigh-resolution RSI semantic segmentation. Compared to seven baseline methods\nfrom five different types of SSCL, GraSS achieves an average improvement of\n1.57\\% and a maximum improvement of 3.58\\% in terms of mean intersection over\nthe union. The source code is available at https://github.com/GeoX-Lab/GraSS\n","authors":["Zhaoyang Zhang","Zhen Ren","Chao Tao","Yunsheng Zhang","Chengli Peng","Haifeng Li"],"pdf_url":"https://arxiv.org/pdf/2306.15868v3.pdf","comment":"14 pages, 10 figures, 4 tables"},{"id":"http://arxiv.org/abs/2311.16471v1","updated":"2023-11-28T04:13:49Z","published":"2023-11-28T04:13:49Z","title":"A Unified Framework for Multimodal, Multi-Part Human Motion Synthesis","summary":"  The field has made significant progress in synthesizing realistic human\nmotion driven by various modalities. Yet, the need for different methods to\nanimate various body parts according to different control signals limits the\nscalability of these techniques in practical scenarios. In this paper, we\nintroduce a cohesive and scalable approach that consolidates multimodal (text,\nmusic, speech) and multi-part (hand, torso) human motion generation. Our\nmethodology unfolds in several steps: We begin by quantizing the motions of\ndiverse body parts into separate codebooks tailored to their respective\ndomains. Next, we harness the robust capabilities of pre-trained models to\ntranscode multimodal signals into a shared latent space. We then translate\nthese signals into discrete motion tokens by iteratively predicting subsequent\ntokens to form a complete sequence. Finally, we reconstruct the continuous\nactual motion from this tokenized sequence. Our method frames the multimodal\nmotion generation challenge as a token prediction task, drawing from\nspecialized codebooks based on the modality of the control signal. This\napproach is inherently scalable, allowing for the easy integration of new\nmodalities. Extensive experiments demonstrated the effectiveness of our design,\nemphasizing its potential for broad application.\n","authors":["Zixiang Zhou","Yu Wan","Baoyuan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.16471v1.pdf","comment":"19 pages, 18 figures"},{"id":"http://arxiv.org/abs/2311.16468v1","updated":"2023-11-28T04:10:07Z","published":"2023-11-28T04:10:07Z","title":"AvatarGPT: All-in-One Framework for Motion Understanding, Planning,\n  Generation and Beyond","summary":"  Large Language Models(LLMs) have shown remarkable emergent abilities in\nunifying almost all (if not every) NLP tasks. In the human motion-related\nrealm, however, researchers still develop siloed models for each task. Inspired\nby InstuctGPT, and the generalist concept behind Gato, we introduce AvatarGPT,\nan All-in-One framework for motion understanding, planning, generations as well\nas other tasks such as motion in-between synthesis. AvatarGPT treats each task\nas one type of instruction fine-tuned on the shared LLM. All the tasks are\nseamlessly interconnected with language as the universal interface,\nconstituting a closed-loop within the framework. To achieve this, human motion\nsequences are first encoded as discrete tokens, which serve as the extended\nvocabulary of LLM. Then, an unsupervised pipeline to generate natural language\ndescriptions of human action sequences from in-the-wild videos is developed.\nFinally, all tasks are jointly trained. Extensive experiments show that\nAvatarGPT achieves SOTA on low-level tasks, and promising results on high-level\ntasks, demonstrating the effectiveness of our proposed All-in-One framework.\nMoreover, for the first time, AvatarGPT enables a principled approach by\niterative traversal of the tasks within the closed-loop for unlimited\nlong-motion synthesis.\n","authors":["Zixiang Zhou","Yu Wan","Baoyuan Wang"],"pdf_url":"https://arxiv.org/pdf/2311.16468v1.pdf","comment":"22 pages, 21 figures"},{"id":"http://arxiv.org/abs/2311.08223v2","updated":"2023-11-28T04:05:03Z","published":"2023-11-14T15:01:58Z","title":"Improving Image Captioning via Predicting Structured Concepts","summary":"  Having the difficulty of solving the semantic gap between images and texts\nfor the image captioning task, conventional studies in this area paid some\nattention to treating semantic concepts as a bridge between the two modalities\nand improved captioning performance accordingly. Although promising results on\nconcept prediction were obtained, the aforementioned studies normally ignore\nthe relationship among concepts, which relies on not only objects in the image,\nbut also word dependencies in the text, so that offers a considerable potential\nfor improving the process of generating good descriptions. In this paper, we\npropose a structured concept predictor (SCP) to predict concepts and their\nstructures, then we integrate them into captioning, so as to enhance the\ncontribution of visual signals in this task via concepts and further use their\nrelations to distinguish cross-modal semantics for better description\ngeneration. Particularly, we design weighted graph convolutional networks\n(W-GCN) to depict concept relations driven by word dependencies, and then\nlearns differentiated contributions from these concepts for following decoding\nprocess. Therefore, our approach captures potential relations among concepts\nand discriminatively learns different concepts, so that effectively facilitates\nimage captioning with inherited information across modalities. Extensive\nexperiments and their results demonstrate the effectiveness of our approach as\nwell as each proposed module in this work.\n","authors":["Ting Wang","Weidong Chen","Yuanhe Tian","Yan Song","Zhendong Mao"],"pdf_url":"https://arxiv.org/pdf/2311.08223v2.pdf","comment":"Accepted by EMNLP 2023 (Main Conference, Oral)"},{"id":"http://arxiv.org/abs/2311.16465v1","updated":"2023-11-28T04:02:40Z","published":"2023-11-28T04:02:40Z","title":"TextDiffuser-2: Unleashing the Power of Language Models for Text\n  Rendering","summary":"  The diffusion model has been proven a powerful generative model in recent\nyears, yet remains a challenge in generating visual text. Several methods\nalleviated this issue by incorporating explicit text position and content as\nguidance on where and what text to render. However, these methods still suffer\nfrom several drawbacks, such as limited flexibility and automation, constrained\ncapability of layout prediction, and restricted style diversity. In this paper,\nwe present TextDiffuser-2, aiming to unleash the power of language models for\ntext rendering. Firstly, we fine-tune a large language model for layout\nplanning. The large language model is capable of automatically generating\nkeywords for text rendering and also supports layout modification through\nchatting. Secondly, we utilize the language model within the diffusion model to\nencode the position and texts at the line level. Unlike previous methods that\nemployed tight character-level guidance, this approach generates more diverse\ntext images. We conduct extensive experiments and incorporate user studies\ninvolving human participants as well as GPT-4V, validating TextDiffuser-2's\ncapacity to achieve a more rational text layout and generation with enhanced\ndiversity. The code and model will be available at\n\\url{https://aka.ms/textdiffuser-2}.\n","authors":["Jingye Chen","Yupan Huang","Tengchao Lv","Lei Cui","Qifeng Chen","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2311.16465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.06296v2","updated":"2023-11-28T03:58:28Z","published":"2021-09-13T20:12:42Z","title":"Monocular Camera Localization for Automated Vehicles Using Image\n  Retrieval","summary":"  We address the problem of finding the current position and heading angle of\nan autonomous vehicle in real-time using a single camera. Compared to methods\nwhich require LiDARs and high definition (HD) 3D maps in real-time, the\nproposed approach is easily scalable and computationally efficient, at the\nprice of lower precision.\n  The new method combines and adapts existing algorithms in three different\nfields: image retrieval, mapping database, and particle filtering. The result\nis a simple, real-time localization method using an image retrieval method\nwhose performance is comparable to other monocular camera localization methods\nwhich use a map built with LiDARs.\n  We evaluate the proposed method using the KITTI odometry dataset and via\nclosed-loop experiments with an indoor 1:10 autonomous vehicle. The tests\ndemonstrate real-time capability and a 10cm level accuracy. Also, experimental\nresults of the closed-loop indoor tests show the presence of a positive\nfeedback loop between the localization error and the control error. Such\nphenomena is analysed in details at the end of the article.\n","authors":["Eunhyek Joa","Francesco Borrelli"],"pdf_url":"https://arxiv.org/pdf/2109.06296v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16464v1","updated":"2023-11-28T03:55:23Z","published":"2023-11-28T03:55:23Z","title":"Bridging the Gap: A Unified Video Comprehension Framework for Moment\n  Retrieval and Highlight Detection","summary":"  Video Moment Retrieval (MR) and Highlight Detection (HD) have attracted\nsignificant attention due to the growing demand for video analysis. Recent\napproaches treat MR and HD as similar video grounding problems and address them\ntogether with transformer-based architecture. However, we observe that the\nemphasis of MR and HD differs, with one necessitating the perception of local\nrelationships and the other prioritizing the understanding of global contexts.\nConsequently, the lack of task-specific design will inevitably lead to\nlimitations in associating the intrinsic specialty of two tasks. To tackle the\nissue, we propose a Unified Video COMprehension framework (UVCOM) to bridge the\ngap and jointly solve MR and HD effectively. By performing progressive\nintegration on intra and inter-modality across multi-granularity, UVCOM\nachieves the comprehensive understanding in processing a video. Moreover, we\npresent multi-aspect contrastive learning to consolidate the local relation\nmodeling and global knowledge accumulation via well aligned multi-modal space.\nExtensive experiments on QVHighlights, Charades-STA, TACoS , YouTube Highlights\nand TVSum datasets demonstrate the effectiveness and rationality of UVCOM which\noutperforms the state-of-the-art methods by a remarkable margin.\n","authors":["Yicheng Xiao","Zhuoyan Luo","Yong Liu","Yue Ma","Hengwei Bian","Yatai Ji","Yujiu Yang","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2311.16464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03211v2","updated":"2023-11-28T03:50:54Z","published":"2023-10-04T23:33:36Z","title":"On the Performance of Multimodal Language Models","summary":"  Instruction-tuned large language models (LLMs) have demonstrated promising\nzero-shot generalization capabilities across various downstream tasks. Recent\nresearch has introduced multimodal capabilities to LLMs by integrating\nindependently pretrained vision encoders through model grafting. These\nmultimodal variants undergo instruction tuning, similar to LLMs, enabling\neffective zero-shot generalization for multimodal tasks. This study conducts a\ncomparative analysis of different multimodal instruction tuning approaches and\nevaluates their performance across a range of tasks, including complex\nreasoning, conversation, image captioning, multiple-choice questions (MCQs),\nand binary classification. Through rigorous benchmarking and ablation\nexperiments, we reveal key insights for guiding architectural choices when\nincorporating multimodal capabilities into LLMs. However, current approaches\nhave limitations; they do not sufficiently address the need for a diverse\nmultimodal instruction dataset, which is crucial for enhancing task\ngeneralization. Additionally, they overlook issues related to truthfulness and\nfactuality when generating responses. These findings illuminate current\nmethodological constraints in adapting language models for image comprehension\nand provide valuable guidance for researchers and practitioners seeking to\nharness multimodal versions of LLMs.\n","authors":["Utsav Garg","Erhan Bas"],"pdf_url":"https://arxiv.org/pdf/2310.03211v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16462v1","updated":"2023-11-28T03:45:29Z","published":"2023-11-28T03:45:29Z","title":"Viewport Prediction for Volumetric Video Streaming by Exploring Video\n  Saliency and Trajectory Information","summary":"  Volumetric video, also known as hologram video, is a novel medium that\nportrays natural content in Virtual Reality (VR), Augmented Reality (AR), and\nMixed Reality (MR). It is expected to be the next-gen video technology and a\nprevalent use case for 5G and beyond wireless communication. Considering that\neach user typically only watches a section of the volumetric video, known as\nthe viewport, it is essential to have precise viewport prediction for optimal\nperformance. However, research on this topic is still in its infancy. In the\nend, this paper presents and proposes a novel approach, named Saliency and\nTrajectory Viewport Prediction (STVP), which aims to improve the precision of\nviewport prediction in volumetric video streaming. The STVP extensively\nutilizes video saliency information and viewport trajectory. To our knowledge,\nthis is the first comprehensive study of viewport prediction in volumetric\nvideo streaming. In particular, we introduce a novel sampling method, Uniform\nRandom Sampling (URS), to reduce computational complexity while still\npreserving video features in an efficient manner. Then we present a saliency\ndetection technique that incorporates both spatial and temporal information for\ndetecting static, dynamic geometric, and color salient regions. Finally, we\nintelligently fuse saliency and trajectory information to achieve more accurate\nviewport prediction. We conduct extensive simulations to evaluate the\neffectiveness of our proposed viewport prediction methods using\nstate-of-the-art volumetric video sequences. The experimental results show the\nsuperiority of the proposed method over existing schemes. The dataset and\nsource code will be publicly accessible after acceptance.\n","authors":["Jie Li","Zhixin Li","Zhi Liu","Pengyuan Zhou","Richang Hong","Qiyue Li","Han Hu"],"pdf_url":"https://arxiv.org/pdf/2311.16462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16456v1","updated":"2023-11-28T03:30:43Z","published":"2023-11-28T03:30:43Z","title":"Spiking Neural Networks with Dynamic Time Steps for Vision Transformers","summary":"  Spiking Neural Networks (SNNs) have emerged as a popular spatio-temporal\ncomputing paradigm for complex vision tasks. Recently proposed SNN training\nalgorithms have significantly reduced the number of time steps (down to 1) for\nimproved latency and energy efficiency, however, they target only convolutional\nneural networks (CNN). These algorithms, when applied on the recently\nspotlighted vision transformers (ViT), either require a large number of time\nsteps or fail to converge. Based on analysis of the histograms of the ANN and\nSNN activation maps, we hypothesize that each ViT block has a different\nsensitivity to the number of time steps. We propose a novel training framework\nthat dynamically allocates the number of time steps to each ViT module\ndepending on a trainable score assigned to each timestep. In particular, we\ngenerate a scalar binary time step mask that filters spikes emitted by each\nneuron in a leaky-integrate-and-fire (LIF) layer. The resulting SNNs have high\nactivation sparsity and require only accumulate operations (AC), except for the\ninput embedding layer, in contrast to expensive multiply-and-accumulates (MAC)\nneeded in traditional ViTs. This yields significant improvements in energy\nefficiency. We evaluate our training framework and resulting SNNs on image\nrecognition tasks including CIFAR10, CIFAR100, and ImageNet with different ViT\narchitectures. We obtain a test accuracy of 95.97% with 4.97 time steps with\ndirect encoding on CIFAR10.\n","authors":["Gourav Datta","Zeyu Liu","Anni Li","Peter A. Beerel"],"pdf_url":"https://arxiv.org/pdf/2311.16456v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2311.16450v1","updated":"2023-11-28T03:11:33Z","published":"2023-11-28T03:11:33Z","title":"Typhoon Intensity Prediction with Vision Transformer","summary":"  Predicting typhoon intensity accurately across space and time is crucial for\nissuing timely disaster warnings and facilitating emergency response. This has\nvast potential for minimizing life losses and property damages as well as\nreducing economic and environmental impacts. Leveraging satellite imagery for\nscenario analysis is effective but also introduces additional challenges due to\nthe complex relations among clouds and the highly dynamic context. Existing\ndeep learning methods in this domain rely on convolutional neural networks\n(CNNs), which suffer from limited per-layer receptive fields. This limitation\nhinders their ability to capture long-range dependencies and global contextual\nknowledge during inference. In response, we introduce a novel approach, namely\n\"Typhoon Intensity Transformer\" (Tint), which leverages self-attention\nmechanisms with global receptive fields per layer. Tint adopts a\nsequence-to-sequence feature representation learning perspective. It begins by\ncutting a given satellite image into a sequence of patches and recursively\nemploys self-attention operations to extract both local and global contextual\nrelations between all patch pairs simultaneously, thereby enhancing per-patch\nfeature representation learning. Extensive experiments on a publicly available\ntyphoon benchmark validate the efficacy of Tint in comparison with both\nstate-of-the-art deep learning and conventional meteorological methods. Our\ncode is available at https://github.com/chen-huanxin/Tint.\n","authors":["Huanxin Chen","Pengshuai Yin","Huichou Huang","Qingyao Wu","Ruirui Liu","Xiatian Zhu"],"pdf_url":"https://arxiv.org/pdf/2311.16450v1.pdf","comment":"8 pages, 2 figures, accepted by Tackling Climate Change with Machine\n  Learning: workshop at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.16447v1","updated":"2023-11-28T03:04:35Z","published":"2023-11-28T03:04:35Z","title":"TopoSemiSeg: Enforcing Topological Consistency for Semi-Supervised\n  Segmentation of Histopathology Images","summary":"  In computational pathology, segmenting densely distributed objects like\nglands and nuclei is crucial for downstream analysis. To alleviate the burden\nof obtaining pixel-wise annotations, semi-supervised learning methods learn\nfrom large amounts of unlabeled data. Nevertheless, existing semi-supervised\nmethods overlook the topological information hidden in the unlabeled images and\nare thus prone to topological errors, e.g., missing or incorrectly\nmerged/separated glands or nuclei. To address this issue, we propose\nTopoSemiSeg, the first semi-supervised method that learns the topological\nrepresentation from unlabeled data. In particular, we propose a topology-aware\nteacher-student approach in which the teacher and student networks learn shared\ntopological representations. To achieve this, we introduce topological\nconsistency loss, which contains signal consistency and noise removal losses to\nensure the learned representation is robust and focuses on true topological\nsignals. Extensive experiments on public pathology image datasets show the\nsuperiority of our method, especially on topology-wise evaluation metrics. Code\nis available at https://github.com/Melon-Xu/TopoSemiSeg.\n","authors":["Meilong Xu","Xiaoling Hu","Saumya Gupta","Shahira Abousamra","Chao Chen"],"pdf_url":"https://arxiv.org/pdf/2311.16447v1.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.16446v1","updated":"2023-11-28T03:02:00Z","published":"2023-11-28T03:02:00Z","title":"Centre Stage: Centricity-based Audio-Visual Temporal Action Detection","summary":"  Previous one-stage action detection approaches have modelled temporal\ndependencies using only the visual modality. In this paper, we explore\ndifferent strategies to incorporate the audio modality, using multi-scale\ncross-attention to fuse the two modalities. We also demonstrate the correlation\nbetween the distance from the timestep to the action centre and the accuracy of\nthe predicted boundaries. Thus, we propose a novel network head to estimate the\ncloseness of timesteps to the action centre, which we call the centricity\nscore. This leads to increased confidence for proposals that exhibit more\nprecise boundaries. Our method can be integrated with other one-stage\nanchor-free architectures and we demonstrate this on three recent baselines on\nthe EPIC-Kitchens-100 action detection benchmark where we achieve\nstate-of-the-art performance. Detailed ablation studies showcase the benefits\nof fusing audio and our proposed centricity scores. Code and models for our\nproposed method are publicly available at\nhttps://github.com/hanielwang/Audio-Visual-TAD.git\n","authors":["Hanyuan Wang","Majid Mirmehdi","Dima Damen","Toby Perrett"],"pdf_url":"https://arxiv.org/pdf/2311.16446v1.pdf","comment":"Accepted to VUA workshop at BMVC 2023"},{"id":"http://arxiv.org/abs/2311.16445v1","updated":"2023-11-28T03:00:59Z","published":"2023-11-28T03:00:59Z","title":"CLAP: Contrastive Learning with Augmented Prompts for Robustness on\n  Pretrained Vision-Language Models","summary":"  Contrastive vision-language models, e.g., CLIP, have garnered substantial\nattention for their exceptional generalization capabilities. However, their\nrobustness to perturbations has ignited concerns. Existing strategies typically\nreinforce their resilience against adversarial examples by enabling the image\nencoder to \"see\" these perturbed examples, often necessitating a complete\nretraining of the image encoder on both natural and adversarial samples. In\nthis study, we propose a new method to enhance robustness solely through text\naugmentation, eliminating the need for retraining the image encoder on\nadversarial examples. Our motivation arises from the realization that text and\nimage data inherently occupy a shared latent space, comprising latent content\nvariables and style variables. This insight suggests the feasibility of\nlearning to disentangle these latent content variables using text data\nexclusively. To accomplish this, we introduce an effective text augmentation\nmethod that focuses on modifying the style while preserving the content in the\ntext data. By changing the style part of the text data, we empower the text\nencoder to emphasize latent content variables, ultimately enhancing the\nrobustness of vision-language models. Our experiments across various datasets\ndemonstrate substantial improvements in the robustness of the pre-trained CLIP\nmodel.\n","authors":["Yichao Cai","Yuhang Liu","Zhen Zhang","Javen Qinfeng Shi"],"pdf_url":"https://arxiv.org/pdf/2311.16445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16444v1","updated":"2023-11-28T02:51:13Z","published":"2023-11-28T02:51:13Z","title":"Exo2EgoDVC: Dense Video Captioning of Egocentric Procedural Activities\n  Using Web Instructional Videos","summary":"  We propose a novel benchmark for cross-view knowledge transfer of dense video\ncaptioning, adapting models from web instructional videos with exocentric views\nto an egocentric view. While dense video captioning (predicting time segments\nand their captions) is primarily studied with exocentric videos (e.g.,\nYouCook2), benchmarks with egocentric videos are restricted due to data\nscarcity. To overcome the limited video availability, transferring knowledge\nfrom abundant exocentric web videos is demanded as a practical approach.\nHowever, learning the correspondence between exocentric and egocentric views is\ndifficult due to their dynamic view changes. The web videos contain mixed views\nfocusing on either human body actions or close-up hand-object interactions,\nwhile the egocentric view is constantly shifting as the camera wearer moves.\nThis necessitates the in-depth study of cross-view transfer under complex view\nchanges. In this work, we first create a real-life egocentric dataset (EgoYC2)\nwhose captions are shared with YouCook2, enabling transfer learning between\nthese datasets assuming their ground-truth is accessible. To bridge the view\ngaps, we propose a view-invariant learning method using adversarial training in\nboth the pre-training and fine-tuning stages. While the pre-training is\ndesigned to learn invariant features against the mixed views in the web videos,\nthe view-invariant fine-tuning further mitigates the view gaps between both\ndatasets. We validate our proposed method by studying how effectively it\novercomes the view change problem and efficiently transfers the knowledge to\nthe egocentric domain. Our benchmark pushes the study of the cross-view\ntransfer into a new task domain of dense video captioning and will envision\nmethodologies to describe egocentric videos in natural language.\n","authors":["Takehiko Ohkawa","Takuma Yagi","Taichi Nishimura","Ryosuke Furuta","Atsushi Hashimoto","Yoshitaka Ushiku","Yoichi Sato"],"pdf_url":"https://arxiv.org/pdf/2311.16444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17098v2","updated":"2023-11-28T02:37:16Z","published":"2023-05-26T17:13:55Z","title":"ControlVideo: Conditional Control for One-shot Text-driven Video Editing\n  and Beyond","summary":"  This paper presents \\emph{ControlVideo} for text-driven video editing --\ngenerating a video that aligns with a given text while preserving the structure\nof the source video. Building on a pre-trained text-to-image diffusion model,\nControlVideo enhances the fidelity and temporal consistency by incorporating\nadditional conditions (such as edge maps), and fine-tuning the key-frame and\ntemporal attention on the source video-text pair via an in-depth exploration of\nthe design space. Extensive experimental results demonstrate that ControlVideo\noutperforms various competitive baselines by delivering videos that exhibit\nhigh fidelity w.r.t. the source content, and temporal consistency, all while\naligning with the text. By incorporating Low-rank adaptation layers into the\nmodel before training, ControlVideo is further empowered to generate videos\nthat align seamlessly with reference images. More importantly, ControlVideo can\nbe readily extended to the more challenging task of long video editing (e.g.,\nwith hundreds of frames), where maintaining long-range temporal consistency is\ncrucial. To achieve this, we propose to construct a fused ControlVideo by\napplying basic ControlVideo to overlapping short video segments and key frame\nvideos and then merging them by pre-defined weight functions. Empirical results\nvalidate its capability to create videos across 140 frames, which is\napproximately 5.83 to 17.5 times more than what previous works achieved. The\ncode is available at\n\\href{https://github.com/thu-ml/controlvideo}{https://github.com/thu-ml/controlvideo}\nand the visualization results are available at\n\\href{https://drive.google.com/file/d/1wEgc2io3UwmoC5vTPbkccFvTkwVqsZlK/view?usp=drive_link}{HERE}.\n","authors":["Min Zhao","Rongzhen Wang","Fan Bao","Chongxuan Li","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2305.17098v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15111v2","updated":"2023-11-28T02:28:27Z","published":"2023-11-25T20:01:20Z","title":"SAMv2: A Unified Framework for Learning Appearance, Semantic and\n  Cross-Modality Anatomical Embeddings","summary":"  Identifying anatomical structures (e.g., lesions or landmarks) in medical\nimages plays a fundamental role in medical image analysis. As an exemplar-based\nlandmark detection method, Self-supervised Anatomical eMbedding (SAM) learns a\ndiscriminative embedding for each voxel in the image and has shown promising\nresults on various tasks. However, SAM still faces challenges in: (1)\ndifferentiating voxels with similar appearance but different semantic meanings\n(\\textit{e.g.}, two adjacent structures without clear borders); (2) matching\nvoxels with similar semantics but markedly different appearance (e.g., the same\nvessel before and after contrast injection); and (3) cross-modality matching\n(e.g., CT-MRI registration). To overcome these challenges, we propose SAMv2,\nwhich is a unified framework designed to learn appearance, semantic, and\ncross-modality anatomical embeddings. Specifically, SAMv2 incorporates three\nkey innovations: (1) semantic embedding learning with prototypical contrastive\nloss; (2) a fixed-point-based matching strategy; and (3) an iterative approach\nfor cross-modality embedding learning. We thoroughly evaluated SAMv2 across\nthree tasks, including one-shot landmark detection, lesion tracking on\nlongitudinal CT scans, and CT-MRI affine/rigid registration with varying field\nof view. Our results suggest that SAMv2 outperforms SAM and other\nstate-of-the-art methods, offering a robust and versatile approach for landmark\nbased medical image analysis tasks. Code and trained models are available at:\nhttps://github.com/alibaba-damo-academy/self-supervised-anatomical-embedding-v2\n","authors":["Xiaoyu Bai","Fan Bai","Xiaofei Huo","Jia Ge","Jingjing Lu","Xianghua Ye","Ke Yan","Yong Xia"],"pdf_url":"https://arxiv.org/pdf/2311.15111v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.00154v2","updated":"2023-11-28T02:28:21Z","published":"2023-06-30T22:05:34Z","title":"Stitched ViTs are Flexible Vision Backbones","summary":"  Large pretrained plain vision Transformers (ViTs) have been the workhorse for\nmany downstream tasks. However, existing works utilizing off-the-shelf ViTs are\ninefficient in terms of training and deployment, because adopting ViTs with\nindividual sizes requires separate trainings and is restricted by fixed\nperformance-efficiency trade-offs. In this paper, we are inspired by stitchable\nneural networks (SN-Net), which is a new framework that cheaply produces a\nsingle model that covers rich subnetworks by stitching pretrained model\nfamilies, supporting diverse performance-efficiency trade-offs at runtime.\nBuilding upon this foundation, we introduce SN-Netv2, a systematically improved\nmodel stitching framework to facilitate downstream task adaptation.\nSpecifically, we first propose a two-way stitching scheme to enlarge the\nstitching space. We then design a resource-constrained sampling strategy that\ntakes into account the underlying FLOPs distributions in the space for better\nsampling. Finally, we observe that learning stitching layers as a low-rank\nupdate plays an essential role on downstream tasks to stabilize training and\nensure a good Pareto frontier. With extensive experiments on ImageNet-1K,\nADE20K, COCO-Stuff-10K and NYUv2, SN-Netv2 demonstrates superior performance\nover SN-Netv1 on downstream dense predictions and shows strong ability as a\nflexible vision backbone, achieving great advantages in both training\nefficiency and deployment flexibility. Code is available at\nhttps://github.com/ziplab/SN-Netv2.\n","authors":["Zizheng Pan","Jing Liu","Haoyu He","Jianfei Cai","Bohan Zhuang"],"pdf_url":"https://arxiv.org/pdf/2307.00154v2.pdf","comment":"Tech report"},{"id":"http://arxiv.org/abs/2311.16432v1","updated":"2023-11-28T02:27:31Z","published":"2023-11-28T02:27:31Z","title":"Text-Driven Image Editing via Learnable Regions","summary":"  Language has emerged as a natural interface for image editing. In this paper,\nwe introduce a method for region-based image editing driven by textual prompts,\nwithout the need for user-provided masks or sketches. Specifically, our\napproach leverages an existing pretrained text-to-image model and introduces a\nbounding box generator to find the edit regions that are aligned with the\ntextual prompts. We show that this simple approach enables flexible editing\nthat is compatible with current image generation models, and is able to handle\ncomplex prompts featuring multiple objects, complex sentences or long\nparagraphs. We conduct an extensive user study to compare our method against\nstate-of-the-art methods. Experiments demonstrate the competitive performance\nof our method in manipulating images with high fidelity and realism that align\nwith the language descriptions provided. Our project webpage:\nhttps://yuanze-lin.me/LearnableRegions_page.\n","authors":["Yuanze Lin","Yi-Wen Chen","Yi-Hsuan Tsai","Lu Jiang","Ming-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2311.16432v1.pdf","comment":"Project webpage: https://yuanze-lin.me/LearnableRegions_page"},{"id":"http://arxiv.org/abs/2310.00826v2","updated":"2023-11-28T02:13:40Z","published":"2023-10-02T00:11:47Z","title":"Large Scale Masked Autoencoding for Reducing Label Requirements on SAR\n  Data","summary":"  Satellite-based remote sensing is instrumental in the monitoring and\nmitigation of the effects of anthropogenic climate change. Large scale, high\nresolution data derived from these sensors can be used to inform intervention\nand policy decision making, but the timeliness and accuracy of these\ninterventions is limited by use of optical data, which cannot operate at night\nand is affected by adverse weather conditions. Synthetic Aperture Radar (SAR)\noffers a robust alternative to optical data, but its associated complexities\nlimit the scope of labelled data generation for traditional deep learning. In\nthis work, we apply a self-supervised pretraining scheme, masked autoencoding,\nto SAR amplitude data covering 8.7\\% of the Earth's land surface area, and tune\nthe pretrained weights on two downstream tasks crucial to monitoring climate\nchange - vegetation cover prediction and land cover classification. We show\nthat the use of this pretraining scheme reduces labelling requirements for the\ndownstream tasks by more than an order of magnitude, and that this pretraining\ngeneralises geographically, with the performance gain increasing when tuned\ndownstream on regions outside the pretraining set. Our findings significantly\nadvance climate change mitigation by facilitating the development of task and\nregion-specific SAR models, allowing local communities and organizations to\ndeploy tailored solutions for rapid, accurate monitoring of climate change\neffects.\n","authors":["Matt Allen","Francisco Dorr","Joseph A. Gallego-Mejia","Laura Martínez-Ferrer","Anna Jungbluth","Freddie Kalaitzis","Raúl Ramos-Pollán"],"pdf_url":"https://arxiv.org/pdf/2310.00826v2.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2311.16424v1","updated":"2023-11-28T02:08:06Z","published":"2023-11-28T02:08:06Z","title":"Manifold Preserving Guided Diffusion","summary":"  Despite the recent advancements, conditional image generation still faces\nchallenges of cost, generalizability, and the need for task-specific training.\nIn this paper, we propose Manifold Preserving Guided Diffusion (MPGD), a\ntraining-free conditional generation framework that leverages pretrained\ndiffusion models and off-the-shelf neural networks with minimal additional\ninference cost for a broad range of tasks. Specifically, we leverage the\nmanifold hypothesis to refine the guided diffusion steps and introduce a\nshortcut algorithm in the process. We then propose two methods for on-manifold\ntraining-free guidance using pre-trained autoencoders and demonstrate that our\nshortcut inherently preserves the manifolds when applied to latent diffusion\nmodels. Our experiments show that MPGD is efficient and effective for solving a\nvariety of conditional generation applications in low-compute settings, and can\nconsistently offer up to 3.8x speed-ups with the same number of diffusion steps\nwhile maintaining high sample quality compared to the baselines.\n","authors":["Yutong He","Naoki Murata","Chieh-Hsin Lai","Yuhta Takida","Toshimitsu Uesaka","Dongjun Kim","Wei-Hsiang Liao","Yuki Mitsufuji","J. Zico Kolter","Ruslan Salakhutdinov","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2311.16424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16420v1","updated":"2023-11-28T02:00:47Z","published":"2023-11-28T02:00:47Z","title":"Model-free Test Time Adaptation for Out-Of-Distribution Detection","summary":"  Out-of-distribution (OOD) detection is essential for the reliability of ML\nmodels. Most existing methods for OOD detection learn a fixed decision\ncriterion from a given in-distribution dataset and apply it universally to\ndecide if a data point is OOD. Recent work~\\cite{fang2022is} shows that given\nonly in-distribution data, it is impossible to reliably detect OOD data without\nextra assumptions. Motivated by the theoretical result and recent exploration\nof test-time adaptation methods, we propose a Non-Parametric Test Time\n\\textbf{Ada}ptation framework for \\textbf{O}ut-Of-\\textbf{D}istribution\n\\textbf{D}etection (\\abbr). Unlike conventional methods, \\abbr utilizes online\ntest samples for model adaptation during testing, enhancing adaptability to\nchanging data distributions. The framework incorporates detected OOD instances\ninto decision-making, reducing false positive rates, particularly when ID and\nOOD distributions overlap significantly. We demonstrate the effectiveness of\n\\abbr through comprehensive experiments on multiple OOD detection benchmarks,\nextensive empirical studies show that \\abbr significantly improves the\nperformance of OOD detection over state-of-the-art methods. Specifically, \\abbr\nreduces the false positive rate (FPR95) by $23.23\\%$ on the CIFAR-10 benchmarks\nand $38\\%$ on the ImageNet-1k benchmarks compared to the advanced methods.\nLastly, we theoretically verify the effectiveness of \\abbr.\n","authors":["YiFan Zhang","Xue Wang","Tian Zhou","Kun Yuan","Zhang Zhang","Liang Wang","Rong Jin","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2311.16420v1.pdf","comment":"12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2206.01370v3","updated":"2023-11-28T01:01:54Z","published":"2022-06-03T02:41:59Z","title":"Towards Improving the Generation Quality of Autoregressive Slot VAEs","summary":"  Unconditional scene inference and generation are challenging to learn jointly\nwith a single compositional model. Despite encouraging progress on models that\nextract object-centric representations (''slots'') from images, unconditional\ngeneration of scenes from slots has received less attention. This is primarily\nbecause learning the multi-object relations necessary to imagine coherent\nscenes is difficult. We hypothesize that most existing slot-based models have a\nlimited ability to learn object correlations. We propose two improvements that\nstrengthen object correlation learning. The first is to condition the slots on\na global, scene-level variable that captures higher-order correlations between\nslots. Second, we address the fundamental lack of a canonical order for objects\nin images by proposing to learn a consistent order to use for the\nautoregressive generation of scene objects. Specifically, we train an\nautoregressive slot prior to sequentially generate scene objects following a\nlearned order. Ordered slot inference entails first estimating a randomly\nordered set of slots using existing approaches for extracting slots from\nimages, then aligning those slots to ordered slots generated autoregressively\nwith the slot prior. Our experiments across three multi-object environments\ndemonstrate clear gains in unconditional scene generation quality. Detailed\nablation studies are also provided that validate the two proposed improvements.\n","authors":["Patrick Emami","Pan He","Sanjay Ranka","Anand Rangarajan"],"pdf_url":"https://arxiv.org/pdf/2206.01370v3.pdf","comment":"Published in Neural Computation. 38 pages, 18 figures. Code and\n  videos available at https://github.com/pemami4911/segregate-relate-imagine"},{"id":"http://arxiv.org/abs/2303.09373v2","updated":"2023-11-28T00:07:12Z","published":"2023-03-16T15:01:50Z","title":"MAPSeg: Unified Unsupervised Domain Adaptation for Heterogeneous Medical\n  Image Segmentation Based on 3D Masked Autoencoding and Pseudo-Labeling","summary":"  Robust segmentation is critical for deriving quantitative measures from\nlarge-scale, multi-center, and longitudinal medical scans. Manually annotating\nmedical scans, however, is expensive and labor-intensive and may not always be\navailable in every domain. Unsupervised domain adaptation (UDA) is a\nwell-studied technique that alleviates this label-scarcity problem by\nleveraging available labels from another domain. In this study, we introduce\nMasked Autoencoding and Pseudo-Labeling Segmentation (MAPSeg), a\n$\\textbf{unified}$ UDA framework with great versatility and superior\nperformance for heterogeneous and volumetric medical image segmentation. To the\nbest of our knowledge, this is the first study that systematically reviews and\ndevelops a framework to tackle four different domain shifts in medical image\nsegmentation. More importantly, MAPSeg is the first framework that can be\napplied to $\\textbf{centralized}$, $\\textbf{federated}$, and\n$\\textbf{test-time}$ UDA while maintaining comparable performance. We compare\nMAPSeg with previous state-of-the-art methods on a private infant brain MRI\ndataset and a public cardiac CT-MRI dataset, and MAPSeg outperforms others by a\nlarge margin (10.5 Dice improvement on the private MRI dataset and 5.7 on the\npublic CT-MRI dataset). MAPSeg poses great practical value and can be applied\nto real-world problems. Our code and pretrained model will be available later.\n","authors":["Xuzhe Zhang","Yuhao Wu","Elsa Angelini","Ang Li","Jia Guo","Jerod M. Rasmussen","Thomas G. O'Connor","Pathik D. Wadhwa","Andrea Parolin Jackowski","Hai Li","Jonathan Posner","Andrew F. Laine","Yun Wang"],"pdf_url":"https://arxiv.org/pdf/2303.09373v2.pdf","comment":"16 pages and 7 figures. Revised and extended to test-time and\n  federated domain adaptation. Xuzhe Zhang and Yuhao Wu are co-first authors.\n  Andrew F. Laine and Yun Wang are co-senior supervising authors"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2311.14968v2","updated":"2023-11-28T11:10:27Z","published":"2023-11-25T08:59:45Z","title":"Hide Your Model: A Parameter Transmission-free Federated Recommender\n  System","summary":"  With the growing concerns regarding user data privacy, Federated Recommender\nSystem (FedRec) has garnered significant attention recently due to its\nprivacy-preserving capabilities. Existing FedRecs generally adhere to a\nlearning protocol in which a central server shares a global recommendation\nmodel with clients, and participants achieve collaborative learning by\nfrequently communicating the model's public parameters. Nevertheless, this\nlearning framework has two drawbacks that limit its practical usability: (1) It\nnecessitates a global-sharing recommendation model; however, in real-world\nscenarios, information related to the recommender model, including its\nalgorithm and parameters, constitutes the platforms' intellectual property.\nHence, service providers are unlikely to release such information actively. (2)\nThe communication costs of model parameter transmission are expensive since the\nmodel parameters are usually high-dimensional matrices. With the model size\nincreasing, the communication burden will be the bottleneck for such\ntraditional FedRecs.\n  Given the above limitations, this paper introduces a novel parameter\ntransmission-free federated recommendation framework that balances the\nprotection between users' data privacy and platforms' model privacy, namely\nPTF-FedRec. Specifically, participants in PTF-FedRec collaboratively exchange\nknowledge by sharing their predictions within a privacy-preserving mechanism.\nThrough this way, the central server can learn a recommender model without\ndisclosing its model parameters or accessing clients' raw data, preserving both\nthe server's model privacy and users' data privacy. Besides, since clients and\nthe central server only need to communicate prediction scores which are just a\nfew real numbers, the overhead is significantly reduced compared to traditional\nFedRecs.\n","authors":["Wei Yuan","Chaoqun Yang","Liang Qu","Quoc Viet Hung Nguyen","Jianxin Li","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2311.14968v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10776v2","updated":"2023-11-28T02:21:40Z","published":"2023-11-16T01:21:33Z","title":"Towards an Automatic AI Agent for Reaction Condition Recommendation in\n  Chemical Synthesis","summary":"  Artificial intelligence (AI) for reaction condition optimization has become\nan important topic in the pharmaceutical industry, given that a data-driven AI\nmodel can assist drug discovery and accelerate reaction design. However,\nexisting AI models lack the chemical insights and real-time knowledge\nacquisition abilities of experienced human chemists. This paper proposes a\nLarge Language Model (LLM) empowered AI agent to bridge this gap. We put forth\na novel three-phase paradigm and applied advanced intelligence-enhancement\nmethods like in-context learning and multi-LLM debate so that the AI agent can\nborrow human insight and update its knowledge by searching the latest chemical\nliterature. Additionally, we introduce a novel Coarse-label Contrastive\nLearning (CCL) based chemical fingerprint that greatly enhances the agent's\nperformance in optimizing the reaction condition. With the above efforts, the\nproposed AI agent can autonomously generate the optimal reaction condition\nrecommendation without any human interaction. Further, the agent is highly\nprofessional in terms of chemical reactions. It demonstrates close-to-human\nperformance and strong generalization capability in both dry-lab and wet-lab\nexperiments. As the first attempt in the chemical AI agent, this work goes a\nstep further in the field of \"AI for chemistry\" and opens up new possibilities\nfor computer-aided synthesis planning.\n","authors":["Kexin Chen","Junyou Li","Kunyi Wang","Yuyang Du","Jiahui Yu","Jiamin Lu","Lanqing Li","Jiezhong Qiu","Qun Fang","Pheng Ann Heng","Guangyong Chen"],"pdf_url":"https://arxiv.org/pdf/2311.10776v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09049v2","updated":"2023-11-28T13:11:41Z","published":"2023-11-15T15:39:33Z","title":"Adapting Large Language Models by Integrating Collaborative Semantics\n  for Recommendation","summary":"  Recently, large language models (LLMs) have shown great potential in\nrecommender systems, either improving existing recommendation models or serving\nas the backbone. However, there exists a large semantic gap between LLMs and\nrecommender systems, since items to be recommended are often indexed by\ndiscrete identifiers (item ID) out of the LLM's vocabulary. In essence, LLMs\ncapture language semantics while recommender systems imply collaborative\nsemantics, making it difficult to sufficiently leverage the model capacity of\nLLMs for recommendation. To address this challenge, in this paper, we propose a\nnew LLM-based recommendation model called LC-Rec, which can better integrate\nlanguage and collaborative semantics for recommender systems. Our approach can\ndirectly generate items from the entire item set for recommendation, without\nrelying on candidate items. Specifically, we make two major contributions in\nour approach. For item indexing, we design a learning-based vector quantization\nmethod with uniform semantic mapping, which can assign meaningful and\nnon-conflicting IDs (called item indices) for items. For alignment tuning, we\npropose a series of specially designed tuning tasks to enhance the integration\nof collaborative semantics in LLMs. Our fine-tuning tasks enforce LLMs to\ndeeply integrate language and collaborative semantics (characterized by the\nlearned item indices), so as to achieve an effective adaptation to recommender\nsystems. Extensive experiments demonstrate the effectiveness of our method,\nshowing that our approach can outperform a number of competitive baselines\nincluding traditional recommenders and existing LLM-based recommenders. Our\ncode is available at https://github.com/RUCAIBox/LC-Rec/.\n","authors":["Bowen Zheng","Yupeng Hou","Hongyu Lu","Yu Chen","Wayne Xin Zhao","Ming Chen","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2311.09049v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16892v1","updated":"2023-11-28T15:43:46Z","published":"2023-11-28T15:43:46Z","title":"Enhancing Item-level Bundle Representation for Bundle Recommendation","summary":"  Bundle recommendation approaches offer users a set of related items on a\nparticular topic. The current state-of-the-art (SOTA) method utilizes\ncontrastive learning to learn representations at both the bundle and item\nlevels. However, due to the inherent difference between the bundle-level and\nitem-level preferences, the item-level representations may not receive\nsufficient information from the bundle affiliations to make accurate\npredictions. In this paper, we propose a novel approach EBRec, short of\nEnhanced Bundle Recommendation, which incorporates two enhanced modules to\nexplore inherent item-level bundle representations. First, we propose to\nincorporate the bundle-user-item (B-U-I) high-order correlations to explore\nmore collaborative information, thus to enhance the previous bundle\nrepresentation that solely relies on the bundle-item affiliation information.\nSecond, we further enhance the B-U-I correlations by augmenting the observed\nuser-item interactions with interactions generated from pre-trained models,\nthus improving the item-level bundle representations. We conduct extensive\nexperiments on three public datasets, and the results justify the effectiveness\nof our approach as well as the two core modules. Codes and datasets are\navailable at https://github.com/answermycode/EBRec.\n","authors":["Xiaoyu Du","Kun Qian","Yunshan Ma","Xinguang Xiang"],"pdf_url":"https://arxiv.org/pdf/2311.16892v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16878v1","updated":"2023-11-28T15:28:12Z","published":"2023-11-28T15:28:12Z","title":"Temporal Importance Factor for Loss Functions for CTR Prediction","summary":"  Click-through rate (CTR) prediction is an important task for the companies to\nrecommend products which better match user preferences. User behavior in\ndigital advertising is dynamic and changes over time. It is crucial for the\ncompanies to capture the most recent trends to provide more accurate\nrecommendations for users. In CTR prediction, most models use binary\ncross-entropy loss function. However, it does not focus on the data\ndistribution shifts occurring over time. To address this problem, we propose a\nfactor for the loss functions by utilizing the sequential nature of user-item\ninteractions. This approach aims to focus on the most recent samples by\npenalizing them more through the loss function without forgetting the long-term\ninformation. Our solution is model-agnostic, and the temporal importance factor\ncan be used with different loss functions. Offline experiments in both public\nand company datasets show that the temporal importance factor for loss\nfunctions outperforms the baseline loss functions considered.\n","authors":["Ramazan Tarık Türksoy","Beyza Türkmen","Furkan Durmuş"],"pdf_url":"https://arxiv.org/pdf/2311.16878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.11270v3","updated":"2023-11-28T13:57:46Z","published":"2023-10-17T13:42:32Z","title":"Graph Neural Networks for Recommendation: Reproducibility, Graph\n  Topology, and Node Representation","summary":"  Graph neural networks (GNNs) have gained prominence in recommendation systems\nin recent years. By representing the user-item matrix as a bipartite and\nundirected graph, GNNs have demonstrated their potential to capture short- and\nlong-distance user-item interactions, thereby learning more accurate preference\npatterns than traditional recommendation approaches. In contrast to previous\ntutorials on the same topic, this tutorial aims to present and examine three\nkey aspects that characterize GNNs for recommendation: (i) the reproducibility\nof state-of-the-art approaches, (ii) the potential impact of graph topological\ncharacteristics on the performance of these models, and (iii) strategies for\nlearning node representations when training features from scratch or utilizing\npre-trained embeddings as additional item information (e.g., multimodal\nfeatures). The goal is to provide three novel theoretical and practical\nperspectives on the field, currently subject to debate in graph learning but\nlong been overlooked in the context of recommendation systems.\n","authors":["Daniele Malitesta","Claudio Pomo","Tommaso Di Noia"],"pdf_url":"https://arxiv.org/pdf/2310.11270v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06985v4","updated":"2023-11-28T12:59:20Z","published":"2023-07-13T17:25:28Z","title":"Patent Documents to Engineering Design Knowledge Graphs","summary":"  Aimed at supporting knowledge-intensive tasks in the design process,\npopulating design knowledge from text documents involves the extraction of\ntriples - head entity :: relationship :: tail entity or h :: r :: t that could\nbe combined into a knowledge graph representation. As relationships are largely\nchosen from ontological or common-sense alternatives, knowledge graphs built\nusing these depict an approximation or restricted view of design knowledge,\nrather than what is explicated in text document. In this article, we present a\ndata-driven approach to identify and explicate facts (h :: r :: t) from\nsentences in patent documents. We create a dataset of 44,227 sentences and\nfacts, encompassing all patent classifications while also capturing the\nvariations among patent document sections. Using this dataset, we train taggers\nthat classify tokens to: 1) identify all entities (h) and relationships (r) and\n2) specific relationships (r) for a pair of entities (h :: ___ :: t). While\nthese taggers are built upon transformer-based sequence classification models,\nwe evaluate our proposed method against edge classification approaches that use\nlinear classifiers and graph neural networks, incorporating transformer-based\ntoken embeddings and linguistic features. The simplicity and coverage of the\nproposed method enable its application to patent documents at any scale and\nvariety. Upon deploying an open-source python package, we apply our method to\npatent documents related to fan systems. From the knowledge graphs thus\nextracted, we explain how facts could be generalised to domain ontologies as\nwell as be specified to subsystem levels. We also highlight the importance of\nknowledge graph representations by retrieving and explicating the knowledge of\nkey issues in fan systems, while holding a comparative discussion against\nopinions from ChatGPT.\n","authors":["L Siddharth","Jianxi Luo"],"pdf_url":"https://arxiv.org/pdf/2307.06985v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16751v1","updated":"2023-11-28T12:50:40Z","published":"2023-11-28T12:50:40Z","title":"MultiCBR: Multi-view Contrastive Learning for Bundle Recommendation","summary":"  Bundle recommendation seeks to recommend a bundle of related items to users\nto improve both user experience and the profits of platform. Existing bundle\nrecommendation models have progressed from capturing only user-bundle\ninteractions to the modeling of multiple relations among users, bundles and\nitems. CrossCBR, in particular, incorporates cross-view contrastive learning\ninto a two-view preference learning framework, significantly improving SOTA\nperformance. It does, however, have two limitations: 1) the two-view\nformulation does not fully exploit all the heterogeneous relations among users,\nbundles and items; and 2) the \"early contrast and late fusion\" framework is\nless effective in capturing user preference and difficult to generalize to\nmultiple views. In this paper, we present MultiCBR, a novel Multi-view\nContrastive learning framework for Bundle Recommendation. First, we devise a\nmulti-view representation learning framework capable of capturing all the\nuser-bundle, user-item and bundle-item relations, especially better utilizing\nthe bundle-item affiliations to enhance sparse bundles' representations.\nSecond, we innovatively adopt an \"early fusion and late contrast\" design that\nfirst fuses the multi-view representations before performing self-supervised\ncontrastive learning. In comparison to existing approaches, our framework\nreverses the order of fusion and contrast, introducing the following\nadvantages: 1)our framework is capable of modeling both cross-view and ego-view\npreferences, allowing us to achieve enhanced user preference modeling; and 2)\ninstead of requiring quadratic number of cross-view contrastive losses, we only\nrequire two self-supervised contrastive losses, resulting in minimal extra\ncosts. Experimental results on three public datasets indicate that our method\noutperforms SOTA methods.\n","authors":["Yunshan Ma","Yingzhi He","Xiang Wang","Yinwei Wei","Xiaoyu Du","Yuyangzi Fu","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2311.16751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16720v1","updated":"2023-11-28T12:04:19Z","published":"2023-11-28T12:04:19Z","title":"RankingGPT: Empowering Large Language Models in Text Ranking with\n  Progressive Enhancement","summary":"  Text ranking is a critical task in various information retrieval\napplications, and the recent success of Large Language Models (LLMs) in natural\nlanguage processing has sparked interest in their application to text ranking.\nThese methods primarily involve combining query and candidate documents and\nleveraging prompt learning to determine query-document relevance using the\nLLM's output probabilities for specific tokens or by directly generating a\nranked list of candidate documents. Although these approaches have demonstrated\npromise, a noteworthy disparity arises between the training objective of LLMs,\nwhich typically centers around next token prediction, and the objective of\nevaluating query-document relevance. To address this gap and fully leverage LLM\npotential in text ranking tasks, we propose a progressive multi-stage training\nstrategy. Firstly, we introduce a large-scale weakly supervised dataset of\nrelevance texts to enable the LLMs to acquire the ability to predict relevant\ntokens without altering their original training objective. Subsequently, we\nincorporate supervised training to further enhance LLM ranking capability. Our\nexperimental results on multiple benchmarks demonstrate the superior\nperformance of our proposed method compared to previous competitive approaches,\nboth in in-domain and out-of-domain scenarios.\n","authors":["Longhui Zhang","Yanzhao Zhang","Dingkun Long","Pengjun Xie","Meishan Zhang","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.16720v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2311.16716v1","updated":"2023-11-28T12:00:06Z","published":"2023-11-28T12:00:06Z","title":"Graph Pre-training and Prompt Learning for Recommendation","summary":"  GNN-based recommenders have excelled in modeling intricate user-item\ninteractions through multi-hop message passing. However, existing methods often\noverlook the dynamic nature of evolving user-item interactions, which impedes\nthe adaption to changing user preferences and distribution shifts in newly\narriving data. Thus, their scalability and performances in real-world dynamic\nenvironments are limited. In this study, we propose GraphPL, a framework that\nincorporates parameter-efficient and dynamic graph pre-training with prompt\nlearning. This novel combination empowers GNNs to effectively capture both\nlong-term user preferences and short-term behavior dynamics, enabling the\ndelivery of accurate and timely recommendations. Our GraphPL framework\naddresses the challenge of evolving user preferences by seamlessly integrating\na temporal prompt mechanism and a graph-structural prompt learning mechanism\ninto the pre-trained GNN model. The temporal prompt mechanism encodes time\ninformation on user-item interaction, allowing the model to naturally capture\ntemporal context, while the graph-structural prompt learning mechanism enables\nthe transfer of pre-trained knowledge to adapt to behavior dynamics without the\nneed for continuous incremental training. We further bring in a dynamic\nevaluation setting for recommendation to mimic real-world dynamic scenarios and\nbridge the offline-online gap to a better level. Our extensive experiments\nincluding a large-scale industrial deployment showcases the lightweight plug-in\nscalability of our GraphPL when integrated with various state-of-the-art\nrecommenders, emphasizing the advantages of GraphPL in terms of effectiveness,\nrobustness and efficiency.\n","authors":["Yuhao Yang","Lianghao Xia","Da Luo","Kangyi Lin","Chao Huang"],"pdf_url":"https://arxiv.org/pdf/2311.16716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16683v1","updated":"2023-11-28T10:55:00Z","published":"2023-11-28T10:55:00Z","title":"Hyper-Relational Knowledge Graph Neural Network for Next POI","summary":"  With the advancement of mobile technology, Point of Interest (POI)\nrecommendation systems in Location-based Social Networks (LBSN) have brought\nnumerous benefits to both users and companies. Many existing works employ\nKnowledge Graph (KG) to alleviate the data sparsity issue in LBSN. These\napproaches primarily focus on modeling the pair-wise relations in LBSN to\nenrich the semantics and thereby relieve the data sparsity issue. However,\nexisting approaches seldom consider the hyper-relations in LBSN, such as the\nmobility relation (a 3-ary relation: user-POI-time). This makes the model hard\nto exploit the semantics accurately. In addition, prior works overlook the rich\nstructural information inherent in KG, which consists of higher-order relations\nand can further alleviate the impact of data sparsity.To this end, we propose a\nHyper-Relational Knowledge Graph Neural Network (HKGNN) model. In HKGNN, a\nHyper-Relational Knowledge Graph (HKG) that models the LBSN data is constructed\nto maintain and exploit the rich semantics of hyper-relations. Then we proposed\na Hypergraph Neural Network to utilize the structural information of HKG in a\ncohesive way. In addition, a self-attention network is used to leverage\nsequential information and make personalized recommendations. Furthermore, side\ninformation, essential in reducing data sparsity by providing background\nknowledge of POIs, is not fully utilized in current methods. In light of this,\nwe extended the current dataset with available side information to further\nlessen the impact of data sparsity. Results of experiments on four real-world\nLBSN datasets demonstrate the effectiveness of our approach compared to\nexisting state-of-the-art methods.\n","authors":["Jixiao Zhang","Yongkang Li","Ruotong Zou","Jingyuan Zhang","Zipei Fan","Xuan Song"],"pdf_url":"https://arxiv.org/pdf/2311.16683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16603v1","updated":"2023-11-28T08:44:01Z","published":"2023-11-28T08:44:01Z","title":"l2Match: Optimization Techniques on Subgraph Matching Algorithm using\n  Label Pair, Neighboring Label Index, and Jump-Redo method","summary":"  Graph database is designed to store bidirectional relationships between\nobjects and facilitate the traversal process to extract a subgraph. However,\nthe subgraph matching process is an NP-Complete problem. Existing solutions to\nthis problem usually employ a filter-and-verification framework and a\ndivide-and-conquer method. The filter-and-verification framework minimizes the\nnumber of inputs to the verification stage by filtering and pruning invalid\ncandidates as much as possible. Meanwhile, subgraph matching is performed on\nthe substructure decomposed from the larger graph to yield partial embedding.\nSubsequently, the recursive traversal or set intersection technique combines\nthe partial embedding into a complete subgraph. In this paper, we first present\na comprehensive literature review of the state-of-the-art solutions. l2Match, a\nsubgraph isomorphism algorithm for small queries utilizing a Label-Pair Index\nand filtering method, is then proposed and presented as a proof of concept.\nEmpirical experimentation shows that l2Match outperforms related\nstate-of-the-art solutions, and the proposed methods optimize the existing\nalgorithms.\n","authors":["C. Q. Cheng","K. S. Wong","L. K. Soon"],"pdf_url":"https://arxiv.org/pdf/2311.16603v1.pdf","comment":"This short version of this article (6 pages) is accepted by ICEIC\n  2024"},{"id":"http://arxiv.org/abs/2311.16586v1","updated":"2023-11-28T08:03:56Z","published":"2023-11-28T08:03:56Z","title":"SARDINE: A Simulator for Automated Recommendation in Dynamic and\n  Interactive Environments","summary":"  Simulators can provide valuable insights for researchers and practitioners\nwho wish to improve recommender systems, because they allow one to easily tweak\nthe experimental setup in which recommender systems operate, and as a result\nlower the cost of identifying general trends and uncovering novel findings\nabout the candidate methods. A key requirement to enable this accelerated\nimprovement cycle is that the simulator is able to span the various sources of\ncomplexity that can be found in the real recommendation environment that it\nsimulates.\n  With the emergence of interactive and data-driven methods - e.g.,\nreinforcement learning or online and counterfactual learning-to-rank - that aim\nto achieve user-related goals beyond the traditional accuracy-centric\nobjectives, adequate simulators are needed. In particular, such simulators must\nmodel the various mechanisms that render the recommendation environment dynamic\nand interactive, e.g., the effect of recommendations on the user or the effect\nof biased data on subsequent iterations of the recommender system. We therefore\npropose SARDINE, a flexible and interpretable recommendation simulator that can\nhelp accelerate research in interactive and data-driven recommender systems. We\ndemonstrate its usefulness by studying existing methods within nine diverse\nenvironments derived from SARDINE, and even uncover novel insights about them.\n","authors":["Romain Deffayet","Thibaut Thonet","Dongyoon Hwang","Vassilissa Lehoux","Jean-Michel Renders","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2311.16586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16441v1","updated":"2023-11-28T02:43:02Z","published":"2023-11-28T02:43:02Z","title":"ControlRec: Bridging the Semantic Gap between Language Model and\n  Personalized Recommendation","summary":"  The successful integration of large language models (LLMs) into\nrecommendation systems has proven to be a major breakthrough in recent studies,\npaving the way for more generic and transferable recommendations. However, LLMs\nstruggle to effectively utilize user and item IDs, which are crucial\nidentifiers for successful recommendations. This is mainly due to their\ndistinct representation in a semantic space that is different from the natural\nlanguage (NL) typically used to train LLMs. To tackle such issue, we introduce\nControlRec, an innovative Contrastive prompt learning framework for\nRecommendation systems. ControlRec treats user IDs and NL as heterogeneous\nfeatures and encodes them individually. To promote greater alignment and\nintegration between them in the semantic space, we have devised two auxiliary\ncontrastive objectives: (1) Heterogeneous Feature Matching (HFM) aligning item\ndescription with the corresponding ID or user's next preferred ID based on\ntheir interaction sequence, and (2) Instruction Contrastive Learning (ICL)\neffectively merging these two crucial data sources by contrasting probability\ndistributions of output sequences generated by diverse tasks. Experimental\nresults on four public real-world datasets demonstrate the effectiveness of the\nproposed method on improving model performance.\n","authors":["Junyan Qiu","Haitao Wang","Zhaolin Hong","Yiping Yang","Qiang Liu","Xingxing Wang"],"pdf_url":"https://arxiv.org/pdf/2311.16441v1.pdf","comment":"11 pages, 7 figures"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2310.06627v3","updated":"2023-11-28T15:57:16Z","published":"2023-10-10T13:45:59Z","title":"What If the TV Was Off? Examining Counterfactual Reasoning Abilities of\n  Multi-modal Language Models","summary":"  Counterfactual reasoning, a fundamental aspect of human cognition, involves\ncontemplating alternatives to established facts or past events, significantly\nenhancing our abilities in planning and decision-making. In light of the\nadvancements in current multi-modal large language models, we explore their\neffectiveness in counterfactual reasoning. To facilitate this investigation, we\nintroduce a novel dataset, C-VQA, specifically designed to test the\ncounterfactual reasoning capabilities of modern multi-modal large language\nmodels. This dataset is constructed by infusing original questions with\ncounterfactual presuppositions, spanning various types such as numerical and\nboolean queries. It encompasses a mix of real and synthetic data, representing\na wide range of difficulty levels. Our thorough evaluations of contemporary\nvision-language models using this dataset have revealed substantial performance\ndrops, with some models showing up to a 40% decrease, highlighting a\nsignificant gap between current models and human-like vision reasoning\ncapabilities. We hope our dataset will serve as a vital benchmark for\nevaluating the counterfactual reasoning capabilities of models. Code and\ndataset are publicly available at https://bzhao.me/C-VQA/.\n","authors":["Letian Zhang","Xiaotong Zhai","Zhongkai Zhao","Yongshuo Zong","Xin Wen","Bingchen Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.06627v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15951v2","updated":"2023-11-28T15:18:43Z","published":"2023-11-27T15:57:11Z","title":"Replay across Experiments: A Natural Extension of Off-Policy RL","summary":"  Replaying data is a principal mechanism underlying the stability and data\nefficiency of off-policy reinforcement learning (RL). We present an effective\nyet simple framework to extend the use of replays across multiple experiments,\nminimally adapting the RL workflow for sizeable improvements in controller\nperformance and research iteration times. At its core, Replay Across\nExperiments (RaE) involves reusing experience from previous experiments to\nimprove exploration and bootstrap learning while reducing required changes to a\nminimum in comparison to prior work. We empirically show benefits across a\nnumber of RL algorithms and challenging control domains spanning both\nlocomotion and manipulation, including hard exploration tasks from egocentric\nvision. Through comprehensive ablations, we demonstrate robustness to the\nquality and amount of data available and various hyperparameter choices.\nFinally, we discuss how our approach can be applied more broadly across\nresearch life cycles and can increase resilience by reloading data across\nrandom seeds or hyperparameter variations.\n","authors":["Dhruva Tirumala","Thomas Lampe","Jose Enrique Chen","Tuomas Haarnoja","Sandy Huang","Guy Lever","Ben Moran","Tim Hertweck","Leonard Hasenclever","Martin Riedmiller","Nicolas Heess","Markus Wulfmeier"],"pdf_url":"https://arxiv.org/pdf/2311.15951v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15936v2","updated":"2023-11-28T18:22:44Z","published":"2023-11-27T15:45:02Z","title":"Towards Responsible Governance of Biological Design Tools","summary":"  Recent advancements in generative machine learning have enabled rapid\nprogress in biological design tools (BDTs) such as protein structure and\nsequence prediction models. The unprecedented predictive accuracy and novel\ndesign capabilities of BDTs present new and significant dual-use risks. For\nexample, their predictive accuracy allows biological agents, whether vaccines\nor pathogens, to be developed more quickly, while the design capabilities could\nbe used to discover drugs or evade DNA screening techniques. Similar to other\ndual-use AI systems, BDTs present a wicked problem: how can regulators uphold\npublic safety without stifling innovation? We highlight how current regulatory\nproposals that are primarily tailored toward large language models may be less\neffective for BDTs, which require fewer computational resources to train and\nare often developed in an open-source manner. We propose a range of measures to\nmitigate the risk that BDTs are misused, across the areas of responsible\ndevelopment, risk assessment, transparency, access management, cybersecurity,\nand investing in resilience. Implementing such measures will require close\ncoordination between developers and governments.\n","authors":["Richard Moulange","Max Langenkamp","Tessa Alexanian","Samuel Curtis","Morgan Livingston"],"pdf_url":"https://arxiv.org/pdf/2311.15936v2.pdf","comment":"10 pages + references, 1 figure, accepted at NeurIPS 2023 Workshop on\n  Regulatable ML as oral presentation"},{"id":"http://arxiv.org/abs/2308.12532v3","updated":"2023-11-28T03:42:45Z","published":"2023-08-24T03:43:02Z","title":"FedSOL: Stabilized Orthogonal Learning in Federated Learning","summary":"  Federated Learning (FL) aggregates locally trained models from individual\nclients to construct a global model. While FL enables learning a model with\ndata privacy, it often suffers from significant performance degradation when\nclient data distributions are heterogeneous. Many previous FL algorithms have\naddressed this issue by introducing various proximal restrictions. These\nrestrictions aim to encourage global alignment by constraining the deviation of\nlocal learning from the global objective. However, they inherently limit local\nlearning by interfering with the original local objectives. Recently, an\nalternative approach has emerged to improve local learning generality. By\nobtaining local models within a smooth loss landscape, this approach mitigates\nconflicts among different local objectives of the clients. Yet, it does not\nensure stable global alignment, as local learning does not take the global\nobjective into account. In this study, we propose Federated Stability on\nLearning (FedSoL), which combines both the concepts of global alignment and\nlocal generality. In FedSoL, the local learning seeks a parameter region robust\nagainst proximal perturbations. This strategy introduces an implicit proximal\nrestriction effect in local learning while maintaining the original local\nobjective for parameter update. Our experiments show that FedSoL consistently\nachieves state-of-the-art performance on various setups.\n","authors":["Gihun Lee","Minchan Jeong","Sangmook Kim","Jaehoon Oh","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2308.12532v3.pdf","comment":"19 pages, 12 figures"},{"id":"http://arxiv.org/abs/2311.17059v1","updated":"2023-11-28T18:59:58Z","published":"2023-11-28T18:59:58Z","title":"Mission-driven Exploration for Accelerated Deep Reinforcement Learning\n  with Temporal Logic Task Specifications","summary":"  This paper addresses the problem of designing optimal control policies for\nmobile robots with mission and safety requirements specified using Linear\nTemporal Logic (LTL). We consider robots with unknown stochastic dynamics\noperating in environments with unknown geometric structure. The robots are\nequipped with sensors allowing them to detect obstacles. Our goal is to\nsynthesize a control policy that maximizes the probability of satisfying an\nLTL-encoded task in the presence of motion and environmental uncertainty.\nSeveral deep reinforcement learning (DRL) algorithms have been proposed\nrecently to address similar problems. A common limitation in related works is\nthat of slow learning performance. In order to address this issue, we propose a\nnovel DRL algorithm, which has the capability to learn control policies at a\nnotably faster rate compared to similar methods. Its sample efficiency is due\nto a mission-driven exploration strategy that prioritizes exploration towards\ndirections that may contribute to mission accomplishment. Identifying these\ndirections relies on an automaton representation of the LTL task as well as a\nlearned neural network that (partially) models the unknown system dynamics. We\nprovide comparative experiments demonstrating the efficiency of our algorithm\non robot navigation tasks in unknown environments.\n","authors":["Jun Wang","Hosein Hasanbeig","Kaiyuan Tan","Zihe Sun","Yiannis Kantaros"],"pdf_url":"https://arxiv.org/pdf/2311.17059v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17055v1","updated":"2023-11-28T18:59:46Z","published":"2023-11-28T18:59:46Z","title":"No Representation Rules Them All in Category Discovery","summary":"  In this paper we tackle the problem of Generalized Category Discovery (GCD).\nSpecifically, given a dataset with labelled and unlabelled images, the task is\nto cluster all images in the unlabelled subset, whether or not they belong to\nthe labelled categories. Our first contribution is to recognize that most\nexisting GCD benchmarks only contain labels for a single clustering of the\ndata, making it difficult to ascertain whether models are using the available\nlabels to solve the GCD task, or simply solving an unsupervised clustering\nproblem. As such, we present a synthetic dataset, named 'Clevr-4', for category\ndiscovery. Clevr-4 contains four equally valid partitions of the data, i.e\nbased on object shape, texture, color or count. To solve the task, models are\nrequired to extrapolate the taxonomy specified by the labelled set, rather than\nsimply latching onto a single natural grouping of the data. We use this dataset\nto demonstrate the limitations of unsupervised clustering in the GCD setting,\nshowing that even very strong unsupervised models fail on Clevr-4. We further\nuse Clevr-4 to examine the weaknesses of existing GCD algorithms, and propose a\nnew method which addresses these shortcomings, leveraging consistent findings\nfrom the representation learning literature to do so. Our simple solution,\nwhich is based on 'mean teachers' and termed $\\mu$GCD, substantially\noutperforms implemented baselines on Clevr-4. Finally, when we transfer these\nfindings to real data on the challenging Semantic Shift Benchmark (SSB), we\nfind that $\\mu$GCD outperforms all prior work, setting a new state-of-the-art.\nFor the project webpage, see https://www.robots.ox.ac.uk/~vgg/data/clevr4/\n","authors":["Sagar Vaze","Andrea Vedaldi","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2311.17055v1.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2309.01291v2","updated":"2023-11-28T18:59:31Z","published":"2023-09-03T23:47:21Z","title":"Generative Social Choice","summary":"  Traditionally, social choice theory has only been applicable to choices among\na few predetermined alternatives but not to more complex decisions such as\ncollectively selecting a textual statement. We introduce generative social\nchoice, a framework that combines the mathematical rigor of social choice\ntheory with the capability of large language models to generate text and\nextrapolate preferences. This framework divides the design of AI-augmented\ndemocratic processes into two components: first, proving that the process\nsatisfies rigorous representation guarantees when given access to oracle\nqueries; second, empirically validating that these queries can be approximately\nimplemented using a large language model. We apply this framework to the\nproblem of generating a slate of statements that is representative of opinions\nexpressed as free-form text; specifically, we develop a democratic process with\nrepresentation guarantees and use this process to represent the opinions of\nparticipants in a survey about chatbot personalization. We find that 93 out of\n100 participants feel \"mostly\" or \"perfectly\" represented by the slate of five\nstatements we extracted.\n","authors":["Sara Fish","Paul Gölz","David C. Parkes","Ariel D. Procaccia","Gili Rusak","Itai Shapira","Manuel Wüthrich"],"pdf_url":"https://arxiv.org/pdf/2309.01291v2.pdf","comment":"Substantially revised with non-approval utility model, new\n  representation axiom (balanced justified representation), and real-world case\n  study"},{"id":"http://arxiv.org/abs/2311.17053v1","updated":"2023-11-28T18:58:48Z","published":"2023-11-28T18:58:48Z","title":"DiffuseBot: Breeding Soft Robots With Physics-Augmented Generative\n  Diffusion Models","summary":"  Nature evolves creatures with a high complexity of morphological and\nbehavioral intelligence, meanwhile computational methods lag in approaching\nthat diversity and efficacy. Co-optimization of artificial creatures'\nmorphology and control in silico shows promise for applications in physical\nsoft robotics and virtual character creation; such approaches, however, require\ndeveloping new learning algorithms that can reason about function atop pure\nstructure. In this paper, we present DiffuseBot, a physics-augmented diffusion\nmodel that generates soft robot morphologies capable of excelling in a wide\nspectrum of tasks. DiffuseBot bridges the gap between virtually generated\ncontent and physical utility by (i) augmenting the diffusion process with a\nphysical dynamical simulation which provides a certificate of performance, and\n(ii) introducing a co-design procedure that jointly optimizes physical design\nand control by leveraging information about physical sensitivities from\ndifferentiable simulation. We showcase a range of simulated and fabricated\nrobots along with their capabilities. Check our website at\nhttps://diffusebot.github.io/\n","authors":["Tsun-Hsuan Wang","Juntian Zheng","Pingchuan Ma","Yilun Du","Byungchul Kim","Andrew Spielberg","Joshua Tenenbaum","Chuang Gan","Daniela Rus"],"pdf_url":"https://arxiv.org/pdf/2311.17053v1.pdf","comment":"NeurIPS 2023. Project page: https://diffusebot.github.io/"},{"id":"http://arxiv.org/abs/2311.17049v1","updated":"2023-11-28T18:55:42Z","published":"2023-11-28T18:55:42Z","title":"MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced\n  Training","summary":"  Contrastive pretraining of image-text foundation models, such as CLIP,\ndemonstrated excellent zero-shot performance and improved robustness on a wide\nrange of downstream tasks. However, these models utilize large\ntransformer-based encoders with significant memory and latency overhead which\npose challenges for deployment on mobile devices. In this work, we introduce\nMobileCLIP -- a new family of efficient image-text models optimized for runtime\nperformance along with a novel and efficient training approach, namely\nmulti-modal reinforced training. The proposed training approach leverages\nknowledge transfer from an image captioning model and an ensemble of strong\nCLIP encoders to improve the accuracy of efficient models. Our approach avoids\ntrain-time compute overhead by storing the additional knowledge in a reinforced\ndataset. MobileCLIP sets a new state-of-the-art latency-accuracy tradeoff for\nzero-shot classification and retrieval tasks on several datasets. Our\nMobileCLIP-S2 variant is 2.3$\\times$ faster while more accurate compared to\nprevious best CLIP model based on ViT-B/16. We further demonstrate the\neffectiveness of our multi-modal reinforced training by training a CLIP model\nbased on ViT-B/16 image backbone and achieving +2.9% average performance\nimprovement on 38 evaluation benchmarks compared to the previous best.\nMoreover, we show that the proposed approach achieves 10$\\times$-1000$\\times$\nimproved learning efficiency when compared with non-reinforced CLIP training.\n","authors":["Pavan Kumar Anasosalu Vasu","Hadi Pouransari","Fartash Faghri","Raviteja Vemulapalli","Oncel Tuzel"],"pdf_url":"https://arxiv.org/pdf/2311.17049v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17035v1","updated":"2023-11-28T18:47:03Z","published":"2023-11-28T18:47:03Z","title":"Scalable Extraction of Training Data from (Production) Language Models","summary":"  This paper studies extractable memorization: training data that an adversary\ncan efficiently extract by querying a machine learning model without prior\nknowledge of the training dataset. We show an adversary can extract gigabytes\nof training data from open-source language models like Pythia or GPT-Neo,\nsemi-open models like LLaMA or Falcon, and closed models like ChatGPT. Existing\ntechniques from the literature suffice to attack unaligned models; in order to\nattack the aligned ChatGPT, we develop a new divergence attack that causes the\nmodel to diverge from its chatbot-style generations and emit training data at a\nrate 150x higher than when behaving properly. Our methods show practical\nattacks can recover far more data than previously thought, and reveal that\ncurrent alignment techniques do not eliminate memorization.\n","authors":["Milad Nasr","Nicholas Carlini","Jonathan Hayase","Matthew Jagielski","A. Feder Cooper","Daphne Ippolito","Christopher A. Choquette-Choo","Eric Wallace","Florian Tramèr","Katherine Lee"],"pdf_url":"https://arxiv.org/pdf/2311.17035v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11876v2","updated":"2023-11-28T18:36:13Z","published":"2023-11-20T16:12:34Z","title":"Forward Gradients for Data-Driven CFD Wall Modeling","summary":"  Computational Fluid Dynamics (CFD) is used in the design and optimization of\ngas turbines and many other industrial/ scientific applications. However, the\npractical use is often limited by the high computational cost, and the accurate\nresolution of near-wall flow is a significant contributor to this cost. Machine\nlearning (ML) and other data-driven methods can complement existing wall\nmodels. Nevertheless, training these models is bottlenecked by the large\ncomputational effort and memory footprint demanded by back-propagation. Recent\nwork has presented alternatives for computing gradients of neural networks\nwhere a separate forward and backward sweep is not needed and storage of\nintermediate results between sweeps is not required because an unbiased\nestimator for the gradient is computed in a single forward sweep. In this\npaper, we discuss the application of this approach for training a subgrid wall\nmodel that could potentially be used as a surrogate in wall-bounded flow CFD\nsimulations to reduce the computational overhead while preserving predictive\naccuracy.\n","authors":["Jan Hückelheim","Tadbhagya Kumar","Krishnan Raghavan","Pinaki Pal"],"pdf_url":"https://arxiv.org/pdf/2311.11876v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10498v3","updated":"2023-11-28T18:33:37Z","published":"2023-05-17T18:06:43Z","title":"Edge Directionality Improves Learning on Heterophilic Graphs","summary":"  Graph Neural Networks (GNNs) have become the de-facto standard tool for\nmodeling relational data. However, while many real-world graphs are directed,\nthe majority of today's GNN models discard this information altogether by\nsimply making the graph undirected. The reasons for this are historical: 1)\nmany early variants of spectral GNNs explicitly required undirected graphs, and\n2) the first benchmarks on homophilic graphs did not find significant gain from\nusing direction. In this paper, we show that in heterophilic settings, treating\nthe graph as directed increases the effective homophily of the graph,\nsuggesting a potential gain from the correct use of directionality information.\nTo this end, we introduce Directed Graph Neural Network (Dir-GNN), a novel\ngeneral framework for deep learning on directed graphs. Dir-GNN can be used to\nextend any Message Passing Neural Network (MPNN) to account for edge\ndirectionality information by performing separate aggregations of the incoming\nand outgoing edges. We prove that Dir-GNN matches the expressivity of the\nDirected Weisfeiler-Lehman test, exceeding that of conventional MPNNs. In\nextensive experiments, we validate that while our framework leaves performance\nunchanged on homophilic datasets, it leads to large gains over base models such\nas GCN, GAT and GraphSage on heterophilic benchmarks, outperforming much more\ncomplex methods and achieving new state-of-the-art results.\n","authors":["Emanuele Rossi","Bertrand Charpentier","Francesco Di Giovanni","Fabrizio Frasca","Stephan Günnemann","Michael Bronstein"],"pdf_url":"https://arxiv.org/pdf/2305.10498v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17030v1","updated":"2023-11-28T18:32:19Z","published":"2023-11-28T18:32:19Z","title":"Is This the Subspace You Are Looking for? An Interpretability Illusion\n  for Subspace Activation Patching","summary":"  Mechanistic interpretability aims to understand model behaviors in terms of\nspecific, interpretable features, often hypothesized to manifest as\nlow-dimensional subspaces of activations. Specifically, recent studies have\nexplored subspace interventions (such as activation patching) as a way to\nsimultaneously manipulate model behavior and attribute the features behind it\nto given subspaces.\n  In this work, we demonstrate that these two aims diverge, potentially leading\nto an illusory sense of interpretability. Counterintuitively, even if a\nsubspace intervention makes the model's output behave as if the value of a\nfeature was changed, this effect may be achieved by activating a dormant\nparallel pathway leveraging another subspace that is causally disconnected from\nmodel outputs. We demonstrate this phenomenon in a distilled mathematical\nexample, in two real-world domains (the indirect object identification task and\nfactual recall), and present evidence for its prevalence in practice. In the\ncontext of factual recall, we further show a link to rank-1 fact editing,\nproviding a mechanistic explanation for previous work observing an\ninconsistency between fact editing performance and fact localization.\n  However, this does not imply that activation patching of subspaces is\nintrinsically unfit for interpretability. To contextualize our findings, we\nalso show what a success case looks like in a task (indirect object\nidentification) where prior manual circuit analysis informs an understanding of\nthe location of a feature. We explore the additional evidence needed to argue\nthat a patched subspace is faithful.\n","authors":["Aleksandar Makelov","Georg Lange","Neel Nanda"],"pdf_url":"https://arxiv.org/pdf/2311.17030v1.pdf","comment":"NeurIPS 2023 Workshop on Attributing Model Behavior at Scale"},{"id":"http://arxiv.org/abs/2311.09312v2","updated":"2023-11-28T18:31:07Z","published":"2023-11-15T19:12:47Z","title":"H-Packer: Holographic Rotationally Equivariant Convolutional Neural\n  Network for Protein Side-Chain Packing","summary":"  Accurately modeling protein 3D structure is essential for the design of\nfunctional proteins. An important sub-task of structure modeling is protein\nside-chain packing: predicting the conformation of side-chains (rotamers) given\nthe protein's backbone structure and amino-acid sequence. Conventional\napproaches for this task rely on expensive sampling procedures over\nhand-crafted energy functions and rotamer libraries. Recently, several deep\nlearning methods have been developed to tackle the problem in a data-driven\nway, albeit with vastly different formulations (from image-to-image translation\nto directly predicting atomic coordinates). Here, we frame the problem as a\njoint regression over the side-chains' true degrees of freedom: the dihedral\n$\\chi$ angles. We carefully study possible objective functions for this task,\nwhile accounting for the underlying symmetries of the task. We propose\nHolographic Packer (H-Packer), a novel two-stage algorithm for side-chain\npacking built on top of two light-weight rotationally equivariant neural\nnetworks. We evaluate our method on CASP13 and CASP14 targets. H-Packer is\ncomputationally efficient and shows favorable performance against conventional\nphysics-based algorithms and is competitive against alternative deep learning\nsolutions.\n","authors":["Gian Marco Visani","William Galvin","Michael Neal Pun","Armita Nourmohammad"],"pdf_url":"https://arxiv.org/pdf/2311.09312v2.pdf","comment":"Accepted as a conference paper at MLCB 2023. 8 pages main body, 20\n  pages with appendix. 10 figures"},{"id":"http://arxiv.org/abs/2311.12878v2","updated":"2023-11-28T18:29:09Z","published":"2023-11-20T17:59:30Z","title":"Adaptive Bayesian Learning with Action and State-Dependent Signal\n  Variance","summary":"  This manuscript presents an advanced framework for Bayesian learning by\nincorporating action and state-dependent signal variances into decision-making\nmodels. This framework is pivotal in understanding complex data-feedback loops\nand decision-making processes in various economic systems. Through a series of\nexamples, we demonstrate the versatility of this approach in different\ncontexts, ranging from simple Bayesian updating in stable environments to\ncomplex models involving social learning and state-dependent uncertainties. The\npaper uniquely contributes to the understanding of the nuanced interplay\nbetween data, actions, outcomes, and the inherent uncertainty in economic\nmodels.\n","authors":["Kaiwen Hou"],"pdf_url":"https://arxiv.org/pdf/2311.12878v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17026v1","updated":"2023-11-28T18:28:03Z","published":"2023-11-28T18:28:03Z","title":"When the Few Outweigh the Many: Illicit Content Recognition with\n  Few-Shot Learning","summary":"  The anonymity and untraceability benefits of the Dark web account for the\nexponentially-increased potential of its popularity while creating a suitable\nwomb for many illicit activities, to date. Hence, in collaboration with\ncybersecurity and law enforcement agencies, research has provided approaches\nfor recognizing and classifying illicit activities with most exploiting textual\ndark web markets' content recognition; few such approaches use images that\noriginated from dark web content. This paper investigates this alternative\ntechnique for recognizing illegal activities from images. In particular, we\ninvestigate label-agnostic learning techniques like One-Shot and Few-Shot\nlearning featuring the use Siamese neural networks, a state-of-the-art approach\nin the field. Our solution manages to handle small-scale datasets with\npromising accuracy. In particular, Siamese neural networks reach 90.9% on\n20-Shot experiments over a 10-class dataset; this leads us to conclude that\nsuch models are a promising and cheaper alternative to the definition of\nautomated law-enforcing machinery over the dark web.\n","authors":["G. Cascavilla","G. Catolino","M. Conti","D. Mellios","D. A. Tamburri"],"pdf_url":"https://arxiv.org/pdf/2311.17026v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17007v1","updated":"2023-11-28T18:02:06Z","published":"2023-11-28T18:02:06Z","title":"Computational Hypergraph Discovery, a Gaussian Process framework for\n  connecting the dots","summary":"  Most scientific challenges can be framed into one of the following three\nlevels of complexity of function approximation. Type 1: Approximate an unknown\nfunction given input/output data. Type 2: Consider a collection of variables\nand functions, some of which are unknown, indexed by the nodes and hyperedges\nof a hypergraph (a generalized graph where edges can connect more than two\nvertices). Given partial observations of the variables of the hypergraph\n(satisfying the functional dependencies imposed by its structure), approximate\nall the unobserved variables and unknown functions. Type 3: Expanding on Type\n2, if the hypergraph structure itself is unknown, use partial observations of\nthe variables of the hypergraph to discover its structure and approximate its\nunknown functions. While most Computational Science and Engineering and\nScientific Machine Learning challenges can be framed as Type 1 and Type 2\nproblems, many scientific problems can only be categorized as Type 3. Despite\ntheir prevalence, these Type 3 challenges have been largely overlooked due to\ntheir inherent complexity. Although Gaussian Process (GP) methods are sometimes\nperceived as well-founded but old technology limited to Type 1 curve fitting,\ntheir scope has recently been expanded to Type 2 problems. In this paper, we\nintroduce an interpretable GP framework for Type 3 problems, targeting the\ndata-driven discovery and completion of computational hypergraphs. Our approach\nis based on a kernel generalization of Row Echelon Form reduction from linear\nsystems to nonlinear ones and variance-based analysis. Here, variables are\nlinked via GPs and those contributing to the highest data variance unveil the\nhypergraph's structure. We illustrate the scope and efficiency of the proposed\napproach with applications to (algebraic) equation discovery, network discovery\n(gene pathways, chemical, and mechanical) and raw data analysis.\n","authors":["Théo Bourdais","Pau Batlle","Xianjin Yang","Ricardo Baptista","Nicolas Rouquette","Houman Owhadi"],"pdf_url":"https://arxiv.org/pdf/2311.17007v1.pdf","comment":"The code for the algorithm introduced in this paper and its\n  application to various examples are available for download (and as as an\n  installable python library/package) at\n  https://github.com/TheoBourdais/ComputationalHypergraphDiscovery"},{"id":"http://arxiv.org/abs/2311.17008v1","updated":"2023-11-28T18:02:06Z","published":"2023-11-28T18:02:06Z","title":"An Investigation of Time Reversal Symmetry in Reinforcement Learning","summary":"  One of the fundamental challenges associated with reinforcement learning (RL)\nis that collecting sufficient data can be both time-consuming and expensive. In\nthis paper, we formalize a concept of time reversal symmetry in a Markov\ndecision process (MDP), which builds upon the established structure of\ndynamically reversible Markov chains (DRMCs) and time-reversibility in\nclassical physics. Specifically, we investigate the utility of this concept in\nreducing the sample complexity of reinforcement learning. We observe that\nutilizing the structure of time reversal in an MDP allows every environment\ntransition experienced by an agent to be transformed into a feasible\nreverse-time transition, effectively doubling the number of experiences in the\nenvironment. To test the usefulness of this newly synthesized data, we develop\na novel approach called time symmetric data augmentation (TSDA) and investigate\nits application in both proprioceptive and pixel-based state within the realm\nof off-policy, model-free RL. Empirical evaluations showcase how these\nsynthetic transitions can enhance the sample efficiency of RL agents in time\nreversible scenarios without friction or contact. We also test this method in\nmore realistic environments where these assumptions are not globally satisfied.\nWe find that TSDA can significantly degrade sample efficiency and policy\nperformance, but can also improve sample efficiency under the right conditions.\nUltimately we conclude that time symmetry shows promise in enhancing the sample\nefficiency of reinforcement learning and provide guidance when the environment\nand reward structures are of an appropriate form for TSDA to be employed\neffectively.\n","authors":["Brett Barkley","Amy Zhang","David Fridovich-Keil"],"pdf_url":"https://arxiv.org/pdf/2311.17008v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17006v1","updated":"2023-11-28T17:59:49Z","published":"2023-11-28T17:59:49Z","title":"On the Impact of Sampling on Deep Sequential State Estimation","summary":"  State inference and parameter learning in sequential models can be\nsuccessfully performed with approximation techniques that maximize the evidence\nlower bound to the marginal log-likelihood of the data distribution. These\nmethods may be referred to as Dynamical Variational Autoencoders, and our\nspecific focus lies on the deep Kalman filter. It has been shown that the ELBO\nobjective can oversimplify data representations, potentially compromising\nestimation quality. Tighter Monte Carlo objectives have been proposed in the\nliterature to enhance generative modeling performance. For instance, the IWAE\nobjective uses importance weights to reduce the variance of marginal\nlog-likelihood estimates. In this paper, importance sampling is applied to the\nDKF framework for learning deep Markov models, resulting in the IW-DKF, which\nshows an improvement in terms of log-likelihood estimates and KL divergence\nbetween the variational distribution and the transition model. The framework\nusing the sampled DKF update rule is also accommodated to address sequential\nstate and parameter estimation when working with highly non-linear\nphysics-based models. An experiment with the 3-space Lorenz attractor shows an\nenhanced generative modeling performance and also a decrease in RMSE when\nestimating the model parameters and latent states, indicating that tighter MCOs\nlead to improved state inference performance.\n","authors":["Helena Calatrava","Ricardo Augusto Borsoi","Tales Imbiriba","Pau Closas"],"pdf_url":"https://arxiv.org/pdf/2311.17006v1.pdf","comment":"To appear in the Proceedings of the Asilomar Conference on Signals,\n  Systems, and Computers, October 2023, 5 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2311.16996v1","updated":"2023-11-28T17:48:18Z","published":"2023-11-28T17:48:18Z","title":"Goal-conditioned Offline Planning from Curious Exploration","summary":"  Curiosity has established itself as a powerful exploration strategy in deep\nreinforcement learning. Notably, leveraging expected future novelty as\nintrinsic motivation has been shown to efficiently generate exploratory\ntrajectories, as well as a robust dynamics model. We consider the challenge of\nextracting goal-conditioned behavior from the products of such unsupervised\nexploration techniques, without any additional environment interaction. We find\nthat conventional goal-conditioned reinforcement learning approaches for\nextracting a value function and policy fall short in this difficult offline\nsetting. By analyzing the geometry of optimal goal-conditioned value functions,\nwe relate this issue to a specific class of estimation artifacts in learned\nvalues. In order to mitigate their occurrence, we propose to combine\nmodel-based planning over learned value landscapes with a graph-based value\naggregation scheme. We show how this combination can correct both local and\nglobal artifacts, obtaining significant improvements in zero-shot goal-reaching\nperformance across diverse simulated environments.\n","authors":["Marco Bagatella","Georg Martius"],"pdf_url":"https://arxiv.org/pdf/2311.16996v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16984v1","updated":"2023-11-28T17:35:38Z","published":"2023-11-28T17:35:38Z","title":"FedECA: A Federated External Control Arm Method for Causal Inference\n  with Time-To-Event Data in Distributed Settings","summary":"  External control arms (ECA) can inform the early clinical development of\nexperimental drugs and provide efficacy evidence for regulatory approval in\nnon-randomized settings. However, the main challenge of implementing ECA lies\nin accessing real-world data or historical clinical trials. Indeed, data\nsharing is often not feasible due to privacy considerations related to data\nleaving the original collection centers, along with pharmaceutical companies'\ncompetitive motives. In this paper, we leverage a privacy-enhancing technology\ncalled federated learning (FL) to remove some of the barriers to data sharing.\nWe introduce a federated learning inverse probability of treatment weighted\n(IPTW) method for time-to-event outcomes called FedECA which eases the\nimplementation of ECA by limiting patients' data exposure. We show with\nextensive experiments that FedECA outperforms its closest competitor,\nmatching-adjusted indirect comparison (MAIC), in terms of statistical power and\nability to balance the treatment and control groups. To encourage the use of\nsuch methods, we publicly release our code which relies on Substra, an\nopen-source FL software with proven experience in privacy-sensitive contexts.\n","authors":["Jean Ogier du Terrail","Quentin Klopfenstein","Honghao Li","Imke Mayer","Nicolas Loiseau","Mohammad Hallal","Félix Balazard","Mathieu Andreux"],"pdf_url":"https://arxiv.org/pdf/2311.16984v1.pdf","comment":"code available at: https://github.com/owkin/fedeca"},{"id":"http://arxiv.org/abs/2311.16977v1","updated":"2023-11-28T17:25:16Z","published":"2023-11-28T17:25:16Z","title":"Bidirectional Reactive Programming for Machine Learning","summary":"  Reactive languages are dedicated to the programming of systems which interact\ncontinuously and concurrently with their environment. Values take the form of\nunbounded streams modeling the (discrete) passing of time or the sequence of\nconcurrent interactions. While conventional reactivity models recurrences\nforward in time, we introduce a symmetric reactive construct enabling backward\nrecurrences. Constraints on the latter allow to make the implementation\npractical. Machine Learning (ML) systems provide numerous motivations for all\nof this: we demonstrate that reverse-mode automatic differentiation,\nbackpropagation, batch normalization, bidirectional recurrent neural networks,\ntraining and reinforcement learning algorithms, are all naturally captured as\nbidirectional reactive programs.\n","authors":["Dumitru Potop Butucaru","Albert Cohen","Gordon Plotkin","Hugo Pompougnac"],"pdf_url":"https://arxiv.org/pdf/2311.16977v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.16847v2","updated":"2023-11-28T17:24:29Z","published":"2023-08-31T16:26:17Z","title":"Diffusion Models for Interferometric Satellite Aperture Radar","summary":"  Probabilistic Diffusion Models (PDMs) have recently emerged as a very\npromising class of generative models, achieving high performance in natural\nimage generation. However, their performance relative to non-natural images,\nlike radar-based satellite data, remains largely unknown. Generating large\namounts of synthetic (and especially labelled) satellite data is crucial to\nimplement deep-learning approaches for the processing and analysis of\n(interferometric) satellite aperture radar data. Here, we leverage PDMs to\ngenerate several radar-based satellite image datasets. We show that PDMs\nsucceed in generating images with complex and realistic structures, but that\nsampling time remains an issue. Indeed, accelerated sampling strategies, which\nwork well on simple image datasets like MNIST, fail on our radar datasets. We\nprovide a simple and versatile open-source\nhttps://github.com/thomaskerdreux/PDM_SAR_InSAR_generation to train, sample and\nevaluate PDMs using any dataset on a single GPU.\n","authors":["Alexandre Tuel","Thomas Kerdreux","Claudia Hulbert","Bertrand Rouet-Leduc"],"pdf_url":"https://arxiv.org/pdf/2308.16847v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16964v1","updated":"2023-11-28T17:12:03Z","published":"2023-11-28T17:12:03Z","title":"Machine learning force-field models for metallic spin glass","summary":"  Metallic spin glass systems, such as dilute magnetic alloys, are\ncharacterized by randomly distributed local moments coupled to each other\nthrough a long-range electron-mediated effective interaction. We present a\nscalable machine learning (ML) framework for dynamical simulations of metallic\nspin glasses. A Behler-Parrinello type neural-network model, based on the\nprinciple of locality, is developed to accurately and efficiently predict\nelectron-induced local magnetic fields that drive the spin dynamics. A crucial\ncomponent of the ML model is a proper symmetry-invariant representation of\nlocal magnetic environment which is direct input to the neural net. We develop\nsuch a magnetic descriptor by incorporating the spin degrees of freedom into\nthe atom-centered symmetry function methods which are widely used in ML\nforce-field models for quantum molecular dynamics. We apply our approach to\nstudy the relaxation dynamics of an amorphous generalization of the s-d model.\nOur work highlights the promising potential of ML models for large-scale\ndynamical modeling of itinerant magnets with quenched disorder.\n","authors":["Menglin Shi","Sheng Zhang","Gia-Wei Chern"],"pdf_url":"https://arxiv.org/pdf/2311.16964v1.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.16956v1","updated":"2023-11-28T17:03:56Z","published":"2023-11-28T17:03:56Z","title":"Adaptive Step Sizes for Preconditioned Stochastic Gradient Descent","summary":"  This paper proposes a novel approach to adaptive step sizes in stochastic\ngradient descent (SGD) by utilizing quantities that we have identified as\nnumerically traceable -- the Lipschitz constant for gradients and a concept of\nthe local variance in search directions. Our findings yield a nearly\nhyperparameter-free algorithm for stochastic optimization, which has provable\nconvergence properties when applied to quadratic problems and exhibits truly\nproblem adaptive behavior on classical image classification tasks. Our\nframework enables the potential inclusion of a preconditioner, thereby enabling\nthe implementation of adaptive step sizes for stochastic second-order\noptimization methods.\n","authors":["Frederik Köhne","Leonie Kreis","Anton Schiela","Roland Herzog"],"pdf_url":"https://arxiv.org/pdf/2311.16956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.04486v2","updated":"2023-11-28T17:02:31Z","published":"2023-10-06T15:45:28Z","title":"T-Rep: Representation Learning for Time Series using Time-Embeddings","summary":"  Multivariate time series present challenges to standard machine learning\ntechniques, as they are often unlabeled, high dimensional, noisy, and contain\nmissing data. To address this, we propose T-Rep, a self-supervised method to\nlearn time series representations at a timestep granularity. T-Rep learns\nvector embeddings of time alongside its feature extractor, to extract temporal\nfeatures such as trend, periodicity, or distribution shifts from the signal.\nThese time-embeddings are leveraged in pretext tasks, to incorporate smooth and\nfine-grained temporal dependencies in the representations, as well as reinforce\nrobustness to missing data. We evaluate T-Rep on downstream classification,\nforecasting, and anomaly detection tasks. It is compared to existing\nself-supervised algorithms for time series, which it outperforms in all three\ntasks. We test T-Rep in missing data regimes, where it proves more resilient\nthan its counterparts. Finally, we provide latent space visualisation\nexperiments, highlighting the interpretability of the learned representations.\n","authors":["Archibald Fraikin","Adrien Bennetot","Stéphanie Allassonnière"],"pdf_url":"https://arxiv.org/pdf/2310.04486v2.pdf","comment":"Under review at ICLR 2024"},{"id":"http://arxiv.org/abs/2310.06328v3","updated":"2023-11-28T16:59:02Z","published":"2023-10-10T05:54:00Z","title":"Antenna Response Consistency Driven Self-supervised Learning for\n  WIFI-based Human Activity Recognition","summary":"  Self-supervised learning (SSL) for WiFi-based human activity recognition\n(HAR) holds great promise due to its ability to address the challenge of\ninsufficient labeled data. However, directly transplanting SSL algorithms,\nespecially contrastive learning, originally designed for other domains to CSI\ndata, often fails to achieve the expected performance. We attribute this issue\nto the inappropriate alignment criteria, which disrupt the semantic distance\nconsistency between the feature space and the input space. To address this\nchallenge, we introduce \\textbf{A}ntenna \\textbf{R}esponse \\textbf{C}onsistency\n(ARC) as a solution to define proper alignment criteria. ARC is designed to\nretain semantic information from the input space while introducing robustness\nto real-world noise. Moreover, we substantiate the effectiveness of ARC through\na comprehensive set of experiments, demonstrating its capability to enhance the\nperformance of self-supervised learning for WiFi-based HAR by achieving an\nincrease of over 5\\% in accuracy in most cases and achieving a best accuracy of\n94.97\\%.\n","authors":["Ke Xu","Jiangtao Wang","Hongyuan Zhu","Dingchang Zheng"],"pdf_url":"https://arxiv.org/pdf/2310.06328v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.13658v3","updated":"2023-11-28T16:47:56Z","published":"2023-09-24T14:53:51Z","title":"Fantastic Generalization Measures are Nowhere to be Found","summary":"  We study the notion of a generalization bound being uniformly tight, meaning\nthat the difference between the bound and the population loss is small for all\nlearning algorithms and all population distributions. Numerous generalization\nbounds have been proposed in the literature as potential explanations for the\nability of neural networks to generalize in the overparameterized setting.\nHowever, in their paper ``Fantastic Generalization Measures and Where to Find\nThem,'' Jiang et al. (2020) examine more than a dozen generalization bounds,\nand show empirically that none of them are uniformly tight. This raises the\nquestion of whether uniformly-tight generalization bounds are at all possible\nin the overparameterized setting. We consider two types of generalization\nbounds: (1) bounds that may depend on the training set and the learned\nhypothesis (e.g., margin bounds). We prove mathematically that no such bound\ncan be uniformly tight in the overparameterized setting; (2) bounds that may in\naddition also depend on the learning algorithm (e.g., stability bounds). For\nthese bounds, we show a trade-off between the algorithm's performance and the\nbound's tightness. Namely, if the algorithm achieves good accuracy on certain\ndistributions, then no generalization bound can be uniformly tight for it in\nthe overparameterized setting. We explain how these formal results can, in our\nview, inform research on generalization bounds for neural networks, while\nstressing that other interpretations of these results are also possible.\n","authors":["Michael Gastpar","Ido Nachum","Jonathan Shafer","Thomas Weinberger"],"pdf_url":"https://arxiv.org/pdf/2309.13658v3.pdf","comment":"34 pages, 1 figure. Minor fix: subsection 6.2 -> section 7"},{"id":"http://arxiv.org/abs/2311.16943v1","updated":"2023-11-28T16:46:44Z","published":"2023-11-28T16:46:44Z","title":"Image segmentation with traveling waves in an exactly solvable recurrent\n  neural network","summary":"  We study image segmentation using spatiotemporal dynamics in a recurrent\nneural network where the state of each unit is given by a complex number. We\nshow that this network generates sophisticated spatiotemporal dynamics that can\neffectively divide an image into groups according to a scene's structural\ncharacteristics. Using an exact solution of the recurrent network's dynamics,\nwe present a precise description of the mechanism underlying object\nsegmentation in this network, providing a clear mathematical interpretation of\nhow the network performs this task. We then demonstrate a simple algorithm for\nobject segmentation that generalizes across inputs ranging from simple\ngeometric objects in grayscale images to natural images. Object segmentation\nacross all images is accomplished with one recurrent neural network that has a\nsingle, fixed set of weights. This demonstrates the expressive potential of\nrecurrent neural networks when constructed using a mathematical approach that\nbrings together their structure, dynamics, and computation.\n","authors":["Luisa H. B. Liboni","Roberto C. Budzinski","Alexandra N. Busch","Sindy Löwe","Thomas A. Keller","Max Welling","Lyle E. Muller"],"pdf_url":"https://arxiv.org/pdf/2311.16943v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16941v1","updated":"2023-11-28T16:46:14Z","published":"2023-11-28T16:46:14Z","title":"Debiasing Multimodal Models via Causal Information Minimization","summary":"  Most existing debiasing methods for multimodal models, including causal\nintervention and inference methods, utilize approximate heuristics to represent\nthe biases, such as shallow features from early stages of training or unimodal\nfeatures for multimodal tasks like VQA, etc., which may not be accurate. In\nthis paper, we study bias arising from confounders in a causal graph for\nmultimodal data and examine a novel approach that leverages causally-motivated\ninformation minimization to learn the confounder representations. Robust\npredictive features contain diverse information that helps a model generalize\nto out-of-distribution data. Hence, minimizing the information content of\nfeatures obtained from a pretrained biased model helps learn the simplest\npredictive features that capture the underlying data distribution. We treat\nthese features as confounder representations and use them via methods motivated\nby causal theory to remove bias from models. We find that the learned\nconfounder representations indeed capture dataset biases, and the proposed\ndebiasing methods improve out-of-distribution (OOD) performance on multiple\nmultimodal datasets without sacrificing in-distribution performance.\nAdditionally, we introduce a novel metric to quantify the sufficiency of\nspurious features in models' predictions that further demonstrates the\neffectiveness of our proposed methods. Our code is available at:\nhttps://github.com/Vaidehi99/CausalInfoMin\n","authors":["Vaidehi Patil","Adyasha Maharana","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2311.16941v1.pdf","comment":"EMNLP 2023 Findings (16 pages)"},{"id":"http://arxiv.org/abs/2309.13411v2","updated":"2023-11-28T16:41:35Z","published":"2023-09-23T15:48:35Z","title":"Towards Attributions of Input Variables in a Coalition","summary":"  This paper aims to develop a new attribution method to explain the conflict\nbetween individual variables' attributions and their coalition's attribution\nfrom a fully new perspective. First, we find that the Shapley value can be\nreformulated as the allocation of Harsanyi interactions encoded by the AI\nmodel. Second, based the re-alloction of interactions, we extend the Shapley\nvalue to the attribution of coalitions. Third we ective. We derive the\nfundamental mechanism behind the conflict. This conflict come from the\ninteraction containing partial variables in their coalition.\n","authors":["Xinhao Zheng","Huiqi Deng","Bo Fan","Quanshi Zhang"],"pdf_url":"https://arxiv.org/pdf/2309.13411v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03059v3","updated":"2023-11-28T16:31:34Z","published":"2023-10-04T16:49:36Z","title":"Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models","summary":"  The popularity of pre-trained large models has revolutionized downstream\ntasks across diverse fields, such as language, vision, and multi-modality. To\nminimize the adaption cost for downstream tasks, many Parameter-Efficient\nFine-Tuning (PEFT) techniques are proposed for language and 2D image\npre-trained models. However, the specialized PEFT method for 3D pre-trained\nmodels is still under-explored. To this end, we introduce Point-PEFT, a novel\nframework for adapting point cloud pre-trained models with minimal learnable\nparameters. Specifically, for a pre-trained 3D model, we freeze most of its\nparameters, and only tune the newly added PEFT modules on downstream tasks,\nwhich consist of a Point-prior Prompt and a Geometry-aware Adapter. The\nPoint-prior Prompt adopts a set of learnable prompt tokens, for which we\npropose to construct a memory bank with domain-specific knowledge, and utilize\na parameter-free attention to enhance the prompt tokens. The Geometry-aware\nAdapter aims to aggregate point cloud features within spatial neighborhoods to\ncapture fine-grained geometric information through local interactions.\nExtensive experiments indicate that our Point-PEFT can achieve better\nperformance than the full fine-tuning on various downstream tasks, while using\nonly 5% of the trainable parameters, demonstrating the efficiency and\neffectiveness of our approach. Code will be released at\nhttps://github.com/Even-JK/PEFT-3D.\n","authors":["Ivan Tang","Ray Zhang","Zoey Guo","Dong Wang","Zhigang Wang","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2310.03059v3.pdf","comment":"10 pages. The specialized PEFT framework for 3D pre-trained models,\n  which achieves competitive performance to full fine-tuning, and significantly\n  reduces the computational resources. Project page:\n  https://github.com/Even-JK/PEFT-3D"},{"id":"http://arxiv.org/abs/2206.10479v3","updated":"2023-11-28T16:23:08Z","published":"2022-06-21T15:44:49Z","title":"Policy Learning with Asymmetric Counterfactual Utilities","summary":"  Data-driven decision making plays an important role even in high stakes\nsettings like medicine and public policy. Learning optimal policies from\nobserved data requires a careful formulation of the utility function whose\nexpected value is maximized across a population. Although researchers typically\nuse utilities that depend on observed outcomes alone, in many settings the\ndecision maker's utility function is more properly characterized by the joint\nset of potential outcomes under all actions. For example, the Hippocratic\nprinciple to \"do no harm\" implies that the cost of causing death to a patient\nwho would otherwise survive without treatment is greater than the cost of\nforgoing life-saving treatment. We consider optimal policy learning with\nasymmetric counterfactual utility functions of this form that consider the\njoint set of potential outcomes. We show that asymmetric counterfactual\nutilities lead to an unidentifiable expected utility function, and so we first\npartially identify it. Drawing on statistical decision theory, we then derive\nminimax decision rules by minimizing the maximum expected utility loss relative\nto different alternative policies. We show that one can learn minimax loss\ndecision rules from observed data by solving intermediate classification\nproblems, and establish that the finite sample excess expected utility loss of\nthis procedure is bounded by the regret of these intermediate classifiers. We\napply this conceptual framework and methodology to the decision about whether\nor not to use right heart catheterization for patients with possible pulmonary\nhypertension.\n","authors":["Eli Ben-Michael","Kosuke Imai","Zhichao Jiang"],"pdf_url":"https://arxiv.org/pdf/2206.10479v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16909v1","updated":"2023-11-28T16:12:50Z","published":"2023-11-28T16:12:50Z","title":"Multinomial belief networks","summary":"  A Bayesian approach to machine learning is attractive when we need to\nquantify uncertainty, deal with missing observations, when samples are scarce,\nor when the data is sparse. All of these commonly apply when analysing\nhealthcare data. To address these analytical requirements, we propose a deep\ngenerative model for multinomial count data where both the weights and hidden\nunits of the network are Dirichlet distributed. A Gibbs sampling procedure is\nformulated that takes advantage of a series of augmentation relations,\nanalogous to the Zhou-Cong-Chen model. We apply the model on small handwritten\ndigits, and a large experimental dataset of DNA mutations in cancer, and we\nshow how the model is able to extract biologically meaningful meta-signatures\nin a fully data-driven way.\n","authors":["H. C. Donker","D. Neijzen","G. A. Lunter"],"pdf_url":"https://arxiv.org/pdf/2311.16909v1.pdf","comment":"9 pages, 3 figs; supplement: 13 pages"},{"id":"http://arxiv.org/abs/2310.08659v4","updated":"2023-11-28T16:06:59Z","published":"2023-10-12T18:34:08Z","title":"LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models","summary":"  Quantization is an indispensable technique for serving Large Language Models\n(LLMs) and has recently found its way into LoRA fine-tuning. In this work we\nfocus on the scenario where quantization and LoRA fine-tuning are applied\ntogether on a pre-trained model. In such cases it is common to observe a\nconsistent gap in the performance on downstream tasks between full fine-tuning\nand quantization plus LoRA fine-tuning approach. In response, we propose LoftQ\n(LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that\nsimultaneously quantizes an LLM and finds a proper low-rank initialization for\nLoRA fine-tuning. Such an initialization alleviates the discrepancy between the\nquantized and full-precision model and significantly improves generalization in\ndownstream tasks. We evaluate our method on natural language understanding,\nquestion answering, summarization, and natural language generation tasks.\nExperiments show that our method is highly effective and outperforms existing\nquantization methods, especially in the challenging 2-bit and 2/4-bit mixed\nprecision regimes. The code is available on https://github.com/yxli2123/LoftQ.\n","authors":["Yixiao Li","Yifan Yu","Chen Liang","Pengcheng He","Nikos Karampatziakis","Weizhu Chen","Tuo Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.08659v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09790v3","updated":"2023-11-28T15:53:00Z","published":"2023-11-16T11:10:38Z","title":"Breaking Boundaries: Balancing Performance and Robustness in Deep\n  Wireless Traffic Forecasting","summary":"  Balancing the trade-off between accuracy and robustness is a long-standing\nchallenge in time series forecasting. While most of existing robust algorithms\nhave achieved certain suboptimal performance on clean data, sustaining the same\nperformance level in the presence of data perturbations remains extremely hard.\nIn this paper, we study a wide array of perturbation scenarios and propose\nnovel defense mechanisms against adversarial attacks using real-world telecom\ndata. We compare our strategy against two existing adversarial training\nalgorithms under a range of maximal allowed perturbations, defined using\n$\\ell_{\\infty}$-norm, $\\in [0.1,0.4]$. Our findings reveal that our hybrid\nstrategy, which is composed of a classifier to detect adversarial examples, a\ndenoiser to eliminate noise from the perturbed data samples, and a standard\nforecaster, achieves the best performance on both clean and perturbed data. Our\noptimal model can retain up to $92.02\\%$ the performance of the original\nforecasting model in terms of Mean Squared Error (MSE) on clean data, while\nbeing more robust than the standard adversarially trained models on perturbed\ndata. Its MSE is 2.71$\\times$ and 2.51$\\times$ lower than those of comparing\nmethods on normal and perturbed data, respectively. In addition, the components\nof our models can be trained in parallel, resulting in better computational\nefficiency. Our results indicate that we can optimally balance the trade-off\nbetween the performance and robustness of forecasting models by improving the\nclassifier and denoiser, even in the presence of sophisticated and destructive\npoisoning attacks.\n","authors":["Romain Ilbert","Thai V. Hoang","Zonghua Zhang","Themis Palpanas"],"pdf_url":"https://arxiv.org/pdf/2311.09790v3.pdf","comment":"Accepted for presentation at the ARTMAN workshop, part of the ACM\n  Conference on Computer and Communications Security (CCS), 2023"},{"id":"http://arxiv.org/abs/2311.16894v1","updated":"2023-11-28T15:46:12Z","published":"2023-11-28T15:46:12Z","title":"Dendrogram distance: an evaluation metric for generative networks using\n  hierarchical clustering","summary":"  We present a novel metric for generative modeling evaluation, focusing\nprimarily on generative networks. The method uses dendrograms to represent real\nand fake data, allowing for the divergence between training and generated\nsamples to be computed. This metric focus on mode collapse, targeting\ngenerators that are not able to capture all modes in the training set. To\nevaluate the proposed method it is introduced a validation scheme based on\nsampling from real datasets, therefore the metric is evaluated in a controlled\nenvironment and proves to be competitive with other state-of-the-art\napproaches.\n","authors":["Gustavo Sutter Carvalho","Moacir Antonelli Ponti"],"pdf_url":"https://arxiv.org/pdf/2311.16894v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13131v2","updated":"2023-11-28T15:41:46Z","published":"2022-11-23T17:04:20Z","title":"FeTrIL: Feature Translation for Exemplar-Free Class-Incremental Learning","summary":"  Exemplar-free class-incremental learning is very challenging due to the\nnegative effect of catastrophic forgetting. A balance between stability and\nplasticity of the incremental process is needed in order to obtain good\naccuracy for past as well as new classes. Existing exemplar-free\nclass-incremental methods focus either on successive fine tuning of the model,\nthus favoring plasticity, or on using a feature extractor fixed after the\ninitial incremental state, thus favoring stability. We introduce a method which\ncombines a fixed feature extractor and a pseudo-features generator to improve\nthe stability-plasticity balance. The generator uses a simple yet effective\ngeometric translation of new class features to create representations of past\nclasses, made of pseudo-features. The translation of features only requires the\nstorage of the centroid representations of past classes to produce their\npseudo-features. Actual features of new classes and pseudo-features of past\nclasses are fed into a linear classifier which is trained incrementally to\ndiscriminate between all classes. The incremental process is much faster with\nthe proposed method compared to mainstream ones which update the entire deep\nmodel. Experiments are performed with three challenging datasets, and different\nincremental settings. A comparison with ten existing methods shows that our\nmethod outperforms the others in most cases.\n","authors":["Grégoire Petit","Adrian Popescu","Hugo Schindler","David Picard","Bertrand Delezoide"],"pdf_url":"https://arxiv.org/pdf/2211.13131v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.08415v3","updated":"2023-11-28T15:36:11Z","published":"2023-05-15T07:48:50Z","title":"Marsellus: A Heterogeneous RISC-V AI-IoT End-Node SoC with 2-to-8b DNN\n  Acceleration and 30%-Boost Adaptive Body Biasing","summary":"  Emerging Artificial Intelligence-enabled Internet-of-Things (AI-IoT)\nSystem-on-a-Chip (SoC) for augmented reality, personalized healthcare, and\nnano-robotics need to run many diverse tasks within a power envelope of a few\ntens of mW over a wide range of operating conditions: compute-intensive but\nstrongly quantized Deep Neural Network (DNN) inference, as well as signal\nprocessing and control requiring high-precision floating-point. We present\nMarsellus, an all-digital heterogeneous SoC for AI-IoT end-nodes fabricated in\nGlobalFoundries 22nm FDX that combines 1) a general-purpose cluster of 16\nRISC-V Digital Signal Processing (DSP) cores attuned for the execution of a\ndiverse range of workloads exploiting 4-bit and 2-bit arithmetic extensions\n(XpulpNN), combined with fused MAC&LOAD operations and floating-point support;\n2) a 2-8bit Reconfigurable Binary Engine (RBE) to accelerate 3x3 and 1x1\n(pointwise) convolutions in DNNs; 3) a set of On-Chip Monitoring (OCM) blocks\nconnected to an Adaptive Body Biasing (ABB) generator and a hardware control\nloop, enabling on-the-fly adaptation of transistor threshold voltages.\nMarsellus achieves up to 180 Gop/s or 3.32 Top/s/W on 2-bit precision\narithmetic in software, and up to 637 Gop/s or 12.4 Top/s/W on\nhardware-accelerated DNN layers.\n","authors":["Francesco Conti","Gianna Paulin","Angelo Garofalo","Davide Rossi","Alfio Di Mauro","Georg Rutishauser","Gianmarco Ottavi","Manuel Eggimann","Hayate Okuhara","Luca Benini"],"pdf_url":"https://arxiv.org/pdf/2305.08415v3.pdf","comment":"Post-print accepted by IEEE Journal of Solid-State Circuits. Fixed\n  metadata (was missing one co-author), added DOI of IEEE JSSC"},{"id":"http://arxiv.org/abs/2311.16883v1","updated":"2023-11-28T15:31:31Z","published":"2023-11-28T15:31:31Z","title":"Compressing the Backward Pass of Large-Scale Neural Architectures by\n  Structured Activation Pruning","summary":"  The rise of Deep Neural Networks (DNNs) has led to an increase in model size\nand complexity, straining the memory capacity of GPUs. Sparsity in DNNs,\ncharacterized as structural or ephemeral, has gained attention as a solution.\nThis work focuses on ephemeral sparsity, aiming to reduce memory consumption\nduring training. It emphasizes the significance of activations, an often\noverlooked component, and their role in memory usage. This work employs\nstructured pruning in Block Sparse Compressed Row (BSR) format in combination\nwith a magnitude-based criterion to efficiently prune activations. We\nfurthermore introduce efficient block-sparse operators for GPUs and showcase\ntheir effectiveness, as well as the superior compression offered by block\nsparsity. We report the effectiveness of activation pruning by evaluating\ntraining speed, accuracy, and memory usage of large-scale neural architectures\non the example of ResMLP on image classification tasks. As a result, we observe\na memory reduction of up to 32\\% while maintaining accuracy. Ultimately, our\napproach aims to democratize large-scale model training, reduce GPU\nrequirements, and address ecological concerns.\n","authors":["Daniel Barley","Holger Fröning"],"pdf_url":"https://arxiv.org/pdf/2311.16883v1.pdf","comment":"8 pages, 10 figures, submitted to the 6th AccML workshop at HiPEAC\n  conference 2024"},{"id":"http://arxiv.org/abs/2311.16882v1","updated":"2023-11-28T15:31:11Z","published":"2023-11-28T15:31:11Z","title":"Optimisation-Based Multi-Modal Semantic Image Editing","summary":"  Image editing affords increased control over the aesthetics and content of\ngenerated images. Pre-existing works focus predominantly on text-based\ninstructions to achieve desired image modifications, which limit edit precision\nand accuracy. In this work, we propose an inference-time editing optimisation,\ndesigned to extend beyond textual edits to accommodate multiple editing\ninstruction types (e.g. spatial layout-based; pose, scribbles, edge maps). We\npropose to disentangle the editing task into two competing subtasks: successful\nlocal image modifications and global content consistency preservation, where\nsubtasks are guided through two dedicated loss functions. By allowing to adjust\nthe influence of each loss function, we build a flexible editing solution that\ncan be adjusted to user preferences. We evaluate our method using text, pose\nand scribble edit conditions, and highlight our ability to achieve complex\nedits, through both qualitative and quantitative experiments.\n","authors":["Bowen Li","Yongxin Yang","Steven McDonagh","Shifeng Zhang","Petru-Daniel Tudosiu","Sarah Parisot"],"pdf_url":"https://arxiv.org/pdf/2311.16882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16877v1","updated":"2023-11-28T15:26:09Z","published":"2023-11-28T15:26:09Z","title":"Imputation using training labels and classification via label imputation","summary":"  Missing data is a common problem in practical settings. Various imputation\nmethods have been developed to deal with missing data. However, even though the\nlabel is usually available in the training data, the common practice of\nimputation usually only relies on the input and ignores the label. In this\nwork, we illustrate how stacking the label into the input can significantly\nimprove the imputation of the input. In addition, we propose a classification\nstrategy that initializes the predicted test label with missing values and\nstacks the label with the input for imputation. This allows imputing the label\nand the input at the same time. Also, the technique is capable of handling data\ntraining with missing labels without any prior imputation and is applicable to\ncontinuous, categorical, or mixed-type data. Experiments show promising results\nin terms of accuracy.\n","authors":["Thu Nguyen","Pål Halvorsen","Michael A. Riegler"],"pdf_url":"https://arxiv.org/pdf/2311.16877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16876v1","updated":"2023-11-28T15:25:14Z","published":"2023-11-28T15:25:14Z","title":"Digital Twin-Enhanced Deep Reinforcement Learning for Resource\n  Management in Networks Slicing","summary":"  Network slicing-based communication systems can dynamically and efficiently\nallocate resources for diversified services. However, due to the limitation of\nthe network interface on channel access and the complexity of the resource\nallocation, it is challenging to achieve an acceptable solution in the\npractical system without precise prior knowledge of the dynamics probability\nmodel of the service requests. Existing work attempts to solve this problem\nusing deep reinforcement learning (DRL), however, such methods usually require\na lot of interaction with the real environment in order to achieve good\nresults. In this paper, a framework consisting of a digital twin and\nreinforcement learning agents is present to handle the issue. Specifically, we\npropose to use the historical data and the neural networks to build a digital\ntwin model to simulate the state variation law of the real environment. Then,\nwe use the data generated by the network slicing environment to calibrate the\ndigital twin so that it is in sync with the real environment. Finally, DRL for\nslice optimization optimizes its own performance in this virtual\npre-verification environment. We conducted an exhaustive verification of the\nproposed digital twin framework to confirm its scalability. Specifically, we\npropose to use loss landscapes to visualize the generalization of DRL\nsolutions. We explore a distillation-based optimization scheme for lightweight\nslicing strategies. In addition, we also extend the framework to offline\nreinforcement learning, where solutions can be used to obtain intelligent\ndecisions based solely on historical data. Numerical simulation experiments\nshow that the proposed digital twin can significantly improve the performance\nof the slice optimization strategy.\n","authors":["Zhengming Zhang","Yongming Huang","Cheng Zhang","Qingbi Zheng","Luxi Yang","Xiaohu You"],"pdf_url":"https://arxiv.org/pdf/2311.16876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16872v1","updated":"2023-11-28T15:24:02Z","published":"2023-11-28T15:24:02Z","title":"A unified weighting framework for evaluating nearest neighbour\n  classification","summary":"  We present the first comprehensive and large-scale evaluation of classical\n(NN), fuzzy (FNN) and fuzzy rough (FRNN) nearest neighbour classification. We\nshow that existing proposals for nearest neighbour weighting can be\nstandardised in the form of kernel functions, applied to the distance values\nand/or ranks of the nearest neighbours of a test instance. Furthermore, we\nidentify three commonly used distance functions and four scaling measures. We\nsystematically evaluate these choices on a collection of 85 real-life\nclassification datasets. We find that NN, FNN and FRNN all perform best with\nBoscovich distance. NN and FRNN perform best with a combination of Samworth\nrank- and distance weights and scaling by the mean absolute deviation around\nthe median ($r_1$), the standard deviaton ($r_2$) or the interquartile range\n($r_{\\infty}^*$), while FNN performs best with only Samworth distance-weights\nand $r_1$- or $r_2$-scaling. We also introduce a new kernel based on fuzzy\nYager negation, and show that NN achieves comparable performance with Yager\ndistance-weights, which are simpler to implement than a combination of Samworth\ndistance- and rank-weights. Finally, we demonstrate that FRNN generally\noutperforms NN, which in turns performs systematically better than FNN.\n","authors":["Oliver Urs Lenz","Henri Bollaert","Chris Cornelis"],"pdf_url":"https://arxiv.org/pdf/2311.16872v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16863v1","updated":"2023-11-28T15:09:36Z","published":"2023-11-28T15:09:36Z","title":"Power Hungry Processing: Watts Driving the Cost of AI Deployment?","summary":"  Recent years have seen a surge in the popularity of commercial AI products\nbased on generative, multi-purpose AI systems promising a unified approach to\nbuilding machine learning (ML) models into technology. However, this ambition\nof \"generality\" comes at a steep cost to the environment, given the amount of\nenergy these systems require and the amount of carbon that they emit. In this\nwork, we propose the first systematic comparison of the ongoing inference cost\nof various categories of ML systems, covering both task-specific (i.e.\nfinetuned models that carry out a single task) and `general-purpose' models,\n(i.e. those trained for multiple tasks). We measure deployment cost as the\namount of energy and carbon required to perform 1,000 inferences on\nrepresentative benchmark dataset using these models. We find that\nmulti-purpose, generative architectures are orders of magnitude more expensive\nthan task-specific systems for a variety of tasks, even when controlling for\nthe number of model parameters. We conclude with a discussion around the\ncurrent trend of deploying multi-purpose generative ML systems, and caution\nthat their utility should be more intentionally weighed against increased costs\nin terms of energy and emissions. All the data from our study can be accessed\nvia an interactive demo to carry out further exploration and analysis.\n","authors":["Alexandra Sasha Luccioni","Yacine Jernite","Emma Strubell"],"pdf_url":"https://arxiv.org/pdf/2311.16863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16860v1","updated":"2023-11-28T15:07:25Z","published":"2023-11-28T15:07:25Z","title":"Data-efficient operator learning for solving high Mach number fluid flow\n  problems","summary":"  We consider the problem of using SciML to predict solutions of high Mach\nfluid flows over irregular geometries. In this setting, data is limited, and so\nit is desirable for models to perform well in the low-data setting. We show\nthat Neural Basis Functions (NBF), which learns a basis of behavior modes from\nthe data and then uses this basis to make predictions, is more effective than a\nbasis-unaware baseline model. In addition, we identify continuing challenges in\nthe space of predicting solutions for this type of problem.\n","authors":["Noah Ford","Victor J. Leon","Honest Merman","Jeffrey Gilbert","Alexander New"],"pdf_url":"https://arxiv.org/pdf/2311.16860v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16856v1","updated":"2023-11-28T15:05:13Z","published":"2023-11-28T15:05:13Z","title":"Attentional Graph Neural Networks for Robust Massive Network\n  Localization","summary":"  Graph neural networks (GNNs) have gained significant popularity for\nclassification tasks in machine learning, yet their applications to regression\nproblems remain limited. Concurrently, attention mechanisms have emerged as\npowerful tools in sequential learning tasks. In this paper, we employ GNNs and\nattention mechanisms to address a classical but challenging nonlinear\nregression problem: network localization. We propose a novel GNN-based network\nlocalization method that achieves exceptional stability and accuracy in the\npresence of severe non-line-of-sight (NLOS) propagations, while eliminating the\nneed for laborious offline calibration or NLOS identification. Extensive\nexperimental results validate the effectiveness and high accuracy of our\nGNN-based localization model, particularly in challenging NLOS scenarios.\nHowever, the proposed GNN-based model exhibits limited flexibility, and its\naccuracy is highly sensitive to a specific hyperparameter that determines the\ngraph structure. To address the limitations and extend the applicability of the\nGNN-based model to real scenarios, we introduce two attentional graph neural\nnetworks (AGNNs) that offer enhanced flexibility and the ability to\nautomatically learn the optimal hyperparameter for each node. Experimental\nresults confirm that the AGNN models are able to enhance localization accuracy,\nproviding a promising solution for real-world applications. We also provide\nsome analyses of the improved performance achieved by the AGNN models from the\nperspectives of dynamic attention and signal denoising characteristics.\n","authors":["Wenzhong Yan","Juntao Wang","Feng Yin","Abdelhak M. Zoubir"],"pdf_url":"https://arxiv.org/pdf/2311.16856v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16849v1","updated":"2023-11-28T15:00:11Z","published":"2023-11-28T15:00:11Z","title":"Identifiable Feature Learning for Spatial Data with Nonlinear ICA","summary":"  Recently, nonlinear ICA has surfaced as a popular alternative to the many\nheuristic models used in deep representation learning and disentanglement. An\nadvantage of nonlinear ICA is that a sophisticated identifiability theory has\nbeen developed; in particular, it has been proven that the original components\ncan be recovered under sufficiently strong latent dependencies. Despite this\ngeneral theory, practical nonlinear ICA algorithms have so far been mainly\nlimited to data with one-dimensional latent dependencies, especially\ntime-series data. In this paper, we introduce a new nonlinear ICA framework\nthat employs $t$-process (TP) latent components which apply naturally to data\nwith higher-dimensional dependency structures, such as spatial and\nspatio-temporal data. In particular, we develop a new learning and inference\nalgorithm that extends variational inference methods to handle the combination\nof a deep neural network mixing function with the TP prior, and employs the\nmethod of inducing points for computational efficacy. On the theoretical side,\nwe show that such TP independent components are identifiable under very general\nconditions. Further, Gaussian Process (GP) nonlinear ICA is established as a\nlimit of the TP Nonlinear ICA model, and we prove that the identifiability of\nthe latent components at this GP limit is more restricted. Namely, those\ncomponents are identifiable if and only if they have distinctly different\ncovariance kernels. Our algorithm and identifiability theorems are explored on\nsimulated spatial data and real world spatio-temporal data.\n","authors":["Hermanni Hälvä","Jonathan So","Richard E. Turner","Aapo Hyvärinen"],"pdf_url":"https://arxiv.org/pdf/2311.16849v1.pdf","comment":"Work under review"},{"id":"http://arxiv.org/abs/2307.11957v4","updated":"2023-11-28T14:53:32Z","published":"2023-07-22T01:56:58Z","title":"High-performance real-world optical computing trained by in situ\n  model-free optimization","summary":"  Optical computing systems provide high-speed and low-energy data processing\nbut face deficiencies in computationally demanding training and\nsimulation-to-reality gaps. We propose a model-free optimization (MFO) method\nbased on a score gradient estimation algorithm for computationally efficient in\nsitu training of optical computing systems. This approach treats an optical\ncomputing system as a black box and back-propagates the loss directly to the\noptical computing weights' probability distributions, circumventing the need\nfor a computationally heavy and biased system simulation. Our experiments on a\nsingle-layer diffractive optical computing system show that MFO outperforms\nhybrid training on the MNIST and FMNIST datasets. Furthermore, we demonstrate\nimage-free and high-speed classification of cells from their phase maps. Our\nmethod's model-free and high-performance nature, combined with its low demand\nfor computational resources, expedites the transition of optical computing from\nlaboratory demonstrations to real-world applications.\n","authors":["Guangyuan Zhao","Xin Shu"],"pdf_url":"https://arxiv.org/pdf/2307.11957v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16834v1","updated":"2023-11-28T14:51:06Z","published":"2023-11-28T14:51:06Z","title":"Modular Neural Networks for Time Series Forecasting: Interpretability\n  and Feature Selection using Attention","summary":"  Multivariate time series have many applications, from healthcare and\nmeteorology to life science. Although deep learning models have shown excellent\npredictive performance for time series, they have been criticised for being\n\"black-boxes\" or non-interpretable. This paper proposes a novel modular neural\nnetwork model for multivariate time series prediction that is interpretable by\nconstruction. A recurrent neural network learns the temporal dependencies in\nthe data while an attention-based feature selection component selects the most\nrelevant features and suppresses redundant features used in the learning of the\ntemporal dependencies. A modular deep network is trained from the selected\nfeatures independently to show the users how features influence outcomes,\nmaking the model interpretable. Experimental results show that this approach\ncan outperform state-of-the-art interpretable Neural Additive Models (NAM) and\nvariations thereof in both regression and classification of time series tasks,\nachieving a predictive performance that is comparable to the top\nnon-interpretable methods for time series, LSTM and XGBoost.\n","authors":["Qiqi Su","Christos Kloukinas","Artur d'Garcez"],"pdf_url":"https://arxiv.org/pdf/2311.16834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16833v1","updated":"2023-11-28T14:50:50Z","published":"2023-11-28T14:50:50Z","title":"1-Lipschitz Layers Compared: Memory, Speed, and Certifiable Robustness","summary":"  The robustness of neural networks against input perturbations with bounded\nmagnitude represents a serious concern in the deployment of deep learning\nmodels in safety-critical systems. Recently, the scientific community has\nfocused on enhancing certifiable robustness guarantees by crafting 1-Lipschitz\nneural networks that leverage Lipschitz bounded dense and convolutional layers.\nAlthough different methods have been proposed in the literature to achieve this\ngoal, understanding the performance of such methods is not straightforward,\nsince different metrics can be relevant (e.g., training time, memory usage,\naccuracy, certifiable robustness) for different applications. For this reason,\nthis work provides a thorough theoretical and empirical comparison between\nmethods by evaluating them in terms of memory usage, speed, and certifiable\nrobust accuracy. The paper also provides some guidelines and recommendations to\nsupport the user in selecting the methods that work best depending on the\navailable resources. We provide code at\nhttps://github.com/berndprach/1LipschitzLayersCompared.\n","authors":["Bernd Prach","Fabio Brau","Giorgio Buttazzo","Christoph H. Lampert"],"pdf_url":"https://arxiv.org/pdf/2311.16833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16829v1","updated":"2023-11-28T14:48:22Z","published":"2023-11-28T14:48:22Z","title":"Decomposer: Semi-supervised Learning of Image Restoration and Image\n  Decomposition","summary":"  We present Decomposer, a semi-supervised reconstruction model that decomposes\ndistorted image sequences into their fundamental building blocks - the original\nimage and the applied augmentations, i.e., shadow, light, and occlusions. To\nsolve this problem, we use the SIDAR dataset that provides a large number of\ndistorted image sequences: each sequence contains images with shadows,\nlighting, and occlusions applied to an undistorted version. Each distortion\nchanges the original signal in different ways, e.g., additive or multiplicative\nnoise. We propose a transformer-based model to explicitly learn this\ndecomposition. The sequential model uses 3D Swin-Transformers for\nspatio-temporal encoding and 3D U-Nets as prediction heads for individual parts\nof the decomposition. We demonstrate that by separately pre-training our model\non weakly supervised pseudo labels, we can steer our model to optimize for our\nambiguous problem definition and learn to differentiate between the different\nimage distortions.\n","authors":["Boris Meinardus","Mariusz Trzeciakiewicz","Tim Herzig","Monika Kwiatkowski","Simon Matern","Olaf Hellwich"],"pdf_url":"https://arxiv.org/pdf/2311.16829v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16822v1","updated":"2023-11-28T14:36:43Z","published":"2023-11-28T14:36:43Z","title":"Large Language Models Suffer From Their Own Output: An Analysis of the\n  Self-Consuming Training Loop","summary":"  Large language models (LLM) have become state of the art in many benchmarks\nand conversational LLM applications like ChatGPT are now widely used by the\npublic. Those LLMs can be used to generate large amounts of content which is\nposted on the internet to various platforms. As LLMs are trained on datasets\nusually collected from the internet, this LLM-generated content might be used\nto train the next generation of LLMs. Therefore, a self-consuming training loop\nemerges in which new LLM generations are trained on the output from the\nprevious generations. We empirically study this self-consuming training loop\nusing a novel dataset to analytically and accurately measure quality and\ndiversity of generated outputs. We find that this self-consuming training loop\ninitially improves both quality and diversity. However, after a few generations\nthe output inevitably degenerates in diversity. We find that the rate of\ndegeneration depends on the proportion of real and generated data.\n","authors":["Martin Briesch","Dominik Sobania","Franz Rothlauf"],"pdf_url":"https://arxiv.org/pdf/2311.16822v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.10364v4","updated":"2023-11-28T14:20:28Z","published":"2023-08-20T20:49:15Z","title":"SE(3) Equivariant Augmented Coupling Flows","summary":"  Coupling normalizing flows allow for fast sampling and density evaluation,\nmaking them the tool of choice for probabilistic modeling of physical systems.\nHowever, the standard coupling architecture precludes endowing flows that\noperate on the Cartesian coordinates of atoms with the SE(3) and permutation\ninvariances of physical systems. This work proposes a coupling flow that\npreserves SE(3) and permutation equivariance by performing coordinate splits\nalong additional augmented dimensions. At each layer, the flow maps atoms'\npositions into learned SE(3) invariant bases, where we apply standard flow\ntransformations, such as monotonic rational-quadratic splines, before returning\nto the original basis. Crucially, our flow preserves fast sampling and density\nevaluation, and may be used to produce unbiased estimates of expectations with\nrespect to the target distribution via importance sampling. When trained on the\nDW4, LJ13, and QM9-positional datasets, our flow is competitive with\nequivariant continuous normalizing flows, while allowing sampling more than an\norder of magnitude faster. Moreover, to the best of our knowledge, we are the\nfirst to learn the full Boltzmann distribution of alanine dipeptide by only\nmodeling the Cartesian positions of its atoms. Lastly, we demonstrate that our\nflow can be trained to approximately sample from the Boltzmann distribution of\nthe DW4 and LJ13 particle systems using only their energy functions.\n","authors":["Laurence I. Midgley","Vincent Stimper","Javier Antorán","Emile Mathieu","Bernhard Schölkopf","José Miguel Hernández-Lobato"],"pdf_url":"https://arxiv.org/pdf/2308.10364v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12089v2","updated":"2023-11-28T14:15:33Z","published":"2023-11-20T16:09:06Z","title":"Explaining Deep Learning Models for Age-related Gait Classification\n  based on time series acceleration","summary":"  Gait analysis holds significant importance in monitoring daily health,\nparticularly among older adults. Advancements in sensor technology enable the\ncapture of movement in real-life environments and generate big data. Machine\nlearning, notably deep learning (DL), shows promise to use these big data in\ngait analysis. However, the inherent black-box nature of these models poses\nchallenges for their clinical application. This study aims to enhance\ntransparency in DL-based gait classification for aged-related gait patterns\nusing Explainable Artificial Intelligence, such as SHAP.\n  A total of 244 subjects, comprising 129 adults and 115 older adults (age>65),\nwere included. They performed a 3-minute walking task while accelerometers were\naffixed to the lumbar segment L3. DL models, convolutional neural network (CNN)\nand gated recurrent unit (GRU), were trained using 1-stride and 8-stride\naccelerations, respectively, to classify adult and older adult groups. SHAP was\nemployed to explain the models' predictions.\n  CNN achieved a satisfactory performance with an accuracy of 81.4% and an AUC\nof 0.89, and GRU demonstrated promising results with an accuracy of 84.5% and\nan AUC of 0.94. SHAP analysis revealed that both CNN and GRU assigned higher\nSHAP values to the data from vertical and walking directions, particularly\nemphasizing data around heel contact, spanning from the terminal swing to\nloading response phases. Furthermore, SHAP values indicated that GRU did not\ntreat every stride equally.\n  CNN accurately distinguished between adults and older adults based on the\ncharacteristics of a single stride's data. GRU achieved accurate classification\nby considering the relationships and subtle differences between strides. In\nboth models, data around heel contact emerged as most critical, suggesting\ndifferences in acceleration and deceleration patterns during walking between\ndifferent age groups.\n","authors":["Xiaoping Zheng","Bert Otten","Michiel F Reneman","Claudine JC Lamoth"],"pdf_url":"https://arxiv.org/pdf/2311.12089v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01837v2","updated":"2023-11-28T13:36:58Z","published":"2023-10-03T07:01:23Z","title":"Extending CAM-based XAI methods for Remote Sensing Imagery Segmentation","summary":"  Current AI-based methods do not provide comprehensible physical\ninterpretations of the utilized data, extracted features, and\npredictions/inference operations. As a result, deep learning models trained\nusing high-resolution satellite imagery lack transparency and explainability\nand can be merely seen as a black box, which limits their wide-level adoption.\nExperts need help understanding the complex behavior of AI models and the\nunderlying decision-making process. The explainable artificial intelligence\n(XAI) field is an emerging field providing means for robust, practical, and\ntrustworthy deployment of AI models. Several XAI techniques have been proposed\nfor image classification tasks, whereas the interpretation of image\nsegmentation remains largely unexplored. This paper offers to bridge this gap\nby adapting the recent XAI classification algorithms and making them usable for\nmuti-class image segmentation, where we mainly focus on buildings' segmentation\nfrom high-resolution satellite images. To benchmark and compare the performance\nof the proposed approaches, we introduce a new XAI evaluation methodology and\nmetric based on \"Entropy\" to measure the model uncertainty. Conventional XAI\nevaluation methods rely mainly on feeding area-of-interest regions from the\nimage back to the pre-trained (utility) model and then calculating the average\nchange in the probability of the target class. Those evaluation metrics lack\nthe needed robustness, and we show that using Entropy to monitor the model\nuncertainty in segmenting the pixels within the target class is more suitable.\nWe hope this work will pave the way for additional XAI research for image\nsegmentation and applications in the remote sensing discipline.\n","authors":["Abdul Karim Gizzini","Mustafa Shukor","Ali J. Ghandour"],"pdf_url":"https://arxiv.org/pdf/2310.01837v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18228v2","updated":"2023-11-28T13:34:58Z","published":"2023-05-26T16:35:20Z","title":"SR-OOD: Out-of-Distribution Detection via Sample Repairing","summary":"  Out-of-distribution (OOD) detection is a crucial task for ensuring the\nreliability and robustness of machine learning models. Recent works have shown\nthat generative models often assign high confidence scores to OOD samples,\nindicating that they fail to capture the semantic information of the data. To\ntackle this problem, we take advantage of sample repairing and propose a novel\nOOD detection framework, namely SR-OOD. Our framework leverages the idea that\nrepairing an OOD sample can reveal its semantic inconsistency with the\nin-distribution data. Specifically, our framework consists of two components: a\nsample repairing module and a detection module. The sample repairing module\napplies erosion to an input sample and uses a generative adversarial network to\nrepair it. The detection module then determines whether the input sample is OOD\nusing a distance metric. Our framework does not require any additional data or\nlabel information for detection, making it applicable to various scenarios. We\nconduct extensive experiments on three image datasets: CIFAR-10, CelebA, and\nPokemon. The results demonstrate that our approach achieves superior\nperformance over the state-of-the-art generative methods in OOD detection.\n","authors":["Rui Sun","Andi Zhang","Haiming Zhang","Jinke Ren","Yao Zhu","Ruimao Zhang","Shuguang Cui","Zhen Li"],"pdf_url":"https://arxiv.org/pdf/2305.18228v2.pdf","comment":"This is an updated version of the paper"},{"id":"http://arxiv.org/abs/2311.16771v1","updated":"2023-11-28T13:25:34Z","published":"2023-11-28T13:25:34Z","title":"The HR-Calculus: Enabling Information Processing with Quaternion Algebra","summary":"  From their inception, quaternions and their division algebra have proven to\nbe advantageous in modelling rotation/orientation in three-dimensional spaces\nand have seen use from the initial formulation of electromagnetic filed theory\nthrough to forming the basis of quantum filed theory. Despite their impressive\nversatility in modelling real-world phenomena, adaptive information processing\ntechniques specifically designed for quaternion-valued signals have only\nrecently come to the attention of the machine learning, signal processing, and\ncontrol communities. The most important development in this direction is\nintroduction of the HR-calculus, which provides the required mathematical\nfoundation for deriving adaptive information processing techniques directly in\nthe quaternion domain. In this article, the foundations of the HR-calculus are\nrevised and the required tools for deriving adaptive learning techniques\nsuitable for dealing with quaternion-valued signals, such as the gradient\noperator, chain and product derivative rules, and Taylor series expansion are\npresented. This serves to establish the most important applications of adaptive\ninformation processing in the quaternion domain for both single-node and\nmulti-node formulations. The article is supported by Supplementary Material,\nwhich will be referred to as SM.\n","authors":["Danilo P. Mandic","Sayed Pouria Talebi","Clive Cheong Took","Yili Xia","Dongpo Xu","Min Xiang","Pauline Bourigault"],"pdf_url":"https://arxiv.org/pdf/2311.16771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13029v2","updated":"2023-11-28T13:23:39Z","published":"2023-06-22T16:46:00Z","title":"Decentralized Online Federated G-Network Learning for Lightweight\n  Intrusion Detection","summary":"  Cyberattacks are increasingly threatening networked systems, often with the\nemergence of new types of unknown (zero-day) attacks and the rise of vulnerable\ndevices. Such attacks can also target multiple components of a Supply Chain,\nwhich can be protected via Machine Learning (ML)-based Intrusion Detection\nSystems (IDSs). However, the need to learn large amounts of labelled data often\nlimits the applicability of ML-based IDSs to cybersystems that only have access\nto private local data, while distributed systems such as Supply Chains have\nmultiple components, each of which must preserve its private data while being\ntargeted by the same attack To address this issue, this paper proposes a novel\nDecentralized and Online Federated Learning Intrusion Detection (DOF-ID)\narchitecture based on the G-Network model with collaborative learning, that\nallows each IDS used by a specific component to learn from the experience\ngained in other components, in addition to its own local data, without\nviolating the data privacy of other components. The performance evaluation\nresults using public Kitsune and Bot-IoT datasets show that DOF-ID\nsignificantly improves the intrusion detection performance in all of the\ncollaborating components, with acceptable computation time for online learning.\n","authors":["Mert Nakıp","Baran Can Gül","Erol Gelenbe"],"pdf_url":"https://arxiv.org/pdf/2306.13029v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16769v1","updated":"2023-11-28T13:19:54Z","published":"2023-11-28T13:19:54Z","title":"Equilibrium in the Computing Continuum through Active Inference","summary":"  Computing Continuum (CC) systems are challenged to ensure the intricate\nrequirements of each computational tier. Given the system's scale, the Service\nLevel Objectives (SLOs) which are expressed as these requirements, must be\nbroken down into smaller parts that can be decentralized. We present our\nframework for collaborative edge intelligence enabling individual edge devices\nto (1) develop a causal understanding of how to enforce their SLOs, and (2)\ntransfer knowledge to speed up the onboarding of heterogeneous devices. Through\ncollaboration, they (3) increase the scope of SLO fulfillment. We implemented\nthe framework and evaluated a use case in which a CC system is responsible for\nensuring Quality of Service (QoS) and Quality of Experience (QoE) during video\nstreaming. Our results showed that edge devices required only ten training\nrounds to ensure four SLOs; furthermore, the underlying causal structures were\nalso rationally explainable. The addition of new types of devices can be done a\nposteriori, the framework allowed them to reuse existing models, even though\nthe device type had been unknown. Finally, rebalancing the load within a device\ncluster allowed individual edge devices to recover their SLO compliance after a\nnetwork failure from 22% to 89%.\n","authors":["Boris Sedlak","Victor Casamayor Pujol","Praveen Kumar Donta","Schahram Dustdar"],"pdf_url":"https://arxiv.org/pdf/2311.16769v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16766v1","updated":"2023-11-28T13:14:55Z","published":"2023-11-28T13:14:55Z","title":"Rescuing referral failures during automated diagnosis of domain-shifted\n  medical images","summary":"  The success of deep learning models deployed in the real world depends\ncritically on their ability to generalize well across diverse data domains.\nHere, we address a fundamental challenge with selective classification during\nautomated diagnosis with domain-shifted medical images. In this scenario,\nmodels must learn to avoid making predictions when label confidence is low,\nespecially when tested with samples far removed from the training set\n(covariate shift). Such uncertain cases are typically referred to the clinician\nfor further analysis and evaluation. Yet, we show that even state-of-the-art\ndomain generalization approaches fail severely during referral when tested on\nmedical images acquired from a different demographic or using a different\ntechnology. We examine two benchmark diagnostic medical imaging datasets\nexhibiting strong covariate shifts: i) diabetic retinopathy prediction with\nretinal fundus images and ii) multilabel disease prediction with chest X-ray\nimages. We show that predictive uncertainty estimates do not generalize well\nunder covariate shifts leading to non-monotonic referral curves, and severe\ndrops in performance (up to 50%) at high referral rates (>70%). We evaluate\nnovel combinations of robust generalization and post hoc referral approaches,\nthat rescue these failures and achieve significant performance improvements,\ntypically >10%, over baseline methods. Our study identifies a critical\nchallenge with referral in domain-shifted medical images and finds key\napplications in reliable, automated disease diagnosis.\n","authors":["Anuj Srivastava","Karm Patel","Pradeep Shenoy","Devarajan Sridharan"],"pdf_url":"https://arxiv.org/pdf/2311.16766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.15243v2","updated":"2023-11-28T13:06:43Z","published":"2023-11-26T09:06:40Z","title":"ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection","summary":"  Out-of-distribution (OOD) detection methods often exploit auxiliary outliers\nto train model identifying OOD samples, especially discovering challenging\noutliers from auxiliary outliers dataset to improve OOD detection. However,\nthey may still face limitations in effectively distinguishing between the most\nchallenging OOD samples that are much like in-distribution (ID) data, i.e.,\nID-like samples. To this end, we propose a novel OOD detection framework that\ndiscovers ID-like outliers using CLIP from the vicinity space of the ID\nsamples, thus helping to identify these most challenging OOD samples. Then a\nprompt learning framework is proposed that utilizes the identified ID-like\noutliers to further leverage the capabilities of CLIP for OOD detection.\nBenefiting from the powerful CLIP, we only need a small number of ID samples to\nlearn the prompts of the model without exposing other auxiliary outlier\ndatasets. By focusing on the most challenging ID-like OOD samples and elegantly\nexploiting the capabilities of CLIP, our method achieves superior few-shot\nlearning performance on various real-world image datasets (e.g., in 4-shot OOD\ndetection on the ImageNet-1k dataset, our method reduces the average FPR95 by\n12.16% and improves the average AUROC by 2.76%, compared to state-of-the-art\nmethods).\n","authors":["Yichen Bai","Zongbo Han","Changqing Zhang","Bing Cao","Xiaoheng Jiang","Qinghua Hu"],"pdf_url":"https://arxiv.org/pdf/2311.15243v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2311.16741v1","updated":"2023-11-28T12:39:34Z","published":"2023-11-28T12:39:34Z","title":"Asynchronous Wireless Federated Learning with Probabilistic Client\n  Selection","summary":"  Federated learning (FL) is a promising distributed learning framework where\ndistributed clients collaboratively train a machine learning model coordinated\nby a server. To tackle the stragglers issue in asynchronous FL, we consider\nthat each client keeps local updates and probabilistically transmits the local\nmodel to the server at arbitrary times. We first derive the (approximate)\nexpression for the convergence rate based on the probabilistic client\nselection. Then, an optimization problem is formulated to trade off the\nconvergence rate of asynchronous FL and mobile energy consumption by joint\nprobabilistic client selection and bandwidth allocation. We develop an\niterative algorithm to solve the non-convex problem globally optimally.\nExperiments demonstrate the superiority of the proposed approach compared with\nthe traditional schemes.\n","authors":["Jiarong Yang","Yuan Liu","Fangjiong Chen","Wen Chen","Changle Li"],"pdf_url":"https://arxiv.org/pdf/2311.16741v1.pdf","comment":"To appear in IEEE Transactions on Wireless Communications"},{"id":"http://arxiv.org/abs/2311.12399v2","updated":"2023-11-28T12:32:05Z","published":"2023-11-21T07:22:48Z","title":"A Survey of Graph Meets Large Language Model: Progress and Future\n  Directions","summary":"  Graph plays a significant role in representing and analyzing complex\nrelationships in real-world applications such as citation networks, social\nnetworks, and biological data. Recently, Large Language Models (LLMs), which\nhave achieved tremendous success in various domains, have also been leveraged\nin graph-related tasks to surpass traditional Graph Neural Networks (GNNs)\nbased methods and yield state-of-the-art performance. In this survey, we first\npresent a comprehensive review and analysis of existing methods that integrate\nLLMs with graphs. First of all, we propose a new taxonomy, which organizes\nexisting methods into three categories based on the role (i.e., enhancer,\npredictor, and alignment component) played by LLMs in graph-related tasks. Then\nwe systematically survey the representative methods along the three categories\nof the taxonomy. Finally, we discuss the remaining limitations of existing\nstudies and highlight promising avenues for future research. The relevant\npapers are summarized and will be consistently updated at:\nhttps://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.\n","authors":["Yuhan Li","Zhixun Li","Peisong Wang","Jia Li","Xiangguo Sun","Hong Cheng","Jeffrey Xu Yu"],"pdf_url":"https://arxiv.org/pdf/2311.12399v2.pdf","comment":"Work in progress; 13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.16727v1","updated":"2023-11-28T12:16:06Z","published":"2023-11-28T12:16:06Z","title":"Sluggish and Chemically-Biased Interstitial Diffusion in Concentrated\n  Solid Solution Alloys: Mechanisms and Methods","summary":"  Interstitial diffusion is a pivotal process that governs the phase stability\nand irradiation response of materials in non-equilibrium conditions. In this\nwork, we study sluggish and chemically-biased interstitial diffusion in Fe-Ni\nconcentrated solid solution alloys (CSAs) by combining machine learning (ML)\nand kinetic Monte Carlo (kMC), where ML is used to accurately and efficiently\npredict the migration energy barriers on-the-fly. The ML-kMC reproduces the\ndiffusivity that was reported by molecular dynamics results at high\ntemperatures. With this powerful tool, we find that the observed sluggish\ndiffusion and the \"Ni-Ni-Ni\"-biased diffusion in Fe-Ni alloys are ascribed to a\nunique \"Barrier Lock\" mechanism, whereas the \"Fe-Fe-Fe\"-biased diffusion is\ninfluenced by a \"Component Dominance\" mechanism. Inspired by the mentioned\nmechanisms, a practical AvgS-kMC method is proposed for conveniently and\nswiftly determining interstitial-mediated diffusivity by only relying on the\nmean energy barriers of migration patterns. Combining the AvgS-kMC with the\ndifferential evolutionary algorithm, an inverse design strategy for optimizing\nsluggish diffusion properties is applied to emphasize the crucial role of\nfavorable migration patterns.\n","authors":["Biao Xu","Haijun Fu","Shasha Huang","Shihua Ma","Yaoxu Xiong","Jun Zhang","Xuepeng Xiang","Wenyu Lu","Ji-Jung Kai","Shijun Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.16727v1.pdf","comment":"30 pages,9 figures"},{"id":"http://arxiv.org/abs/2311.16711v1","updated":"2023-11-28T11:45:35Z","published":"2023-11-28T11:45:35Z","title":"LEDITS++: Limitless Image Editing using Text-to-Image Models","summary":"  Text-to-image diffusion models have recently received increasing interest for\ntheir astonishing ability to produce high-fidelity images from solely text\ninputs. Subsequent research efforts aim to exploit and apply their capabilities\nto real image editing. However, existing image-to-image methods are often\ninefficient, imprecise, and of limited versatility. They either require\ntime-consuming fine-tuning, deviate unnecessarily strongly from the input\nimage, and/or lack support for multiple, simultaneous edits. To address these\nissues, we introduce LEDITS++, an efficient yet versatile and precise textual\nimage manipulation technique. LEDITS++'s novel inversion approach requires no\ntuning nor optimization and produces high-fidelity results with a few diffusion\nsteps. Second, our methodology supports multiple simultaneous edits and is\narchitecture-agnostic. Third, we use a novel implicit masking technique that\nlimits changes to relevant image regions. We propose the novel TEdBench++\nbenchmark as part of our exhaustive evaluation. Our results demonstrate the\ncapabilities of LEDITS++ and its improvements over previous methods. The\nproject page is available at https://leditsplusplus-project.static.hf.space .\n","authors":["Manuel Brack","Felix Friedrich","Katharina Kornmeier","Linoy Tsaban","Patrick Schramowski","Kristian Kersting","Apolinário Passos"],"pdf_url":"https://arxiv.org/pdf/2311.16711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16706v1","updated":"2023-11-28T11:29:12Z","published":"2023-11-28T11:29:12Z","title":"Sinkhorn Flow: A Continuous-Time Framework for Understanding and\n  Generalizing the Sinkhorn Algorithm","summary":"  Many problems in machine learning can be formulated as solving\nentropy-regularized optimal transport on the space of probability measures. The\ncanonical approach involves the Sinkhorn iterates, renowned for their rich\nmathematical properties. Recently, the Sinkhorn algorithm has been recast\nwithin the mirror descent framework, thus benefiting from classical\noptimization theory insights. Here, we build upon this result by introducing a\ncontinuous-time analogue of the Sinkhorn algorithm. This perspective allows us\nto derive novel variants of Sinkhorn schemes that are robust to noise and bias.\nMoreover, our continuous-time dynamics not only generalize but also offer a\nunified perspective on several recently discovered dynamics in machine learning\nand mathematics, such as the \"Wasserstein mirror flow\" of (Deb et al. 2023) or\nthe \"mean-field Schr\\\"odinger equation\" of (Claisse et al. 2023).\n","authors":["Mohammad Reza Karimi","Ya-Ping Hsieh","Andreas Krause"],"pdf_url":"https://arxiv.org/pdf/2311.16706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16700v1","updated":"2023-11-28T11:22:08Z","published":"2023-11-28T11:22:08Z","title":"Rethinking Intermediate Layers design in Knowledge Distillation for\n  Kidney and Liver Tumor Segmentation","summary":"  Knowledge distillation(KD) has demonstrated remarkable success across various\ndomains, but its application to medical imaging tasks, such as kidney and liver\ntumor segmentation, has encountered challenges. Many existing KD methods are\nnot specifically tailored for these tasks. Moreover, prevalent KD methods often\nlack a careful consideration of what and from where to distill knowledge from\nthe teacher to the student. This oversight may lead to issues like the\naccumulation of training bias within shallower student layers, potentially\ncompromising the effectiveness of KD. To address these challenges, we propose\nHierarchical Layer-selective Feedback Distillation (HLFD). HLFD strategically\ndistills knowledge from a combination of middle layers to earlier layers and\ntransfers final layer knowledge to intermediate layers at both the feature and\npixel levels. This design allows the model to learn higher-quality\nrepresentations from earlier layers, resulting in a robust and compact student\nmodel. Extensive quantitative evaluations reveal that HLFD outperforms existing\nmethods by a significant margin. For example, in the kidney segmentation task,\nHLFD surpasses the student model (without KD) by over 10pp, significantly\nimproving its focus on tumor-specific features. From a qualitative standpoint,\nthe student model trained using HLFD excels at suppressing irrelevant\ninformation and can focus sharply on tumor-specific details, which opens a new\npathway for more efficient and accurate diagnostic tools.\n","authors":["Vandan Gorade","Sparsh Mittal","Debesh Jha","Ulas Bagci"],"pdf_url":"https://arxiv.org/pdf/2311.16700v1.pdf","comment":"Under-review at ISBI-2024"},{"id":"http://arxiv.org/abs/2306.07745v2","updated":"2023-11-28T11:11:54Z","published":"2023-06-13T13:01:42Z","title":"Kernelized Reinforcement Learning with Order Optimal Regret Bounds","summary":"  Reinforcement learning (RL) has shown empirical success in various real world\nsettings with complex models and large state-action spaces. The existing\nanalytical results, however, typically focus on settings with a small number of\nstate-actions or simple models such as linearly modeled state-action value\nfunctions. To derive RL policies that efficiently handle large state-action\nspaces with more general value functions, some recent works have considered\nnonlinear function approximation using kernel ridge regression. We propose\n$\\pi$-KRVI, an optimistic modification of least-squares value iteration, when\nthe state-action value function is represented by a reproducing kernel Hilbert\nspace (RKHS). We prove the first order-optimal regret guarantees under a\ngeneral setting. Our results show a significant polynomial in the number of\nepisodes improvement over the state of the art. In particular, with highly\nnon-smooth kernels (such as Neural Tangent kernel or some Mat\\'ern kernels) the\nexisting results lead to trivial (superlinear in the number of episodes) regret\nbounds. We show a sublinear regret bound that is order optimal in the case of\nMat\\'ern kernels where a lower bound on regret is known.\n","authors":["Sattar Vakili","Julia Olkhovskaya"],"pdf_url":"https://arxiv.org/pdf/2306.07745v2.pdf","comment":"Advances in Neural Information Processing Systems (NeurIPS)"},{"id":"http://arxiv.org/abs/2307.12689v2","updated":"2023-11-28T10:59:01Z","published":"2023-07-24T11:04:22Z","title":"Addressing the Impact of Localized Training Data in Graph Neural\n  Networks","summary":"  Graph Neural Networks (GNNs) have achieved notable success in learning from\ngraph-structured data, owing to their ability to capture intricate dependencies\nand relationships between nodes. They excel in various applications, including\nsemi-supervised node classification, link prediction, and graph generation.\nHowever, it is important to acknowledge that the majority of state-of-the-art\nGNN models are built upon the assumption of an in-distribution setting, which\nhinders their performance on real-world graphs with dynamic structures. In this\narticle, we aim to assess the impact of training GNNs on localized subsets of\nthe graph. Such restricted training data may lead to a model that performs well\nin the specific region it was trained on but fails to generalize and make\naccurate predictions for the entire graph. In the context of graph-based\nsemi-supervised learning (SSL), resource constraints often lead to scenarios\nwhere the dataset is large, but only a portion of it can be labeled, affecting\nthe model's performance. This limitation affects tasks like anomaly detection\nor spam detection when labeling processes are biased or influenced by human\nsubjectivity. To tackle the challenges posed by localized training data, we\napproach the problem as an out-of-distribution (OOD) data issue by by aligning\nthe distributions between the training data, which represents a small portion\nof labeled data, and the graph inference process that involves making\npredictions for the entire graph. We propose a regularization method to\nminimize distributional discrepancies between localized training data and graph\ninference, improving model performance on OOD data. Extensive tests on popular\nGNN models show significant performance improvement on three citation GNN\nbenchmark datasets. The regularization approach effectively enhances model\nadaptation and generalization, overcoming challenges posed by OOD data.\n","authors":["Akansha A"],"pdf_url":"https://arxiv.org/pdf/2307.12689v2.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2311.16683v1","updated":"2023-11-28T10:55:00Z","published":"2023-11-28T10:55:00Z","title":"Hyper-Relational Knowledge Graph Neural Network for Next POI","summary":"  With the advancement of mobile technology, Point of Interest (POI)\nrecommendation systems in Location-based Social Networks (LBSN) have brought\nnumerous benefits to both users and companies. Many existing works employ\nKnowledge Graph (KG) to alleviate the data sparsity issue in LBSN. These\napproaches primarily focus on modeling the pair-wise relations in LBSN to\nenrich the semantics and thereby relieve the data sparsity issue. However,\nexisting approaches seldom consider the hyper-relations in LBSN, such as the\nmobility relation (a 3-ary relation: user-POI-time). This makes the model hard\nto exploit the semantics accurately. In addition, prior works overlook the rich\nstructural information inherent in KG, which consists of higher-order relations\nand can further alleviate the impact of data sparsity.To this end, we propose a\nHyper-Relational Knowledge Graph Neural Network (HKGNN) model. In HKGNN, a\nHyper-Relational Knowledge Graph (HKG) that models the LBSN data is constructed\nto maintain and exploit the rich semantics of hyper-relations. Then we proposed\na Hypergraph Neural Network to utilize the structural information of HKG in a\ncohesive way. In addition, a self-attention network is used to leverage\nsequential information and make personalized recommendations. Furthermore, side\ninformation, essential in reducing data sparsity by providing background\nknowledge of POIs, is not fully utilized in current methods. In light of this,\nwe extended the current dataset with available side information to further\nlessen the impact of data sparsity. Results of experiments on four real-world\nLBSN datasets demonstrate the effectiveness of our approach compared to\nexisting state-of-the-art methods.\n","authors":["Jixiao Zhang","Yongkang Li","Ruotong Zou","Jingyuan Zhang","Zipei Fan","Xuan Song"],"pdf_url":"https://arxiv.org/pdf/2311.16683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.11526v2","updated":"2023-11-28T10:47:37Z","published":"2023-09-20T06:55:39Z","title":"Likelihood-based Sensor Calibration using Affine Transformation","summary":"  An important task in the field of sensor technology is the efficient\nimplementation of adaptation procedures of measurements from one sensor to\nanother sensor of identical design. One idea is to use the estimation of an\naffine transformation between different systems, which can be improved by the\nknowledge of experts. This paper presents an improved solution from Glacier\nResearch that was published back in 1973. The results demonstrate the\nadaptability of this solution for various applications, including software\ncalibration of sensors, implementation of expert-based adaptation, and paving\nthe way for future advancements such as distributed learning methods. One idea\nhere is to use the knowledge of experts for estimating an affine transformation\nbetween different systems. We evaluate our research with simulations and also\nwith real measured data of a multi-sensor board with 8 identical sensors. Both\ndata set and evaluation script are provided for download. The results show an\nimprovement for both the simulation and the experiments with real data.\n","authors":["Rüdiger Machhamer","Lejla Begic Fazlic","Eray Guven","David Junk","Gunes Karabulut Kurt","Stefan Naumann","Stephan Didas","Klaus-Uwe Gollmer","Ralph Bergmann","Ingo J. Timm","Guido Dartmann"],"pdf_url":"https://arxiv.org/pdf/2309.11526v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.10099v2","updated":"2023-11-28T10:35:06Z","published":"2023-08-19T20:10:54Z","title":"Geometric instability of graph neural networks on large graphs","summary":"  We analyse the geometric instability of embeddings produced by graph neural\nnetworks (GNNs). Existing methods are only applicable for small graphs and lack\ncontext in the graph domain. We propose a simple, efficient and graph-native\nGraph Gram Index (GGI) to measure such instability which is invariant to\npermutation, orthogonal transformation, translation and order of evaluation.\nThis allows us to study the varying instability behaviour of GNN embeddings on\nlarge graphs for both node classification and link prediction.\n","authors":["Emily Morris","Haotian Shen","Weiling Du","Muhammad Hamza Sajjad","Borun Shi"],"pdf_url":"https://arxiv.org/pdf/2308.10099v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16670v1","updated":"2023-11-28T10:34:48Z","published":"2023-11-28T10:34:48Z","title":"PyTorch Geometric High Order: A Unified Library for High Order Graph\n  Neural Network","summary":"  We introduce PyTorch Geometric High Order (PyGHO), a library for High Order\nGraph Neural Networks (HOGNNs) that extends PyTorch Geometric (PyG). Unlike\nordinary Message Passing Neural Networks (MPNNs) that exchange messages between\nnodes, HOGNNs, encompassing subgraph GNNs and k-WL GNNs, encode node tuples, a\nmethod previously lacking a standardized framework and often requiring complex\ncoding. PyGHO's main objective is to provide an unified and user-friendly\ninterface for various HOGNNs. It accomplishes this through streamlined data\nstructures for node tuples, comprehensive data processing utilities, and a\nflexible suite of operators for high-order GNN methodologies. In this work, we\npresent a detailed in-depth of PyGHO and compare HOGNNs implemented with PyGHO\nwith their official implementation on real-world tasks. PyGHO achieves up to\n$50\\%$ acceleration and reduces the code needed for implementation by an order\nof magnitude. Our library is available at\n\\url{https://github.com/GraphPKU/PygHO}.\n","authors":["Xiyuan Wang","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.16670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16666v1","updated":"2023-11-28T10:28:35Z","published":"2023-11-28T10:28:35Z","title":"MultiModal-Learning for Predicting Molecular Properties: A Framework\n  Based on Image and Graph Structures","summary":"  The quest for accurate prediction of drug molecule properties poses a\nfundamental challenge in the realm of Artificial Intelligence Drug Discovery\n(AIDD). An effective representation of drug molecules emerges as a pivotal\ncomponent in this pursuit. Contemporary leading-edge research predominantly\nresorts to self-supervised learning (SSL) techniques to extract meaningful\nstructural representations from large-scale, unlabeled molecular data,\nsubsequently fine-tuning these representations for an array of downstream\ntasks. However, an inherent shortcoming of these studies lies in their singular\nreliance on one modality of molecular information, such as molecule image or\nSMILES representations, thus neglecting the potential complementarity of\nvarious molecular modalities. In response to this limitation, we propose MolIG,\na novel MultiModaL molecular pre-training framework for predicting molecular\nproperties based on Image and Graph structures. MolIG model innovatively\nleverages the coherence and correlation between molecule graph and molecule\nimage to execute self-supervised tasks, effectively amalgamating the strengths\nof both molecular representation forms. This holistic approach allows for the\ncapture of pivotal molecular structural characteristics and high-level semantic\ninformation. Upon completion of pre-training, Graph Neural Network (GNN)\nEncoder is used for the prediction of downstream tasks. In comparison to\nadvanced baseline models, MolIG exhibits enhanced performance in downstream\ntasks pertaining to molecular property prediction within benchmark groups such\nas MoleculeNet Benchmark Group and ADMET Benchmark Group.\n","authors":["Zhuoyuan Wang","Jiacong Mi","Shan Lu","Jieyue He"],"pdf_url":"https://arxiv.org/pdf/2311.16666v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2212.04548v2","updated":"2023-11-28T10:20:09Z","published":"2022-12-08T20:24:59Z","title":"STLGRU: Spatio-Temporal Lightweight Graph GRU for Traffic Flow\n  Prediction","summary":"  Reliable forecasting of traffic flow requires efficient modeling of traffic\ndata. Different correlations and influences arise in a dynamic traffic network,\nmaking modeling a complicated task. Existing literature has proposed many\ndifferent methods to capture the complex underlying spatial-temporal relations\nof traffic networks. However, methods still struggle to capture different local\nand global dependencies of long-range nature. Also, as more and more\nsophisticated methods are being proposed, models are increasingly becoming\nmemory-heavy and, thus, unsuitable for low-powered devices. In this paper, we\nfocus on solving these problems by proposing a novel deep learning framework -\nSTLGRU. Specifically, our proposed STLGRU can effectively capture both local\nand global spatial-temporal relations of a traffic network using\nmemory-augmented attention and gating mechanism. Instead of employing separate\ntemporal and spatial components, we show that our memory module and gated unit\ncan learn the spatial-temporal dependencies successfully, allowing for reduced\nmemory usage with fewer parameters. We extensively experiment on several\nreal-world traffic prediction datasets to show that our model performs better\nthan existing methods while the memory footprint remains lower. Code is\navailable at \\url{https://github.com/Kishor-Bhaumik/STLGRU}.\n","authors":["Kishor Kumar Bhaumik","Fahim Faisal Niloy","Saif Mahmud","Simon Woo"],"pdf_url":"https://arxiv.org/pdf/2212.04548v2.pdf","comment":"We withdraw for now and shall further work on the manuscript and\n  upload it again"},{"id":"http://arxiv.org/abs/2311.16656v1","updated":"2023-11-28T10:17:52Z","published":"2023-11-28T10:17:52Z","title":"Pseudo-Likelihood Inference","summary":"  Simulation-Based Inference (SBI) is a common name for an emerging family of\napproaches that infer the model parameters when the likelihood is intractable.\nExisting SBI methods either approximate the likelihood, such as Approximate\nBayesian Computation (ABC) or directly model the posterior, such as Sequential\nNeural Posterior Estimation (SNPE). While ABC is efficient on low-dimensional\nproblems, on higher-dimensional tasks, it is generally outperformed by SNPE,\nwhich leverages function approximation. In this paper, we propose\nPseudo-Likelihood Inference (PLI), a new method that brings neural\napproximation into ABC, making it competitive on challenging Bayesian system\nidentification tasks. By utilizing integral probability metrics, we introduce a\nsmooth likelihood kernel with an adaptive bandwidth that is updated based on\ninformation-theoretic trust regions. Thanks to this formulation, our method (i)\nallows for optimizing neural posteriors via gradient descent, (ii) does not\nrely on summary statistics, and (iii) enables multiple observations as input.\nIn comparison to SNPE, it leads to improved performance when more data is\navailable. The effectiveness of PLI is evaluated on four classical SBI\nbenchmark tasks and on a highly dynamic physical system, showing particular\nadvantages on stochastic simulations and multi-modal posterior landscapes.\n","authors":["Theo Gruner","Boris Belousov","Fabio Muratore","Daniel Palenicek","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2311.16656v1.pdf","comment":"27 pages, 12 figures, Published as a conference paper at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.16654v1","updated":"2023-11-28T10:13:31Z","published":"2023-11-28T10:13:31Z","title":"Elucidating Discrepancy in Explanations of Predictive Models Developed\n  using EMR","summary":"  The lack of transparency and explainability hinders the clinical adoption of\nMachine learning (ML) algorithms. While explainable artificial intelligence\n(XAI) methods have been proposed, little research has focused on the agreement\nbetween these methods and expert clinical knowledge. This study applies current\nstate-of-the-art explainability methods to clinical decision support algorithms\ndeveloped for Electronic Medical Records (EMR) data to analyse the concordance\nbetween these factors and discusses causes for identified discrepancies from a\nclinical and technical perspective. Important factors for achieving trustworthy\nXAI solutions for clinical decision support are also discussed.\n","authors":["Aida Brankovic","Wenjie Huang","David Cook","Sankalp Khanna","Konstanty Bialkowski"],"pdf_url":"https://arxiv.org/pdf/2311.16654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14971v2","updated":"2023-11-28T10:08:35Z","published":"2023-11-25T09:08:30Z","title":"Segmentation of diagnostic tissue compartments on whole slide images\n  with renal thrombotic microangiopathies (TMAs)","summary":"  The thrombotic microangiopathies (TMAs) manifest in renal biopsy histology\nwith a broad spectrum of acute and chronic findings. Precise diagnostic\ncriteria for a renal biopsy diagnosis of TMA are missing. As a first step\ntowards a machine learning- and computer vision-based analysis of wholes slide\nimages from renal biopsies, we trained a segmentation model for the decisive\ndiagnostic kidney tissue compartments artery, arteriole, glomerulus on a set of\nwhole slide images from renal biopsies with TMAs and Mimickers (distinct\ndiseases with a similar nephropathological appearance as TMA like severe benign\nnephrosclerosis, various vasculitides, Bevacizumab-plug glomerulopathy,\narteriolar light chain deposition disease). Our segmentation model combines a\nU-Net-based tissue detection with a Shifted windows-transformer architecture to\nreach excellent segmentation results for even the most severely altered\nglomeruli, arterioles and arteries, even on unseen staining domains from a\ndifferent nephropathology lab. With accurate automatic segmentation of the\ndecisive renal biopsy compartments in human renal vasculopathies, we have laid\nthe foundation for large-scale compartment-specific machine learning and\ncomputer vision analysis of renal biopsy repositories with TMAs.\n","authors":["Huy Q. Vo","Pietro A. Cicalese","Surya Seshan","Syed A. Rizvi","Aneesh Vathul","Gloria Bueno","Anibal Pedraza Dorado","Niels Grabe","Katharina Stolle","Francesco Pesce","Joris J. T. H. Roelofs","Jesper Kers","Vitoantonio Bevilacqua","Nicola Altini","Bernd Schröppel","Dario Roccatello","Antonella Barreca","Savino Sciascia","Chandra Mohan","Hien V. Nguyen","Jan U. Becker"],"pdf_url":"https://arxiv.org/pdf/2311.14971v2.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2311.16646v1","updated":"2023-11-28T09:53:05Z","published":"2023-11-28T09:53:05Z","title":"Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method\n  Perspective","summary":"  Dataset distillation offers a potential means to enhance data efficiency in\ndeep learning. Recent studies have shown its ability to counteract backdoor\nrisks present in original training samples. In this study, we delve into the\ntheoretical aspects of backdoor attacks and dataset distillation based on\nkernel methods. We introduce two new theory-driven trigger pattern generation\nmethods specialized for dataset distillation. Following a comprehensive set of\nanalyses and experiments, we show that our optimization-based trigger design\nframework informs effective backdoor attacks on dataset distillation. Notably,\ndatasets poisoned by our designed trigger prove resilient against conventional\nbackdoor attack detection and mitigation methods. Our empirical results\nvalidate that the triggers developed using our approaches are proficient at\nexecuting resilient backdoor attacks.\n","authors":["Ming-Yu Chung","Sheng-Yen Chou","Chia-Mu Yu","Pin-Yu Chen","Sy-Yen Kuo","Tsung-Yi Ho"],"pdf_url":"https://arxiv.org/pdf/2311.16646v1.pdf","comment":"19 pages, 4 figures"},{"id":"http://arxiv.org/abs/2311.16632v1","updated":"2023-11-28T09:34:44Z","published":"2023-11-28T09:34:44Z","title":"Opening the Black Box: Towards inherently interpretable energy data\n  imputation models using building physics insight","summary":"  Missing data are frequently observed by practitioners and researchers in the\nbuilding energy modeling community. In this regard, advanced data-driven\nsolutions, such as Deep Learning methods, are typically required to reflect the\nnon-linear behavior of these anomalies. As an ongoing research question related\nto Deep Learning, a model's applicability to limited data settings can be\nexplored by introducing prior knowledge in the network. This same strategy can\nalso lead to more interpretable predictions, hence facilitating the field\napplication of the approach. For that purpose, the aim of this paper is to\npropose the use of Physics-informed Denoising Autoencoders (PI-DAE) for missing\ndata imputation in commercial buildings. In particular, the presented method\nenforces physics-inspired soft constraints to the loss function of a Denoising\nAutoencoder (DAE). In order to quantify the benefits of the physical component,\nan ablation study between different DAE configurations is conducted. First,\nthree univariate DAEs are optimized separately on indoor air temperature,\nheating, and cooling data. Then, two multivariate DAEs are derived from the\nprevious configurations. Eventually, a building thermal balance equation is\ncoupled to the last multivariate configuration to obtain PI-DAE. Additionally,\ntwo commonly used benchmarks are employed to support the findings. It is shown\nhow introducing physical knowledge in a multivariate Denoising Autoencoder can\nenhance the inherent model interpretability through the optimized physics-based\ncoefficients. While no significant improvement is observed in terms of\nreconstruction error with the proposed PI-DAE, its enhanced robustness to\nvarying rates of missing data and the valuable insights derived from the\nphysics-based coefficients create opportunities for wider applications within\nbuilding systems and the built environment.\n","authors":["Antonio Liguori","Matias Quintana","Chun Fu","Clayton Miller","Jérôme Frisch","Christoph van Treeck"],"pdf_url":"https://arxiv.org/pdf/2311.16632v1.pdf","comment":"Under review in Energy and Buildings"},{"id":"http://arxiv.org/abs/2311.16630v1","updated":"2023-11-28T09:30:52Z","published":"2023-11-28T09:30:52Z","title":"Outfit Completion via Conditional Set Transformation","summary":"  In this paper, we formulate the outfit completion problem as a set retrieval\ntask and propose a novel framework for solving this problem. The proposal\nincludes a conditional set transformation architecture with deep neural\nnetworks and a compatibility-based regularization method. The proposed method\nutilizes a map with permutation-invariant for the input set and\npermutation-equivariant for the condition set. This allows retrieving a set\nthat is compatible with the input set while reflecting the properties of the\ncondition set. In addition, since this structure outputs the element of the\noutput set in a single inference, it can achieve a scalable inference speed\nwith respect to the cardinality of the output set. Experimental results on real\ndata reveal that the proposed method outperforms existing approaches in terms\nof accuracy of the outfit completion task, condition satisfaction, and\ncompatibility of completion results.\n","authors":["Takuma Nakamura","Yuki Saito","Ryosuke Goto"],"pdf_url":"https://arxiv.org/pdf/2311.16630v1.pdf","comment":"8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2311.16628v1","updated":"2023-11-28T09:27:44Z","published":"2023-11-28T09:27:44Z","title":"Symmetry-regularized neural ordinary differential equations","summary":"  Neural Ordinary Differential Equations (Neural ODEs) is a class of deep\nneural network models that interpret the hidden state dynamics of neural\nnetworks as an ordinary differential equation, thereby capable of capturing\nsystem dynamics in a continuous time framework. In this work, I integrate\nsymmetry regularization into Neural ODEs. In particular, I use continuous Lie\nsymmetry of ODEs and PDEs associated with the model to derive conservation laws\nand add them to the loss function, making it physics-informed. This\nincorporation of inherent structural properties into the loss function could\nsignificantly improve robustness and stability of the model during training. To\nillustrate this method, I employ a toy model that utilizes a cosine rate of\nchange in the hidden state, showcasing the process of identifying Lie\nsymmetries, deriving conservation laws, and constructing a new loss function.\n","authors":["Wenbo Hao"],"pdf_url":"https://arxiv.org/pdf/2311.16628v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16625v1","updated":"2023-11-28T09:25:23Z","published":"2023-11-28T09:25:23Z","title":"Gaussian Processes for Monitoring Air-Quality in Kampala","summary":"  Monitoring air pollution is of vital importance to the overall health of the\npopulation. Unfortunately, devices that can measure air quality can be\nexpensive, and many cities in low and middle-income countries have to rely on a\nsparse allocation of them. In this paper, we investigate the use of Gaussian\nProcesses for both nowcasting the current air-pollution in places where there\nare no sensors and forecasting the air-pollution in the future at the sensor\nlocations. In particular, we focus on the city of Kampala in Uganda, using data\nfrom AirQo's network of sensors. We demonstrate the advantage of removing\noutliers, compare different kernel functions and additional inputs. We also\ncompare two sparse approximations to allow for the large amounts of temporal\ndata in the dataset.\n","authors":["Clara Stoddart","Lauren Shrack","Richard Sserunjogi","Usman Abdul-Ganiy","Engineer Bainomugisha","Deo Okure","Ruth Misener","Jose Pablo Folch","Ruby Sedgwick"],"pdf_url":"https://arxiv.org/pdf/2311.16625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.07221v3","updated":"2023-11-28T09:23:51Z","published":"2023-02-14T17:51:00Z","title":"On the Role of Randomization in Adversarially Robust Classification","summary":"  Deep neural networks are known to be vulnerable to small adversarial\nperturbations in test data. To defend against adversarial attacks,\nprobabilistic classifiers have been proposed as an alternative to deterministic\nones. However, literature has conflicting findings on the effectiveness of\nprobabilistic classifiers in comparison to deterministic ones. In this paper,\nwe clarify the role of randomization in building adversarially robust\nclassifiers. Given a base hypothesis set of deterministic classifiers, we show\nthe conditions under which a randomized ensemble outperforms the hypothesis set\nin adversarial risk, extending previous results. Additionally, we show that for\nany probabilistic binary classifier (including randomized ensembles), there\nexists a deterministic classifier that outperforms it. Finally, we give an\nexplicit description of the deterministic hypothesis set that contains such a\ndeterministic classifier for many types of commonly used probabilistic\nclassifiers, i.e. randomized ensembles and parametric/input noise injection.\n","authors":["Lucas Gnecco-Heredia","Yann Chevaleyre","Benjamin Negrevergne","Laurent Meunier","Muni Sreenivas Pydi"],"pdf_url":"https://arxiv.org/pdf/2302.07221v3.pdf","comment":"10 pages main paper (27 total), 2 figures in main paper. Neurips 2023"},{"id":"http://arxiv.org/abs/2311.16621v1","updated":"2023-11-28T09:22:17Z","published":"2023-11-28T09:22:17Z","title":"Beyond Labels: Advancing Cluster Analysis with the Entropy of Distance\n  Distribution (EDD)","summary":"  In the evolving landscape of data science, the accurate quantification of\nclustering in high-dimensional data sets remains a significant challenge,\nespecially in the absence of predefined labels. This paper introduces a novel\napproach, the Entropy of Distance Distribution (EDD), which represents a\nparadigm shift in label-free clustering analysis. Traditional methods, reliant\non discrete labels, often struggle to discern intricate cluster patterns in\nunlabeled data. EDD, however, leverages the characteristic differences in\npairwise point-to-point distances to discern clustering tendencies, independent\nof data labeling.\n  Our method employs the Shannon information entropy to quantify the\n'peakedness' or 'flatness' of distance distributions in a data set. This\nentropy measure, normalized against its maximum value, effectively\ndistinguishes between strongly clustered data (indicated by pronounced peaks in\ndistance distribution) and more homogeneous, non-clustered data sets. This\nlabel-free quantification is resilient against global translations and\npermutations of data points, and with an additional dimension-wise z-scoring,\nit becomes invariant to data set scaling.\n  We demonstrate the efficacy of EDD through a series of experiments involving\ntwo-dimensional data spaces with Gaussian cluster centers. Our findings reveal\na monotonic increase in the EDD value with the widening of cluster widths,\nmoving from well-separated to overlapping clusters. This behavior underscores\nthe method's sensitivity and accuracy in detecting varying degrees of\nclustering. EDD's potential extends beyond conventional clustering analysis,\noffering a robust, scalable tool for unraveling complex data structures without\nreliance on pre-assigned labels.\n","authors":["Claus Metzner","Achim Schilling","Patrick Krauss"],"pdf_url":"https://arxiv.org/pdf/2311.16621v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16620v1","updated":"2023-11-28T09:21:48Z","published":"2023-11-28T09:21:48Z","title":"On the Long Range Abilities of Transformers","summary":"  Despite their dominance in modern DL and, especially, NLP domains,\ntransformer architectures exhibit sub-optimal performance on long-range tasks\ncompared to recent layers that are specifically designed for this purpose. In\nthis work, drawing inspiration from key attributes of long-range layers, such\nas state-space layers, linear RNN layers, and global convolution layers, we\ndemonstrate that minimal modifications to the transformer architecture can\nsignificantly enhance performance on the Long Range Arena (LRA) benchmark, thus\nnarrowing the gap with these specialized layers. We identify that two key\nprinciples for long-range tasks are (i) incorporating an inductive bias towards\nsmoothness, and (ii) locality. As we show, integrating these ideas into the\nattention mechanism improves results with a negligible amount of additional\ncomputation and without any additional trainable parameters. Our theory and\nexperiments also shed light on the reasons for the inferior performance of\ntransformers on long-range tasks and identify critical properties that are\nessential for successfully capturing long-range dependencies.\n","authors":["Itamar Zimerman","Lior Wolf"],"pdf_url":"https://arxiv.org/pdf/2311.16620v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2311.16616v1","updated":"2023-11-28T09:12:37Z","published":"2023-11-28T09:12:37Z","title":"Adversarial Distribution Balancing for Counterfactual Reasoning","summary":"  The development of causal prediction models is challenged by the fact that\nthe outcome is only observable for the applied (factual) intervention and not\nfor its alternatives (the so-called counterfactuals); in medicine we only know\npatients' survival for the administered drug and not for other therapeutic\noptions. Machine learning approaches for counterfactual reasoning have to deal\nwith both unobserved outcomes and distributional differences due to non-random\ntreatment administration. Unsupervised domain adaptation (UDA) addresses\nsimilar issues; one has to deal with unobserved outcomes -- the labels of the\ntarget domain -- and distributional differences between source and target\ndomain. We propose Adversarial Distribution Balancing for Counterfactual\nReasoning (ADBCR), which directly uses potential outcome estimates of the\ncounterfactuals to remove spurious causal relations. We show that ADBCR\noutcompetes state-of-the-art methods on three benchmark datasets, and\ndemonstrate that ADBCR's performance can be further improved if unlabeled\nvalidation data are included in the training procedure to better adapt the\nmodel to the validation domain.\n","authors":["Stefan Schrod","Fabian Sinz","Michael Altenbuchinger"],"pdf_url":"https://arxiv.org/pdf/2311.16616v1.pdf","comment":"Implementation available at https://github.com/sschrod/ADBCR"},{"id":"http://arxiv.org/abs/2311.16614v1","updated":"2023-11-28T09:11:02Z","published":"2023-11-28T09:11:02Z","title":"A Multivariate Unimodality Test Harnenssing the Dip Statistic of\n  Mahalanobis Distances Over Random Projections","summary":"  Unimodality, pivotal in statistical analysis, offers insights into dataset\nstructures and drives sophisticated analytical procedures. While unimodality's\nconfirmation is straightforward for one-dimensional data using methods like\nSilverman's approach and Hartigans' dip statistic, its generalization to higher\ndimensions remains challenging. By extrapolating one-dimensional unimodality\nprinciples to multi-dimensional spaces through linear random projections and\nleveraging point-to-point distancing, our method, rooted in\n$\\alpha$-unimodality assumptions, presents a novel multivariate unimodality\ntest named mud-pod. Both theoretical and empirical studies confirm the efficacy\nof our method in unimodality assessment of multidimensional datasets as well as\nin estimating the number of clusters.\n","authors":["Prodromos Kolyvakis","Aristidis Likas"],"pdf_url":"https://arxiv.org/pdf/2311.16614v1.pdf","comment":"12 pages, 1 figure"},{"id":"http://arxiv.org/abs/2311.16609v1","updated":"2023-11-28T08:54:29Z","published":"2023-11-28T08:54:29Z","title":"Eigenmatrix for unstructured sparse recovery","summary":"  This paper considers the unstructured sparse recovery problems in a general\nform. Examples include rational approximation, spectral function estimation,\nFourier inversion, Laplace inversion, and sparse deconvolution. The main\nchallenges are the noise in the sample values and the unstructured nature of\nthe sample locations. This paper proposes the eigenmatrix, a data-driven\nconstruction with desired approximate eigenvalues and eigenvectors. The\neigenmatrix offers a new way for these sparse recovery problems. Numerical\nresults are provided to demonstrate the efficiency of the proposed method.\n","authors":["Lexing Ying"],"pdf_url":"https://arxiv.org/pdf/2311.16609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02691v2","updated":"2023-11-28T08:54:13Z","published":"2023-10-04T10:02:49Z","title":"Robust Ocean Subgrid-Scale Parameterizations Using Fourier Neural\n  Operators","summary":"  In climate simulations, small-scale processes shape ocean dynamics but remain\ncomputationally expensive to resolve directly. For this reason, their\ncontributions are commonly approximated using empirical parameterizations,\nwhich lead to significant errors in long-term projections. In this work, we\ndevelop parameterizations based on Fourier Neural Operators, showcasing their\naccuracy and generalizability in comparison to other approaches. Finally, we\ndiscuss the potential and limitations of neural networks operating in the\nfrequency domain, paving the way for future investigation.\n","authors":["Victor Mangeleer","Gilles Louppe"],"pdf_url":"https://arxiv.org/pdf/2310.02691v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16605v1","updated":"2023-11-28T08:45:37Z","published":"2023-11-28T08:45:37Z","title":"LasTGL: An Industrial Framework for Large-Scale Temporal Graph Learning","summary":"  Over the past few years, graph neural networks (GNNs) have become powerful\nand practical tools for learning on (static) graph-structure data. However,\nmany real-world applications, such as social networks and e-commerce, involve\ntemporal graphs where nodes and edges are dynamically evolving. Temporal graph\nneural networks (TGNNs) have progressively emerged as an extension of GNNs to\naddress time-evolving graphs and have gradually become a trending research\ntopic in both academics and industry. Advancing research in such an emerging\nfield requires new tools to compose TGNN models and unify their different\nschemes in dealing with temporal graphs. To facilitate research and application\nin temporal graph learning, we introduce LasTGL, an industrial framework that\nintegrates unified and extensible implementations of common temporal graph\nlearning algorithms for various advanced tasks. The purpose of LasTGL is to\nprovide the essential building blocks for solving temporal graph learning\ntasks, focusing on the guiding principles of user-friendliness and quick\nprototyping on which PyTorch is based. In particular, LasTGL provides\ncomprehensive temporal graph datasets, TGNN models and utilities along with\nwell-documented tutorials, making it suitable for both absolute beginners and\nexpert deep learning practitioners alike.\n","authors":["Jintang Li","Jiawang Dan","Ruofan Wu","Jing Zhou","Sheng Tian","Yunfei Liu","Baokun Wang","Changhua Meng","Weiqiang Wang","Yuchang Zhu","Liang Chen","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2311.16605v1.pdf","comment":"Preprint; Work in progress"},{"id":"http://arxiv.org/abs/2310.08165v2","updated":"2023-11-28T08:45:13Z","published":"2023-10-12T09:37:56Z","title":"COVID-19 detection using ViT transformer-based approach from Computed\n  Tomography Images","summary":"  In here, we introduce a novel approach to enhance the accuracy and efficiency\nof COVID-19 diagnosis using CT images. Leveraging state-of-the-art Transformer\nmodels in computer vision, we employed the base ViT Transformer configured for\n224x224-sized input images, modifying the output to suit the binary\nclassification task. Notably, input images were resized from the standard CT\nscan size of 512x512 to match the model's expectations. Our method implements a\nsystematic patient-level prediction strategy, classifying individual CT slices\nas COVID-19 or non-COVID. To determine the overall diagnosis for each patient,\na majority voting approach as well as other thresholding approaches were\nemployed. This method involves evaluating all CT slices for a given patient and\nassigning the patient the diagnosis that relates to the thresholding for the CT\nscan. This meticulous patient-level prediction process contributes to the\nrobustness of our solution as it starts from 2D-slices to 3D-patient level.\nThroughout the evaluation process, our approach resulted in 0.7 macro F1 score\non the COV19-CT -DB validation set. To ensure the reliability and effectiveness\nof our model, we rigorously validate it on the extensive COV-19 CT dataset,\nwhich is meticulously annotated for the task. This dataset, with its\ncomprehensive annotations, reinforces the overall robustness of our solution.\n","authors":["Kenan Morani"],"pdf_url":"https://arxiv.org/pdf/2310.08165v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16604v1","updated":"2023-11-28T08:44:04Z","published":"2023-11-28T08:44:04Z","title":"LC4SV: A Denoising Framework Learning to Compensate for Unseen Speaker\n  Verification Models","summary":"  The performance of speaker verification (SV) models may drop dramatically in\nnoisy environments. A speech enhancement (SE) module can be used as a front-end\nstrategy. However, existing SE methods may fail to bring performance\nimprovements to downstream SV systems due to artifacts in the predicted signals\nof SE models. To compensate for artifacts, we propose a generic denoising\nframework named LC4SV, which can serve as a pre-processor for various unknown\ndownstream SV models. In LC4SV, we employ a learning-based interpolation agent\nto automatically generate the appropriate coefficients between the enhanced\nsignal and its noisy input to improve SV performance in noisy environments. Our\nexperimental results demonstrate that LC4SV consistently improves the\nperformance of various unseen SV systems. To the best of our knowledge, this\nwork is the first attempt to develop a learning-based interpolation scheme\naiming at improving SV performance in noisy environments.\n","authors":["Chi-Chang Lee","Hong-Wei Chen","Chu-Song Chen","Hsin-Min Wang","Tsung-Te Liu","Yu Tsao"],"pdf_url":"https://arxiv.org/pdf/2311.16604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16602v1","updated":"2023-11-28T08:43:10Z","published":"2023-11-28T08:43:10Z","title":"GSP-KalmanNet: Tracking Graph Signals via Neural-Aided Kalman Filtering","summary":"  Dynamic systems of graph signals are encountered in various applications,\nincluding social networks, power grids, and transportation. While such systems\ncan often be described as state space (SS) models, tracking graph signals via\nconventional tools based on the Kalman filter (KF) and its variants is\ntypically challenging. This is due to the nonlinearity, high dimensionality,\nirregularity of the domain, and complex modeling associated with real-world\ndynamic systems of graph signals. In this work, we study the tracking of graph\nsignals using a hybrid model-based/data-driven approach. We develop the\nGSP-KalmanNet, which tracks the hidden graphical states from the graphical\nmeasurements by jointly leveraging graph signal processing (GSP) tools and deep\nlearning (DL) techniques. The derivations of the GSP-KalmanNet are based on\nextending the KF to exploit the inherent graph structure via graph frequency\ndomain filtering, which considerably simplifies the computational complexity\nentailed in processing high-dimensional signals and increases the robustness to\nsmall topology changes. Then, we use data to learn the Kalman gain following\nthe recently proposed KalmanNet framework, which copes with partial and\napproximated modeling, without forcing a specific model over the noise\nstatistics. Our empirical results demonstrate that the proposed GSP-KalmanNet\nachieves enhanced accuracy and run time performance as well as improved\nrobustness to model misspecifications compared with both model-based and\ndata-driven benchmarks.\n","authors":["Itay Buchnik","Guy Sagi","Nimrod Leinwand","Yuval Loya","Nir Shlezinger","Tirza Routtenberg"],"pdf_url":"https://arxiv.org/pdf/2311.16602v1.pdf","comment":"Submitted for possible publication in the IEEE"},{"id":"http://arxiv.org/abs/2303.01928v3","updated":"2023-11-28T08:41:59Z","published":"2023-03-03T13:53:36Z","title":"FairShap: A Data Re-weighting Approach for Algorithmic Fairness based on\n  Shapley Values","summary":"  Algorithmic fairness is of utmost societal importance, yet the current trend\nin large-scale machine learning models requires training with massive datasets\nthat are frequently biased. In this context, pre-processing methods that focus\non modeling and correcting bias in the data emerge as valuable approaches. In\nthis paper, we propose FairShap, a novel instance-level data re-weighting\nmethod for fair algorithmic decision-making through data valuation by means of\nShapley Values. FairShap is model-agnostic and easily interpretable, as it\nmeasures the contribution of each training data point to a predefined fairness\nmetric. We empirically validate FairShap on several state-of-the-art datasets\nof different nature, with a variety of training scenarios and models and show\nhow it yields fairer models with similar levels of accuracy than the baselines.\nWe illustrate FairShap's interpretability by means of histograms and latent\nspace visualizations. Moreover, we perform a utility-fairness study, and\nablation and runtime experiments to illustrate the impact of the size of the\nreference dataset and FairShap's computational cost depending on the size of\nthe dataset and the number of features. We believe that FairShap represents a\npromising direction in interpretable and model-agnostic approaches to\nalgorithmic fairness that yield competitive accuracy even when only biased\ndatasets are available.\n","authors":["Adrian Arnaiz-Rodriguez","Nuria Oliver"],"pdf_url":"https://arxiv.org/pdf/2303.01928v3.pdf","comment":"33 pages, 11 figures, 7 tables"},{"id":"http://arxiv.org/abs/2311.16595v1","updated":"2023-11-28T08:27:27Z","published":"2023-11-28T08:27:27Z","title":"D4AM: A General Denoising Framework for Downstream Acoustic Models","summary":"  The performance of acoustic models degrades notably in noisy environments.\nSpeech enhancement (SE) can be used as a front-end strategy to aid automatic\nspeech recognition (ASR) systems. However, existing training objectives of SE\nmethods are not fully effective at integrating speech-text and noisy-clean\npaired data for training toward unseen ASR systems. In this study, we propose a\ngeneral denoising framework, D4AM, for various downstream acoustic models. Our\nframework fine-tunes the SE model with the backward gradient according to a\nspecific acoustic model and the corresponding classification objective. In\naddition, our method aims to consider the regression objective as an auxiliary\nloss to make the SE model generalize to other unseen acoustic models. To\njointly train an SE unit with regression and classification objectives, D4AM\nuses an adjustment scheme to directly estimate suitable weighting coefficients\nrather than undergoing a grid search process with additional training costs.\nThe adjustment scheme consists of two parts: gradient calibration and\nregression objective weighting. The experimental results show that D4AM can\nconsistently and effectively provide improvements to various unseen acoustic\nmodels and outperforms other combination setups. Specifically, when evaluated\non the Google ASR API with real noisy data completely unseen during SE\ntraining, D4AM achieves a relative WER reduction of 24.65% compared with the\ndirect feeding of noisy input. To our knowledge, this is the first work that\ndeploys an effective combination scheme of regression (denoising) and\nclassification (ASR) objectives to derive a general pre-processor applicable to\nvarious unseen ASR systems. Our code is available at\nhttps://github.com/ChangLee0903/D4AM.\n","authors":["Chi-Chang Lee","Yu Tsao","Hsin-Min Wang","Chu-Song Chen"],"pdf_url":"https://arxiv.org/pdf/2311.16595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16593v1","updated":"2023-11-28T08:18:30Z","published":"2023-11-28T08:18:30Z","title":"Empowering COVID-19 Detection: Optimizing Performance Through Fine-Tuned\n  EfficientNet Deep Learning Architecture","summary":"  The worldwide COVID-19 pandemic has profoundly influenced the health and\neveryday experiences of individuals across the planet. It is a highly\ncontagious respiratory disease requiring early and accurate detection to curb\nits rapid transmission. Initial testing methods primarily revolved around\nidentifying the genetic composition of the coronavirus, exhibiting a relatively\nlow detection rate and requiring a time-intensive procedure. To address this\nchallenge, experts have suggested using radiological imagery, particularly\nchest X-rays, as a valuable approach within the diagnostic protocol. This study\ninvestigates the potential of leveraging radiographic imaging (X-rays) with\ndeep learning algorithms to swiftly and precisely identify COVID-19 patients.\nThe proposed approach elevates the detection accuracy by fine-tuning with\nappropriate layers on various established transfer learning models. The\nexperimentation was conducted on a COVID-19 X-ray dataset containing 2000\nimages. The accuracy rates achieved were impressive of 100% for EfficientNetB4\nmodel. The fine-tuned EfficientNetB4 achieved an excellent accuracy score,\nshowcasing its potential as a robust COVID-19 detection model. Furthermore,\nEfficientNetB4 excelled in identifying Lung disease using Chest X-ray dataset\ncontaining 4,350 Images, achieving remarkable performance with an accuracy of\n99.17%, precision of 99.13%, recall of 99.16%, and f1-score of 99.14%. These\nresults highlight the promise of fine-tuned transfer learning for efficient\nlung detection through medical imaging, especially with X-ray images. This\nresearch offers radiologists an effective means of aiding rapid and precise\nCOVID-19 diagnosis and contributes valuable assistance for healthcare\nprofessionals in accurately identifying affected patients.\n","authors":["Md. Alamin Talukder","Md. Abu Layek","Mohsin Kazi","Md Ashraf Uddin","Sunil Aryal"],"pdf_url":"https://arxiv.org/pdf/2311.16593v1.pdf","comment":"Computers in Biology and Medicine [Q1, IF: 7.7, CS: 9.2]"},{"id":"http://arxiv.org/abs/2311.16589v1","updated":"2023-11-28T08:15:27Z","published":"2023-11-28T08:15:27Z","title":"Improving Lane Detection Generalization: A Novel Framework using HD Maps\n  for Boosting Diversity","summary":"  Lane detection is a vital task for vehicles to navigate and localize their\nposition on the road. To ensure reliable results, lane detection algorithms\nmust have robust generalization performance in various road environments.\nHowever, despite the significant performance improvement of deep learning-based\nlane detection algorithms, their generalization performance in response to\nchanges in road environments still falls short of expectations. In this paper,\nwe present a novel framework for single-source domain generalization (SSDG) in\nlane detection. By decomposing data into lane structures and surroundings, we\nenhance diversity using High-Definition (HD) maps and generative models. Rather\nthan expanding data volume, we strategically select a core subset of data,\nmaximizing diversity and optimizing performance. Our extensive experiments\ndemonstrate that our framework enhances the generalization performance of lane\ndetection, comparable to the domain adaptation-based method.\n","authors":["Daeun Lee","Minhyeok Heo","Jiwon Kim"],"pdf_url":"https://arxiv.org/pdf/2311.16589v1.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.16584v1","updated":"2023-11-28T08:01:43Z","published":"2023-11-28T08:01:43Z","title":"FedAL: Black-Box Federated Knowledge Distillation Enabled by Adversarial\n  Learning","summary":"  Knowledge distillation (KD) can enable collaborative learning among\ndistributed clients that have different model architectures and do not share\ntheir local data and model parameters with others. Each client updates its\nlocal model using the average model output/feature of all client models as the\ntarget, known as federated KD. However, existing federated KD methods often do\nnot perform well when clients' local models are trained with heterogeneous\nlocal datasets. In this paper, we propose Federated knowledge distillation\nenabled by Adversarial Learning (FedAL) to address the data heterogeneity among\nclients. First, to alleviate the local model output divergence across clients\ncaused by data heterogeneity, the server acts as a discriminator to guide\nclients' local model training to achieve consensus model outputs among clients\nthrough a min-max game between clients and the discriminator. Moreover,\ncatastrophic forgetting may happen during the clients' local training and\nglobal knowledge transfer due to clients' heterogeneous local data. Towards\nthis challenge, we design the less-forgetting regularization for both local\ntraining and global knowledge transfer to guarantee clients' ability to\ntransfer/learn knowledge to/from others. Experimental results show that FedAL\nand its variants achieve higher accuracy than other federated KD baselines.\n","authors":["Pengchao Han","Xingyan Shi","Jianwei Huang"],"pdf_url":"https://arxiv.org/pdf/2311.16584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14714v2","updated":"2023-11-28T07:32:55Z","published":"2023-10-23T08:51:05Z","title":"BatteryML:An Open-source platform for Machine Learning on Battery\n  Degradation","summary":"  Battery degradation remains a pivotal concern in the energy storage domain,\nwith machine learning emerging as a potent tool to drive forward insights and\nsolutions. However, this intersection of electrochemical science and machine\nlearning poses complex challenges. Machine learning experts often grapple with\nthe intricacies of battery science, while battery researchers face hurdles in\nadapting intricate models tailored to specific datasets. Beyond this, a\ncohesive standard for battery degradation modeling, inclusive of data formats\nand evaluative benchmarks, is conspicuously absent. Recognizing these\nimpediments, we present BatteryML - a one-step, all-encompass, and open-source\nplatform designed to unify data preprocessing, feature extraction, and the\nimplementation of both traditional and state-of-the-art models. This\nstreamlined approach promises to enhance the practicality and efficiency of\nresearch applications. BatteryML seeks to fill this void, fostering an\nenvironment where experts from diverse specializations can collaboratively\ncontribute, thus elevating the collective understanding and advancement of\nbattery research.The code for our project is publicly available on GitHub at\nhttps://github.com/microsoft/BatteryML.\n","authors":["Han Zhang","Xiaofan Gui","Shun Zheng","Ziheng Lu","Yuqi Li","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2310.14714v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16556v1","updated":"2023-11-28T06:52:53Z","published":"2023-11-28T06:52:53Z","title":"Scalable Label Distribution Learning for Multi-Label Classification","summary":"  Multi-label classification (MLC) refers to the problem of tagging a given\ninstance with a set of relevant labels. Most existing MLC methods are based on\nthe assumption that the correlation of two labels in each label pair is\nsymmetric, which is violated in many real-world scenarios. Moreover, most\nexisting methods design learning processes associated with the number of\nlabels, which makes their computational complexity a bottleneck when scaling up\nto large-scale output space. To tackle these issues, we propose a novel MLC\nlearning method named Scalable Label Distribution Learning (SLDL) for\nmulti-label classification which can describe different labels as distributions\nin a latent space, where the label correlation is asymmetric and the dimension\nis independent of the number of labels. Specifically, SLDL first converts\nlabels into continuous distributions within a low-dimensional latent space and\nleverages the asymmetric metric to establish the correlation between different\nlabels. Then, it learns the mapping from the feature space to the latent space,\nresulting in the computational complexity is no longer related to the number of\nlabels. Finally, SLDL leverages a nearest-neighbor-based strategy to decode the\nlatent representations and obtain the final predictions. Our extensive\nexperiments illustrate that SLDL can achieve very competitive classification\nperformances with little computational consumption.\n","authors":["Xingyu Zhao","Yuexuan An","Lei Qi","Xin Geng"],"pdf_url":"https://arxiv.org/pdf/2311.16556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.04840v5","updated":"2023-11-28T06:39:41Z","published":"2021-08-10T18:00:14Z","title":"Post-hoc Interpretability for Neural NLP: A Survey","summary":"  Neural networks for NLP are becoming increasingly complex and widespread, and\nthere is a growing concern if these models are responsible to use. Explaining\nmodels helps to address the safety and ethical concerns and is essential for\naccountability. Interpretability serves to provide these explanations in terms\nthat are understandable to humans. Additionally, post-hoc methods provide\nexplanations after a model is learned and are generally model-agnostic. This\nsurvey provides a categorization of how recent post-hoc interpretability\nmethods communicate explanations to humans, it discusses each method in-depth,\nand how they are validated, as the latter is often a common concern.\n","authors":["Andreas Madsen","Siva Reddy","Sarath Chandar"],"pdf_url":"https://arxiv.org/pdf/2108.04840v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.05204v2","updated":"2023-11-28T06:38:03Z","published":"2023-10-08T15:35:00Z","title":"Towards Optimizing with Large Language Models","summary":"  In this work, we conduct an assessment of the optimization capabilities of\nLLMs across various tasks and data sizes. Each of these tasks corresponds to\nunique optimization domains, and LLMs are required to execute these tasks with\ninteractive prompting. That is, in each optimization step, the LLM generates\nnew solutions from the past generated solutions with their values, and then the\nnew solutions are evaluated and considered in the next optimization step.\nAdditionally, we introduce three distinct metrics for a comprehensive\nassessment of task performance from various perspectives. These metrics offer\nthe advantage of being applicable for evaluating LLM performance across a broad\nspectrum of optimization tasks and are less sensitive to variations in test\nsamples. By applying these metrics, we observe that LLMs exhibit strong\noptimization capabilities when dealing with small-sized samples. However, their\nperformance is significantly influenced by factors like data size and values,\nunderscoring the importance of further research in the domain of optimization\ntasks for LLMs.\n","authors":["Pei-Fu Guo","Ying-Hsuan Chen","Yun-Da Tsai","Shou-De Lin"],"pdf_url":"https://arxiv.org/pdf/2310.05204v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16507v1","updated":"2023-11-28T06:19:30Z","published":"2023-11-28T06:19:30Z","title":"Exploring Straighter Trajectories of Flow Matching with Diffusion\n  Guidance","summary":"  Flow matching as a paradigm of generative model achieves notable success\nacross various domains. However, existing methods use either multi-round\ntraining or knowledge within minibatches, posing challenges in finding a\nfavorable coupling strategy for straight trajectories. To address this issue,\nwe propose a novel approach, Straighter trajectories of Flow Matching\n(StraightFM). It straightens trajectories with the coupling strategy guided by\ndiffusion model from entire distribution level. First, we propose a coupling\nstrategy to straighten trajectories, creating couplings between image and noise\nsamples under diffusion model guidance. Second, StraightFM also integrates real\ndata to enhance training, employing a neural network to parameterize another\ncoupling process from images to noise samples. StraightFM is jointly optimized\nwith couplings from above two mutually complementary directions, resulting in\nstraighter trajectories and enabling both one-step and few-step generation.\nExtensive experiments demonstrate that StraightFM yields high quality samples\nwith fewer step. StraightFM generates visually appealing images with a lower\nFID among diffusion and traditional flow matching methods within 5 sampling\nsteps when trained on pixel space. In the latent space (i.e., Latent\nDiffusion), StraightFM achieves a lower KID value compared to existing methods\non the CelebA-HQ 256 dataset in fewer than 10 sampling steps.\n","authors":["Siyu Xing","Jie Cao","Huaibo Huang","Xiao-Yu Zhang","Ran He"],"pdf_url":"https://arxiv.org/pdf/2311.16507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08164v4","updated":"2023-11-28T06:17:30Z","published":"2022-06-16T13:33:22Z","title":"Long Range Graph Benchmark","summary":"  Graph Neural Networks (GNNs) that are based on the message passing (MP)\nparadigm generally exchange information between 1-hop neighbors to build node\nrepresentations at each layer. In principle, such networks are not able to\ncapture long-range interactions (LRI) that may be desired or necessary for\nlearning a given task on graphs. Recently, there has been an increasing\ninterest in development of Transformer-based methods for graphs that can\nconsider full node connectivity beyond the original sparse structure, thus\nenabling the modeling of LRI. However, MP-GNNs that simply rely on 1-hop\nmessage passing often fare better in several existing graph benchmarks when\ncombined with positional feature representations, among other innovations,\nhence limiting the perceived utility and ranking of Transformer-like\narchitectures. Here, we present the Long Range Graph Benchmark (LRGB) with 5\ngraph learning datasets: PascalVOC-SP, COCO-SP, PCQM-Contact, Peptides-func and\nPeptides-struct that arguably require LRI reasoning to achieve strong\nperformance in a given task. We benchmark both baseline GNNs and Graph\nTransformer networks to verify that the models which capture long-range\ndependencies perform significantly better on these tasks. Therefore, these\ndatasets are suitable for benchmarking and exploration of MP-GNNs and Graph\nTransformer architectures that are intended to capture LRI.\n","authors":["Vijay Prakash Dwivedi","Ladislav Rampášek","Mikhail Galkin","Ali Parviz","Guy Wolf","Anh Tuan Luu","Dominique Beaini"],"pdf_url":"https://arxiv.org/pdf/2206.08164v4.pdf","comment":"Added reference to T\\\"onshoff et al., 2023 in Sec. 4.1; NeurIPS 2022\n  Track on D&B; Open-sourced at: https://github.com/vijaydwivedi75/lrgb"},{"id":"http://arxiv.org/abs/2311.16540v1","updated":"2023-11-28T06:12:57Z","published":"2023-11-28T06:12:57Z","title":"Communication Efficiency Optimization of Federated Learning for\n  Computing and Network Convergence of 6G Networks","summary":"  Federated learning effectively addresses issues such as data privacy by\ncollaborating across participating devices to train global models. However,\nfactors such as network topology and device computing power can affect its\ntraining or communication process in complex network environments. A new\nnetwork architecture and paradigm with computing-measurable, perceptible,\ndistributable, dispatchable, and manageable capabilities, computing and network\nconvergence (CNC) of 6G networks can effectively support federated learning\ntraining and improve its communication efficiency. By guiding the participating\ndevices' training in federated learning based on business requirements,\nresource load, network conditions, and arithmetic power of devices, CNC can\nreach this goal. In this paper, to improve the communication efficiency of\nfederated learning in complex networks, we study the communication efficiency\noptimization of federated learning for computing and network convergence of 6G\nnetworks, methods that gives decisions on its training process for different\nnetwork conditions and arithmetic power of participating devices in federated\nlearning. The experiments address two architectures that exist for devices in\nfederated learning and arrange devices to participate in training based on\narithmetic power while achieving optimization of communication efficiency in\nthe process of transferring model parameters. The results show that the method\nwe proposed can (1) cope well with complex network situations (2) effectively\nbalance the delay distribution of participating devices for local training (3)\nimprove the communication efficiency during the transfer of model parameters\n(4) improve the resource utilization in the network.\n","authors":["Yizhuo Cai","Bo Lei","Qianying Zhao","Jing Peng","Min Wei","Yushun Zhang","Xing Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.16540v1.pdf","comment":"13 pages, 11 figures, accepted by Frontiers of Information Technology\n  & Electronic Engineering"},{"id":"http://arxiv.org/abs/2211.05228v2","updated":"2023-11-28T06:09:31Z","published":"2022-11-07T09:38:34Z","title":"FIXED: Frustratingly Easy Domain Generalization with Mixup","summary":"  Domain generalization (DG) aims to learn a generalizable model from multiple\ntraining domains such that it can perform well on unseen target domains. A\npopular strategy is to augment training data to benefit generalization through\nmethods such as Mixup~\\cite{zhang2018mixup}. While the vanilla Mixup can be\ndirectly applied, theoretical and empirical investigations uncover several\nshortcomings that limit its performance. Firstly, Mixup cannot effectively\nidentify the domain and class information that can be used for learning\ninvariant representations. Secondly, Mixup may introduce synthetic noisy data\npoints via random interpolation, which lowers its discrimination capability.\nBased on the analysis, we propose a simple yet effective enhancement for\nMixup-based DG, namely domain-invariant Feature mIXup (FIX). It learns\ndomain-invariant representations for Mixup. To further enhance discrimination,\nwe leverage existing techniques to enlarge margins among classes to further\npropose the domain-invariant Feature MIXup with Enhanced Discrimination (FIXED)\napproach. We present theoretical insights about guarantees on its\neffectiveness. Extensive experiments on seven public datasets across two\nmodalities including image classification (Digits-DG, PACS, Office-Home) and\ntime series (DSADS, PAMAP2, UCI-HAR, and USC-HAD) demonstrate that our approach\nsignificantly outperforms nine state-of-the-art related methods, beating the\nbest performing baseline by 6.5\\% on average in terms of test accuracy. Code is\navailable at:\nhttps://github.com/jindongwang/transferlearning/tree/master/code/deep/fixed.\n","authors":["Wang Lu","Jindong Wang","Han Yu","Lei Huang","Xiang Zhang","Yiqiang Chen","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2211.05228v2.pdf","comment":"First Conference on Parsimony and Learning (CPAL) 2024; code for DG\n  at: https://github.com/jindongwang/transferlearning/tree/master/code/DeepDG"},{"id":"http://arxiv.org/abs/2311.16538v1","updated":"2023-11-28T06:08:16Z","published":"2023-11-28T06:08:16Z","title":"Federated Learning with Diffusion Models for Privacy-Sensitive Vision\n  Tasks","summary":"  Diffusion models have shown great potential for vision-related tasks,\nparticularly for image generation. However, their training is typically\nconducted in a centralized manner, relying on data collected from publicly\navailable sources. This approach may not be feasible or practical in many\ndomains, such as the medical field, which involves privacy concerns over data\ncollection. Despite the challenges associated with privacy-sensitive data, such\ndomains could still benefit from valuable vision services provided by diffusion\nmodels. Federated learning (FL) plays a crucial role in enabling decentralized\nmodel training without compromising data privacy. Instead of collecting data,\nan FL system gathers model parameters, effectively safeguarding the private\ndata of different parties involved. This makes FL systems vital for managing\ndecentralized learning tasks, especially in scenarios where privacy-sensitive\ndata is distributed across a network of clients. Nonetheless, FL presents its\nown set of challenges due to its distributed nature and privacy-preserving\nproperties. Therefore, in this study, we explore the FL strategy to train\ndiffusion models, paving the way for the development of federated diffusion\nmodels. We conduct experiments on various FL scenarios, and our findings\ndemonstrate that federated diffusion models have great potential to deliver\nvision services to privacy-sensitive domains.\n","authors":["Ye Lin Tun","Chu Myaet Thwal","Ji Su Yoon","Sun Moo Kang","Chaoning Zhang","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2311.16538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16536v1","updated":"2023-11-28T05:45:20Z","published":"2023-11-28T05:45:20Z","title":"Personalized Predictions of Glioblastoma Infiltration: Mathematical\n  Models, Physics-Informed Neural Networks and Multimodal Scans","summary":"  Predicting the infiltration of Glioblastoma (GBM) from medical MRI scans is\ncrucial for understanding tumor growth dynamics and designing personalized\nradiotherapy treatment plans.Mathematical models of GBM growth can complement\nthe data in the prediction of spatial distributions of tumor cells. However,\nthis requires estimating patient-specific parameters of the model from clinical\ndata, which is a challenging inverse problem due to limited temporal data and\nthe limited time between imaging and diagnosis. This work proposes a method\nthat uses Physics-Informed Neural Networks (PINNs) to estimate patient-specific\nparameters of a reaction-diffusion PDE model of GBM growth from a single 3D\nstructural MRI snapshot. PINNs embed both the data and the PDE into a loss\nfunction, thus integrating theory and data. Key innovations include the\nidentification and estimation of characteristic non-dimensional parameters, a\npre-training step that utilizes the non-dimensional parameters and a\nfine-tuning step to determine the patient specific parameters. Additionally,\nthe diffuse domain method is employed to handle the complex brain geometry\nwithin the PINN framework. Our method is validated both on synthetic and\npatient datasets, and shows promise for real-time parametric inference in the\nclinical setting for personalized GBM treatment.\n","authors":["Ray Zirui Zhang","Ivan Ezhov","Michal Balcerak","Andy Zhu","Benedikt Wiestler","Bjoern Menze","John Lowengrub"],"pdf_url":"https://arxiv.org/pdf/2311.16536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16535v1","updated":"2023-11-28T05:44:26Z","published":"2023-11-28T05:44:26Z","title":"Contrastive encoder pre-training-based clustered federated learning for\n  heterogeneous data","summary":"  Federated learning (FL) is a promising approach that enables distributed\nclients to collaboratively train a global model while preserving their data\nprivacy. However, FL often suffers from data heterogeneity problems, which can\nsignificantly affect its performance. To address this, clustered federated\nlearning (CFL) has been proposed to construct personalized models for different\nclient clusters. One effective client clustering strategy is to allow clients\nto choose their own local models from a model pool based on their performance.\nHowever, without pre-trained model parameters, such a strategy is prone to\nclustering failure, in which all clients choose the same model. Unfortunately,\ncollecting a large amount of labeled data for pre-training can be costly and\nimpractical in distributed environments. To overcome this challenge, we\nleverage self-supervised contrastive learning to exploit unlabeled data for the\npre-training of FL systems. Together, self-supervised pre-training and client\nclustering can be crucial components for tackling the data heterogeneity issues\nof FL. Leveraging these two crucial strategies, we propose contrastive\npre-training-based clustered federated learning (CP-CFL) to improve the model\nconvergence and overall performance of FL systems. In this work, we demonstrate\nthe effectiveness of CP-CFL through extensive experiments in heterogeneous FL\nsettings, and present various interesting observations.\n","authors":["Ye Lin Tun","Minh N. H. Nguyen","Chu Myaet Thwal","Jinwoo Choi","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2311.16535v1.pdf","comment":"Published in Neural Networks"},{"id":"http://arxiv.org/abs/2310.08164v2","updated":"2023-11-28T05:36:12Z","published":"2023-10-12T09:36:03Z","title":"Interpreting Reward Models in RLHF-Tuned Language Models Using Sparse\n  Autoencoders","summary":"  Large language models (LLMs) aligned to human preferences via reinforcement\nlearning from human feedback (RLHF) underpin many commercial applications of\nLLM technology. Despite this, the impacts of RLHF on LLM internals remain\nopaque. We propose a novel method for interpreting implicit reward models\n(IRMs) in LLMs learned through RLHF. Our approach trains pairs of autoencoders\non activations from a base LLM and its RLHF-tuned variant. Through a comparison\nof autoencoder hidden spaces, we identify features that reflect the accuracy of\nthe learned IRM. To illustrate our method, we fine-tune an LLM via RLHF to\nlearn a token-utility mapping and maximize the aggregate utility of generated\ntext. This is the first application of sparse autoencoders to interpreting\nIRMs. Our method provides an abstract approximation of reward integrity and\nholds promise for measuring alignment between specified objectives and learned\nmodel behaviors.\n","authors":["Luke Marks","Amir Abdullah","Luna Mendez","Rauno Arike","Philip Torr","Fazl Barez"],"pdf_url":"https://arxiv.org/pdf/2310.08164v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09506v2","updated":"2023-11-28T05:31:06Z","published":"2023-11-16T02:06:23Z","title":"Investigating the Impact of Weight Sharing Decisions on Knowledge\n  Transfer in Continual Learning","summary":"  Continual Learning (CL) has generated attention as a method of avoiding\nCatastrophic Forgetting (CF) in the sequential training of neural networks,\nimproving network efficiency and adaptability to different tasks. Additionally,\nCL serves as an ideal setting for studying network behavior and Forward\nKnowledge Transfer (FKT) between tasks. Pruning methods for CL train\nsubnetworks to handle the sequential tasks which allows us to take a structured\napproach to investigating FKT. Sharing prior subnetworks' weights leverages\npast knowledge for the current task through FKT. Understanding which weights to\nshare is important as sharing all weights can yield sub-optimal accuracy. This\npaper investigates how different sharing decisions affect the FKT between\ntasks. Through this lens we demonstrate how task complexity and similarity\ninfluence the optimal weight sharing decisions, giving insights into the\nrelationships between tasks and helping inform decision making in similar CL\nmethods. We implement three sequential datasets designed to emphasize variation\nin task complexity and similarity, reporting results for both ResNet-18 and\nVGG-16. By sharing in accordance with the decisions supported by our findings,\nwe show that we can improve task accuracy compared to other sharing decisions.\n","authors":["Josh Andle","Ali Payani","Salimeh Yasaei-Sekeh"],"pdf_url":"https://arxiv.org/pdf/2311.09506v2.pdf","comment":"5 Figures, 4 Tables, 2 Algorithms"},{"id":"http://arxiv.org/abs/2311.07222v2","updated":"2023-11-28T05:29:19Z","published":"2023-11-13T10:40:17Z","title":"Neural General Circulation Models","summary":"  General circulation models (GCMs) are the foundation of weather and climate\nprediction. GCMs are physics-based simulators which combine a numerical solver\nfor large-scale dynamics with tuned representations for small-scale processes\nsuch as cloud formation. Recently, machine learning (ML) models trained on\nreanalysis data achieved comparable or better skill than GCMs for deterministic\nweather forecasting. However, these models have not demonstrated improved\nensemble forecasts, or shown sufficient stability for long-term weather and\nclimate simulations. Here we present the first GCM that combines a\ndifferentiable solver for atmospheric dynamics with ML components, and show\nthat it can generate forecasts of deterministic weather, ensemble weather and\nclimate on par with the best ML and physics-based methods. NeuralGCM is\ncompetitive with ML models for 1-10 day forecasts, and with the European Centre\nfor Medium-Range Weather Forecasts ensemble prediction for 1-15 day forecasts.\nWith prescribed sea surface temperature, NeuralGCM can accurately track climate\nmetrics such as global mean temperature for multiple decades, and climate\nforecasts with 140 km resolution exhibit emergent phenomena such as realistic\nfrequency and trajectories of tropical cyclones. For both weather and climate,\nour approach offers orders of magnitude computational savings over conventional\nGCMs. Our results show that end-to-end deep learning is compatible with tasks\nperformed by conventional GCMs, and can enhance the large-scale physical\nsimulations that are essential for understanding and predicting the Earth\nsystem.\n","authors":["Dmitrii Kochkov","Janni Yuval","Ian Langmore","Peter Norgaard","Jamie Smith","Griffin Mooers","James Lottes","Stephan Rasp","Peter Düben","Milan Klöwer","Sam Hatfield","Peter Battaglia","Alvaro Sanchez-Gonzalez","Matthew Willson","Michael P. Brenner","Stephan Hoyer"],"pdf_url":"https://arxiv.org/pdf/2311.07222v2.pdf","comment":"67 pages, 34 figures"},{"id":"http://arxiv.org/abs/2206.13269v2","updated":"2023-11-28T05:29:06Z","published":"2022-06-27T13:02:59Z","title":"Wasserstein Distributionally Robust Estimation in High Dimensions:\n  Performance Analysis and Optimal Hyperparameter Tuning","summary":"  Wasserstein distributionally robust optimization has recently emerged as a\npowerful framework for robust estimation, enjoying good out-of-sample\nperformance guarantees, well-understood regularization effects, and\ncomputationally tractable reformulations. In such framework, the estimator is\nobtained by minimizing the worst-case expected loss over all probability\ndistributions which are close, in a Wasserstein sense, to the empirical\ndistribution. In this paper, we propose a Wasserstein distributionally robust\nestimation framework to estimate an unknown parameter from noisy linear\nmeasurements, and we focus on the task of analyzing the squared error\nperformance of such estimators. Our study is carried out in the modern\nhigh-dimensional proportional regime, where both the ambient dimension and the\nnumber of samples go to infinity at a proportional rate which encodes the\nunder/over-parametrization of the problem. Under an isotropic Gaussian features\nassumption, we show that the squared error can be recovered as the solution of\na convex-concave optimization problem which, surprinsingly, involves at most\nfour scalar variables. Importantly, the precise quantification of the squared\nerror allows to accurately and efficiently compare different ambiguity radii\nand to understand the effect of the under/over-parametrization on the\nestimation error. We conclude the paper with a list of exciting research\ndirections enabled by our results.\n","authors":["Liviu Aolaritei","Soroosh Shafiee","Florian Dörfler"],"pdf_url":"https://arxiv.org/pdf/2206.13269v2.pdf","comment":"This paper was previously titled \"The Performance of Wasserstein\n  Distributionally Robust M-Estimators in High Dimensions\""},{"id":"http://arxiv.org/abs/2310.05898v4","updated":"2023-11-28T05:21:41Z","published":"2023-10-09T17:41:29Z","title":"Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts","summary":"  Lion (Evolved Sign Momentum), a new optimizer discovered through program\nsearch, has shown promising results in training large AI models. It performs\ncomparably or favorably to AdamW but with greater memory efficiency. As we can\nexpect from the results of a random search program, Lion incorporates elements\nfrom several existing algorithms, including signed momentum, decoupled weight\ndecay, Polak, and Nesterov momentum, but does not fit into any existing\ncategory of theoretically grounded optimizers. Thus, even though Lion appears\nto perform well as a general-purpose optimizer for a wide range of tasks, its\ntheoretical basis remains uncertain. This lack of theoretical clarity limits\nopportunities to further enhance and expand Lion's efficacy.\n  This work aims to demystify Lion. Based on both continuous-time and\ndiscrete-time analysis, we demonstrate that Lion is a theoretically novel and\nprincipled approach for minimizing a general loss function $f(x)$ while\nenforcing a bound constraint $\\|x\\|_\\infty \\leq 1/\\lambda$. Lion achieves this\nthrough the incorporation of decoupled weight decay, where $\\lambda$ represents\nthe weight decay coefficient. Our analysis is made possible by the development\nof a new Lyapunov function for the Lion updates. It applies to a broader family\nof Lion-$\\kappa$ algorithms, where the $\\text{sign}(\\cdot)$ operator in Lion is\nreplaced by the subgradient of a convex function $\\kappa$, leading to the\nsolution of a general composite optimization problem of $\\min_x f(x) +\n\\kappa^*(x)$. Our findings provide valuable insights into the dynamics of Lion\nand pave the way for further improvements and extensions of Lion-related\nalgorithms.\n","authors":["Lizhang Chen","Bo Liu","Kaizhao Liang","Qiang Liu"],"pdf_url":"https://arxiv.org/pdf/2310.05898v4.pdf","comment":"31 pages, 7 figures"},{"id":"http://arxiv.org/abs/2311.16528v1","updated":"2023-11-28T05:19:23Z","published":"2023-11-28T05:19:23Z","title":"Utility Fairness in Contextual Dynamic Pricing with Demand Learning","summary":"  This paper introduces a novel contextual bandit algorithm for personalized\npricing under utility fairness constraints in scenarios with uncertain demand,\nachieving an optimal regret upper bound. Our approach, which incorporates\ndynamic pricing and demand learning, addresses the critical challenge of\nfairness in pricing strategies. We first delve into the static full-information\nsetting to formulate an optimal pricing policy as a constrained optimization\nproblem. Here, we propose an approximation algorithm for efficiently and\napproximately computing the ideal policy.\n  We also use mathematical analysis and computational studies to characterize\nthe structures of optimal contextual pricing policies subject to fairness\nconstraints, deriving simplified policies which lays the foundations of more\nin-depth research and extensions.\n  Further, we extend our study to dynamic pricing problems with demand\nlearning, establishing a non-standard regret lower bound that highlights the\ncomplexity added by fairness constraints. Our research offers a comprehensive\nanalysis of the cost of fairness and its impact on the balance between utility\nand revenue maximization. This work represents a step towards integrating\nethical considerations into algorithmic efficiency in data-driven dynamic\npricing.\n","authors":["Xi Chen","David Simchi-Levi","Yining Wang"],"pdf_url":"https://arxiv.org/pdf/2311.16528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.14053v2","updated":"2023-11-28T05:18:31Z","published":"2023-09-25T11:35:10Z","title":"Revisiting LARS for Large Batch Training Generalization of Neural\n  Networks","summary":"  LARS and LAMB have emerged as prominent techniques in Large Batch Learning\n(LBL) to ensure training stability in AI. Convergence stability is a challenge\nin LBL, where the AI agent usually gets trapped in the sharp minimizer. To\naddress this challenge, warm-up is an efficient technique, but it lacks a\nstrong theoretical foundation. Specifically, the warm-up process often reduces\ngradients in the early phase, inadvertently preventing the agent from escaping\nthe sharp minimizer early on. In light of this situation, we conduct empirical\nexperiments to analyze the behaviors of LARS and LAMB with and without a\nwarm-up strategy. Our analyses give a comprehensive insight into the behaviors\nof LARS, LAMB, and the necessity of a warm-up technique in LBL, including an\nexplanation of their failure in many cases. Building upon these insights, we\npropose a novel algorithm called Time Varying LARS (TVLARS), which facilitates\nrobust training in the initial phase without the need for warm-up. A\nconfigurable sigmoid-like function is employed in TVLARS to replace the warm-up\nprocess to enhance training stability. Moreover, TVLARS stimulates gradient\nexploration in the early phase, thus allowing it to surpass the sharp minimizes\nearly on and gradually transition to LARS and achieving robustness of LARS in\nthe latter phases. Extensive experimental evaluations reveal that TVLARS\nconsistently outperforms LARS and LAMB in most cases, with improvements of up\nto 2% in classification scenarios. Notably, in every case of self-supervised\nlearning, TVLARS dominates LARS and LAMB with performance improvements of up to\n10%.\n","authors":["Khoi Do","Duong Nguyen","Hoa Nguyen","Long Tran-Thanh","Quoc-Viet Pham"],"pdf_url":"https://arxiv.org/pdf/2309.14053v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16526v1","updated":"2023-11-28T05:11:53Z","published":"2023-11-28T05:11:53Z","title":"On robust overfitting: adversarial training induced distribution matters","summary":"  Adversarial training may be regarded as standard training with a modified\nloss function. But its generalization error appears much larger than standard\ntraining under standard loss. This phenomenon, known as robust overfitting, has\nattracted significant research attention and remains largely as a mystery. In\nthis paper, we first show empirically that robust overfitting correlates with\nthe increasing generalization difficulty of the perturbation-induced\ndistributions along the trajectory of adversarial training (specifically\nPGD-based adversarial training). We then provide a novel upper bound for\ngeneralization error with respect to the perturbation-induced distributions, in\nwhich a notion of the perturbation operator, referred to \"local dispersion\",\nplays an important role.\n","authors":["Runzhi Tian","Yongyi Mao"],"pdf_url":"https://arxiv.org/pdf/2311.16526v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18766v3","updated":"2023-11-28T05:09:02Z","published":"2023-05-30T05:56:58Z","title":"HiFA: High-fidelity Text-to-3D Generation with Advanced Diffusion\n  Guidance","summary":"  The advancements in automatic text-to-3D generation have been remarkable.\nMost existing methods use pre-trained text-to-image diffusion models to\noptimize 3D representations like Neural Radiance Fields (NeRFs) via\nlatent-space denoising score matching. Yet, these methods often result in\nartifacts and inconsistencies across different views due to their suboptimal\noptimization approaches and limited understanding of 3D geometry. Moreover, the\ninherent constraints of NeRFs in rendering crisp geometry and stable textures\nusually lead to a two-stage optimization to attain high-resolution details.\nThis work proposes holistic sampling and smoothing approaches to achieve\nhigh-quality text-to-3D generation, all in a single-stage optimization. We\ncompute denoising scores in the text-to-image diffusion model's latent and\nimage spaces. Instead of randomly sampling timesteps (also referred to as noise\nlevels in denoising score matching), we introduce a novel timestep annealing\napproach that progressively reduces the sampled timestep throughout\noptimization. To generate high-quality renderings in a single-stage\noptimization, we propose regularization for the variance of z-coordinates along\nNeRF rays. To address texture flickering issues in NeRFs, we introduce a kernel\nsmoothing technique that refines importance sampling weights coarse-to-fine,\nensuring accurate and thorough sampling in high-density regions. Extensive\nexperiments demonstrate the superiority of our method over previous approaches,\nenabling the generation of highly detailed and view-consistent 3D assets\nthrough a single-stage training process.\n","authors":["Junzhe Zhu","Peiye Zhuang"],"pdf_url":"https://arxiv.org/pdf/2305.18766v3.pdf","comment":"Project page: https://hifa-team.github.io/HiFA-site/"},{"id":"http://arxiv.org/abs/2311.16524v1","updated":"2023-11-28T05:06:22Z","published":"2023-11-28T05:06:22Z","title":"3D Teeth Reconstruction from Panoramic Radiographs using Neural Implicit\n  Functions","summary":"  Panoramic radiography is a widely used imaging modality in dental practice\nand research. However, it only provides flattened 2D images, which limits the\ndetailed assessment of dental structures. In this paper, we propose Occudent, a\nframework for 3D teeth reconstruction from panoramic radiographs using neural\nimplicit functions, which, to the best of our knowledge, is the first work to\ndo so. For a given point in 3D space, the implicit function estimates whether\nthe point is occupied by a tooth, and thus implicitly determines the boundaries\nof 3D tooth shapes. Firstly, Occudent applies multi-label segmentation to the\ninput panoramic radiograph. Next, tooth shape embeddings as well as tooth class\nembeddings are generated from the segmentation outputs, which are fed to the\nreconstruction network. A novel module called Conditional eXcitation (CX) is\nproposed in order to effectively incorporate the combined shape and class\nembeddings into the implicit function. The performance of Occudent is evaluated\nusing both quantitative and qualitative measures. Importantly, Occudent is\ntrained and validated with actual panoramic radiographs as input, distinct from\nrecent works which used synthesized images. Experiments demonstrate the\nsuperiority of Occudent over state-of-the-art methods.\n","authors":["Sihwa Park","Seongjun Kim","In-Seok Song","Seung Jun Baek"],"pdf_url":"https://arxiv.org/pdf/2311.16524v1.pdf","comment":"12 pages, 2 figures, accepted to International Conference on Medical\n  Image Computing and Computer-Assisted Intervention MICCAI 2023"},{"id":"http://arxiv.org/abs/2311.16522v1","updated":"2023-11-28T05:00:27Z","published":"2023-11-28T05:00:27Z","title":"Evaluation of dynamic characteristics of power grid based on GNN and\n  application on knowledge graph","summary":"  A novel method for detecting faults in power grids using a graph neural\nnetwork (GNN) has been developed, aimed at enhancing intelligent fault\ndiagnosis in network operation and maintenance. This GNN-based approach\nidentifies faulty nodes within the power grid through a specialized electrical\nfeature extraction model coupled with a knowledge graph. Incorporating temporal\ndata, the method leverages the status of nodes from preceding and subsequent\ntime periods to aid in current fault detection. To validate the effectiveness\nof this GNN in extracting node features, a correlation analysis of the output\nfeatures from each node within the neural network layer was conducted. The\nresults from experiments show that this method can accurately locate fault\nnodes in simulated scenarios with a remarkable 99.53% accuracy. Additionally,\nthe graph neural network's feature modeling allows for a qualitative\nexamination of how faults spread across nodes, providing valuable insights for\nanalyzing fault nodes.\n","authors":["Hao Pei","Si Lin","Chuanfu Li","Che Wang","Haoming Chen","Sizhe Li"],"pdf_url":"https://arxiv.org/pdf/2311.16522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16520v1","updated":"2023-11-28T04:58:41Z","published":"2023-11-28T04:58:41Z","title":"Value Approximation for Two-Player General-Sum Differential Games with\n  State Constraints","summary":"  Solving Hamilton-Jacobi-Isaacs (HJI) PDEs enables equilibrial feedback\ncontrol in two-player differential games, yet faces the curse of dimensionality\n(CoD). While physics-informed machine learning has been adopted to address CoD\nin solving PDEs, this method falls short in learning discontinuous solutions\ndue to its sampling nature, leading to poor safety performance of the resulting\ncontrollers in robotics applications where values are discontinuous due to\nstate or other temporal logic constraints. In this study, we explore three\npotential solutions to this problem: (1) a hybrid learning method that uses\nboth equilibrium demonstrations and the HJI PDE, (2) a value-hardening method\nwhere a sequence of HJIs are solved with increasing Lipschitz constant on the\nconstraint violation penalty, and (3) the epigraphical technique that lifts the\nvalue to a higher dimensional auxiliary state space where the value becomes\ncontinuous. Evaluations through 5D and 9D vehicle simulations and 13D drone\nsimulations reveal that the hybrid method outperforms others in terms of\ngeneralization and safety performance.\n","authors":["Lei Zhang","Mukesh Ghimire","Wenlong Zhang","Zhe Xu","Yi Ren"],"pdf_url":"https://arxiv.org/pdf/2311.16520v1.pdf","comment":"Submitted to TRO"},{"id":"http://arxiv.org/abs/2311.16519v1","updated":"2023-11-28T04:58:17Z","published":"2023-11-28T04:58:17Z","title":"B-LSTM-MIONet: Bayesian LSTM-based Neural Operators for Learning the\n  Response of Complex Dynamical Systems to Length-Variant Multiple Input\n  Functions","summary":"  Deep Operator Network (DeepONet) is a neural network framework for learning\nnonlinear operators such as those from ordinary differential equations (ODEs)\ndescribing complex systems. Multiple-input deep neural operators (MIONet)\nextended DeepONet to allow multiple input functions in different Banach spaces.\nMIONet offers flexibility in training dataset grid spacing, without constraints\non output location. However, it requires offline inputs and cannot handle\nvarying sequence lengths in testing datasets, limiting its real-time\napplication in dynamic complex systems. This work redesigns MIONet, integrating\nLong Short Term Memory (LSTM) to learn neural operators from time-dependent\ndata. This approach overcomes data discretization constraints and harnesses\nLSTM's capability with variable-length, real-time data. Factors affecting\nlearning performance, like algorithm extrapolation ability are presented. The\nframework is enhanced with uncertainty quantification through a novel Bayesian\nmethod, sampling from MIONet parameter distributions. Consequently, we develop\nthe B-LSTM-MIONet, incorporating LSTM's temporal strengths with Bayesian\nrobustness, resulting in a more precise and reliable model for noisy datasets.\n","authors":["Zhihao Kong","Amirhossein Mollaali","Christian Moya","Na Lu","Guang Lin"],"pdf_url":"https://arxiv.org/pdf/2311.16519v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16509v1","updated":"2023-11-28T04:49:17Z","published":"2023-11-28T04:49:17Z","title":"StyleCap: Automatic Speaking-Style Captioning from Speech Based on\n  Speech and Language Self-supervised Learning Models","summary":"  We propose StyleCap, a method to generate natural language descriptions of\nspeaking styles appearing in speech. Although most of conventional techniques\nfor para-/non-linguistic information recognition focus on the category\nclassification or the intensity estimation of pre-defined labels, they cannot\nprovide the reasoning of the recognition result in an interpretable manner. As\na first step towards an end-to-end method for generating speaking-style prompts\nfrom speech, i.e., automatic speaking-style captioning, StyleCap uses paired\ndata of speech and natural language descriptions to train neural networks that\npredict prefix vectors fed into a large language model (LLM)-based text decoder\nfrom a speech representation vector. We explore an appropriate text decoder and\nspeech feature representation suitable for this new task. The experimental\nresults demonstrate that our StyleCap leveraging richer LLMs for the text\ndecoder, speech self-supervised learning (SSL) features, and sentence\nrephrasing augmentation improves the accuracy and diversity of generated\nspeaking-style captions. Samples of speaking-style captions generated by our\nStyleCap are publicly available.\n","authors":["Kazuki Yamauchi","Yusuke Ijima","Yuki Saito"],"pdf_url":"https://arxiv.org/pdf/2311.16509v1.pdf","comment":"Submitted to ICASSP 2024"},{"id":"http://arxiv.org/abs/2307.12226v2","updated":"2023-11-28T04:35:51Z","published":"2023-07-23T04:48:41Z","title":"Geometry-Aware Adaptation for Pretrained Models","summary":"  Machine learning models -- including prominent zero-shot models -- are often\ntrained on datasets whose labels are only a small proportion of a larger label\nspace. Such spaces are commonly equipped with a metric that relates the labels\nvia distances between them. We propose a simple approach to exploit this\ninformation to adapt the trained model to reliably predict new classes -- or,\nin the case of zero-shot prediction, to improve its performance -- without any\nadditional training. Our technique is a drop-in replacement of the standard\nprediction rule, swapping argmax with the Fr\\'echet mean. We provide a\ncomprehensive theoretical analysis for this approach, studying (i)\nlearning-theoretic results trading off label space diameter, sample complexity,\nand model dimension, (ii) characterizations of the full range of scenarios in\nwhich it is possible to predict any unobserved class, and (iii) an optimal\nactive learning-like next class selection procedure to obtain optimal training\nclasses for when it is not possible to predict the entire range of unobserved\nclasses. Empirically, using easily-available external metrics, our proposed\napproach, Loki, gains up to 29.7% relative improvement over SimCLR on ImageNet\nand scales to hundreds of thousands of classes. When no such metric is\navailable, Loki can use self-derived metrics from class embeddings and obtains\na 10.5% improvement on pretrained zero-shot models such as CLIP.\n","authors":["Nicholas Roberts","Xintong Li","Dyah Adila","Sonia Cromp","Tzu-Heng Huang","Jitian Zhao","Frederic Sala"],"pdf_url":"https://arxiv.org/pdf/2307.12226v2.pdf","comment":"NeurIPS 2023"},{"id":"http://arxiv.org/abs/2311.16487v1","updated":"2023-11-28T04:34:04Z","published":"2023-11-28T04:34:04Z","title":"On the Robustness of Decision-Focused Learning","summary":"  Decision-Focused Learning (DFL) is an emerging learning paradigm that tackles\nthe task of training a machine learning (ML) model to predict missing\nparameters of an incomplete optimization problem, where the missing parameters\nare predicted. DFL trains an ML model in an end-to-end system, by integrating\nthe prediction and optimization tasks, providing better alignment of the\ntraining and testing objectives. DFL has shown a lot of promise and holds the\ncapacity to revolutionize decision-making in many real-world applications.\nHowever, very little is known about the performance of these models under\nadversarial attacks. We adopt ten unique DFL methods and benchmark their\nperformance under two distinctly focused attacks adapted towards the\nPredict-then-Optimize problem setting. Our study proposes the hypothesis that\nthe robustness of a model is highly correlated with its ability to find\npredictions that lead to optimal decisions without deviating from the\nground-truth label. Furthermore, we provide insight into how to target the\nmodels that violate this condition and show how these models respond\ndifferently depending on the achieved optimality at the end of their training\ncycles.\n","authors":["Yehya Farhat"],"pdf_url":"https://arxiv.org/pdf/2311.16487v1.pdf","comment":"17 pages, 45 figures, submitted to AAAI artificial intelligence for\n  operations research workshop"},{"id":"http://arxiv.org/abs/2306.15868v3","updated":"2023-11-28T04:28:48Z","published":"2023-06-28T01:50:46Z","title":"GraSS: Contrastive Learning with Gradient Guided Sampling Strategy for\n  Remote Sensing Image Semantic Segmentation","summary":"  Self-supervised contrastive learning (SSCL) has achieved significant\nmilestones in remote sensing image (RSI) understanding. Its essence lies in\ndesigning an unsupervised instance discrimination pretext task to extract image\nfeatures from a large number of unlabeled images that are beneficial for\ndownstream tasks. However, existing instance discrimination based SSCL suffer\nfrom two limitations when applied to the RSI semantic segmentation task: 1)\nPositive sample confounding issue; 2) Feature adaptation bias. It introduces a\nfeature adaptation bias when applied to semantic segmentation tasks that\nrequire pixel-level or object-level features. In this study, We observed that\nthe discrimination information can be mapped to specific regions in RSI through\nthe gradient of unsupervised contrastive loss, these specific regions tend to\ncontain singular ground objects. Based on this, we propose contrastive learning\nwith Gradient guided Sampling Strategy (GraSS) for RSI semantic segmentation.\nGraSS consists of two stages: Instance Discrimination warm-up (ID warm-up) and\nGradient guided Sampling contrastive training (GS training). The ID warm-up\naims to provide initial discrimination information to the contrastive loss\ngradients. The GS training stage aims to utilize the discrimination information\ncontained in the contrastive loss gradients and adaptively select regions in\nRSI patches that contain more singular ground objects, in order to construct\nnew positive and negative samples. Experimental results on three open datasets\ndemonstrate that GraSS effectively enhances the performance of SSCL in\nhigh-resolution RSI semantic segmentation. Compared to seven baseline methods\nfrom five different types of SSCL, GraSS achieves an average improvement of\n1.57\\% and a maximum improvement of 3.58\\% in terms of mean intersection over\nthe union. The source code is available at https://github.com/GeoX-Lab/GraSS\n","authors":["Zhaoyang Zhang","Zhen Ren","Chao Tao","Yunsheng Zhang","Chengli Peng","Haifeng Li"],"pdf_url":"https://arxiv.org/pdf/2306.15868v3.pdf","comment":"14 pages, 10 figures, 4 tables"},{"id":"http://arxiv.org/abs/2310.11676v3","updated":"2023-11-28T03:42:30Z","published":"2023-10-18T02:59:57Z","title":"PREM: A Simple Yet Effective Approach for Node-Level Graph Anomaly\n  Detection","summary":"  Node-level graph anomaly detection (GAD) plays a critical role in identifying\nanomalous nodes from graph-structured data in various domains such as medicine,\nsocial networks, and e-commerce. However, challenges have arisen due to the\ndiversity of anomalies and the dearth of labeled data. Existing methodologies -\nreconstruction-based and contrastive learning - while effective, often suffer\nfrom efficiency issues, stemming from their complex objectives and elaborate\nmodules. To improve the efficiency of GAD, we introduce a simple method termed\nPREprocessing and Matching (PREM for short). Our approach streamlines GAD,\nreducing time and memory consumption while maintaining powerful anomaly\ndetection capabilities. Comprising two modules - a pre-processing module and an\nego-neighbor matching module - PREM eliminates the necessity for\nmessage-passing propagation during training, and employs a simple contrastive\nloss, leading to considerable reductions in training time and memory usage.\nMoreover, through rigorous evaluations of five real-world datasets, our method\ndemonstrated robustness and effectiveness. Notably, when validated on the ACM\ndataset, PREM achieved a 5% improvement in AUC, a 9-fold increase in training\nspeed, and sharply reduce memory usage compared to the most efficient baseline.\n","authors":["Junjun Pan","Yixin Liu","Yizhen Zheng","Shirui Pan"],"pdf_url":"https://arxiv.org/pdf/2310.11676v3.pdf","comment":"Accepted by IEEE International Conference of Data Mining 2023 (ICDM\n  2023)"},{"id":"http://arxiv.org/abs/2007.10784v3","updated":"2023-11-28T03:35:32Z","published":"2020-07-16T21:14:45Z","title":"OccamNet: A Fast Neural Model for Symbolic Regression at Scale","summary":"  Neural networks' expressiveness comes at the cost of complex, black-box\nmodels that often extrapolate poorly beyond the domain of the training dataset,\nconflicting with the goal of finding compact analytic expressions to describe\nscientific data. We introduce OccamNet, a neural network model that finds\ninterpretable, compact, and sparse symbolic fits to data, \\`a la Occam's razor.\nOur model defines a probability distribution over functions with efficient\nsampling and function evaluation. We train by sampling functions and biasing\nthe probability mass toward better fitting solutions, backpropagating using\ncross-entropy matching in a reinforcement-learning loss. OccamNet can identify\nsymbolic fits for a variety of problems, including analytic and non-analytic\nfunctions, implicit functions, and simple image classification, and can\noutperform state-of-the-art symbolic regression methods on real-world\nregression datasets. Our method requires a minimal memory footprint, fits\ncomplicated functions in minutes on a single CPU, and scales on a GPU.\n","authors":["Owen Dugan","Rumen Dangovski","Allan Costa","Samuel Kim","Pawan Goyal","Joseph Jacobson","Marin Soljačić"],"pdf_url":"https://arxiv.org/pdf/2007.10784v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16459v1","updated":"2023-11-28T03:34:22Z","published":"2023-11-28T03:34:22Z","title":"On the Effect of Defections in Federated Learning and How to Prevent\n  Them","summary":"  Federated learning is a machine learning protocol that enables a large\npopulation of agents to collaborate over multiple rounds to produce a single\nconsensus model. There are several federated learning applications where agents\nmay choose to defect permanently$-$essentially withdrawing from the\ncollaboration$-$if they are content with their instantaneous model in that\nround. This work demonstrates the detrimental impact of such defections on the\nfinal model's robustness and ability to generalize. We also show that current\nfederated optimization algorithms fail to disincentivize these harmful\ndefections. We introduce a novel optimization algorithm with theoretical\nguarantees to prevent defections while ensuring asymptotic convergence to an\neffective solution for all participating agents. We also provide numerical\nexperiments to corroborate our findings and demonstrate the effectiveness of\nour algorithm.\n","authors":["Minbiao Han","Kumar Kshitij Patel","Han Shao","Lingxiao Wang"],"pdf_url":"https://arxiv.org/pdf/2311.16459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.13164v2","updated":"2023-11-28T03:13:42Z","published":"2023-10-19T21:31:11Z","title":"Almost Equivariance via Lie Algebra Convolutions","summary":"  Recently, the equivariance of models with respect to a group action has\nbecome an important topic of research in machine learning. However, imbuing an\narchitecture with a specific group equivariance imposes a strong prior on the\ntypes of data transformations that the model expects to see. While\nstrictly-equivariant models enforce symmetries, real-world data does not always\nconform to such strict equivariances, be it due to noise in the data or\nunderlying physical laws that encode only approximate or partial symmetries. In\nsuch cases, the prior of strict equivariance can actually prove too strong and\ncause models to underperform on real-world data. Therefore, in this work we\nstudy a closely related topic, that of almost equivariance. We provide a\ndefinition of almost equivariance that differs from those extant in the current\nliterature and give a practical method for encoding almost equivariance in\nmodels by appealing to the Lie algebra of a Lie group. Specifically, we define\nLie algebra convolutions and demonstrate that they offer several benefits over\nLie group convolutions, including being well-defined for non-compact groups.\nFrom there, we pivot to the realm of theory and demonstrate connections between\nthe notions of equivariance and isometry and those of almost equivariance and\nalmost isometry, respectively. We prove two existence theorems, one showing the\nexistence of almost isometries within bounded distance of isometries of a\ngeneral manifold, and another showing the converse for Hilbert spaces. We then\nextend these theorems to prove the existence of almost equivariant manifold\nembeddings within bounded distance of fully equivariant embedding functions,\nsubject to certain constraints on the group action and the function class.\nFinally, we demonstrate the validity of our approach by benchmarking against\ndatasets in fully equivariant and almost equivariant settings.\n","authors":["Daniel McNeela"],"pdf_url":"https://arxiv.org/pdf/2310.13164v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16442v1","updated":"2023-11-28T02:44:59Z","published":"2023-11-28T02:44:59Z","title":"Enabling Fast 2-bit LLM on GPUs: Memory Alignment, Sparse Outlier, and\n  Asynchronous Dequantization","summary":"  Large language models (LLMs) have demonstrated impressive abilities in\nvarious domains while the inference cost is expensive. The state-of-the-art\nmethods use 2-bit quantization for mainstream LLMs. However, challenges still\nexist: (1) Nonnegligible accuracy loss for 2-bit quantization. Weights are\nquantized by groups, while the ranges of weights are large in some groups,\nresulting in large quantization errors and nonnegligible accuracy loss (e.g.\n>3% for Llama2-7b with 2-bit quantization in GPTQ and Greenbit). (2) Limited\naccuracy improvement by adding 4-bit weights. Increasing 10% extra average bit\nmore 4-bit weights only leads to <0.5% accuracy improvement on a quantized\nLlama2-7b. (3) Time-consuming dequantization operations on GPUs. The\ndequantization operations lead to >50% execution time, hindering the potential\nof reducing LLM inference cost. To tackle these challenges, we propose the\nfollowing techniques: (1) We only quantize a small fraction of groups with the\nlarger range using 4-bit with memory alignment consideration on GPUs. (2) We\npoint out that the distribution of the sparse outliers with larger weights is\ndifferent in 2-bit and 4-bit groups, and only a small fraction of outliers\nrequire 16-bit quantization. Such design leads to >0.5% accuracy improvement\nwith <3% average increased bit for Llama2-7b. (3) We design the asynchronous\ndequantization on GPUs, leading to up to 3.92X speedup. We conduct extensive\nexperiments on different model families and model sizes. We achieve 2.85-bit\nfor each weight and the end-to-end speedup for Llama2-7b is 1.74X over the\noriginal model, and we reduce both runtime cost and hardware cost by up to\n2.70X and 2.81X with less GPU requirements.\n","authors":["Jinhao Li","Shiyao Li","Jiaming Xu","Shan Huang","Yaoxiu Lian","Jun Liu","Yu Wang","Guohao Dai"],"pdf_url":"https://arxiv.org/pdf/2311.16442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.00154v2","updated":"2023-11-28T02:28:21Z","published":"2023-06-30T22:05:34Z","title":"Stitched ViTs are Flexible Vision Backbones","summary":"  Large pretrained plain vision Transformers (ViTs) have been the workhorse for\nmany downstream tasks. However, existing works utilizing off-the-shelf ViTs are\ninefficient in terms of training and deployment, because adopting ViTs with\nindividual sizes requires separate trainings and is restricted by fixed\nperformance-efficiency trade-offs. In this paper, we are inspired by stitchable\nneural networks (SN-Net), which is a new framework that cheaply produces a\nsingle model that covers rich subnetworks by stitching pretrained model\nfamilies, supporting diverse performance-efficiency trade-offs at runtime.\nBuilding upon this foundation, we introduce SN-Netv2, a systematically improved\nmodel stitching framework to facilitate downstream task adaptation.\nSpecifically, we first propose a two-way stitching scheme to enlarge the\nstitching space. We then design a resource-constrained sampling strategy that\ntakes into account the underlying FLOPs distributions in the space for better\nsampling. Finally, we observe that learning stitching layers as a low-rank\nupdate plays an essential role on downstream tasks to stabilize training and\nensure a good Pareto frontier. With extensive experiments on ImageNet-1K,\nADE20K, COCO-Stuff-10K and NYUv2, SN-Netv2 demonstrates superior performance\nover SN-Netv1 on downstream dense predictions and shows strong ability as a\nflexible vision backbone, achieving great advantages in both training\nefficiency and deployment flexibility. Code is available at\nhttps://github.com/ziplab/SN-Netv2.\n","authors":["Zizheng Pan","Jing Liu","Haoyu He","Jianfei Cai","Bohan Zhuang"],"pdf_url":"https://arxiv.org/pdf/2307.00154v2.pdf","comment":"Tech report"},{"id":"http://arxiv.org/abs/2311.16432v1","updated":"2023-11-28T02:27:31Z","published":"2023-11-28T02:27:31Z","title":"Text-Driven Image Editing via Learnable Regions","summary":"  Language has emerged as a natural interface for image editing. In this paper,\nwe introduce a method for region-based image editing driven by textual prompts,\nwithout the need for user-provided masks or sketches. Specifically, our\napproach leverages an existing pretrained text-to-image model and introduces a\nbounding box generator to find the edit regions that are aligned with the\ntextual prompts. We show that this simple approach enables flexible editing\nthat is compatible with current image generation models, and is able to handle\ncomplex prompts featuring multiple objects, complex sentences or long\nparagraphs. We conduct an extensive user study to compare our method against\nstate-of-the-art methods. Experiments demonstrate the competitive performance\nof our method in manipulating images with high fidelity and realism that align\nwith the language descriptions provided. Our project webpage:\nhttps://yuanze-lin.me/LearnableRegions_page.\n","authors":["Yuanze Lin","Yi-Wen Chen","Yi-Hsuan Tsai","Lu Jiang","Ming-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2311.16432v1.pdf","comment":"Project webpage: https://yuanze-lin.me/LearnableRegions_page"},{"id":"http://arxiv.org/abs/2311.16424v1","updated":"2023-11-28T02:08:06Z","published":"2023-11-28T02:08:06Z","title":"Manifold Preserving Guided Diffusion","summary":"  Despite the recent advancements, conditional image generation still faces\nchallenges of cost, generalizability, and the need for task-specific training.\nIn this paper, we propose Manifold Preserving Guided Diffusion (MPGD), a\ntraining-free conditional generation framework that leverages pretrained\ndiffusion models and off-the-shelf neural networks with minimal additional\ninference cost for a broad range of tasks. Specifically, we leverage the\nmanifold hypothesis to refine the guided diffusion steps and introduce a\nshortcut algorithm in the process. We then propose two methods for on-manifold\ntraining-free guidance using pre-trained autoencoders and demonstrate that our\nshortcut inherently preserves the manifolds when applied to latent diffusion\nmodels. Our experiments show that MPGD is efficient and effective for solving a\nvariety of conditional generation applications in low-compute settings, and can\nconsistently offer up to 3.8x speed-ups with the same number of diffusion steps\nwhile maintaining high sample quality compared to the baselines.\n","authors":["Yutong He","Naoki Murata","Chieh-Hsin Lai","Yuhta Takida","Toshimitsu Uesaka","Dongjun Kim","Wei-Hsiang Liao","Yuki Mitsufuji","J. Zico Kolter","Ruslan Salakhutdinov","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2311.16424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16420v1","updated":"2023-11-28T02:00:47Z","published":"2023-11-28T02:00:47Z","title":"Model-free Test Time Adaptation for Out-Of-Distribution Detection","summary":"  Out-of-distribution (OOD) detection is essential for the reliability of ML\nmodels. Most existing methods for OOD detection learn a fixed decision\ncriterion from a given in-distribution dataset and apply it universally to\ndecide if a data point is OOD. Recent work~\\cite{fang2022is} shows that given\nonly in-distribution data, it is impossible to reliably detect OOD data without\nextra assumptions. Motivated by the theoretical result and recent exploration\nof test-time adaptation methods, we propose a Non-Parametric Test Time\n\\textbf{Ada}ptation framework for \\textbf{O}ut-Of-\\textbf{D}istribution\n\\textbf{D}etection (\\abbr). Unlike conventional methods, \\abbr utilizes online\ntest samples for model adaptation during testing, enhancing adaptability to\nchanging data distributions. The framework incorporates detected OOD instances\ninto decision-making, reducing false positive rates, particularly when ID and\nOOD distributions overlap significantly. We demonstrate the effectiveness of\n\\abbr through comprehensive experiments on multiple OOD detection benchmarks,\nextensive empirical studies show that \\abbr significantly improves the\nperformance of OOD detection over state-of-the-art methods. Specifically, \\abbr\nreduces the false positive rate (FPR95) by $23.23\\%$ on the CIFAR-10 benchmarks\nand $38\\%$ on the ImageNet-1k benchmarks compared to the advanced methods.\nLastly, we theoretically verify the effectiveness of \\abbr.\n","authors":["YiFan Zhang","Xue Wang","Tian Zhou","Kun Yuan","Zhang Zhang","Liang Wang","Rong Jin","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2311.16420v1.pdf","comment":"12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2309.02705v2","updated":"2023-11-28T01:56:17Z","published":"2023-09-06T04:37:20Z","title":"Certifying LLM Safety against Adversarial Prompting","summary":"  Large language models (LLMs) released for public use incorporate guardrails\nto ensure their output is safe, often referred to as \"model alignment.\" An\naligned language model should decline a user's request to produce harmful\ncontent. However, such safety measures are vulnerable to adversarial attacks,\nwhich add maliciously designed token sequences to a harmful prompt to bypass\nthe model's safety guards. In this work, we introduce erase-and-check, the\nfirst framework to defend against adversarial prompts with verifiable safety\nguarantees. We defend against three attack modes: i) adversarial suffix, which\nappends an adversarial sequence at the end of the prompt; ii) adversarial\ninsertion, where the adversarial sequence is inserted anywhere in the middle of\nthe prompt; and iii) adversarial infusion, where adversarial tokens are\ninserted at arbitrary positions in the prompt, not necessarily as a contiguous\nblock. Our experimental results demonstrate that this procedure can obtain\nstrong certified safety guarantees on harmful prompts while maintaining good\nempirical performance on safe prompts. For example, against adversarial\nsuffixes of length 20, it certifiably detects 92% of harmful prompts and labels\n94% of safe prompts correctly using the open-source language model Llama 2 as\nthe safety filter. We further improve the filter's performance, in terms of\naccuracy and speed, by replacing Llama 2 with a DistilBERT safety classifier\nfine-tuned on safe and harmful prompts. Additionally, we propose two efficient\nempirical defenses: i) RandEC, a randomized version of erase-and-check that\nevaluates the safety filter on a small subset of the erased subsequences, and\nii) GradEC, a gradient-based version that optimizes the erased tokens to remove\nthe adversarial sequence. The code for our experiments is available at\nhttps://github.com/aounon/certified-llm-safety.\n","authors":["Aounon Kumar","Chirag Agarwal","Suraj Srinivas","Aaron Jiaxun Li","Soheil Feizi","Himabindu Lakkaraju"],"pdf_url":"https://arxiv.org/pdf/2309.02705v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.16416v1","updated":"2023-11-28T01:49:51Z","published":"2023-11-28T01:49:51Z","title":"A Combinatorial Approach to Robust PCA","summary":"  We study the problem of recovering Gaussian data under adversarial\ncorruptions when the noises are low-rank and the corruptions are on the\ncoordinate level. Concretely, we assume that the Gaussian noises lie in an\nunknown $k$-dimensional subspace $U \\subseteq \\mathbb{R}^d$, and $s$ randomly\nchosen coordinates of each data point fall into the control of an adversary.\nThis setting models the scenario of learning from high-dimensional yet\nstructured data that are transmitted through a highly-noisy channel, so that\nthe data points are unlikely to be entirely clean.\n  Our main result is an efficient algorithm that, when $ks^2 = O(d)$, recovers\nevery single data point up to a nearly-optimal $\\ell_1$ error of $\\tilde\nO(ks/d)$ in expectation. At the core of our proof is a new analysis of the\nwell-known Basis Pursuit (BP) method for recovering a sparse signal, which is\nknown to succeed under additional assumptions (e.g., incoherence or the\nrestricted isometry property) on the underlying subspace $U$. In contrast, we\npresent a novel approach via studying a natural combinatorial problem and show\nthat, over the randomness in the support of the sparse signal, a\nhigh-probability error bound is possible even if the subspace $U$ is arbitrary.\n","authors":["Weihao Kong","Mingda Qiao","Rajat Sen"],"pdf_url":"https://arxiv.org/pdf/2311.16416v1.pdf","comment":"To appear at ITCS 2024"},{"id":"http://arxiv.org/abs/2206.01370v3","updated":"2023-11-28T01:01:54Z","published":"2022-06-03T02:41:59Z","title":"Towards Improving the Generation Quality of Autoregressive Slot VAEs","summary":"  Unconditional scene inference and generation are challenging to learn jointly\nwith a single compositional model. Despite encouraging progress on models that\nextract object-centric representations (''slots'') from images, unconditional\ngeneration of scenes from slots has received less attention. This is primarily\nbecause learning the multi-object relations necessary to imagine coherent\nscenes is difficult. We hypothesize that most existing slot-based models have a\nlimited ability to learn object correlations. We propose two improvements that\nstrengthen object correlation learning. The first is to condition the slots on\na global, scene-level variable that captures higher-order correlations between\nslots. Second, we address the fundamental lack of a canonical order for objects\nin images by proposing to learn a consistent order to use for the\nautoregressive generation of scene objects. Specifically, we train an\nautoregressive slot prior to sequentially generate scene objects following a\nlearned order. Ordered slot inference entails first estimating a randomly\nordered set of slots using existing approaches for extracting slots from\nimages, then aligning those slots to ordered slots generated autoregressively\nwith the slot prior. Our experiments across three multi-object environments\ndemonstrate clear gains in unconditional scene generation quality. Detailed\nablation studies are also provided that validate the two proposed improvements.\n","authors":["Patrick Emami","Pan He","Sanjay Ranka","Anand Rangarajan"],"pdf_url":"https://arxiv.org/pdf/2206.01370v3.pdf","comment":"Published in Neural Computation. 38 pages, 18 figures. Code and\n  videos available at https://github.com/pemami4911/segregate-relate-imagine"},{"id":"http://arxiv.org/abs/2306.13053v2","updated":"2023-11-28T00:53:55Z","published":"2023-06-22T17:20:30Z","title":"Context-lumpable stochastic bandits","summary":"  We consider a contextual bandit problem with $S$ contexts and $K$ actions. In\neach round $t=1,2,\\dots$, the learner observes a random context and chooses an\naction based on its past experience. The learner then observes a random reward\nwhose mean is a function of the context and the action for the round. Under the\nassumption that the contexts can be lumped into $r\\le \\min\\{S,K\\}$ groups such\nthat the mean reward for the various actions is the same for any two contexts\nthat are in the same group, we give an algorithm that outputs an\n$\\epsilon$-optimal policy after using at most $\\widetilde O(r (S +K\n)/\\epsilon^2)$ samples with high probability and provide a matching\n$\\Omega(r(S+K)/\\epsilon^2)$ lower bound. In the regret minimization setting, we\ngive an algorithm whose cumulative regret up to time $T$ is bounded by\n$\\widetilde O(\\sqrt{r^3(S+K)T})$. To the best of our knowledge, we are the\nfirst to show the near-optimal sample complexity in the PAC setting and\n$\\widetilde O(\\sqrt{{poly}(r)(S+K)T})$ minimax regret in the online setting for\nthis problem. We also show our algorithms can be applied to more general\nlow-rank bandits and get improved regret bounds in some scenarios.\n","authors":["Chung-Wei Lee","Qinghua Liu","Yasin Abbasi-Yadkori","Chi Jin","Tor Lattimore","Csaba Szepesvári"],"pdf_url":"https://arxiv.org/pdf/2306.13053v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.03017v3","updated":"2023-11-28T00:31:49Z","published":"2022-07-06T23:51:44Z","title":"ACHO: Adaptive Conformal Hyperparameter Optimization","summary":"  Several novel frameworks for hyperparameter search have emerged in the last\ndecade, but most rely on strict, often normal, distributional assumptions,\nlimiting search model flexibility. This paper proposes a novel optimization\nframework based on upper confidence bound sampling of conformal confidence\nintervals, whose weaker assumption of exchangeability enables greater choice of\nsearch model architectures. Several such architectures were explored and\nbenchmarked on hyperparameter search of random forests and convolutional neural\nnetworks, displaying satisfactory interval coverage and superior tuning\nperformance to random search.\n","authors":["Riccardo Doyle"],"pdf_url":"https://arxiv.org/pdf/2207.03017v3.pdf","comment":"12 pages, 4 tables, 4 figures"},{"id":"http://arxiv.org/abs/2303.09373v2","updated":"2023-11-28T00:07:12Z","published":"2023-03-16T15:01:50Z","title":"MAPSeg: Unified Unsupervised Domain Adaptation for Heterogeneous Medical\n  Image Segmentation Based on 3D Masked Autoencoding and Pseudo-Labeling","summary":"  Robust segmentation is critical for deriving quantitative measures from\nlarge-scale, multi-center, and longitudinal medical scans. Manually annotating\nmedical scans, however, is expensive and labor-intensive and may not always be\navailable in every domain. Unsupervised domain adaptation (UDA) is a\nwell-studied technique that alleviates this label-scarcity problem by\nleveraging available labels from another domain. In this study, we introduce\nMasked Autoencoding and Pseudo-Labeling Segmentation (MAPSeg), a\n$\\textbf{unified}$ UDA framework with great versatility and superior\nperformance for heterogeneous and volumetric medical image segmentation. To the\nbest of our knowledge, this is the first study that systematically reviews and\ndevelops a framework to tackle four different domain shifts in medical image\nsegmentation. More importantly, MAPSeg is the first framework that can be\napplied to $\\textbf{centralized}$, $\\textbf{federated}$, and\n$\\textbf{test-time}$ UDA while maintaining comparable performance. We compare\nMAPSeg with previous state-of-the-art methods on a private infant brain MRI\ndataset and a public cardiac CT-MRI dataset, and MAPSeg outperforms others by a\nlarge margin (10.5 Dice improvement on the private MRI dataset and 5.7 on the\npublic CT-MRI dataset). MAPSeg poses great practical value and can be applied\nto real-world problems. Our code and pretrained model will be available later.\n","authors":["Xuzhe Zhang","Yuhao Wu","Elsa Angelini","Ang Li","Jia Guo","Jerod M. Rasmussen","Thomas G. O'Connor","Pathik D. Wadhwa","Andrea Parolin Jackowski","Hai Li","Jonathan Posner","Andrew F. Laine","Yun Wang"],"pdf_url":"https://arxiv.org/pdf/2303.09373v2.pdf","comment":"16 pages and 7 figures. Revised and extended to test-time and\n  federated domain adaptation. Xuzhe Zhang and Yuhao Wu are co-first authors.\n  Andrew F. Laine and Yun Wang are co-senior supervising authors"},{"id":"http://arxiv.org/abs/2311.16381v1","updated":"2023-11-28T00:03:18Z","published":"2023-11-28T00:03:18Z","title":"Deep Learning for Time Series Classification of Parkinson's Disease Eye\n  Tracking Data","summary":"  Eye-tracking is an accessible and non-invasive technology that provides\ninformation about a subject's motor and cognitive abilities. As such, it has\nproven to be a valuable resource in the study of neurodegenerative diseases\nsuch as Parkinson's disease. Saccade experiments, in particular, have proven\nuseful in the diagnosis and staging of Parkinson's disease. However, to date,\nno single eye-movement biomarker has been found to conclusively differentiate\npatients from healthy controls. In the present work, we investigate the use of\nstate-of-the-art deep learning algorithms to perform Parkinson's disease\nclassification using eye-tracking data from saccade experiments. In contrast to\nprevious work, instead of using hand-crafted features from the saccades, we use\nraw $\\sim1.5\\,s$ long fixation intervals recorded during the preparatory phase\nbefore each trial. Using these short time series as input we implement two\ndifferent classification models, InceptionTime and ROCKET. We find that the\nmodels are able to learn the classification task and generalize to unseen\nsubjects. InceptionTime achieves $78\\%$ accuracy, while ROCKET achieves $88\\%$\naccuracy. We also employ a novel method for pruning the ROCKET model to improve\ninterpretability and generalizability, achieving an accuracy of $96\\%$. Our\nresults suggest that fixation data has low inter-subject variability and\npotentially carries useful information about brain cognitive and motor\nconditions, making it suitable for use with machine learning in the discovery\nof disease-relevant biomarkers.\n","authors":["Gonzalo Uribarri","Simon Ekman von Huth","Josefine Waldthaler","Per Svenningsson","Erik Fransén"],"pdf_url":"https://arxiv.org/pdf/2311.16381v1.pdf","comment":"Extended Abstract presented at Machine Learning for Health (ML4H)\n  symposium 2023, December 10th, 2023, New Orleans, United States, 12 pages"}],"Multimedia":[{"id":"http://arxiv.org/abs/2311.13409v2","updated":"2023-11-28T12:12:46Z","published":"2023-11-22T14:13:27Z","title":"CompenHR: Efficient Full Compensation for High-resolution Projector","summary":"  Full projector compensation is a practical task of projector-camera systems.\nIt aims to find a projector input image, named compensation image, such that\nwhen projected it cancels the geometric and photometric distortions due to the\nphysical environment and hardware. State-of-the-art methods use deep learning\nto address this problem and show promising performance for low-resolution\nsetups. However, directly applying deep learning to high-resolution setups is\nimpractical due to the long training time and high memory cost. To address this\nissue, this paper proposes a practical full compensation solution. Firstly, we\ndesign an attention-based grid refinement network to improve geometric\ncorrection quality. Secondly, we integrate a novel sampling scheme into an\nend-to-end compensation network to alleviate computation and introduce\nattention blocks to preserve key features. Finally, we construct a benchmark\ndataset for high-resolution projector full compensation. In experiments, our\nmethod demonstrates clear advantages in both efficiency and quality.\n","authors":["Yuxi Wang","Haibin Ling","Bingyao Huang"],"pdf_url":"https://arxiv.org/pdf/2311.13409v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.11255v2","updated":"2023-11-28T10:24:12Z","published":"2023-11-19T06:50:52Z","title":"M$^{2}$UGen: Multi-modal Music Understanding and Generation with the\n  Power of Large Language Models","summary":"  The current landscape of research leveraging large language models (LLMs) is\nexperiencing a surge. Many works harness the powerful reasoning capabilities of\nthese models to comprehend various modalities, such as text, speech, images,\nvideos, etc. They also utilize LLMs to understand human intention and generate\ndesired outputs like images, videos, and music. However, research that combines\nboth understanding and generation using LLMs is still limited and in its\nnascent stage. To address this gap, we introduce a Multi-modal Music\nUnderstanding and Generation (M$^{2}$UGen) framework that integrates LLM's\nabilities to comprehend and generate music for different modalities. The\nM$^{2}$UGen framework is purpose-built to unlock creative potential from\ndiverse sources of inspiration, encompassing music, image, and video through\nthe use of pretrained MERT, ViT, and ViViT models, respectively. To enable\nmusic generation, we explore the use of AudioLDM 2 and MusicGen. Bridging\nmulti-modal understanding and music generation is accomplished through the\nintegration of the LLaMA 2 model. Furthermore, we make use of the MU-LLaMA\nmodel to generate extensive datasets that support text/image/video-to-music\ngeneration, facilitating the training of our M$^{2}$UGen framework. We conduct\na thorough evaluation of our proposed framework. The experimental results\ndemonstrate that our model achieves or surpasses the performance of the current\nstate-of-the-art models.\n","authors":["Atin Sakkeer Hussain","Shansong Liu","Chenshuo Sun","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2311.11255v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08006v3","updated":"2023-11-28T00:57:15Z","published":"2023-10-12T03:19:13Z","title":"MCPNS: A Macropixel Collocated Position and Its Neighbors Search for\n  Plenoptic 2.0 Video Coding","summary":"  Recently, it was demonstrated that a newly focused plenoptic 2.0 camera can\ncapture much higher spatial resolution owing to its effective light field\nsampling, as compared to a traditional unfocused plenoptic 1.0 camera. However,\ndue to the nature difference of the optical structure between the plenoptic 1.0\nand 2.0 cameras, the existing fast motion estimation (ME) method for plenoptic\n1.0 videos is expected to be sub-optimal for encoding plenoptic 2.0 videos. In\nthis paper, we point out the main motion characteristic differences between\nplenoptic 1.0 and 2.0 videos and then propose a new fast ME, called macropixel\ncollocated position and its neighbors search (MCPNS) for plenoptic 2.0 videos.\nIn detail, we propose to reduce the number of macropixel collocated position\n(MCP) search candidates based on the new observation of center-biased motion\nvector distribution at macropixel resolution. After that, due to large motion\ndeviation behavior around each MCP location in plenoptic 2.0 videos, we propose\nto select a certain number of key MCP locations with the lowest matching cost\nto perform the neighbors MCP search to improve the motion search accuracy.\nDifferent from existing methods, our method can achieve better performance\nwithout requiring prior knowledge of microlens array orientations. Our\nsimulation results confirmed the effectiveness of the proposed algorithm in\nterms of both bitrate savings and computational costs compared to existing\nmethods.\n","authors":["Vinh Van Duong","Thuc Nguyen Huu","Jonghoon Yim","Byeungwoo Jeon"],"pdf_url":"https://arxiv.org/pdf/2310.08006v3.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2311.14680v2","updated":"2023-11-28T10:03:24Z","published":"2023-11-01T18:25:13Z","title":"E-polis: A serious game for the gamification of sociological surveys","summary":"  E-polis is a multi-platform serious game that gamifies a sociological survey\nfor studying young people's opinions regarding their ideal society. The\ngameplay is based on a user navigating through a digital city, experiencing the\nchanges inflicted, triggered by responses to social and pedagogical surveys,\nknown as \"dilemmas\". The game integrates elements of adventure, exploration,\nand simulation. Unity was the selected game engine used for the development of\nthe game, while a middleware component was also developed to gather and process\nthe users' data. At the end of each game, users are presented with a blueprint\nof the city they navigated to showcase how their choices influenced its\ndevelopment. This motivates them to reflect on their answers and validate them.\nThe game can be used to collect data on a variety of topics, such as social\njustice, and economic development, or to promote civic engagement and encourage\nyoung people to think critically about the world around them.\n","authors":["Alexandros Gazis","Eleftheria Katsiri"],"pdf_url":"https://arxiv.org/pdf/2311.14680v2.pdf","comment":"8 pages, 11 figures, Proceedings of the International Conference on\n  Applied Mathematics & Computer Science (ICAMCS) 2023"},{"id":"http://arxiv.org/abs/2308.02816v2","updated":"2023-11-28T17:06:48Z","published":"2023-08-05T08:12:34Z","title":"PromptCARE: Prompt Copyright Protection by Watermark Injection and\n  Verification","summary":"  Large language models (LLMs) have witnessed a meteoric rise in popularity\namong the general public users over the past few months, facilitating diverse\ndownstream tasks with human-level accuracy and proficiency. Prompts play an\nessential role in this success, which efficiently adapt pre-trained LLMs to\ntask-specific applications by simply prepending a sequence of tokens to the\nquery texts. However, designing and selecting an optimal prompt can be both\nexpensive and demanding, leading to the emergence of Prompt-as-a-Service\nproviders who profit by providing well-designed prompts for authorized use.\nWith the growing popularity of prompts and their indispensable role in\nLLM-based services, there is an urgent need to protect the copyright of prompts\nagainst unauthorized use.\n  In this paper, we propose PromptCARE, the first framework for prompt\ncopyright protection through watermark injection and verification. Prompt\nwatermarking presents unique challenges that render existing watermarking\ntechniques developed for model and dataset copyright verification ineffective.\nPromptCARE overcomes these hurdles by proposing watermark injection and\nverification schemes tailor-made for prompts and NLP characteristics. Extensive\nexperiments on six well-known benchmark datasets, using three prevalent\npre-trained LLMs (BERT, RoBERTa, and Facebook OPT-1.3b), demonstrate the\neffectiveness, harmlessness, robustness, and stealthiness of PromptCARE.\n","authors":["Hongwei Yao","Jian Lou","Kui Ren","Zhan Qin"],"pdf_url":"https://arxiv.org/pdf/2308.02816v2.pdf","comment":"To Appear in the 45th IEEE Symposium on Security and Privacy 2024,\n  code is available at: https://github.com/grasses/PromptCARE"},{"id":"http://arxiv.org/abs/2311.16462v1","updated":"2023-11-28T03:45:29Z","published":"2023-11-28T03:45:29Z","title":"Viewport Prediction for Volumetric Video Streaming by Exploring Video\n  Saliency and Trajectory Information","summary":"  Volumetric video, also known as hologram video, is a novel medium that\nportrays natural content in Virtual Reality (VR), Augmented Reality (AR), and\nMixed Reality (MR). It is expected to be the next-gen video technology and a\nprevalent use case for 5G and beyond wireless communication. Considering that\neach user typically only watches a section of the volumetric video, known as\nthe viewport, it is essential to have precise viewport prediction for optimal\nperformance. However, research on this topic is still in its infancy. In the\nend, this paper presents and proposes a novel approach, named Saliency and\nTrajectory Viewport Prediction (STVP), which aims to improve the precision of\nviewport prediction in volumetric video streaming. The STVP extensively\nutilizes video saliency information and viewport trajectory. To our knowledge,\nthis is the first comprehensive study of viewport prediction in volumetric\nvideo streaming. In particular, we introduce a novel sampling method, Uniform\nRandom Sampling (URS), to reduce computational complexity while still\npreserving video features in an efficient manner. Then we present a saliency\ndetection technique that incorporates both spatial and temporal information for\ndetecting static, dynamic geometric, and color salient regions. Finally, we\nintelligently fuse saliency and trajectory information to achieve more accurate\nviewport prediction. We conduct extensive simulations to evaluate the\neffectiveness of our proposed viewport prediction methods using\nstate-of-the-art volumetric video sequences. The experimental results show the\nsuperiority of the proposed method over existing schemes. The dataset and\nsource code will be publicly accessible after acceptance.\n","authors":["Jie Li","Zhixin Li","Zhi Liu","Pengyuan Zhou","Richang Hong","Qiyue Li","Han Hu"],"pdf_url":"https://arxiv.org/pdf/2311.16462v1.pdf","comment":null}]}}